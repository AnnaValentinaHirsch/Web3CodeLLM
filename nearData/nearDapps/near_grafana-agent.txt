*GitHub Repository "near/grafana-agent"*

'''--- .drone/README.md ---
When updating the drone.yml file the file must be re-signed using `make drone`. This is limited to Grafana employees for security reasons.

Drone environment variables will need to be setup beforehand.

```
export DRONE_SERVER=<url>
export DRONE_TOKEN=<token>
```

'''
'''--- .drone/drone.yml ---
---
kind: pipeline
type: docker
name: Create Linux build image
platform:
  os: linux
  arch: amd64
trigger:
  event: [tag]
  ref: [refs/tags/build-image/v*]
steps:
  - name: Build
    image: docker
    volumes:
      - name: docker
        path: /var/run/docker.sock
    environment:
      DOCKER_LOGIN:
        from_secret: DOCKER_LOGIN
      DOCKER_PASSWORD:
        from_secret: DOCKER_PASSWORD
    commands:
    - export IMAGE_TAG=${DRONE_TAG##build-image/v}
    - docker login -u $DOCKER_LOGIN -p $DOCKER_PASSWORD
    - docker build -t grafana/agent-build-image:$IMAGE_TAG ./build-image
    - docker push grafana/agent-build-image:$IMAGE_TAG
volumes:
  - name: docker
    host:
      path: /var/run/docker.sock

---
kind: pipeline
type: docker
name: Create Windows build image
platform:
  os: windows
  arch: amd64
  version: "1809"
trigger:
  event: [tag]
  ref: [refs/tags/build-image/v*]
steps:
  - name: Build
    image: docker:windowsservercore-1809
    volumes:
      - name: docker
        path: //./pipe/docker_engine/
    environment:
      DOCKER_LOGIN:
        from_secret: DOCKER_LOGIN
      DOCKER_PASSWORD:
        from_secret: DOCKER_PASSWORD
    commands:
      # NOTE(rfratto): the variable syntax is parsed ahead of time by Drone,
      # and not by Windows (where the syntax obviously wouldn't work).
      - $IMAGE_TAG="${DRONE_TAG##build-image/v}-windows"
      - docker login -u $Env:DOCKER_LOGIN -p $Env:DOCKER_PASSWORD
      - docker build -t grafana/agent-build-image:$IMAGE_TAG ./build-image/windows
      - docker push grafana/agent-build-image:$IMAGE_TAG
volumes:
- name: docker
  host:
    path: //./pipe/docker_engine/

---
kind: pipeline
name: Lint
platform:
  os: linux
  arch: amd64
trigger:
  event:
    - push
    - pull_request
    - tag
  ref:
    - refs/heads/main
    - refs/pull/*/head
    - refs/tags/v*

steps:
  - name: lint
    image: golangci/golangci-lint:v1.46
    commands:
      - apt-get update -y && apt-get install -y libsystemd-dev libbpfcc-dev
      - make DOCKER_OPTS="" lint

---
kind: pipeline
type: docker
name: Test
platform:
  os: linux
  arch: amd64
trigger:
  event:
    - push
    - pull_request
    - tag
  ref:
    - refs/heads/main
    - refs/pull/*/head
    - refs/tags/v*

steps:
  - name: test
    image: rfratto/seego
    volumes:
      - name: docker
        path: /var/run/docker.sock
    commands:
      - apt-get update &&  apt-get install -y rubygems rpm nsis apt-transport-https ca-certificates curl gnupg lsb-release libbpfcc-dev
      - gem install --no-document fpm
      - rm -r /usr/local/go
      - mkdir -p /usr/local/go/bin
      - wget -q https://golang.org/dl/go1.18.linux-amd64.tar.gz
      - tar -C /usr/local -xzf go1.18.linux-amd64.tar.gz
      - rm go1.18.linux-amd64.tar.gz
      - export PATH=$PATH:/usr/local/go/bin
      - make DOCKER_OPTS="" cmd/agent/agent cmd/agentctl/agentctl cmd/agent-operator/agent-operator tools/crow/grafana-agent-crow tools/smoke/grafana-agent-smoke
      - make DOCKER_OPTS="" K8S_USE_DOCKER_NETWORK=1 DRONE=true BUILD_IN_CONTAINER=false test

volumes:
 - name: docker
   host:
     path: /var/run/docker.sock
---
kind: pipeline
type: docker
name: Windows-Test
platform:
  arch: amd64
  os: windows
  version: "1809"
trigger:
  event:
    - push
    - pull_request
    - tag
  ref:
    - refs/heads/main
    - refs/pull/*/head
    - refs/tags/v*
steps:
  - name: test
    image: grafana/agent-build-image:0.14.0-windows
    commands:
      - go test -tags="nodocker,nonetwork" ./...
---
kind: pipeline
type: docker
name: Containerize
platform:
  os: linux
  arch: amd64
trigger:
  ref:
    - refs/heads/main
    - refs/tags/v*
    - refs/heads/dev.*
steps:
  - name: Build Containers
    image: docker
    volumes:
      - name: docker
        path: /var/run/docker.sock
    environment:
      DOCKER_LOGIN:
        from_secret: DOCKER_LOGIN
      DOCKER_PASSWORD:
        from_secret: DOCKER_PASSWORD
      GCR_CREDS:
        from_secret: gcr_admin
    commands:
      - mkdir -p $HOME/.docker
      - printenv GCR_CREDS > $HOME/.docker/config.json
      - docker login -u $DOCKER_LOGIN -p $DOCKER_PASSWORD
      - apk update && apk add make bash wget git qemu
      - wget -q https://github.com/docker/buildx/releases/download/v0.5.1/buildx-v0.5.1.linux-amd64
      - mkdir -p ~/.docker/cli-plugins
      - cp buildx-v0.5.1.linux-amd64 ~/.docker/cli-plugins/docker-buildx
      - chmod a+x ~/.docker/cli-plugins/docker-buildx
      - docker run --rm --privileged multiarch/qemu-user-static --reset -p yes
      - docker buildx create --name multiarch --driver docker-container --use
      - export RELEASE_TAG=${DRONE_TAG}
      - export IMAGE_BRANCH_TAG=${DRONE_BRANCH}
      - make DOCKER_OPTS="" DRONE=true CROSS_BUILD=true BUILD_IN_CONTAINER=true RELEASE_BUILD=true agent-image
      - make DOCKER_OPTS="" DRONE=true CROSS_BUILD=true BUILD_IN_CONTAINER=true RELEASE_BUILD=true agentctl-image
      - make DOCKER_OPTS="" DRONE=true CROSS_BUILD=true BUILD_IN_CONTAINER=true RELEASE_BUILD=true agent-operator-image
      - make DOCKER_OPTS="" DRONE=true CROSS_BUILD=true BUILD_IN_CONTAINER=true RELEASE_BUILD=true grafana-agent-crow-image
      - make DOCKER_OPTS="" DRONE=true CROSS_BUILD=true BUILD_IN_CONTAINER=true RELEASE_BUILD=true agent-smoke-image
      - docker buildx rm multiarch

depends_on:
  - Test

volumes:
  - name: docker
    host:
      path: /var/run/docker.sock
---
kind: pipeline
type: docker
name: Deploy-To-Deployment-Tools
platform:
  os: linux
  arch: amd64
trigger:
  ref:
    - refs/heads/main

image_pull_secrets:
  - dockerconfigjson

steps:
  - name: put image tag in a file
    image: alpine
    commands:
      - apk update && apk add git
      - echo "$(sh ./tools/image-tag)" > .tag-only
      - echo "grafana/agent:$(sh ./tools/image-tag)" > .image-tag
  - name: Update Deployment Tools
    image: us.gcr.io/kubernetes-dev/drone/plugins/updater
    settings:
      config_json: |-
        {
          "destination_branch": "master",
          "pull_request_branch_prefix": "cd-agent",
          "pull_request_enabled": false,
          "pull_request_team_reviewers": [
            "agent-squad"
          ],
          "repo_name": "deployment_tools",
          "update_jsonnet_attribute_configs": [
            {
              "file_path": "ksonnet/environments/kowalski/dev-us-central-0.kowalski-dev/main.jsonnet",
              "jsonnet_key": "agent_image",
              "jsonnet_value_file": ".image-tag"
            },
            {
              "file_path": "ksonnet/environments/grafana-agent/waves/agent.libsonnet",
              "jsonnet_key": "dev_canary",
              "jsonnet_value_file": ".image-tag"
            },
            {
              "file_path": "ksonnet/environments/agent-smoke-test/dev-us-central-0.agent-smoke-test/main.jsonnet",
              "jsonnet_key": "image_tag",
              "jsonnet_value_file": ".tag-only"
            }
          ]
        }
      github_token:
        from_secret: gh_token

depends_on:
  - Containerize

volumes:
  - name: docker
    host:
      path: /var/run/docker.sock
---
kind: pipeline
type: docker
name: Release
platform:
  os: linux
  arch: amd64
trigger:
  ref:
    - refs/tags/v*

steps:
  - name: create-release
    image: rfratto/seego
    volumes:
      - name: docker
        path: /var/run/docker.sock
    environment:
      DOCKER_LOGIN:
        from_secret: DOCKER_LOGIN
      DOCKER_PASSWORD:
        from_secret: DOCKER_PASSWORD
      GITHUB_TOKEN:
        from_secret: GITHUB_KEY
      GPG_PRIVATE_KEY:
        from_secret: gpg_private_key
      GPG_PUBLIC_KEY:
        from_secret: gpg_public_key
      GPG_PASSPHRASE:
        from_secret: gpg_passphrase
    commands:
      - apt-get install -y apt-transport-https ca-certificates curl gnupg lsb-release
      - curl -fsSL https://download.docker.com/linux/debian/gpg | sudo apt-key add -
      - add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/debian bullseye stable"
      - apt-get update &&  apt-get install -y rubygems rpm nsis docker-ce docker-ce-cli containerd.io gettext
      - docker login -u $DOCKER_LOGIN -p $DOCKER_PASSWORD
      - gem install --no-document fpm
      - rm -r /usr/local/go
      - mkdir -p /usr/local/go/bin
      - wget -q https://golang.org/dl/go1.18.linux-amd64.tar.gz
      - tar -C /usr/local -xzf go1.18.linux-amd64.tar.gz
      - rm go1.18.linux-amd64.tar.gz
      - export PATH=$PATH:/usr/local/go/bin
      - GO111MODULE=on go get -u github.com/mitchellh/gox github.com/tcnksm/ghr
      - export PATH="$(go env GOPATH)/bin:$PATH"
      - make -j4 DOCKER_OPTS="" BUILD_IN_CONTAINER=false RELEASE_BUILD=true RELEASE_TAG=${DRONE_TAG} publish
depends_on:
  - Test

volumes:
  - name: docker
    host:
      path: /var/run/docker.sock

---
kind: secret
name: dockerconfigjson

get:
  path: secret/data/common/gcr
  name: .dockerconfigjson

---
kind: secret
name: gcr_admin

get:
  name: .dockerconfigjson
  path: infra/data/ci/gcr-admin

---
kind: secret
name: gh_token

get:
  path: infra/data/ci/github/grafanabot
  name: pat

---
kind: secret
name: gpg_public_key

get:
  name: public-key
  path: infra/data/ci/packages-publish/gpg

---
kind: secret
name: gpg_private_key

get:
  name: private-key
  path: infra/data/ci/packages-publish/gpg

---
kind: secret
name: gpg_passphrase

get:
  name: passphrase
  path: infra/data/ci/packages-publish/gpg

---
kind: signature
hmac: 2cf5a5ca48b13a35f2f609985ab81e5cf21bf5f31a1543fde16a74ce3ff60c13

...

'''
'''--- .github/ISSUE_TEMPLATE/BOUNTY.yml ---
name: "Simple Bounty"
description: "Use this template to create a HEROES Simple Bounty via Github bot"
title: "Bounty: "
labels: ["bounty"]
assignees: heroes-bot-test
body:
  - type: markdown
    attributes:
      value: |
        Hi! Let's set up your bounty! Please don't change the template - @heroes-bot-test won't be able to help you.

  - type: dropdown
    id: type
    attributes:
      label: What talent are you looking for?
      options:
        - Marketing
        - Development
        - Design
        - Other
        - Content
        - Research
        - Audit

  - type: textarea
    id: description
    attributes:
      label: What you need to be done?

  - type: dropdown
    id: tags
    attributes:
      label: Tags
      description: Add tags that match the topic of the work
      multiple: true
      options:
        - API
        - Blockchain
        - Community
        - CSS
        - DAO
        - dApp
        - DeFi
        - Design
        - Documentation
        - HTML
        - Javascript
        - NFT
        - React
        - Rust
        - Smart contract
        - Typescript
        - UI/UX
        - web3
        - Translation
        - Illustration
        - Branding
        - Copywriting
        - Blogging
        - Editing
        - Video Creation
        - Social Media
        - Graphic Design
        - Transcription
        - Product Design
        - Artificial Intelligence
        - Quality Assurance
        - Risk Assessment
        - Security Audit
        - Bug Bounty
        - Code Review
        - Blockchain Security
        - Smart Contract Testing
        - Penetration Testing
        - Vulnerability Assessment
        - BOS
        - News
        - Hackathon
        - NEARCON2023
        - NEARWEEK

  - type: input
    id: deadline
    attributes:
      label: Deadline
      description: "Set a deadline for your bounty. Please enter the date in format: DD.MM.YYYY"
      placeholder: "19.05.2027"

  - type: dropdown
    id: currencyType
    attributes:
      label: Currency
      description: What is the currency you want to pay?
      options:
        - USDC.e
        - USDT.e
        - DAI
        - wNEAR
        - USDt
        - XP
        - marmaj
        - NEKO
        - JUMP
        - USDC
        - NEARVIDIA
      default: 0
    validations:
      required: true

  - type: input
    id: currencyAmount
    attributes:
      label: Amount
      description: How much it will be cost?

  - type: markdown
    attributes:
      value: "## Advanced settings"

  - type: checkboxes
    id: kyc
    attributes:
      label: KYC
      description: "Use HEROES' KYC Verification, only applicants who passed HEROES' KYC can apply and work on this bounty!"
      options:
        - label: Use KYC Verification

  - type: markdown
    attributes:
      value: |
        ### This cannot be changed once the bounty is live!

'''
'''--- .github/depcheck.yml ---
# List of go modules to check for outdated-ness. The current version is
# obtained from the listing in go.mod.
go_modules:
  - github.com/cortexproject/cortex
  - github.com/drone/envsubst/v2
  - github.com/grafana/loki
  - github.com/oliver006/redis_exporter
  - github.com/prometheus-community/elasticsearch_exporter
  - github.com/prometheus/consul_exporter
  - github.com/prometheus/memcached_exporter
  - github.com/prometheus/node_exporter
  - github.com/prometheus/statsd_exporter
  - github.com/weaveworks/common
  - go.opentelemetry.io/collector
  - sigs.k8s.io/controller-runtime

# List of Github repos to check for newer tags. Only repos that are not listed
# explicitly in go.mod *OR* are in go.mod but replaced with a fork should be
# added here.
#
# The "current" version being used in the Agent must be provided explicitly as
# you can see below.
github_repos:
  - github.com/google/dnsmasq_exporter v0.2.0
  - github.com/ncabatoff/process-exporter v0.7.5
  - github.com/prometheus/mysqld_exporter v0.13.0
  - github.com/prometheus-community/postgres_exporter v0.10.0
  - github.com/prometheus-community/windows_exporter v0.16.0
  - github.com/percona/mongodb_exporter v0.20.7
  - project: github.com/prometheus/prometheus
    version: v2.27.0
    # Ignore release candidates
    ignore_version_pattern: '-rc\.\d+$'

'''
'''--- .github/dependabot.yml ---
version: 2
updates:
  - package-ecosystem: "github-actions"
    directory: "/"
    schedule:
      interval: "weekly"
  - package-ecosystem: "gomod"
    directory: "/"
    schedule:
      interval: "daily"
    open-pull-requests-limit: 2
    ignore:
      # OpenTelemetry needs special handling due to a temporary fork; exempt
      # from Dependabot auto-updating.
      - dependency-name: "github.com/open-telemetry/opentelemetry-collector-contrib/*"
      - dependency-name: "go.opentelemetry.io/collector"
      - dependency-name: "go.opentelemetry.io/collector/model"

'''
'''--- .github/pull_request_template.md ---
<!--

CONTRIBUTORS GUIDE: https://github.com/grafana/agent/blob/main/docs/developer/contributing.md#updating-the-changelog

If this is your first PR or you have not contributed in a while, we recommend
taking the time to review the guide. It gives helpful instructions for
contributors around things like how to update the changelog.

-->

#### PR Description

#### Which issue(s) this PR fixes

#### Notes to the Reviewer

#### PR Checklist

- [ ] CHANGELOG updated
- [ ] Documentation added
- [ ] Tests updated

'''
'''--- .github/workflows/bump-formula-pr.yml ---
name: bump-formula-pr
on:
  # Allows you to run this workflow manually from the Actions tab
  workflow_dispatch:
  push:
    tags:
      - 'v*'
      - '!v*-rc*' # Ignore release candidates
jobs:
  homebrew-core:
    name: homebrew-core
    runs-on: macos-latest
    steps:
    - name: Update Homebrew formula
      uses: dawidd6/action-homebrew-bump-formula@v3
      with:
        # Required, custom GitHub access token with the 'public_repo' and 'workflow' scopes
        token: ${{secrets.HOMEBREW_FORMULA_GH_TOKEN}}
        # Formula name, required
        formula: grafana-agent
        # Optional, will be determined automatically
        tag: ${{github.ref}}
        # Optional, will be determined automatically
        revision: ${{github.sha}}
        # Optional, if don't want to check for already open PRs
        force: false # true
  homebrew-grafana:
    name: homebrew-grafana
    runs-on: macos-latest
    steps:
    - name: Update Homebrew formula
      uses: dawidd6/action-homebrew-bump-formula@v3
      with:
        # Required, custom GitHub access token with the 'public_repo' and 'workflow' scopes
        token: ${{secrets.HOMEBREW_FORMULA_GH_TOKEN}}
        # Optional, defaults to homebrew/core
        tap: grafana/grafana
        # Formula name, required
        formula: grafana-agent
        # Optional, will be determined automatically
        tag: ${{github.ref}}
        # Optional, will be determined automatically
        revision: ${{github.sha}}
        # Optional, if don't want to check for already open PRs
        force: false # true

'''
'''--- .github/workflows/check_docs.yml ---
name: Check docs
on: [pull_request]
jobs:
  build-technical-documentation:
    runs-on: "ubuntu-latest"
    steps:
    - name: "Check out code"
      uses: "actions/checkout@v3"
    - name: "Build technical documentation"
      run: |
        docker run -v ${PWD}/docs/sources:/hugo/content/docs/agent/latest -e HUGO_REFLINKSERRORLEVEL=ERROR --rm grafana/docs-base:latest /bin/bash -c 'make hugo'

'''
'''--- .github/workflows/depcheck.yml ---
name: Check Dependencies
on:
  workflow_dispatch: {}
  schedule:
    - cron: '0 0 * * *'
jobs:
  check:
    name: Check
    runs-on: ubuntu-latest
    steps:
    - name: Checkout code
      uses: actions/checkout@v3

    - name: Invoke action
      uses: rfratto/depcheck@main
      with:
        github-token: ${{ secrets.GITHUB_TOKEN }}

'''
'''--- .github/workflows/publish.yml ---
name: publish_docs

on:
  push:
    branches:
      - main
      - 'release-*'
    tags:
      - 'v[0-9]+.[0-9]+.[0-9]+'
    paths:
      - 'docs/sources/**'

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - name: Check out code
        uses: actions/checkout@v3
      - name: "Build technical documentation"
        run: |
          docker run -v ${PWD}/docs/sources:/hugo/content/docs/agent/latest -e HUGO_REFLINKSERRORLEVEL=ERROR --rm grafana/docs-base:latest /bin/bash -c 'make hugo'
  sync:
    runs-on: ubuntu-latest
    needs: test
    steps:

    - name: Checkout Agent repo
      uses: actions/checkout@v3

    - name: Checkout Actions library
      uses: actions/checkout@v3
      with:
        repository: "grafana/grafana-github-actions"
        path: ./actions

    - name: Install Actions from library
      run: npm install --production --prefix ./actions

    - name: Extract semver
      uses: ./actions/docs-target
      id: target
      with:
        ref_name: ${{ github.ref_name }}

    - name: Clone website-sync Action
      run: git clone --single-branch --no-tags --depth 1 -b master https://grafanabot:${{ secrets.GH_BOT_ACCESS_TOKEN }}@github.com/grafana/website-sync ./.github/actions/website-sync

    - name: publish-to-git
      uses: ./.github/actions/website-sync
      id: publish
      with:
        repository: grafana/website
        branch: master
        host: github.com
        github_pat: '${{ secrets.GH_BOT_ACCESS_TOKEN }}'
        source_folder: docs/sources
        target_folder: 'content/docs/agent/${{ steps.target.outputs.target }}'
    - shell: bash
      run: |
        test -n "${{ steps.publish.outputs.commit_hash }}"
        test -n "${{ steps.publish.outputs.working_directory }}"

'''
'''--- .github/workflows/scripts.yml ---
name: Lint Scripts
on: [pull_request]
jobs:
  shellcheck:
    name: Shellcheck
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3
    - uses: azohra/shell-linter@latest
      with:
        path: "packaging,production"

'''
'''--- .github/workflows/stale.yml ---
name: Stale check
on:
  workflow_dispatch: {}
  schedule:
    - cron: '0 0 * * *'
permissions:
  issues: write
  pull-requests: write
jobs:
  stale:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/stale@v5.1.1
        with:
          close-issue-reason: not_planned
          days-before-stale: 30
          days-before-close: 7
          stale-issue-message: >
            This issue has been automatically marked as stale because it has
            not had any activity in the past 30 days.

            The next time this stale check runs, the stale label will be
            removed if there is new activity. The issue will be closed in 7
            days if there is no new activity.

            Thank you for your contributions!
          stale-pr-message: >
            This PR has been automatically marked as stale because it has not
            had any activity in the past 30 days.

            The next time this stale check runs, the stale label will be
            removed if there is new activity. The issue will be closed in 7
            days if there is no new activity.

            Thank you for your contributions!
          stale-issue-label: stale
          stale-pr-label: stale
          exempt-issue-labels: keepalive,proposal,outdated-dependency,dev-branch
          exempt-pr-labels: keepalive,proposal,outdated-dependency,dev-branch

'''
'''--- .github/workflows/test.yml ---
name: Test
on: [pull_request]
jobs:
  test:
    name: Test
    strategy:
      matrix:
        platform: [macos-latest]
    runs-on: ${{ matrix.platform }}
    steps:
    - name: Checkout code
      uses: actions/checkout@v3
    - name: Set up Go 1.18
      uses: actions/setup-go@v3
      with:
        go-version: 1.18.0
      id: go
    - name: Determine Go cache directories
      id: go-cache
      run: |
        echo "::set-output name=go-build::$(go env GOCACHE)"
        echo "::set-output name=go-mod::$(go env GOMODCACHE)"
    - name: Restore Go cache
      uses: actions/cache@v3.0.6
      with:
        path: |
          ${{ steps.go-cache.outputs.go-build }}
          ${{ steps.go-cache.outputs.go-mod }}
        key: ${{ runner.os }}-go-${{ hashFiles('**/go.sum') }}
        restore-keys: |
          ${{ runner.os }}-go-
    - name: Test
      run: make DOCKER_OPTS="" GOFLAGS="-tags=netgo,nodocker" BUILD_IN_CONTAINER=false test

'''
'''--- .github/workflows/test_packages.yml ---
name: Test Packages
on:
  pull_request:
    branches:
    - main
    paths:
    - packaging/**
    - Makefile
jobs:
  test:
    name: Test Packages
    runs-on: ubuntu-latest
    steps:
    - name: Set up Go 1.18
      uses: actions/setup-go@v3
      with:
        go-version: 1.18.0
      id: go
    - name: Checkout code
      uses: actions/checkout@v3
    - name: Test
      run: DOCKER_OPTS="" make test-packages

'''
'''--- .golangci.yml ---
# Full list of configuration options: https://golangci-lint.run/usage/configuration/

run:
  timeout: 5m

output:
  sort-results: true

linters:
  enable:
    - deadcode    # Report on unused code
    - errcheck    # Report unchecked errors
    - goconst     # Find repeated strings that could be replaced by constant
    - gofmt       # Check whether code was gofmt-ed
    - goimports   # Check imports were formatted with gofmt
    - revive      # Broad set of rules; replaces deprecated golint
    - gosimple    # Check whether code can be simplified
    - ineffassign # Detect when assignment to variable is never used
    - misspell    # Report on commonly misspelled English words
    - structcheck # Report on unused struct fields
    - unconvert   # Remove unnecessary type conversions
    - unparam     # Detect unused function parameters
    - varcheck    # Find unused global variables/constants
    - govet       # `go vet`
    - unused      # Detect unused constants/variables/functions/types
    - typecheck   # Ensure code typechecks
    - depguard    # Allow/denylist specific imports
    - makezero    # Detect misuse of make with non-zero length and append
    - tenv        # Use testing.(*T).Setenv instead of os.Setenv
    - whitespace  # Report unnecessary blank lines

issues:
  # We want to use our own exclusion rules and ignore all the defaults.
  exclude-use-default: false

  exclude-rules:
    # It's fine if tests ignore errors.
    - path: _test.go
      linters:
        - errcheck

  exclude:
    # Ignoring errors on Close, Log, and removing files is OK in most cases.
    - "Error return value of `(.*\\.Close|.*\\.Log|os.Remove)` is not checked"
    # Packages for integrations are named matching their upstream counterpart,
    # which almost always have underscores.
    - "var-naming: don't use an underscore in package name"

# Linter settings options: https://golangci-lint.run/usage/linters/
linters-settings:
  depguard:
    # We want to report errors on stdlib packages, not just third party modules
    include-go-root: true

    packages-with-error-message:
      - sync/atomic: "Use go.uber.org/atomic instead of sync/atomic"
      - github.com/pkg/errors: "Use errors instead of github.com/pkg/errors"
      - github.com/go-kit/kit/log: "Use github.com/go-kit/log instead of github.com/go-kit/kit/log"
      - golang.org/x/sync/errgroup: "Use github.com/oklog/run instead of golang.org/x/sync/errgroup"

  whitespace:
    # While there normally shouldn't be extra redundant leading/trailing
    # whitespace, if statement conditions and function headers that cross
    # multiple lines are an exception.
    #
    #   if true ||
    #      false {
    #
    #       // ... ^ must have empty line above
    #    }
    #
    #   func foo(
    #     a int,
    #   ) {
    #
    #     // ... ^ must have empty line above
    #   }
    #
    # This helps readers easily separate where the multi-line if/function ends
    # at a glance.
    multi-if: true
    multi-func: true

'''
'''--- ADOPTERS.md ---
This is the list of organizations, organized alphebetically, that are using the Grafana Agent in
production environments. Please send PRs to add or remove organizations.

* [AB Tasty](https://www.abtasty.com/)
* [Canonical](https://www.ubuntu.com/)
* Cerner Enterprise Hosting
* [Embark Studios](https://www.embark.dev/)
* [Grafana Labs](https://grafana.com)

'''
'''--- CHANGELOG.md ---
# Changelog

> _Contributors should read our [contributors guide][] for instructions on how
> to update the changelog._

This document contains a historical list of changes between releases. Only
changes that impact end-user behavior are listed; changes to documentation or
internal API changes are not present.

Main (unreleased)
-----------------

> **BREAKING CHANGES**: This release has breaking changes. Please read entries
> carefully and consult the [upgrade guide][] for specific instructions.

### Breaking changes

### Features

- Integrations: (beta) Add vmware_exporter integration (@rlankfo)

### Enhancements

- Tracing: Introduce a periodic appender to the remotewriteexporter to control sample rate. (@mapno)

- Tracing: Update OpenTelemetry dependency to v0.55.0. (@rfratto, @mapno)

- Add base agent-operator jsonnet library and generated manifests (@hjet)

- Add full (metrics, logs, K8s events) sample agent-operator jsonnet library and gen manifests (@hjet)

- Introduce new configuration fields for disabling Keep-Alives and setting the
  IdleConnectionTimeout when scraping. (@tpaschalis)

### Bugfixes

- Tracing: Fixed issue with the PromSD processor using the `connection` method to discover the IP
  address.  It was failing to match because the port number was included in the address string. (@jphx)

- Register prometheus discovery metrics. (@mattdurham)

- Fix seg fault when no instance parameter is provided for apache_http integration, using integrations-next feature flag. (@rgeyer)

- Fix grafanacloud-install.ps1 web request internal server error when fetching config. (@rlankfo)

### Other changes

 - Update several go dependencies to resolve warnings from certain security scanning tools. None of the resolved vulnerabilities were known to be exploitable through the agent. (@captncraig)

 - It is now possible to compile Grafana Agent using Go 1.19. (@rfratto)

v0.26.1 (2022-07-25)
-------------------------

> **BREAKING CHANGES**: This release has breaking changes. Please read entries
> carefully and consult the [upgrade guide][] for specific instructions.

### Breaking changes

- Change windows certificate store so client certificate is no longer required in store. (@mattdurham)

### Bugfixes

- Operator: Fix issue where configured `targetPort` ServiceMonitors resulted in
  generating an incorrect scrape_config. (@rfratto)

- Build the Linux/AMD64 artifacts using the opt-out flag for the ebpf_exporter. (@tpaschalis)

v0.26.0 (2022-07-18)
-------------------------

> **BREAKING CHANGES**: This release has breaking changes. Please read entries
> carefully and consult the [upgrade guide][] for specific instructions.

### Breaking changes

- Deprecated `server` YAML block fields have now been removed in favor of the
  command-line flags that replaced them. These fields were originally
  deprecated in v0.24.0. (@rfratto)

- Changed tail sampling policies to be configured as in the OpenTelemetry
  Collector. (@mapno)

### Features

- Introduce Apache HTTP exporter integration. (@v-zhuravlev)

- Introduce eBPF exporter integration. (@tpaschalis)

### Enhancements

- Truncate all records in WAL if repair attempt fails. (@rlankfo)

### Bugfixes

- Relative symlinks for promtail now work as expected. (@RangerCD, @mukerjee)

- Fix rate limiting implementation for the app agent receiver integration. (@domasx2)

- Fix mongodb exporter so that it now collects all metrics. (@mattdurham)

v0.25.1 (2022-06-16)
-------------------------

### Bugfixes

- Integer types fail to unmarshal correctly in operator additional scrape configs. (@rlankfo)

- Unwrap replayWAL error before attempting corruption repair. (@rlankfo)

v0.25.0 (2022-06-06)
-------------------------

> **BREAKING CHANGES**: This release has breaking changes. Please read entries
> carefully and consult the [upgrade guide][] for specific instructions.

### Breaking changes

- Traces: Use `rpc.grpc.status_code` attribute to determine
  span failed in the service graph processor (@rcrowe)

### Features

- Add HTTP endpoints to fetch active instances and targets for the Logs subsystem.
  (@marctc)

- (beta) Add support for using windows certificate store for TLS connections. (@mattdurham)

- Grafana Agent Operator: add support for integrations through an `Integration`
  CRD which is discovered by `GrafanaAgent`. (@rfratto)

- (experimental) Add app agent receiver integration. This depends on integrations-next being enabled
  via the `integrations-next` feature flag. Use `-enable-features=integrations-next` to use
  this integration. (@kpelelis, @domas)

- Introduce SNMP exporter integration. (@v-zhuravlev)

- Configure the agent to report the use of feature flags to grafana.com. (@marctc)

### Enhancements

- integrations-next: Integrations using autoscrape will now autoscrape metrics
  using in-memory connections instead of connecting to themselves over the
  network. As a result of this change, the `client_config` field has been
  removed. (@rfratto)

- Enable `proxy_url` support on `oauth2` for metrics and logs (update **prometheus/common** dependency to `v0.33.0`). (@martin-jaeger-maersk)

- `extra-scrape-metrics` can now be enabled with the `--enable-features=extra-scrape-metrics` feature flag. See https://prometheus.io/docs/prometheus/2.31/feature_flags/#extra-scrape-metrics for details. (@rlankfo)

- Resolved issue in v2 integrations where if an instance name was a prefix of another the route handler would fail to
  match requests on the longer name (@mattdurham)

- Set `include_metadata` to true by default for OTLP traces receivers (@mapno)

### Bugfixes

- Scraping service was not honoring the new server grpc flags `server.grpc.address`.  (@mattdurham)

### Other changes

- Update base image of official Docker containers from Debian buster to Debian
  bullseye. (@rfratto)

- Use Go 1.18 for builds. (@rfratto)

- Add `metrics` prefix to the url of list instances endpoint (`GET
  /agent/api/v1/instances`) and list targets endpoint (`GET
  /agent/api/v1/metrics/targets`). (@marctc)

- Add extra identifying labels (`job`, `instance`, `agent_hostname`) to eventhandler integration. (@hjet)

- Add `extra_labels` configuration to eventhandler integration. (@hjet)

v0.24.2 (2022-05-02)
--------------------

### Bugfixes

- Added configuration watcher delay to prevent race condition in cases where scraping service mode has not gracefully exited. (@mattdurham)

### Other changes

- Update version of node_exporter to include additional metrics for osx. (@v-zhuravlev)

v0.24.1 (2022-04-14)
--------------------

### Bugfixes

- Add missing version information back into `agentctl --version`. (@rlankfo)

- Bump version of github-exporter to latest upstream SHA 284088c21e7d, which
  includes fixes from bugs found in their latest tag. This includes a fix
  where not all releases where retrieved when pulling release information.
  (@rfratto)

- Set the `Content-Type` HTTP header to `application/json` for API endpoints
  returning json objects. (@marctc)

- Operator: fix issue where a `username_file` field was incorrectly set.
  (@rfratto)

- Initialize the logger with default `log_level` and `log_format` parameters.
  (@tpaschalis)

### Other changes

- Embed timezone data to enable Promtail pipelines using the `location` field
  on Windows machines. (@tpaschalis)

v0.24.0 (2022-04-07)
--------------------

> **BREAKING CHANGES**: This release has breaking changes. Please read entries
> carefully and consult the [upgrade guide][] for specific instructions.
>
> **GRAFANA AGENT OPERATOR USERS**: As of this release, Grafana Agent Operator
> does not support versions of Grafana Agent prior to v0.24.0.

### Breaking changes

- The following metrics will now be prefixed with `agent_dskit_` instead of
  `cortex_`: `cortex_kv_request_duration_seconds`,
  `cortex_member_consul_heartbeats_total`, `cortex_member_ring_tokens_owned`,
  `cortex_member_ring_tokens_to_own`, `cortex_ring_member_ownership_percent`,
  `cortex_ring_members`, `cortex_ring_oldest_member_timestamp`,
  `cortex_ring_tokens_owned`, `cortex_ring_tokens_total`. (@rlankfo)

- Traces: the `traces_spanmetrics_calls_total_total` metric has been renamed to
  `traces_spanmetrics_calls_total` (@fredr)

- Two new flags, `-server.http.enable-tls` and `-server.grpc.enable-tls` must
  be provided to explicitly enable TLS support. This is a change of the
  previous behavior where TLS support was enabled when a certificate pair was
  provided. (@rfratto)

- Many command line flags starting with `-server.` block have been renamed.
  (@rfratto)

- The `-log.level` and `-log.format` flags are removed in favor of being set in
  the configuration file. (@rfratto)

- Flags for configuring TLS have been removed in favor of being set in the
  configuration file. (@rfratto)

- Dynamic reload is no longer supported for deprecated server block fields.
  Changing a deprecated field will be ignored and cause the reload to fail.
  (@rfratto)

- The default HTTP listen address is now `127.0.0.1:12345`. Use the
  `-server.http.address` flag to change this value. (@rfratto)

- The default gRPC listen address is now `127.0.0.1:12346`. Use the
  `-server.grpc.address` flag to change this value. (@rfratto)

- `-reload-addr` and `-reload-port` have been removed. They are no longer
  necessary as the primary HTTP server is now static and can't be shut down in
  the middle of a `/-/reload` call. (@rfratto)

- (Only impacts `integrations-next` feature flag) Many integrations have been
  renamed to better represent what they are integrating with. For example,
  `redis_exporter` is now `redis`. This change requires updating
  `integrations-next`-enabled configuration files. This change also changes
  integration names shown in metric labels. (@rfratto)

- The deprecated `-prometheus.*` flags have been removed in favor of
  their `-metrics.*` counterparts. The `-prometheus.*` flags were first
  deprecated in v0.19.0. (@rfratto)

### Deprecations

- Most fields in the `server` block of the configuration file are
  now deprecated in favor of command line flags. These fields will be removed
  in the v0.26.0 release. Please consult the upgrade guide for more information
  and rationale. (@rfratto)

### Features

- Added config read API support to GrafanaAgent Custom Resource Definition.
  (@shamsalmon)

- Added consulagent_sd to target discovery. (@chuckyz)

- Introduce EXPERIMENTAL support for dynamic configuration. (@mattdurham)

- Introduced endpoint that accepts remote_write requests and pushes metrics data directly into an instance's WAL. (@tpaschalis)

- Added builds for linux/ppc64le. (@aklyachkin)

### Enhancements

- Tracing: Exporters can now be configured to use OAuth. (@canuteson)

- Strengthen readiness check for metrics instances. (@tpaschalis)

- Parameterize namespace field in sample K8s logs manifests (@hjet)

- Upgrade to Loki k87. (@rlankfo)

- Update Prometheus dependency to v2.34.0. (@rfratto)

- Update OpenTelemetry-collector dependency to v0.46.0. (@mapno)

- Update cAdvisor dependency to v0.44.0. (@rfratto)

- Update mongodb_exporter dependency to v0.31.2 (@mukerjee)

- Use grafana-agent/v2 Tanka Jsonnet to generate K8s manifests (@hjet)

- Replace agent-bare.yaml K8s sample Deployment with StatefulSet (@hjet)

- Improve error message for `agentctl` when timeout happens calling
  `cloud-config` command (@marctc)

- Enable integrations-next by default in agent-bare.yaml. Please note #1262 (@hjet)

### Bugfixes

- Fix Kubernetes manifests to use port `4317` for OTLP instead of the previous
  `55680` in line with the default exposed port in the agent.

- Ensure singleton integrations are honored in v2 integrations (@mattdurham)

- Tracing: `const_labels` is now correctly parsed in the remote write exporter.
  (@fredr)

- integrations-next: Fix race condition where metrics endpoints for
  integrations may disappear after reloading the config file. (@rfratto)

- Removed the `server.path_prefix` field which would break various features in
  Grafana Agent when set. (@rfratto)

- Fix issue where installing the DEB/RPM packages would overwrite the existing
  config files and environment files. (@rfratto)

- Set `grafanaDashboardFolder` as top level key in the mixin. (@Duologic)

- Operator: Custom Secrets or ConfigMaps to mount will no longer collide with
  the path name of the default secret mount. As a side effect of this bugfix,
  custom Secrets will now be mounted at
  `/var/lib/grafana-agent/extra-secrets/<secret name>` and custom ConfigMaps
  will now be mounted at `/var/lib/grafana-agent/extra-configmaps/<configmap
  name>`. This is not a breaking change as it was previously impossible to
  properly provide these custom mounts. (@rfratto)

- Flags accidentally prefixed with `-metrics.service..` (two `.` in a row) have
  now been fixed to only have one `.`. (@rfratto)

- Protect concurrent writes to the WAL in the remote write exporter (@mapno)

### Other changes

- The `-metrics.wal-directory` flag and `metrics.wal_directory` config option
  will now default to `data-agent/`, the same default WAL directory as
  Prometheus Agent. (@rfratto)

v0.23.0 (2022-02-10)
--------------------

### Enhancements

- Go 1.17 is now used for all builds of the Agent. (@tpaschalis)

- integrations-next: Add `extra_labels` to add a custom set of labels to
  integration targets. (@rfratto)

- The agent no longer appends duplicate exemplars. (@tpaschalis)

- Added Kubernetes eventhandler integration (@hjet)

- Enables sending of exemplars over remote write by default. (@rlankfo)

### Bugfixes

- Fixed issue where Grafana Agent may panic if there is a very large WAL
  loading while old WALs are being deleted or the `/agent/api/v1/targets`
  endpoint is called. (@tpaschalis)

- Fix panic in prom_sd_processor when address is empty (@mapno)

- Operator: Add missing proxy_url field from generated remote_write configs.
  (@rfratto)

- Honor the specified log format in the traces subsystem (@mapno)

- Fix typo in node_exporter for runit_service_dir. (@mattdurham)

- Allow inlining credentials in remote_write url. (@tpaschalis)

- integrations-next: Wait for integrations to stop when starting new instances
  or shutting down (@rfratto).

- Fix issue with windows_exporter mssql collector crashing the agent.
  (@mattdurham)

- The deb and rpm files will now ensure the /var/lib/grafana-agent data
  directory is created with permissions set to 0770. (@rfratto)

- Make agent-traces.yaml Namespace a template-friendly variable (@hjet)

- Disable `machine-id` journal vol by default in sample logs manifest (@hjet)

v0.22.0 (2022-01-13)
--------------------

> This release has deprecations. Please read entries carefully and consult
> the [upgrade guide][] for specific instructions.

### Deprecations

- The node_exporter integration's `netdev_device_whitelist` field is deprecated
  in favor of `netdev_device_include`. Support for the old field name will be
  removed in a future version. (@rfratto)

- The node_exporter integration's `netdev_device_blacklist` field is deprecated
  in favor of `netdev_device_include`. Support for the old field name will be
  removed in a future version. (@rfratto)

- The node_exporter integration's `systemd_unit_whitelist` field is deprecated
  in favor of `systemd_unit_include`. Support for the old field name will be
  removed in a future version. (@rfratto)

- The node_exporter integration's `systemd_unit_blacklist` field is deprecated
  in favor of `systemd_unit_exclude`. Support for the old field name will be
  removed in a future version. (@rfratto)

- The node_exporter integration's `filesystem_ignored_mount_points` field is
  deprecated in favor of `filesystem_mount_points_exclude`. Support for the old
  field name will be removed in a future version. (@rfratto)

- The node_exporter integration's `filesystem_ignored_fs_types` field is
  deprecated in favor of `filesystem_fs_types_exclude`. Support for the old
  field name will be removed in a future version. (@rfratto)

### Features

- (beta) Enable experimental config urls for fetching remote configs.
  Currently, only HTTP/S is supported. Pass the
  `-enable-features=remote-configs` flag to turn this on. (@rlankfo)

- Added [cAdvisor](https://github.com/google/cadvisor) integration. (@rgeyer)

- Traces: Add `Agent Tracing Pipeline` dashboard and alerts (@mapno)

- Traces: Support jaeger/grpc exporter (@nicoche)

- (beta) Enable an experimental integrations subsystem revamp. Pass
  `integrations-next` to `-enable-features` to turn this on. Reading the
  documentation for the revamp is recommended; enabling it causes breaking
  config changes. (@rfratto)

### Enhancements

- Traces: Improved pod association in PromSD processor (@mapno)

- Updated OTel to v0.40.0 (@mapno)

- Remote write dashboard: show in and out sample rates (@bboreham)

- Remote write dashboard: add mean latency (@bboreham)

- Update node_exporter dependency to v1.3.1. (@rfratto)

- Cherry-pick Prometheus PR #10102 into our Prometheus dependency (@rfratto).

### Bugfixes

- Fix usage of POSTGRES_EXPORTER_DATA_SOURCE_NAME when using postgres_exporter
  integration (@f11r)

- Change ordering of the entrypoint for windows service so that it accepts
  commands immediately (@mattdurham)

- Only stop WAL cleaner when it has been started (@56quarters)

- Fix issue with unquoted install path on Windows, that could allow escalation
  or running an arbitrary executable (@mattdurham)

- Fix cAdvisor so it collects all defined metrics instead of the last
  (@pkoenig10)

- Fix panic when using 'stdout' in automatic logging (@mapno)

- Grafana Agent Operator: The /-/ready and /-/healthy endpoints will
  no longer always return 404 (@rfratto).

### Other changes

- Remove log-level flag from systemd unit file (@jpkrohling)

v0.21.2 (2021-12-08)
--------------------

### Security fixes

- This release contains a fix for
  [CVE-2021-41090](https://github.com/grafana/agent/security/advisories/GHSA-9c4x-5hgq-q3wh).

### Other changes

- This release disables the existing `/-/config` and
  `/agent/api/v1/configs/{name}` endpoints by default. Pass the
  `--config.enable-read-api` flag at the command line to opt in to these
  endpoints.

v0.21.1 (2021-11-18)
--------------------

### Bugfixes

- Fix panic when using postgres_exporter integration (@saputradharma)

- Fix panic when dnsamsq_exporter integration tried to log a warning (@rfratto)

- Statsd Integration: Adding logger instance to the statsd mapper
  instantiation. (@gaantunes)

- Statsd Integration: Fix issue where mapped metrics weren't exposed to the
  integration. (@mattdurham)

- Operator: fix bug where version was a required field (@rfratto)

- Metrics: Only run WAL cleaner when metrics are being used and a WAL is
  configured. (@rfratto)

v0.21.0 (2021-11-17)
--------------------

### Enhancements

- Update Cortex dependency to v1.10.0-92-g85c378182. (@rlankfo)

- Update Loki dependency to v2.1.0-656-g0ae0d4da1. (@rlankfo)

- Update Prometheus dependency to v2.31.0 (@rlankfo)

- Add Agent Operator Helm quickstart guide (@hjet)

- Reorg Agent Operator quickstart guides (@hjet)

### Bugfixes

- Packaging: Use correct user/group env variables in RPM %post script (@simonc6372)

- Validate logs config when using logs_instance with automatic logging processor (@mapno)

- Operator: Fix MetricsInstance Service port (@hjet)

- Operator: Create govern service per Grafana Agent (@shturman)

- Operator: Fix relabel_config directive for PodLogs resource (@hjet)

- Traces: Fix `success_logic` code in service graphs processor (@mapno)

### Other changes

- Self-scraped integrations will now use an SUO-specific value for the `instance` label. (@rfratto)

- Traces: Changed service graphs store implementation to improve CPU performance (@mapno)

v0.20.1 (2021-12-08)
--------------------

> *NOTE*: The fixes in this patch are only present in v0.20.1 and >=v0.21.2.

### Security fixes

- This release contains a fix for
  [CVE-2021-41090](https://github.com/grafana/agent/security/advisories/GHSA-9c4x-5hgq-q3wh).

### Other changes

- This release disables the existing `/-/config` and
  `/agent/api/v1/configs/{name}` endpoitns by default. Pass the
  `--config.enable-read-api` flag at the command line to opt in to these
  endpoints.

v0.20.0 (2021-10-28)
--------------------

> **BREAKING CHANGES**: This release has breaking changes. Please read entries
> carefully and consult the [upgrade guide][] for specific instructions.

### Breaking Changes

- push_config is no longer supported in trace's config (@mapno)

### Features

- Operator: The Grafana Agent Operator can now generate a Kubelet service to
  allow a ServiceMonitor to collect Kubelet and cAdvisor metrics. This requires
  passing a `--kubelet-service` flag to the Operator in `namespace/name` format
  (like `kube-system/kubelet`). (@rfratto)

- Service graphs processor (@mapno)

### Enhancements

- Updated mysqld_exporter to v0.13.0 (@gaantunes)

- Updated postgres_exporter to v0.10.0 (@gaantunes)

- Updated redis_exporter to v1.27.1 (@gaantunes)

- Updated memcached_exporter to v0.9.0 (@gaantunes)

- Updated statsd_exporter to v0.22.2 (@gaantunes)

- Updated elasticsearch_exporter to v1.2.1 (@gaantunes)

- Add remote write to silent Windows Installer  (@mattdurham)

- Updated mongodb_exporter to v0.20.7 (@rfratto)

- Updated OTel to v0.36 (@mapno)

- Updated statsd_exporter to v0.22.2 (@mattdurham)

- Update windows_exporter to v0.16.0 (@rfratto, @mattdurham)

- Add send latency to agent dashboard (@bboreham)

### Bugfixes

- Do not immediately cancel context when creating a new trace processor. This
  was preventing scrape_configs in traces from functioning. (@lheinlen)

- Sanitize autologged Loki labels by replacing invalid characters with
  underscores (@mapno)

- Traces: remove extra line feed/spaces/tabs when reading password_file content
  (@nicoche)

- Updated envsubst to v2.0.0-20210730161058-179042472c46. This version has a
  fix needed for escaping values outside of variable substitutions. (@rlankfo)

- Grafana Agent Operator should no longer delete resources matching the names
  of the resources it manages. (@rfratto)

- Grafana Agent Operator will now appropriately assign an
  `app.kubernetes.io/managed-by=grafana-agent-operator` to all created
  resources. (@rfratto)

### Other changes

- Configuration API now returns 404 instead of 400 when attempting to get or
  delete a config which does not exist. (@kgeckhart)

- The windows_exporter now disables the textfile collector by default.
  (@rfratto)

v0.19.0 (2021-09-29)
--------------------

> **BREAKING CHANGES**: This release has breaking changes. Please read entries
> carefully and consult the [upgrade guide][] for specific instructions.

### Breaking Changes

- Reduced verbosity of tracing autologging by not logging `STATUS_CODE_UNSET`
  status codes. (@mapno)

- Operator: rename Prometheus* CRDs to Metrics* and Prometheus* fields to
  Metrics*. (@rfratto)

- Operator: CRDs are no longer referenced using a hyphen in the name to be
  consistent with how Kubernetes refers to resources. (@rfratto)

- `prom_instance` in the spanmetrics config is now named `metrics_instance`.
  (@rfratto)

### Deprecations

- The `loki` key at the root of the config file has been deprecated in favor of
  `logs`. `loki`-named fields in `automatic_logging` have been renamed
  accordinly: `loki_name` is now `logs_instance_name`, `loki_tag` is now
  `logs_instance_tag`, and `backend: loki` is now `backend: logs_instance`.
  (@rfratto)

- The `prometheus` key at the root of the config file has been deprecated in
  favor of `metrics`. Flag names starting with `prometheus.` have also been
  deprecated in favor of the same flags with the `metrics.` prefix. Metrics
  prefixed with `agent_prometheus_` are now prefixed with `agent_metrics_`.
  (@rfratto)

- The `tempo` key at the root of the config file has been deprecated in favor
  of `traces`. (@mattdurham)

### Features

- Added [Github exporter](https://github.com/infinityworks/github-exporter)
  integration. (@rgeyer)

- Add TLS config options for tempo `remote_write`s. (@mapno)

- Support autologging span attributes as log labels (@mapno)

- Put Tests requiring Network Access behind a -online flag (@flokli)

- Add logging support to the Grafana Agent Operator. (@rfratto)

- Add `operator-detach` command to agentctl to allow zero-downtime upgrades
  when removing an Operator CRD. (@rfratto)

- The Grafana Agent Operator will now default to deploying the matching release
  version of the Grafana Agent instead of v0.14.0. (@rfratto)

### Enhancements

- Update OTel dependency to v0.30.0 (@mapno)

- Allow reloading configuration using `SIGHUP` signal. (@tharun208)

- Add HOSTNAME environment variable to service file to allow for expanding the
  $HOSTNAME variable in agent config.  (@dfrankel33)

- Update jsonnet-libs to 1.21 for Kubernetes 1.21+ compatability. (@MurzNN)

- Make method used to add k/v to spans in prom_sd processor configurable.
  (@mapno)

### Bugfixes

- Regex capture groups like `${1}` will now be kept intact when using
  `-config.expand-env`. (@rfratto)

- The directory of the logs positions file will now properly be created on
  startup for all instances. (@rfratto)

- The Linux system packages will now configure the grafana-agent user to be a
  member of the adm and systemd-journal groups. This will allow logs to read
  from journald and /var/log by default. (@rfratto)

- Fix collecting filesystem metrics on Mac OS (darwin) in the `node_exporter`
  integration default config. (@eamonryan)

- Remove v0.0.0 flags during build with no explicit release tag (@mattdurham)

- Fix issue with global scrape_interval changes not reloading integrations
  (@kgeckhart)

- Grafana Agent Operator will now detect changes to referenced ConfigMaps and
  Secrets and reload the Agent properly. (@rfratto)

- Grafana Agent Operator's object label selectors will now use Kubernetes
  defaults when undefined (i.e., default to nothing). (@rfratto)

- Fix yaml marshalling tag for cert_file in kafka exporter agent config.
  (@rgeyer)

- Fix warn-level logging of dropped targets. (@james-callahan)

- Standardize scrape_interval to 1m in examples. (@mattdurham)

v0.18.4 (2021-09-14)
--------------------

### Enhancements

- Add `agent_prometheus_configs_changed_total` metric to track instance config
  events. (@rfratto)

### Bugfixes

- Fix info logging on windows. (@mattdurham)

- Scraping service: Ensure that a reshard is scheduled every reshard
  interval. (@rfratto)

v0.18.3 (2021-09-08)
--------------------

### Bugfixes

- Register missing metric for configstore consul request duration. (@rfratto)

- Logs should contain a caller field with file and line numbers again
  (@kgeckhart)

- In scraping service mode, the polling configuration refresh should honor
  timeout. (@mattdurham)

- In scraping service mode, the lifecycle reshard should happen using a
  goroutine. (@mattdurham)

- In scraping service mode, scraping service can deadlock when reloading during
  join. (@mattdurham)

- Scraping service: prevent more than one refresh from being queued at a time.
  (@rfratto)

v0.18.2 (2021-08-12)
--------------------

### Bugfixes

- Honor the prefix and remove prefix from consul list results (@mattdurham)

v0.18.1 (2021-08-09)
--------------------

### Bugfixes

- Reduce number of consul calls when ran in scrape service mode (@mattdurham)

v0.18.0 (2021-07-29)
--------------------

### Features

- Added [Github exporter](https://github.com/infinityworks/github-exporter)
  integration. (@rgeyer)

- Add support for OTLP HTTP trace exporting. (@mapno)

### Enhancements

- Switch to drone for releases. (@mattdurham)

- Update postgres_exporter to a [branch of](https://github.com/grafana/postgres_exporter/tree/exporter-package-v0.10.0) v0.10.0

### Bugfixes

- Enabled flag for integrations is not being honored. (@mattdurham)

v0.17.0 (2021-07-15)
--------------------

### Features

- Added [Kafka Lag exporter](https://github.com/davidmparrott/kafka_exporter)
  integration. (@gaantunes)

### Bugfixes

- Fix race condition that may occur and result in a panic when initializing
  scraping service cluster. (@rfratto)

v0.16.1 (2021-06-22)
--------------------

### Bugfixes

- Fix issue where replaying a WAL caused incorrect metrics to be sent over
  remote write. (@rfratto)

v0.16.0 (2021-06-17)
--------------------

### Features

- (beta) A Grafana Agent Operator is now available. (@rfratto)

### Enhancements

- Error messages when installing the Grafana Agent for Grafana Cloud will now
  be shown. (@rfratto)

### Bugfixes

- Fix a leak in the shared string interner introduced in v0.14.0. This fix was
  made to a [dependency](https://github.com/grafana/prometheus/pull/21).
  (@rfratto)

- Fix issue where a target will fail to be scraped for the process lifetime if
  that target had gone down for long enough that its series were removed from
  the in-memory cache (2 GC cycles). (@rfratto)

v0.15.0 (2021-06-03)
--------------------

> **BREAKING CHANGES**: This release has breaking changes. Please read entries
> carefully and consult the [upgrade guide][] for specific instructions.

### Breaking Changes

- The configuration of Tempo Autologging has changed. (@mapno)

### Features

- Add support for exemplars. (@mapno)

### Enhancements

- Add the option to log to stdout instead of a Loki instance. (@joe-elliott)

- Update Cortex dependency to v1.8.0.

- Running the Agent as a DaemonSet with host_filter and role: pod should no
  longer cause unnecessary load against the Kubernetes SD API. (@rfratto)

- Update Prometheus to v2.27.0. (@mapno)

- Update Loki dependency to d88f3996eaa2. This is a non-release build, and was
  needed to support exemplars. (@mapno)

- Update Cortex dependency to to d382e1d80eaf. This is a non-release build, and
  was needed to support exemplars. (@mapno)

### Bugfixes

- Host filter relabeling rules should now work. (@rfratto)

- Fixed issue where span metrics where being reported with wrong time unit.
  (@mapno)

### Other changes

- Intentionally order tracing processors. (@joe-elliott)

v0.14.0 (2021-05-24)
--------------------

> **BREAKING CHANGES**: This release has breaking changes. Please read entries
> carefully and consult the [upgrade guide][] for specific instructions.
>
> **STABILITY NOTICE**: As of this release, functionality that is not
> recommended for production use and is expected to change will be tagged
> interchangably as "experimental" or "beta."

### Security fixes

* The Scraping service API will now reject configs that read credentials from
  disk by default. This prevents malicious users from reading arbitrary files
  and sending their contents over the network. The old behavior can be
  re-enabled by setting `dangerous_allow_reading_files: true` in the scraping
  service config. (@rfratto)

### Breaking changes

* Configuration for SigV4 has changed. (@rfratto)

### Deprecations

- `push_config` is now supplanted by `remote_block` and `batch`. `push_config`
  will be removed in a future version (@mapno)

### Features

- (beta) New integration: windows_exporter (@mattdurham)

- (beta) Grafana Agent Windows Installer is now included as a release artifact.
  (@mattdurham)

- Official M1 Mac release builds will now be generated! Look for
  `agent-darwin-arm64` and `agentctl-darwin-arm64` in the release assets.
  (@rfratto)

- Add support for running as a Windows service (@mattdurham)

- (beta) Add /-/reload support. It is not recommended to invoke `/-/reload`
  against the main HTTP server. Instead, two new command-line flags have been
  added: `--reload-addr` and `--reload-port`. These will launch a
  `/-/reload`-only HTTP server that can be used to safely reload the Agent's
  state.  (@rfratto)

- Add a /-/config endpoint. This endpoint will return the current configuration
  file with defaults applied that the Agent has loaded from disk. (@rfratto)

- (beta) Support generating metrics and exposing them via a Prometheus exporter
  from span data. (@yeya24)

- Tail-based sampling for tracing pipelines (@mapno)

- Added Automatic Logging feature for Tempo (@joe-elliott)

- Disallow reading files from within scraping service configs by default.
  (@rfratto)

- Add remote write for span metrics (@mapno)

### Enhancements

- Support compression for trace export. (@mdisibio)

- Add global remote_write configuration that is shared between all instances
  and integrations. (@mattdurham)

- Go 1.16 is now used for all builds of the Agent. (@rfratto)

- Update Prometheus dependency to v2.26.0. (@rfratto)

- Upgrade `go.opentelemetry.io/collector` to v0.21.0 (@mapno)

- Add kafka trace receiver (@mapno)

- Support mirroring a trace pipeline to multiple backends (@mapno)

- Add `headers` field in `remote_write` config for Tempo. `headers` specifies
  HTTP headers to forward to the remote endpoint. (@alexbiehl)

- Add silent uninstall to Windows Uninstaller. (@mattdurham)

### Bugfixes

- Native Darwin arm64 builds will no longer crash when writing metrics to the
  WAL. (@rfratto)

- Remote write endpoints that never function across the lifetime of the Agent
  will no longer prevent the WAL from being truncated. (@rfratto)

- Bring back FreeBSD support. (@rfratto)

- agentctl will no longer leak WAL resources when retrieving WAL stats.
  (@rfratto)

- Ensure defaults are applied to undefined sections in config file. This fixes
  a problem where integrations didn't work if `prometheus:` wasn't configured.
  (@rfratto)

- Fixed issue where automatic logging double logged "svc". (@joe-elliott)

### Other changes

- The Grafana Cloud Agent has been renamed to the Grafana Agent. (@rfratto)

- Instance configs uploaded to the Config Store API will no longer be stored
  along with the global Prometheus defaults. This is done to allow globals to
  be updated and re-apply the new global defaults to the configs from the
  Config Store. (@rfratto)

- The User-Agent header sent for logs will now be `GrafanaAgent/<version>`
  (@rfratto)

- Add `tempo_spanmetrics` namespace in spanmetrics (@mapno)

v0.13.1 (2021-04-09)
--------------------

### Bugfixes

- Validate that incoming scraped metrics do not have an empty label set or a
  label set with duplicate labels, mirroring the behavior of Prometheus.
  (@rfratto)

v0.13.0 (2021-02-25)
--------------------

> The primary branch name has changed from `master` to `main`. You may have to
> update your local checkouts of the repository to point at the new branch name.

### Features

- postgres_exporter: Support query_path and disable_default_metrics. (@rfratto)

### Enhancements

- Support other architectures in installation script. (@rfratto)

- Allow specifying custom wal_truncate_frequency per integration. (@rfratto)

- The SigV4 region can now be inferred using the shared config (at
  `$HOME/.aws/config`) or environment variables (via `AWS_CONFIG`). (@rfratto)

- Update Prometheus dependency to v2.25.0. (@rfratto)

### Bugfixes

- Not providing an `-addr` flag for `agentctl config-sync` will no longer
  report an error and will instead use the pre-existing default value.
  (@rfratto)

- Fixed a bug from v0.12.0 where the Loki installation script failed because
  positions_directory was not set. (@rfratto)

- Reduce the likelihood of dataloss during a remote_write-side outage by
  increasing the default wal_truncation_frequency to 60m and preventing the WAL
  from being truncated if the last truncation timestamp hasn't changed. This
  change increases the size of the WAL on average, and users may configure a
  lower wal_truncation_frequency to deliberately choose a smaller WAL over
  write guarantees. (@rfratto)

- Add the ability to read and serve HTTPS integration metrics when given a set
  certificates (@mattdurham)

v0.12.0 (2021-02-05)
--------------------

> **BREAKING CHANGES**: This release has breaking changes. Please read entries
> carefully and consult the [upgrade guide][] for specific instructions.

### Breaking Changes

* The configuration format for the `loki` block has changed. (@rfratto)

* The configuration format for the `tempo` block has changed. (@rfratto)

### Features

- Support for multiple Loki Promtail instances has been added. (@rfratto)

- Support for multiple Tempo instances has been added. (@rfratto)

- Added [ElasticSearch exporter](https://github.com/justwatchcom/elasticsearch_exporter)
  integration. (@colega)

### Enhancements

- `.deb` and `.rpm` packages are now generated for all supported architectures.
  The architecture of the AMD64 package in the filename has been renamed to
  `amd64` to stay synchronized with the architecture name presented from other
  release assets. (@rfratto)

- The `/agent/api/v1/targets` API will now include discovered labels on the
  target pre-relabeling in a `discovered_labels` field. (@rfratto)

- Update Loki to 59a34f9867ce. This is a non-release build, and was needed to
  support multiple Loki instances. (@rfratto)

- Scraping service: Unhealthy Agents in the ring will no longer cause job
  distribution to fail. (@rfratto)

- Scraping service: Cortex ring metrics (prefixed with cortex_ring_) will now
  be registered for tracking the state of the hash ring. (@rfratto)

- Scraping service: instance config ownership is now determined by the hash of
  the instance config name instead of the entire config. This means that
  updating a config is guaranteed to always hash to the same Agent, reducing
  the number of metrics gaps. (@rfratto)

- Only keep a handful of K8s API server metrics by default to reduce default
  active series usage. (@hjet)

- Go 1.15.8 is now used for all distributions of the Agent. (@rfratto)

### Bugfixes

- `agentctl config-check` will now work correctly when the supplied config file
  contains integrations. (@hoenn)

v0.11.0 (2021-01-20)
--------------------

### Features

- ARMv6 builds of `agent` and `agentctl` will now be included in releases to
  expand Agent support to cover all models of Raspberry Pis. ARMv6 docker
  builds are also now available. (@rfratto)

- Added `config-check` subcommand for `agentctl` that can be used to validate
  Agent configuration files before attempting to load them in the `agent`
  itself. (@56quarters)

### Enhancements

- A sigv4 install script for Prometheus has been added. (@rfratto)

- NAMESPACE may be passed as an environment variable to the Kubernetes install
  scripts to specify an installation namespace. (@rfratto)

### Bugfixes

- The K8s API server scrape job will use the API server Service name when
  resolving IP addresses for Prometheus service discovery using the "Endpoints"
  role. (@hjet)

- The K8s manifests will no longer include the `default/kubernetes` job twice
  in both the DaemonSet and the Deployment. (@rfratto)

v0.10.0 (2021-01-13)
--------------------

### Features

- Prometheus `remote_write` now supports SigV4 authentication using the
  [AWS default credentials chain](https://docs.aws.amazon.com/sdk-for-java/v1/developer-guide/credentials.html).
  This enables the Agent to send metrics to Amazon Managed Prometheus without
  needing the [SigV4 Proxy](https://github.com/awslabs/aws-sigv4-proxy).
  (@rfratto)

### Enhancements

- Update `redis_exporter` to v1.15.0. (@rfratto)

- `memcached_exporter` has been updated to v0.8.0. (@rfratto)

- `process-exporter` has been updated to v0.7.5. (@rfratto)

- `wal_cleanup_age` and `wal_cleanup_period` have been added to the top-level
  Prometheus configuration section. These settings control how Write Ahead Logs
  (WALs) that are not associated with any instances are cleaned up. By default,
  WALs not associated with an instance that have not been written in the last
  12 hours are eligible to be cleaned up. This cleanup can be disabled by
  setting `wal_cleanup_period` to `0`. (@56quarters)

- Configuring logs to read from the systemd journal should now work on journals
  that use +ZSTD compression. (@rfratto)

### Bugfixes

- Integrations will now function if the HTTP listen address was set to a value
  other than the default. (@mattdurham)

- The default Loki installation will now be able to write its positions file.
  This was prevented by accidentally writing to a readonly volume mount.
  (@rfratto)

v0.9.1 (2021-01-04)
-------------------

### Enhancements

- agentctl will now be installed by the rpm and deb packages as
  `grafana-agentctl`. (@rfratto)

v0.9.0 (2020-12-10)
-------------------

### Features

- Add support to configure TLS config for the Tempo exporter to use
  insecure_skip_verify to disable TLS chain verification. (@bombsimon)

- Add `sample-stats` to `agentctl` to search the WAL and return a summary of
  samples of series matching the given label selector. (@simonswine)

- New integration:
  [postgres_exporter](https://github.com/wrouesnel/postgres_exporter)
  (@rfratto)

- New integration:
  [statsd_exporter](https://github.com/prometheus/statsd_exporter) (@rfratto)

- New integration:
  [consul_exporter](https://github.com/prometheus/consul_exporter) (@rfratto)

- Add optional environment variable substitution of configuration file.
  (@dcseifert)

### Enhancements

- `min_wal_time` and `max_wal_time` have been added to the instance config
  settings, guaranteeing that data in the WAL will exist for at least
  `min_wal_time` and will not exist for longer than `max_wal_time`. This change
  will increase the size of the WAL slightly but will prevent certain scenarios
  where data is deleted before it is sent. To revert back to the old behavior,
  set `min_wal_time` to `0s`. (@rfratto)

- Update `redis_exporter` to v1.13.1. (@rfratto)

- Bump OpenTelemetry-collector dependency to v0.16.0. (@bombsimon)

### Bugfixes

- Fix issue where the Tempo example manifest could not be applied because the
  port names were too long. (@rfratto)

- Fix issue where the Agent Kubernetes manifests may not load properly on AKS.
  (#279) (@rfratto)

### Other changes

- The User-Agent header sent for logs will now be `GrafanaCloudAgent/<version>`
  (@rfratto)

v0.8.0 (2020-11-06)
-------------------

### Features

- New integration: [dnsamsq_exporter](https://github.com/google/dnsamsq_exporter)
  (@rfratto).

- New integration: [memcached_exporter](https://github.com/prometheus/memcached_exporter)
  (@rfratto).

### Enhancements

- Add `<integration name>_build_info` metric to all integrations. The build
  info displayed will match the build information of the Agent and *not* the
  embedded exporter. This metric is used by community dashboards, so adding it
  to the Agent increases compatibility with existing dashboards that depend on
  it existing. (@rfratto)

- Bump OpenTelemetry-collector dependency to 0.14.0 (@joe-elliott)

### Bugfixes

- Error messages when retrieving configs from the KV store will now be logged,
  rather than just logging a generic message saying that retrieving the config
  has failed. (@rfratto)

v0.7.2 (2020-10-29)
-------------------

### Enhancements

- Bump Prometheus dependency to 2.21. (@rfratto)

- Bump OpenTelemetry-collector dependency to 0.13.0 (@rfratto)

- Bump Promtail dependency to 2.0. (@rfratto)

- Enhance host_filtering mode to support targets from Docker Swarm and Consul.
  Also, add a `host_filter_relabel_configs` to that will apply relabeling rules
  for determining if a target should be dropped. Add a documentation section
  explaining all of this in detail. (@rfratto)

### Bugfixes

- Fix deb package prerm script so that it stops the agent on package removal.
  (@jdbaldry)

- Fix issue where the `push_config` for Tempo field was expected to be
  `remote_write`. `push_config` now works as expected. (@rfratto)

v0.7.1 (2020-10-23)
-------------------

### Bugfixes

- Fix issue where ARM binaries were not published with the GitHub release.

v0.7.0 (2020-10-23)
-------------------

### Features

- Added Tracing Support. (@joe-elliott)

- Add RPM and deb packaging. (@jdbaldry, @simon6372)

- arm64 and arm/v7 Docker containers and release builds are now available for
  `agent` and `agentctl`. (@rfratto)

- Add `wal-stats` and `target-stats` tooling to `agentctl` to discover WAL and
  cardinality issues. (@rfratto)

- [mysqld_exporter](https://github.com/prometheus/mysqld_exporter) is now
  embedded and available as an integration. (@rfratto)

- [redis_exporter](https://github.com/oliver006/redis_exporter) is now embedded
  and available as an integration. (@dafydd-t)

### Enhancements

- Resharding the cluster when using the scraping service mode now supports
  timeouts through `reshard_timeout`. The default value is `30s.` This timeout
  applies to cluster-wide reshards (performed when joining and leaving the
  cluster) and local reshards (done on the `reshard_interval`). (@rfratto)

### Bugfixes

- Fix issue where integrations crashed with instance_mode was set to `distinct`
  (@rfratto)

- Fix issue where the `agent` integration did not work on Windows (@rfratto).

- Support URL-encoded paths in the scraping service API. (@rfratto)

- The instance label written from replace_instance_label can now be overwritten
  with relabel_configs. This bugfix slightly modifies the behavior of what data
  is stored. The final instance label will now be stored in the WAL rather than
  computed by remote_write. This change should not negatively effect existing
  users. (@rfratto)

v0.6.1 (2020-04-11)
-------------------

### Bugfixes

- Fix issue where build information was empty when running the Agent with
  --version. (@rfratto)

- Fix issue where updating a config in the scraping service may fail to pick up
  new targets. (@rfratto)

- Fix deadlock that slowly prevents the Agent from scraping targets at a high
  scrape volume. (@rfratto)

v0.6.0 (2020-09-04)
-------------------

### Breaking Changes

- The Configs API will now disallow two instance configs having multiple
  `scrape_configs` with the same `job_name`. This was needed for the instance
  sharing mode, where combined instances may have duplicate `job_names` across
  their `scrape_configs`. This brings the scraping service more in line with
  Prometheus, where `job_names` must globally be unique. This change also
  disallows concurrent requests to the put/apply config API endpoint to prevent
  a race condition of two conflicting configs being applied at the same time.
  (@rfratto)

### Deprecations

- `use_hostname_label` is now supplanted by `replace_instance_label`.
  `use_hostname_label` will be removed in a future version. (@rfratto)

### Features

- The Grafana Agent can now collect logs and send to Loki. This is done by
  embedding Promtail, the official Loki log collection client. (@rfratto)

- Integrations can now be enabled without scraping. Set scrape_integrations to
  `false` at the `integrations` key or within the specific integration you
  don't want to scrape. This is useful when another Agent or Prometheus server
  will scrape the integration. (@rfratto)

- [process-exporter](https://github.com/ncabatoff/process-exporter) is now
  embedded as `process_exporter`. The hypen has been changed to an underscore
  in the config file to retain consistency with `node_exporter`. (@rfratto)

### Enhancements

- A new config option, `replace_instance_label`, is now available for use with
  integrations. When this is true, the instance label for all metrics coming
  from an integration will be replaced with the machine's hostname rather than
  127.0.0.1. (@rfratto)

- The embedded Prometheus version has been updated to 2.20.1. (@rfratto,
  @gotjosh)

- The User-Agent header written by the Agent when remote_writing will now be
  `GrafanaCloudAgent/<Version>` instead of `Prometheus/<Prometheus Version>`.
  (@rfratto)

- The subsystems of the Agent (`prometheus`, `loki`) are now made optional.
  Enabling integrations also implicitly enables the associated subsystem. For
  example, enabling the `agent` or `node_exporter` integration will force the
  `prometheus` subsystem to be enabled.  (@rfratto)

### Bugfixes

- The documentation for Tanka configs is now correct. (@amckinley)

- Minor corrections and spelling issues have been fixed in the Overview
  documentation. (@amckinley)

- The new default of `shared` instances mode broke the metric value for
  `agent_prometheus_active_configs`, which was tracking the number of combined
  configs (i.e., number of launched instances). This metric has been fixed and
  a new metric, `agent_prometheus_active_instances`, has been added to track
  the numbger of launched instances. If instance sharing is not enabled, both
  metrics will share the same value. (@rfratto)

- `remote_write` names in a group will no longer be copied from the
  remote_write names of the first instance in the group. Rather, all
  remote_write names will be generated based on the first 6 characters of the
  group hash and the first six characters of the remote_write hash. (@rfratto)

- Fix a panic that may occur during shutdown if the WAL is closed in the middle
  of the WAL being truncated. (@rfratto)

v0.5.0 (2020-08-12)
-------------------

### Features

- A [scrape targets API](https://github.com/grafana/agent/blob/main/docs/api.md#list-current-scrape-targets)
  has been added to show every target the Agent is currently scraping, when it
  was last scraped, how long it took to scrape, and errors from the last
  scrape, if any. (@rfratto)

- "Shared Instance Mode" is the new default mode for spawning Prometheus
  instances, and will improve CPU and memory usage for users of integrations
  and the scraping service. (@rfratto)

### Enhancements

- Memory stability and utilization of the WAL has been improved, and the
  reported number of active series in the WAL will stop double-counting
  recently churned series. (@rfratto)

- Changing scrape_configs and remote_write configs for an instance will now be
  dynamically applied without restarting the instance. This will result in less
  missing metrics for users of the scraping service that change a config.
  (@rfratto)

- The Tanka configuration now uses k8s-alpha. (@duologic)

### Bugfixes

- The Tanka configuration will now also deploy a single-replica deployment
  specifically for scraping the Kubernetes API. This deployment acts together
  with the Daemonset to scrape the full cluster and the control plane.
  (@gotjosh)

- The node_exporter filesystem collector will now work on Linux systems without
  needing to manually set the blocklist and allowlist of filesystems.
  (@rfratto)

v0.4.0 (2020-06-18)
-------------------

### Features

- Support for integrations has been added. Integrations can be any embedded
  tool, but are currently used for embedding exporters and generating scrape
  configs. (@rfratto)

- node_exporter has been added as an integration. This is the full version of
  node_exporter with the same configuration options. (@rfratto)

- An Agent integration that makes the Agent automatically scrape itself has
  been added. (@rfratto)

### Enhancements

- The WAL can now be truncated if running the Agent without any remote_write
  endpoints. (@rfratto)

### Bugfixes

- Prevent the Agent from crashing when a global Prometheus config stanza is not
  provided. (@robx)

- Enable agent host_filter in the Tanka configs, which was disabled by default
  by mistake. (@rfratto)

v0.3.2 (2020-05-29)
-------------------

### Features

- Tanka configs that deploy the scraping service mode are now available
  (@rfratto)

- A k3d example has been added as a counterpart to the docker-compose example.
  (@rfratto)

### Enhancements

- Labels provided by the default deployment of the Agent (Kubernetes and Tanka)
  have been changed to align with the latest changes to grafana/jsonnet-libs.
  The old `instance` label is now called `pod`, and the new `instance` label is
  unique. A `container` label has also been added. The Agent mixin has been
  subsequently updated to also incorporate these label changes. (@rfratto)

- The `remote_write` and `scrape_config` sections now share the same
  validations as Prometheus (@rfratto)

- Setting `wal_truncation_frequency` to less than the scrape interval is now
  disallowed (@rfratto)

### Bugfixes

- A deadlock in scraping service mode when updating a config that shards to the
  same node has been fixed (@rfratto)

- `remote_write` config stanzas will no longer ignore `password_file`
  (@rfratto)

- `scrape_config` client secrets (e.g., basic auth, bearer token,
  `password_file`) will now be properly retained in scraping service mode
  (@rfratto)

- Labels for CPU, RX, and TX graphs in the Agent Operational dashboard now
  correctly show the pod name of the Agent instead of the exporter name.
  (@rfratto)

v0.3.1 (2020-05-20)
-------------------

### Features

- The Agent has upgraded its vendored Prometheus to v2.18.1 (@gotjosh,
  @rfratto)

### Bugfixes

- A typo in the Tanka configs and Kubernetes manifests that prevents the Agent
  launching with v0.3.0 has been fixed (@captncraig)

- Fixed a bug where Tanka mixins could not be used due to an issue with the
  folder placement enhancement (@rfratto)

### Enhancements

- `agentctl` and the config API will now validate that the YAML they receive
  are valid instance configs. (@rfratto)

v0.3.0 (2020-05-13)
-------------------

### Features

- A third operational mode called "scraping service mode" has been added. A KV
  store is used to store instance configs which are distributed amongst a
  clustered set of Agent processes, dividing the total scrape load across each
  agent. An API is exposed on the Agents to list, create, update, and delete
  instance configurations from the KV store. (@rfratto)

- An "agentctl" binary has been released to interact with the new instance
  config management API created by the "scraping service mode." (@rfratto,
  @hoenn)

- The Agent now includes readiness and healthiness endpoints. (@rfratto)

### Enhancements

- The YAML files are now parsed strictly and an invalid YAML will generate an
  error at runtime. (@hoenn)

- The default build mode for the Docker containers is now release, not debug.
  (@rfratto)

- The Grafana Agent Tanka Mixins now are placed in an "Agent" folder within
  Grafana. (@cyriltovena)

v0.2.0 (2020-04-09)
-------------------

### Features

- The Prometheus remote write protocol will now send scraped metadata (metric
  name, help, type and unit). This results in almost negligent bytes sent
  increase as metadata is only sent every minute. It is on by default.
  (@gotjosh)

  These metrics are available to monitor metadata being sent:
    - `prometheus_remote_storage_succeeded_metadata_total`
    - `prometheus_remote_storage_failed_metadata_total`
    - `prometheus_remote_storage_retried_metadata_total`
    - `prometheus_remote_storage_sent_batch_duration_seconds` and
      `prometheus_remote_storage_sent_bytes_total` have a new label type with
      the values of `metadata` or `samples`.

### Enhancements

- The Agent has upgraded its vendored Prometheus to v2.17.1 (@rfratto)

### Bugfixes

- Invalid configs passed to the agent will now stop the process after they are
  logged as invalid; previously the Agent process would continue. (@rfratto)

- Enabling host_filter will now allow metrics from node role Kubernetes service
  discovery to be scraped properly (e.g., cAdvisor, Kubelet). (@rfratto)

v0.1.1 (2020-03-16)
-------------------

### Other changes

- Nits in documentation (@sh0rez)

- Fix various dashboard mixin problems from v0.1.0 (@rfratto)

- Pass through release tag to `docker build` (@rfratto)

v0.1.0 (2020-03-16)
-------------------

> First release!

### Features

* Support for scraping Prometheus metrics and sharding the agent through the
  presence of a `host_filter` flag within the Agent configuration file.

[upgrade guide]: https://grafana.com/docs/agent/latest/upgrade-guide/
[contributors guide]: ./docs/developer/contributing.md#updating-the-changelog

'''
'''--- CODE_OF_CONDUCT.md ---
# Contributor Covenant Code of Conduct

## Our Pledge

In the interest of fostering an open and welcoming environment, we as
contributors and maintainers pledge to making participation in our project and
our community a harassment-free experience for everyone, regardless of age, body
size, disability, ethnicity, sex characteristics, gender identity and expression,
level of experience, education, socio-economic status, nationality, personal
appearance, race, religion, or sexual identity and orientation.

## Our Standards

Examples of behavior that contributes to creating a positive environment
include:

* Using welcoming and inclusive language
* Being respectful of differing viewpoints and experiences
* Gracefully accepting constructive criticism
* Focusing on what is best for the community
* Showing empathy towards other community members

Examples of unacceptable behavior by participants include:

* The use of sexualized language or imagery and unwelcome sexual attention or
 advances
* Trolling, insulting/derogatory comments, and personal or political attacks
* Public or private harassment
* Publishing others' private information, such as a physical or electronic
 address, without explicit permission
* Other conduct which could reasonably be considered inappropriate in a
 professional setting

## Our Responsibilities

Project maintainers are responsible for clarifying the standards of acceptable
behavior and are expected to take appropriate and fair corrective action in
response to any instances of unacceptable behavior.

Project maintainers have the right and responsibility to remove, edit, or
reject comments, commits, code, wiki edits, issues, and other contributions
that are not aligned to this Code of Conduct, or to ban temporarily or
permanently any contributor for other behaviors that they deem inappropriate,
threatening, offensive, or harmful.

## Scope

This Code of Conduct applies both within project spaces and in public spaces
when an individual is representing the project or its community. Examples of
representing a project or community include using an official project e-mail
address, posting via an official social media account, or acting as an appointed
representative at an online or offline event. Representation of a project may be
further defined and clarified by project maintainers.

## Enforcement

Instances of abusive, harassing, or otherwise unacceptable behavior may be
reported by contacting the project team at conduct@grafana.com. All
complaints will be reviewed and investigated and will result in a response that
is deemed necessary and appropriate to the circumstances. The project team is
obligated to maintain confidentiality with regard to the reporter of an incident.
Further details of specific enforcement policies may be posted separately.

Project maintainers who do not follow or enforce the Code of Conduct in good
faith may face temporary or permanent repercussions as determined by other
members of the project's leadership.

## Attribution

This Code of Conduct is adapted from the [Contributor Covenant][homepage], version 1.4,
available at https://www.contributor-covenant.org/version/1/4/code-of-conduct.html

[homepage]: https://www.contributor-covenant.org

For answers to common questions about this code of conduct, see
https://www.contributor-covenant.org/faq

'''
'''--- GOVERNANCE.md ---
---
title: Governance
---
# Governance

This document describes the rules and governance of the project. It is meant to be followed by all the developers of the project and the Grafana Agent community. Common terminology used in this governance document are listed below:

- **Team members**: Any members of the private [team mailing list][team].

- **Maintainers**: Maintainers lead an individual project or parts thereof ([`MAINTAINERS.md`][maintainers]).

- **Projects**: A single repository in the Grafana GitHub organization and listed below is referred to as a project:
  - Grafana Agent

- **The Grafana Agent project**: The sum of all activities performed under this governance, concerning one or more repositories or the community.

## Values

The Grafana Agent developers and community are expected to follow the values defined in the [Code of Conduct][coc]. Furthermore, the Grafana Agent community strives for kindness, giving feedback effectively, and building a welcoming environment. The Grafana Agent developers generally decide by consensus and only resort to conflict resolution by a majority vote if consensus cannot be reached.

## Projects

Each project must have a [`MAINTAINERS.md`][maintainers] file with at least one maintainer. Where a project has a release process, access and documentation should be such that more than one person can perform a release. Where a project has a release process, access and documentation should be such that more than one person can perform a release. Releases should be announced on the [GitHub Discussions][discussions] page. Any new projects should be first proposed on the [team mailing list][team] following the voting procedures listed below.

## Decision making

### Team members

Team member status may be given to those who have made ongoing contributions to the Grafana Agent project for at least 3 months. This is usually in the form of code improvements and/or notable work on documentation, but organizing events or user support could also be taken into account.

New members may be proposed by any existing member by email to the [team mailing list][team]. It is highly desirable to reach consensus about acceptance of a new member. However, the proposal is ultimately voted on by a formal [supermajority vote](#supermajority-vote).

If the new member proposal is accepted, the proposed team member should be contacted privately via email to confirm or deny their acceptance of team membership. This email will also be CC'd to the [team mailing list][team] for record-keeping purposes.

If they choose to accept, the [onboarding](#onboarding) procedure is followed.

Team members may retire at any time by emailing [the team][team].

Team members can be removed by [supermajority vote](#supermajority-vote) on [the team mailing list][team].
For this vote, the member in question is not eligible to vote and does not count towards the quorum.
Any removal vote can cover only one single person.

Upon death of a member, they leave the team automatically.

In case a member leaves, the [offboarding](#offboarding) procedure is applied.

The current team members are:

- Matt Durham - [mattdurham](https://github.com/mattdurham) ([Grafana Labs](https://grafana.com))
- Joe Elliott - [joe-elliott](https://github.com/joe-elliott) ([Grafana Labs](https://grafana.com))
- Robert Fratto - [rfratto](https://github.com/rfratto) ([Grafana Labs](https://grafana.com))
- Richard Hartmann - [RichiH](https://github.com/RichiH) ([Grafana Labs](https://grafana.com))
- Hanif Jetha - [hjet](https://github.com/hjet) ([Grafana Labs](https://grafana.com))
- Mario Rodriguez - [mapno](https://github.com/mapno) ([Grafana Labs](https://grafana.com))
- Robert Lankford - [rlankfo](https://github.com/rlankfo) ([Grafana Labs](https://grafana.com))

### Maintainers

Maintainers lead one or more project(s) or parts thereof and serve as a point of conflict resolution amongst the contributors to this project. Ideally, maintainers are also team members, but exceptions are possible for suitable maintainers that, for whatever reason, are not yet team members.

Changes in maintainership have to be announced on the [developers mailing list][devs]. They are decided by [rough consensus](#consensus) and formalized by changing the [`MAINTAINERS.md`][maintainers] file of the respective repository.

Maintainers are granted commit rights to all projects covered by this governance.

A maintainer or committer may resign by notifying the [team mailing list][team]. A maintainer with no project activity for a year is considered to have resigned. Maintainers that wish to resign are encouraged to propose another team member to take over the project.

A project may have multiple maintainers, as long as the responsibilities are clearly agreed upon between them. This includes coordinating who handles which issues and pull requests.

### Technical decisions

Technical decisions that only affect a single project are made informally by the maintainer of this project, and [rough consensus](#consensus) is assumed. Technical decisions that span multiple parts of the project should be discussed and made on the [developer mailing list][devs].

Decisions are usually made by [rough consensus](#consensus). If no consensus can be reached, the matter may be resolved by [majority vote](#majority-vote).

### Governance changes

Changes to this document are made by Grafana Labs.

### Other matters

Any matter that needs a decision may be called to a vote by any member if they deem it necessary. For private or personnel matters, discussion and voting takes place on the [team mailing list][team], otherwise on the [developer mailing list][devs].

## Voting

The Grafana Agent project usually runs by informal consensus, however sometimes a formal decision must be made.

Depending on the subject matter, as laid out [above](#decision-making), different methods of voting are used.

For all votes, voting must be open for at least one week. The end date should be clearly stated in the call to vote. A vote may be called and closed early if enough votes have come in one way so that further votes cannot change the final decision.

In all cases, all and only [team members](#team-members) are eligible to vote, with the sole exception of the forced removal of a team member, in which said member is not eligible to vote.

Discussion and votes on personnel matters (including but not limited to team membership and maintainership) are held in private on the [team mailing list][team]. All other discussion and votes are held in public on the [developer mailing list][devs].

For public discussions, anyone interested is encouraged to participate. Formal power to object or vote is limited to [team members](#team-members).

### Consensus

The default decision making mechanism for the Grafana Agent project is [rough][rough] consensus. This means that any decision on technical issues is considered supported by the [team][team] as long as nobody objects or the objection has been considered but not necessarily accommodated.

Silence on any consensus decision is implicit agreement and equivalent to explicit agreement. Explicit agreement may be stated at will. Decisions may, but do not need to be called out and put up for decision on the [developers mailing list][devs] at any time and by anyone.

Consensus decisions can never override or go against the spirit of an earlier explicit vote.

If any [team member](#team-members) raises objections, the team members work together towards a solution that all involved can accept. This solution is again subject to rough consensus.

In case no consensus can be found, but a decision one way or the other must be made, any [team member](#team-members) may call a formal [majority vote](#majority-vote).

### Majority vote

Majority votes must be called explicitly in a separate thread on the appropriate mailing list. The subject must be prefixed with `[VOTE]`. In the body, the call to vote must state the proposal being voted on. It should reference any discussion leading up to this point.

Votes may take the form of a single proposal, with the option to vote yes or no, or the form of multiple alternatives.

A vote on a single proposal is considered successful if more vote in favor than against.

If there are multiple alternatives, members may vote for one or more alternatives, or vote no to object to all alternatives. It is not possible to cast an abstain vote. A vote on multiple alternatives is considered decided in favor of one alternative if it has received the most votes in favor, and a vote from more than half of those voting. Should no alternative reach this quorum, another vote on a reduced number of options may be called separately.

### Supermajority vote

Supermajority votes must be called explicitly in a separate thread on the appropriate mailing list. The subject must be prefixed with `[VOTE]`. In the body, the call to vote must state the proposal being voted on. It should reference any discussion leading up to this point.

Votes may take the form of a single proposal, with the option to vote yes or no, or the form of multiple alternatives.

A vote on a single proposal is considered successful if at least two thirds of those eligible to vote vote in favor.

If there are multiple alternatives, members may vote for one or more alternatives, or vote no to object to all alternatives. A vote on multiple alternatives is considered decided in favor of one alternative if it has received the most votes in favor, and a vote from at least two thirds of those eligible to vote. Should no alternative reach this quorum, another vote on a reduced number of options may be called separately.

## On- / Offboarding

### Onboarding

The new member is

- added to the list of [team members](#team-members). Ideally by sending a PR of their own, at least approving said PR.
- announced on the [developers mailing list][devs] by an existing team member. Ideally, the new member replies in this thread, acknowledging team membership.
- added to the projects with commit rights.
- added to the [team mailing list][team].

### Offboarding

The ex-member is

- removed from the list of [team members](#team-members). Ideally by sending a PR of their own, at least approving said PR. In case of forced removal, no approval is needed.
- removed from the projects. Optionally, they can retain maintainership of one or more repositories if the [team](#team-members) agrees.
- removed from the team mailing list and demoted to a normal member of the other mailing lists.
- not allowed to call themselves an active team member any more, nor allowed to imply this to be the case.
- added to a list of previous members if they so choose.

If needed, we reserve the right to publicly announce removal.

[coc]: https://github.com/grafana/agent/blob/main/CODE_OF_CONDUCT.md
[devs]: https://groups.google.com/forum/#!forum/grafana-agent-developers
[maintainers]: https://github.com/grafana/agent/blob/main/MAINTAINERS.md
[rough]: https://tools.ietf.org/html/rfc7282
[team]: https://groups.google.com/forum/#!forum/grafana-agent-team
[discussions]: https://github.com/grafana/agent/discussions

'''
'''--- MAINTAINERS.md ---
The following people are the primary maintainers of the project:

* Robert Fratto (<robert.fratto@grafana.com> / @rfratto)
* Matt Durham (<matt.durham@grafana.com> / @mattdurham)
* Robbie Lankford (<robert.lankford@grafana.com> / @rlankfo)
* Paschalis Tsilias (<paschalis.tsilias@grafana.com> / @tpaschalis)

Some parts of the codebase have other maintainers:

* `cmd/agent-operator`: Craig Peterson (<craig.peterson@grafana.com> / @catpncraig), Marc Tudur (<marc.tuduri@grafana.com> / @marctc)
* `pkg/integrations`: Gabriel Antunes (<gabriel.antunes@grafana.com> / @gaantunes), Ryan Geyer (<ryan.geyer@grafana.com> / @rgeyer), Craig Peterson (<craig.peterson@grafana.com> / @catpncraig), Marc Tudur (<marc.tuduri@grafana.com> / @marctc)
* `pkg/operator`: Craig Peterson (<craig.peterson@grafana.com> / @catpncraig), Marc Tudur (<marc.tuduri@grafana.com> / @marctc)
* `pkg/traces`: Joe Elliott (<joe.elliott@grafana.com> / @joe-elliott), Mario Rodriguez (<mario.rodriguez@grafana.com>/ @mapno)

For the sake of brevity, not all subtrees are explicitly listed. Due to the
size of this repository, the natural changes in focus of maintainers over time,
and nuances of where particular features live, this list will always be
incomplete and out of date. However the listed maintainer(s) should be able to
direct a PR/question to the right person.

'''
'''--- README.md ---
<p align="center"><img src="docs/sources/assets/logo_and_name.png" alt="Grafana Agent logo"></p>

Grafana Agent is a telemetry collector for sending metrics, logs,
and trace data to the opinionated Grafana observability stack. It works best
with:

* [Grafana Cloud](https://grafana.com/products/cloud/)
* [Grafana Enterprise Stack](https://grafana.com/products/enterprise/)
* OSS deployments of [Grafana Loki](https://grafana.com/oss/loki/), [Prometheus](https://prometheus.io/), [Grafana Mimir](https://grafana.com/oss/mimir/), and [Grafana Tempo](https://grafana.com/oss/tempo/)

Users of Prometheus operating at a massive scale (i.e., millions of active
series) can struggle to run an unsharded singleton Prometheus instance: it becomes a
single point of failure and requires a giant machine with a lot of resources
allocated to it. Even with proper sharding across multiple Prometheus instances,
using Prometheus to send data to a cloud vendor can seem redundant: why pay for
cloud storage if data is already stored locally?

The Grafana Agent uses the same code as Prometheus, but tackles these issues
by only using the most relevant parts of Prometheus for interaction with hosted
metrics:

1. Service Discovery
2. Scraping
3. Write Ahead Log (WAL)
4. Remote Write

On top of these, the Grafana Agent enables easier sharding mechanisms that
enable users to shard Agents across their cluster and lower the memory requirements
per machine.

A typical deployment of the Grafana Agent for Prometheus metrics can see
up to a 40% reduction in memory usage with equal scrape loads.

The Grafana Agent it can be used to send Prometheus metrics to any system that
supports the Prometheus `remote_write` API.

## Trade-offs

By heavily optimizing Prometheus for remote write and resource reduction, some
trade-offs have been made:

- You can't query the Agent; you can only query metrics from the remote write
  storage.
- Recording rules aren't supported.
- Alerts aren't supported.
- When sharding the Agent, if your node has problems that interrupt metric
  availability, metrics tracking that node won't be sent for alerting on.

While the Agent can't use recording rules and alerts, `remote_write` systems such
as Mimir currently support server-side rules and alerts. Note that this trade-off
means that reliability of alerts are tied to the reliability of the remote system
and alerts will be delayed at least by the time it takes for samples to reach
the remote system.

## Getting Started

When using Kubernetes this [link](https://grafana.com/docs/grafana-cloud/quickstart/agent-k8s) offers the best guide.

Other installation methods can be found in our
[Grafana Agent](https://grafana.com/docs/agent/latest/set-up/) documentation.

More detailed [documentation](./docs/README.md) is provided as part of the
repository.

## Example

The [`example/`](./example) folder contains docker-compose configs and a local
k3d/Tanka environment. Both examples deploy the Agent, Cortex and Grafana for
testing the agent. See the [docker-compose README](./example/docker-compose/README.md)
and the [k3d example README](./example/k3d/README.md) for more information.

## Prometheus Vendoring

The Grafana Agent vendors a downstream Prometheus repository maintained by
[Grafana Labs](https://github.com/grafana/prometheus). This is done so
experimental features Grafana Labs wants to contribute upstream can first be
tested and iterated on quickly within the Agent. We aim to keep the
experimental changes to a minimum and upstream changes as soon as possible.

For more context on our vendoring strategy, read our
[downstream repo maintenance guide](./docs/developer/downstream-prometheus.md).

## Getting Help

If you have any questions or feedback regarding the Grafana Agent:

* Ask a question on the Agent Slack channel. To invite yourself to the Grafana
  Slack, visit https://slack.grafana.com/ and join the #agent channel.
* Alternatively ask questions on the
  [Discussions page](https://github.com/grafana/agent/discussions).
* [File an issue](https://github.com/grafana/agent/issues/new) for bugs, issues
  and feature suggestions.
* Attend the [Grafana Agent Community Call](https://docs.google.com/document/d/1TqaZD1JPfNadZ4V81OCBPCG_TksDYGlNlGdMnTWUSpo).

## Contributing

Any contributions are welcome and details can be found
[in our contributors guide](./docs/developer/contributing.md).

'''
'''--- SECURITY.md ---
# Reporting security issues

If you think you have found a security vulnerability, please send a report to [security@grafana.com](mailto:security@grafana.com). This address can be used for all of Grafana Labs's open source and commercial products (including but not limited to Grafana, Grafana Cloud, Grafana Enterprise, and grafana.com). We can accept only vulnerability reports at this address.

Please encrypt your message to us; please use our PGP key. The key fingerprint is:

F988 7BEA 027A 049F AE8E 5CAA D125 8932 BE24 C5CA

The key is available from [keyserver.ubuntu.com](https://keyserver.ubuntu.com/pks/lookup?search=0xF9887BEA027A049FAE8E5CAAD1258932BE24C5CA&fingerprint=on&op=index).

Grafana Labs will send you a response indicating the next steps in handling your report. After the initial reply to your report, the security team will keep you informed of the progress towards a fix and full announcement, and may ask for additional information or guidance.

**Important:** We ask you to not disclose the vulnerability before it has been fixed and announced, unless you received a response from the Grafana Labs security team that you can do so.

## Security announcements

We maintain a category on the community site called [Security Announcements](https://community.grafana.com/c/support/security-announcements),
where we will post a summary, remediation, and mitigation details for any patch containing security fixes.

You can also subscribe to email updates to this category if you have a grafana.com account and sign on to the community site or track updates via an [RSS feed](https://community.grafana.com/c/support/security-announcements.rss).

'''
'''--- build-image/README.md ---
# Grafana Agent build images

The Grafana Agent build images are used for CI workflows to manage builds of
Grafana Agent.

There are two images:

* `grafana/agent-build-image:vX.Y.Z` (for building Linux containers)
* `grafana/agent-build-image:vX.Y.Z-windows` (for building Windows containers)

(Where `vX.Y.Z` is replaced with some semantic version, like v0.14.0).

## Pushing new images

Once a commit is merged to main which updates the build-image Dockerfiles, a
maintainer must push a tag matching the pattern `build-image/vX.Y.Z` to the
grafana/agent repo. For example, to create version v0.15.0 of the build images,
a maintainer would push the tag `build-image/v0.15.0`.

Automation will trigger off of this tag being pushed, building and pushing the
new build images to Docker Hub.

A follow-up commit to use the newly pushed build images must be made.

'''
'''--- cmd/agent-operator/DEVELOPERS.md ---
# Developer's Guide

This document contains maintainer-specific information.

Table of Contents:

1. [Introduction](#introduction)
2. [Updating CRDs](#updating-crds)
3. [Testing Locally](#testing-locally)
4. [Development Architecture](#development-architecture)

## Introduction

Kubernetes Operators are designed to automate the behavior of human operators
for pieces of software. The Grafana Agent Operator, in particular, is based off
of the very popular [Prometheus
Operator](https://github.com/prometheus-operator/prometheus-operator):

1. We use the same v1 CRDs from the official project.
2. We aim to generate the same remote_write and scrape_configs that the
   Prometheus Operator does.

That being said, we're not fully compatible, and the Grafana Agent Operator has
the same trade-offs that the Grafana Agent does: no recording rules, no alerts,
no local storage for querying metrics.

The public [Grafana Agent Operator design
doc](https://docs.google.com/document/d/1nlwhJLspTkkm8vLgrExJgf02b9GCAWv_Ci_a9DliI_s)
goes into more detail about the context and design decisions being made.

## Updating CRDs

The `make crds` command at the root of this repository will generate CRDs and
other code used by the operator. This calls the [generate-crds
script](../../tools/generate-crds.bash) in a container. If you wish to call this
script manually, you must also install `controller-gen`.
Ensure to keep the version in sync with what's defined in the `Dockerfile`.

```
go install sigs.k8s.io/controller-tools/cmd/controller-gen@v0.6.2
```

## Testing Locally

Create a k3d cluster (depending on k3d v4.x):

```
k3d cluster create agent-operator \
  --port 30080:80@loadbalancer \
  --api-port 50043 \
  --kubeconfig-update-default=true \
  --kubeconfig-switch-context=true \
  --wait
```

### Deploy Prometheus

An example Prometheus server is provided in `./example-prometheus.yaml`. Deploy
it with the following, from the root of the repository:

```
kubectl apply -f ./cmd/agent-operator/example-prometheus.yaml
```

You can view it at http://prometheus.k3d.localhost:30080 once the k3d cluster is
running.

### Apply the CRDs

Generated CRDs used by the operator can be found in [the Production
folder](../../production/operator/crds). Deploy them from the root of the
repository with:

```
kubectl apply -f production/operator/crds
```

### Run the Operator

Now that the CRDs are applied, you can run the operator from the root of the
repository:

```
go run ./cmd/agent-operator
```

### Apply a GrafanaAgent custom resource

Finally, you can apply an example GrafanaAgent custom resource. One is [provided
for you](../../cmd/agent-operator/agent-example-config.yaml). From the root of the repository, run:

```
kubectl apply -f ./cmd/agent-operator/agent-example-config.yaml
```

If you are running the operator, you should see it pick up the change and start
mutating the cluster.

## Development Architecture

This project makes heavy use of the [Kubernetes SIG Controller
Runtime](https://pkg.go.dev/sigs.k8s.io/controller-runtime) project. That
project has its own documentation, but for a high level overview of how it
relates to this project:

1. The Grafana Agent Operator is composed of a single _controller_. A
   _controller_ is responsible for responding to changes to Kubernetes resources.

2. Controllers can be notified about changes to:

   1. One Primary resource (i.e., the GrafanaAgent CR)

   2. Any number of secondary resources used to deploy the managed software
      (e.g., ServiceMonitor, PodMonitors). This is done using a custom event
      handler, which we'll detail below.

   3. Any number of resources the Operator deploys (ConfigMaps, Secrets,
      StatefulSets). This is done using
      [ownerReferences](https://kubernetes.io/docs/concepts/workloads/controllers/garbage-collection/#owners-and-dependents).

3. Controllers have one _reconciler_. The reconciler handles updating managed
   resources for one specific primary resource. The `GrafanaAgent` CRD is
   the primary resource, and the reconciler will handle updating managed
   resources for all discovered GrafanaAgent CRs. Each reconcile request is for
   a specific CR, such as `agent-1` or `agent-2`.

4. A _manager_ initializes all controllers for a project. It provides a caching
   Kubernetes client and propagates Kubernetes events to controllers.

An `EnqueueRequestForSelector` event handler was added to handle dealing to
changes to secondary resources, which is not a concept in the official
Controller Runtime project. This works by allowing the reconciler to request
events for a given primary resource if one of the secondary resource changes.
This means that multiple primary resources can watch a ServiceMonitor and cause
a reconcile when it changes.

Event handlers are specific to a resource, so there is one
`EnqueueRequestForSelector` handler per secondary resource.

Reconciles are supposed to be idempotent, so deletes, updates, and creates
should be treated the same. All managed resources are deployed with
ownerReferences set, so managed resources will be automatically deleted by
Kubernetes' garbage collector when the primary resource gets deleted by the
user.

### Flow

This section walks through what happens when a user deploys a new GrafanaAgent
CR:

1. A GrafanaAgent CR `default/agent` gets deployed to a cluster

2. The Controller's event handlers get notified about the event and queue a
   reconcile request for `default/agent`.

3. The reonciler discovers all secondary `MetricsInstance` referenced by
   `default/agent`.

4. The reconciler discovers all secondary `ServiceMonitor`, `PodMonitor` and
   `Probe` resources that are referenced by the discovered `MetricsInstance`
   resource.

5. The reconciler informs the appropriate `EnqueueRequestForSelector` event
   handlers that changes to those resources should cause a new reconcile for
   `default/agent`.

6. The reconciler discovers all `Secrets` referenced across all current
   resources. The content of the secrets are held in-memory to statically
   configure Grafana Agent fields that do not support reading in from a file
   (e.g., basic auth username).

7. All the discovered secrets are copied to a new Secret in the `default`
   namespace. This is done in case a `ServiceMonitor` is found in a different
   namespace than where the Agent will be deployed.

8. A new Secret is created for the configuration of the Grafana Agent.

9. A StatefulSet is generated for the Grafana Agent.

When `default/agent` gets deleted, all `EnqueueRequestForSelector` event
handlers get notified to stop sending events for `default/agent`.

'''
'''--- cmd/agent-operator/README.md ---
# Grafana Agent Operator

The Grafana Agent Operator is a Kubernetes operator that makes it easier to
deploy the Grafana Agent and easier to collect telemetry data from your pods.
It is currently in **beta**, and is subject to change at any time.

It works by watching for [Kubernetes custom resources](https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/)
that specify how you would like to collect telemetry data from your Kubernetes
cluster and where you would like to send it. They abstract Kubernetes-specific
configuration that is more tedious to perform manually. The Grafana Agent
Operator manages corresponding Grafana Agent deployments in your cluster by
watching for changes against the custom resources.

Metric collection is based on the [Prometheus
Operator](https://github.com/prometheus-operator/prometheus-operator) and
supports the official v1 ServiceMonitor, PodMonitor, and Probe CRDs from the
project. These custom resources represent abstractions for monitoring services,
pods, and ingresses. They are especially useful for Helm users, where manually
writing a generic SD to match all your charts can be difficult (or impossible!)
or where manually writing a specific SD for each chart can be tedious.

## Roadmap

- [ ] Helm chart
- [ ] Logs support
- [ ] Traces support
- [ ] Integrations support

## Documentation

Refer to the project's [documentation](../../docs/operator) for how to install
and get started with the Grafana Agent Operator.

## Developer Reference

The [Maintainer's Guide](./DEVELOPERS.md) includes
basic information to help you understand how the code works. This can be very
useful if you are planning on working on the operator.

'''
'''--- cmd/agent-operator/main.go ---
package main

import (
	"flag"
	"fmt"
	"os"

	cortex_log "github.com/cortexproject/cortex/pkg/util/log"
	"github.com/go-kit/log"
	"github.com/go-kit/log/level"
	"github.com/grafana/agent/pkg/operator"
	"github.com/grafana/agent/pkg/operator/logutil"
	"github.com/prometheus/common/version"
	controller "sigs.k8s.io/controller-runtime"

	// Needed for clients.
	_ "k8s.io/client-go/plugin/pkg/client/auth"
)

func main() {
	var (
		logger = log.NewLogfmtLogger(log.NewSyncWriter(os.Stderr))
		cfg    = loadConfig(logger)

		err error
	)

	logger = setupLogger(logger, cfg)

	op, err := operator.New(logger, cfg)
	if err != nil {
		level.Error(logger).Log("msg", "unable to create operator", "err", err)
		os.Exit(1)
	}

	// Run the manager and wait for a signal to shut down.
	level.Info(logger).Log("msg", "starting manager")
	if err := op.Start(controller.SetupSignalHandler()); err != nil {
		level.Error(logger).Log("msg", "problem running manager", "err", err)
		os.Exit(1)
	}
}

// loadConfig will read command line flags and populate a Config. loadConfig
// will exit the program on failure.
func loadConfig(l log.Logger) *operator.Config {
	fs := flag.NewFlagSet(os.Args[0], flag.ExitOnError)

	var (
		printVersion bool
	)

	cfg, err := operator.NewConfig(fs)
	if err != nil {
		level.Error(l).Log("msg", "failed to parse flags", "err", err)
		os.Exit(1)
	}

	fs.BoolVar(&printVersion, "version", false, "Print this build's version information")

	if err := fs.Parse(os.Args[1:]); err != nil {
		level.Error(l).Log("msg", "failed to parse flags", "err", err)
		os.Exit(1)
	}

	if printVersion {
		fmt.Println(version.Print("agent-operator"))
		os.Exit(0)
	}

	return cfg
}

// setupLogger sets up our logger. If this function fails, the program will
// exit.
func setupLogger(l log.Logger, cfg *operator.Config) log.Logger {
	newLogger, err := cortex_log.NewPrometheusLogger(cfg.LogLevel, cfg.LogFormat)
	if err != nil {
		level.Error(l).Log("msg", "failed to create logger", "err", err)
		os.Exit(1)
	}
	l = newLogger

	adapterLogger := logutil.Wrap(l)

	// NOTE: we don't set up a caller field here, unlike the normal agent.
	// There's too many multiple nestings of the logger that prevent getting the
	// caller from working properly.

	// Set up the global logger and the controller-local logger.
	controller.SetLogger(adapterLogger)
	cfg.Controller.Logger = adapterLogger
	return l
}

'''
'''--- cmd/agent/entrypoint.go ---
package main

import (
	"context"
	"fmt"
	"net"
	"net/http"
	"net/url"
	"os"
	"os/signal"
	"sync"
	"syscall"

	"github.com/gorilla/mux"
	"github.com/grafana/agent/pkg/logs"
	"github.com/grafana/agent/pkg/metrics"
	"github.com/grafana/agent/pkg/metrics/instance"
	"github.com/grafana/agent/pkg/server"
	"github.com/grafana/agent/pkg/traces"
	"github.com/grafana/agent/pkg/usagestats"
	"github.com/oklog/run"
	"google.golang.org/grpc"
	"gopkg.in/yaml.v2"

	"github.com/grafana/agent/pkg/config"
	"github.com/prometheus/client_golang/prometheus"
	"github.com/weaveworks/common/signals"

	"github.com/go-kit/log/level"
)

// Entrypoint is the entrypoint of the application that starts all subsystems.
type Entrypoint struct {
	mut sync.Mutex

	reloader Reloader

	log *server.Logger
	cfg config.Config

	srv          *server.Server
	promMetrics  *metrics.Agent
	lokiLogs     *logs.Logs
	tempoTraces  *traces.Traces
	integrations config.Integrations
	reporter     *usagestats.Reporter

	reloadListener net.Listener
	reloadServer   *http.Server
}

// Reloader is any function that returns a new config.
type Reloader = func() (*config.Config, error)

// NewEntrypoint creates a new Entrypoint.
func NewEntrypoint(logger *server.Logger, cfg *config.Config, reloader Reloader) (*Entrypoint, error) {
	var (
		reg      = prometheus.DefaultRegisterer
		gatherer = prometheus.DefaultGatherer

		ep = &Entrypoint{
			log:      logger,
			reloader: reloader,
		}
		err error
	)

	ep.srv, err = server.New(logger, reg, gatherer, cfg.Server, cfg.ServerFlags)
	if err != nil {
		return nil, err
	}

	ep.promMetrics, err = metrics.New(reg, cfg.Metrics, logger)
	if err != nil {
		return nil, err
	}

	ep.lokiLogs, err = logs.New(reg, cfg.Logs, logger)
	if err != nil {
		return nil, err
	}

	ep.tempoTraces, err = traces.New(ep.lokiLogs, ep.promMetrics.InstanceManager(), reg, cfg.Traces, cfg.Server.LogLevel.Logrus, cfg.Server.LogFormat)
	if err != nil {
		return nil, err
	}

	integrationGlobals, err := ep.createIntegrationsGlobals(cfg)
	if err != nil {
		return nil, err
	}

	ep.integrations, err = config.NewIntegrations(logger, &cfg.Integrations, integrationGlobals)
	if err != nil {
		return nil, err
	}

	ep.reporter, err = usagestats.NewReporter(logger, cfg)
	if err != nil {
		return nil, err
	}

	ep.wire(ep.srv.HTTP, ep.srv.GRPC)

	// Mostly everything should be up to date except for the server, which hasn't
	// been created yet.
	if err := ep.ApplyConfig(*cfg); err != nil {
		return nil, err
	}
	return ep, nil
}

func (ep *Entrypoint) createIntegrationsGlobals(cfg *config.Config) (config.IntegrationsGlobals, error) {
	hostname, err := instance.Hostname()
	if err != nil {
		return config.IntegrationsGlobals{}, fmt.Errorf("getting hostname: %w", err)
	}

	var listenPort int
	if ta, ok := ep.srv.HTTPAddress().(*net.TCPAddr); ok {
		listenPort = ta.Port
	}

	return config.IntegrationsGlobals{
		AgentIdentifier: fmt.Sprintf("%s:%d", hostname, listenPort),
		Metrics:         ep.promMetrics,
		Logs:            ep.lokiLogs,
		Tracing:         ep.tempoTraces,
		// TODO(rfratto): set SubsystemOptions here when v1 is removed.

		// Configure integrations to connect to the agent's in-memory server and avoid the network.
		DialContextFunc: ep.srv.DialContext,
		AgentBaseURL: &url.URL{
			Scheme: "http",
			Host:   cfg.ServerFlags.HTTP.InMemoryAddr,
		},
	}, nil
}

// ApplyConfig applies changes to the subsystems of the Agent.
func (ep *Entrypoint) ApplyConfig(cfg config.Config) error {
	ep.mut.Lock()
	defer ep.mut.Unlock()

	var failed bool

	if err := ep.log.ApplyConfig(&cfg.Server); err != nil {
		level.Error(ep.log).Log("msg", "failed to update logger", "err", err)
		failed = true
	}

	if err := ep.srv.ApplyConfig(cfg.Server); err != nil {
		level.Error(ep.log).Log("msg", "failed to update server", "err", err)
		failed = true
	}

	// Go through each component and update it.
	if err := ep.promMetrics.ApplyConfig(cfg.Metrics); err != nil {
		level.Error(ep.log).Log("msg", "failed to update prometheus", "err", err)
		failed = true
	}

	if err := ep.lokiLogs.ApplyConfig(cfg.Logs); err != nil {
		level.Error(ep.log).Log("msg", "failed to update loki", "err", err)
		failed = true
	}

	if err := ep.tempoTraces.ApplyConfig(ep.lokiLogs, ep.promMetrics.InstanceManager(), cfg.Traces, cfg.Server.LogLevel.Logrus); err != nil {
		level.Error(ep.log).Log("msg", "failed to update traces", "err", err)
		failed = true
	}

	integrationGlobals, err := ep.createIntegrationsGlobals(&cfg)
	if err != nil {
		level.Error(ep.log).Log("msg", "failed to update integrations", "err", err)
		failed = true
	} else if err := ep.integrations.ApplyConfig(&cfg.Integrations, integrationGlobals); err != nil {
		level.Error(ep.log).Log("msg", "failed to update integrations", "err", err)
		failed = true
	}

	ep.cfg = cfg
	if failed {
		return fmt.Errorf("changes did not apply successfully")
	}

	return nil
}

// wire is used to hook up API endpoints to components. It is called once after
// all subsystems are created.
func (ep *Entrypoint) wire(mux *mux.Router, grpc *grpc.Server) {
	ep.promMetrics.WireAPI(mux)
	ep.promMetrics.WireGRPC(grpc)

	ep.integrations.WireAPI(mux)
	ep.lokiLogs.WireAPI(mux)

	mux.HandleFunc("/-/healthy", func(w http.ResponseWriter, r *http.Request) {
		w.WriteHeader(http.StatusOK)
		fmt.Fprintf(w, "Agent is Healthy.\n")
	})

	mux.HandleFunc("/-/ready", func(w http.ResponseWriter, r *http.Request) {
		if !ep.promMetrics.Ready() {
			w.WriteHeader(http.StatusServiceUnavailable)
			fmt.Fprint(w, "Metrics are not ready yet.\n")

			return
		}
		w.WriteHeader(http.StatusOK)
		fmt.Fprintf(w, "Agent is Ready.\n")
	})

	mux.HandleFunc("/-/config", func(rw http.ResponseWriter, r *http.Request) {
		ep.mut.Lock()
		cfg := ep.cfg
		ep.mut.Unlock()

		if cfg.EnableConfigEndpoints {
			bb, err := yaml.Marshal(cfg)
			if err != nil {
				http.Error(rw, fmt.Sprintf("failed to marshal config: %s", err), http.StatusInternalServerError)
			} else {
				_, _ = rw.Write(bb)
			}
		} else {
			rw.WriteHeader(http.StatusNotFound)
			_, _ = rw.Write([]byte("404 - config endpoint is disabled"))
		}
	})

	mux.HandleFunc("/-/reload", ep.reloadHandler).Methods("GET", "POST")
}

func (ep *Entrypoint) reloadHandler(rw http.ResponseWriter, r *http.Request) {
	success := ep.TriggerReload()
	if success {
		rw.WriteHeader(http.StatusOK)
	} else {
		rw.WriteHeader(http.StatusBadRequest)
	}
}

// TriggerReload will cause the Entrypoint to re-request the config file and
// apply the latest config. TriggerReload returns true if the reload was
// successful.
func (ep *Entrypoint) TriggerReload() bool {
	level.Info(ep.log).Log("msg", "reload of config file requested")

	cfg, err := ep.reloader()
	if err != nil {
		level.Error(ep.log).Log("msg", "failed to reload config file", "err", err)
		return false
	}
	cfg.LogDeprecations(ep.log)

	err = ep.ApplyConfig(*cfg)
	if err != nil {
		level.Error(ep.log).Log("msg", "failed to reload config file", "err", err)
		return false
	}

	return true
}

// Stop stops the Entrypoint and all subsystems.
func (ep *Entrypoint) Stop() {
	ep.mut.Lock()
	defer ep.mut.Unlock()

	ep.integrations.Stop()
	ep.lokiLogs.Stop()
	ep.promMetrics.Stop()
	ep.tempoTraces.Stop()
	ep.srv.Close()

	if ep.reloadServer != nil {
		ep.reloadServer.Close()
	}
}

// Start starts the server used by the Entrypoint, and will block until a
// termination signal is sent to the process.
func (ep *Entrypoint) Start() error {
	var g run.Group

	// Create a signal handler that will stop the Entrypoint once a termination
	// signal is received.
	signalHandler := signals.NewHandler(server.GoKitLogger(ep.log))

	notifier := make(chan os.Signal, 1)
	signal.Notify(notifier, syscall.SIGHUP)

	defer func() {
		signal.Stop(notifier)
		close(notifier)
	}()

	g.Add(func() error {
		signalHandler.Loop()
		return nil
	}, func(e error) {
		signalHandler.Stop()
	})

	if ep.reloadServer != nil && ep.reloadListener != nil {
		g.Add(func() error {
			return ep.reloadServer.Serve(ep.reloadListener)
		}, func(e error) {
			ep.reloadServer.Close()
		})
	}

	srvContext, srvCancel := context.WithCancel(context.Background())
	defer srvCancel()
	defer ep.srv.Close()

	g.Add(func() error {
		return ep.srv.Run(srvContext)
	}, func(e error) {
		srvCancel()
	})

	ep.mut.Lock()
	cfg := ep.cfg
	ep.mut.Unlock()
	if cfg.EnableUsageReport {
		g.Add(func() error {
			return ep.reporter.Start(srvContext)
		}, func(e error) {
			srvCancel()
		})
	}

	go func() {
		for range notifier {
			ep.TriggerReload()
		}
	}()

	return g.Run()
}

'''
'''--- cmd/agent/flow.go ---
package main

import (
	"context"
	"errors"
	"flag"
	"fmt"
	"net"
	"net/http"
	"os"
	"os/signal"
	"sync"

	"go.uber.org/atomic"

	"github.com/fatih/color"
	"github.com/go-kit/log/level"
	"github.com/gorilla/mux"
	"github.com/grafana/agent/pkg/flow"
	"github.com/grafana/agent/pkg/flow/logging"
	"github.com/grafana/agent/pkg/river/diag"
	"github.com/prometheus/client_golang/prometheus"
	"github.com/prometheus/client_golang/prometheus/promhttp"

	// Install Components
	_ "github.com/grafana/agent/component/all"
)

func isFlowEnabled() bool {
	key, found := os.LookupEnv("EXPERIMENTAL_ENABLE_FLOW")
	if !found {
		return false
	}
	return key == "true"
}

func runFlow() error {
	var wg sync.WaitGroup
	defer wg.Wait()

	ctx, cancel := interruptContext()
	defer cancel()

	var (
		httpListenAddr = "127.0.0.1:12345"
		configFile     string
		storagePath    = "data-agent/"
		ready          = atomic.NewBool(true)
	)

	fs := flag.NewFlagSet(os.Args[0], flag.ExitOnError)
	fs.StringVar(&httpListenAddr, "server.http-listen-addr", httpListenAddr, "address to listen for http traffic on")
	fs.StringVar(&configFile, "config.file", configFile, "path to config file to load")
	fs.StringVar(&storagePath, "storage.path", storagePath, "Base directory where Flow components can store data")

	if err := fs.Parse(os.Args[1:]); err != nil {
		return fmt.Errorf("error parsing flags: %w", err)
	}

	// Validate flags
	if configFile == "" {
		return fmt.Errorf("the -config.file flag is required")
	}

	l, err := logging.New(os.Stderr, logging.DefaultOptions)
	if err != nil {
		return fmt.Errorf("building logger: %w", err)
	}

	f := flow.New(flow.Options{
		Logger:   l,
		DataPath: storagePath,
		Reg:      prometheus.DefaultRegisterer,
	})

	reload := func() error {
		flowCfg, err := loadFlowFile(configFile)
		if err != nil {
			return fmt.Errorf("reading config file %q: %w", configFile, err)
		}
		if err := f.LoadFile(flowCfg); err != nil {
			return fmt.Errorf("error during the initial gragent load: %w", err)
		}
		return nil
	}

	if err := reload(); err != nil {
		var diags diag.Diagnostics
		if errors.As(err, &diags) {
			bb, _ := os.ReadFile(configFile)

			p := diag.NewPrinter(diag.PrinterConfig{
				Color:              !color.NoColor,
				ContextLinesBefore: 1,
				ContextLinesAfter:  1,
			})
			_ = p.Fprint(os.Stderr, map[string][]byte{configFile: bb}, diags)

			// Print newline after the diagnostics.
			fmt.Println()

			return fmt.Errorf("could not perform the initial load successfully")
		}

		// Exit if the initial load files
		return err
	}

	// HTTP server
	{
		lis, err := net.Listen("tcp", httpListenAddr)
		if err != nil {
			return fmt.Errorf("failed to listen on %s: %w", httpListenAddr, err)
		}

		r := mux.NewRouter()
		r.HandleFunc("/-/ready", func(w http.ResponseWriter, r *http.Request) {
			if ready.Load() {
				w.WriteHeader(http.StatusOK)
				fmt.Fprintf(w, "Agent is Ready.\n")
			} else {
				w.WriteHeader(http.StatusServiceUnavailable)
				fmt.Fprint(w, "Config failed to load.\n")
			}
		})
		r.Handle("/metrics", promhttp.Handler())
		r.Handle("/debug/config", f.ConfigHandler())
		r.Handle("/debug/graph", f.GraphHandler())
		r.Handle("/debug/scope", f.ScopeHandler())
		r.PathPrefix("/debug/pprof").Handler(http.DefaultServeMux)

		r.HandleFunc("/-/reload", func(w http.ResponseWriter, _ *http.Request) {
			err := reload()
			ready.Store(err == nil)
			if err != nil {
				http.Error(w, err.Error(), http.StatusBadRequest)
				return
			}
			fmt.Fprintln(w, "config reloaded")
		})

		srv := &http.Server{Handler: r}

		wg.Add(1)
		go func() {
			defer wg.Done()
			defer cancel()

			level.Info(l).Log("msg", "now listening for http traffic", "addr", httpListenAddr)
			if err := srv.Serve(lis); err != nil {
				level.Info(l).Log("msg", "http server closed", "err", err)
			}
		}()

		defer func() { _ = srv.Shutdown(ctx) }()
	}

	<-ctx.Done()
	return f.Close()
}

func loadFlowFile(filename string) (*flow.File, error) {
	bb, err := os.ReadFile(filename)
	if err != nil {
		return nil, err
	}

	return flow.ReadFile(filename, bb)
}

func interruptContext() (context.Context, context.CancelFunc) {
	ctx, cancel := context.WithCancel(context.Background())

	go func() {
		defer cancel()
		sig := make(chan os.Signal, 1)
		signal.Notify(sig, os.Interrupt)
		select {
		case <-sig:
		case <-ctx.Done():
		}
		signal.Stop(sig)

		fmt.Fprintln(os.Stderr, "interrupt received")
	}()

	return ctx, cancel
}

'''
'''--- cmd/agent/main.go ---
package main

import (
	"flag"
	"fmt"
	"log"
	"os"

	util_log "github.com/cortexproject/cortex/pkg/util/log"
	"github.com/go-kit/log/level"
	"github.com/grafana/agent/pkg/config"
	"github.com/grafana/agent/pkg/server"

	// Adds version information
	_ "github.com/grafana/agent/pkg/build"

	"github.com/prometheus/client_golang/prometheus"
	"github.com/prometheus/common/version"

	// Register Prometheus SD components
	_ "github.com/grafana/loki/clients/pkg/promtail/discovery/consulagent"
	_ "github.com/prometheus/prometheus/discovery/install"

	// Register integrations
	_ "github.com/grafana/agent/pkg/integrations/install"
)

func init() {
	prometheus.MustRegister(version.NewCollector("agent"))
}

func main() {
	// If Windows is trying to run as a service, go through that
	// path instead.
	if IsWindowsService() {
		err := RunService()
		if err != nil {
			log.Fatalln(err)
		}
		return
	}

	// If flow is enabled go into that working mode
	// TODO allow flow to run as a windows service
	if isFlowEnabled() {
		if err := runFlow(); err != nil {
			fmt.Fprintf(os.Stderr, "error: %s\n", err)
			os.Exit(1)
		}
		return
	}

	reloader := func() (*config.Config, error) {
		fs := flag.NewFlagSet(os.Args[0], flag.ExitOnError)
		return config.Load(fs, os.Args[1:])
	}
	cfg, err := reloader()
	if err != nil {
		log.Fatalln(err)
	}

	// After this point we can start using go-kit logging.
	logger := server.NewLogger(&cfg.Server)
	util_log.Logger = logger

	ep, err := NewEntrypoint(logger, cfg, reloader)
	if err != nil {
		level.Error(logger).Log("msg", "error creating the agent server entrypoint", "err", err)
		os.Exit(1)
	}

	if err = ep.Start(); err != nil {
		level.Error(logger).Log("msg", "error running agent", "err", err)
		// Don't os.Exit here; we want to do cleanup by stopping promMetrics
	}

	ep.Stop()
	level.Info(logger).Log("msg", "agent exiting")
}

'''
'''--- cmd/agent/service.go ---
//go:build !windows
// +build !windows

package main

// IsWindowsService returns whether the current process is running as a Windows
// Service. On non-Windows platforms, this always returns false.
func IsWindowsService() bool {
	return false
}

// RunService runs the current process as a Windows servce. On non-Windows platforms,
// this is always a no-op.
func RunService() error {
	return nil
}

'''
'''--- cmd/agent/service_windows.go ---
//go:build windows
// +build windows

package main

import (
	"flag"
	"log"
	"os"

	util_log "github.com/cortexproject/cortex/pkg/util/log"
	"github.com/go-kit/log/level"
	"github.com/grafana/agent/pkg/config"
	"github.com/grafana/agent/pkg/server"

	"golang.org/x/sys/windows/svc"
)

const cmdsAccepted = svc.AcceptStop | svc.AcceptShutdown

// AgentService runs the Grafana Agent as a service.
type AgentService struct{}

// Execute starts the AgentService.
func (m *AgentService) Execute(args []string, serviceRequests <-chan svc.ChangeRequest, changes chan<- svc.Status) (ssec bool, errno uint32) {
	changes <- svc.Status{State: svc.StartPending}

	// Executable name and any command line parameters will be placed into os.args, this comes from
	// registry key `Computer\HKEY_LOCAL_MACHINE\SYSTEM\ControlSet001\Services\<servicename>\ImagePath`
	// oddly enough args is blank

	reloader := func() (*config.Config, error) {
		fs := flag.NewFlagSet(os.Args[0], flag.ExitOnError)
		return config.Load(fs, os.Args[1:])
	}
	cfg, err := reloader()
	if err != nil {
		log.Fatalln(err)
	}

	// Pause is not accepted, we immediately set the service as running and trigger the entrypoint load in the background
	// this is because the WAL is reloaded and the timeout for a windows service starting is 30 seconds. In this case
	// the service is running but Agent may still be starting up reading the WAL and doing other operations.
	changes <- svc.Status{State: svc.Running, Accepts: cmdsAccepted}

	// After this point we can start using go-kit logging.
	logger := server.NewWindowsEventLogger(&cfg.Server)
	util_log.Logger = logger

	entrypointExit := make(chan error)

	// Kick off the server in the background so that we can respond to status queries
	var ep *Entrypoint
	go func() {
		ep, err = NewEntrypoint(logger, cfg, reloader)
		if err != nil {
			level.Error(logger).Log("msg", "error creating the agent server entrypoint", "err", err)
			os.Exit(1)
		}
		entrypointExit <- ep.Start()
	}()

loop:
	for {
		select {
		case c := <-serviceRequests:
			switch c.Cmd {
			case svc.Interrogate:
				changes <- c.CurrentStatus
			case svc.Stop, svc.Shutdown:
				break loop
			case svc.Pause:
			case svc.Continue:
			default:
				break loop
			}
		case err := <-entrypointExit:
			level.Error(logger).Log("msg", "error while running agent server entrypoint", "err", err)
			break loop
		}
	}
	// There is a chance the entrypoint may not be setup yet, in that case we don't want to stop.
	// Since it is in another go func it may start after this has returned, in either case the program
	// will exit.
	if ep != nil {
		ep.Stop()
	}
	changes <- svc.Status{State: svc.StopPending}
	return
}

// IsWindowsService returns whether the current process is running as a Windows
// Service. On non-Windows platforms, this always returns false.
func IsWindowsService() bool {
	isService, err := svc.IsWindowsService()
	if err != nil {
		return false
	}
	return isService
}

// RunService runs the current process as a Windows servce. On non-Windows platforms,
// this is always a no-op.
func RunService() error {
	return svc.Run(server.ServiceName, &AgentService{})
}

'''
'''--- cmd/agent/test-local-file.txt ---
Change me!
'''
'''--- cmd/agentctl/main.go ---
// Command agentctl provides utilities for interacting with Grafana Agent
package main

import (
	"context"
	"fmt"
	"net/http"
	"os"
	"path/filepath"
	goruntime "runtime"
	"sort"
	"strings"
	"time"

	"gopkg.in/yaml.v2"

	"github.com/grafana/agent/pkg/client/grafanacloud"
	"github.com/grafana/agent/pkg/config"
	"github.com/olekukonko/tablewriter"
	"github.com/prometheus/common/version"

	"github.com/go-kit/log"
	"github.com/go-kit/log/level"
	"github.com/grafana/agent/pkg/agentctl"
	"github.com/grafana/agent/pkg/client"
	"github.com/spf13/cobra"

	// Register Prometheus SD components
	_ "github.com/prometheus/prometheus/discovery/install"

	// Register integrations
	_ "github.com/grafana/agent/pkg/integrations/install"

	// Needed for operator-detach
	"k8s.io/apimachinery/pkg/fields"
	"k8s.io/apimachinery/pkg/labels"
	"k8s.io/apimachinery/pkg/runtime"
	_ "k8s.io/client-go/plugin/pkg/client/auth"

	apps_v1 "k8s.io/api/apps/v1"
	core_v1 "k8s.io/api/core/v1"
	"k8s.io/apimachinery/pkg/api/meta"
	meta_v1 "k8s.io/apimachinery/pkg/apis/meta/v1"
	kclient "sigs.k8s.io/controller-runtime/pkg/client"
	"sigs.k8s.io/controller-runtime/pkg/client/apiutil"
	kconfig "sigs.k8s.io/controller-runtime/pkg/client/config"

	// Adds version information
	_ "github.com/grafana/agent/pkg/build"
)

func main() {
	var cmd = &cobra.Command{
		Use:     "agentctl",
		Short:   "Tools for interacting with the Grafana Agent",
		Version: version.Print("agentctl"),
	}
	cmd.SetVersionTemplate("{{ .Version }}\n")

	cmd.AddCommand(
		configSyncCmd(),
		configCheckCmd(),
		walStatsCmd(),
		targetStatsCmd(),
		samplesCmd(),
		operatorDetachCmd(),
		cloudConfigCmd(),
		templateDryRunCmd(),
	)

	_ = cmd.Execute()
}

func configSyncCmd() *cobra.Command {
	var (
		agentAddr string
		dryRun    bool
	)

	cmd := &cobra.Command{
		Use:   "config-sync [directory]",
		Short: "Sync config files from a directory to an Agent's config management API",
		Long: `config-sync loads all files ending with .yml or .yaml from the specified
directory and uploads them the the config management API. The name of the config
uploaded will be the base name of the file (e.g., the name of the file without
its extension).

The directory is used as the source-of-truth for the entire set of configs that
should be present in the API. config-sync will delete all existing configs from the API
that do not match any of the names of the configs that were uploaded from the
source-of-truth directory.`,
		Args: cobra.ExactArgs(1),

		Run: func(_ *cobra.Command, args []string) {
			logger := log.NewLogfmtLogger(log.NewSyncWriter(os.Stdout))

			if agentAddr == "" {
				level.Error(logger).Log("msg", "-addr must not be an empty string")
				os.Exit(1)
			}

			directory := args[0]
			cli := client.New(agentAddr)

			err := agentctl.ConfigSync(logger, cli.PrometheusClient, directory, dryRun)
			if err != nil {
				level.Error(logger).Log("msg", "failed to sync config", "err", err)
				os.Exit(1)
			}
		},
	}

	cmd.Flags().StringVarP(&agentAddr, "addr", "a", "http://localhost:12345", "address of the agent to connect to")
	cmd.Flags().BoolVarP(&dryRun, "dry-run", "d", false, "use the dry run option to validate config files without attempting to upload")
	return cmd
}

func configCheckCmd() *cobra.Command {
	var expandEnv bool

	cmd := &cobra.Command{
		Use:   "config-check [config file]",
		Short: "Perform basic validation of the given Agent configuration file",
		Long: `config-check performs basic syntactic validation of the given Agent configuration
file. The file is checked to ensure the types match the expected configuration types. Optionally,
${var} style substitutions can be expanded based on the values of the environmental variables.

If the configuration file is valid the exit code will be 0. If the configuration file is invalid
the exit code will be 1.`,
		Args: cobra.ExactArgs(1),
		Run: func(_ *cobra.Command, args []string) {
			file := args[0]

			cfg := config.Config{}
			err := config.LoadFile(file, expandEnv, &cfg)
			if err != nil {
				fmt.Fprintf(os.Stderr, "failed to validate config: %s\n", err)
				os.Exit(1)
			} else {
				fmt.Fprintln(os.Stdout, "config valid")
			}
		},
	}

	cmd.Flags().BoolVarP(&expandEnv, "expand-env", "e", false, "expands ${var} in config according to the values of the environment variables")
	return cmd
}

func samplesCmd() *cobra.Command {
	var selector string

	cmd := &cobra.Command{
		Use:   "sample-stats [WAL directory]",
		Short: "Discover sample statistics for series matching a label selector within the WAL",
		Long: `sample-stats reads a WAL directory and collects information on the series and
samples within it. A label selector can be used to filter the series that should be targeted.

Examples:

Show sample stats for all series in the WAL:

$ agentctl sample-stats /tmp/wal

Show sample stats for the 'up' series:

$ agentctl sample-stats -s up /tmp/wal

Show sample stats for all series within 'job=a':

$ agentctl sample-stats -s '{job="a"}' /tmp/wal
`,
		Args: cobra.ExactArgs(1),
		Run: func(_ *cobra.Command, args []string) {
			directory := args[0]
			if _, err := os.Stat(directory); os.IsNotExist(err) {
				fmt.Printf("%s does not exist\n", directory)
				os.Exit(1)
			} else if err != nil {
				fmt.Printf("error getting wal: %v\n", err)
				os.Exit(1)
			}

			// Check if ./wal is a subdirectory, use that instead.
			if _, err := os.Stat(filepath.Join(directory, "wal")); err == nil {
				directory = filepath.Join(directory, "wal")
			}

			stats, err := agentctl.FindSamples(directory, selector)
			if err != nil {
				fmt.Printf("failed to get sample stats: %v\n", err)
				os.Exit(1)
			}

			for _, series := range stats {
				fmt.Print(series.Labels.String(), "\n")
				fmt.Printf("  Oldest Sample:      %s\n", series.From)
				fmt.Printf("  Newest Sample:      %s\n", series.To)
				fmt.Printf("  Total Samples:      %d\n", series.Samples)
			}
		},
	}

	cmd.Flags().StringVarP(&selector, "selector", "s", "{}", "label selector to search for")
	return cmd
}

func targetStatsCmd() *cobra.Command {
	var (
		jobLabel      string
		instanceLabel string
	)

	cmd := &cobra.Command{
		Use:   "target-stats [WAL directory]",
		Short: "Discover statistics on a specific target within the WAL.",
		Long: `target-stats computes statistics on a specific target within the WAL at
greater detail than the general wal-stats. The statistics computed is the
cardinality of all series within that target.

The cardinality for a series is defined as the total number of unique
combinations of label names and values that a given metric has. The result of
this operation can be used to define metric_relabel_rules and drop
high-cardinality series that you do not want to send.`,
		Args: cobra.ExactArgs(1),

		Run: func(_ *cobra.Command, args []string) {
			directory := args[0]
			if _, err := os.Stat(directory); os.IsNotExist(err) {
				fmt.Printf("%s does not exist\n", directory)
				os.Exit(1)
			} else if err != nil {
				fmt.Printf("error getting wal: %v\n", err)
				os.Exit(1)
			}

			// Check if ./wal is a subdirectory, use that instead.
			if _, err := os.Stat(filepath.Join(directory, "wal")); err == nil {
				directory = filepath.Join(directory, "wal")
			}

			cardinality, err := agentctl.FindCardinality(directory, jobLabel, instanceLabel)
			if err != nil {
				fmt.Printf("failed to get cardinality: %v\n", err)
				os.Exit(1)
			}

			sort.Slice(cardinality, func(i, j int) bool {
				return cardinality[i].Instances > cardinality[j].Instances
			})

			fmt.Printf("Metric cardinality:\n\n")

			for _, metric := range cardinality {
				fmt.Printf("%s: %d\n", metric.Metric, metric.Instances)
			}
		},
	}

	cmd.Flags().StringVarP(&jobLabel, "job", "j", "", "job label to search for")
	cmd.Flags().StringVarP(&instanceLabel, "instance", "i", "", "instance label to search for")
	must(cmd.MarkFlagRequired("job"))
	must(cmd.MarkFlagRequired("instance"))
	return cmd
}

func walStatsCmd() *cobra.Command {
	return &cobra.Command{
		Use:   "wal-stats [WAL directory]",
		Short: "Collect stats on the WAL",
		Long: `wal-stats reads a WAL directory and collects information on the series and
samples within it.

The "Hash Collisions" value refers to the number of ref IDs a label's hash was
assigned to. A non-zero amount of collisions has no negative effect on the data
sent to the Remote Write endpoint, but may have an impact on memory usage. Labels
may collide with multiple ref IDs normally if a series flaps (i.e., gets marked for
deletion but then comes back at some point).`,
		Args: cobra.ExactArgs(1),

		Run: func(_ *cobra.Command, args []string) {
			directory := args[0]
			if _, err := os.Stat(directory); os.IsNotExist(err) {
				fmt.Printf("%s does not exist\n", directory)
				os.Exit(1)
			} else if err != nil {
				fmt.Printf("error getting wal: %v\n", err)
				os.Exit(1)
			}

			// Check if ./wal is a subdirectory, use that instead.
			if _, err := os.Stat(filepath.Join(directory, "wal")); err == nil {
				directory = filepath.Join(directory, "wal")
			}

			stats, err := agentctl.CalculateStats(directory)
			if err != nil {
				fmt.Printf("failed to get WAL stats: %v\n", err)
				os.Exit(1)
			}

			fmt.Printf("Oldest Sample:      %s\n", stats.From)
			fmt.Printf("Newest Sample:      %s\n", stats.To)
			fmt.Printf("Total Series:       %d\n", stats.Series())
			fmt.Printf("Total Samples:      %d\n", stats.Samples())
			fmt.Printf("Hash Collisions:    %d\n", stats.HashCollisions)
			fmt.Printf("Invalid Refs:       %d\n", stats.InvalidRefs)
			fmt.Printf("Checkpoint Segment: %d\n", stats.CheckpointNumber)
			fmt.Printf("First Segment:      %d\n", stats.FirstSegment)
			fmt.Printf("Latest Segment:     %d\n", stats.LastSegment)

			fmt.Printf("\nPer-target stats:\n")

			table := tablewriter.NewWriter(os.Stdout)
			defer table.Render()

			table.SetHeader([]string{"Job", "Instance", "Series", "Samples"})

			sort.Sort(agentctl.BySeriesCount(stats.Targets))

			for _, t := range stats.Targets {
				seriesStr := fmt.Sprintf("%d", t.Series)
				samplesStr := fmt.Sprintf("%d", t.Samples)
				table.Append([]string{t.Job, t.Instance, seriesStr, samplesStr})
			}
		},
	}
}

func operatorDetachCmd() *cobra.Command {
	cmd := &cobra.Command{
		Use:   "operator-detach",
		Short: "Detaches any Operator-Managed resource so CRDs can temporarily be deleted",
		Long:  `operator-detach will find Grafana Agent Operator-Managed resources across the cluster and edit them to remove the OwnerReferences tying them to a GrafanaAgent CRD. This allows the CRDs to be modified without losing the deployment of Grafana Agents.`,
		Args:  cobra.ExactArgs(0),

		RunE: func(_ *cobra.Command, args []string) error {
			logger := log.NewLogfmtLogger(log.NewSyncWriter(os.Stdout))
			scheme := runtime.NewScheme()
			hadErrors := false

			for _, add := range []func(*runtime.Scheme) error{
				core_v1.AddToScheme,
				apps_v1.AddToScheme,
			} {
				if err := add(scheme); err != nil {
					return fmt.Errorf("unable to register scheme: %w", err)
				}
			}

			cli, err := kclient.New(kconfig.GetConfigOrDie(), kclient.Options{
				Scheme: scheme,
				Mapper: nil,
			})
			if err != nil {
				return fmt.Errorf("unable to generate Kubernetes client: %w", err)
			}

			// Resources to list
			lists := []kclient.ObjectList{
				&apps_v1.StatefulSetList{},
				&apps_v1.DaemonSetList{},
				&core_v1.SecretList{},
				&core_v1.ServiceList{},
			}
			for _, l := range lists {
				gvk, err := apiutil.GVKForObject(l, scheme)
				if err != nil {
					return fmt.Errorf("failed to get GroupVersionKind: %w", err)
				}
				level.Info(logger).Log("msg", "getting objects for resource", "resource", gvk.Kind)

				err = cli.List(context.Background(), l, &kclient.ListOptions{
					LabelSelector: labels.Everything(),
					FieldSelector: fields.Everything(),
					Namespace:     "",
				})
				if err != nil {
					level.Error(logger).Log("msg", "failed to list resource", "resource", gvk.Kind, "err", err)
					hadErrors = true
					continue
				}

				elements, err := meta.ExtractList(l)
				if err != nil {
					level.Error(logger).Log("msg", "failed to get elements for resource", "resource", gvk.Kind, "err", err)
					hadErrors = true
					continue
				}
				for _, e := range elements {
					obj := e.(kclient.Object)

					filtered, changed := filterAgentOwners(obj.GetOwnerReferences())
					if !changed {
						continue
					}

					level.Info(logger).Log("msg", "detatching ownerreferences for object", "resource", gvk.Kind, "namespace", obj.GetNamespace(), "name", obj.GetName())
					obj.SetOwnerReferences(filtered)

					if err := cli.Update(context.Background(), obj); err != nil {
						level.Error(logger).Log("msg", "failed to update object", "resource", gvk.Kind, "namespace", obj.GetNamespace(), "name", obj.GetName(), "err", err)
						hadErrors = true
						continue
					}
				}
			}

			if hadErrors {
				return fmt.Errorf("encountered errors during execution")
			}
			return nil
		},
	}

	return cmd
}

func filterAgentOwners(refs []meta_v1.OwnerReference) (filtered []meta_v1.OwnerReference, changed bool) {
	filtered = make([]meta_v1.OwnerReference, 0, len(refs))

	for _, ref := range refs {
		if ref.Kind == "GrafanaAgent" && strings.HasPrefix(ref.APIVersion, "monitoring.grafana.com/") {
			changed = true
			continue
		}
		filtered = append(filtered, ref)
	}
	return
}

func cloudConfigCmd() *cobra.Command {
	var (
		stackID   string
		apiURL    string
		apiKey    string
		platforms string
	)

	cmd := &cobra.Command{
		Use:   "cloud-config",
		Short: "Retrieves the cloud config for the Grafana Agent",
		Long: `cloud-config connects to Grafana Cloud and retrieves the generated
config that may be used with this agent.`,
		Args: cobra.ExactArgs(0),

		// Hidden, this is only expected to be used by scripts.
		Hidden: true,

		RunE: func(_ *cobra.Command, args []string) error {
			if stackID == "" {
				return fmt.Errorf("--stack must be provided")
			}
			if apiKey == "" {
				return fmt.Errorf("--api-key must be provided")
			}

			// setting timeout 2x as the default HTTP transport timeout (30s)
			httpClient := &http.Client{
				Timeout: time.Minute,
			}
			cli := grafanacloud.NewClient(httpClient, apiKey, apiURL)

			cfg, err := cli.AgentConfig(context.Background(), stackID, platforms)
			if err != nil {
				fmt.Fprintf(os.Stderr, "could not retrieve agent cloud config: %s\n", err)
				os.Exit(1)
			}

			fmt.Println(cfg)
			return nil
		},
	}

	cmd.Flags().StringVarP(&stackID, "stack", "u", "", "stack ID to get a config for")
	cmd.Flags().StringVarP(&apiKey, "api-key", "p", "", "API key to authenticate against Grafana Cloud's API with")
	cmd.Flags().StringVarP(&apiURL, "api-url", "e", "", "Grafana Cloud's API url")
	cmd.Flags().StringVar(&platforms, "platforms", goruntime.GOOS, "comma-separated list of Platforms/OSes")
	must(cmd.MarkFlagRequired("stack"))
	must(cmd.MarkFlagRequired("api-key"))

	return cmd
}

func templateDryRunCmd() *cobra.Command {
	cmd := &cobra.Command{
		Use:   "template-parse [directory]",
		Short: "dry run dynamic configuration",
		Long:  `This will load the dynamic configuration, load configs, run templates and then output the full config as yaml`,
		Args:  cobra.ExactArgs(1),

		RunE: func(_ *cobra.Command, args []string) error {
			cmf, err := config.NewDynamicLoader()
			if err != nil {
				return err
			}
			c := &config.Config{}
			err = cmf.LoadConfigByPath(args[0])
			if err != nil {
				return err
			}
			err = cmf.ProcessConfigs(c)
			if err != nil {
				return fmt.Errorf("error processing config templates %s", err)
			}

			outBytes, err := yaml.Marshal(c)
			if err != nil {
				return err
			}
			fmt.Println(string(outBytes))
			return nil
		},
	}

	return cmd
}

func must(err error) {
	if err != nil {
		panic(err)
	}
}

'''
'''--- component/all/all.go ---
// Package all imports all known component packages.
package all

import (
	_ "github.com/grafana/agent/component/discovery/kubernetes" // Import discovery.k8s
	_ "github.com/grafana/agent/component/local/file"           // Import local.file
	_ "github.com/grafana/agent/component/metrics/mutate"       // Import metrics.mutate
	_ "github.com/grafana/agent/component/metrics/remotewrite"  // Import metrics.remotewrite
	_ "github.com/grafana/agent/component/metrics/scrape"       // Import metrics.scrape
	_ "github.com/grafana/agent/component/remote/s3"            // Import s3.file
	_ "github.com/grafana/agent/component/targets/mutate"       // Import targets.mutate
)

'''
'''--- component/common/appendable/appendable.go ---
package appendable

import (
	"context"
	"sync"

	"github.com/grafana/agent/component/metrics"
	"github.com/prometheus/prometheus/model/exemplar"
	"github.com/prometheus/prometheus/model/labels"
	"github.com/prometheus/prometheus/model/value"
	"github.com/prometheus/prometheus/storage"
)

// FlowMetric is a wrapper around a single sample without the timestamp.
type FlowMetric struct {
	Labels labels.Labels
	Value  float64
}

// FlowAppendable is a flow-specific implementation of an Appender.
type FlowAppendable struct {
	mut       sync.RWMutex
	receivers []*metrics.Receiver
}

// NewFlowAppendable initializes the appendable.
func NewFlowAppendable(receivers ...*metrics.Receiver) *FlowAppendable {
	return &FlowAppendable{
		receivers: receivers,
	}
}

type flowAppender struct {
	buffer    map[int64][]*metrics.FlowMetric // Though mostly a map of 1 item, this allows it to work if more than one TS gets added
	receivers []*metrics.Receiver
}

// Appender implements the Prometheus Appendable interface.
func (app *FlowAppendable) Appender(_ context.Context) storage.Appender {
	app.mut.RLock()
	defer app.mut.RUnlock()

	return &flowAppender{
		buffer:    make(map[int64][]*metrics.FlowMetric),
		receivers: app.receivers,
	}
}

// SetReceivers defines the list of receivers for this appendable.
func (app *FlowAppendable) SetReceivers(receivers []*metrics.Receiver) {
	app.mut.Lock()
	app.receivers = receivers
	app.mut.Unlock()
}

// ListReceivers is a test method for exposing the Appender's receivers.
func (app *FlowAppendable) ListReceivers() []*metrics.Receiver {
	app.mut.RLock()
	defer app.mut.RUnlock()
	return app.receivers
}

func (app *flowAppender) Append(ref storage.SeriesRef, l labels.Labels, t int64, v float64) (storage.SeriesRef, error) {
	if len(app.receivers) == 0 {
		return 0, nil
	}
	_, found := app.buffer[t]
	if !found {
		set := make([]*metrics.FlowMetric, 0)
		app.buffer[t] = set
	}
	// If ref is 0 then lets grab a global id
	if ref == 0 {
		ref = storage.SeriesRef(metrics.GlobalRefMapping.GetOrAddGlobalRefID(l))
	}
	// If it is stale then we can remove it
	if value.IsStaleNaN(v) {
		metrics.GlobalRefMapping.AddStaleMarker(uint64(ref), l)
	} else {
		metrics.GlobalRefMapping.RemoveStaleMarker(uint64(ref))
	}
	app.buffer[t] = append(app.buffer[t], metrics.NewFlowMetric(uint64(ref), l, v))
	return ref, nil
}

func (app *flowAppender) AppendExemplar(ref storage.SeriesRef, l labels.Labels, e exemplar.Exemplar) (storage.SeriesRef, error) {
	return 0, nil
}

func (app *flowAppender) Commit() error {
	for _, r := range app.receivers {
		for ts, metrics := range app.buffer {
			if r == nil || r.Receive == nil {
				continue
			}
			r.Receive(ts, metrics)
		}
	}
	app.buffer = make(map[int64][]*metrics.FlowMetric)
	return nil
}

func (app *flowAppender) Rollback() error {
	app.buffer = make(map[int64][]*metrics.FlowMetric)
	return nil
}

'''
'''--- component/common/config/types.go ---
// Package config contains types from github.com/prometheus/common/config,
// but modifiys them to be serializable with River.
package config

import (
	"fmt"
	"net/url"

	"github.com/grafana/agent/pkg/river"

	"github.com/grafana/agent/pkg/flow/rivertypes"
	"github.com/prometheus/common/config"
)

// HTTPClientConfig mirrors config.HTTPClientConfig
type HTTPClientConfig struct {
	BasicAuth       *BasicAuth        `river:"basic_auth,block,optional"`
	Authorization   *Authorization    `river:"authorization,block,optional"`
	OAuth2          *OAuth2Config     `river:"oauth2,block,optional"`
	BearerToken     rivertypes.Secret `river:"bearer_token,attr,optional"`
	BearerTokenFile string            `river:"bearer_token_file,attr,optional"`
	ProxyURL        URL               `river:"proxy_url,attr,optional"`
	TLSConfig       TLSConfig         `river:"tls_config,block,optional"`
	FollowRedirects bool              `river:"follow_redirects,attr,optional"`
	EnableHTTP2     bool              `river:"enable_http2,attr,optional"`
}

// UnmarshalRiver implements the umarshaller
func (h *HTTPClientConfig) UnmarshalRiver(f func(v interface{}) error) error {
	*h = HTTPClientConfig{
		FollowRedirects: true,
		EnableHTTP2:     true,
	}
	type config HTTPClientConfig
	return f((*config)(h))
}

// Convert converts our type to the native prometheus type
func (h *HTTPClientConfig) Convert() *config.HTTPClientConfig {
	return &config.HTTPClientConfig{
		BasicAuth:       h.BasicAuth.Convert(),
		Authorization:   h.Authorization.Convert(),
		OAuth2:          h.OAuth2.Convert(),
		BearerToken:     config.Secret(h.BearerToken),
		BearerTokenFile: h.BearerTokenFile,
		ProxyURL:        h.ProxyURL.Convert(),
		TLSConfig:       *h.TLSConfig.Convert(),
		FollowRedirects: h.FollowRedirects,
		EnableHTTP2:     h.EnableHTTP2,
	}
}

// DefaultHTTPClientConfig for initializing objects
var DefaultHTTPClientConfig = HTTPClientConfig{
	FollowRedirects: true,
	EnableHTTP2:     true,
}

var _ river.Unmarshaler = (*HTTPClientConfig)(nil)

// BasicAuth configures Basic HTTP authentication credentials.
type BasicAuth struct {
	Username     string            `river:"username,attr,optional"`
	Password     rivertypes.Secret `river:"password,attr,optional"`
	PasswordFile string            `river:"password_file,attr,optional"`
}

// Convert converts our type to the native prometheus type
func (b *BasicAuth) Convert() *config.BasicAuth {
	if b == nil {
		return nil
	}
	return &config.BasicAuth{
		Username:     b.Username,
		Password:     config.Secret(b.Password),
		PasswordFile: b.PasswordFile,
	}
}

// URL mirrors config.URL
type URL struct {
	*url.URL
}

// MarshalText implements encoding.TextMarshaler
func (u URL) MarshalText() (text []byte, err error) {
	u2 := &config.URL{
		URL: u.URL,
	}
	if u.URL != nil {
		return []byte(u2.Redacted()), nil
	}
	return nil, nil
}

// UnmarshalText implements encoding.TextUnmarshaler
func (u *URL) UnmarshalText(text []byte) error {
	s := string(text)
	urlp, err := url.Parse(s)
	if err != nil {
		return err
	}
	u.URL = urlp
	return nil
}

// Convert converts our type to the native prometheus type
func (u URL) Convert() config.URL {
	return config.URL{URL: u.URL}
}

// Authorization sets up HTTP authorization credentials.
type Authorization struct {
	Type            string            `river:"type,attr,optional"`
	Credentials     rivertypes.Secret `river:"credentials,attr,optional"`
	CredentialsFile string            `river:"credentials_file,attr,optional"`
}

// Convert converts our type to the native prometheus type
func (a *Authorization) Convert() *config.Authorization {
	if a == nil {
		return nil
	}
	return &config.Authorization{
		Type:            a.Type,
		Credentials:     config.Secret(a.Credentials),
		CredentialsFile: a.CredentialsFile,
	}
}

// TLSVersion mirrors config.TLSVersion
type TLSVersion uint16

// MarshalText implements encoding.TextMarshaler
func (tv TLSVersion) MarshalText() (text []byte, err error) {
	for s, v := range config.TLSVersions {
		if config.TLSVersion(tv) == v {
			return []byte(s), nil
		}
	}
	return nil, fmt.Errorf("unknown TLS version: %d", tv)
}

// UnmarshalText implements encoding.TextUnmarshaler
func (tv *TLSVersion) UnmarshalText(text []byte) error {
	if v, ok := config.TLSVersions[string(text)]; ok {
		*tv = TLSVersion(v)
		return nil
	}
	return fmt.Errorf("unknown TLS version: %s", string(text))
}

// TLSConfig sets up options for TLS connections.
type TLSConfig struct {
	CAFile             string     `river:"ca_file,attr,optional"`
	CertFile           string     `river:"cert_file,attr,optional"`
	KeyFile            string     `river:"key_file,attr,optional"`
	ServerName         string     `river:"server_name,attr,optional"`
	InsecureSkipVerify bool       `river:"insecure_skip_verify,attr,optional"`
	MinVersion         TLSVersion `river:"min_version,attr,optional"`
}

// Convert converts our type to the native prometheus type
func (t *TLSConfig) Convert() *config.TLSConfig {
	if t == nil {
		return nil
	}
	return &config.TLSConfig{
		CAFile:             t.CAFile,
		CertFile:           t.CertFile,
		KeyFile:            t.KeyFile,
		ServerName:         t.ServerName,
		InsecureSkipVerify: t.InsecureSkipVerify,
		MinVersion:         config.TLSVersion(t.MinVersion),
	}
}

// OAuth2Config sets up the OAuth2 client.
type OAuth2Config struct {
	ClientID         string            `river:"client_id,attr,optional"`
	ClientSecret     rivertypes.Secret `river:"client_secret,attr,optional"`
	ClientSecretFile string            `river:"client_secret_file,attr,optional"`
	Scopes           []string          `river:"scopes,attr,optional"`
	TokenURL         string            `river:"token_url,attr,optional"`
	EndpointParams   map[string]string `river:"endpoint_params,attr,optional"`
	ProxyURL         URL               `river:"proxy_url,attr,optional"`
	TLSConfig        *TLSConfig        `river:"tls_config,attr,optional"`
}

// Convert converts our type to the native prometheus type
func (o *OAuth2Config) Convert() *config.OAuth2 {
	if o == nil {
		return nil
	}
	return &config.OAuth2{
		ClientID:         o.ClientID,
		ClientSecret:     config.Secret(o.ClientSecret),
		ClientSecretFile: o.ClientSecretFile,
		Scopes:           o.Scopes,
		TokenURL:         o.TokenURL,
		EndpointParams:   o.EndpointParams,
		ProxyURL:         o.ProxyURL.Convert(),
		TLSConfig:        *o.TLSConfig.Convert(),
	}
}

'''
'''--- component/common/relabel/relabel.go ---
package relabel

import (
	"fmt"

	"github.com/grafana/regexp"
	"github.com/prometheus/common/model"
	"github.com/prometheus/prometheus/model/relabel"
)

// Action is the relabelling action to be performed.
type Action string

// All possible Action values.
const (
	Replace   Action = "replace"
	Keep      Action = "keep"
	Drop      Action = "drop"
	HashMod   Action = "hashmod"
	LabelMap  Action = "labelmap"
	LabelDrop Action = "labeldrop"
	LabelKeep Action = "labelkeep"
	Lowercase Action = "lowercase"
	Uppercase Action = "uppercase"
)

var actions = map[Action]struct{}{
	Replace:   {},
	Keep:      {},
	Drop:      {},
	HashMod:   {},
	LabelMap:  {},
	LabelDrop: {},
	LabelKeep: {},
	Lowercase: {},
	Uppercase: {},
}

// String returns the string representation of the Action type.
func (a Action) String() string {
	if _, exists := actions[a]; exists {
		return string(a)
	}
	return "Action:" + string(a)
}

// MarshalText implements encoding.TextMarshaler for Action.
func (a Action) MarshalText() (text []byte, err error) {
	return []byte(a.String()), nil
}

// UnmarshalText implements encoding.TextUnmarshaler for Action.
func (a *Action) UnmarshalText(text []byte) error {
	if _, exists := actions[Action(text)]; exists {
		*a = Action(text)
		return nil
	}
	return fmt.Errorf("unrecognized action type %q", string(text))
}

// Regexp encapsulates the Regexp type from Grafana's fork of the Go stdlib regexp package.
type Regexp struct {
	*regexp.Regexp
}

func newRegexp(s string) (Regexp, error) {
	re, err := regexp.Compile("^(?:" + s + ")$")
	return Regexp{re}, err
}

func mustNewRegexp(s string) Regexp {
	re, err := newRegexp(s)
	if err != nil {
		panic(err)
	}
	return re
}

// MarshalText implements encoding.TextMarshaler for Regexp.
func (re Regexp) MarshalText() (text []byte, err error) {
	if re.String() != "" {
		return []byte(re.String()), nil
	}
	return nil, nil
}

// UnmarshalText implements encoding.TextUnmarshaler for Regexp.
func (re *Regexp) UnmarshalText(text []byte) error {
	regex, err := regexp.Compile("^(?:" + string(text) + ")$")
	if err != nil {
		return err
	}

	*re = Regexp{regex}
	return nil
}

// Config describes a relabelling step to be applied on a target.
type Config struct {
	SourceLabels []string `river:"source_labels,attr,optional"`
	Separator    string   `river:"separator,attr,optional"`
	Regex        Regexp   `river:"regex,attr,optional"`
	Modulus      uint64   `river:"modulus,attr,optional"`
	TargetLabel  string   `river:"target_label,attr,optional"`
	Replacement  string   `river:"replacement,attr,optional"`
	Action       Action   `river:"action,attr,optional"`
}

// DefaultRelabelConfig sets the default values of fields when decoding a RelabelConfig block.
var DefaultRelabelConfig = Config{
	Action:      Replace,
	Separator:   ";",
	Regex:       mustNewRegexp("(.*)"),
	Replacement: "$1",
}

var relabelTarget = regexp.MustCompile(`^(?:(?:[a-zA-Z_]|\$(?:\{\w+\}|\w+))+\w*)+$`)

// UnmarshalRiver implements river.Unmarshaler.
func (rc *Config) UnmarshalRiver(f func(interface{}) error) error {
	*rc = DefaultRelabelConfig

	type relabelConfig Config
	if err := f((*relabelConfig)(rc)); err != nil {
		return err
	}

	if rc.Action == "" {
		return fmt.Errorf("relabel action cannot be empty")
	}
	if rc.Modulus == 0 && rc.Action == HashMod {
		return fmt.Errorf("relabel configuration for hashmod requires non-zero modulus")
	}
	if (rc.Action == Replace || rc.Action == HashMod || rc.Action == Lowercase || rc.Action == Uppercase) && rc.TargetLabel == "" {
		return fmt.Errorf("relabel configuration for %s action requires 'target_label' value", rc.Action)
	}
	if (rc.Action == Replace || rc.Action == Lowercase || rc.Action == Uppercase) && !relabelTarget.MatchString(rc.TargetLabel) {
		return fmt.Errorf("%q is invalid 'target_label' for %s action", rc.TargetLabel, rc.Action)
	}
	if (rc.Action == Lowercase || rc.Action == Uppercase) && rc.Replacement != DefaultRelabelConfig.Replacement {
		return fmt.Errorf("'replacement' can not be set for %s action", rc.Action)
	}
	if rc.Action == LabelMap && !relabelTarget.MatchString(rc.Replacement) {
		return fmt.Errorf("%q is invalid 'replacement' for %s action", rc.Replacement, rc.Action)
	}
	if rc.Action == HashMod && !model.LabelName(rc.TargetLabel).IsValid() {
		return fmt.Errorf("%q is invalid 'target_label' for %s action", rc.TargetLabel, rc.Action)
	}

	if rc.Action == LabelDrop || rc.Action == LabelKeep {
		if rc.SourceLabels != nil ||
			rc.TargetLabel != DefaultRelabelConfig.TargetLabel ||
			rc.Modulus != DefaultRelabelConfig.Modulus ||
			rc.Separator != DefaultRelabelConfig.Separator ||
			rc.Replacement != DefaultRelabelConfig.Replacement {

			return fmt.Errorf("%s action requires only 'regex', and no other fields", rc.Action)
		}
	}

	return nil
}

// ComponentToPromRelabelConfigs bridges the Compnoent-based configuration of
// relabeling steps to the Prometheus implementation.
func ComponentToPromRelabelConfigs(rcs []*Config) []*relabel.Config {
	res := make([]*relabel.Config, len(rcs))
	for i, rc := range rcs {
		sourceLabels := make([]model.LabelName, len(rc.SourceLabels))
		for i, sl := range rc.SourceLabels {
			sourceLabels[i] = model.LabelName(sl)
		}

		res[i] = &relabel.Config{
			SourceLabels: sourceLabels,
			Separator:    rc.Separator,
			Modulus:      rc.Modulus,
			TargetLabel:  rc.TargetLabel,
			Replacement:  rc.Replacement,
			Action:       relabel.Action(rc.Action),
			Regex:        relabel.Regexp{Regexp: rc.Regex.Regexp},
		}
	}

	return res
}

'''
'''--- component/component.go ---
// Package component describes the interfaces which Flow components implement.
//
// A Flow component is a distinct piece of business logic that accepts inputs
// (Arguments) for its configuration and can optionally export a set of outputs
// (Exports).
//
// Arguments and Exports do not need to be static for the lifetime of a
// component. A component will be given a new Config if the runtime
// configuration changes. A component may also update its Exports throughout
// its lifetime, such as a component which outputs the current day of the week.
//
// Components are built by users with River, where they can use River
// expressions to refer to any input or exported field from other components.
// This allows users to connect components together to declaratively form a
// pipeline.
//
// Defining Arguments and Exports structs
//
// Arguments and Exports implemented by new components must be able to be
// encoded to and from River. "river" struct field tags are used for encoding;
// refer to the package documentation at pkg/river for a description of how to
// write these tags.
//
// The set of River element names of a given component's Arguments and Exports
// types must not overlap. Additionally, the following River field and block
// names are reserved for use by the Flow controller:
//
//     * for_each
//     * enabled
//     * health
//     * debug
//
// Default values for Arguments may be provided by implementing
// river.Unmarshaler.
//
// Arguments and Exports immutability
//
// Arguments passed to a component should be treated as immutable, as memory
// can be shared between components as an optimization. Components should make
// copies for fields they need to modify. An exception to this is for fields
// which are expected to be mutable (e.g., interfaces which expose a
// goroutine-safe API).
//
// Similarly, Exports and the fields within Exports must be considered
// immutable after they are written for the same reason.
//
// Mapping River strings to custom types
//
// Custom encoding and decoding of fields is available by implementing
// encoding.TextMarshaler and encoding.TextUnmarshaler. Types implementing
// these interfaces will be represented as strings in River.
//
// Component registration
//
// Components are registered globally by calling Register. These components are
// then made available by including them in the import path. The "all" child
// package imports all known component packages and should be updated when
// creating a new one.
package component

import "context"

// The Arguments contains the input fields for a specific component, which is
// unmarshaled from River.
//
// Refer to the package documentation for details around how to build proper
// Arguments implementations.
type Arguments interface{}

// Exports contains the current set of outputs for a specific component, which
// is then marshaled to River.
//
// Refer to the package documentation for details around how to build proper
// Exports implementations.
type Exports interface{}

// Component is the base interface for a Flow component. Components may
// implement extension interfaces (named <Extension>Component) to implement
// extra known behavior.
type Component interface {
	// Run starts the component, blocking until ctx is canceled or the component
	// suffers a fatal error. Run is guaranteed to be called exactly once per
	// Component.
	//
	// Implementations of Component should perform any necessary cleanup before
	// returning from Run.
	Run(ctx context.Context) error

	// Update provides a new Config to the component. The type of newConfig will
	// always match the struct type which the component registers.
	//
	// Update will be called concurrently with Run. The component must be able to
	// gracefully handle updating its config will still running.
	//
	// An error may be returned if the provided config is invalid.
	Update(args Arguments) error
}

// DebugComponent is an extension interface for components which can report
// debugging information upon request.
type DebugComponent interface {
	Component

	// DebugInfo returns the current debug information of the component. May
	// return nil if there is no debug info to currently report. The result of
	// DebugInfo must be encodable to River like Arguments and Exports.
	//
	// Values from DebugInfo are not exposed to other components for use in
	// expressions.
	//
	// DebugInfo must be safe for calling concurrently.
	DebugInfo() interface{}
}

'''
'''--- component/component_health.go ---
package component

import (
	"encoding"
	"fmt"
	"time"
)

// HealthComponent is an optional extension interface for Components which
// report health information.
//
// Health information is exposed to the end user for informational purposes and
// cannot be referened in a River expression.
type HealthComponent interface {
	Component

	// CurrentHealth returns the current Health status for the component.
	//
	// CurrentHealth may be overridden by the Flow controller if there is a
	// higher-level issue, such as a config file being invalid or a Component
	// shutting down unexpectedly.
	CurrentHealth() Health
}

// Health is the reported health state of a component. It can be encoded to
// River.
type Health struct {
	// The specific health value.
	Health HealthType `river:"state,attr"`

	// An optional message to describe the health; useful to say why a component
	// is unhealthy.
	Message string `river:"message,attr,optional"`

	// An optional time to indicate when the component last modified something
	// which updated its health.
	UpdateTime time.Time `river:"update_time,attr,optional"`
}

// HealthType holds the health value for a component.
type HealthType uint8

var (
	_ encoding.TextMarshaler   = HealthType(0)
	_ encoding.TextUnmarshaler = (*HealthType)(nil)
)

const (
	// HealthTypeUnknown is the initial health of components, set when they're
	// first created.
	HealthTypeUnknown HealthType = iota

	// HealthTypeHealthy represents a component which is working as expected.
	HealthTypeHealthy

	// HealthTypeUnhealthy represents a component which is not working as
	// expected.
	HealthTypeUnhealthy

	// HealthTypeExited represents a component which has stopped running.
	HealthTypeExited
)

// String returns the string representation of ht.
func (ht HealthType) String() string {
	switch ht {
	case HealthTypeHealthy:
		return "healthy"
	case HealthTypeUnhealthy:
		return "unhealthy"
	case HealthTypeExited:
		return "exited"
	default:
		return "unknown"
	}
}

// MarshalText implements encoding.TextMarshaler.
func (ht HealthType) MarshalText() (text []byte, err error) {
	return []byte(ht.String()), nil
}

// UnmarshalText implments encoding.TextUnmarshaler.
func (ht *HealthType) UnmarshalText(text []byte) error {
	switch string(text) {
	case "healthy":
		*ht = HealthTypeHealthy
	case "unhealthy":
		*ht = HealthTypeUnhealthy
	case "unknown":
		*ht = HealthTypeUnknown
	case "exited":
		*ht = HealthTypeExited
	default:
		return fmt.Errorf("invalid health type %q", string(text))
	}
	return nil
}

'''
'''--- component/discovery/discovery.go ---
package discovery

import (
	"context"
	"time"

	"github.com/prometheus/prometheus/discovery"
	"github.com/prometheus/prometheus/discovery/targetgroup"
)

// Target refers to a singular discovered endpoint found by a discovery
// component.
type Target map[string]string

// maxUpdateFrequency is the minimum time to wait between updating targets.
// Currently not settable, since prometheus uses a static threshold, but
// we could reconsider later.
const maxUpdateFrequency = 5 * time.Second

// Discoverer is an alias for Prometheus' Discoverer interface, so users of this package don't need
// to import github.com/prometheus/prometheus/discover as well.
type Discoverer discovery.Discoverer

// RunDiscovery is a utility for consuming and forwarding target groups from a discoverer.
// It will handle collating targets (and clearing), as well as time based throttling of updates.
// f should be a function that updates the component's exports, most likely calling `opts.OnStateChange()`.
func RunDiscovery(ctx context.Context, d Discoverer, f func([]Target)) {
	// all targets we have seen so far
	cache := map[string]*targetgroup.Group{}

	ch := make(chan []*targetgroup.Group)
	go d.Run(ctx, ch)

	// function to convert and send targets in format scraper expects
	send := func() {
		allTargets := []Target{}
		for _, group := range cache {
			for _, target := range group.Targets {
				labels := map[string]string{}
				// first add the group labels, and then the
				// target labels, so that target labels take precedence.
				for k, v := range group.Labels {
					labels[string(k)] = string(v)
				}
				for k, v := range target {
					labels[string(k)] = string(v)
				}
				allTargets = append(allTargets, labels)
			}
		}
		f(allTargets)
	}

	ticker := time.NewTicker(maxUpdateFrequency)
	// true if we have received new targets and need to send.
	haveUpdates := false
	for {
		select {
		case <-ticker.C:
			if haveUpdates {
				send()
				haveUpdates = false
			}
		case <-ctx.Done():
			send()
			return
		case groups := <-ch:
			for _, group := range groups {
				// Discoverer will send an empty target set to indicate the group (keyed by Source field)
				// should be removed
				if len(group.Targets) == 0 {
					delete(cache, group.Source)
				} else {
					cache[group.Source] = group
				}
			}
			haveUpdates = true
		}
	}
}

'''
'''--- component/discovery/kubernetes/k8s.go ---
package kubernetes

import (
	"context"
	"sync"

	"github.com/grafana/agent/component"
	"github.com/grafana/agent/component/common/config"
	"github.com/grafana/agent/component/discovery"
	promk8s "github.com/prometheus/prometheus/discovery/kubernetes"
)

func init() {
	component.Register(component.Registration{
		Name:    "discovery.k8s",
		Args:    SDConfig{},
		Exports: Exports{},

		Build: func(opts component.Options, args component.Arguments) (component.Component, error) {
			return New(opts, args.(SDConfig))
		},
	})
}

// SDConfig is a conversion of discover/kubernetes/SDConfig to be compatible with flow
type SDConfig struct {
	APIServer          config.URL              `river:"api_server,attr,optional"`
	Role               string                  `river:"role,attr"`
	KubeConfig         string                  `river:"kubeconfig_file,attr,optional"`
	HTTPClientConfig   config.HTTPClientConfig `river:"http_client_config,block,optional"`
	NamespaceDiscovery NamespaceDiscovery      `river:"namespaces,block,optional"`
	Selectors          []SelectorConfig        `river:"selectors,block,optional"`
}

// DefaultConfig holds defaults for SDConfig. (copied from prometheus)
var DefaultConfig = SDConfig{
	HTTPClientConfig: config.DefaultHTTPClientConfig,
}

// UnmarshalRiver simply applies defaults then unmarshals regularly
func (sd *SDConfig) UnmarshalRiver(f func(interface{}) error) error {
	*sd = DefaultConfig
	type arguments SDConfig
	return f((*arguments)(sd))
}

// Convert to prometheus config type
func (sd *SDConfig) Convert() *promk8s.SDConfig {
	selectors := make([]promk8s.SelectorConfig, len(sd.Selectors))
	for i, s := range sd.Selectors {
		selectors[i] = *s.convert()
	}
	return &promk8s.SDConfig{
		APIServer:          sd.APIServer.Convert(),
		Role:               promk8s.Role(sd.Role),
		KubeConfig:         sd.KubeConfig,
		HTTPClientConfig:   *sd.HTTPClientConfig.Convert(),
		NamespaceDiscovery: *sd.NamespaceDiscovery.convert(),
		Selectors:          selectors,
	}
}

// NamespaceDiscovery mirroring prometheus type
type NamespaceDiscovery struct {
	IncludeOwnNamespace bool     `river:"own_namespace,attr,optional"`
	Names               []string `river:"names,attr,optional"`
}

func (nd *NamespaceDiscovery) convert() *promk8s.NamespaceDiscovery {
	return &promk8s.NamespaceDiscovery{
		IncludeOwnNamespace: nd.IncludeOwnNamespace,
		Names:               nd.Names,
	}
}

// SelectorConfig mirroring prometheus type
type SelectorConfig struct {
	Role  string `river:"role,attr"`
	Label string `river:"label,attr,optional"`
	Field string `river:"field,attr,optional"`
}

func (sc *SelectorConfig) convert() *promk8s.SelectorConfig {
	return &promk8s.SelectorConfig{
		Role:  promk8s.Role(sc.Role),
		Label: sc.Label,
		Field: sc.Field,
	}
}

// Exports holds values which are exported by the discovery.k8s component.
type Exports struct {
	Targets []discovery.Target `river:"targets,attr"`
}

// Component implements the discovery.k8s component.
type Component struct {
	opts component.Options

	discMut       sync.Mutex
	latestDisc    discovery.Discoverer
	newDiscoverer chan struct{}
}

// New creates a new discovery.k8s component.
func New(o component.Options, args SDConfig) (*Component, error) {
	c := &Component{
		opts: o,
		// buffered to avoid deadlock from the first immediate update
		newDiscoverer: make(chan struct{}, 1),
	}
	return c, c.Update(args)
}

// Run implements component.Component.
func (c *Component) Run(ctx context.Context) error {
	var cancel context.CancelFunc
	for {
		select {
		case <-ctx.Done():
			return nil
		case <-c.newDiscoverer:
			// cancel any previously running discovery
			if cancel != nil {
				cancel()
			}
			// function to send updates on change
			f := func(t []discovery.Target) {
				c.opts.OnStateChange(Exports{Targets: t})
			}
			// create new context so we can cancel it if we get any future updates
			// since it is derived from the main run context, it only needs to be
			// canceled directly if we receive new updates
			newCtx, cancelFunc := context.WithCancel(ctx)
			cancel = cancelFunc

			// finally run discovery
			c.discMut.Lock()
			disc := c.latestDisc
			c.discMut.Unlock()
			go discovery.RunDiscovery(newCtx, disc, f)
		}
	}
}

// Update implements component.Compnoent.
func (c *Component) Update(args component.Arguments) error {
	newArgs := args.(SDConfig)

	disc, err := promk8s.New(c.opts.Logger, newArgs.Convert())
	if err != nil {
		return err
	}
	c.discMut.Lock()
	c.latestDisc = disc
	c.discMut.Unlock()

	select {
	case c.newDiscoverer <- struct{}{}:
	default:
	}

	return nil
}

'''
'''--- component/local/file/detector.go ---
package file

import (
	"context"
	"encoding"
	"fmt"
	"sync"
	"time"

	"github.com/fsnotify/fsnotify"
	"github.com/go-kit/log"
	"github.com/go-kit/log/level"
)

// Detector is used to specify how changes to the file should be detected.
type Detector int

const (
	// DetectorInvalid indicates an invalid UpdateType.
	DetectorInvalid Detector = iota
	// DetectorFSNotify uses filesystem events to wait for changes to the file.
	DetectorFSNotify
	// DetectorPoll will re-read the file on an interval to detect changes.
	DetectorPoll

	// DetectorDefault holds the default UpdateType.
	DetectorDefault = DetectorFSNotify
)

var (
	_ encoding.TextMarshaler   = Detector(0)
	_ encoding.TextUnmarshaler = (*Detector)(nil)
)

// String returns the string representation of the UpdateType.
func (ut Detector) String() string {
	switch ut {
	case DetectorFSNotify:
		return "fsnotify"
	case DetectorPoll:
		return "poll"
	default:
		return fmt.Sprintf("Detector(%d)", ut)
	}
}

// MarshalText implements encoding.TextMarshaler.
func (ut Detector) MarshalText() (text []byte, err error) {
	return []byte(ut.String()), nil
}

// UnmarshalText implements encoding.TextUnmarshaler.
func (ut *Detector) UnmarshalText(text []byte) error {
	switch string(text) {
	case "":
		*ut = DetectorDefault
	case "fsnotify":
		*ut = DetectorFSNotify
	case "poll":
		*ut = DetectorPoll
	default:
		return fmt.Errorf("unrecognized detector %q, expected fsnotify or poll", string(text))
	}
	return nil
}

type fsNotify struct {
	opts   fsNotifyOptions
	cancel context.CancelFunc

	// watcherMut is needed to prevent race conditions on Windows. This can be
	// removed once fsnotify/fsnotify#454 is merged and included in a patch
	// release.
	watcherMut sync.Mutex
	watcher    *fsnotify.Watcher
}

type fsNotifyOptions struct {
	Logger       log.Logger
	Filename     string
	ReloadFile   func()        // Callback to request file reload.
	PollFreqency time.Duration // How often to do fallback polling
}

// newFSNotify creates a new fsnotify detector which uses filesystem events to
// detect that a file has changed.
func newFSNotify(opts fsNotifyOptions) (*fsNotify, error) {
	w, err := fsnotify.NewWatcher()
	if err != nil {
		return nil, err
	}
	if err := w.Add(opts.Filename); err != nil {
		// It's possible that the file already got deleted by the time our fsnotify
		// was created. We'll log the error and wait for our polling fallback for
		// the file to be recreated.
		level.Warn(opts.Logger).Log("msg", "failed to watch file", "err", err)
	}

	ctx, cancel := context.WithCancel(context.Background())

	wd := &fsNotify{
		opts:    opts,
		watcher: w,
		cancel:  cancel,
	}

	go wd.wait(ctx)
	return wd, nil
}

func (fsn *fsNotify) wait(ctx context.Context) {
	pollTick := time.NewTicker(fsn.opts.PollFreqency)
	defer pollTick.Stop()

	for {
		select {
		case <-ctx.Done():
			return
		case <-pollTick.C:
			// fsnotify falls back to polling in case the watch stopped (i.e., the
			// file got deleted) or failed.
			//
			// We'll use the poll period to re-establish the watch in case it was
			// stopped. This is a no-op if the watch is already active.
			fsn.watcherMut.Lock()
			err := fsn.watcher.Add(fsn.opts.Filename)
			fsn.watcherMut.Unlock()

			if err != nil {
				level.Warn(fsn.opts.Logger).Log("msg", "failed re-watch file", "err", err)
			}

			fsn.opts.ReloadFile()

		case err := <-fsn.watcher.Errors:
			// The fsnotify watcher can generate errors for OS-level reasons (watched
			// failed, failed when closing the file, etc). We don't know if the error
			// is related to the file, so we always treat it as if the file updated.
			//
			// This will force the component to reload the file and report the error
			// directly to the user via the component health.
			if err != nil {
				level.Warn(fsn.opts.Logger).Log("msg", "got error from fsnotify watcher; treating as file updated event", "err", err)
				fsn.opts.ReloadFile()
			}
		case ev := <-fsn.watcher.Events:
			level.Debug(fsn.opts.Logger).Log("msg", "got fsnotify event", "op", ev.Op.String())
			fsn.opts.ReloadFile()
		}
	}
}

func (fsn *fsNotify) Close() error {
	fsn.watcherMut.Lock()
	defer fsn.watcherMut.Unlock()

	fsn.cancel()
	return fsn.watcher.Close()
}

type poller struct {
	opts   pollerOptions
	cancel context.CancelFunc
}

type pollerOptions struct {
	Filename      string
	ReloadFile    func() // Callback to request file reload.
	PollFrequency time.Duration
}

// newPoller creates a new poll-based file update detector.
func newPoller(opts pollerOptions) *poller {
	ctx, cancel := context.WithCancel(context.Background())

	pw := &poller{
		opts:   opts,
		cancel: cancel,
	}

	go pw.run(ctx)
	return pw
}

func (p *poller) run(ctx context.Context) {
	t := time.NewTicker(p.opts.PollFrequency)
	defer t.Stop()

	for {
		select {
		case <-ctx.Done():
			return
		case <-t.C:
			// Always tell the component to re-check the file. This avoids situations
			// where the file changed without changing any of the stats (like modify
			// time).
			p.opts.ReloadFile()
		}
	}
}

// Close terminates the poller.
func (p *poller) Close() error {
	p.cancel()
	return nil
}

'''
'''--- component/local/file/file.go ---
package file

import (
	"context"
	"fmt"
	"io"
	"os"
	"sync"
	"time"

	"github.com/prometheus/client_golang/prometheus"

	"github.com/go-kit/log/level"
	"github.com/grafana/agent/component"
	"github.com/grafana/agent/pkg/flow/rivertypes"
	"github.com/grafana/agent/pkg/river"
)

// waitReadPeriod holds the time to wait before reading a file while the
// local.file component is running.
//
// This prevents local.file from updating too frequently and exporting partial
// writes.
const waitReadPeriod time.Duration = 30 * time.Millisecond

func init() {
	component.Register(component.Registration{
		Name:    "local.file",
		Args:    Arguments{},
		Exports: Exports{},

		Build: func(opts component.Options, args component.Arguments) (component.Component, error) {
			return New(opts, args.(Arguments))
		},
	})
}

// Arguments holds values which are used to configure the local.file component.
type Arguments struct {
	// Filename indicates the file to watch.
	Filename string `river:"filename,attr"`
	// Type indicates how to detect changes to the file.
	Type Detector `river:"detector,attr,optional"`
	// PollFrequency determines the frequency to check for changes when Type is
	// UpdateTypePoll.
	PollFrequency time.Duration `river:"poll_freqency,attr,optional"`
	// IsSecret marks the file as holding a secret value which should not be
	// displayed to the user.
	IsSecret bool `river:"is_secret,attr,optional"`
}

// DefaultArguments provides the default arguments for the local.file
// component.
var DefaultArguments = Arguments{
	Type:          DetectorFSNotify,
	PollFrequency: time.Minute,
}

var _ river.Unmarshaler = (*Arguments)(nil)

// UnmarshalRiver implements river.Unmarshaler.
func (a *Arguments) UnmarshalRiver(f func(interface{}) error) error {
	*a = DefaultArguments

	type arguments Arguments
	return f((*arguments)(a))
}

// Exports holds values which are exported by the local.file component.
type Exports struct {
	// Content of the file.
	Content rivertypes.OptionalSecret `river:"content,attr"`
}

// Component implements the local.file component.
type Component struct {
	opts component.Options

	mut           sync.Mutex
	args          Arguments
	latestContent string
	detector      io.Closer

	healthMut sync.RWMutex
	health    component.Health

	// reloadCh is a buffered channel which is written to when the watched file
	// should be reloaded by the component.
	reloadCh     chan struct{}
	lastAccessed prometheus.Gauge
}

var (
	_ component.Component       = (*Component)(nil)
	_ component.HealthComponent = (*Component)(nil)
)

// New creates a new local.file component.
func New(o component.Options, args Arguments) (*Component, error) {
	c := &Component{
		opts: o,

		reloadCh: make(chan struct{}, 1),
		lastAccessed: prometheus.NewGauge(prometheus.GaugeOpts{
			Name: "agent_local_file_timestamp_last_accessed_unix_seconds",
			Help: "The last successful access in unix seconds",
		}),
	}

	err := o.Registerer.Register(c.lastAccessed)
	if err != nil {
		return nil, err
	}
	// Perform an update which will immediately set our exports to the initial
	// contents of the file.
	if err = c.Update(args); err != nil {
		return nil, err
	}
	return c, nil
}

// Run implements component.Component.
func (c *Component) Run(ctx context.Context) error {
	defer func() {
		c.mut.Lock()
		defer c.mut.Unlock()

		if err := c.detector.Close(); err != nil {
			level.Error(c.opts.Logger).Log("msg", "failed to shut down detector", "err", err)
		}
		c.detector = nil
	}()

	// Since Run _may_ get recalled if we're told to exit but still exist in the
	// config file, we may have prematurely destroyed the detector. If no
	// detector exists, we need to recreate it for Run to work properly.
	//
	// We ignore the error (indicating the file has disappeared) so we can allow
	// the detector to inform us when it comes back.
	//
	// TODO(rfratto): this is a design wart, and can hopefully be removed in
	// future iterations.
	c.mut.Lock()
	_ = c.configureDetector()
	c.mut.Unlock()

	for {
		select {
		case <-ctx.Done():
			return nil
		case <-c.reloadCh:
			time.Sleep(waitReadPeriod)

			// We ignore the error here from readFile since readFile will log errors
			// and also report the error as the health of the component.
			c.mut.Lock()
			_ = c.readFile()
			c.mut.Unlock()
		}
	}
}

func (c *Component) readFile() error {
	// Force a re-load of the file outside of the update detection mechanism.
	bb, err := os.ReadFile(c.args.Filename)
	if err != nil {
		c.setHealth(component.Health{
			Health:     component.HealthTypeUnhealthy,
			Message:    fmt.Sprintf("failed to read file: %s", err),
			UpdateTime: time.Now(),
		})
		level.Error(c.opts.Logger).Log("msg", "failed to read file", "path", c.opts.DataPath, "err", err)
		return err
	}
	c.latestContent = string(bb)
	c.lastAccessed.SetToCurrentTime()

	c.opts.OnStateChange(Exports{
		Content: rivertypes.OptionalSecret{
			IsSecret: c.args.IsSecret,
			Value:    c.latestContent,
		},
	})

	c.setHealth(component.Health{
		Health:     component.HealthTypeHealthy,
		Message:    "read file",
		UpdateTime: time.Now(),
	})
	return nil
}

// Update implements component.Compnoent.
func (c *Component) Update(args component.Arguments) error {
	newArgs := args.(Arguments)

	if newArgs.PollFrequency <= 0 {
		return fmt.Errorf("poll_freqency must be greater than 0")
	}

	c.mut.Lock()
	defer c.mut.Unlock()
	c.args = newArgs

	// Force an immediate read of the file to report any potential errors early.
	if err := c.readFile(); err != nil {
		return fmt.Errorf("failed to read file: %w", err)
	}

	// Each detector is dedicated to a single file path. We'll naively shut down
	// the existing detector (if any) before setting up a new one to make sure
	// the correct file is being watched in case the path changed between calls
	// to Update.
	if c.detector != nil {
		if err := c.detector.Close(); err != nil {
			level.Error(c.opts.Logger).Log("msg", "failed to shut down old detector", "err", err)
		}
		c.detector = nil
	}

	return c.configureDetector()
}

// configureDetector configures the detector if one isn't set. mut must be held
// when called.
func (c *Component) configureDetector() error {
	if c.detector != nil {
		// Already have a detector; don't do anything.
		return nil
	}

	var err error

	reloadFile := func() {
		select {
		case c.reloadCh <- struct{}{}:
		default:
			// no-op: a reload is already queued so we don't need to queue a second
			// one.
		}
	}

	switch c.args.Type {
	case DetectorPoll:
		c.detector = newPoller(pollerOptions{
			Filename:      c.args.Filename,
			ReloadFile:    reloadFile,
			PollFrequency: c.args.PollFrequency,
		})
	case DetectorFSNotify:
		c.detector, err = newFSNotify(fsNotifyOptions{
			Logger:       c.opts.Logger,
			Filename:     c.args.Filename,
			ReloadFile:   reloadFile,
			PollFreqency: c.args.PollFrequency,
		})
	}

	return err
}

// CurrentHealth implements component.HealthComponent.
func (c *Component) CurrentHealth() component.Health {
	c.healthMut.RLock()
	defer c.healthMut.RUnlock()
	return c.health
}

func (c *Component) setHealth(h component.Health) {
	c.healthMut.Lock()
	defer c.healthMut.Unlock()
	c.health = h
}

'''
'''--- component/local/file/file_test.go ---
package file_test

import (
	"context"
	"io/fs"
	"os"
	"path/filepath"
	"testing"
	"time"

	"github.com/grafana/agent/component/local/file"
	"github.com/grafana/agent/pkg/flow/componenttest"
	"github.com/grafana/agent/pkg/flow/rivertypes"
	"github.com/stretchr/testify/require"
)

func TestFile(t *testing.T) {
	t.Run("Polling change detector", func(t *testing.T) {
		runFileTests(t, file.DetectorPoll)
	})

	t.Run("Event change detector", func(t *testing.T) {
		runFileTests(t, file.DetectorFSNotify)
	})
}

// runFileTests will run a suite of tests with the configured update type.
func runFileTests(t *testing.T, ut file.Detector) {
	newSuiteController := func(t *testing.T, filename string) *componenttest.Controller {
		require.NoError(t, os.WriteFile(filename, []byte("First load!"), 0664))

		tc, err := componenttest.NewControllerFromID(nil, "local.file")
		require.NoError(t, err)
		go func() {
			err := tc.Run(componenttest.TestContext(t), file.Arguments{
				Filename: filename,
				Type:     ut,

				// Pick a polling frequency which is fast enough so that tests finish
				// quickly but not so frequent such that Go struggles to schedule the
				// goroutines of the tests on slower machines.
				PollFrequency: 50 * time.Millisecond,
			})
			require.NoError(t, err)
		}()

		// Swallow the initial exports notification.
		require.NoError(t, tc.WaitExports(time.Second))
		require.Equal(t, file.Exports{
			Content: rivertypes.OptionalSecret{
				IsSecret: false,
				Value:    "First load!",
			},
		}, tc.Exports())
		return tc
	}

	t.Run("Updates to files are detected", func(t *testing.T) {
		testFile := filepath.Join(t.TempDir(), "testfile")
		sc := newSuiteController(t, testFile)

		// Update the file.
		require.NoError(t, os.WriteFile(testFile, []byte("New content!"), 0664))

		require.NoError(t, sc.WaitExports(time.Second))
		require.Equal(t, file.Exports{
			Content: rivertypes.OptionalSecret{
				IsSecret: false,
				Value:    "New content!",
			},
		}, sc.Exports())
	})

	t.Run("Deleted and recreated files are detected", func(t *testing.T) {
		testFile := filepath.Join(t.TempDir(), "testfile")
		sc := newSuiteController(t, testFile)

		// Delete the file, then recreate it with new content.
		require.NoError(t, os.Remove(testFile))
		require.NoError(t, os.WriteFile(testFile, []byte("New content!"), 0664))

		require.NoError(t, sc.WaitExports(time.Second))
		require.Equal(t, file.Exports{
			Content: rivertypes.OptionalSecret{
				IsSecret: false,
				Value:    "New content!",
			},
		}, sc.Exports())
	})
}

// TestFile_ImmediateExports validates that constructing a local.file component
// immediately exports the contents of the file.
func TestFile_ImmediateExports(t *testing.T) {
	testFile := filepath.Join(t.TempDir(), "testfile")
	require.NoError(t, os.WriteFile(testFile, []byte("Hello, world!"), 0664))

	tc, err := componenttest.NewControllerFromID(nil, "local.file")
	require.NoError(t, err)
	go func() {
		err := tc.Run(componenttest.TestContext(t), file.Arguments{
			Filename:      testFile,
			Type:          file.DetectorPoll,
			PollFrequency: 1 * time.Hour,
		})
		require.NoError(t, err)
	}()

	require.NoError(t, tc.WaitExports(time.Second))
	require.Equal(t, file.Exports{
		Content: rivertypes.OptionalSecret{
			IsSecret: false,
			Value:    "Hello, world!",
		},
	}, tc.Exports())
}

// TestFile_ExistOnLoad ensures that the the configured file must exist on the
// first load of local.file.
func TestFile_ExistOnLoad(t *testing.T) {
	testFile := filepath.Join(t.TempDir(), "testfile")

	tc, err := componenttest.NewControllerFromID(nil, "local.file")
	require.NoError(t, err)

	err = tc.Run(canceledContext(), file.Arguments{
		Filename:      testFile,
		Type:          file.DetectorPoll,
		PollFrequency: 1 * time.Hour,
	})

	var expectErr error = &fs.PathError{}
	require.ErrorAs(t, err, &expectErr)
}

// canceledContext creates a context which is already canceled.
func canceledContext() context.Context {
	ctx, cancel := context.WithCancel(context.Background())
	cancel()
	return ctx
}

'''
'''--- component/metrics/globalrefmap.go ---
package metrics

import (
	"sync"
	"time"

	"github.com/prometheus/prometheus/model/labels"
)

// GlobalRefMapping is used when translating to and from remote writes and the rest of the system (mostly scrapers)
// normal components except those should in general NOT need this.
var GlobalRefMapping = &GlobalRefMap{}

func init() {
	GlobalRefMapping = newGlobalRefMap()
}

// staleDuration determines how often we should wait after a stale value is received to GC that value
var staleDuration = time.Minute * 10

// GlobalRefMap allows conversion from remote_write refids to global refs ids that everything else can use
type GlobalRefMap struct {
	mut                sync.Mutex
	globalRefID        uint64
	mappings           map[string]*remoteWriteMapping
	labelsHashToGlobal map[uint64]uint64
	staleGlobals       map[uint64]*staleMarker
}

type staleMarker struct {
	globalID        uint64
	lastMarkedStale time.Time
	labelHash       uint64
}

// newGlobalRefMap creates a refmap for usage, there should ONLY be one of these
func newGlobalRefMap() *GlobalRefMap {
	return &GlobalRefMap{
		globalRefID:        0,
		mappings:           make(map[string]*remoteWriteMapping),
		labelsHashToGlobal: make(map[uint64]uint64),
		staleGlobals:       make(map[uint64]*staleMarker),
	}
}

// GetOrAddLink is called by a remote_write endpoint component to add mapping and get back the global id.
func (g *GlobalRefMap) GetOrAddLink(componentID string, localRefID uint64, fm *FlowMetric) uint64 {
	g.mut.Lock()
	defer g.mut.Unlock()

	// If the mapping doesn't exist then we need to create it
	m, found := g.mappings[componentID]
	if !found {
		m = &remoteWriteMapping{
			RemoteWriteID: componentID,
			localToGlobal: make(map[uint64]uint64),
			globalToLocal: make(map[uint64]uint64),
		}
		g.mappings[componentID] = m
	}

	labelHash := fm.labels.Hash()
	globalID, found := g.labelsHashToGlobal[labelHash]
	if found {
		m.localToGlobal[localRefID] = globalID
		m.globalToLocal[globalID] = localRefID
		return globalID
	}
	// We have a value we have never seen before so increment the globalrefid and assign
	g.globalRefID++
	g.labelsHashToGlobal[labelHash] = g.globalRefID
	m.localToGlobal[localRefID] = g.globalRefID
	m.globalToLocal[g.globalRefID] = localRefID
	return g.globalRefID
}

// GetOrAddGlobalRefID is used to create a global refid for a labelset
func (g *GlobalRefMap) GetOrAddGlobalRefID(l labels.Labels) uint64 {
	g.mut.Lock()
	defer g.mut.Unlock()

	labelHash := l.Hash()
	globalID, found := g.labelsHashToGlobal[labelHash]
	if found {
		return globalID
	}
	g.globalRefID++
	g.labelsHashToGlobal[labelHash] = g.globalRefID
	return g.globalRefID
}

// GetGlobalRefID returns the global refid for a component local combo, or 0 if not found
func (g *GlobalRefMap) GetGlobalRefID(componentID string, localRefID uint64) uint64 {
	g.mut.Lock()
	defer g.mut.Unlock()

	m, found := g.mappings[componentID]
	if !found {
		return 0
	}
	global := m.localToGlobal[localRefID]
	return global
}

// GetLocalRefID returns the local refid for a component global combo, or 0 if not found
func (g *GlobalRefMap) GetLocalRefID(componentID string, globalRefID uint64) uint64 {
	g.mut.Lock()
	defer g.mut.Unlock()

	m, found := g.mappings[componentID]
	if !found {
		return 0
	}
	local := m.globalToLocal[globalRefID]
	return local
}

// AddStaleMarker adds a stale marker
func (g *GlobalRefMap) AddStaleMarker(globalRefID uint64, l labels.Labels) {
	g.mut.Lock()
	defer g.mut.Unlock()

	g.staleGlobals[globalRefID] = &staleMarker{
		lastMarkedStale: time.Now(),
		labelHash:       l.Hash(),
		globalID:        globalRefID,
	}
}

// RemoveStaleMarker removes a stale marker
func (g *GlobalRefMap) RemoveStaleMarker(globalRefID uint64) {
	g.mut.Lock()
	defer g.mut.Unlock()

	delete(g.staleGlobals, globalRefID)
}

// CheckStaleMarkers is called to garbage collect and items that have grown stale over stale duration (10m)
func (g *GlobalRefMap) CheckStaleMarkers() {
	g.mut.Lock()
	defer g.mut.Unlock()

	curr := time.Now()
	idsToBeGCed := make([]*staleMarker, 0)
	for _, stale := range g.staleGlobals {
		// If the difference between now and the last time the stale was marked doesnt exceed stale then let it stay
		if curr.Sub(stale.lastMarkedStale) < staleDuration {
			continue
		}
		idsToBeGCed = append(idsToBeGCed, stale)
	}
	for _, marker := range idsToBeGCed {
		delete(g.staleGlobals, marker.globalID)
		delete(g.labelsHashToGlobal, marker.labelHash)
		// Delete our mapping keys
		for _, mapping := range g.mappings {
			mapping.deleteStaleIDs(marker.globalID)
		}
	}
}

'''
'''--- component/metrics/globalrefmap_test.go ---
package metrics

import (
	"testing"
	"time"

	"github.com/prometheus/prometheus/model/labels"
	"github.com/stretchr/testify/require"
)

func TestAddingMarker(t *testing.T) {
	mapping := newGlobalRefMap()
	l := labels.Labels{}
	l = append(l, labels.Label{
		Name:  "__name__",
		Value: "test",
	})
	globalID := mapping.GetOrAddGlobalRefID(l)
	shouldBeSameGlobalID := mapping.GetOrAddGlobalRefID(l)
	require.True(t, globalID == shouldBeSameGlobalID)
	require.Len(t, mapping.labelsHashToGlobal, 1)
}

func TestAddingDifferentMarkers(t *testing.T) {
	mapping := newGlobalRefMap()
	l := labels.Labels{}
	l = append(l, labels.Label{
		Name:  "__name__",
		Value: "test",
	})
	l2 := labels.Labels{}
	l2 = append(l2, labels.Label{
		Name:  "__name__",
		Value: "roar",
	})
	globalID := mapping.GetOrAddGlobalRefID(l)
	shouldBeDifferentID := mapping.GetOrAddGlobalRefID(l2)
	require.True(t, globalID != shouldBeDifferentID)
	require.Len(t, mapping.labelsHashToGlobal, 2)
}

func TestAddingLocalMapping(t *testing.T) {
	mapping := newGlobalRefMap()
	l := labels.Labels{}
	l = append(l, labels.Label{
		Name:  "__name__",
		Value: "test",
	})

	globalID := mapping.GetOrAddGlobalRefID(l)
	fm := NewFlowMetric(globalID, l, 0)
	shouldBeSameGlobalID := mapping.GetOrAddLink("1", 1, fm)
	require.True(t, globalID == shouldBeSameGlobalID)
	require.Len(t, mapping.labelsHashToGlobal, 1)
	require.Len(t, mapping.mappings, 1)
	require.True(t, mapping.mappings["1"].RemoteWriteID == "1")
	require.True(t, mapping.mappings["1"].globalToLocal[shouldBeSameGlobalID] == 1)
	require.True(t, mapping.mappings["1"].localToGlobal[1] == shouldBeSameGlobalID)
}

func TestAddingLocalMappings(t *testing.T) {
	mapping := newGlobalRefMap()
	l := labels.Labels{}
	l = append(l, labels.Label{
		Name:  "__name__",
		Value: "test",
	})

	globalID := mapping.GetOrAddGlobalRefID(l)
	fm := NewFlowMetric(globalID, l, 0)
	shouldBeSameGlobalID := mapping.GetOrAddLink("1", 1, fm)
	shouldBeSameGlobalID2 := mapping.GetOrAddLink("2", 1, fm)
	require.True(t, globalID == shouldBeSameGlobalID)
	require.True(t, globalID == shouldBeSameGlobalID2)
	require.Len(t, mapping.labelsHashToGlobal, 1)
	require.Len(t, mapping.mappings, 2)

	require.True(t, mapping.mappings["1"].RemoteWriteID == "1")
	require.True(t, mapping.mappings["1"].globalToLocal[shouldBeSameGlobalID] == 1)
	require.True(t, mapping.mappings["1"].localToGlobal[1] == shouldBeSameGlobalID)

	require.True(t, mapping.mappings["2"].RemoteWriteID == "2")
	require.True(t, mapping.mappings["2"].globalToLocal[shouldBeSameGlobalID2] == 1)
	require.True(t, mapping.mappings["2"].localToGlobal[1] == shouldBeSameGlobalID2)
}

func TestAddingLocalMappingsWithoutCreatingGlobalUpfront(t *testing.T) {
	mapping := newGlobalRefMap()
	l := labels.Labels{}
	l = append(l, labels.Label{
		Name:  "__name__",
		Value: "test",
	})

	fm := NewFlowMetric(1, l, 0)

	shouldBeSameGlobalID := mapping.GetOrAddLink("1", 1, fm)
	shouldBeSameGlobalID2 := mapping.GetOrAddLink("2", 1, fm)
	require.True(t, shouldBeSameGlobalID2 == shouldBeSameGlobalID)
	require.Len(t, mapping.labelsHashToGlobal, 1)
	require.Len(t, mapping.mappings, 2)

	require.True(t, mapping.mappings["1"].RemoteWriteID == "1")
	require.True(t, mapping.mappings["1"].globalToLocal[shouldBeSameGlobalID] == 1)
	require.True(t, mapping.mappings["1"].localToGlobal[1] == shouldBeSameGlobalID)

	require.True(t, mapping.mappings["2"].RemoteWriteID == "2")
	require.True(t, mapping.mappings["2"].globalToLocal[shouldBeSameGlobalID2] == 1)
	require.True(t, mapping.mappings["2"].localToGlobal[1] == shouldBeSameGlobalID2)
}

func TestStaleness(t *testing.T) {
	mapping := newGlobalRefMap()
	l := labels.Labels{}
	l = append(l, labels.Label{
		Name:  "__name__",
		Value: "test",
	})
	l2 := labels.Labels{}
	l2 = append(l2, labels.Label{
		Name:  "__name__",
		Value: "test2",
	})

	fm := NewFlowMetric(0, l, 0)
	fm2 := NewFlowMetric(0, l2, 0)

	global1 := mapping.GetOrAddLink("1", 1, fm)
	_ = mapping.GetOrAddLink("2", 1, fm2)
	mapping.AddStaleMarker(global1, l)
	require.Len(t, mapping.staleGlobals, 1)
	require.Len(t, mapping.labelsHashToGlobal, 2)
	staleDuration = 1 * time.Millisecond
	time.Sleep(10 * time.Millisecond)
	mapping.CheckStaleMarkers()
	require.Len(t, mapping.staleGlobals, 0)
	require.Len(t, mapping.labelsHashToGlobal, 1)
}

func TestRemovingStaleness(t *testing.T) {
	mapping := newGlobalRefMap()
	l := labels.Labels{}
	l = append(l, labels.Label{
		Name:  "__name__",
		Value: "test",
	})

	fm := NewFlowMetric(0, l, 0)

	global1 := mapping.GetOrAddLink("1", 1, fm)
	mapping.AddStaleMarker(global1, l)
	require.Len(t, mapping.staleGlobals, 1)
	mapping.RemoveStaleMarker(global1)
	require.Len(t, mapping.staleGlobals, 0)
}

'''
'''--- component/metrics/mapping.go ---
package metrics

// remoteWriteMapping maps a remote_write to a set of global ids
type remoteWriteMapping struct {
	RemoteWriteID string
	localToGlobal map[uint64]uint64
	globalToLocal map[uint64]uint64
}

func (rw *remoteWriteMapping) deleteStaleIDs(globalID uint64) {
	localID, found := rw.globalToLocal[globalID]
	if !found {
		return
	}
	delete(rw.globalToLocal, globalID)
	delete(rw.localToGlobal, localID)
}

'''
'''--- component/metrics/mutate/mutate.go ---
package mutate

import (
	"context"
	"sync"

	"github.com/grafana/agent/component"
	flow_relabel "github.com/grafana/agent/component/common/relabel"
	"github.com/grafana/agent/component/metrics"
	"github.com/prometheus/client_golang/prometheus"
	"github.com/prometheus/prometheus/model/relabel"
)

func init() {
	component.Register(component.Registration{
		Name:    "metrics.mutate",
		Args:    Arguments{},
		Exports: Exports{},
		Build: func(opts component.Options, args component.Arguments) (component.Component, error) {
			return New(opts, args.(Arguments))
		},
	})
}

// Arguments holds values which are used to configure the metrics.mutate
// component.
type Arguments struct {
	// Where the relabelled metrics should be forwarded to.
	ForwardTo []*metrics.Receiver `river:"forward_to,attr"`

	// The relabelling steps to apply to each metric before it's forwarded.
	MetricRelabelConfigs []*flow_relabel.Config `river:"metric_relabel_config,block,optional"`
}

// Exports holds values which are exported by the metrics.mutate component.
type Exports struct {
	Receiver *metrics.Receiver `river:"receiver,attr"`
}

// Component implements the metrics.mutate component.
type Component struct {
	mut              sync.RWMutex
	opts             component.Options
	mrc              []*relabel.Config
	forwardto        []*metrics.Receiver
	receiver         *metrics.Receiver
	metricsProcessed prometheus.Counter
}

var (
	_ component.Component = (*Component)(nil)
)

// New creates a new metrics.mutate component.
func New(o component.Options, args Arguments) (*Component, error) {
	c := &Component{opts: o}
	c.receiver = &metrics.Receiver{Receive: c.Receive}
	c.metricsProcessed = prometheus.NewCounter(prometheus.CounterOpts{
		Name: "agent_metrics_mutate_metrics_processed",
		Help: "Total number of metrics processed",
	})

	err := o.Registerer.Register(c.metricsProcessed)
	if err != nil {
		return nil, err
	}
	// Call to Update() to set the relabelling rules once at the start.
	if err = c.Update(args); err != nil {
		return nil, err
	}

	return c, nil
}

// Run implements component.Component.
func (c *Component) Run(ctx context.Context) error {
	<-ctx.Done()
	c.opts.Registerer.Unregister(c.metricsProcessed)
	return nil
}

// Update implements component.Component.
func (c *Component) Update(args component.Arguments) error {
	c.mut.Lock()
	defer c.mut.Unlock()

	newArgs := args.(Arguments)

	c.mrc = flow_relabel.ComponentToPromRelabelConfigs(newArgs.MetricRelabelConfigs)
	c.forwardto = newArgs.ForwardTo
	c.opts.OnStateChange(Exports{Receiver: c.receiver})

	return nil
}

// Receive implements the receiver.Receive func that allows an array of metrics
// to be passed around.
// TODO (@tpaschalis) The relabelling process will run _every_ time, for all
// metrics, resulting in some serious CPU overhead. We should be caching the
// relabeling results per refID and clearing entries for dropped or stale
// series. This is a blocker for releasing a production-grade  of the metrics.mutate
// component.
func (c *Component) Receive(ts int64, metricArr []*metrics.FlowMetric) {
	c.mut.RLock()
	defer c.mut.RUnlock()

	relabelledMetrics := make([]*metrics.FlowMetric, 0)
	for _, m := range metricArr {
		// Relabel may return the original flowmetric if no changes applied, nil if everything was removed or an entirely new flowmetric.
		relabelledFm := m.Relabel(c.mrc...)
		if relabelledFm == nil {
			continue
		}
		relabelledMetrics = append(relabelledMetrics, relabelledFm)
	}
	if len(relabelledMetrics) == 0 {
		return
	}
	for _, forward := range c.forwardto {
		forward.Receive(ts, relabelledMetrics)
	}
}

'''
'''--- component/metrics/receiver.go ---
package metrics

import (
	"github.com/prometheus/prometheus/model/labels"
	promrelabel "github.com/prometheus/prometheus/model/relabel"
)

// Receiver is used to pass an array of metrics to another receiver
type Receiver struct {
	// metrics should be considered immutable
	Receive func(timestamp int64, metrics []*FlowMetric)
}

// RiverCapsule marks receivers as a capsule.
func (r Receiver) RiverCapsule() {}

// FlowMetric is a wrapper around a single metric without the timestamp.
type FlowMetric struct {
	globalRefID uint64
	labels      labels.Labels
	value       float64
}

// NewFlowMetric instantiates a new flow metric
func NewFlowMetric(globalRefID uint64, lbls labels.Labels, value float64) *FlowMetric {
	// Always ensure we have a valid global ref id
	if globalRefID == 0 {
		globalRefID = GlobalRefMapping.GetOrAddGlobalRefID(lbls)
	}
	return &FlowMetric{
		globalRefID: globalRefID,
		labels:      lbls,
		value:       value,
	}
}

// GlobalRefID Retrieves the GlobalRefID
func (fw *FlowMetric) GlobalRefID() uint64 { return fw.globalRefID }

// Value returns the value
func (fw *FlowMetric) Value() float64 { return fw.value }

// LabelsCopy returns a copy of the labels structure
func (fw *FlowMetric) LabelsCopy() labels.Labels {
	return fw.labels.Copy()
}

// RawLabels returns the actual underlying labels that SHOULD be treated as immutable. Usage of this
// must be very careful to ensure that nothing that consume this mutates labels in anyway.
func (fw *FlowMetric) RawLabels() labels.Labels {
	return fw.labels
}

// Relabel applies normal prometheus relabel rules and returns a flow metric. NOTE this may return itself.
func (fw *FlowMetric) Relabel(cfgs ...*promrelabel.Config) *FlowMetric {
	retLbls := promrelabel.Process(fw.labels, cfgs...)
	if retLbls == nil {
		return nil
	}
	if retLbls.Hash() == fw.labels.Hash() && labels.Equal(retLbls, fw.labels) {
		return fw
	}
	return NewFlowMetric(0, retLbls, fw.value)
}

'''
'''--- component/metrics/receiver_test.go ---
package metrics

import (
	"testing"

	"github.com/prometheus/prometheus/model/labels"
	promrelabel "github.com/prometheus/prometheus/model/relabel"
	"github.com/stretchr/testify/require"
)

func TestRelabel(t *testing.T) {
	fm := NewFlowMetric(0, labels.FromStrings("key", "value"), 0)
	require.True(t, fm.globalRefID != 0)
	rg, _ := promrelabel.NewRegexp("(.*)")
	newfm := fm.Relabel(&promrelabel.Config{
		Replacement: "${1}_new",
		Action:      "replace",
		TargetLabel: "new",
		Regex:       rg,
	})
	require.Len(t, fm.labels, 1)
	require.True(t, fm.labels.Has("key"))

	require.Len(t, newfm.labels, 2)
	require.True(t, newfm.labels.Has("new"))
}

func TestRelabelTheSame(t *testing.T) {
	fm := NewFlowMetric(0, labels.FromStrings("key", "value"), 0)
	require.True(t, fm.globalRefID != 0)
	rg, _ := promrelabel.NewRegexp("bad")
	newfm := fm.Relabel(&promrelabel.Config{
		Replacement: "${1}_new",
		Action:      "replace",
		TargetLabel: "new",
		Regex:       rg,
	})
	require.Len(t, fm.labels, 1)
	require.True(t, fm.labels.Has("key"))
	require.Len(t, newfm.labels, 1)
	require.True(t, newfm.globalRefID == fm.globalRefID)
	require.True(t, labels.Equal(newfm.labels, fm.labels))
}

'''
'''--- component/metrics/remotewrite/remote_write.go ---
package remotewrite

// NOTE: This is a placeholder component for remote_write for testing of the appendable, it should NOT be considered final

import (
	"context"
	"fmt"
	"math"
	"path/filepath"
	"sync"
	"time"

	"github.com/grafana/agent/component/metrics"

	"github.com/go-kit/log"
	"github.com/go-kit/log/level"
	"github.com/grafana/agent/component"
	"github.com/grafana/agent/pkg/build"
	"github.com/grafana/agent/pkg/metrics/wal"
	"github.com/prometheus/prometheus/model/timestamp"
	"github.com/prometheus/prometheus/storage"
	"github.com/prometheus/prometheus/storage/remote"
)

// Options.
//
// TODO(rfratto): This should be exposed. How do we want to expose this?
var remoteFlushDeadline = 1 * time.Minute

func init() {
	remote.UserAgent = fmt.Sprintf("GrafanaAgent/%s", build.Version)

	component.Register(component.Registration{
		Name:    "metrics.remote_write",
		Args:    RemoteConfig{},
		Exports: Export{},
		Build: func(o component.Options, c component.Arguments) (component.Component, error) {
			return NewComponent(o, c.(RemoteConfig))
		},
	})
}

// Component is the metrics_forwarder component.
type Component struct {
	log  log.Logger
	opts component.Options

	walStore    *wal.Storage
	remoteStore *remote.Storage
	storage     storage.Storage

	mut sync.RWMutex
	cfg RemoteConfig

	receiver *metrics.Receiver
}

// NewComponent creates a new metrics_forwarder component.
func NewComponent(o component.Options, c RemoteConfig) (*Component, error) {
	walLogger := log.With(o.Logger, "subcomponent", "wal")
	dataPath := filepath.Join(o.DataPath, "wal", o.ID)
	walStorage, err := wal.NewStorage(walLogger, o.Registerer, dataPath)
	if err != nil {
		return nil, err
	}

	remoteLogger := log.With(o.Logger, "subcomponent", "rw")
	remoteStore := remote.NewStorage(remoteLogger, o.Registerer, startTime, dataPath, remoteFlushDeadline, nil)

	res := &Component{
		log:         o.Logger,
		opts:        o,
		walStore:    walStorage,
		remoteStore: remoteStore,
		storage:     storage.NewFanout(o.Logger, walStorage, remoteStore),
	}
	res.receiver = &metrics.Receiver{Receive: res.Receive}
	if err := res.Update(c); err != nil {
		return nil, err
	}
	return res, nil
}

func startTime() (int64, error) { return 0, nil }

var _ component.Component = (*Component)(nil)

// Run implements Component.
func (c *Component) Run(ctx context.Context) error {
	c.opts.OnStateChange(Export{Receiver: c.receiver})
	defer func() {
		level.Debug(c.log).Log("msg", "closing storage")
		err := c.storage.Close()
		level.Debug(c.log).Log("msg", "storage closed")
		if err != nil {
			level.Error(c.log).Log("msg", "error when closing storage", "err", err)
		}
	}()

	// Track the last timestamp we truncated for to prevent segments from getting
	// deleted until at least some new data has been sent.
	var lastTs = int64(math.MinInt64)

	for {
		select {
		case <-ctx.Done():
			return nil
		case <-time.After(c.truncateFrequency()):
			// We retrieve the current min/max keepalive time at once, since
			// retrieving them separately could lead to issues where we have an older
			// value for min which is now larger than max.
			c.mut.RLock()
			var (
				minWALTime = c.cfg.WALOptions.MinKeepaliveTime
				maxWALTime = c.cfg.WALOptions.MaxKeepaliveTime
			)
			c.mut.RUnlock()

			// The timestamp ts is used to determine which series are not receiving
			// samples and may be deleted from the WAL. Their most recent append
			// timestamp is compared to ts, and if that timestamp is older then ts,
			// they are considered inactive and may be deleted.
			//
			// Subtracting a duration from ts will delay when it will be considered
			// inactive and scheduled for deletion.
			ts := c.remoteStore.LowestSentTimestamp() - minWALTime.Milliseconds()
			if ts < 0 {
				ts = 0
			}

			// Network issues can prevent the result of getRemoteWriteTimestamp from
			// changing. We don't want data in the WAL to grow forever, so we set a cap
			// on the maximum age data can be. If our ts is older than this cutoff point,
			// we'll shift it forward to start deleting very stale data.
			if maxTS := timestamp.FromTime(time.Now().Add(-maxWALTime)); ts < maxTS {
				ts = maxTS
			}

			if ts == lastTs {
				level.Debug(c.log).Log("msg", "not truncating the WAL, remote_write timestamp is unchanged", "ts", ts)
				continue
			}
			lastTs = ts

			level.Debug(c.log).Log("msg", "truncating the WAL", "ts", ts)
			err := c.walStore.Truncate(ts)
			if err != nil {
				// The only issue here is larger disk usage and a greater replay time,
				// so we'll only log this as a warning.
				level.Warn(c.log).Log("msg", "could not truncate WAL", "err", err)
			}
		}
	}
}

func (c *Component) truncateFrequency() time.Duration {
	c.mut.RLock()
	defer c.mut.RUnlock()
	return c.cfg.WALOptions.TruncateFrequency
}

// Update implements Component.
func (c *Component) Update(newConfig component.Arguments) error {
	cfg := newConfig.(RemoteConfig)

	c.mut.Lock()
	defer c.mut.Unlock()

	convertedConfig, err := convertConfigs(cfg)
	if err != nil {
		return err
	}
	err = c.remoteStore.ApplyConfig(convertedConfig)
	if err != nil {
		return err
	}

	c.cfg = cfg
	return nil
}

// Receive implements the receiver.receive func that allows an array of metrics to be passed
func (c *Component) Receive(ts int64, metricArr []*metrics.FlowMetric) {
	app := c.storage.Appender(context.Background())
	for _, m := range metricArr {
		localID := metrics.GlobalRefMapping.GetLocalRefID(c.opts.ID, m.GlobalRefID())
		// Currently it doesn't look like the storage interfaces mutate the labels, but thats not a strong
		// promise. So this should be treated with care.
		newLocal, err := app.Append(storage.SeriesRef(localID), m.RawLabels(), ts, m.Value())
		// Add link if there wasn't one before, and we received a valid local id
		if localID == 0 && newLocal != 0 {
			metrics.GlobalRefMapping.GetOrAddLink(c.opts.ID, uint64(newLocal), m)
		}
		if err != nil {
			_ = app.Rollback()
			//TODO what should we log and behave?
			level.Error(c.log).Log("err", err, "msg", "error receiving metrics", "component", c.opts.ID)
			return
		}
	}
	_ = app.Commit()
}

// Config implements Component.
func (c *Component) Config() RemoteConfig {
	c.mut.RLock()
	defer c.mut.RUnlock()
	return c.cfg
}

'''
'''--- component/metrics/remotewrite/types.go ---
package remotewrite

import (
	"fmt"
	"net/url"
	"sort"
	"time"

	"github.com/prometheus/prometheus/model/labels"

	"github.com/prometheus/prometheus/config"

	types "github.com/grafana/agent/component/common/config"
	"github.com/grafana/agent/component/metrics"
	"github.com/grafana/agent/pkg/flow/rivertypes"
	"github.com/grafana/agent/pkg/river"
	common "github.com/prometheus/common/config"
	"github.com/prometheus/common/model"
)

// Defaults for config blocks.
var (
	DefaultRemoteConfig = RemoteConfig{
		WALOptions: DefaultWALOptions,
	}

	DefaultQueueConfig = QueueConfig{
		Capacity:          2500,
		MaxShards:         200,
		MinShards:         1,
		MaxSamplesPerSend: 500,
		BatchSendDeadline: 5 * time.Second,
		MinBackoff:        30 * time.Millisecond,
		MaxBackoff:        5 * time.Second,
		RetryOn429:        false,
	}

	DefaultWALOptions = WALOptions{
		TruncateFrequency: 2 * time.Hour,
		MinKeepaliveTime:  5 * time.Minute,
		MaxKeepaliveTime:  8 * time.Hour,
	}

	_ river.Unmarshaler = (*QueueConfig)(nil)
)

// RemoteConfig represents the input state of the metrics_forwarder component.
type RemoteConfig struct {
	ExternalLabels map[string]string `river:"external_labels,attr,optional"`
	RemoteWrite    []*Config         `river:"remote_write,block,optional"`
	WALOptions     WALOptions        `river:"wal,block,optional"`
}

// UnmarshalRiver implements river.Unmarshaler.
func (rc *RemoteConfig) UnmarshalRiver(f func(interface{}) error) error {
	*rc = DefaultRemoteConfig

	type config RemoteConfig
	return f((*config)(rc))
}

// Config is the metrics_fowarder's configuration for where to send
// metrics stored in the WAL.
type Config struct {
	Name             string                  `river:"name,attr,optional"`
	URL              string                  `river:"url,attr"`
	SendExemplars    bool                    `river:"send_exemplars,attr,optional"`
	BasicAuth        *BasicAuthConfig        `river:"basic_auth,block,optional"`
	QueueConfig      *QueueConfig            `river:"queue_config,block,optional"`
	HTTPClientConfig *types.HTTPClientConfig `river:"client_config,block,optional"`
}

// QueueConfig handles the low level queue config options for a remote_write
type QueueConfig struct {
	Capacity          int           `river:"capacity,attr,optional"`
	MaxShards         int           `river:"max_shards,attr,optional"`
	MinShards         int           `river:"min_shards,attr,optional"`
	MaxSamplesPerSend int           `river:"max_samples_per_send,attr,optional"`
	BatchSendDeadline time.Duration `river:"batch_send_deadline,attr,optional"`
	MinBackoff        time.Duration `river:"min_backoff,attr,optional"`
	MaxBackoff        time.Duration `river:"max_backoff,attr,optional"`
	RetryOn429        bool          `river:"retry_on_http_429,attr,optional"`
}

// WALOptions configures behavior within the WAL.
type WALOptions struct {
	TruncateFrequency time.Duration `river:"truncate_frequency,attr,optional"`
	MinKeepaliveTime  time.Duration `river:"min_keepalive_time,attr,optional"`
	MaxKeepaliveTime  time.Duration `river:"max_keepalive_time,attr,optional"`
}

// UnmarshalRiver implements river.Unmarshaler.
func (o *WALOptions) UnmarshalRiver(f func(interface{}) error) error {
	*o = DefaultWALOptions

	type config WALOptions
	if err := f((*config)(o)); err != nil {
		return err
	}

	switch {
	case o.TruncateFrequency == 0:
		return fmt.Errorf("truncate_frequency must not be 0")
	case o.MaxKeepaliveTime <= o.MinKeepaliveTime:
		return fmt.Errorf("min_keepalive_time must be smaller than max_keepalive_time")
	}

	return nil
}

// Export is used to assign this to receive metrics
type Export struct {
	Receiver *metrics.Receiver `river:"receiver,attr"`
}

// BasicAuthConfig is the metrics_forwarder's configuration for authenticating
// against the remote system when sending metrics.
type BasicAuthConfig struct {
	Username     string            `river:"username,attr"`
	Password     rivertypes.Secret `river:"password,attr,optional"`
	PasswordFile string            `river:"password_file,attr,optional"`
}

// UnmarshalRiver allows injecting of default values
func (r *Config) UnmarshalRiver(f func(v interface{}) error) error {
	*r = Config{
		SendExemplars: true,
	}

	type arguments Config
	return f((*arguments)(r))
}

// UnmarshalRiver allows injecting of default values
func (r *QueueConfig) UnmarshalRiver(f func(v interface{}) error) error {
	*r = DefaultQueueConfig

	type arguments QueueConfig
	return f((*arguments)(r))
}

func convertConfigs(cfg RemoteConfig) (*config.Config, error) {
	var rwConfigs []*config.RemoteWriteConfig
	for _, rw := range cfg.RemoteWrite {
		parsedURL, err := url.Parse(rw.URL)
		if err != nil {
			return nil, fmt.Errorf("cannot parse remote_write url %q: %w", rw.URL, err)
		}

		rwc := &config.RemoteWriteConfig{
			Name:          rw.Name,
			URL:           &common.URL{URL: parsedURL},
			RemoteTimeout: model.Duration(30 * time.Second),
			QueueConfig:   config.DefaultQueueConfig,
			MetadataConfig: config.MetadataConfig{
				Send: false,
			},
			HTTPClientConfig: common.DefaultHTTPClientConfig,
		}

		if rw.BasicAuth != nil {
			rwc.HTTPClientConfig.BasicAuth = &common.BasicAuth{
				Username:     rw.BasicAuth.Username,
				Password:     common.Secret(rw.BasicAuth.Password),
				PasswordFile: rw.BasicAuth.PasswordFile,
			}
		}

		if rw.QueueConfig != nil {
			rwc.QueueConfig = config.QueueConfig{
				Capacity:          rw.QueueConfig.Capacity,
				MaxShards:         rw.QueueConfig.MaxShards,
				MinShards:         rw.QueueConfig.MinShards,
				MaxSamplesPerSend: rw.QueueConfig.MaxSamplesPerSend,
				BatchSendDeadline: model.Duration(rw.QueueConfig.BatchSendDeadline),
				MinBackoff:        model.Duration(rw.QueueConfig.MinBackoff),
				MaxBackoff:        model.Duration(rw.QueueConfig.MaxBackoff),
				RetryOnRateLimit:  rw.QueueConfig.RetryOn429,
			}
		}

		if rw.HTTPClientConfig != nil {
			rwc.HTTPClientConfig = *rw.HTTPClientConfig.Convert()
		}

		rwc.SendExemplars = rw.SendExemplars

		rwConfigs = append(rwConfigs, rwc)
	}

	return &config.Config{
		GlobalConfig: config.GlobalConfig{
			ExternalLabels: toLabels(cfg.ExternalLabels),
		},
		RemoteWriteConfigs: rwConfigs,
	}, nil
}

func toLabels(in map[string]string) labels.Labels {
	res := make(labels.Labels, 0, len(in))
	for k, v := range in {
		res = append(res, labels.Label{Name: k, Value: v})
	}
	sort.Sort(res)
	return res
}

'''
'''--- component/metrics/scrape/scrape.go ---
package scrape

import (
	"context"
	"fmt"
	"sync"
	"time"

	"github.com/go-kit/log/level"
	"github.com/grafana/agent/component"
	fa "github.com/grafana/agent/component/common/appendable"
	"github.com/grafana/agent/component/discovery"
	"github.com/grafana/agent/component/metrics"
	"github.com/grafana/agent/pkg/build"
	"github.com/prometheus/common/model"
	"github.com/prometheus/prometheus/config"
	"github.com/prometheus/prometheus/discovery/targetgroup"
	"github.com/prometheus/prometheus/scrape"
)

func init() {
	scrape.UserAgent = fmt.Sprintf("GrafanaAgent/%s", build.Version)

	component.Register(component.Registration{
		Name: "metrics.scrape",
		Args: Arguments{},

		Build: func(opts component.Options, args component.Arguments) (component.Component, error) {
			return New(opts, args.(Arguments))
		},
	})
}

// Arguments holds values which are used to configure the metrics.scrape
// component.
type Arguments struct {
	Targets   []discovery.Target  `river:"targets,attr"`
	ForwardTo []*metrics.Receiver `river:"forward_to,attr"`

	ScrapeConfig Config `river:"scrape_config,block"`

	// Scrape Options
	ExtraMetrics bool `river:"extra_metrics,attr,optional"`
}

// Component implements the metrics.Scrape component.
type Component struct {
	opts component.Options

	reloadTargets chan struct{}

	mut        sync.RWMutex
	args       Arguments
	scraper    *scrape.Manager
	appendable *fa.FlowAppendable
}

var (
	_ component.Component = (*Component)(nil)
)

// New creates a new metrics.scrape component.
func New(o component.Options, args Arguments) (*Component, error) {
	flowAppendable := fa.NewFlowAppendable(args.ForwardTo...)

	scrapeOptions := &scrape.Options{ExtraMetrics: args.ExtraMetrics}
	scraper := scrape.NewManager(scrapeOptions, o.Logger, flowAppendable)
	c := &Component{
		opts:          o,
		reloadTargets: make(chan struct{}, 1),
		scraper:       scraper,
		appendable:    flowAppendable,
	}

	// Call to Update() to set the receivers and targets once at the start.
	if err := c.Update(args); err != nil {
		return nil, err
	}

	return c, nil
}

// Run implements component.Component.
func (c *Component) Run(ctx context.Context) error {
	defer c.scraper.Stop()

	targetSetsChan := make(chan map[string][]*targetgroup.Group)

	go func() {
		err := c.scraper.Run(targetSetsChan)
		level.Info(c.opts.Logger).Log("msg", "scrape manager stopped")
		if err != nil {
			level.Error(c.opts.Logger).Log("msg", "scrape manager failed", "err", err)
		}
	}()

	for {
		select {
		case <-ctx.Done():
			return nil
		case <-c.reloadTargets:
			c.mut.RLock()
			tgs := c.args.Targets
			c.mut.RUnlock()
			promTargets := c.componentTargetsToProm(tgs)

			select {
			case targetSetsChan <- promTargets:
				level.Debug(c.opts.Logger).Log("msg", "passed new targets to scrape manager")
			case <-ctx.Done():
			}
		}
	}
}

// Update implements component.Component.
func (c *Component) Update(args component.Arguments) error {
	newArgs := args.(Arguments)

	c.mut.Lock()
	defer c.mut.Unlock()
	c.args = newArgs

	c.appendable.SetReceivers(newArgs.ForwardTo)

	sc, err := newArgs.ScrapeConfig.getPromScrapeConfigs(c.opts.ID)
	if err != nil {
		return fmt.Errorf("invalid scrape_config: %w", err)
	}

	err = c.scraper.ApplyConfig(&config.Config{
		ScrapeConfigs: []*config.ScrapeConfig{sc},
	})
	if err != nil {
		return fmt.Errorf("error applying scrape configs: %w", err)
	}
	level.Debug(c.opts.Logger).Log("msg", "scrape config was updated")

	select {
	case c.reloadTargets <- struct{}{}:
	default:
	}

	return nil
}

// ScraperStatus reports the status of the scraper's jobs.
type ScraperStatus struct {
	TargetStatus []TargetStatus `river:"target,block,optional"`
}

// TargetStatus reports on the status of the latest scrape for a target.
type TargetStatus struct {
	JobName            string            `river:"job,attr"`
	URL                string            `river:"url,attr"`
	Health             string            `river:"health,attr"`
	Labels             map[string]string `river:"labels,attr"`
	LastError          string            `river:"last_error,attr,optional"`
	LastScrape         time.Time         `river:"last_scrape,attr"`
	LastScrapeDuration time.Duration     `river:"last_scrape_duration,attr,optional"`
}

// DebugInfo implements component.DebugComponent
func (c *Component) DebugInfo() interface{} {
	var res []TargetStatus

	for job, stt := range c.scraper.TargetsActive() {
		for _, st := range stt {
			var lastError string
			if st.LastError() != nil {
				lastError = st.LastError().Error()
			}
			if st != nil {
				res = append(res, TargetStatus{
					JobName:            job,
					URL:                st.URL().String(),
					Health:             string(st.Health()),
					Labels:             st.Labels().Map(),
					LastError:          lastError,
					LastScrape:         st.LastScrape(),
					LastScrapeDuration: st.LastScrapeDuration(),
				})
			}
		}
	}

	return ScraperStatus{TargetStatus: res}
}

func (c *Component) componentTargetsToProm(tgs []discovery.Target) map[string][]*targetgroup.Group {
	promGroup := &targetgroup.Group{Source: c.opts.ID}
	for _, tg := range tgs {
		promGroup.Targets = append(promGroup.Targets, convertLabelSet(tg))
	}

	return map[string][]*targetgroup.Group{c.opts.ID: {promGroup}}
}

func convertLabelSet(tg discovery.Target) model.LabelSet {
	lset := make(model.LabelSet, len(tg))
	for k, v := range tg {
		lset[model.LabelName(k)] = model.LabelValue(v)
	}
	return lset
}

'''
'''--- component/metrics/scrape/scrape_test.go ---
package scrape

import (
	"context"
	"os"
	"testing"
	"time"

	"github.com/prometheus/client_golang/prometheus"

	"github.com/grafana/agent/component"
	"github.com/grafana/agent/component/discovery"
	"github.com/grafana/agent/component/metrics"
	"github.com/grafana/agent/pkg/flow/logging"
	"github.com/prometheus/prometheus/model/labels"
	"github.com/stretchr/testify/require"
)

func TestForwardingToAppendable(t *testing.T) {
	l, err := logging.New(os.Stderr, logging.DefaultOptions)
	require.NoError(t, err)
	opts := component.Options{
		Logger:     l,
		Registerer: prometheus.NewRegistry(),
	}

	nilReceivers := []*metrics.Receiver{nil, nil}

	args := Arguments{
		Targets:      []discovery.Target{},
		ForwardTo:    nilReceivers,
		ScrapeConfig: DefaultConfig,
	}

	s, err := New(opts, args)
	require.NoError(t, err)

	// List the Appendable's receivers; they are nil.
	require.Equal(t, nilReceivers, s.appendable.ListReceivers())

	// Forwarding samples to the nil receivers shouldn't fail.
	appender := s.appendable.Appender(context.Background())
	_, err = appender.Append(0, labels.FromStrings("foo", "bar"), 0, 0)
	require.NoError(t, err)

	err = appender.Commit()
	require.NoError(t, err)

	// Update the component with a mock receiver; it should be passed along to the Appendable.
	var receivedTs int64
	var receivedSamples []*metrics.FlowMetric
	mockReceiver := []*metrics.Receiver{
		{
			Receive: func(t int64, m []*metrics.FlowMetric) {
				receivedTs = t
				receivedSamples = m
			},
		},
	}

	args.ForwardTo = mockReceiver
	err = s.Update(args)
	require.NoError(t, err)

	require.Equal(t, mockReceiver, s.appendable.ListReceivers())

	// Forwarding a sample to the mock receiver should succeed.
	appender = s.appendable.Appender(context.Background())
	sample := metrics.NewFlowMetric(1, labels.FromStrings("foo", "bar"), 42.0)
	timestamp := time.Now().Unix()
	_, err = appender.Append(0, sample.LabelsCopy(), timestamp, sample.Value())
	require.NoError(t, err)

	err = appender.Commit()
	require.NoError(t, err)

	require.Equal(t, receivedTs, timestamp)
	require.Len(t, receivedSamples, 1)
	require.Equal(t, receivedSamples[0], sample)
}

'''
'''--- component/metrics/scrape/types.go ---
package scrape

import (
	"fmt"
	"net/url"
	"strings"
	"time"

	"github.com/alecthomas/units"
	component_config "github.com/grafana/agent/component/common/config"
	common_config "github.com/prometheus/common/config"
	"github.com/prometheus/common/model"
	"github.com/prometheus/prometheus/config"
)

const bearer string = "Bearer"

// Config holds all of the attributes that can be used to configure a scrape
// component.
type Config struct {
	// The job name to which the job label is set by default.
	JobName string `river:"job_name,attr"`

	// Indicator whether the scraped metrics should remain unmodified.
	HonorLabels bool `river:"honor_labels,attr,optional"`
	// Indicator whether the scraped timestamps should be respected.
	HonorTimestamps bool `river:"honor_timestamps,attr,optional"`
	// A set of query parameters with which the target is scraped.
	Params url.Values `river:"params,attr,optional"`
	// How frequently to scrape the targets of this scrape config.
	ScrapeInterval time.Duration `river:"scrape_interval,attr,optional"`
	// The timeout for scraping targets of this config.
	ScrapeTimeout time.Duration `river:"scrape_timeout,attr,optional"`
	// The HTTP resource path on which to fetch metrics from targets.
	MetricsPath string `river:"metrics_path,attr,optional"`
	// The URL scheme with which to fetch metrics from targets.
	Scheme string `river:"scheme,attr,optional"`
	// An uncompressed response body larger than this many bytes will cause the
	// scrape to fail. 0 means no limit.
	BodySizeLimit units.Base2Bytes `river:"body_size_limit,attr,optional"`
	// More than this many samples post metric-relabeling will cause the scrape to
	// fail.
	SampleLimit uint `river:"sample_limit,attr,optional"`
	// More than this many targets after the target relabeling will cause the
	// scrapes to fail.
	TargetLimit uint `river:"target_limit,attr,optional"`
	// More than this many labels post metric-relabeling will cause the scrape to
	// fail.
	LabelLimit uint `river:"label_limit,attr,optional"`
	// More than this label name length post metric-relabeling will cause the
	// scrape to fail.
	LabelNameLengthLimit uint `river:"label_name_length_limit,attr,optional"`
	// More than this label value length post metric-relabeling will cause the
	// scrape to fail.
	LabelValueLengthLimit uint `river:"label_value_length_limit,attr,optional"`

	HTTPClientConfig component_config.HTTPClientConfig `river:"http_client_config,block,optional"`
}

// DefaultConfig is the set of default options applied before decoding a given
// scrape_config block.
var DefaultConfig = Config{
	MetricsPath:      "/metrics",
	Scheme:           "http",
	HonorLabels:      false,
	HonorTimestamps:  true,
	HTTPClientConfig: component_config.DefaultHTTPClientConfig,
	ScrapeInterval:   1 * time.Minute,  // From config.DefaultGlobalConfig
	ScrapeTimeout:    10 * time.Second, // From config.DefaultGlobalConfig
}

// UnmarshalRiver implements river.Unmarshaler.
func (c *Config) UnmarshalRiver(f func(interface{}) error) error {
	*c = DefaultConfig

	type scrapeConfig Config
	return f((*scrapeConfig)(c))
}

// Helper function to bridge the in-house configuration with the Prometheus
// scrape_config.
// As explained in the Config struct, the following fields are purposefully
// missing out, as they're being implemented by another components.
// - RelabelConfigs
// - MetricsRelabelConfigs
// - ServiceDiscoveryConfigs
func (c *Config) getPromScrapeConfigs(jobName string) (*config.ScrapeConfig, error) {
	dec := config.DefaultScrapeConfig
	dec.JobName = jobName
	dec.HonorLabels = c.HonorLabels
	dec.HonorTimestamps = c.HonorTimestamps
	dec.Params = c.Params
	dec.ScrapeInterval = model.Duration(c.ScrapeInterval)
	dec.ScrapeTimeout = model.Duration(c.ScrapeTimeout)
	dec.MetricsPath = c.MetricsPath
	dec.Scheme = c.Scheme
	dec.BodySizeLimit = c.BodySizeLimit
	dec.SampleLimit = c.SampleLimit
	dec.TargetLimit = c.TargetLimit
	dec.LabelLimit = c.LabelLimit
	dec.LabelNameLengthLimit = c.LabelNameLengthLimit
	dec.LabelValueLengthLimit = c.LabelValueLengthLimit

	// HTTP scrape client settings
	dec.HTTPClientConfig = *c.HTTPClientConfig.Convert()

	err := validateHTTPClientConfig(dec.HTTPClientConfig)
	if err != nil {
		return nil, fmt.Errorf("the provided scrape_config resulted in an invalid HTTP Client configuration: %w", err)
	}
	return &dec, nil
}

func validateHTTPClientConfig(c common_config.HTTPClientConfig) error {
	// Backwards compatibility with the bearer_token field.
	if len(c.BearerToken) > 0 && len(c.BearerTokenFile) > 0 {
		return fmt.Errorf("at most one of bearer_token & bearer_token_file must be configured")
	}
	if (c.BasicAuth != nil || c.OAuth2 != nil) && (len(c.BearerToken) > 0 || len(c.BearerTokenFile) > 0) {
		return fmt.Errorf("at most one of basic_auth, oauth2, bearer_token & bearer_token_file must be configured")
	}
	if c.BasicAuth != nil && (string(c.BasicAuth.Password) != "" && c.BasicAuth.PasswordFile != "") {
		return fmt.Errorf("at most one of basic_auth password & password_file must be configured")
	}
	if c.Authorization != nil {
		if len(c.BearerToken) > 0 || len(c.BearerTokenFile) > 0 {
			return fmt.Errorf("authorization is not compatible with bearer_token & bearer_token_file")
		}
		if string(c.Authorization.Credentials) != "" && c.Authorization.CredentialsFile != "" {
			return fmt.Errorf("at most one of authorization credentials & credentials_file must be configured")
		}
		c.Authorization.Type = strings.TrimSpace(c.Authorization.Type)
		if len(c.Authorization.Type) == 0 {
			c.Authorization.Type = bearer
		}
		if strings.ToLower(c.Authorization.Type) == "basic" {
			return fmt.Errorf(`authorization type cannot be set to "basic", use "basic_auth" instead`)
		}
		if c.BasicAuth != nil || c.OAuth2 != nil {
			return fmt.Errorf("at most one of basic_auth, oauth2 & authorization must be configured")
		}
	} else {
		if len(c.BearerToken) > 0 {
			c.Authorization = &common_config.Authorization{Credentials: c.BearerToken}
			c.Authorization.Type = bearer
			c.BearerToken = ""
		}
		if len(c.BearerTokenFile) > 0 {
			c.Authorization = &common_config.Authorization{CredentialsFile: c.BearerTokenFile}
			c.Authorization.Type = bearer
			c.BearerTokenFile = ""
		}
	}
	if c.OAuth2 != nil {
		if c.BasicAuth != nil {
			return fmt.Errorf("at most one of basic_auth, oauth2 & authorization must be configured")
		}
		if len(c.OAuth2.ClientID) == 0 {
			return fmt.Errorf("oauth2 client_id must be configured")
		}
		if len(c.OAuth2.ClientSecret) == 0 && len(c.OAuth2.ClientSecretFile) == 0 {
			return fmt.Errorf("either oauth2 client_secret or client_secret_file must be configured")
		}
		if len(c.OAuth2.TokenURL) == 0 {
			return fmt.Errorf("oauth2 token_url must be configured")
		}
		if len(c.OAuth2.ClientSecret) > 0 && len(c.OAuth2.ClientSecretFile) > 0 {
			return fmt.Errorf("at most one of oauth2 client_secret & client_secret_file must be configured")
		}
	}
	return nil
}

'''
'''--- component/registry.go ---
package component

import (
	"fmt"
	"reflect"
	"strings"

	"github.com/go-kit/log"
	"github.com/grafana/regexp"
	"github.com/prometheus/client_golang/prometheus"
)

// The parsedName of a component is the parts of its name ("remote.http") split
// by the "." delimiter.
type parsedName []string

// String re-joins the parsed name by the "." delimiter.
func (pn parsedName) String() string { return strings.Join(pn, ".") }

var (
	// Globally registered components
	registered = map[string]Registration{}
	// Parsed names for components
	parsedNames = map[string]parsedName{}
)

// Options are provided to a component when it is being constructed. Options
// are static for the lifetime of a component.
type Options struct {
	// ID of the component. Guaranteed to be globally unique across all running
	// components.
	ID string

	// Logger the component may use for logging. The component ID will always be
	// set as a field.
	Logger log.Logger

	// A path to a directory with this component may use for storage. The path is
	// guaranteed to be unique across all running components.
	//
	// The directory may not exist when the component is created; components
	// should create the directory if needed.
	DataPath string

	// OnStateChange may be invoked at any time by a component whose Export value
	// changes. The Flow controller then will queue re-processing components
	// which depend on the changed component.
	//
	// OnStateChange will panic if e does not match the Exports type registered
	// by the component; a component must use the same Exports type for its
	// lifetime.
	OnStateChange func(e Exports)

	// Registerer allows components to add their own metrics. The register will come pre-wrapped with the component ID. It is not necessary for components to unregister metrics on shutdown.
	Registerer prometheus.Registerer
}

// Registration describes a single component.
type Registration struct {
	// Name of the component. Must be a list of period-delimited valid
	// identifiers, such as "remote.s3". Components sharing a prefix must have
	// the same number of identifiers; it is valid to register "remote.s3" and
	// "remote.http" but not "remote".
	//
	// Components may not have more than 2 identifiers.
	//
	// Each identifier must start with a valid ASCII letter, and be followed by
	// any number of underscores or alphanumeric ASCII characters.
	Name string

	// A singleton component only supports one instance of itself across the
	// whole process. Normally, multiple components of the same type may be
	// created.
	//
	// The fully-qualified name of a component is the combination of River block
	// name and all of its labels. Fully-qualified names must be unique across
	// the process. Components which are *NOT* singletons automatically support
	// user-supplied identifiers:
	//
	//     // Fully-qualified names: remote.s3.object-a, remote.s3.object-b
	//     remote.s3 "object-a" { ... }
	//     remote.s3 "object-b" { ... }
	//
	// This allows for multiple instances of the same component to be defined.
	// However, components registered as a singleton do not support user-supplied
	// identifiers:
	//
	//     node_exporter { ... }
	//
	// This prevents the user from defining multiple instances of node_exporter
	// with different fully-qualified names.
	Singleton bool

	// An example Arguments value that the registered component expects to
	// receive as input. Components should provide the zero value of their
	// Arguments type here.
	Args Arguments

	// An example Exports value that the registered component may emit as output.
	// A component which does not expose exports must leave this set to nil.
	Exports Exports

	// Build should construct a new component from an initial Arguments and set
	// of options.
	Build func(opts Options, args Arguments) (Component, error)
}

// CloneArguments returns a new zero value of the registered Arguments type.
func (r Registration) CloneArguments() Arguments {
	return reflect.New(reflect.TypeOf(r.Args)).Interface()
}

// Register registers a component. Register will panic if the name is in use by
// another component, if the name is invalid, or if the component name has a
// suffix length mismatch with an existing component.
func Register(r Registration) {
	if _, exist := registered[r.Name]; exist {
		panic(fmt.Sprintf("Component name %q already registered", r.Name))
	}

	parsed, err := parseComponentName(r.Name)
	if err != nil {
		panic(fmt.Sprintf("invalid component name %q: %s", r.Name, err))
	}
	if err := validatePrefixMatch(parsed, parsedNames); err != nil {
		panic(err)
	}

	registered[r.Name] = r
	parsedNames[r.Name] = parsed
}

var identifierRegex = regexp.MustCompile("^[A-Za-z][0-9A-Za-z_]*$")

// parseComponentName parses and validates name. "remote.http" will return
// []string{"remote", "http"}.
func parseComponentName(name string) (parsedName, error) {
	parts := strings.Split(name, ".")
	if len(parts) == 0 {
		return nil, fmt.Errorf("missing name")
	}

	if len(parts) > 2 {
		return nil, fmt.Errorf("component name may only have 1 or 2 identifiers, found %d", len(parts))
	}

	for _, part := range parts {
		if part == "" {
			return nil, fmt.Errorf("found empty identifier")
		}

		if !identifierRegex.MatchString(part) {
			return nil, fmt.Errorf("identifier %q is not valid", part)
		}
	}

	return parts, nil
}

// validatePrefixMatch validates that components that share a prefix have the
// same length of identifiers in their names.
//
// For example, this will return an error if both a "remote" and "remote.http"
// component are defined.
func validatePrefixMatch(check parsedName, against map[string]parsedName) error {
	for _, other := range against {
		if other[0] != check[0] {
			continue
		}

		if len(other) != len(check) {
			return fmt.Errorf("%q cannot be used because it is incompatible with %q", check, other)
		}
	}

	return nil
}

// Get finds a registered component by name.
func Get(name string) (Registration, bool) {
	r, ok := registered[name]
	return r, ok
}

'''
'''--- component/registry_test.go ---
package component

import (
	"testing"

	"github.com/stretchr/testify/require"
)

func Test_parseComponentName(t *testing.T) {
	tt := []struct {
		check       string
		expectValid bool
	}{
		{check: "", expectValid: false},
		{check: " ", expectValid: false},
		{check: "test", expectValid: true},
		{check: "foo.bar", expectValid: true},
		{check: "foo.bar.", expectValid: false},
		{check: "foo.bar. ", expectValid: false},
		{check: "small.LARGE", expectValid: true},
		{check: "a_b_c_012345", expectValid: true},
	}

	for _, tc := range tt {
		t.Run(tc.check, func(t *testing.T) {
			_, err := parseComponentName(tc.check)
			if tc.expectValid {
				require.NoError(t, err, "expected component name to be valid")
			} else {
				require.Error(t, err, "expected component name to not be valid")
			}
		})
	}
}

func Test_validatePrefixMatch(t *testing.T) {
	existing := map[string]parsedName{
		"remote.http": {"remote", "http"},
		"test":        {"test"},
	}

	tt := []struct {
		check       string
		expectValid bool
	}{
		{check: "remote.s3", expectValid: true},
		{check: "remote", expectValid: false},
		{check: "test2", expectValid: true},
		{check: "test.new", expectValid: false},
	}

	for _, tc := range tt {
		t.Run(tc.check, func(t *testing.T) {
			parsed, err := parseComponentName(tc.check)
			require.NoError(t, err)

			err = validatePrefixMatch(parsed, existing)
			if tc.expectValid {
				require.NoError(t, err, "expected component to be accepted")
			} else {
				require.Error(t, err, "expected component to not be accepted")
			}
		})
	}
}

'''
'''--- component/remote/s3/s3.go ---
package s3

import (
	"crypto/tls"
	"fmt"
	"net/http"
	"strings"
	"sync"
	"time"

	"github.com/aws/aws-sdk-go-v2/aws"
	aws_config "github.com/aws/aws-sdk-go-v2/config"
	"github.com/aws/aws-sdk-go-v2/service/s3"
	"github.com/grafana/agent/component"
	"github.com/grafana/agent/pkg/flow/rivertypes"
	"github.com/prometheus/client_golang/prometheus"
	"golang.org/x/net/context"
)

func init() {
	component.Register(component.Registration{
		Name:    "remote.s3",
		Args:    Arguments{},
		Exports: Exports{},
		Build: func(opts component.Options, args component.Arguments) (component.Component, error) {
			return New(opts, args.(Arguments))
		},
	})
}

// S3 handles reading content from a file located in S3
type S3 struct {
	mut     sync.Mutex
	opts    component.Options
	args    Arguments
	health  component.Health
	content string

	watcher      *watcher
	updateChan   chan result
	s3Errors     prometheus.Counter
	lastAccessed prometheus.Gauge
}

var (
	_ component.Component       = (*S3)(nil)
	_ component.HealthComponent = (*S3)(nil)
)

// New initializes the s3 component
func New(o component.Options, args Arguments) (*S3, error) {
	s3cfg, err := generateS3Config(args)
	if err != nil {
		return nil, err
	}

	s3Client := s3.NewFromConfig(*s3cfg, func(s3o *s3.Options) {
		s3o.UsePathStyle = args.Options.UsePathStyle
	})

	bucket, file := getPathBucketAndFile(args.Path)
	s := &S3{
		opts:       o,
		args:       args,
		health:     component.Health{},
		updateChan: make(chan result),
		s3Errors: prometheus.NewCounter(prometheus.CounterOpts{
			Name: "agent_remote_s3_errors_total",
			Help: "The number of errors while accessing s3",
		}),
		lastAccessed: prometheus.NewGauge(prometheus.GaugeOpts{
			Name: "agent_remote_s3_timestamp_last_accessed_unix_seconds",
			Help: "The last successful access in unix seconds",
		}),
	}

	w := newWatcher(bucket, file, s.updateChan, args.PollFrequency, s3Client)
	s.watcher = w

	err = o.Registerer.Register(s.s3Errors)
	if err != nil {
		return nil, err
	}
	err = o.Registerer.Register(s.lastAccessed)
	if err != nil {
		return nil, err
	}

	content, err := w.downloadSynchronously()
	s.handleContentPolling(content, err)
	return s, nil
}

// Run activates the content handler and watcher
func (s *S3) Run(ctx context.Context) error {
	go s.handleContentUpdate(ctx)
	go s.watcher.run(ctx)
	<-ctx.Done()

	return nil
}

// Update is called whenever the arguments have changed
func (s *S3) Update(args component.Arguments) error {
	newArgs := args.(Arguments)

	s3cfg, err := generateS3Config(newArgs)
	if err != nil {
		return nil
	}
	s3Client := s3.NewFromConfig(*s3cfg, func(s3o *s3.Options) {
		s3o.UsePathStyle = newArgs.Options.UsePathStyle
	})

	bucket, file := getPathBucketAndFile(newArgs.Path)

	s.mut.Lock()
	defer s.mut.Unlock()
	s.args = newArgs
	s.watcher.updateValues(bucket, file, newArgs.PollFrequency, s3Client)

	return nil
}

// CurrentHealth returns the health of the component
func (s *S3) CurrentHealth() component.Health {
	s.mut.Lock()
	defer s.mut.Unlock()
	return s.health
}

func generateS3Config(args Arguments) (*aws.Config, error) {
	configOptions := make([]func(*aws_config.LoadOptions) error, 0)
	// Override the endpoint
	if args.Options.Endpoint != "" {
		endFunc := aws.EndpointResolverWithOptionsFunc(func(service, region string, _ ...interface{}) (aws.Endpoint, error) {
			return aws.Endpoint{URL: args.Options.Endpoint}, nil
		})
		endResolver := aws_config.WithEndpointResolverWithOptions(endFunc)
		configOptions = append(configOptions, endResolver)
	}

	// This incredibly nested option turns off ssl
	if args.Options.DisableSSL {
		httpOverride := aws_config.WithHTTPClient(
			&http.Client{
				Transport: &http.Transport{
					TLSClientConfig: &tls.Config{
						InsecureSkipVerify: args.Options.DisableSSL,
					},
				},
			},
		)
		configOptions = append(configOptions, httpOverride)
	}

	// check credentials
	if args.Options.AccessKey != "" {
		if args.Options.Secret == "" {
			return nil, fmt.Errorf("if accesskey or secret are specified then the other must also be specified")
		}
		credFunc := aws.CredentialsProviderFunc(func(ctx context.Context) (aws.Credentials, error) {
			return aws.Credentials{
				AccessKeyID:     args.Options.AccessKey,
				SecretAccessKey: string(args.Options.Secret),
			}, nil
		})
		credProvider := aws_config.WithCredentialsProvider(credFunc)
		configOptions = append(configOptions, credProvider)
	}

	cfg, err := aws_config.LoadDefaultConfig(context.TODO(), configOptions...)
	if err != nil {
		return nil, err
	}
	// Set region
	if args.Options.Region != "" {
		cfg.Region = args.Options.Region
	}

	return &cfg, nil
}

// handleContentUpdate reads from the update and error channels setting as appropriate
func (s *S3) handleContentUpdate(ctx context.Context) {
	for {
		select {
		case r := <-s.updateChan:
			// r.result will never be nil,
			s.handleContentPolling(string(r.result), r.err)
		case <-ctx.Done():
			return
		}
	}
}

func (s *S3) handleContentPolling(newContent string, err error) {
	s.mut.Lock()
	defer s.mut.Unlock()

	if err == nil {
		s.opts.OnStateChange(Exports{
			Content: rivertypes.OptionalSecret{
				IsSecret: s.args.IsSecret,
				Value:    newContent,
			},
		})
		s.lastAccessed.SetToCurrentTime()
		s.content = newContent
		s.health.Health = component.HealthTypeHealthy
		s.health.Message = "s3 file updated"
	} else {
		s.s3Errors.Inc()
		s.health.Health = component.HealthTypeUnhealthy
		s.health.Message = err.Error()
	}
	s.health.UpdateTime = time.Now()
}

func getPathBucketAndFile(path string) (bucket, file string) {
	parts := strings.Split(path, "/")
	file = parts[len(parts)-1]
	bucket = strings.Join(parts[:len(parts)-1], "/")
	bucket = strings.ReplaceAll(bucket, "s3://", "")
	// TODO see if we can add some checks around the file/bucket
	return
}

'''
'''--- component/remote/s3/s3_test.go ---
//go:build linux
// +build linux

package s3

import (
	"bytes"
	"context"
	"net/http/httptest"
	"sync"
	"testing"
	"time"

	"github.com/prometheus/client_golang/prometheus"

	"github.com/grafana/agent/component"
	"github.com/johannesboyne/gofakes3"
	"github.com/johannesboyne/gofakes3/backend/s3mem"
	"github.com/stretchr/testify/assert"
	"github.com/stretchr/testify/require"
)

func TestCorrectBucket(t *testing.T) {
	o := component.Options{
		ID:            "t1",
		OnStateChange: func(_ component.Exports) {},
		Registerer:    prometheus.NewRegistry(),
	}
	s3File, err := New(o,
		Arguments{
			Path:          "s3://bucket/file",
			PollFrequency: 30 * time.Second,
			IsSecret:      false,
		})
	require.NoError(t, err)
	require.NotNil(t, s3File)
}

func TestWatchingFile(t *testing.T) {
	var mut sync.Mutex
	_, srv := pushFilesToFakeS3(t, "test.txt", "success!")
	var output string
	s3File, err := New(component.Options{
		ID: "id1",
		OnStateChange: func(e component.Exports) {
			mut.Lock()
			defer mut.Unlock()
			output = e.(Exports).Content.Value
		},
		Registerer: prometheus.NewRegistry(),
	}, Arguments{
		Path:          "s3://mybucket/test.txt",
		PollFrequency: 10 * time.Second,
		IsSecret:      false,
		Options: ClientOptions{
			Endpoint:     srv.URL,
			DisableSSL:   true,
			UsePathStyle: true,
		},
	})
	require.NoError(t, err)
	ctx, cancel := context.WithCancel(context.Background())
	go s3File.Run(ctx)
	time.Sleep(100 * time.Millisecond)

	// This is due to race detector
	mut.Lock()
	require.True(t, output == "success!")
	mut.Unlock()
	cancel()
}

func pushFilesToFakeS3(t *testing.T, filename string, filecontents string) (*s3mem.Backend, *httptest.Server) {
	t.Setenv("AWS_ANON", "true")

	backend := s3mem.New()
	faker := gofakes3.New(backend)
	srv := httptest.NewServer(faker.Server())
	_ = backend.CreateBucket("mybucket")
	t.Cleanup(srv.Close)
	pushFile(t, backend, filename, filecontents)
	return backend, srv
}

func pushFile(t *testing.T, backend *s3mem.Backend, filename string, filecontents string) {
	_, err := backend.PutObject(
		"mybucket",
		filename,
		map[string]string{"Content-Type": "application/yaml"},
		bytes.NewBufferString(filecontents),
		int64(len(filecontents)),
	)
	assert.NoError(t, err)
}

'''
'''--- component/remote/s3/types.go ---
package s3

import (
	"fmt"
	"time"

	"github.com/grafana/agent/pkg/river"

	"github.com/grafana/agent/pkg/flow/rivertypes"
)

var _ river.Unmarshaler = (*Arguments)(nil)

// Arguments implements the input for the s3 component
type Arguments struct {
	Path string `river:"path,attr"`
	// PollFrequency determines the frequency to check for changes
	// defaults to 10m
	PollFrequency time.Duration `river:"poll_frequency,attr,optional"`
	// IsSecret determines if the content should be displayed to the user
	IsSecret bool `river:"is_secret,attr,optional"`
	// Options allows you to override default settings
	Options ClientOptions `river:"client_options,block,optional"`
}

// ClientOptions implements specific AWS configuration options
type ClientOptions struct {
	AccessKey    string            `river:"key,attr,optional"`
	Secret       rivertypes.Secret `river:"secret,attr,optional"`
	Endpoint     string            `river:"endpoint,attr,optional"`
	DisableSSL   bool              `river:"disable_ssl,attr,optional"`
	UsePathStyle bool              `river:"use_path_style,attr,optional"`
	Region       string            `river:"region,attr,optional"`
}

const minimumPollFrequency = 30 * time.Second

// DefaultArguments sets the poll frequency
var DefaultArguments = Arguments{
	PollFrequency: 10 * time.Minute,
}

// UnmarshalRiver implements the unmarshaller
func (a *Arguments) UnmarshalRiver(f func(v interface{}) error) error {
	*a = DefaultArguments
	type arguments Arguments
	err := f((*arguments)(a))
	if err != nil {
		return err
	}
	if a.PollFrequency <= minimumPollFrequency {
		return fmt.Errorf("poll_frequency must be greater than 30s")
	}
	return nil
}

// Exports implements the file content
type Exports struct {
	Content rivertypes.OptionalSecret `river:"content,attr"`
}

'''
'''--- component/remote/s3/watcher.go ---
package s3

import (
	"errors"
	"io"
	"sync"
	"time"

	"github.com/aws/aws-sdk-go/aws"

	"github.com/aws/aws-sdk-go-v2/service/s3"
	"golang.org/x/net/context"
)

type watcher struct {
	mut        sync.Mutex
	bucket     string
	file       string
	output     chan result
	dlTicker   *time.Ticker
	downloader *s3.Client
}

type result struct {
	result []byte
	err    error
}

func newWatcher(
	bucket, file string,
	out chan result,
	frequency time.Duration,
	downloader *s3.Client,
) *watcher {

	return &watcher{
		bucket:     bucket,
		file:       file,
		output:     out,
		dlTicker:   time.NewTicker(frequency),
		downloader: downloader,
	}
}

func (w *watcher) updateValues(bucket, file string, frequency time.Duration, downloader *s3.Client) {
	w.mut.Lock()
	defer w.mut.Unlock()
	w.bucket = bucket
	w.file = file
	w.dlTicker.Reset(frequency)
	w.downloader = downloader
}

func (w *watcher) run(ctx context.Context) {
	w.download(ctx)
	defer w.dlTicker.Stop()
	for {
		select {
		case <-w.dlTicker.C:
			w.download(ctx)
		case <-ctx.Done():
			return
		}
	}
}

// download actually downloads the file from s3
func (w *watcher) download(ctx context.Context) {
	w.mut.Lock()
	defer w.mut.Unlock()
	buf, err := w.getObject(context.Background())
	r := result{
		result: buf,
		err:    err,
	}
	select {
	case <-ctx.Done():
		return
	case w.output <- r:
	}
}

func (w *watcher) downloadSynchronously() (string, error) {
	w.mut.Lock()
	defer w.mut.Unlock()
	buf, err := w.getObject(context.Background())
	if err != nil {
		return "", err
	}
	return string(buf), nil
}

// getObject ensure that the return []byte is never nil
func (w *watcher) getObject(ctx context.Context) ([]byte, error) {
	output, err := w.downloader.GetObject(ctx, &s3.GetObjectInput{
		Bucket: aws.String(w.bucket),
		Key:    aws.String(w.file),
	})
	if err != nil {
		return []byte{}, err
	}
	buf := make([]byte, output.ContentLength)
	_, err = output.Body.Read(buf)
	if !errors.Is(err, io.EOF) {
		return []byte{}, err
	}
	return buf, nil
}

'''
'''--- component/targets/mutate/mutate.go ---
package mutate

import (
	"context"

	"github.com/grafana/agent/component"
	flow_relabel "github.com/grafana/agent/component/common/relabel"
	"github.com/grafana/agent/component/discovery"
	"github.com/prometheus/prometheus/model/labels"
	"github.com/prometheus/prometheus/model/relabel"
)

func init() {
	component.Register(component.Registration{
		Name:    "targets.mutate",
		Args:    Arguments{},
		Exports: Exports{},

		Build: func(opts component.Options, args component.Arguments) (component.Component, error) {
			return New(opts, args.(Arguments))
		},
	})
}

// Arguments holds values which are used to configure the targets.mutate component.
type Arguments struct {
	// Targets contains the input 'targets' passed by a service discovery component.
	Targets []discovery.Target `river:"targets,attr"`

	// The relabelling steps to apply to the each target's label set.
	RelabelConfigs []*flow_relabel.Config `river:"relabel_config,block,optional"`
}

// Exports holds values which are exported by the targets.mutate component.
type Exports struct {
	Output []discovery.Target `river:"output,attr"`
}

// Component implements the targets.mutate component.
type Component struct {
	opts component.Options
}

var (
	_ component.Component = (*Component)(nil)
)

// New creates a new targets.mutate component.
func New(o component.Options, args Arguments) (*Component, error) {
	c := &Component{opts: o}

	// Call to Update() to set the output once at the start
	if err := c.Update(args); err != nil {
		return nil, err
	}

	return c, nil
}

// Run implements component.Component.
func (c *Component) Run(ctx context.Context) error {
	<-ctx.Done()
	return nil
}

// Update implements component.Component.
func (c *Component) Update(args component.Arguments) error {
	newArgs := args.(Arguments)

	targets := make([]discovery.Target, 0, len(newArgs.Targets))
	relabelConfigs := flow_relabel.ComponentToPromRelabelConfigs(newArgs.RelabelConfigs)

	for _, t := range newArgs.Targets {
		lset := componentMapToPromLabels(t)
		lset = relabel.Process(lset, relabelConfigs...)
		if lset != nil {
			targets = append(targets, promLabelsToComponent(lset))
		}
	}

	c.opts.OnStateChange(Exports{
		Output: targets,
	})

	return nil
}

func componentMapToPromLabels(ls discovery.Target) labels.Labels {
	res := make([]labels.Label, 0, len(ls))
	for k, v := range ls {
		res = append(res, labels.Label{Name: k, Value: v})
	}

	return res
}

func promLabelsToComponent(ls labels.Labels) discovery.Target {
	res := make(map[string]string, len(ls))
	for _, l := range ls {
		res[l.Name] = l.Value
	}

	return res
}

'''
'''--- component/targets/mutate/mutate_test.go ---
package mutate_test

import (
	"testing"
	"time"

	"github.com/grafana/agent/component/discovery"
	"github.com/grafana/agent/component/targets/mutate"
	"github.com/grafana/agent/pkg/flow/componenttest"
	"github.com/grafana/agent/pkg/river/parser"
	"github.com/grafana/agent/pkg/river/vm"
	"github.com/stretchr/testify/require"
)

func TestRelabelConfigApplication(t *testing.T) {
	riverArguments := `
targets = [ 
	{ "__meta_foo" = "foo", "__meta_bar" = "bar", "__address__" = "localhost", "instance" = "one", "app" = "backend", __tmp_a = "tmp" },
	{ "__meta_foo" = "foo", "__meta_bar" = "bar", "__address__" = "localhost", "instance" = "two", "app" = "db", "__tmp_b" = "tmp" },
	{ "__meta_baz" = "baz", "__meta_qux" = "qux", "__address__" = "localhost", "instance" = "three", "app" = "frontend", "__tmp_c" = "tmp" },
]

relabel_config {
	source_labels = ["__address__", "instance"]
	separator     = "/"
	target_label  = "destination"
	action        = "replace"
} 

relabel_config {
	source_labels = ["app"]
	action        = "drop"
	regex         = "frontend"
}

relabel_config {
	source_labels = ["app"]
	action        = "keep"
	regex         = "backend"
}

relabel_config {
	source_labels = ["instance"]
	target_label  = "name"
}

relabel_config {
	action      = "labelmap"
	regex       = "__meta_(.*)"
	replacement = "meta_$1"
}

relabel_config {
	action = "labeldrop"
	regex  = "__meta(.*)|__tmp(.*)|instance"
}
`
	expectedExports := mutate.Exports{
		Output: []discovery.Target{
			map[string]string{"__address__": "localhost", "app": "backend", "destination": "localhost/one", "meta_bar": "bar", "meta_foo": "foo", "name": "one"},
		},
	}

	file, err := parser.ParseFile("agent-config.river", []byte(riverArguments))
	require.NoError(t, err)

	var args mutate.Arguments
	err = vm.New(file).Evaluate(nil, &args)
	require.NoError(t, err)

	tc, err := componenttest.NewControllerFromID(nil, "targets.mutate")
	require.NoError(t, err)
	go func() {
		err = tc.Run(componenttest.TestContext(t), args)
		require.NoError(t, err)
	}()

	require.NoError(t, tc.WaitExports(time.Second))
	require.Equal(t, expectedExports, tc.Exports())
}

'''
'''--- docs/README.md ---
# Grafana Agent Documentation

This directory contains documentation for Grafana Agent. It is split into two
parts:

* `user/`: Documentation for users. This directory is hosted on
  [grafana.com/docs/agent](https://grafana.com/docs/agent/latest/) and we
  recommend interacting with it there instead of viewing the markdown on
  Github.
* `developer/`: Documentation for contributors and maintainers.
* `rfcs/`: RFCs for proposals relating to Grafana Agent.

## Preview the website

Run `make docs`. This launches a preview of the website with the current grafana docs at `http://localhost:3002/docs/agent/latest/` which will refresh automatically when changes are made to content in the `sources` directory.
Make sure Docker is running.

### Community Projects

Below is a list of community-led projects for working with Grafana Agent. These projects are not maintained or supported by Grafana Labs.

#### Helm (Kubernetes Deployment)

A publically available release of a Grafana Agent Helm chart is maintained [here](https://github.com/DandyDeveloper/charts/tree/master/charts/grafana-agent). Contributions and improvements are welcomed. Full details on rolling out and supported options can be found in the [readme](https://github.com/DandyDeveloper/charts/blob/master/charts/grafana-agent/README.md).

This *does not* require the Grafana Agent Operator to rollout / deploy.

#### Juju (Charmed Operator)

The [grafana-agent-k8s](https://github.com/canonical/grafana-agent-operator) charmed operator runs with [Juju](https://juju.is) the Grafana Agent on Kubernetes.
The Grafana Agent charmed operator is designed to work with the [Logs, Metrics and Alerts](https://juju.is/docs/lma2) observability stack.

'''
'''--- docs/developer/contributing.md ---
# Contributing

Grafana Agent uses GitHub to manage reviews of pull requests.

If you're planning to do a large amount of work, you should discuss your ideas
in an [issue][new-issue] or an [RFC][]. This will help you avoid unnecessary
work and surely give you and us a good deal of inspiration.

Pull requests can be opened immediately without an issue for trivial fixes or
improvements.

## Before Contributing

* Review the following code coding style guidelines:
  * [Go Code Review Comments][code-review-comments]
  * The _Formatting and style_ section of Peter Bourgon's [Go: Best Practices for Production Environments][best-practices]
  * The [Uber Go Style Guide][uber-style-guide]
* Sign our [CLA][], otherwise we're not able to accept contributions.

## Steps to Contribute

Should you wish to work on an issue, please claim it first by commenting on the
GitHub issue that you want to work on it. This is to prevent duplicated efforts
from contributors on the same issue.

Please check the [`good first issue`][good-first-issue] label to find issues
that are good for getting started. If you have questions about one of the
issues, with or without the tag, please comment on them and one of the
maintainers will clarify it. For a quicker response, contact us in the #agent
channel in our [community Slack][community-slack].

See next section for detailed instructions to compile the project. For quickly
compiling and testing your changes do:

```bash
# For building:
go build ./cmd/agent/
./agent -config.file=<config-file>

# For testing:
make lint test # Make sure all the tests pass before you commit and push :)
```

We use [`golangci-lint`](https://github.com/golangci/golangci-lint) for linting
the code.

As a last resort, if linting reports an issue and you think that the warning
needs to be disregarded or is a false-positive, you can add a special comment
`//nolint:linter1[,linter2,...]` before the offending line.

All our issues are regularly tagged with labels so that you can also filter
down the issues involving the components you want to work on.

## Compiling the Agent

To build Grafana Agent from source code, please install the following tools:

1. [Git](https://git-scm.com/)
2. [Go](https://golang.org/) (version 1.18 and up)
3. [Make](https://www.gnu.org/software/make/)
4. [Docker](https://www.docker.com/)

You can directly use the go tool to download and install the agent binary into your GOPATH:

    $ GO111MODULE=on go install github.com/grafana/agent/cmd/agent
    $ agent -config.file=your_config.yml

An example of the above configuration file can be found [here][example-config].

You can also clone the repository yourself and build using `make agent`:

    $ mkdir -p $GOPATH/src/github.com/grafana
    $ cd $GOPATH/src/github.com/grafana
    $ git clone https://github.com/grafana/agent.git
    $ cd agent
    $ make agent
    $ ./agent -config.file=your_config.yml

The Makefile provides several targets:

* `agent`: build the agent binary
* `test`: run the tests
* `lint`: run linting checks

### Compile on Linux
Compiling Grafana Agent on Linux requires a couple of extra dependencies:

* [systemd headers](https://github.com/grafana/agent/blob/main/cmd/agent/Dockerfile#L8-L9) for Promtail
* [bcc tools](https://github.com/grafana/agent/blob/main/cmd/agent/Dockerfile#L12-L13) for the eBPF integration on AMD64 systems

If you have issues installing the bcc tooling, you can use `-tags=noebpf` to compile Grafana Agent without the eBPF integration.

## Pull Request Checklist

Changes should be branched off of the `main` branch. It's recommended to rebase
on top of `main` before submitting the pull request to fix any merge conflicts
that may have appeared during development.

PRs should not introduce regressions or introduce any critical bugs. If your PR
isn't covered by existing tests, some tests should be added to validate the new
code (note that 100% code coverage is _not_ a requirement). Smaller PRs are
more likely to be reviewed faster and easier to validate for correctness;
consider splitting up your work across multiple PRs if making a significant
contribution.

If your PR is not getting reviewed or you need a specific person to review it,
you can @-reply a reviewer asking for a review in the pull request or a
comment, or you can ask for a review on the Slack channel
[#agent](https://slack.grafana.com).

## Updating the changelog

We keep a [changelog](../../CHANGELOG.md) of code changes which result in new
or changed user-facing behavior.

Changes are grouped by change type, denoted by `### Category_Name`. The change
types are, in order:

1. Security fixes
2. Breaking changes
3. Deprecations
4. Features
5. Enhancements
6. Bugfixes
7. Other changes

Categories won't be listed if there's not any changes for that category.

When opening a PR which impacts user-facing behavior, contributors should:

1. Determine which changes need to be documented in the changelog (a PR may
   change more than one user-facing behavior).

2. If there are no other changes for that change type, add a header for it
   (e.g., `### Bugfixes`). Make sure to keep the order listed above.

3. Add relevant entries into the changelog.

When in doubt, look at a previous release for style and ordering examples.

### Changelog entry style tips

Change entries in the changelog should:

1. Be complete sentences, ending in a period. It is acceptible to use multiple
   complete sentences if one sentence can't accurately describe the change.
2. Describe the impact on the user which is reading the changelog.
3. Include credit to the Github user that opened the PR following the sentence.

For example:
`- Config file reading is now 1500% faster. (@torvalds)`

> Readers should be able to understand how a change impacts them. Default to
> being explicit over vague.
>
> * Vague: `- Fixed issue with metric names. (@ghost)`
> * Explicit: `- Fixed issue where instances of the letter s in metric names were replaced with z. (@ghost)`

## Dependency management

The Grafana Agent project uses [Go modules][go-modules] to manage dependencies
on external packages.

To add or update a new dependency, use the `go get` command:

```bash
# Pick the latest tagged release.
go install example.com/some/module/pkg@latest

# Pick a specific version.
go install example.com/some/module/pkg@vX.Y.Z
```

Tidy up the `go.mod` and `go.sum` files:

```bash
# The GO111MODULE variable can be omitted when the code isn't located in GOPATH.
GO111MODULE=on go mod tidy
```

You have to commit the changes to `go.mod` and `go.sum` before submitting the
pull request.

[new-issue]: https://github.com/grafana/agent/issues/new
[RFC]: ../rfcs/0001-designing-in-the-open.md
[code-review-comments]: https://code.google.com/p/go-wiki/wiki/CodeReviewComments
[best-practices]: https://peter.bourgon.org/go-in-production/#formatting-and-style
[uber-style-guide]: https://github.com/uber-go/guide/blob/master/style.md
[CLA]: https://cla-assistant.io/grafana/agent
[good-first-issue]: https://github.com/grafana/agent/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22
[community-slack]: https://slack.grafana.com/
[example-config]: ../../cmd/agent/agent-local-config.yaml
[go-modules]: https://golang.org/cmd/go/#hdr-Modules__module_versions__and_more

'''
'''--- docs/developer/downstream-prometheus.md ---
# `grafana/prometheus` Maintenance

Grafana Labs includes the Agent as part of their internal monitoring, running it
alongside Prometheus. This gives an opportunity to utilize the Agent to
proof-of-concept additions to Prometheus before they get moved upstream. A
`grafana/prometheus` repository maintained by Grafana Labs holds non-trivial
and experimental changes. Having this repository allows for experimental features to
be vendored into the Agent and enables faster development iteration. Ideally,
this experimental testing can help serve as evidence towards usefulness and
correctness when the feature becomes proposed upstream.

We are committing ourselves to doing the following:

1. Keep changes mergeable upstream: we want to continue to be good OSS citizens,
   and we intend that all features we add to our Prometheus repository will
   become an upstream PR. We will maintain our repository in a way that supports
   doing this.
2. Always vendor a branch from `grafana/prometheus` based off of a recent Prometheus
   stable release; we want the Agent's Prometheus roots to be stable.
3. Reduce code drift: The code the Agent uses on top of Prometheus will be
   layered on top of a Prometheus release rather than sandwiched in between.
4. Keep the number of experimental changes not merged upstream to a minimum. We're
   not trying to fork Prometheus.

Maintenance of the `grafana/prometheus` repository revolves around feature
branches (named `feat-SOME-FEATURE`) and release branches (named
`release-vX.Y.Z-grafana`). The release branches will always use the same release
version as the `prometheus/prometheus` release it is based off of.

By adding features to the `grafana/prometheus` repository first, we are
committing ourselves to extra maintenance of features that have not yet been
merged upstream. Feature authors will have to babysit their features to
coordinate with the Prometheus release schedule to always be compatible. Maintenance
burden becomes lightened once each feature is upstreamed as breaking changes will
no longer happen out of sync with upstream changes for the respective upstreamed
feature.

We are purposefully carrying this extra burden because we intend to ultimately
make Prometheus better and contribute all of our enhancements upstream. We want
to strive to benefit the Prometheus ecosystem at large.

## Creating a New Feature

Grafana Labs developers should try to get all features upstreamed *first*. If
it's clear the feature is experimental or more unproven than the upstream team
is comfortable with, developers should then create a downstream
`grafana/prometheus` feature branch.

For `grafana/prometheus` maintainers to create a new feature, they will do the
following:

1. Create a feature branch in `grafana/prometheus` based on the latest release
   tag that `grafana/prometheus` currently has a release branch for. The feature
   branch should follow the naming convention `feat-<feature name>`.
2. Implement the feature and open a PR to merge the feature branch into the
   associated `grafana/prometheus` release branch.
3. After updating the release branch, open a PR to update `grafana/agent` to
   use the latest release branch SHA.

## Updating an Existing Feature

If a feature branch that was already merged to a release branch needs to be
updated for any reason:

1. Push directly to the feature branch or open a PR to merge changes into that
   feature branch.
2. Open a PR to merge the new changes from the feature branch into the
   associated release branch.
3. After updating the release branch, open a PR to update `grafana/agent` by
   vendoring the changes using the latest release branch SHA.

## Handling New Upstream Release

When a new upstream `prometheus/prometheus` release is available, we must go
through the following process:

1. Create a new `grafana/prometheus` release branch named
   `release-X.Y.Z-grafana`.
2. For all feature branches still not merged upstream, rebase them on top of the
   newly created branch. Force push them to update the `grafana/prometheus`
   feature branch.
3. Create one or more PRs to introduce the features into the newly created
   release branch.

Once a new release branch has been created, the previous release branch in
`grafana/prometheus` is considered stale and will no longer receive updates.

## Updating the Agent's vendor

The easiest way to do this is the following:

1. Edit `go.mod` and change the replace directive to the release branch name.
2. Update `README.md` in the Agent to change which version of Prometheus
   the Agent is vendoring.
2. Run `go mod tidy -compat=1.17 && go mod vendor`.
3. Commit and open a PR.

## Gotchas

If the `grafana/prometheus` feature is incompatible with the upstream
`prometheus/prometheus` master branch, merge conflicts would prevent
an upstream PR from being merged. There are a few ways this can be handled
at the feature author's discretion:

When this happens, downstream feature branch maintainers should wait until
a new `prometheus/prometheus` release is available and rebase their feature
branch on top of the latest release. This will make the upstream PR compatible
with the master branch, though the window of compatibility is unpredictable
and may change at any time.

If it proves unfeasible to get a feature branch merged upstream within the
"window of upstream compatibility," feature branch maintainers should create
a fork of their branch that is based off of master and use that master-compatible
branch for the upstream PR. Note that this means any changes made to the feature
branch will now have to be mirrored to the master-compatible branch.

## Open Questions

If two feature branches depend on one another, a combined feature branch
(like an "epic" branch) should be created where development of interrelated
features go. All features within this category go directly to the combined
"epic" branch rather than individual branches.

'''
'''--- docs/developer/releasing.md ---
# Releasing

This document describes the process of creating a release for the
`grafana/agent` repo. A release includes release assets for everything inside
the repository, including Grafana Agent and Grafana Agent Operator.

The processes described here are for v0.24.0 and above.

## Release Branches

A release branch is created for every major or minor release. That release
branch is then used for all release candidates, the stable release, and all
patch releases.

For any given release branch, there will be the following tags:

* `vX.Y.0-rc.N`: release candidate N for vX.Y.0. At least one release candidate
  will be made for every release.
* `vX.Y.0`: the stable release for vX.Y.
* `vX.Y.Z`: patch release Z for vX.Y. A release branch may have zero or more
  patch releases.

Release branches follow a `release-v<major>.<minor>` naming convention (i.e.,
`release-v0.24`).

## Releaser Prerequisites

Each maintainer performing a release should perform the following steps once
before performing the release.

### Add Existing GPG Key to GitHub

First, Navigate to your user's
[SSH and GPG keys settings page](https://github.com/settings/keys). If the GPG
key for the email address used to commit is not present, do the following:

1. Run `gpg --armor --export <your email address>`
2. Copy the output.
3. In the settings page linked above, click "New GPG Key".
4. Copy and paste the PGP public key block.

### Signing Commits and Tags by Default

To avoid accidentally publishing a tag or commit without signing it, run the
following to ensure all commits and tags are signed:

```bash
git config --global commit.gpgSign true
git config --global tag.gpgSign true
```

#### macOS Signing Errors

If you are on macOS and using an encrypted GPG key, `gpg-agent` may be unable
to prompt you for your private key passphrase. This will be denoted by an error
when creating a commit or tag. To circumvent the error, add the following into
your `~/.bash_profile` or `~/.zshrc`, depending on which shell you are using:

```
export GPG_TTY=$(tty)
```

## Performing Releases

The lifetime of a release branch is sheparded by a single person, picked from a
rota of project maintainers and contributors. The release shepard is
responsible for managing all releases that compose the release branch.

For a new release branch, the release shepard will:

1. Gather consensus on which commit should be used as a base for the release
   branch.

2. Create and push the release branch from the selected base commit.

3. Create a PR to cherry-pick additional commits into the release branch as
   needed.

4. Create a PR to [update code](#updating-code) for the upcoming release
   candidate. A new section in the changelog should be added for the release
   candidate, documenting all changes introduced by the release candidate.

4. Update the changelog with a new section for the upcoming release candidate,
   documenting changes that will be introduced in that release candidate.

5. Tag the release candidate using the tag naming convention `vX.Y.0-rc.N`.

6. Run the release candidate in a testing environment for at least 48 hours. If
   you do not have a testing environment, one can be spawned locally using the
   sample environments in `example/k3d`.

   During this period, no regressions or critical issues must be found.
   Discovered issues should be fixed via PRs to main. Return to step 3 after
   fixes are available, cherry-picking the fixes into the release branch and
   starting a new release candidate.

7. Create a PR to update code for the upcoming stable release. The changelog
   sections for the release candidates should be replaced with a single section
   for the stable release.

8. Create the stable release tag.

9. Force-push the `release` branch to point at the stable release tag. This
   branch is used to externally reference files in the repository for a stable
   release.

For patch releases, the release shepard will:

1. Create a PR to cherry-pick relevant bug fixes into the release branch.

2. Create a PR to update code for the upcoming patch release. A new changelog
   section should be dded for the patch release.

3. Create the patch release tag.

After the release shepard pushes a new tag, they must [publish the release](#publishing-the-release).

### Updating code

The codebase must be updated whenever a new release is being made to reference
the upcoming release tag:

* Modify `CHANGELOG.md` with a new version number and its release date.
* Go through the entire repository and find references to the previous release
  version, updating them to reference the new version.
* Run `make example-kubernetes` and `make example-dashboards` to update
  manifests in case they are stale.

NOTE: Any time CHANGELOG.md is updated for a release, it should first be done
via PR to the release branch, and then by a second PR to main.

### Merge freezes

Release shepards may request a merge freeze to main for any reason during the
release process.

### Publishing the Release

GitHub Actions will create release assets and open a release draft for every
pushed tag. To publish the release:

1. Go to the [GitHub releases page](https://github.com/grafana/agent/releases)
   and find the drafted release.

2. Edit the drafted release, copying and pasting *notable changes* from the
   CHANGELOG. Add a link to the CHANGELOG, noting that the full list of changes
   can be found there. Refer to other releases for help with formatting this.

3. Optionally, have other team members review the release draft if you wish
   to feel more comfortable with it.

4. Publish the release!

## Maintaining older release branches

Older release branches are maintained on a best-effort basis. The release
shepard for that branch determines whether an older release branch have a new
patch release at their own discretion.

'''
'''--- docs/flow/_index.md ---
---
aliases:
- /docs/agent/latest/flow/
title: Grafana Agent Flow
weight: 900
---

# Grafana Agent Flow (Experimental)

'''
'''--- docs/flow/concepts/_index.md ---
---
aliases:
- /docs/agent/latest/concepts/
title: Concepts
weight: 100
---

# Concepts

'''
'''--- docs/flow/concepts/component_controller.md ---
---
aliases:
- /docs/agent/latest/concepts/component-controller
title: Component controller
weight: 200
---

# Component controller

'''
'''--- docs/flow/concepts/components.md ---
---
aliases:
- /docs/agent/latest/concepts/components
title: Components
weight: 100
---

# Components

'''
'''--- docs/flow/concepts/configuration_language.md ---
---
aliases:
- /docs/agent/latest/concepts/configuration-language
title: Configuration language
weight: 300
---

# Configuration language

'''
'''--- docs/flow/config-language/_index.md ---
---
aliases:
- /docs/agent/latest/flow/configuration-language
title: Configuration language
weight: 400
---

# Configuration language

'''
'''--- docs/flow/config-language/components.md ---
---
aliases:
- /docs/agent/latest/flow/configuration-language/components
title: Components
weight: 300
---

# Components

'''
'''--- docs/flow/config-language/expressions/_index.md ---
---
aliases:
- /docs/agent/latest/flow/configuration-language/expressions
title: Expressions
weight: 400
---

# Expressions

'''
'''--- docs/flow/config-language/expressions/function_calls.md ---
---
aliases:
- /docs/agent/latest/flow/configuration-language/expressions/function-calls
title: Function calls
weight: 400
---

# Function Calls

'''
'''--- docs/flow/config-language/expressions/operators.md ---
---
aliases:
- /docs/agent/latest/flow/configuration-language/expressions/operators
title: Operators
weight: 300
---

# Operators

'''
'''--- docs/flow/config-language/expressions/referencing_outputs.md ---
---
aliases:
- /docs/agent/latest/flow/configuration-language/expressions/referencing-outputs
title: Referencing component exports
weight: 200
---

# Types and Values

'''
'''--- docs/flow/config-language/expressions/types_and_values.md ---
---
aliases:
- /docs/agent/latest/flow/configuration-language/expressions/types-and-values
title: Types and values
weight: 100
---

# Types and values

'''
'''--- docs/flow/config-language/files.md ---
---
aliases:
- /docs/agent/latest/flow/configuration-language/files
title: Files
weight: 100
---

# Files

'''
'''--- docs/flow/config-language/syntax.md ---
---
aliases:
- /docs/agent/latest/flow/configuration-language/syntax
title: Syntax
weight: 200
---

# Syntax

'''
'''--- docs/flow/getting_started.md ---
---
aliases:
- /docs/agent/latest/flow/getting-started
title: Getting started
weight: 200
---

# Getting Started

'''
'''--- docs/flow/monitoring/_index.md ---
---
aliases:
- /docs/agent/latest/flow/monitoring
title: Monitoring Grafana Agent Flow
weight: 500
---

# Monitoring Grafana Agent Flow

'''
'''--- docs/flow/monitoring/component_metrics.md ---
---
aliases:
- /docs/agent/latest/flow/monitoring/component-metrics
title: Component metrics
weight: 200
---

# Component metrics

'''
'''--- docs/flow/monitoring/controller_metrics.md ---
---
aliases:
- /docs/agent/latest/flow/monitoring/controller-metrics
title: Controller metrics
weight: 100
---

# Controller metrics

'''
'''--- docs/flow/monitoring/debugging.md ---
---
aliases:
- /docs/agent/latest/flow/monitoring/debugging
title: Debugging
weight: 300
---

# Debugging

'''
'''--- docs/flow/reference/_index.md ---
---
aliases:
- /docs/agent/latest/flow/reference
title: Reference
weight: 600
---

'''
'''--- docs/flow/reference/cli/_index.md ---
---
aliases:
- /docs/agent/latest/flow/reference/cli
title: Command-line interface
weight: 100
---

'''
'''--- docs/flow/reference/cli/run.md ---
---
aliases:
- /docs/agent/latest/flow/reference/cli/run
title: agent run
weight: 100
---

# `agent run` command

'''
'''--- docs/flow/reference/components/_index.md ---
---
aliases:
- /docs/agent/latest/flow/reference/components
title: Components
weight: 300
---

# Components

'''
'''--- docs/flow/reference/components/local.file.md ---
---
aliases:
- /docs/agent/latest/flow/reference/components/local.file
title: local.file
---

# local.file

`local.file` exposes the contents of a file on disk to other components. The
file will be watched for changes so that its latest content is always exposed.

The most common use of `local.file` is to load secrets (e.g., API keys) from
files.

Multiple `local.file` components can be specified by giving them different
labels.

## Example

```river
local.file "my-file" {
  filename = "path/to/my/file"
}
```

## Arguments

The following arguments are supported:

Name | Type | Description | Default | Required
---- | ---- | ----------- | ------- | --------
`filename` | `string` | Path of the file on disk to watch | | **yes**
`detector` | `string` | Which file change detector to use (fsnotify, poll) | `"fsnotify"` | no
`poll_frequency` | `duration` | How often to poll for file changes | `"1m"` | no
`is_secret` | `bool` | Marks the file as containing a [secret][] | `false` | no

### File change detectors

File change detectors are used for detecting when the file needs to be re-read
from disk. `local.file` supports two detectors: `fsnotify` and `poll`.

#### fsnotify

The `fsnotify` detector subscribes to filesystem events which indicate when the
watched file had been updated. This requires a filesystem which supports events
at the Operating System level: network-based filesystems like NFS or FUSE won't
work.

When a filesystem event is received, the component will reread the watched
file. This will happen for any filesystem event to the file, including a change
of permissions.

`fsnotify` also polls for changes to the file with the configured
`poll_frequency` as a fallback.

`fsnotify` will stop receiving filesystem events if the watched file has been
deleted, renamed, or moved. The subscription will be re-established on the next
poll once the watched file exists again.

#### poll

The `poll` file change detector will cause the watched file to be reread
every `poll_frequency`, regardless of whether the file changed.

## Exported fields

The following fields are exported and can be referenced by other components:

Name | Type | Description
---- | ---- | -----------
`content` | `string` or `secret` | The contents of the file from the most recent read

The `content` field will have the `secret` type only if the `is_secret`
argument was true.

## Component health

`local.file` will be reported as healthy whenever if the watched file was read
successfully.

Failing to read the file whenever an update is detected (or after the poll
period elapses) will cause the component to be reported as unhealthy. When
unhealthy, exported fields will be kept at the last healthy value. The read
error will be exposed as a log message and in the debug information for the
component.

## Debug information

`local.file` does not expose any component-specific debug information.

### Debug metrics

`local.file` does not expose any component-specific debug metrics.

[secret]: ../secrets.md#is_secret-argument-in-components

'''
'''--- docs/flow/reference/components/metrics.scrape.md ---
---
aliases:
- /docs/agent/latest/flow/reference/components/metrics.scrape
title: metrics.scrape
---

# metrics.scrape

`metrics.scrape` configures a metrics scraping job for a given set of
`targets`. The scraped metrics are forwarded to the list of receivers passed in
`forward_to`.

Multiple `metrics.scrape` components can be specified by giving them different
labels.

## Example

The following example will set up the job with certain attributes (scrape
intervals, query parameters) and let it scrape two instances of the blackbox
exporter. The received metrics will be sent over to the provided list of
remote_writes, as defined by other components.

```river
metrics.scrape "blackbox-scraper" {
  targets = [
    {"__address__" = "blackbox-exporter:9115", "instance" = "one"},
    {"__address__" = "blackbox-exporter:9116", "instance" = "two"},
  ]
  forward_to = [metrics.remote_write.grafanacloud.receiver, metrics.remote_write.onprem.receiver]

  scrape_config {
    job_name        = "grafana"
    scrape_interval = "10s"
    params          = { "target" = ["grafana.com"], "module" = ["http_2xx"]}
    metrics_path    = "/probe"
  }
}
```

## Arguments

The following arguments are supported:

Name | Type | Description | Default | Required
---- | ---- | ----------- | ------- | --------
`targets` | `list(map(string))` | Targets to scrape | | **yes**
`forward_to` | `list(MetricsReceiver)` | List of receivers to send scraped metrics to | | **yes**
`extra_metrics` | `bool` | Whether extra metrics should be generated for scrape targets | `false` | no

The following subblocks are supported:

Name | Description | Required
---- | ----------- | --------
[`scrape_config`](#scrape_config-block) | Configures how metrics will be collected from the targets | **yes**

### `scrape_config` block

The user must provide one `scrape_config` block; it will configure and start a
new scrape job to scrape all of the input targets. The list of arguments that
can be used to configure the block is presented below.

All arguments except for `job_name` are optional and any omitted fields will
take on their default values. In case that conflicting attributes are being
passed (eg. defining both a BearerToken and BearerTokenFile or configuring both
Basic Authorization and OAuth2 at the same time), the scrape job will not be
created.

Name                       | Type       | Description | Default | Required
-------------------------- | ---------- | ----------- | ------- | --------
`job_name`                 | `string`   | The job name to which the job label is set by default. | | **yes**
`honor_labels`             | `bool`     | Indicator whether the scraped metrics should remain unmodified. | false | no
`honor_timestamps`         | `bool`     | Indicator whether the scraped timestamps should be respected. | true | no
`params`                   | `map(list(string))` | A set of query parameters with which the target is scraped. | | no
`scrape_interval`          | `duration` | How frequently to scrape the targets of this scrape config. | `"60s"` | no
`scrape_timeout`           | `duration` | The timeout for scraping targets of this config. | `"10s"` | no
`metrics_path`             | `string`   | The HTTP resource path on which to fetch metrics from targets. | `/metrics` | no
`scheme`                   | `string`   | The URL scheme with which to fetch metrics from targets. | | no
`body_size_limit`          | `int`      | An uncompressed response body larger than this many bytes will cause the scrape to fail. 0 means no limit. | | no
`sample_limit`             | `uint`     | More than this many samples post metric-relabeling will cause the scrape to fail | | no
`target_limit`             | `uint`     | More than this many targets after the target relabeling will cause the scrapes to fail. | | no
`label_limit`              | `uint`     | More than this many labels post metric-relabeling will cause the scrape to fail. | | no
`label_name_length_limit`  | `uint`     | More than this label name length post metric-relabeling will cause the | | no
`label_value_length_limit` | `uint`     | More than this label value length post metric-relabeling will cause the scrape to fail. | | no
`basic_auth`               | `basic_auth` block    | Setup of Basic HTTP authentication credentials. | | no
`authorization`            | `authorization` block | Setup of HTTP Authorization credentials. | | no
`oauth2`                   | `oauth2` block        | Setup of the OAuth2 client. | | no
`tls_config`               | `tls_config` block    | Configuration options for TLS connections. | | no
`bearer_token`             | `secret`   | Used to set up the Bearer Token. | | no
`bearer_token_file`        | `string`   | Used to set up the Bearer Token file. | | no
`proxy_url`                | `string`   | Used to set up a Proxy URL. | | no
`follow_redirects`         | `bool`     | Whether the scraper should follow redirects. | `true` | no
`enable_http_2`            | `bool`     | Whether the scraper should use HTTP2. | | no

The following subblocks are supported:

Name | Description | Required
---- | ----------- | --------
[`basic_auth`](#basic_auth-block) | Configures basic_auth for authenticating against targets | no
[`authorization`](#authorization-block) | Configures generic authentication against targets | no
[`oauth2`](#oauth2-block) | Configures OAuth2 for authenticating against targets | no
[`tls_config`](#tls_config-block) | Configures TLS settings for connecting to targets | no

#### `basic_auth` block

Name          | Type     | Description                                     | Default | Required
--------------| -------- | ----------------------------------------------- | ------- | -------
username      | string   | Setup of Basic HTTP authentication credentials. |         | no
password      | secret   | Setup of Basic HTTP authentication credentials. |         | no
password_file | string   | Setup of Basic HTTP authentication credentials. |         | no

#### `authorization` block

Name                | Type     | Description                              | Default | Required
------------------- | -------- | -----------------------------------------| ------- | --------
type                | string   | Setup of HTTP Authorization credentials. |         | no
credential          | secret   | Setup of HTTP Authorization credentials. |         | no
credentials_file    | string   | Setup of HTTP Authorization credentials. |         | no

#### `oauth2` block

Name               | Type             | Description                              | Default | Required
------------------ | ---------------- | -----------------------------------------| ------- | --------
client_id          | string           | Setup of the OAuth2 client.              |         | no
client_secret      | secret           | Setup of the OAuth2 client.              |         | no
client_secret_file | string           | Setup of the OAuth2 client.              |         | no
scopes             | list(string)     | Setup of the OAuth2 client.              |         | no
token_url          | string           | Setup of the OAuth2 client.              |         | no
endpoint_params    | map(string)      | Setup of the OAuth2 client.              |         | no
proxy_url          | string           | Setup of the OAuth2 client.              |         | no
tls_config         | tls_config block | Setup of TLS options.                    |         | no

#### `tls_config` block

Name                            | Type     | Description                                | Default | Required
------------------------------- | -------- | ------------------------------------------ | ------- | --------
tls_config_ca_file              | string   | Configuration options for TLS connections. |         | no
tls_config_cert_file            | string   | Configuration options for TLS connections. |         | no
tls_config_key_file             | string   | Configuration options for TLS connections. |         | no
tls_config_server_name          | string   | Configuration options for TLS connections. |         | no
tls_config_insecure_skip_verify | bool     | Configuration options for TLS connections. |         | no

## Exported fields

`metrics.scrape` does not export any fields that can be referenced by other
components.

## Component health

`metrics.scrape` will only be reported as unhealthy when given an invalid
configuration.

## Debug information

`metrics.scrape` reports the status of the last scrape for each configured
scrape job on the component's debug endpoint.

### Debug metrics

`metrics.scrape` does not expose any component-specific debug metrics.

'''
'''--- docs/flow/reference/components/remote.s3.md ---
---
aliases:
- /docs/agent/latest/flow/reference/components/remote.s3
title: remote.s3
---

# remote.s3

`remote.s3` exposes the contents of a file located in an S3 compatible system
to other components. The file will be polled for changes so that the most
recent content is always available.

Multiple `remote.s3` components can be specified by giving them different name
labels. By default, AWS environment variables are used to authenticate against
S3. The `key` and `secret` arguments can be used to provide custom
authentication.

## Example

```river
remote.s3 "data" {
  path = "s3://test-bucket/file.txt"
}
```

## Arguments

The following arguments are supported:

Name | Type | Description                                                             | Default | Required
---- | ---- |-------------------------------------------------------------------------| ------- | --------
`path` | `string` | Path in the format of `"s3://bucket/file"` | | **yes**
`poll_frequency` | `duration` | How often to poll the file for changes, must be greater than 30 seconds | `"10m"` | no
`is_secret` | `bool` | Marks the file as containing a [secret][] | `false` | no

The following subblocks are supported:

Name | Description | Required
---- | ----------- | --------
[`client_options`](#client_options) | Additional options for configuring the S3 client | no

### `client_options` block

Name | Type | Description | Default | Required
---- | ---- | ----------- | ------- | --------
`key` | `string` | Used to override default access key | | no
`secret` | `secret` | Used to override default secret | | no
`endpoint` | `string` | Endpoint specifies a custom url to access, used generally for S3 compatible systems | | no
`disable_ssl` | `bool` | Used to disable SSL, generally used for testing | | no
`use_path_style` | `string` | Path style is a deprecated that is generally enabled for S3 compatible systems | `false` | no
`region` | `string` | Used to override default region | | no

## Exported fields

The following fields are exported and can be referenced by other components:

Name | Type | Description | Default | Required
---- | ---- | ----------- | ------- | --------
`content` | `string` or `secret` | The contents of the file | | no

The `content` field will be secret is `is_secret` was set.

## Component health

Instances of `remote.s3` will reported as healthy if the most recent read of
the watched file succeeded.

## Debug information

`remote.s3` does not expose any component-specific debug information.

### Debug metrics

`remote.s3` does not expose any component-specific debug metrics.

[secret]: ../secrets.md#is_secret-argument-in-components

'''
'''--- docs/flow/reference/components/targets.mutate.md ---
---
aliases:
- /docs/agent/latest/flow/reference/components/targets.mutate
title: targets.mutate
---

# targets.mutate

`targets.mutate` rewrites the label set of the input targets by applying one or
more `relabel_config` steps. If no relabeling steps are defined, then the input
targets will be exported as-is.

The most common use of `targets.mutate` is to filter Prometheus targets or
standardize the label set that will be passed to a downstream component. The
`relabel_config` blocks will be applied to the label set of each target in
order of their appearance in the configuration file.

Multiple `targets.mutate` components can be specified by giving them different
labels.

## Example

```river
targets.mutate "keep-backend-only" {
  targets = [
    { "__meta_foo" = "foo", "__address__" = "localhost", "instance" = "one",   "app" = "backend"  },
    { "__meta_bar" = "bar", "__address__" = "localhost", "instance" = "two",   "app" = "database" },
    { "__meta_baz" = "baz", "__address__" = "localhost", "instance" = "three", "app" = "frontend" }
  ]

  relabel_config {
    source_labels = ["__address__", "instance"]
    separator     = "/"
    target_label  = "destination"
    action        = "replace"
  }

  relabel_config {
    source_labels = ["app"]
    action        = "keep"
    regex         = "backend"
  }
}
```

## Arguments

The following arguments are supported:

Name | Type | Description | Default | Required
---- | ---- | ----------- | ------- | --------
targets | list(map(string)) | Targets to mutate | | **yes**

The following subblocks are supported:

Name | Description | Required
---- | ----------- | --------
[`relabel_config`](#relabel_config-block) | Mutations to apply to targets | no

### `relabel_config` block

The `relabel_config` block contains the definition of any relabeling rules that
can be applied to an input target. If more than one `relabel_config` block is
defined within `targets.mutate`, the transformations will be applied in-order
from top down.

The following arguments can be used to configure a `relabel_config` block.
All arguments are optional and any omitted fields will take on their default
values.

Name | Type | Description | Default | Required
---- | ---- | ----------- | ------- | --------
source_labels | list(string) | The list of labels whose values should be selected. Their content is concatenated using the `separator` and matched against `regex`. | | no
separator     | string       |  The separator used to concatenate the values present in `source_labels`. | ; | no
regex         | string       | A valid RE2 expression with support for parenthesized capture groups. Used to match the extracted value from the combination of the `source_label` and `separator` fields or filter labels during the labelkeep/labeldrop/labelmap actions. | `(.*)` | no
modulus       | uint         | A positive integer used to calculate the modulus of the hashed source label values. | | no
target_label  | string       | Label to which the resulting value will be written to. | | no
replacement   | string       | The value against which a regex replace is performed, if the regex matched the extracted value. Supports previously captured groups. | $1 | no
action        | string       | The relabeling action to perform. | replace | no

Here's a list of the available actions along with a brief description of their usage.

* replace - This action matches `regex` to the concatenated labels. If there's a match, it replaces the content of the `target_label` using the contents of the `replacement` field.
* keep    - This action only keeps the targets where `regex` matches the string extracted using the `source_labels` and `separator`.
* drop    - This action drops the targets where `regex` matches the string extracted using the `source_labels` and `separator`.
* hashmod - This action hashes the concatenated labels, calculates its modulo `modulus` and writes the result to the `target_label`.
* labelmap  - This action matches `regex` against all label names. Any labels that match will be renamed according to the contents of the `replacement` field.
* labeldrop - This action matches `regex` against all label names. Any labels that match will be removed from the target's label set.
* labelkeep - This action matches `regex` against all label names. Any labels that don't match will be removed from the target's label set.

Finally, note that the regex capture groups can be referred to using either the `$1` or `$${1}` notation.

## Exported fields

The following fields are exported and can be referenced by other components:

Name | Type | Description
---- | ---- | -----------
output | list(map(string)) | The set of targets after applying relabeling.

## Component health

`targets.mutate` will only be reported as unhealthy when given an invalid
configuration. In those cases, exported fields will be kept at their last
healthy values.

## Debug information

`targets.mutate` does not expose any component-specific debug information.

### Debug metrics

`targets.mutate` does not expose any component-specific debug metrics.

'''
'''--- docs/flow/reference/config-blocks/_index.md ---
---
aliases:
- /docs/agent/latest/flow/reference/config-blocks
title: Configuration blocks
weight: 200
---

# Configuration blocks

'''
'''--- docs/flow/reference/config-blocks/logging.md ---
---
aliases:
- /docs/agent/latest/flow/reference/config-blocks/logging
title: logging
weight: 100
---

# `logging` block

'''
'''--- docs/flow/reference/flags.md ---
---
aliases:
- /docs/agent/latest/flow/reference/command-line-flags
title: Command-line flags
weight: 100
---

# Command-line flags

'''
'''--- docs/flow/reference/stdlib/_index.md ---
---
aliases:
- /docs/agent/latest/flow/reference/standard-library
title: Standard library
weight: 400
---

# Standard library

> Grafana Agent Flow is still growing, and its standard library isn't mature
> yet. If you have a request for for extensions to the standard library, please
> leave feedback on our dedicated [GitHub discussion for River
> feedback][feedback].

The standard library is a list of functions which can be used in expressions
when assigning values to attributes.

All standard library functions are idempotent: they will always return the same
output if given the same input.

* [`concat`]({{< relref "./concat.md" >}})
* [`env`]({{< relref "./env.md" >}})
* [`json_decode`]({{< relref "./json_decode.md" >}})

[feedback]: https://github.com/grafana/agent/discussions/1969

'''
'''--- docs/flow/reference/stdlib/concat.md ---
---
aliases:
- /docs/agent/latest/flow/configuration-language/standard-library/concat
title: concat
---

# `concat` Function

`concat` concatenates one or more lists of values into a single list. Each
argument to `concat` must be a list value. Elements within the list can be any
type.

## Examples

```
> concat([])
[]

> concat([1, 2], [3, 4])
[1, 2, 3, 4]

> concat([1, 2], [], [bool, null])
[1, 2, bool, null]

> concat([[1, 2], [3, 4]], [[5, 6]])
[[1, 2], [3, 4], [5, 6]]
```

'''
'''--- docs/flow/reference/stdlib/env.md ---
---
aliases:
- /docs/agent/latest/flow/configuration-language/standard-library/env
title: env
---

# `env` Function

`env` gets the value of an environment variable from the system Grafana Agent
is running on. If the environment variable does not exist, `env` returns an
empty string.

## Examples

```
> env("HOME")
"/home/grafana-agent"

> env("DOES_NOT_EXIST")
""
```

'''
'''--- docs/flow/reference/stdlib/json_decode.md ---
---
aliases:
- /docs/agent/latest/flow/configuration-language/standard-library/json_decode
title: json_decode
---

# `json_decode` Function

`json_decode` decodes a string representing JSON into a River value.
`json_decode` will fail if the string argument provided cannot be parsed as
JSON.

A common use case of `json_decode` is to decode the output of a
[`local.file`][] component to a River value.

> Remember to escape double quotes when passing JSON string literals to `json_decode`.
>
> For example, the JSON value `{"key": "value"}` is properly represented by the
> string `"{\"key\": \"value\"}"`.

## Examples

```
> json_decode("15")
15

> json_decode("[1, 2, 3]")
[1, 2, 3]

> json_decode("null")
null

> json_decode("{\"key\": \"value\"}")
{
  key = "value",
}

> json_decode(local.file.some_file.contents)
"Hello, world!"
```

[`local.file`]: {{< relref "../../components/local.file.md" >}}

'''
'''--- docs/flow/tutorials/_index.md ---
---
aliases:
- /docs/agent/latest/flow/tutorials
title: Tutorials
weight: 300
---

# Tutorials

'''
'''--- docs/flow/tutorials/prometheus-metrics.md ---
---
aliases:
- /docs/agent/latest/flow/tutorials/prometheus-metrics
title: Collecting and sending Prometheus metrics
weight: 200
---

# Collecting and sending Prometheus metrics

'''
'''--- docs/flow/tutorials/your-first-component.md ---
---
aliases:
- /docs/agent/latest/flow/tutorials/your-first-component
title: Your first component
weight: 100
---

# Tutorials

'''
'''--- docs/rfcs/0000-template.md ---
# Title

* Date: YYYY-MM-DD
* Author: Full Name (@github_username)
* PR: [grafana/agent#XXXX](https://github.com/grafana/agent/pull/XXXX)
* Status: Draft

'''
'''--- docs/rfcs/0001-designing-in-the-open.md ---
# Designing in the Open

* Date: 2021-11-02
* Author: Robert Fratto (@rfratto)
* PR: [grafana/agent#1055](https://github.com/grafana/agent/pull/1055)
* Status: Implemented

## Summary

Many open source projects start behind closed doors, where it's designed,
prototyped, and tested before being released publicly. This can be true
regardless of why the project is being made; even personal side projects likely
start by someone designing alone.

Meanwhile, many open source projects might want to create a community of
developers. Much of the beauty of succesful open source projects originates
from the varied backgrounds of its contributors: different people with
different use cases combining together to make a widely useful piece of
software.

However, even with an intent to foster a community of developers, it's natural
to accidentally build a habit from the closed-door design process. Even when
once-private proposals are made public, potential external contributors can
find themselves simply as spectators:

* Initial design is gated to core maintainers, in particular if they all work
  for the same company. This leaves less room for new people to help out.
* New concerns are less impactful if the proposal already receieved core
  maintainer consensus.
* Historical proposals with context and discussions become hard to find.

I believe it takes a deliberate inversion of process to foster community
participation. This document proposes how Grafana Agent will utilize public
spaces for its primary home for future design proposals.

## Goals

* Outline options for proposing changes to Grafana Agent
* Lower the barrier to entry for interested parties to become maintainers

## Non-Goals

* Enforce that every change originates from a fully public proposal or
  discussion. While all maintainers and contributors will be encouraged to
  design openly, there may be legal, security, privacy, or business reasons
  that prevent some or all context from being made public.

* Be overly prescriptive: too many rules can hinder adoption of a process. This
  document outlines intention, not hard policy.

## Proposal

Public proposals may take one of two forms:

* Issue proposals
* RFC PR proposals (e.g., this document)

### Issues

Issues are the quickest path towards proposing a change. Issue proposals must
be opened at the [grafana/agent issues page](https://github.com/grafana/agent/issues).

There are no strict set of rules for issue-based proposals, but authors are
recommended to prefix the issue title with `Proposal:` so it may be found more
easily.

### RFC PRs

RFC PR proposals must at least:

* Be placed in the `docs/rfcs` folder of the `grafana/agent` repository
* Have a lowercase filename in hyphen-case with an `.md` extension
* Prefix the filename with the RFC ID
  * ID `xxxx` may be initially used until the final ID is known
* Contain valid markdown
* Start with the title of the proposal
* Contain a bullet point list of metadata of:
  * The date the proposal was written
  * The list of authors, with their names and GitHub usernames
  * The PR where the proposal was posted
  * The status of the proposal

`0000-template.md` contains a template to use for writing proposals that
conforms to these rules.

The remainder of the proposal may be formatted however the author wishes. Some
example sections in the RFC may be:

* Summary: What is the background that lead to this proposal?
* Goals: What are the main goals of the proposal?
* Non-Goals: What _aren't_ the main goals of the proposal?
* Proposal: What is the proposal?
* Pros/Cons:
  * Pros: What are the upsides to this proposal?
  * Cons: What are the downsides to this proposal?
* Considered Alternatives: Why is this proposal the best path forward? What
  were the alternatives?
* Open Questions: What questions still need to be answered?
* Prior Art: What was this proposal based on, if anything?

#### RFC Status

The "Status" field of an RFC must be one of the following:

* Draft: This RFC is a work-in-progress and may change
* Implemented: Relevant code for this RFC has been merged to the main branch
* Deprecated: This RFC is no longer relevant to the current state of the
  project

RFCs may be merged in Draft state as work on them progresses. The _Draft_ state
is intended to signal to readers that an RFC is in flux. Once all relevant code
for an RFC is merged to main, the RFC may move to the _Implemented_ status.
RFCs without code, such as this RFC, may immediately be set as Implemented.

If, for any reason, an RFC becomes no longer relevant (deprecated by another
RFC, code removed, etc.), its status should move to Deprecated.

#### RFC Review

RFCs should be opened as a PR to grafana/agent, ideally prefixed in the PR
title with `RFC:` to easily identify it amongst other PRs.

### Google Docs Proposals

Google Docs may be useful for early feedback rounds during a proposal. However,
it is not recommended for the permanent home of a proposal:

* Change and comment history may not be available to all viewers.

* The file owner may delete the proposal, leading to a gap in historical
  context.

Google Docs proposals will be permitted if linked to from an issue proposal.
Google Doc proposals must be converted into an RFC proposal prior to formally
accepting the proposal. Enforcing this ensures that historical context is
recorded, though it is still not ideal as it discards comment history.

## Accepting Proposals

All readers are encouraged to engage in reviewing proposals. However, whether a
proposal is accepted is determined by [rough consensus][] of the Grafana Agent
governance team. External contributors may eventually be invited to [join the
governance team][governance] if they have a history of making ongoing
contributions to the project or community.

## Considered alternatives

A few existing public proposal processes have been examined for inspiration:

* [IETF's RFCs](https://www.ietf.org/standards/rfcs/)
* [Rust's RFCs](https://github.com/rust-lang/rfcs)
* [Joyent's Requests for Discussions](https://github.com/joyent/rfd)
* [OpenTelemetry's OTEPs](https://github.com/open-telemetry/oteps)
* [Kubernetes Enhancement Proposals (KEPs)](https://github.com/kubernetes/enhancements)

All of these processes are similar, but in the end, the current objective is to
start collecting proposals publicly rather than to be prescriptive yet.

[rough consensus]: https://github.com/grafana/agent/blob/main/GOVERNANCE.md#technical-decisions
[governance]: https://github.com/grafana/agent/blob/main/GOVERNANCE.md#team-members

'''
'''--- docs/rfcs/0002-integrations-in-operator.md ---
# Integrations in Grafana Agent Operator

* Date: 2022-01-04
* Author: Robert Fratto (@rfratto)
* PR: [grafana/agent#1224](https://github.com/grafana/agent/pull/1224)
* Status: Draft

## Background

Grafana Agent includes support for integrations, which are intended as
"batteries-included" features to assist with collecting telemetry data. With
the `integrations-next` feature enabled, there are multiple types of
integrations:

* Integrations that generate metrics (i.e., `node_exporter`)
* Integrations that generate logs (i.e., `eventhandler`)
* Integrations that generate other types of telemetry are planned (i.e., an
  upcoming `app_agent_receiver`)

Generically, an integration is a specialized telemetry collector for some
system under observation. For example, a `redis` integration collects telemetry
for Redis. Integrations can generate any combination of Prometheus metrics,
Grafana Loki logs, or Grafana Tempo traces.

This document proposes adding a way to add support for all current and future
integrations into the Grafana Agent Operator.

This proposal supersedes [#883][], which was the first attempt at designing the
feature. This proposal takes advantage of the lessons I've learned and
minimizes the implementation effort.

## Goals

* Allow Grafana Agent Operator to deploy integrations
* Allow deployed integrations to write telemetry data
* Support integrations that must exist on every machine (i.e., `node_exporter`)
* Minimize development effort for creating new integrations

## Non-Goals

* Support externally collecting metrics from integrations

## Proposal

At a high level, the proposal is to:

* Define a new `Integration` CRD which specifies a single instance of an
  integration to run.
* Update `GrafanaAgent` to discover `Integration`s and run integrations.

## Architecture

### Running integrations

The new CRD, Integration, will be used for supporting all current integrations.
The spec of Integration primarily revolves around three fields:

* `name`: The name of the integration (e.g., `node_exporter`, `mysqld_exporter`)
* `type`: Information about the integration being deployed
* `config`: YAML configuration block for the integration

The `type` field is an object with the following fields:

* `allNodes`: True when the `name` integration should run on all Kubernetes
  Nodes.
* `unique`: True when the `name` integration must be unique across a
  GrafanaAgent resource hierarchy.

> Example of a valid integration:
>
> ```yaml
> apiVersion: monitoring.grafana.com/v1alpha1
> kind: Integration
> metadata:
>   name: mysql
>   namespace: default
> spec:
>   name: mysqld_exporter
>   type:
>     allNodes: false # optional; false is default
>     unique:   false # optional; false is default
>   config:
>     data_source_name: root@(mysql.default:3306)/
>     disable_collectors: [slave_status]
> ```

GrafanaAgent will be updated to discover Integrations as part of its resource
hierarchy. During reconcile, the following Kubernetes objects will be deployed:

* One DaemonSet and Secret if there is at least one integration in the resource
  hierarchy where `type.allNodes` is true.

* One Deployment and Secret if there is at least one integration in the
  resource hierarchy where `type.allNodes` is false.

Secrets hold the generated Grafana Agent configuration; a Secret is used as
integration configs may contain credentials.

**NOTE**: As this functionality depends on [#1198][], integration pods will
always be deployed with the experimental feature flag
`-enable-feature=integrations-next` enabled. This also means that operator
support for integrations requires a release of the agent where that
experimental feature is available.

### Integration validation

The initial implementation of integrations support will have no knowledge of
what integrations exist. As a result, the `spec.type` and `spec.config` fields
for an Integration MUST be configured correctly for an integration to work.
Users must refer to documentation to discover how `type` should be configured
for their specific integration, and what settings are valid for the `config`
block. Configuration errors will only surface as runtime errors from the
deployed agent.

Future versions of the Operator may:

* Add knowledge for some integrations and validate `type` and `config`
  accordingly (though breaking changes to the config at the Agent level may
  introduce extra complexity to this).

* Update the `status` field of the root GrafanaAgent resource during reconcile
  to expose any reconcile or runtime errors.

### Additional settings for the Integration CRD

Some integrations may require changes to the deployed Pods to function
properly. Integrations will additionally support declaring `volumes`,
`volumeMounts`, `secrets` and `configMaps`. These fields will be merged with
the fields of the same name from the root GrafanaAgent resource when creating
integration pods:

> ```yaml
> apiVersion: monitoring.grafana.com/v1alpha1
> kind: Integration
> metadata:
>   name: kafka
>   namespace: default
> spec:
>   name: kafka_exporter
>   config: |
>     ca_file: /etc/grafana-agent/secrets/kafka-ca-file
>     # ...
>   # Same "secrets" field present in GrafanaAgent.spec, where each secret
>   # is loaded from the same namespace and gets exposed at
>   # /etc/grafana-agent/secrets/<secret name>
>   secrets: [kafka-ca-file]
> ```

### Sending telemetry from integrations

Because the operator will not have any knowledge about individual integrations, it
also doesn't know how integrations generate telemetry data. Users must manally
configure an integration to send its data to the appropriate instance.

Users can refer to MetricsInstances and LogsInstance from the same resource
hierarchy by `<namespace>/<name>` in their integration configs. This
configuring `autoscrape` for collecting metrics from an exporter-based
integration.

Given the following following resource hierarchy:

> ```yaml
> apiVersion: monitoring.grafana.com/v1alpha1
> kind: GrafanaAgent
> metadata:
>   name: grafana-agent-example
>   namespace: default
>   labels:
>     app: grafana-agent-example
> spec:
>   metrics:
>     instanceSelector:
>       matchLabels:
>         agent: grafana-agent-example
>   integrations:
>     instanceSelector:
>       matchLabels:
>         agent: grafana-agent-example
> ---
> apiVersion: monitoring.grafana.com/v1alpha1
> kind: MetricsInstance
> metadata:
>   name: primary
>   namespace: default
>   labels:
>     app: grafana-agent-example
> spec:
>   remoteWrite:
>   - url: http://prometheus:9090/api/v1/write
> ---
> apiVersion: monitoring.grafana.com/v1alpha1
> kind: Integration
> metadata:
>   name: mysql
>   namespace: default
>   labels:
>     app: grafana-agent-example
> spec:
>   name: mysqld_exporter
>   config:
>     autoscrape:
>       enable: true
>       # MetricsInstance <namespace>/<name> to send metrics to
>       metrics_instance: default/primary
>     data_source_name: root@(mysql.default:3306)/
>     disable_collectors: [slave_status]
> ```

the Operator would generate the following agent config:

```yaml
metrics:
  configs:
  - name: default/primary
    remote_write:
    - url: http://prometheus:9090/api/v1/write
integrations:
  mysqld_exporter_configs:
  - autoscrape:
      enable: true
      metrics_instance: default/primary
    data_source_name: root@(mysql.default:3306)/
    disable_collectors: [slave_status]
```

All integrations support some way of self-collecting their telemetry data. In
the future, Integrations that support metrics could support being collected by
an external source (i.e., a MetricsInstance). This is out of scope of this
proposal, as we are focusing on lowest-common-denominator support for all
integrations first.

Note that the Integration config above is only contextually valid: it is only
valid if it is part of a resource hierarchy where a `default/primary`
MetricsInstance exists. This makes it impossible for an Integration to be fully
validated indepently of the resource hierarchy where it is discovered.

## Pros/Cons

Despite its limitations, this specific implementation is proposed for its
simplicity. Its issues with validation can be resolved in the future without
needing to change the CRD or introduce new CRDs.

Pros:

* Works for all known integrations
* Supports future work for custom validation logic
* No changes needed to support future integrations
* You do not have to update the operator to use new integrations

Cons:

* Users must know use documentation to configure `type` and `config` properly.
* Without validation, configuration errors can be hard to debug.
* An Integration may be discovered as part of two resource hierarchies, but
  refer to a MetricsInstance that exists in one hierarchy but not the other.

## Alternatives considered

### Do nothing

Instead of adding support for integrations, users could be expected to deploy
exporters though custom means (i.e., a `node_exporter` Helm chart +
ServiceMonitor).

Pros:

* Requires no additional effort to implement
* Metrics can be scraped by any MetricsInstance
* Feels like a natural fit for Kubernetes' deployment model

Cons:

* Prevents non-exporter integrations from working (i.e., `eventhandler` has no
  separate container that can be run indepently)
* Prevents us from making agent-specific changes on top of exporters
* Requires different documentation for people using the node_exporter
  integration vs deploying the actual node_exporter

### One CRD per integration

Instead of a generic CRD, we could have CRD per supported integration.

Pros:

* Allows creating Kubernetes-specific config schemas for integrations
* Can be validated at the CRD level

Cons:

* Operator must be updated whenever a new integration is added
* Adds extra development effort for creating new integrations
* Requires custom config mapping code for each integration
* Breaking changes to Grafana Agent can break the translation of the CRD to
  Agent config.
  * This is true for the current proposal, but in the current proposal you can
    fix the error in the Integration resource, while a custom CRD would need a
    new operator version to fix the translation.

[#883]: https://github.com/grafana/agent/issues/883
[#1198]: https://github.com/grafana/agent/pull/1198

'''
'''--- docs/rfcs/0003-new-metrics-subsystem.md ---
# New metrics subsystem

* Date: 2021-11-29
* Author: Robert Fratto (@rfratto)
* PR: [grafana/agent#1140](https://github.com/grafana/agent/pull/1140)
* Status: Draft

## Background

There are several open issues discussing major changes to the metrics
subsystem:

* [#872][#872]: Per-target sharding
* [#873][#873]: Reduce operational modes
* [#875][#875]: Introduce agent-wide clustering mechanism
* [#888][#888]: Remove internal instance manager system

These are significant changes to the code base. With the exception of #872, all
of the changes are mainly to reduce technical debt. The implementation effort
and lack of end-user benefits make them hard to schedule, despite being
genuinely beneficial for the maintenance of the project.

This proposal suggests a redesign of the metrics subsystem which has native
support for target sharding and lacks the technical debt from the current
subsystem.

## Goals

* Enable dynamically target scraping with:
  * Automatic scaling
  * Automatic failover
  * Target distribution

## Non-Goals

* Interaction with this new subsystem from existing subsystems
* Utilization of the configuration management API

## Implementation

Given the size of the change, work on the new subsystem should be done in a new
package (e.g., `pkg/metrics/next`), and exposed as an experimental change
hidden behind a feature flag (e.g., `--enable-features=metrics-next`).

## Design

The existing metrics subsystem is focused around a runtime-configurable Metrics
Instance system. Metrics Instances are primarily sourced from the config file
(through the `metrics.configs` array), but can also be dynamically added when
using integrations or the scraping service.

The new metrics subsystem break Metrics Instances up into multiple co-operating
parts:

1. [Discoverers](#Discoverers)
2. [Scrapers](#Scrapers)
3. [Senders](#Senders)

A Metrics Instance still exists conceptually, and is configured as normal
through the `metrics.configs` array. However, there will no longer be an
internal CRUD interface for dynamically managing them.

Finally, an agent-wide clustering mechanism will be added. This clustering
mechanism will allow agents to be aware of other running agents, and will
expose methods for an individual agent to determine ownership of a resource.
The [Clustering](#Clustering) section will describe how this works in detail.

All agents in the cluster will implement Discovers, Scrapers, and Senders.

```
                         +------------+ +------------+
Scrape Configs           | Config  A  | |  Config  B |
                         +------------+ +------------+
                                \              /
(1) SD Distribution              +------------/-------------+
                            v----------------+               \
                         +------------+ +------------+ +------------+
(2) Discoverers          |  Agent  A  | |  Agent  B  | |  Agent  C  |
                         +------------+ +------------+ +------------+
                             \    \                         /
(3) Target Distribution       +----+---------+-------------/---+
                            v-----------------\-----------+     \
                         +------------+ +------------+ +------------+
(4) Scrapers & Senders   |  Agent  A  | |  Agent  B  | |  Agent  C  |
                         +------------+ +------------+ +------------+

+============================================================+
||                                                          ||
|| (1) scrape_configs from runtime config are distributed   ||
||     amongst agents. Agent A owns Config B. Agent C owns  ||
||     Config A.                                            ||
||                                                          ||
|| (2) Agents perform service discovery for scrape configs. ||
||                                                          ||
|| (3) Agents partition discovered targets amongst cluster. ||
||     Agent A finds targets for Agent B and C. Agent C     ||
||     finds targets for Agent A.                           ||
||                                                          ||
|| (3) Agents partition discovered targets amongst cluster. ||
|| (4) Agents scrape targets from partitions they were sent ||
||     and write metrics to WAL which is picked up by       ||
||     remote_write.                                        ||
||                                                          ||
+===========================================================+
```

### Discoverers

Discoverers discover Prometheus targets and distribute them to Scrapers across
the cluster. There is one Discoverer per Metrics Instance in the
`metrics.configs` array from the agent's runtime config.

Each Discoverer runs a single Prometheus SD manager. The Discoverer will be
launched only with the set of SD jobs that the local agent owns, using the job
name as the ownership key. This introduces one layer of sharding, where each SD
job will only have one agent responsible for it. Note that relabeling rules are
not applied by the Discoverer.

Discovered targets are flushed to Scrapers in multiple partitions. Partitions
contain a set of targets owned by the same agent in the cluster, and introduces
the second (and last) layer of sharding, where each target will only have one
agent responsible for it. Partitions also include the Metrics Instance name,
since the same job may exist across multiple instances. The `__address__` label
from the target is used as the ownership key. Once all partitions are created,
they are sent to the corresponding agents over gRPC. Partitions that are owned
by the same agent as the Discoverer may be sent through a non-network
mechanism.

A partition will be created and sent to all agents in the cluster, even if the
partition is empty. This allows agents to know when they can stop scraping
something from a previous received partition.

Discovered targets will be re-flushed whenever the set of agents in the cluster
changes.

### Scrapers

Scrapers receive Prometheus targets from a Discoverer and scrape them,
appending scraped metrics to a Sender.

Specifically, Scrapers manage a dynamic set of Prometheus scrape managers. One
scrape manager will exist per instance that has a non-empty target partition.
Scrape managers will then be configured with the scrape jobs (including
relabeling rules) if they received at least one target for that job. The
definition of a scrape job is retrieved using the agent's runtime config.

There may be more than one Discoverer performing SD. This means that a Scraper
can expect to receive target partition from multiple Discoverers, and that it
needs a way to merge those partitions to determine the full set of targets to
scrape.

Scrapers utilize the knowledge that each targets from a scrape job are owned by
exactly one Discoverer. This allows the merge logic to be simple: store targets
by scrape job name which can be flattened into a single set. Jobs that do not
exist in the agent's runtime config will be ignored when merging, and
eventually removed in the background to limit memory growth.

With a set of targets, Scrapers will perform relabeling rules, scrape targets,
perform metric relabeling rules, and finally send the metrics to a Sender that
is associated with the Instance name from the partition.

### Senders

Finally, Senders store data in a WAL and configure Prometheus remote_write to
ship the WAL metrics to some remote system.

There is one sender launched per Metrics Instance from the agent configuration
file. Because other subsystems append samples to the WAL for delivery, Senders
must always exist, even if there aren't any Scrapers sending metrics to them.

The set of running Senders and their individual configurations will update
whenever the agent's configuration file changes.

### Clustering

An agent-wide cluster is always available, even if the local agent is not
connected to any remote agents.

The cluster will initially use [rfratto/ckit][ckit], an extremely light
clustering toolkit that uses gossip for peer discovery and health checking. A
hash ring is locally deterministically calculated based on known peers.

Normally, gossip is done over a dedicated UDP connection to transmit messages
between peers. Since gossip is only utilized here for the peer list and health
checking, gossip is done over the existing gRPC protocol. This has the added
benefits for health checking the gRPC connection directly and reducing the
amount of things to configure when setting up clustering.

Bootstrapping the cluster will be done through [go-discover][go-discover] and a
`--cluster.discover-peers` command-line flag. This flag will be required to use
clustering, otherwise agents will act as a one-node cluster.

## Changes from the original design

### No partition TTL

The [original proposal][per-target sharding] for target-level sharding used a
TTL to detect if targets from jobs have gone stale. This added unnecessary
complexity to the implementation, and introduced bugs where clock drift could
cause targets to go stale immediately.

This new design avoids the need for a TTL by instead checking to see if an
entire job has gone stale using the runtime configuration.

## Edge Cases

### Discoverer network partition

A Discoverer network partition occurs when two Discoverers determine ownership
of the same job. This will cause targets to be sent twice to Scrapers. If
targets are sent to the same Scraper, no negative effect will occur: the
merging logic of scrapers will ignore the first partition and use the second
instead.

However, if targets are sent to different scrapers, then a Scraper network
partition occurs. This may also cause some targets to not be scraped by any
agent, depending on the order in which partitions are received by Discoverers.
Future changes may add resistance to ordering problems by using Lamport clocks.

### Scraper network partition

If two Scrapers are scraping the same target, Remote Write will reject the
duplicate samples. Otherwise, no noticeable effect occurs.

### Unhealthy Discoverer

Targets sent by the unhealthy Discoverer will continue to be active. Once the
unhealthy Discoverer is removed from the gossip memberlist, a new Discoverer
will pick up its SD jobs and re-deliver targets to the appropriate Scrapers.

### Unhealthy Scraper

Targets owned by the Scraper will be unscraped for a brief period of time. The
Scraper will be removed from the gossip memberlist, and force Discoverers to
re-flush targets. The targets will then be assigned to a new Scraper and the
system state will recover.

### Cluster networking failure

Nodes must be required to communicate with one another. If this is not
possible, the gossip memberlist will remove unreachable nodes and cause one or
more network partitions.

## Trade-offs

### No runtime instance management

This approach removes runtime instance management by using the loaded
configuration file as the source of truth. Subsystems that previously
dynamically launched instances can work around this by mutating the runtime
config when the config is first loaded.

### Complexity

Using the network for distribution adds some level of complexity and fragility
to the system. There may be unidentified edge cases or flaws in the designed
proposed here.

### No Configuration Store API

This approach doesn't support an external configuration store API. Such an API
should be delegated to an external process that flushes state to a file for the
agent to read.

### Configuration Desync

This approach requires all agents have the same configuration file. This can be
worked around by using [#1121][#1121] to help make sure all agents pull their
configs from the same source. A new metric that hashes the runtime config can
also enable alerting on config desync.

[#872]: https://github.com/grafana/agent/issues/872
[#873]: https://github.com/grafana/agent/issues/873
[#875]: https://github.com/grafana/agent/issues/875
[#888]: https://github.com/grafana/agent/issues/888
[per-target sharding]: https://docs.google.com/document/d/1JI804iaut6bKvZprOydes3Gb5Awo_J0sX-3ORlyc5l0
[ckit]: https://github.com/rfratto/ckit
[go-discover]: https://github.com/hashicorp/go-discover
[#1121]: https://github.com/grafana/agent/issues/1121

'''
'''--- docs/rfcs/0004-agent-flow.md ---
# This provided the basis for Agent Flow, and though not all the concepts/ideas will make it into flow, it is good to have the historical context for why we started down this path. 

# Agent Flow - Agent Utilizing Components 

* Date: 2022-03-30
* Author: Matt Durham (@mattdurham)
* PRs: 
    * [grafana/agent#1538](https://github.com/grafana/agent/pull/1538) - Problem Statement 
    * [grafana/agent#1546](https://github.com/grafana/agent/pull/1546) - Messages and Expressions
* Status: Draft

## Overarching Problem Statement

The Agents configuration and onboarding is difficult to use. Viewing the effect of configuration changes on telemetry data is difficult. Making the configuration simplier, composable and intuitive allieviates these concerns.

## Description

Agent Flow is intended to solve real world needs that the Grafana Agent team have idenfified in conversations with users and developers. 

These broadly include:

- Lack of introspection within the agent
    - Questions about what telemetry data are being sent
    - Are rules applying correctly?
    - How does filtering work?
- Users have been requesting additional capabilites and adding new features is hard due to coupling between systems, some examples include
    - Remote Write, Different Input Formats
    - Different output formats
    - Filtering ala Relabel Configs is complex and hard to figure out when they occur
- Lack of understanding how telemetry data moves through agent
    - Other systems use pipeline/extensions to allow users to understand how data moves through the system

# 1. Introduction and Goals 

This design document outlines Agent Flow, a system for describing a programmable pipeline for telemetry data. 

Agent Flow refers to both the execution, configuration and visual configurator of data flow.

### Goals 

* Allow users to more easily understand the impact of their configuration
* Allow users to collect integration metrics across a set of agents
* Allow users to run components based on a dynamic environment
* Allow developers to easily add components to the system
* Maintain high performance on all currently-supported platforms
* Produce machine-readable and machine-writable configs for tooling such as formatters or a GUI.

### Non-goals

* Discuss technical details: we instead focus on how a user would interact with a hypothetical implementation of Agent Flow.

# 2. Broad Solution Path

At a high level, Agent Flow:

* Breaks apart the existing hierarchical configuration file into reusable components 
* Allows components to be connected, resulting in a programmable pipeline of telemetry data

This document considers three potential approaches to allow users to connect components together: 

1. Message passing (i.e., an actor model) 
2. Expressions (i.e., directly referencing the output of another component)
3. A hybrid of both messages and expressions  

The Flow Should in general resemble a flowchart or node graph. The data flow diagram would conceptually look like the below, with each node being composable and connecting with other nodes. 

```
                                            
                                 Target Filter     Redis Integration     Metric Filter              
                                                                   
    Service Discovery                                                                                                        
                                                                                                                                   
                                                                                                                                   
                                                      
                                   Target Filter    MySQL Integrations                              
                                                                                         
                                                                                                                                    
                                                                                                  
                                   Target Filter     Scraper               
                                                                      Remote Write  
                                                                                                                    
                                                                                                                                      
                                                                                                                                      
                                                                                                          
  Remote Write Receiver                                                                              
                                       Metric Transformer                               
                                                                                                            
                                                                                                                                     
                                                                                    
      HTTP Receiver         Metric Filter                                    
                                                 Global and Server Settings         
                                                                                                   
```

**Note: Consider all examples pseudoconfig**

## 2.1 Expression Based

Expression based is writing expressions that allow referencing other components streams/outputs/values and using them directly. Expressions allow referencing other fields, along with complex programming concepts. (functions, arithmetic ect). For instance `field1 = len(service_discover1.targets)`.

**Pros**

* Easier to Implement, evaluating expressions can map directly to existing config structs
* Components are more reusable, you can pass basic types around (string, int, bool) in addition to custom types

**Cons**
* Harder for users to wire things together
  * References to components are more complex, which may be harder to understand 
* Harder to build a GUI for
  * Every field of a component is potentially dynamic, making it harder to represent visually

## 2.2 Message Based

Message based is where components have no knowledge of other components and information is passed strictly via input and output streams. 

**Pros**

* Easier for users to understand the dependencies between components
* Easier to build a GUI for
    * Inputs and Outputs are well defined and less granular
    * Connections are made by connecting two components directly, compared to expressions which connect subsets of a component's output
* References between components are no more than strings, making the text-based representation language agnostic (e.g., it could be YAML, JSON, or any language)  

**Cons**

* More time consuming to implement, existing integrations/items would need to be componentized
* Larger type system needed
* More structured to keep the amount of types down

Messages require a more rigid type structure to minimize the number of total components. 

For example, it would be preferable to have a single `Credential` type that can be emitted by an s3, Vault, or Consul component. These components would then need to set a field that marks their output as a specific kind of Credential (such as Basic Auth or Bearer Auth).

If, instead, you had multiple Credential types, like `MySQLCredentials` and `RedisCredentials`, you would have the following components:

* Vault component for MySQL credentials 
* Vault component for Redis credentials 
* S3 component for MySQL credentials 
* S3 component for Redis credentials 
* (and so on)

## 2.3 Hybrid

## 2.4 Examples

### 2.4.1 Simple Example Mysql from Target Discovery

**Expression**

```
discovery "mysql_pods" {
    # some sort of config here to find pods
}

integration "mysql" {
  # Create one mysql integration for every element in the array here 
  for_each = discovery.mysql_pods.targets

  # Each spawned mysql integration has its data_source_name derived from 
  # the address label of the input target.
  data_source_name = "root@(${each.labels["__address__"]})"
}
```

**Message**

```
discovery "mysqlpods" {
    relabel_config {
        [
            {
                source = "__address__"
                match = "*mysql"
                action = "replace"
                replacement = "root@($1)"
            }
        ]
    }
}

# I think this would depend on convention, mysql would look at __address__ , and maybe optionally look for username/password
integration "mysql" {}

connections {
    [
        {
            source = mysqlpods
            destination = mysql
        }
    ]
}
```

'''
'''--- docs/sources/README.md ---
---
aliases:
- /docs/agent/latest/README/
draft: "True"
---

<p align="center"><img src="assets/logo_and_name.png" alt="Grafana Agent logo"></p>

Grafana Agent is an telemetry collector for sending metrics, logs,
and trace data to the opinionated Grafana observability stack. It works best
with:

* [Grafana Cloud](https://grafana.com/products/cloud/)
* [Grafana Enterprise Stack](https://grafana.com/products/enterprise/)
* OSS deployments of [Grafana Loki](https://grafana.com/oss/loki/), [Prometheus](https://prometheus.io/), [Cortex](https://cortexmetrics.io/), and [Grafana Tempo](https://grafana.com/oss/tempo/)

- Grafana Agent uses less memory on average than Prometheus  by doing less
  (only focusing on `remote_write`-related functionality).
- Grafana Agent allows for deploying multiple instances of the Agent in a
  cluster and only scraping metrics from targets that are running on the same host.
  This allows for distributing memory requirements across the cluster
  rather than pressurizing a single node.

'''
'''--- docs/sources/_index.md ---
---
aliases:
- /docs/agent/latest/
title: Grafana Agent
weight: 1
---

# Grafana Agent

## Overview

Grafana Agent collects and forwards telemetry data to open source deployments of the Grafana Stack, Grafana Cloud, or Grafana Enterprise, where your data can then be analyzed. You can install Grafana Agent on Kubernetes and Docker, or as a system process for Linux, macOS, and Windows machines.  

Grafana Agent is open source and its source code is available on GitHub at https://github.com/grafana/agent.

Grafana Agent is for engineers, operators, or administrators who want to collect and forward telemetry data for analysis and on-call alerting. Those operating Grafana Agent must install and configure Grafana Agent to properly collect telemetry data and monitor the health of running agents.

## Features

There are other ways of sending metrics, logs and traces to the Grafana Stack, Grafana Cloud or Grafana Enterprise, but there are a few advantages of using Grafana Agent. These features are outlined below.

- Provides a one-stop solution for collecting metrics, logs, and traces.
- Collects out-of-the-box telemetry from popular projects like MySQL through integrations
- Works seamlessly with the Grafana Stack. Alternatively, metrics can be sent to any Prometheus-compatible endpoint, and traces can be sent to any OTLP-compatible endpoint.  
- Offers new solutions to help scale metrics collection like host_filtering and sharding 
- Provides the Grafana Agent Operator, which enables individual teams to manage their configurations through PodMonitors, ServiceMonitors, and Probes.

## Metrics

Grafana Agent focuses metrics support around Prometheus' remote_write protocol,
so some Prometheus features, such as querying, local storage, recording rules,
and alerts are not present. `remote_write`, service discovery, and relabeling
rules are included.

Grafana Agent has a concept of an "instance" each of which acts as
its own mini Prometheus agent with its own `scrape_configs` section and
`remote_write` rules. More than one instance is useful when you want to have
separate configurations that write to two different locations without
needing to consider advanced metric relabeling rules. Multiple instances also
come into play for the [Scraping Service Mode]({{< relref "configuration/scraping-service/" >}}).

Grafana Agent for collecting metrics can be deployed in three modes:

- Prometheus `remote_write` drop-in
- [Host Filtering mode](#host-filtering)
- [Scraping Service mode]({{< relref "configuration/scraping-service/" >}})

### Prometheus `remote_write` drop-in
The default deployment mode of Grafana Agent is a _drop-in_
replacement for Prometheus `remote_write`. Grafana Agent acts similarly to a
single-process Prometheus, doing service discovery, scraping, and remote
writing.

### Host filtering
Host filtering configures agents to scrape targets that are running on the same
machine as the Grafana Agent process.

1. Gets the hostname of the agent by the `HOSTNAME` environment variable or
   through the default.
1. Checks if the hostname of the agent matches the label value for `__address__`
   service-discovery-specific node labels against the discovered target.

If the filter passes, the target is scraped. Otherwise, the target
is ignored and not scraped.

To use _Host Filtering mode_, you set a `host_filter` flag on a specific
instance inside the Agent's configuration file. When you set this flag, the
instance only scrapes metrics from targets that are running on the same
machine. This is useful for migrating to sharded
Prometheus instances in a Kubernetes cluster, where the Agent can be deployed as
a DaemonSet and distribute memory requirements across multiple nodes.

Note that _Host Filtering_ mode and sharding your instances means that if an
Agent's metrics are being sent to an alerting system, alerts for that Agent might
not be able to be generated if the entire node has problems. This changes the
semantics of failure detection, and alerts would have to be configured to catch
agents not reporting in.

For more information on the host filtering mode, refer to the [operation
guide]({{< relref "./operation-guide#host-filtering" >}}).

### Scraping Service 
_Scraping Service Mode_ 
clusters a subset of agents. It acts as a go-between for the drop-in mode
(which does no automatic sharding) and `host_filter` mode (which forces sharding
by node). The Scraping Service Mode clusters a set of agents with a set of
shared configurations and distributes the scrape load automatically between them. For
more information on Scraping Service, see [Scraping Service]({{< relref "configuration/scraping-service/" >}}).

## Logs

Grafana Agent supports collecting logs and sending them to Loki using its
`loki` subsystem. This is done using the upstream
[Promtail](https://grafana.com/docs/loki/latest/clients/promtail/) client, which
is the official first-party log collection client created by the Loki
developer team.

## Traces

Grafana Agent collects traces and forwards them to Tempo using its
`traces` subsystem. This is done using the upstream [OpenTelemetry Collector](https://github.com/open-telemetry/opentelemetry-collector).
Grafana Agent can ingest OpenTelemetry, OpenCensus, Jaeger, Zipkin, or Kafka spans.
For more information on how to configure, refer to [receivers]({{< relref "./configuration/traces-config.md" >}}).
The Grafana Agent is also capable of exporting to any OpenTelemetry GRPC compatible system.

'''
'''--- docs/sources/api/_index.md ---
---
aliases:
- /docs/agent/latest/api/
title: Grafana Agent API
weight: 400
---

# Grafana Agent APIs (Stable)

The API is divided into several parts:

- [Config Management API](#config-management-api)
- [Agent API](#agent-api)
- [Integrations API](#integrations-api)
- [Ready/Healthy API](#ready--health-api)

API endpoints are stable unless otherwise noted.

## Config management API (Beta)

Grafana Agent exposes a config management REST API for managing instance configurations when it is running in [scraping service mode]({{< relref "../configuration/scraping-service/" >}}).

(Note that scraping service mode is a requirement for the config management
API, however this is not a prerequisite for the Agent API or Ready/Healthy API)

The following endpoints are exposed:

- List configs: [`GET /agent/api/v1/configs`](#list-configs)
- Get config: [`GET /agent/api/v1/configs/{name}`](#get-config)
- Update config: [`PUT /agent/api/v1/config/{name}`](#update-config)
- Delete config: [`DELETE /agent/api/v1/config/{name}`](#delete-config)

### API response

All Config Management API endpoints will return responses in the following
form, unless an internal service error prevents the server from responding
properly:

```
{
  "status": "success" | "error",
  "data": {}
}
```

Status will be either `success` or `error`. All 2xx responses will be
accompanied with a `success` value for the status field. 4xx and 5xx
responses will provide a value of `error`. All requests may potentially
return 500 on an internal error. Other non-500 responses will be documented
per API.

The data field may or may not be present, depending on the endpoint. It
provides extra information for the query. The documentation for each endpoint
will describe the full response provided.

### List configs

```
GET /agent/api/v1/configs
```

List configs returns a list of the named configurations currently known by the
underlying KV store.

Status code: 200 on success.
Response:

```
{
  "status": "success",
  "data": {
    "configs": [
      // list of config names:
      "a",
      "b",
      "c",
      // ...
    ]
  }
}
```

### Get config

```
GET /agent/api/v1/configs/{name}
```

Get config returns a single configuration by name. The configuration must
exist or an error will be returned. URL-encoded names will be retrieved in decoded
form. e.g., `hello%2Fworld` will represent the config named `hello/world`.

Status code: 200 on success, 400 on invalid config name.
Response on success:

```
{
  "status": "success",
  "data": {
    "value": "/* YAML configuration */"
  }
}
```

### Update config

```
PUT /agent/api/v1/config/{name}
POST /agent/api/v1/config/{name}
```

Update config updates or adds a new configuration by name. If a configuration
with the same name already exists, then it will be completely overwritten.

URL-encoded names are stored in decoded form. e.g., `hello%2Fworld` will
represent the config named `hello/world`.

The request body passed to this endpoint must match the format of
[metrics_instance_config]({{< relref "../configuration/metrics-config" >}})
defined in the Configuration Reference. The name field of the configuration is
ignored and the name in the URL takes precedence. The request body must be
formatted as YAML.

**WARNING**: By default, all instance configuration files that read
credentials from a file on disk will be rejected. This prevents malicious users
from reading the contents of arbitrary files as passwords and sending their
contents to fake remote_write endpoints. To change the behavior, set
`dangerous_allow_reading_files` to true in the `scraping_service` block.

Status code: 201 with a new config, 200 on updated config.
Response on success:

```
{
  "status": "success"
}
```

### Delete config

```
DELETE /agent/api/v1/config/{name}
```

Delete config attempts to delete a configuration by name. The named
configuration must exist; deleting a nonexistent config will result in an
error.

URL-encoded names will be interpreted in decoded form. e.g., `hello%2Fworld`
will represent the config named `hello/world`.

Status code: 200 on success, 400 with invalid config name.
Response on success:

```
{
  "status": "success"
}
```

## Agent API

### List current running instances of metrics subsystem

```
GET /agent/api/v1/metrics/instances
```
*note:* deprecated alias is `/agent/api/v1/instances`

Status code: 200 on success.
Response on success:

```
{
  "status": "success",
  "data": [
    <strings of instance names that are currently running>
  ]
}
```

### List current scrape targets of metrics subsystem

```
GET /agent/api/v1/metrics/targets
```
*note:* deprecated alias is `/agent/api/v1/targets`

This endpoint collects all metrics subsystem targets known to the Agent across all
running instances. Only targets being scraped from the local Agent will be returned. If
running in scraping service mode, this endpoint must be invoked in all Agents
separately to get the combined set of targets across the whole Agent cluster.

The `labels` fields shows the labels that will be added to metrics from the
target, while the `discovered_labels` field shows all labels found during
service discovery.

Status code: 200 on success.
Response on success:

```
{
  "status": "success",
  "data": [
    {
      "instance": <string, instance config name>,
      "target_group": <string, scrape config group name>,
      "endpoint": <string, URL being scraped>
      "state": <string, one of up, down, unknown>,
      "discovered_labels": {
        "__address__": "<address>",
        ...
      },
      "labels": {
        "label_a": "value_a",
        ...
      },
      "last_scrape": <string, RFC 3339 timestamp of last scrape>,
      "scrape_duration_ms": <number, last scrape duration in milliseconds>,
      "scrape_error": <string, last error. empty if scrape succeeded>
    },
    ...
  ]
}
```

### Accept remote_write requests

```
POST /agent/api/v1/metrics/instance/{instance}/write
```

This endpoint accepts Prometheus-compatible remote_write POST requests, and
appends their contents into an instance's WAL. 

Replace `{instance}` with the name of the metrics instance from your config
file. For example, this block defines the "dev" and "prod" instances:

```yaml
metrics:
  configs:
  - name: dev     # /agent/api/v1/metrics/instance/dev/write
    ...
  - name: prod    # /agent/api/v1/metrics/instance/prod/write
    ...
```

Status code: 204 on success, 400 for bad requests related to the provided
instance or POST payload format and content, 500 for cases where appending
to the WAL failed.

### List current running instances of logs subsystem

```
GET /agent/api/v1/logs/instances
```

Status code: 200 on success.
Response on success:

```
{
  "status": "success",
  "data": [
    <strings of instance names that are currently running>
  ]
}
```

### List current scrape targets of logs subsystem

```
GET /agent/api/v1/logs/targets
```

This endpoint collects all logs subsystem targets known to the Agent across 
all running instances. Only targets being scraped from Promtail will be returned. 

The `labels` fields shows the labels that will be added to metrics from the
target, while the `discovered_labels` field shows all labels found during
service discovery.

Status code: 200 on success.
Response on success:

```
{
  "status": "success",
  "data": [
    {
      "instance": "default",
      "target_group": "varlogs",
      "type": "File",
      "labels": {
        "job": "varlogs"
      },
      "discovered_labels": {
        "__address__": "localhost",
        "__path__": "/var/log/*log",
        "job": "varlogs"
      },
      "ready": true,
      "details": {
        "/var/log/alternatives.log": 13386,
        "/var/log/apport.log": 0,
        "/var/log/auth.log": 37009,
        "/var/log/bootstrap.log": 107347,
        "/var/log/dpkg.log": 374420,
        "/var/log/faillog": 0,
        "/var/log/fontconfig.log": 11629,
        "/var/log/gpu-manager.log": 1541,
        "/var/log/kern.log": 782582,
        "/var/log/lastlog": 0,
        "/var/log/syslog": 788450
      }
    }
  ]
}
```

### Reload configuration file (beta)

This endpoint is currently in beta and may have issues. Please open any issues
you encounter.

```
GET /-/reload
POST /-/reload
```

This endpoint will re-read the configuration file from disk and refresh the
entire state of the Agent to reflect the new file on disk:

- HTTP Server
- Prometheus metrics subsystem
- Loki logs subsystem
- Tempo traces subsystem
- Integrations

Valid configurations will be applied to each of the subsystems listed above, and
`/-/reload` will return with a status code of 200 once all subsystems have been
updated. Malformed configuration files (invalid YAML, failed validation checks)
will be immediately rejected with a status code of 400.

Well-formed configuration files can still be invalid for various reasons, such
as not having permissions to read the WAL directory. Issues such as these will
cause per-subsystem problems while reloading the configuration, and will leave
that subsystem in an undefined state. Specific errors encountered during reload
will be logged, and should be fixed before calling `/-/reload` again.

Status code: 200 on success, 400 otherwise.

### Show configuration file

```
GET /-/config
```

This endpoint prints out the currently loaded configuration the Agent is using.
The returned YAML has defaults applied, and only shows changes to the state that
validated successfuly, so the results will not identically match the
configuration file on disk.

Status code: 200 on success.

## Integrations API (Experimental)

> **WARNING**: This API is currently only available when the experimental
> [integrations revamp]({{< relref "../configuration/integrations/integrations-next" >}})
> is enabled. Both the revamp and this API are subject to change while they
> are still experimental.

### Integrations SD API

```
GET /agent/api/v1/metrics/integrations/sd
```

This endpoint returns all running metrics-based integrations. It conforms to
the Prometheus [http_sd_config
API](https://prometheus.io/docs/prometheus/latest/configuration/configuration/#http_sd_config).
Targets include integrations regardless of autoscrape being enabled; this
allows for manually configuring scrape jobs to collect metrics from an
integration running on an external agent.

The following labels will be present on all returned targets:

- `instance`: The unique instance ID of the running integration.
- `job`: `integrations/<__meta_agent_integration_name>`
- `agent_hostname`: `hostname:port` of the agent running the integration.
- `__meta_agent_integration_name`: The name of the integration.
- `__meta_agent_integration_instance`: The unique instance ID for the running integration.
- `__meta_agent_integration_autoscrape`: `1` if autoscrape is enabled for this integration, `0` otherwise.

To reduce the load on the agent's HTTP server, the following query parameters
may also be provided to the URL:

- `integrations`: Comma-delimited list of integrations to return. i.e., `agent,node_exporter`.
- `instance`: Return all integrations matching a specific value for instance.

Status code: 200 if successful.
Response on success:

```
[
  {
    "targets": [ "<host>", ... ],
    "labels": {
      "<labelname>": "<labelvalue>", ...
    }
  },
  ...
]
```

### Integrations autoscrape targets

```
GET /agent/api/v1/metrics/integrations/targets
```

This endpoint returns all integrations for which autoscrape is enabled. The
response is identical to [`/agent/api/v1/metrics/targets`](#list-current-scrape-targets).

Status code: 200 on success.
Response on success:

```
{
  "status": "success",
  "data": [
    {
      "instance": <string, metrics instance where autoscraped metrics are sent>,
      "target_group": <string, scrape config group name>,
      "endpoint": <string, URL being scraped>
      "state": <string, one of up, down, unknown>,
      "discovered_labels": {
        "__address__": "<address>",
        ...
      },
      "labels": {
        "label_a": "value_a",
        ...
      },
      "last_scrape": <string, RFC 3339 timestamp of last scrape>,
      "scrape_duration_ms": <number, last scrape duration in milliseconds>,
      "scrape_error": <string, last error. empty if scrape succeeded>
    },
    ...
  ]
}
```

## Ready / health API

### Readiness check

```
GET /-/ready
```

Status code: 200 if ready.

Response:
```
Agent is Ready.
```

### Healthiness check

```
GET /-/healthy
```

Status code: 200 if healthy.

Response:
```
Agent is Healthy.
```

'''
'''--- docs/sources/configuration/_index.md ---
---
aliases:
- /docs/agent/latest/configuration/
title: Configure Grafana Agent
weight: 300
---

# Configure Grafana Agent

Grafana Agent is configured across two places:

* A YAML file
* [Command-line flags]({{< relref "./flags.md" >}})

The YAML file is used to configure settings which are dynamic and can be
changed at runtime. The command-line flags then configure things which cannot
change at runtime, such as the listen port for the HTTP server.

This file describes the YAML configuration, which is usually in a file named `agent.yaml`.

- [server_config]({{< relref "./server-config" >}})
- [metrics_config]({{< relref "./metrics-config" >}})
- [logs_config]({{< relref "./logs-config.md" >}})
- [traces_config]({{< relref "./traces-config" >}})
- [integrations_config]({{< relref "./integrations/_index.md" >}})

The configuration of Grafana Agent is "stable," but subject to breaking changes
as individual features change. Breaking changes to configuration will be
well-documented.

## Updating configuration

The configuration file can be reloaded at runtime using the `/-/reload` API
endpoint or sending a SIGHUP signal to the process.

## Variable substitution

You can use environment variables in the configuration file to set values that
need to be configurable during deployment. To enable this functionality, you
must pass `-config.expand-env` as a command-line flag to the Agent.

To refer to an environment variable in the config file, use:

```
${VAR}
```

Where VAR is the name of the environment variable.

Each variable reference is replaced at startup by the value of the environment
variable. The replacement is case-sensitive and occurs before the YAML file is
parsed. References to undefined variables are replaced by empty strings unless
you specify a default value or custom error text.

To specify a default value, use:

```
${VAR:-default_value}
```

Where default_value is the value to use if the environment variable is
undefined. The full list of supported syntax can be found at Drone's
[envsubst repository](https://github.com/drone/envsubst).

### Regex capture group references

When using `-config.expand-env`, `VAR` must be an alphanumeric string with at
least one non-digit character. If `VAR` is a number, the expander will assume
you're trying to use a regex capture group reference, and will coerce the result
to be one.

This means references in your config file like `${1}` will remain
untouched, but edge cases like `${1:-default}` will also be coerced to `${1}`,
which may be slightly unexpected.

## Reloading (beta)

The configuration file can be reloaded at runtime. Read the [API
documentation]({{< relref "../api#reload-configuration-file-beta" >}}) for more information.

This functionality is in beta, and may have issues. Please open GitHub issues
for any problems you encounter.

## File format

To specify which configuration file to load, pass the `-config.file` flag at
the command line. The file is written in the [YAML
format](https://en.wikipedia.org/wiki/YAML), defined by the scheme below.
Brackets indicate that a parameter is optional. For non-list parameters the
value is set to the specified default.

Generic placeholders are defined as follows:

- `<boolean>`: a boolean that can take the values `true` or `false`
- `<int>`: any integer matching the regular expression `[1-9]+[0-9]*`
- `<duration>`: a duration matching the regular expression `[0-9]+(ns|us|s|ms|[smh])`
- `<labelname>`: a string matching the regular expression `[a-zA-Z_][a-zA-Z0-9_]*`
- `<labelvalue>`: a string of unicode characters
- `<filename>`: a valid path relative to current working directory or an
    absolute path.
- `<host>`: a valid string consisting of a hostname or IP followed by an optional port number
- `<string>`: a regular string
- `<secret>`: a regular string that is a secret, such as a password

Support contents and default values of `agent.yaml`:

```yaml
# Configures the server of the Agent used to enable self-scraping.
[server: <server_config>]

# Configures metric collection.
# In previous versions of the agent, this field was called "prometheus".
[metrics: <metrics_config>]

# Configures log collection.
# In previous versions of the agent, this field was called "loki".
[logs: <logs_config>]

# Configures Traces trace collection.
# In previous versions of the agent, this field was called "tempo".
[traces: <traces_config>]

# Configures integrations for the Agent.
[integrations: <integrations_config>]
```

## Remote Configuration (Experimental)

An experimental feature for fetching remote configuration files over HTTP/S can be
enabled by passing the `-enable-features=remote-configs` flag at the command line.
With this feature enabled, you may pass an HTTP/S URL to the `-config.file` flag.

The following flags will configure basic auth for requests made to HTTP/S remote config URLs:
- `-config.url.basic-auth-user <user>`: the basic auth username
- `-config.url.basic-auth-password-file <file>`: path to a file containing the basic auth password

Note that this beta feature is subject to change in future releases.

'''
'''--- docs/sources/configuration/create-config-file.md ---
---
aliases:
- /docs/agent/latest/set-up/create-config-file/
title: Create a config file
weight: 50
---

# Create a configuration file

The Grafana Agent supports configuring multiple independent "subsystems." Each
subsystem helps you collect data for a specific type of telemetry.

- The **Metrics** subsystem allows you collect metrics to send to Prometheus.
- The **Logs** subsystem allows you to collect logs to send to Grafana Loki.
- The **Traces** subsystem allows you to collect spans to send to Grafana Tempo.
- The **Integrations** subsystem allows you to collect metrics for common
  applications, such as MySQL.

Integrations are recommended for first-time users of observability platforms,
especially newcomers to Prometheus. Users with more experience with Prometheus
or users that already have an existing Prometheus config file can configure
the Prometheus subsystem manually.

## Integrations

_Integrations_ are individual features that collect metrics for you. For
example, the `agent` integration collects metrics from that running instance of
the Grafana Agent. The `node_exporter` integration will collect metrics from the
Linux machine that the Grafana Agent is running on.

```yaml
metrics:
  wal_directory: /tmp/wal
  global:
    remote_write:
      - url: http://localhost:9009/api/prom/push

integrations:
  agent:
    enabled: true
```

In this example, we first must configure the `wal_directory` which is used to
store metrics in a Write-Ahead Log. This is required, but ensures that samples
will be resent in case of failure (e.g., network issues, machine reboot). We
also configure `remote_write`, which is where all metrics should be sent by
default.

Then, the individual `integrations` are configured. In this example, just the
`agent` integration is enabled. Finally, `prometheus_remote_write` is configured
with a location to send metrics. You will have to replace this URL with the
appropriate URL for your `remote_write` system (such as a Grafana Cloud Hosted
Prometheus instance).

When the Agent is run with this file, it will collect metrics from itself and
send those metrics to the default `remote_write` endpoint. All metrics from
integrations will have an `instance` label matching the hostname of the machine
the Grafana Agent is running on. This label helps to uniquely identify the
source of metrics if you are running multiple Grafana Agents across multiple
machines.

Full configuration options can be found in the
[configuration reference]({{< relref "../configuration/_index.md" >}}).

## Prometheus config/migrating from Prometheus

The Prometheus subsystem config is useful for those migrating from Prometheus
and those who want to scrape metrics from something that currently does not have
an associated integration.

To migrate from an existing Prometheus config, use this Agent config as a
template and copy and paste subsections from your existing Prometheus config
into it:

```yaml
metrics:
  global:
  # PASTE PROMETHEUS global SECTION HERE
  configs:
    - name: agent
      scrape_configs:
        # PASTE scrape_configs SECTION HERE
      remote_write:
        # PASTE remote_write SECTION HERE
```

For example, this configuration file configures the Grafana Agent to
scrape itself without using the integration:

```yaml
server:
  log_level: info

metrics:
  global:
    scrape_interval: 1m
  configs:
    - name: agent
      scrape_configs:
        - job_name: agent
          static_configs:
            - targets: ['127.0.0.1:12345']
      remote_write:
        - url: http://localhost:9009/api/prom/push
```

Like with integrations, full configuration options can be found in the
[configuration]({{< relref "../configuration/_index.md" >}}).

## Loki Config/Migrating from Promtail

The Loki Config allows for collecting logs to send to a Loki API. Users that are
familiar with Promtail will notice that the Loki config for the Agent matches
their existing Promtail config with the following exceptions:

- The deprecated field `client` is not present
- The `server` field is not present

To migrate from an existing Promtail config, make sure you are using `clients`
instead of `client` and remove the `server` block if present. Then paste your
Promtail config into the Agent config file inside of a `logs` section:

```yaml
logs:
  configs:
  - name: default
    # PASTE YOUR PROMTAIL CONFIG INSIDE OF HERE
```

### Full config example

Here is an example full config file, using integrations, Prometheus, Loki, and
Tempo:

```yaml
server:
  log_level: info

metrics:
  global:
    scrape_interval: 1m
    remote_write:
      - url: http://localhost:9009/api/prom/push
  configs:
    - name: default
      scrape_configs:
        - job_name: agent
          static_configs:
            - targets: ['127.0.0.1:12345']

logs:
  configs:
  - name: default
    positions:
      filename: /tmp/positions.yaml
    scrape_configs:
      - job_name: varlogs
        static_configs:
          - targets: [localhost]
            labels:
              job: varlogs
              __path__: /var/log/*log
    clients:
      - url: http://localhost:3100/loki/api/v1/push

traces:
  configs:
  - name: default
    receivers:
      jaeger:
        protocols:
          grpc: # listens on the default jaeger grpc port: 14250
    remote_write:
      - endpoint: localhost:55680
        insecure: true  # only add this if TLS is not required
    batch:
      timeout: 5s
      send_batch_size: 100

integrations:
  node_exporter:
    enabled: true
```

'''
'''--- docs/sources/configuration/dynamic-config.md ---
---
aliases:
- /docs/agent/latest/configuration/dynamic-config/
title: dynamic_config
weight: 500
---

# Dynamic Configuration - Experimental

**This is experimental and subject to change at anytime, feedback is much appreciated. This is a feature that MAY NOT make it production.**

Dynamic Configuration is the combination of two things:

* Loading from multiple files
* Using templates and datasources

Both of these make heavy use of the excellent [gomplate](https://github.com/hairyhenderson/gomplate). The goal is
that as the configuration grows that it can be split it up into smaller segments to allow better readability and handling.
The configurations cannot be patched in any order and instead are allowed at several levels.

The second goal is to allow the use of templating, functions for [gomplate doc](https://docs.gomplate.ca/) go into detail
on what functions are available.

## Configuration

Dynamic configuration files can be used by passing `-config.file.type=dynamic
-enable-features=dynamic-config,integrations-next`. When these flags are
passed, the file referred to `-config.file` will be loaded as a dynamic
configuration file.

Dynamic configuration files are YAML which conform the following schema:

```yaml
# Sources to pull template values
datasources:
  [- <sources_config>]

# Locations to use searching for templates, the system does NOT look into subdirectories. Follows gomplate schema
# from [gomplate datasources](https://docs.gomplate.ca/datasources/). File and S3/GCP templates are currently supported
template_paths:
  [ - string ]

# Filters allow you to override the default naming convention

agent_filter:            string # defaults to agent-*.yml
server_filter:           string # defaults to server-*.yml
metrics_filter:          string # defaults to metrics-*.yml
metrics_instance_filter: string # defaults to metrics_instances-*.yml
integrations_filter:     string # defaults to integrations-*.yml
logs_filter:             string # defaults to logs-*.yml
traces_filter:           string # defaults to traces-*.yml
```

### sources_config
```yaml
# Name of the source to use when templating
name: string

# Path to datasource using schema from [gomplate datasources](https://docs.gomplate.ca/datasources/)
url: string

```

## Templates

Note when adding a template you MUST NOT add the type as the top level yaml field. For instance if using traces:

Incorrect

```yaml
traces:
  configs:
  - name: default
    automatic_logging:
      backend: loki
      loki_name: default
      spans: true
```

Correct

```yaml
configs:
- name: default
  automatic_logging:
    backend: loki
    loki_name: default
    spans: true
```

Configurations are loaded in the order as they are listed below.

### Agent

Agent template is the standard agent configuration file in its entirety. The default filter is `agent-*.yml`. Only
one file is supported. This is processed first then any subsequent configurations found REPLACE the values here, it is
not additive.

[Reference]({{< relref "./" >}})

### Server

The default filter is `server-*.yml`, only ONE server file is supported.

[Reference]({{< relref "./server-config.md" >}})

### Metrics

The default filter is `metrics-*.yml`, only ONE metrics file is supported.

[Reference]({{< relref "./metrics-config.md" >}})

### Metric Instances

The default filter is `metrics_instances-*.yml`. Any metric instances are appended to the instances defined in Metrics above. Any number of metric instance files are supporter.

[Reference]({{< relref "./metrics-config.md#metrics_instance_config" >}}) in the metrics instance

### Integrations

The default filter is `integrations-*.yml`, these support more than one file, and multiple integrations can be defined in a file. Do not assume any order of loading for integrations. For any integration that is a singleton, loading multiple of those will result in an error.

[Reference]({{< relref "./integrations/" >}})

### Traces

The default filter is `traces-*.yml`. This supports ONE file.

[Reference]({{< relref "./traces-config/" >}})

### Logs

The default filter is `logs-*.yml`. This supports ONE file.

[Reference]({{< relref "./logs-config/" >}})

'''
'''--- docs/sources/configuration/flags.md ---
---
aliases:
- /docs/agent/latest/configuration/flags/
title: Command-line flags
weight: 100
---

# Command-line flags

Command-line flags are used to configure settings of Grafana Agent which cannot
be updated at runtime.

All flags may be prefixed with either one hypen or two (i.e., both
`-config.file` and `--config.file` are valid).

> Note: There may be flags returned by `-help` which are not listed here; this
> document only lists flags that do not have an equivalent in the YAML file.

## Basic

* `-version`: Print out version information
* `-help`: Print out help

## Experimental feature flags

Grafana Agent has some experimental features that require being enabled through
an `-enable-features` flag. This flag takes a comma-delimited list of feature
names to enable.

Valid feature names are:

* `remote-configs`: Enable [retrieving]({{< relref "./_index.md#remote-configuration-experimental" >}}) config files over HTTP/HTTPS
* `integrations-next`: Enable [revamp]({{< relref "./integrations/integrations-next/" >}}) of the integrations subsystem
* `dynamic-config`: Enable support for [dynamic configuration]({{< relref "./dynamic-config" >}})
* `extra-scrape-metrics`: When enabled, additional time series  are exposed for each metrics instance scrape. See [Extra scrape metrics](https://prometheus.io/docs/prometheus/latest/feature_flags/#extra-scrape-metrics).

### Report use of feature flags

By default, Grafana Agent sends anonymous, but uniquely-identifiable information
of the enabled feature flags from your running Grafana Agent instance to Grafana Labs.
These statistics are sent to `stats.grafana.org`.

Statistics help us better understand how Grafana Agent is used.
This helps us prioritize features and documentation.

If you would like to disable the reporting, Grafana Agent provides the flag `-disable-reporting`
to stop the reporting.

## Configuration file

* `-config.file`: Path to the configuration file to load. May be an HTTP(s) URL when the `remote-configs` feature is enabled.
* `-config.file.type`: Type of file which `-config.file` refers to (default `yaml`). Valid values are `yaml` and `dynamic`.
* `-config.expand-env`: Expand environment variables in the loaded configuration file
* `-config.enable-read-api`: Enables the `/-/config` and `/agent/api/v1/configs/{name}` API endpoints to print YAML configuration

### Remote Configuration

These flags require the `remote-configs` feature to be enabled:

`-config.url.basic-auth-user`: Basic Authentication username to use when fetching the remote configuration file
`-config.url.basic-auth-password-file`: File containing a Basic Authentication password to use when fetching the remote configuration file

### Dynamic Configuration

The `dynamic-config` and `integrations-next` features must be enabled when
`-config.file.type` is set to `dynamic`.

## Server

* `-server.register-instrumentation`: Expose the `/metrics` and `/debug/pprof/` instrumentation handlers over HTTP (default true)
* `-server.graceful-shutdown-timeout`: Timeout for a graceful server shutdown
* `-server.log.source-ips.enabled`: Whether to log IP addresses of incoming requests
* `-server.log.source-ips.header`: Header field to extract incoming IP requests from (defaults to Forwarded, X-Real-IP, X-Forwarded-For)
* `-server.log.source-ips.regex`: Regex to extract the IP out of the read header, using the first capture group as the IP address
* `-server.http.network`: HTTP server listen network (default `tcp`)
* `-server.http.address`: HTTP server listen:port (default `127.0.0.1:12345`)
* `-server.http.enable-tls`: Enable TLS for the HTTP server
* `-server.http.conn-limit`: Maximum number of simultaneous HTTP connections
* `-server.http.idle-timeout`: HTTP server idle timeout
* `-server.http.read-timeout`: HTTP server read timeout
* `-server.http.write-timeout`: HTTP server write timeout
* `-server.http.in-memory-addr`: Internal address used for the agent to make
  in-memory HTTP connections to itself. (default `agent.internal:12345`) The
  port number specified here is virtual and does not open a real network port.
* `-server.grpc.network` gRPC server listen network (default `grpc`)
* `-server.grpc.address`: gRPC server listen host:port (default `127.0.0.1:12346`)
* `-server.grpc.enable-tls`: Enable TLS for the gRPC server
* `-server.grpc.conn-limit`: Maximum number of simultaneous gRPC connections
* `-server.grpc.keepalive.max-connection-age` Maximum age for any gRPC connection for a graceful shutdown
* `-server.grpc.keepalive.max-connection-age-grace` Grace period to forceibly close connections after a graceful shutdown starts
* `-server.grpc.keepalive.max-connection-idle` Time to wait before closing idle gRPC connections
* `-server.grpc.keepalive.min-time-between-pings` Maximum frequency that clients may send pings at
* `-server.grpc.keepalive.ping-without-stream-allowed` Allow clients to send pings without having a gRPC stream
* `-server.grpc.keepalive.time` Frequency to send keepalive pings from the server
* `-server.grpc.keepalive.timeout` How long to wait for a keepalive pong before closing the connection
* `-server.grpc.max-concurrent-streams` Maximum number of concurrent gRPC streams (0 = unlimited)
* `-server.grpc.max-recv-msg-size-bytes` Maximum size in bytes for received gRPC messages
* `-server.grpc.max-send-msg-size-bytes` Maximum size in bytes for send gRPC messages
* `-server.grpc.in-memory-addr`: Internal address used for the agent to make
  in-memory gRPC connections to itself. (default `agent.internal:12346`). The
  port number specified here is virtual and does not open a real network port.

### TLS Support

TLS support can be enabled with `-server.http.tls-enabled` and
`-server.grpc.tls-enabled` for the HTTP and gRPC servers respectively.

`server.http_tls_config` and `integrations.http_tls_config` must be set in the
YAML configuration when the `-server.http.tls-enabled` flag is used.

`server.grpc_tls_config` must be set in the YAML configuration when the
`-server.grpc.tls-enabled` flag is used.

## Metrics

* `-metrics.wal-directory`: Directory to store the metrics Write-Ahead Log in

'''
'''--- docs/sources/configuration/integrations/_index.md ---
---
aliases:
- /docs/agent/latest/configuration/integrations/
title: integrations_config
weight: 500
---

# integrations_config

The `integrations_config` block configures how the Agent runs integrations that
scrape and send metrics without needing to run specific Prometheus exporters or
manually write `scrape_configs`:

```yaml
# Controls the Agent integration
agent:
  # Enables the Agent integration, allowing the Agent to automatically
  # collect and send metrics about itself.
  [enabled: <boolean> | default = false]

  # Sets an explicit value for the instance label when the integration is
  # self-scraped. Overrides inferred values.
  #
  # The default value for this integration is inferred from the agent hostname
  # and HTTP listen port, delimited by a colon.
  [instance: <string>]

  # Automatically collect metrics from this integration. If disabled,
  # the agent integration will be run but not scraped and thus not
  # remote_written. Metrics for the integration will be exposed at
  # /integrations/agent/metrics and can be scraped by an external process.
  [scrape_integration: <boolean> | default = <integrations_config.scrape_integrations>]

  # How often should the metrics be collected? Defaults to
  # prometheus.global.scrape_interval.
  [scrape_interval: <duration> | default = <global_config.scrape_interval>]

  # The timeout before considering the scrape a failure. Defaults to
  # prometheus.global.scrape_timeout.
  [scrape_timeout: <duration> | default = <global_config.scrape_timeout>]

  # How frequent to truncate the WAL for this integration.
  [wal_truncate_frequency: <duration> | default = "60m"]

  # Allows for relabeling labels on the target.
  relabel_configs:
    [- <relabel_config> ... ]

  # Relabel metrics coming from the integration, allowing to drop series
  # from the integration that you don't care about.
  metric_relabel_configs:
    [ - <relabel_config> ... ]

# Client TLS Configuration
# Client Cert/Key Values need to be defined if the server is requesting a certificate
#  (Client Auth Type = RequireAndVerifyClientCert || RequireAnyClientCert).
http_tls_config: <tls_config>

# Controls the apache_http integration
apache_http: <apache_http_config>

# Controls the node_exporter integration
node_exporter: <node_exporter_config>

# Controls the process_exporter integration
process_exporter: <process_exporter_config>

# Controls the mysqld_exporter integration
mysqld_exporter: <mysqld_exporter_config>

# Controls the redis_exporter integration
redis_exporter: <redis_exporter_config>

# Controls the dnsmasq_exporter integration
dnsmasq_exporter: <dnsmasq_exporter_config>

# Controls the elasticsearch_exporter integration
elasticsearch_exporter: <elasticsearch_exporter_config>

# Controls the memcached_exporter integration
memcached_exporter: <memcached_exporter_config>

# Controls the postgres_exporter integration
postgres_exporter: <postgres_exporter_config>

# Controls the snmp_exporter integration
snmp_exporter: <snmp_exporter_config>

# Controls the statsd_exporter integration
statsd_exporter: <statsd_exporter_config>

# Controls the consul_exporter integration
consul_exporter: <consul_exporter_config>

# Controls the windows_exporter integration
windows_exporter: <windows_exporter_config>

# Controls the kafka_exporter integration
kafka_exporter: <kafka_exporter_config>

# Controls the mongodb_exporter integration
mongodb_exporter: <mongodb_exporter_config>

# Controls the github_exporter integration
github_exporter: <github_exporter_config>

# Controls the ebpf integration
ebpf: <ebpf_config>

# Automatically collect metrics from enabled integrations. If disabled,
# integrations will be run but not scraped and thus not remote_written. Metrics
# for integrations will be exposed at /integrations/<integration_key>/metrics
# and can be scraped by an external process.
[scrape_integrations: <boolean> | default = true]

# Extra labels to add to all samples coming from integrations.
labels:
  { <string>: <string> }

# The period to wait before restarting an integration that exits with an
# error.
[integration_restart_backoff: <duration> | default = "5s"]

# A list of remote_write targets. Defaults to global_config.remote_write.
# If provided, overrides the global defaults.
prometheus_remote_write:
  - [<remote_write>]
```

'''
'''--- docs/sources/configuration/integrations/apache-exporter-config.md ---
---
aliases:
- /docs/agent/latest/configuration/integrations/apache-exporter-config/
title: apache_http_config
---

# apache_http_config

The `apache_http_config` block configures the `apache_http` integration,
which is an embedded version of
[`apache_exporter`](https://github.com/Lusitaniae/apache_exporter). This allows the collection of Apache [mod_status](https://httpd.apache.org/docs/current/mod/mod_status.html) statistics via HTTP.

Full reference of options:

```yaml
  # Enables the apache_http integration, allowing the Agent to automatically
  # collect metrics for the specified apache http servers.
  [enabled: <boolean> | default = false]

  # Sets an explicit value for the instance label when the integration is
  # self-scraped. Overrides inferred values.
  #
  # The default value for this integration is inferred from the hostname portion
  # of api_url.
  [instance: <string>]

  # Automatically collect metrics from this integration. If disabled,
  # the apache_http integration will be run but not scraped and thus not
  # remote-written. Metrics for the integration will be exposed at
  # /integrations/apache_http/metrics and can be scraped by an external
  # process.
  [scrape_integration: <boolean> | default = <integrations_config.scrape_integrations>]

  # How often should the metrics be collected? Defaults to
  # prometheus.global.scrape_interval.
  [scrape_interval: <duration> | default = <global_config.scrape_interval>]

  # The timeout before considering the scrape a failure. Defaults to
  # prometheus.global.scrape_timeout.
  [scrape_timeout: <duration> | default = <global_config.scrape_timeout>]

  # Allows for relabeling labels on the target.
  relabel_configs:
    [- <relabel_config> ... ]

  # Relabel metrics coming from the integration, allowing to drop series
  # from the integration that you don't care about.
  metric_relabel_configs:
    [ - <relabel_config> ... ]

  # How frequent to truncate the WAL for this integration.
  [wal_truncate_frequency: <duration> | default = "60m"]

  #
  # Exporter-specific configuration options
  #
     
  # URI to apache stub status page.
  # If your server-status page is secured by http auth, add the credentials to the scrape URL following this example:
  # http://user:password@localhost/server-status?auto .
  [scrape_uri: <string> | default = "http://localhost/server-status?auto"]

  # Override for HTTP Host header; empty string for no override.
  [host_override: <string> | default = ""]

  # Ignore server certificate if using https.
  [insecure: <bool> | default = false]

```

'''
'''--- docs/sources/configuration/integrations/cadvisor-config.md ---
---
aliases:
- /docs/agent/latest/configuration/integrations/cadvisor-config/
title: cadvisor_config
---

# cadvisor_config

The `cadvisor_config` block configures the `cadvisor` integration,
which is an embedded version of
[`cadvisor`](https://github.com/google/cadvisor). This allows for the collection of container utilization metrics.

The cAdvisor integration requires some broad privileged permissions to the host. Without these permissions the metrics will not be accessible. This means that the agent must *also* have those elevated permissions.

A good example of the required file, and system permissions can be found in the docker run command published in the [cAdvisor docs](https://github.com/google/cadvisor#quick-start-running-cadvisor-in-a-docker-container).

Full reference of options:

```yaml
  # Enables the cadvisor integration, allowing the Agent to automatically
  # collect metrics for the specified github objects.
  [enabled: <boolean> | default = false]

  # Sets an explicit value for the instance label when the integration is
  # self-scraped. Overrides inferred values.
  [instance: <string> | default = <integrations_config.instance>]

  # Automatically collect metrics from this integration. If disabled,
  # the cadvisor integration will be run but not scraped and thus not
  # remote-written. Metrics for the integration will be exposed at
  # /integrations/cadvisor/metrics and can be scraped by an external
  # process.
  [scrape_integration: <boolean> | default = <integrations_config.scrape_integrations>]

  # How often should the metrics be collected? Defaults to
  # prometheus.global.scrape_interval.
  [scrape_interval: <duration> | default = <global_config.scrape_interval>]

  # The timeout before considering the scrape a failure. Defaults to
  # prometheus.global.scrape_timeout.
  [scrape_timeout: <duration> | default = <global_config.scrape_timeout>]

  # Allows for relabeling labels on the target.
  relabel_configs:
    [- <relabel_config> ... ]

  # Relabel metrics coming from the integration, allowing to drop series
  # from the integration that you don't care about.
  metric_relabel_configs:
    [ - <relabel_config> ... ]

  # How frequent to truncate the WAL for this integration.
  [wal_truncate_frequency: <duration> | default = "60m"]

  #
  # cAdvisor-specific configuration options
  #

  # Convert container labels and environment variables into labels on prometheus metrics for each container. If false, then only metrics exported are container name, first alias, and image name.
  [store_container_labels: <boolean> | default = true]

  # List of container labels to be converted to labels on prometheus metrics for each container. store_container_labels must be set to false for this to take effect.
  allowlisted_container_labels:
    [ - <string> ]

  # List of environment variable keys matched with specified prefix that needs to be collected for containers, only support containerd and docker runtime for now.
  env_metadata_allowlist:
    [ - <string> ]

  # List of cgroup path prefix that needs to be collected even when docker_only is specified.
  raw_cgroup_prefix_allowlist:
    [ - <string> ]

  # Path to a JSON file containing configuration of perf events to measure. Empty value disabled perf events measuring.
  [perf_events_config: <boolean>]

  # resctrl mon groups updating interval. Zero value disables updating mon groups.
  [resctrl_interval: <int> | default = 0]

  # List of `metrics` to be disabled. If set, overrides the default disabled metrics.
  disabled_metrics:
    [ - <string> ]

  # List of `metrics` to be enabled. If set, overrides disabled_metrics
  enabled_metrics:
    [ - <string> ]

  # Length of time to keep data stored in memory
  [storage_duration: <duration> | default = "2m"]

  # Containerd endpoint
  [containerd: <string> | default = "/run/containerd/containerd.sock"]

  # Containerd namespace
  [containerd_namespace: <string> | default = "k8s.io"]

  # Docker endpoint
  [docker: <string> | default = "unix:///var/run/docker.sock"]

  # Use TLS to connect to docker
  [docker_tls: <boolean> | default = false]

  # Path to client certificate for TLS connection to docker
  [docker_tls_cert: <string> | default = "cert.pem"]

  # Path to private key for TLS connection to docker
  [docker_tls_key: <string> | default = "key.pem"]

  # Path to a trusted CA for TLS connection to docker
  [docker_tls_ca: <string> | default = "ca.pem"]

  # Only report docker containers in addition to root stats
  [docker_only: <boolean> | default = false]
```

'''
'''--- docs/sources/configuration/integrations/consul-exporter-config.md ---
---
aliases:
- /docs/agent/latest/configuration/integrations/consul-exporter-config/
title: consul_exporter_config
---

# consul_exporter_config

The `consul_exporter_config` block configures the `consul_exporter`
integration, which is an embedded version of
[`consul_exporter`](https://github.com/prometheus/consul_exporter). This allows
for the collection of consul metrics and exposing them as Prometheus metrics.

Full reference of options:

```yaml
  # Enables the consul_exporter integration, allowing the Agent to automatically
  # collect system metrics from the configured consul server address
  [enabled: <boolean> | default = false]

  # Sets an explicit value for the instance label when the integration is
  # self-scraped. Overrides inferred values.
  #
  # The default value for this integration is inferred from the hostname portion
  # of the server URL.
  [instance: <string>]

  # Automatically collect metrics from this integration. If disabled,
  # the consul_exporter integration will be run but not scraped and thus not
  # remote-written. Metrics for the integration will be exposed at
  # /integrations/consul_exporter/metrics and can be scraped by an external
  # process.
  [scrape_integration: <boolean> | default = <integrations_config.scrape_integrations>]

  # How often should the metrics be collected? Defaults to
  # prometheus.global.scrape_interval.
  [scrape_interval: <duration> | default = <global_config.scrape_interval>]

  # The timeout before considering the scrape a failure. Defaults to
  # prometheus.global.scrape_timeout.
  [scrape_timeout: <duration> | default = <global_config.scrape_timeout>]

  # Allows for relabeling labels on the target.
  relabel_configs:
    [- <relabel_config> ... ]

  # Relabel metrics coming from the integration, allowing to drop series
  # from the integration that you don't care about.
  metric_relabel_configs:
    [ - <relabel_config> ... ]

  # How frequent to truncate the WAL for this integration.
  [wal_truncate_frequency: <duration> | default = "60m"]

  # Monitor the exporter itself and include those metrics in the results.
  [include_exporter_metrics: <bool> | default = false]

  #
  # Exporter-specific configuration options
  #

  # Prefix from which to expose key/value pairs.
  [kv_prefix: <string> | default = ""]

  # Regex that determines which keys to expose.
  [kv_filter: <string> | default = ".*"]

  # Generate a health summary for each service instance. Needs n+1 queries to
  # collect all information.
  [generate_health_summary: <bool> | default = true]

  # HTTP API address of a Consul server or agent. Prefix with https:// to
  # connect using HTTPS.
  [server: <string> | default = "http://localhost:8500"]

  # Disable TLS host verification.
  [insecure_skip_verify: <bool> | default = false]

  # File path to a PEM-encoded certificate authority used to validate the
  # authenticity of a server certificate.
  [ca_file: <string> | default = ""]

  # File path to a PEM-encoded certificate used with the private key to verify
  # the exporter's authenticity.
  [cert_file: <string> | default = ""]

  # File path to a PEM-encoded private key used with the certificate to verify
  # the exporter's authenticity.
  [key_file: <string> | default = ""]

  # When provided, this overrides the hostname for the TLS certificate. It can
  # be used to ensure that the certificate name matches the hostname we declare.
  [server_name: <string> | default = ""]

  # Timeout on HTTP requests to the Consul API.
  [timeout: <duration> | default = "500ms"]

  # Limit the maximum number of concurrent requests to consul. 0 means no limit.
  [concurrent_request_limit: <int> | default = 0]

  # Allows any Consul server (non-leader) to service a read.
  [allow_stale: <bool> | default = true]

  # Forces the read to be fully consistent.
  [require_consistent: <bool> | default = false]
```

'''
'''--- docs/sources/configuration/integrations/dnsmasq-exporter-config.md ---
---
aliases:
- /docs/agent/latest/configuration/integrations/dnsmasq-exporter-config/
title: dnsmasq_exporter_config
---

# dnsmasq_exporter_config

The `dnsmasq_exporter_config` block configures the `dnsmasq_exporter` integration,
which is an embedded version of
[`dnsmasq_exporter`](https://github.com/google/dnsmasq_exporter). This allows for
the collection of metrics from dnsmasq servers.

Note that currently, an Agent can only collect metrics from a single dnsmasq
server. If you want to collect metrics from multiple servers, you can run
multiple Agents and add labels using `relabel_configs` to differentiate between
the servers:

```yaml
dnsmasq_exporter:
  enabled: true
  dnsmasq_address: dnsmasq-a:53
  relabel_configs:
  - source_labels: [__address__]
    target_label: instance
    replacement: dnsmasq-a
```

Full reference of options:

```yaml
  # Enables the dnsmasq_exporter integration, allowing the Agent to automatically
  # collect system metrics from the configured dnsmasq server address
  [enabled: <boolean> | default = false]

  # Sets an explicit value for the instance label when the integration is
  # self-scraped. Overrides inferred values.
  #
  # The default value for this integration is inferred from the dnsmasq_address
  # value.
  [instance: <string>]

  # Automatically collect metrics from this integration. If disabled,
  # the dnsmasq_exporter integration will be run but not scraped and thus not
  # remote-written. Metrics for the integration will be exposed at
  # /integrations/dnsmasq_exporter/metrics and can be scraped by an external
  # process.
  [scrape_integration: <boolean> | default = <integrations_config.scrape_integrations>]

  # How often should the metrics be collected? Defaults to
  # prometheus.global.scrape_interval.
  [scrape_interval: <duration> | default = <global_config.scrape_interval>]

  # The timeout before considering the scrape a failure. Defaults to
  # prometheus.global.scrape_timeout.
  [scrape_timeout: <duration> | default = <global_config.scrape_timeout>]

  # Allows for relabeling labels on the target.
  relabel_configs:
    [- <relabel_config> ... ]

  # Relabel metrics coming from the integration, allowing to drop series
  # from the integration that you don't care about.
  metric_relabel_configs:
    [ - <relabel_config> ... ]

  # How frequent to truncate the WAL for this integration.
  [wal_truncate_frequency: <duration> | default = "60m"]

  # Monitor the exporter itself and include those metrics in the results.
  [include_exporter_metrics: <bool> | default = false]

  #
  # Exporter-specific configuration options
  #

  # Address of the dnsmasq server in host:port form.
  [dnsmasq_address: <string> | default = "localhost:53"]

  # Path to the dnsmasq leases file. If this file doesn't exist, scraping
  # dnsmasq # will fail with an warning log message.
  [leases_path: <string> | default = "/var/lib/misc/dnsmasq.leases"]
```

'''
'''--- docs/sources/configuration/integrations/ebpf-config.md ---
---
aliases:
- /docs/agent/latest/configuration/integrations/ebpf-config/
title: ebpf_config
---

# ebpf_config

The `ebpf_config` block configures the Agent's eBPF integration.
It is an embedded version of
[`ebpf_exporter`](https://github.com/cloudflare/ebpf_exporter)
that allows the Agent to attach eBPF programs to the host kernel
and export defined metrics in a Prometheus-compatible format.

As such, this integration is only supported on Linux/AMD64, and
it comes with the relevant caveats of running eBPF programs 
on your host, like being on a kernel version >4.1, specific
kernel flags being enabled, plus having superuser access.

Currently, the exporter only supports `kprobes`, that is
kernel-space probes.

Configuration reference:

```yaml
  ## ebpf runs the provided 'programs' on the host's kernel
  ## and reports back on the metrics attached to them.
  programs: 
     [- <program_config> ... ]
```

Each provided [`<program_config>`](https://pkg.go.dev/github.com/cloudflare/ebpf_exporter@v1.2.5/config#Program) block defines a single eBPF program that the integration should run, along with what metrics should be attached to it.

Here's an [example](https://github.com/cloudflare/ebpf_exporter/blob/master/examples/cachestat.yaml) of a valid configuration that includes a program to measure hits and misses to the file system page cache.

```yaml
programs:
- name: cachestat
  metrics:
    counters:
      - name: page_cache_ops_total
        help: Page cache operation counters by type
        table: counts
        labels:
          - name: op
            size: 8
            decoders:
              - name: ksym
  kprobes:
    add_to_page_cache_lru: do_count
    mark_page_accessed: do_count
    account_page_dirtied: do_count
    mark_buffer_dirty: do_count
  code: |
    #include <uapi/linux/ptrace.h>
    BPF_HASH(counts, u64);
    int do_count(struct pt_regs *ctx) {
        counts.increment(PT_REGS_IP(ctx) - 1);
        return 0;
    }
```

'''
'''--- docs/sources/configuration/integrations/elasticsearch-exporter-config.md ---
---
aliases:
- /docs/agent/latest/configuration/integrations/elasticsearch-exporter-config/
title: elasticsearch_exporter_config
---

# elasticsearch_exporter_config

The `elasticsearch_exporter_config` block configures the `elasticsearch_exporter` integration,
which is an embedded version of
[`elasticsearch_exporter`](https://github.com/prometheus-community/elasticsearch_exporter). This allows for
the collection of metrics from ElasticSearch servers.

Note that currently, an Agent can only collect metrics from a single ElasticSearch server.
However, the exporter is able to collect the metrics from all nodes through that server configured.

We strongly recommend that you configure a separate user for the Agent, and give it only the strictly mandatory
security privileges necessary for monitoring your node, as per the [official documentation](https://github.com/prometheus-community/elasticsearch_exporter#elasticsearch-7x-security-privileges).

Full reference of options:

```yaml
  # Enables the elasticsearch_exporter integration, allowing the Agent to automatically
  # collect system metrics from the configured ElasticSearch server address
  [enabled: <boolean> | default = false]

  # Sets an explicit value for the instance label when the integration is
  # self-scraped. Overrides inferred values.
  #
  # The default value for this integration is inferred from the hostname portion
  # of address.
  [instance: <string>]

  # Automatically collect metrics from this integration. If disabled,
  # the elasticsearch_exporter integration will be run but not scraped and thus not
  # remote-written. Metrics for the integration will be exposed at
  # /integrations/elasticsearch_exporter/metrics and can be scraped by an external
  # process.
  [scrape_integration: <boolean> | default = <integrations_config.scrape_integrations>]

  # How often should the metrics be collected? Defaults to
  # prometheus.global.scrape_interval.
  [scrape_interval: <duration> | default = <global_config.scrape_interval>]

  # The timeout before considering the scrape a failure. Defaults to
  # prometheus.global.scrape_timeout.
  [scrape_timeout: <duration> | default = <global_config.scrape_timeout>]

  # Allows for relabeling labels on the target.
  relabel_configs:
    [- <relabel_config> ... ]

  # Relabel metrics coming from the integration, allowing to drop series
  # from the integration that you don't care about.
  metric_relabel_configs:
    [ - <relabel_config> ... ]

  # How frequent to truncate the WAL for this integration.
  [wal_truncate_frequency: <duration> | default = "60m"]

  # Monitor the exporter itself and include those metrics in the results.
  [include_exporter_metrics: <bool> | default = false]

  #
  # Exporter-specific configuration options
  #

  # HTTP API address of an Elasticsearch node.
  [ address: <string> | default = "http://localhost:9200" ]

  # Timeout for trying to get stats from Elasticsearch.
  [ timeout: <duration> | default = "5s" ]

  # Export stats for all nodes in the cluster. If used, this flag will override the flag `node`.
  [ all: <boolean> ]

  # Node's name of which metrics should be exposed.
  [ node: <boolean> ]

  # Export stats for indices in the cluster.
  [ indices: <boolean> ]

  # Export stats for settings of all indices of the cluster.
  [ indices_settings: <boolean> ]

  # Export stats for cluster settings.
  [ cluster_settings: <boolean> ]

  # Export stats for shards in the cluster (implies indices).
  [ shards: <boolean> ]

  # Export stats for the cluster snapshots.
  [ snapshots: <boolean> ]

  # Cluster info update interval for the cluster label.
  [ clusterinfo_interval: <duration> | default = "5m" ]

  # Path to PEM file that contains trusted Certificate Authorities for the Elasticsearch connection.
  [ ca: <string> ]

  # Path to PEM file that contains the private key for client auth when connecting to Elasticsearch.
  [ client_private_key: <string> ]

  # Path to PEM file that contains the corresponding cert for the private key to connect to Elasticsearch.
  [ client_cert: <string> ]

  # Skip SSL verification when connecting to Elasticsearch.
  [ ssl_skip_verify: <boolean> ]
```

'''
'''--- docs/sources/configuration/integrations/github-exporter-config.md ---
---
aliases:
- /docs/agent/latest/configuration/integrations/github-exporter-config/
title: github_exporter_config
---

# github_exporter_config

The `github_exporter_config` block configures the `github_exporter` integration,
which is an embedded version of
[`github_exporter`](https://github.com/infinityworks/github-exporter). This allows for the collection of metrics from the github api.

We strongly recommend that you configure a separate authentication token for the Agent, and give it only the strictly mandatory
security privileges necessary for monitoring your repositories, as per the [official documentation](https://docs.github.com/en/rest/reference/permissions-required-for-github-apps).
We also recommend that you use `api_token_file` parameter, to avoid setting the authentication token directly on the Agent config file.

Full reference of options:

```yaml
  # Enables the github_exporter integration, allowing the Agent to automatically
  # collect metrics for the specified github objects.
  [enabled: <boolean> | default = false]

  # Sets an explicit value for the instance label when the integration is
  # self-scraped. Overrides inferred values.
  #
  # The default value for this integration is inferred from the hostname portion
  # of api_url.
  [instance: <string>]

  # Automatically collect metrics from this integration. If disabled,
  # the github_exporter integration will be run but not scraped and thus not
  # remote-written. Metrics for the integration will be exposed at
  # /integrations/github_exporter/metrics and can be scraped by an external
  # process.
  [scrape_integration: <boolean> | default = <integrations_config.scrape_integrations>]

  # How often should the metrics be collected? Defaults to
  # prometheus.global.scrape_interval.
  [scrape_interval: <duration> | default = <global_config.scrape_interval>]

  # The timeout before considering the scrape a failure. Defaults to
  # prometheus.global.scrape_timeout.
  [scrape_timeout: <duration> | default = <global_config.scrape_timeout>]

  # Allows for relabeling labels on the target.
  relabel_configs:
    [- <relabel_config> ... ]

  # Relabel metrics coming from the integration, allowing to drop series
  # from the integration that you don't care about.
  metric_relabel_configs:
    [ - <relabel_config> ... ]

  # How frequent to truncate the WAL for this integration.
  [wal_truncate_frequency: <duration> | default = "60m"]

  #
  # Exporter-specific configuration options
  #

  # The full URI of the github API.
  [api_url: <string> | default = "https://api.github.com"]

  # A list of github repositories for which to collect metrics.
  repositories:
    [ - <string> ]

  # A list of github organizations for which to collect metrics.
  organizations:
    [ - <string> ]

  # A list of github users for which to collect metrics.
  users:
    [ - <string> ]

  # A github authentication token that allows the API to be queried more often.
  # Optional, but recommended.
  [api_token: <string>]

  # A path to a file containing a github authentication token that allows the
  # API to be queried more often. If supplied, this supercedes `api_token`
  # Optional, but recommended.
  [api_token_file: <string>]
```

'''
'''--- docs/sources/configuration/integrations/integrations-next/_index.md ---
---
aliases:
- /docs/agent/latest/configuration/integrations/integrations-next/
title: Integrations Revamp
weight: 100
---

# Integrations Revamp (Experimental)

Release v0.22.0 of Grafana Agent includes experimental support for a revamped
integrations subsystem. The integrations subsystem is the second oldest part of
Grafana Agent, and has started to feel out of place as we built out the
project.

The revamped integrations subsystem can be enabled by passing
`integrations-next` to the `-enable-features` command line flag. As an
experimental feature, there are no stability guarantees, and it may receive a
higher frequency of breaking changes than normal.

The revamped integrations subsystem has the following benefits over the
original subsystem:

* Integrations can opt in to supporting multiple instances. For example, you
  may now run any number of `redis_exporter` integrations, where before you
  could only have one per agent. Integrations such as `node_exporter` still
  only support a single instance, as it wouldn't make sense to have multiple
  instances of those.

* Autoscrape (previously called "self-scraping"), when enabled, now supports
  sending metrics for an integration directly to a running metrics instance.
  This allows you configuring an integration to send to a specific Prometheus
  remote_write endpoint.

* A new service discovery HTTP API is included. This can be used with
  Prometheus' [http_sd_config][http_sd_config]. The API returns extra labels
  for integrations that previously were only availble when autoscraping, such
  as `agent_hostname`.

* Integrations that aren't Prometheus exporters may now be added, such as
  integrations that generate logs or traces.

* Autoscrape, when enabled, now works completely in-memory without using the
  network.

[http_sd_config]: https://prometheus.io/docs/prometheus/latest/configuration/configuration/#http_sd_config

## Config changes

The revamp contains a number of breaking changes to the config. The schema of the
`integrations` key in the config file is now the following:

```yaml
integrations:
  # Controls settings for integrations that generate metrics.
  metrics:
    # Controls default settings for autoscrape. Individual instances of
    # integrations inherit the defaults and may override them.
    autoscrape:
      # Enables autoscrape of integrations.
      [enable: <boolean> | default = true]

      # Specifies the metrics instance name to send metrics to. Instance
      # names are located at metrics.configs[].name from the top-level config.
      # The instance must exist.
      #
      # As it is common to use the name "default" for your primary instance,
      # we assume the same here.
      [metrics_instance: <string> | default = "default"]

      # Autoscrape interval and timeout. Defaults are inherited from the global
      # section of the top-level metrics config.
      [scrape_interval: <duration> | default = <metrics.global.scrape_interval>]
      [scrape_timeout: <duration> | default = <metrics.global.scrape_timeout>]

  # Configs for integrations which do not support multiple instances.
  [agent: <agent_config>]
  [cadvisor: <cadvisor_config>]
  [node_exporter: <node_exporter_config>]
  [process: <process_exporter_config>]
  [statsd: <statsd_exporter_config>]
  [windows: <windows_exporter_config>]
  [eventhandler: <eventhandler_config>]
  [snmp: <snmp_exporter_config>]
  [ebpf: <ebpf_config>]

  # Configs for integrations that do support multiple instances. Note that
  # these must be arrays.
  consul_configs:
    [- <consul_exporter_config> ...]

  dnsmasq_configs:
    [- <dnsmasq_exporter_config> ...]

  elasticsearch_configs:
    [- <elasticsearch_exporter_config> ...]

  github_configs:
    [- <github_exporter_config> ...]

  kafka_configs:
    [- <kafka_exporter_config> ...]

  memcached_configs:
    [- <memcached_exporter_config> ...]

  mongodb_configs:
    [- <mongodb_exporter_config> ...]

  mysql_configs:
    [- <mysqld_exporter_config> ...]

  postgres_configs:
    [- <postgres_exporter_config> ...]

  redis_configs:
    [- <redis_exporter_config> ...]

  app_agent_receiver_configs:
    [- <app_agent_receiver_config>]

  apache_http_configs:
    [- <apache_http_config>]

  vsphere_configs:
    [- <vsphere_config>]
```

Note that most integrations are no longer configured with the `_exporter` name.
`node_exporter` is the only integration with `_exporter` name due to its
popularity in the Prometheus ecosystem.

## Integrations changes

Integrations no longer support an `enabled` field; they are enabled by being
defined in the YAML. To disable an integration, comment it out or remove it.

Metrics-based integrations now use this common set of options:

```yaml
# Provide an explicit value to uniquely identify this instance of the
# integration. If not provided, a reasonable default will be inferred based
# on the integration.
#
# The value here must be unique across all instances of the same integration.
[instance: <string>]

# Override autoscrape defaults for this integration.
autoscrape:
  # Enables autoscrape of integrations.
  [enable: <boolean> | default = <integrations.metrics.autoscrape.enable>]

  # Specifies the metrics instance name to send metrics to.
  [metrics_instance: <string> | default = <integrations.metrics.autoscrape.metrics_instance>]

  # Relabel the autoscrape job.
  relabel_configs:
    [- <relabel_config> ... ]

  # Relabel metrics coming from the integration.
  metric_relabel_configs:
    [ - <relabel_config> ... ]

  # Autoscrape interval and timeout.
  [scrape_interval: <duration> | default = <integrations.metrics.autoscrape.scrape_interval>]
  [scrape_timeout: <duration> | default = <integrations.metrics.autoscrape.scrape_timeout>]

# An optional extra set of labels to add to metrics from the integration target. These
# labels are only exposed via the integration service discovery HTTP API and
# added when autoscrape is used. They will not be found directly on the metrics
# page for an integration.
extra_labels:
  [ <labelname>: <labelvalue> ... ]
```

The old set of common options have been removed and do not work when the revamp
is being used:

```yaml
# OLD SCHEMA: NO LONGER SUPPORTED

[enabled: <boolean> | default = false]
[instance: <string>]
[scrape_integration: <boolean> | default = <integrations_config.scrape_integrations>]
[scrape_interval: <duration> | default = <global_config.scrape_interval>]
[scrape_timeout: <duration> | default = <global_config.scrape_timeout>]
[wal_truncate_frequency: <duration> | default = "60m"]
relabel_configs:
  [- <relabel_config> ...]
metric_relabel_configs:
  [ - <relabel_config> ...]
```

'''
'''--- docs/sources/configuration/integrations/integrations-next/app-agent-receiver-config.md ---
---
aliases:
- /docs/agent/latest/configuration/integrations/integrations-next/app-agent-receiver-config/
title: app_agent_config
---

# app_agent_receiver_config

The `app_agent_receiver_config` block configures the `app_agent_receiver`
integration. This integration exposes a http endpoint that can receive telemetry
from the [Grafana Javascript Agent](https://github.com/grafana/grafana-javascript-agent)
and forward it to logs, traces or metrics backends.

These are the options you have for configuring the app_agent_receiver integration.

```yaml
  autoscrape:
    # Enables autoscrape of integrations.
    [enable: <boolean> | default = true]

    # Specifies the metrics instance name to send metrics to. Instance
    # names are located at metrics.configs[].name from the top-level config.
    # The instance must exist.
    #
    # As it is common to use the name "default" for your primary instance,
    # we assume the same here.
    [metrics_instance: <string> | default = "default"]

    # Autoscrape interval and timeout. Defaults are inherited from the global
    # section of the top-level metrics config.
    [scrape_interval: <duration> | default = <metrics.global.scrape_interval>]
    [scrape_timeout: <duration> | default = <metrics.global.scrape_timeout>]

  # Integration instance name
  [instance: <string>]

  # Traces instance to send traces to. This assumes that you have a traces config with such instance defined
  [traces_instance: <string> | default = ""]

  # Logs instance to send logs and exceptions to. This assumes that you have a logs
  # config with the instance defined
  [logs_instance: <string> | default = ""]

  # Server config refers to the HTTP endpoint that the integration will be exposing
  # to receive data from.
  server:
    [host: <string> | default = "127.0.0.1"]
    [port: <number> | default = 12347]
    
    # Domains in which the agent is sending data from. For example "https://myapp.com"
    cors_allowed_origins:
      [- <string>]

    # Configure rate limiting. The HTTP server of the App observability implements
    # a token bucket rate limitng algorithm in which we can configure the maximum RPS
    # as well as the burstiness (peaks of RPS)
    rate_limiting:
      [enabled: <boolean> | default = false]
      [rps: <number> | default = 100]
      [burstiness: <number> | default = 50]
    
    # If configured, incoming requests will be required to specify this key in "x-api-key" header
    [api_key: <string>]

    # Max allowed payload size in bytes for the JSON payload. Interanlly the
    # Content-Length header is used to make this check
    [max_allowed_payload_size: <number> | default = 0]

  # Labels to set for the log entry. 
  # If value is specified, it will be used.
  # If value is empty and key exists in data, it's value will be used from data
  logs_labels:
    [- <key>: <string>]

  # Timeout duration when sending an entry to Loki, milliseconds
  [logs_send_timeout: <duration> | default = 2s]

  # Sourcemap configuration for enabling stack trace transformation to original source locations
  [sourcemaps: <sourcemap_config>]
```

## sourcemap_config

```yaml
# Whether agent should attempt to download compiled sources and source maps
[download: <boolean> | default = false]

# List of HTTP origins to download sourcemaps for
[download_origins: []<string> | default = ["*"]]

# Timeout for downloading compiled sources and sourcemaps
[download_timeout: <duration> | default = "1s"]

# Sourcemap locations on filesystem. Takes precedence over downloading if both methods are enabled
filesystem:
  [- <sourcemap_file_location>]
```

## sourcemap_file_location

```yaml
# Source URL prefix. If a minified source URL matches this prefix,
# a filepath is constructed by removing the prefix, prepending path below and appending ".map".
#
# Example:
#
# minified_path_prefix = "https://my-app.dev/static/"
# path = "/var/app/static/"
#
# Then given source url "https://my-app.dev/static/foo.js"
# it will look for sourcemap at "/var/app/static/foo.js.map"

minified_path_prefix: <string> 

# Directory on file system that contains source maps. 
# See above for more detailed explanation.
# It is parsed as a Go template. You can use "{{.Release }}" which will be replaced with
# app.release meta property.
path: <string>
```

'''
'''--- docs/sources/configuration/integrations/integrations-next/eventhandler-config.md ---
---
aliases:
- /docs/agent/latest/configuration/integrations/integrations-next/eventhandler-config/
title: eventhandler_config
---

# eventhandler_config

`eventhandler_config` configures the Kubernetes eventhandler integration. This
integration watches
[Event](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.19/#event-v1-core)
resources in a Kubernetes cluster and forwards them as log entries to a Loki
sink. This integration depends on the experimental `integrations-next` feature
being enabled.

On restart, the integration will look for a cache file (configured using
`cache_path`) that stores the last shipped event. This file is optional, and if
present, will be used to avoid double-shipping events if Agent or the
integration restarts. Kubernetes expires events after 60 minutes, so events
older than 60 minutes ago will never be shipped.

To use the cache feature and maintain state in a Kubernetes environment, a
[StatefulSet](https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/)
must be used. Sample manifests are provided at the bottom of this doc. Please
adjust these according to your deployment preferences. You can also use a
Deployment, however the presence of the cache file will not be guaranteed and
the integration may ship duplicate entries in the event of a restart. Loki does
not yet support entry deduplication for the A->B->A case, so further
deduplication can only take place at the Grafana / front-end layer (Grafana
Explore does provide some deduplication features for Loki datasources).

This integration uses Grafana Agent's embedded Loki-compatible `logs` subsystem
to ship entries, and a logs client and sink must be configured to use the
integration. Please see the sample Agent config below for an example
configuration.
[Pipelines](https://grafana.com/docs/loki/latest/clients/promtail/pipelines/)
and relabel configuration are not yet supported, but these features will be
added soon. You should use the `job=eventhandler cluster=...` labels to query
your events (you can then use LogQL on top of the result set).

If not running the integration in-cluster, the integration will use
`kubeconfig_path` to search for a valid Kubeconfig file, defaulting to a
kubeconfig in the user's home directory. If running in-cluster, the appropriate
`ServiceAccount` and Roles must be defined. Sample manifests are provided
below.

Configuration reference:

```yaml
  ## Eventhandler hands watched events off to promtail using a promtail
  ## client channel. This parameter configures how long to wait (in seconds) on the channel
  ## before abandoning and moving on.
  [send_timeout: <int> | default = 60]

  ## Configures the path to a kubeconfig file. If not set, will fall back to using
  ## an in-cluster config. If this fails, will fall back to checking the user's home
  ## directory for a kubeconfig.
  [kubeconfig_path: <string>]

  ## Path to a cache file that will store the last timestamp for a shipped event and events
  ## shipped for that timestamp. Used to prevent double-shipping on integration restart.
  [cache_path: <string> | default = "./.eventcache/eventhandler.cache"]

  ## Name of logs subsystem instance to hand log entries off to.
  [logs_instance: <string> | default = "default"]

  ## K8s informer resync interval (seconds). You should use defaults here unless you are
  ## familiar with K8s informers.
  [informer_resync: <int> | default = 120]

  ## The integration will flush the last event shipped out to disk every flush_interval seconds.
  [flush_interval: <int> | default = 10]

  ## If you would like to limit events to a given namespace, use this parameter.
  [namespace: <string>]

  ## Configure extra labels to add to log lines
  extra_labels:
    { <string>: <string> }
```

Sample agent config:

```yaml
server:
  log_level: info

integrations:
  eventhandler:
    cache_path: "/etc/eventhandler/eventhandler.cache"

logs:
  configs:
  - name: default
    clients:
    - url: https://logs-prod-us-central1.grafana.net/api/prom/push
      basic_auth:
        username: YOUR_LOKI_USER
        password: YOUR_LOKI_API_KEY
      external_labels:
        cluster: "cloud"
    positions:
      filename: /tmp/positions0.yaml
```

Be sure to replace the Loki credentials with the appropriate values.

Sample StatefulSet manifests. Please adjust these according to your needs:

```yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: grafana-agent-eventhandler
  namespace: default
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: grafana-agent-eventhandler
rules:
- apiGroups:
  - ""
  resources:
  - events
  verbs:
  - get
  - list
  - watch
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: grafana-agent-eventhandler
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: grafana-agent-eventhandler
subjects:
- kind: ServiceAccount
  name: grafana-agent-eventhandler
  namespace: default
---
apiVersion: v1
kind: Service
metadata:
  name: grafana-agent-eventhandler-svc
spec:
  ports:
  - port: 12345
    name: http-metrics
  clusterIP: None
  selector:
    name: grafana-agent-eventhandler
---
kind: ConfigMap
metadata:
  name: grafana-agent-eventhandler
  namespace: default
apiVersion: v1
data:
  agent.yaml: |
    server:
      log_level: info

    integrations:
      eventhandler:
        cache_path: "/etc/eventhandler/eventhandler.cache"

    logs:
      configs:
      - name: default
        clients:
        - url: https://logs-prod-us-central1.grafana.net/api/prom/push
          basic_auth:
            username: YOUR_LOKI_USER
            password: YOUR_LOKI_API_KEY
          external_labels:
            cluster: "cloud"
        positions:
          filename: /tmp/positions0.yaml
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: grafana-agent-eventhandler
  namespace: default
spec:
  serviceName: "grafana-agent-eventhandler-svc"
  selector:
    matchLabels:
      name: grafana-agent-eventhandler
  replicas: 1
  template:
    metadata:
      labels:
        name: grafana-agent-eventhandler
    spec:
      terminationGracePeriodSeconds: 10
      containers:
      - name: agent
        image: grafana/agent:main
        imagePullPolicy: IfNotPresent
        args:
        - -config.file=/etc/agent/agent.yaml
        - -enable-features=integrations-next
        - -server.http.address=0.0.0.0:12345
        command:
        - /bin/agent
        env:
        - name: HOSTNAME
          valueFrom:
            fieldRef:
              fieldPath: spec.nodeName
        ports:
        - containerPort: 12345
          name: http-metrics
        volumeMounts:
        - name: grafana-agent
          mountPath: /etc/agent
        - name: eventhandler-cache
          mountPath: /etc/eventhandler
      serviceAccount: grafana-agent-eventhandler
      volumes:
        - configMap:
            name: grafana-agent-eventhandler
          name: grafana-agent
  volumeClaimTemplates:
  - metadata:
      name: eventhandler-cache
    spec:
      accessModes: [ "ReadWriteOnce" ]
      resources:
        requests:
          storage: 1Gi
```

'''
'''--- docs/sources/configuration/integrations/integrations-next/snmp-config.md ---
---
aliases:
- /docs/agent/latest/configuration/integrations/integrations-next/snmp-config/
title: snmp_exporter_config
---

# snmp config

The `snmp` block configures the `snmp` integration,
which is an embedded version of
[`snmp_exporter`](https://github.com/prometheus/snmp_exporter). This allows collection of SNMP metrics from the network devices with ease.

## Quick configuration example

To get started, define SNMP targets in Grafana agent's integration block:

```yaml
metrics:
  wal_directory: /tmp/wal
integrations:
  snmp:
    snmp_targets:
      - name: network_switch_1
        address: 192.168.1.2
        module: if_mib
        walk_params: public
      - name: network_router_2
        address: 192.168.1.3
        module: mikrotik
        walk_params: private
    walk_params:
      private:
        version: 2
        auth:
          community: mysecret
      public:
        version: 2
        auth:
          community: public
```

## Prometheus service discovery use case

If you need to scrape SNMP devices in more dynamic environment, and cannot define devices in `snmp_targets` because targets would change over time, you can use service discovery approach. For instance, with [DNS discovery](https://prometheus.io/docs/prometheus/latest/configuration/configuration/#dns_sd_config):

```yaml

metrics:
  wal_directory: /tmp/wal
  configs:
    - name: snmp_targets
      scrape_configs:
        - job_name: 'snmp'
          dns_sd_configs:
            - names:
              - switches.srv.example.org
              - routers.srv.example.org
          params:
            module: [if_mib]
            walk_params: [private]
          metrics_path: /integrations/snmp/metrics
          relabel_configs:
            - source_labels: [__address__]
              target_label: __param_target
            - source_labels: [__param_target]
              target_label: instance
            - replacement: 127.0.0.1:12345 # address must match grafana agent -server.http.address flag
              target_label: __address__
integrations:
  snmp:
    autoscrape:
      enabled: false # set autoscrape to off
    walk_params:
      private:
        version: 2
        auth:
          community: secretpassword
```

Full reference of options:

```yaml
  # Provide an explicit value to uniquely identify this instance of the
  # integration. If not provided, a reasonable default will be inferred based
  # on the integration.
  #
  # The value here must be unique across all instances of the same integration.
  [instance: <string>]

  # Override autoscrape defaults for this integration.
  autoscrape:
    # Enables autoscrape of integrations.
    [enable: <boolean> | default = <integrations.metrics.autoscrape.enable>]

    # Specifies the metrics instance name to send metrics to.
    [metrics_instance: <string> | default = <integrations.metrics.autoscrape.metrics_instance>]

    # Autoscrape interval and timeout.
    [scrape_interval: <duration> | default = <integrations.metrics.autoscrape.scrape_interval>]
    [scrape_timeout: <duration> | default = <integrations.metrics.autoscrape.scrape_timeout>]

  # An optional extra set of labels to add to metrics from the integration target. These
  # labels are only exposed via the integration service discovery HTTP API and
  # added when autoscrape is used. They will not be found directly on the metrics
  # page for an integration.
  extra_labels:
    [ <labelname>: <labelvalue> ... ]

  #
  # Exporter-specific configuration options
  #

  # SNMP configuration file with custom modules.
  # See https://github.com/prometheus/snmp_exporter#generating-configuration for more details how to generate custom snmp.yml file.
  # If not defined, embedded snmp_exporter default set of modules is used.
  [config_file: <string> | default = ""]

  # List of SNMP targets to poll
  snmp_targets:
    [- <snmp_target> ... ]

  # Map of SNMP connection profiles that can be used to override default SNMP settings.
  walk_params:
    [ <string>: <walk_param> ... ]

```
## snmp_target config

```yaml
  # Name of a snmp_target
  [name: <string>]

  # The address of SNMP device
  [address: <string>]

  # SNMP module to use for polling
  [module: <string> | default = ""]

  # walk_param config to use for this snmp_target
  [walk_params: <string> | default = ""]
```

## walk_param config

```yaml
  # SNMP version to use. Defaults to 2.
  # 1 will use GETNEXT, 2 and 3 use GETBULK.
  [version: <int> | default = 2]

  # How many objects to request with GET/GETBULK, defaults to 25.
  # May need to be reduced for buggy devices.
  [max_repetitions: <int> | default = 25]

  # How many times to retry a failed request, defaults to 3.
  [retries: <int> | default = 25]

  # Timeout for each SNMP request, defaults to 5s.
  [timeout: <duration> | default = 5s]

  auth:
    # Community string is used with SNMP v1 and v2. Defaults to "public".
    [community: <string> | default = "public"]

    # v3 has different and more complex settings.
    # Which are required depends on the security_level.
    # The equivalent options on NetSNMP commands like snmpbulkwalk
    # and snmpget are also listed. See snmpcmd(1).

    # Required if v3 is used, no default. -u option to NetSNMP.
    [username: <string> | default = "user"]

    # Defaults to noAuthNoPriv. -l option to NetSNMP.
    # Can be noAuthNoPriv, authNoPriv or authPriv.
    [security_level: <string> | default = "noAuthNoPriv"]

    # Has no default. Also known as authKey, -A option to NetSNMP.
    # Required if security_level is authNoPriv or authPriv.
    [password: <string> | default = ""]

    # MD5, SHA, SHA224, SHA256, SHA384, or SHA512. Defaults to MD5. -a option to NetSNMP.
    # Used if security_level is authNoPriv or authPriv.
    [auth_protocol: <string> | default = "MD5"]

    # DES, AES, AES192, or AES256. Defaults to DES. -x option to NetSNMP.
    # Used if security_level is authPriv.
    [priv_protocol: <string> | default = "DES"]

    # Has no default. Also known as privKey, -X option to NetSNMP.
    # Required if security_level is authPriv.
    [priv_password: <string> | default = ""]

    # Has no default. -n option to NetSNMP.
    # Required if context is configured on the device.
    [context_name: <string> | default = ""]

```

## About SNMP modules

SNMP module is the set of SNMP counters to be scraped together from the specific network device.

SNMP modules available can be found in the embedded snmp.yml file [here](https://github.com/grafana/agent/blob/main/pkg/integrations/snmp_exporter/common/snmp.yml). If not specified, `if_mib` module is used.

If you need to use custom SNMP modules, you can [generate](https://github.com/prometheus/snmp_exporter#generating-configuration) your own snmp.yml file and specify it using `config_file` parameter.

'''
'''--- docs/sources/configuration/integrations/integrations-next/vsphere-config.md ---
---
aliases:
  - /docs/agent/latest/configuration/integrations/integrations-next/vsphere-config/
title: vsphere_config
---

# vsphere config (beta)

The `vsphere_config` block configures the `vmware_exporter` integration, an embedded
version of [`vmware_exporter`](https://github.com/grafana/vmware_exporter), configured
to collect vSphere metrics. This integration is considered beta.

Configuration reference:

```yaml
  autoscrape:
    # Enables autoscrape of integrations.
    [enable: <boolean> | default = true]

    # Specifies the metrics instance name to send metrics to. Instance
    # names are located at metrics.configs[].name from the top-level config.
    # The instance must exist.
    #
    # As it is common to use the name "default" for your primary instance,
    # we assume the same here.
    [metrics_instance: <string> | default = "default"]

    # Autoscrape interval and timeout. Defaults are inherited from the global
    # section of the top-level metrics config.
    [scrape_interval: <duration> | default = <metrics.global.scrape_interval>]
    [scrape_timeout: <duration> | default = <metrics.global.scrape_timeout>]

  # Integration instance name. This will default to the host:port of the configured
  # vsphere_url.
  [instance: <string> | default = <vsphere_url>]

  # Number of managed objects to include in each request to vsphere when
  # fetching performance counters.
  [request_chunk_size: <int> | default = 256]

  # Number of concurrent requests to vsphere when fetching performance counters.
  [collect_concurrency: <int> | default = 8]

  # Interval on which to run vsphere managed object discovery. Setting this to a
  # non-zero value will result in object discovery running in the background. Each
  # scrape will use object data gathered during the last discovery.
  # When this value is 0, object discovery occurs per scrape.
  [discovery_interval: <duration> | default = 0]
  [enable_exporter_metrics: <boolean> | default = true]

  # The url of the vCenter SDK endpoint
  vsphere_url: <string>

  # vCenter username
  vsphere_user: <string>

  # vCenter password
  vsphere_password: <string>

```

## Quick configuration example

```yaml
integrations:
  vsphere_configs:
    - vsphere_url: https://127.0.0.1:8989/sdk
      vsphere_user: user
      vsphere_password: pass
      request_chunk_size: 256
      collect_concurrency: 8
      instance: vsphere
      autoscrape:
        enable: true
        metrics_instance: default

metrics:
  wal_directory: /tmp/grafana-agent-wal
server:
  log_level: debug
```

'''
'''--- docs/sources/configuration/integrations/kafka-exporter-config.md ---
---
aliases:
- /docs/agent/latest/configuration/integrations/kafka-exporter-config/
title: kafka_exporter_config
---

# kafka_exporter_config

The `kafka_exporter_config` block configures the `kafka_exporter`
integration, which is an embedded version of [`kafka_exporter`](https://github.com/davidmparrott/kafka_exporter).
This allows for the collection of Kafka Lag metrics and exposing them as Prometheus metrics.

We strongly recommend that you configure a separate user for the Agent, and give it only the strictly mandatory
security privileges necessary for monitoring your node, as per the [documentation](https://github.com/lightbend/kafka-lag-exporter#required-permissions-for-kafka-acl).

Full reference of options:

```yaml
  # Enables the kafka_exporter integration, allowing the Agent to automatically
  # collect system metrics from the configured dnsmasq server address
  [enabled: <boolean> | default = false]

  # Sets an explicit value for the instance label when the integration is
  # self-scraped. Overrides inferred values.
  #
  # The default value for this integration is inferred from the hostname
  # portion of the first kafka_uri value. If there is more than one string
  # in kafka_uri, the integration will fail to load and an instance value
  # must be manually provided.
  [instance: <string>]

  # Automatically collect metrics from this integration. If disabled,
  # the dnsmasq_exporter integration will be run but not scraped and thus not
  # remote-written. Metrics for the integration will be exposed at
  # /integrations/dnsmasq_exporter/metrics and can be scraped by an external
  # process.
  [scrape_integration: <boolean> | default = <integrations_config.scrape_integrations>]

  # How often should the metrics be collected? Defaults to
  # prometheus.global.scrape_interval.
  [scrape_interval: <duration> | default = <global_config.scrape_interval>]

  # The timeout before considering the scrape a failure. Defaults to
  # prometheus.global.scrape_timeout.
  [scrape_timeout: <duration> | default = <global_config.scrape_timeout>]

  # Allows for relabeling labels on the target.
  relabel_configs:
  [- <relabel_config> ... ]

  # Relabel metrics coming from the integration, allowing to drop series
  # from the integration that you don't care about.
  metric_relabel_configs:
  [ - <relabel_config> ... ]

  # How frequent to truncate the WAL for this integration.
  [wal_truncate_frequency: <duration> | default = "60m"]

  # Monitor the exporter itself and include those metrics in the results.
  [include_exporter_metrics: <bool> | default = false]

  # Address array (host:port) of Kafka server
  [kafka_uris: <[]string>]

  # Connect using SASL/PLAIN
  [use_sasl: <bool>]

  # Only set this to false if using a non-Kafka SASL proxy
  [use_sasl_handshake: <bool> | default = true]

  # SASL user name
  [sasl_username: <string>]

  # SASL user password
  [sasl_password: <string>]

  # The SASL SCRAM SHA algorithm sha256 or sha512 as mechanism
  [sasl_mechanism: <string>]

  # Connect using TLS
  [use_tls: <bool>]

  # The optional certificate authority file for TLS client authentication
  [ca_file: <string>]

  # The optional certificate file for TLS client authentication
  [cert_file: <string>]

  # The optional key file for TLS client authentication
  [key_file: <string>]

  # If true, the server's certificate will not be checked for validity. This will make your HTTPS connections insecure
  [insecure_skip_verify: <bool>]

  # Kafka broker version
  [kafka_version: <string> | default = "2.0.0"]

  # if you need to use a group from zookeeper
  [use_zookeeper_lag: <bool>]

  # Address array (hosts) of zookeeper server.
  [zookeeper_uris: <[]string>]

  # Kafka cluster name
  [kafka_cluster_name: <string>]

  # Metadata refresh interval
  [metadata_refresh_interval: <duration> | default = "1m"]

  # If true, all scrapes will trigger kafka operations otherwise, they will share results. WARN: This should be disabled on large clusters
  [allow_concurrency: <bool> | default = true]

  # Maximum number of offsets to store in the interpolation table for a partition
  [max_offsets: <int> | default = 1000]

  # How frequently should the interpolation table be pruned, in seconds
  [prune_interval_seconds: <int> | default = 30]

  # Regex filter for topics to be monitored
  [topics_filter_regex: <string> | default = ".*"]

  # Regex filter for consumer groups to be monitored
  [groups_filter_regex: <string> | default = ".*"]

```

'''
'''--- docs/sources/configuration/integrations/memcached-exporter-config.md ---
---
aliases:
- /docs/agent/latest/configuration/integrations/memcached-exporter-config/
title: memcached_exporter_config
---

# memcached_exporter_config

The `memcached_exporter_config` block configures the `memcached_exporter`
integration, which is an embedded version of
[`memcached_exporter`](https://github.com/prometheus/memcached_exporter). This
allows for the collection of metrics from memcached servers.

Note that currently, an Agent can only collect metrics from a single memcached
server. If you want to collect metrics from multiple servers, you can run
multiple Agents and add labels using `relabel_configs` to differentiate between
the servers:

```yaml
memcached_exporter:
  enabled: true
  memcached_address: memcached-a:53
  relabel_configs:
  - source_labels: [__address__]
    target_label: instance
    replacement: memcached-a
```

Full reference of options:

```yaml
  # Enables the memcached_exporter integration, allowing the Agent to automatically
  # collect system metrics from the configured memcached server address
  [enabled: <boolean> | default = false]

  # Sets an explicit value for the instance label when the integration is
  # self-scraped. Overrides inferred values.
  #
  # The default value for this integration is inferred from
  # memcached_address.
  [instance: <string>]

  # Automatically collect metrics from this integration. If disabled,
  # the memcached_exporter integration will be run but not scraped and thus not
  # remote-written. Metrics for the integration will be exposed at
  # /integrations/memcached_exporter/metrics and can be scraped by an external
  # process.
  [scrape_integration: <boolean> | default = <integrations_config.scrape_integrations>]

  # How often should the metrics be collected? Defaults to
  # prometheus.global.scrape_interval.
  [scrape_interval: <duration> | default = <global_config.scrape_interval>]

  # The timeout before considering the scrape a failure. Defaults to
  # prometheus.global.scrape_timeout.
  [scrape_timeout: <duration> | default = <global_config.scrape_timeout>]

  # Allows for relabeling labels on the target.
  relabel_configs:
    [- <relabel_config> ... ]

  # Relabel metrics coming from the integration, allowing to drop series
  # from the integration that you don't care about.
  metric_relabel_configs:
    [ - <relabel_config> ... ]

  # How frequent to truncate the WAL for this integration.
  [wal_truncate_frequency: <duration> | default = "60m"]

  # Monitor the exporter itself and include those metrics in the results.
  [include_exporter_metrics: <bool> | default = false]

  #
  # Exporter-specific configuration options
  #

  # Address of the memcached server in host:port form.
  [memcached_address: <string> | default = "localhost:53"]

  # Timeout for connecting to memcached.
  [timeout: <duration> | default = "1s"]
```

'''
'''--- docs/sources/configuration/integrations/mongodb_exporter-config.md ---
---
aliases:
- /docs/agent/latest/configuration/integrations/mongodb_exporter-config/
title: mongodb_exporter_config
---

# mongodb_exporter_config

The `mongodb_exporter_config` block configures the `mongodb_exporter` integration, which is an embedded version of percona's [`mongodb_exporter`](https://github.com/percona/mongodb_exporter).

In order for this integration to work properly, you have to connect each node of your mongoDB cluster to an agent instance.
That's because this exporter does not collect metrics from multiple nodes.
Additionally, you need to define two custom label for your metrics using relabel_configs.
The first one is service_name, which is how you identify this node in your cluster (example: ReplicaSet1-Node1).
The second one is mongodb_cluster, which is the name of your mongodb cluster, and must be set the same value for all nodes composing the cluster (example: prod-cluster).
Here`s an example:

```yaml
relabel_configs:
    - source_labels: [__address__]
      target_label: service_name
      replacement: 'replicaset1-node1'
    - source_labels: [__address__]
      target_label: mongodb_cluster
      replacement: 'prod-cluster'
```

We strongly recommend that you configure a separate user for the Agent, and give it only the strictly mandatory
security privileges necessary for monitoring your node, as per the [official documentation](https://github.com/percona/mongodb_exporter#permissions).

Besides that, there's not much to configure. Please refer to the full reference of options:

```yaml
  # Enables the mongodb_exporter integration
  [enabled: <boolean> | default = false]

  # Sets an explicit value for the instance label when the integration is
  # self-scraped. Overrides inferred values.
  #
  # The default value for this integration is inferred from the hostname
  # portion of the mongodb_uri field.
  [instance: <string>]

  # Automatically collect metrics from this integration. If disabled,
  # the mongodb_exporter integration will be run but not scraped and thus not
  # remote-written. Metrics for the integration will be exposed at
  # /integrations/mongodb_exporter/metrics and can be scraped by an external
  # process.
  [scrape_integration: <boolean> | default = <integrations_config.scrape_integrations>]

  # How often should the metrics be collected? Defaults to
  # metrics.global.scrape_interval.
  [scrape_interval: <duration> | default = <global_config.scrape_interval>]

  # The timeout before considering the scrape a failure. Defaults to
  # metrics.global.scrape_timeout.
  [scrape_timeout: <duration> | default = <global_config.scrape_timeout>]

  # Allows for relabeling labels on the target.
  relabel_configs:
    [- <relabel_config> ... ]

  # Relabel metrics coming from the integration, allowing to drop series
  # from the integration that you don't care about.
  metric_relabel_configs:
    [ - <relabel_config> ... ]

  # How frequent to truncate the WAL for this integration.
  [wal_truncate_frequency: <duration> | default = "60m"]

  # Monitor the exporter itself and include those metrics in the results.
  [include_exporter_metrics: <bool> | default = false]

  #
  # Exporter-specific configuration options
  #

  # MongoDB node connection URL, which must be in the [`Standard Connection String Format`](https://docs.mongodb.com/manual/reference/connection-string/#std-label-connections-standard-connection-string-format)
  [mongodb_uri: <string>]
```

'''
'''--- docs/sources/configuration/integrations/mysqld-exporter-config.md ---
---
aliases:
- /docs/agent/latest/configuration/integrations/mysqld-exporter-config/
title: mysqld_exporter_config
---

# mysqld_exporter_config

The `mysqld_exporter_config` block configures the `mysqld_exporter` integration,
which is an embedded version of
[`mysqld_exporter`](https://github.com/prometheus/mysqld_exporter)
and allows for collection metrics from MySQL servers.

Note that currently, an Agent can only collect metrics from a single MySQL
server. If you want to collect metrics from multiple servers, run multiple
Agents and add labels using `relabel_configs` to differentiate between the MySQL
servers:

```yaml
mysqld_exporter:
  enabled: true
  data_source_name: root@(server-a:3306)/
  relabel_configs:
  - source_labels: [__address__]
    target_label: instance
    replacement: server-a
```

We strongly recommend that you configure a separate user for the Agent, and give it only the strictly mandatory
security privileges necessary for monitoring your node, as per the [official documentation](https://github.com/prometheus/mysqld_exporter#required-grants).

Full reference of options:

```yaml
  # Enables the mysqld_exporter integration, allowing the Agent to collect
  # metrics from a MySQL server.
  [enabled: <boolean> | default = false]

  # Sets an explicit value for the instance label when the integration is
  # self-scraped. Overrides inferred values.
  #
  # The default value for this integration is a truncated version of the
  # connection DSN, containing only the server and db name. (Credentials
  # are not included.)
  [instance: <string>]

  # Automatically collect metrics from this integration. If disabled,
  # the mysqld_exporter integration will be run but not scraped and thus not
  # remote-written. Metrics for the integration will be exposed at
  # /integrations/mysqld_exporter/metrics and can be scraped by an external
  # process.
  [scrape_integration: <boolean> | default = <integrations_config.scrape_integrations>]

  # How often should the metrics be collected? Defaults to
  # prometheus.global.scrape_interval.
  [scrape_interval: <duration> | default = <global_config.scrape_interval>]

  # The timeout before considering the scrape a failure. Defaults to
  # prometheus.global.scrape_timeout.
  [scrape_timeout: <duration> | default = <global_config.scrape_timeout>]

  # Allows for relabeling labels on the target.
  relabel_configs:
    [- <relabel_config> ... ]

  # Relabel metrics coming from the integration, allowing to drop series
  # from the integration that you don't care about.
  metric_relabel_configs:
    [ - <relabel_config> ... ]

  # How frequent to truncate the WAL for this integration.
  [wal_truncate_frequency: <duration> | default = "60m"]

  # Data Source Name specifies the MySQL server to connect to. This is REQUIRED
  # but may also be specified by the MYSQLD_EXPORTER_DATA_SOURCE_NAME
  # environment variable. If neither are set, the integration will fail to
  # start.
  #
  # The format of this is specified here: https://github.com/go-sql-driver/mysql#dsn-data-source-name
  #
  # A working example value for a server with no required password
  # authentication is: "root@(localhost:3306)/"
  data_source_name: <string>

  # A list of collector names to enable on top of the default set.
  enable_collectors:
    [ - <string> ]
  # A list of collector names to disable from the default set.
  disable_collectors:
    [ - <string> ]
  # A list of collectors to run. Fully overrides the default set.
  set_collectors:
    [ - <string> ]

  # Set a lock_wait_timeout on the connection to avoid long metadata locking.
  [lock_wait_timeout: <int> | default = 2]
  # Add a low_slow_filter to avoid slow query logging of scrapes. NOT supported
  # by Oracle MySQL.
  [log_slow_filter: <bool> | default = false]

  ## Collector-specific options

  # Minimum time a thread must be in each state to be counted.
  [info_schema_processlist_min_time: <int> | default = 0]
  # Enable collecting the number of processes by user.
  [info_schema_processlist_processes_by_user: <bool> | default = true]
  # Enable collecting the number of processes by host.
  [info_schema_processlist_processes_by_host: <bool> | default = true]
  # The list of databases to collect table stats for. * for all
  [info_schema_tables_databases: <string> | default = "*"]
  # Limit the number of events statements digests by response time.
  [perf_schema_eventsstatements_limit: <int> | default = 250]
  # Limit how old the 'last_seen' events statements can be, in seconds.
  [perf_schema_eventsstatements_time_limit: <int> | default = 86400]
  # Maximum length of the normalized statement text.
  [perf_schema_eventsstatements_digtext_text_limit: <int> | default = 120]
  # Regex file_name filter for performance_schema.file_summary_by_instance
  [perf_schema_file_instances_filter: <string> | default = ".*"]
  # Remove path prefix in performance_schema.file_summary_by_instance
  [perf_schema_file_instances_remove_prefix: <string> | default = "/var/lib/mysql"]
  # Database from where to collect heartbeat data.
  [heartbeat_database: <string> | default = "heartbeat"]
  # Table from where to collect heartbeat data.
  [heartbeat_table: <string> | default = "heartbeat"]
  # Use UTC for timestamps of the current server (`pt-heartbeat` is called with `--utc`)
  [heartbeat_utc: <bool> | default = false]
  # Enable collecting user privileges from mysql.user
  [mysql_user_privileges: <bool> | default = false]
```

The full list of collectors that are supported for `mysqld_exporter` is:

| Name                                             | Description | Enabled by default |
| ------------------------------------------------ | ----------- | ------------------ |
| auto_increment.columns                           | Collect auto_increment columns and max values from information_schema | no |
| binlog_size                                      | Collect the current size of all registered binlog files | no |
| engine_innodb_status                             | Collect from SHOW ENGINE INNODB STATUS | no |
| engine_tokudb_status                             | Collect from SHOW ENGINE TOKUDB STATUS | no |
| global_status                                    | Collect from SHOW GLOBAL STATUS | yes |
| global_variables                                 | Collect from SHOW GLOBAL VARIABLES | yes |
| heartbeat                                        | Collect from heartbeat | no |
| info_schema.clientstats                          | If running with userstat=1, enable to collect client statistics | no |
| info_schema.innodb_cmpmem                        | Collect metrics from information_schema.innodb_cmpmem | yes |
| info_schema.innodb_metrics                       | Collect metrics from information_schema.innodb_metrics | yes |
| info_schema.innodb_tablespaces                   | Collect metrics from information_schema.innodb_sys_tablespaces | no |
| info_schema.processlist                          | Collect current thread state counts from the information_schema.processlist | no |
| info_schema.query_response_time                  | Collect query response time distribution if query_response_time_stats is ON | yes |
| info_schema.replica_host                         | Collect metrics from information_schema.replica_host_status | no |
| info_schema.schemastats                          | If running with userstat=1, enable to collect schema statistics | no |
| info_schema.tables                               | Collect metrics from information_schema.tables | no |
| info_schema.tablestats                           | If running with userstat=1, enable to collect table statistics | no |
| info_schema.userstats                            | If running with userstat=1, enable to collect user statistics | no |
| mysql.user                                       | Collect data from mysql.user | no |
| perf_schema.eventsstatements                     | Collect metrics from performance_schema.events_statements_summary_by_digest | no |
| perf_schema.eventsstatementssum                  | Collect metrics of grand sums from performance_schema.events_statements_summary_by_digest | no |
| perf_schema.eventswaits                          | Collect metrics from performance_schema.events_waits_summary_global_by_event_name | no |
| perf_schema.file_events                          | Collect metrics from performance_schema.file_summary_by_event_name | no |
| perf_schema.file_instances                       | Collect metrics from performance_schema.file_summary_by_instance | no |
| perf_schema.indexiowaits                         | Collect metrics from performance_schema.table_io_waits_summary_by_index_usage | no |
| perf_schema.replication_applier_status_by_worker | Collect metrics from performance_schema.replication_applier_status_by_worker | no |
| perf_schema.replication_group_member_stats       | Collect metrics from performance_schema.replication_group_member_stats | no |
| perf_schema.replication_group_members            | Collect metrics from performance_schema.replication_group_members | no |
| perf_schema.tableiowaits                         | Collect metrics from performance_schema.table_io_waits_summary_by_table | no |
| perf_schema.tablelocks                           | Collect metrics from performance_schema.table_lock_waits_summary_by_table | no |
| slave_hosts                                      | Scrape information from 'SHOW SLAVE HOSTS' | no |
| slave_status                                     | Scrape information from SHOW SLAVE STATUS | yes |

'''
'''--- docs/sources/configuration/integrations/node-exporter-config.md ---
---
aliases:
- /docs/agent/latest/configuration/integrations/node-exporter-config/
title: node_exporter_config
---

# node_exporter_config

The `node_exporter_config` block configures the `node_exporter` integration,
which is an embedded version of
[`node_exporter`](https://github.com/prometheus/node_exporter)
and allows for collecting metrics from the UNIX system that `node_exporter` is
running on. It provides a significant amount of collectors that are responsible
for monitoring various aspects of the host system.

Note that if running the Agent in a container, you will need to bind mount
folders from the host system so the integration can monitor them. You can use
the example below, making sure to replace `/path/to/config.yaml` with a path on
your host machine where an Agent configuration file is:

```
docker run \
  --net="host" \
  --pid="host" \
  --cap-add=SYS_TIME \
  -v "/:/host/root:ro,rslave" \
  -v "/sys:/host/sys:ro,rslave" \
  -v "/proc:/host/proc:ro,rslave" \
  -v /tmp/agent:/etc/agent \
  -v /path/to/config.yaml:/etc/agent-config/agent.yaml \
  grafana/agent:v0.26.1 \
  --config.file=/etc/agent-config/agent.yaml
```

Use this configuration file for testing out `node_exporter` support, replacing
the `remote_write` settings with settings appropriate for you:

```yaml
server:
  log_level: info

metrics:
  wal_directory: /tmp/agent
  global:
    scrape_interval: 15s
    remote_write:
    - url: https://prometheus-us-central1.grafana.net/api/prom/push
      basic_auth:
        username: user-id
        password: api-token

integrations:
  node_exporter:
    enabled: true
    rootfs_path: /host/root
    sysfs_path: /host/sys
    procfs_path: /host/proc
```

For running on Kubernetes, ensure to set the equivalent mounts and capabilities
there as well:

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: agent
spec:
  containers:
  - image: grafana/agent:v0.26.1
    name: agent
    args:
    - --config.file=/etc/agent-config/agent.yaml
    securityContext:
      capabilities:
        add: ["SYS_TIME"]
      privileged: true
      runAsUser: 0
    volumeMounts:
    - name: rootfs
      mountPath: /host/root
      readOnly: true
    - name: sysfs
      mountPath: /host/sys
      readOnly: true
    - name: procfs
      mountPath: /host/proc
      readOnly: true
  hostPID: true
  hostNetwork: true
  dnsPolicy: ClusterFirstWithHostNet
  volumes:
  - name: rootfs
    hostPath:
      path: /
  - name: sysfs
    hostPath:
      path: /sys
  - name: procfs
    hostPath:
      path: /proc
```

The manifest and Tanka configs provided by this repository do not have the
mounts or capabilities required for running this integration.

Some collectors only work on specific operating systems, documented in the
table below. Enabling a collector that is not supported by the operating system
the Agent is running on is a no-op.

| Name             | Description | OS | Enabled by default |
| ---------------- | ----------- | -- | ------------------ |
| arp              | Exposes ARP statistics from /proc/net/arp. | Linux | yes |
| bcache           | Exposes bcache statistics from /sys/fs/bcache. | Linux | yes |
| bonding          | Exposes the number of configured and active slaves of Linux bonding interfaces. | Linux | yes |
| boottime         | Exposes system boot time derived from the kern.boottime sysctl. | Darwin, Dragonfly, FreeBSD, NetBSD, OpenBSD, Solaris | yes |
| btrfs            | Exposes statistics on btrfs. | Linux | yes |
| buddyinfo        | Exposes statistics of memory fragments as reported by /proc/buddyinfo. | Linux | no |
| conntrack        | Shows conntrack statistics (does nothing if no /proc/sys/net/netfilter/ present). | Linux | yes |
| cpu              | Exposes CPU statistics. | Darwin, Dragonfly, FreeBSD, Linux, Solaris | yes |
| cpufreq          | Exposes CPU frequency statistics. | Linux, Solaris | yes |
| devstat          | Exposes device statistics. | Dragonfly, FreeBSD | no |
| diskstats        | Exposes disk I/O statistics. | Darwin, Linux, OpenBSD | yes |
| dmi              | Exposes DMI information. | Linux | yes |
| drbd             | Exposes Distributed Replicated Block Device statistics (to version 8.4). | Linux | no |
| drm              | Exposes GPU card info from /sys/class/drm/card?/device | Linux | no |
| edac             | Exposes error detection and correction statistics. | Linux | yes |
| entropy          | Exposes available entropy. | Linux | yes |
| ethtool          | Exposes ethtool stats | Linux | no |
| exec             | Exposes execution statistics. | Dragonfly, FreeBSD | yes |
| fibrechannel     | Exposes FibreChannel statistics. | Linux | yes |
| filefd           | Exposes file descriptor statistics from /proc/sys/fs/file-nr. | Linux | yes |
| filesystem       | Exposes filesystem statistics, such as disk space used. | Darwin, Dragonfly, FreeBSD, Linux, OpenBSD | yes |
| hwmon            | Exposes hardware monitoring and sensor data from /sys/class/hwmon. | Linux | yes |
| infiniband       | Exposes network statistics specific to InfiniBand and Intel OmniPath configurations. | Linux | yes |
| interrupts       | Exposes detailed interrupts statistics. | Linux, OpenBSD | no |
| ipvs             | Exposes IPVS status from /proc/net/ip_vs and stats from /proc/net/ip_vs_stats. | Linux | yes |
| ksmd             | Exposes kernel and system statistics from /sys/kernel/mm/ksm. | Linux | no |
| lnstat           | Exposes Linux network cache stats | Linux | no |
| loadavg          | Exposes load average. | Darwin, Dragonfly, FreeBSD, Linux, NetBSD, OpenBSD, Solaris | yes |
| logind           | Exposes session counts from logind. | Linux | no |
| mdadm            | Exposes statistics about devices in /proc/mdstat (does nothing if no /proc/mdstat present). | Linux | yes |
| meminfo          | Exposes memory statistics. | Darwin, Dragonfly, FreeBSD, Linux, OpenBSD | yes |
| meminfo_numa     | Exposes memory statistics from /proc/meminfo_numa. | Linux | no |
| mountstats       | Exposes filesystem statistics from /proc/self/mountstats. Exposes detailed NFS client statistics. | Linux | no |
| netclass         | Exposes network interface info from /sys/class/net. | Linux | yes |
| netdev           | Exposes network interface statistics such as bytes transferred. | Darwin, Dragonfly, FreeBSD, Linux, OpenBSD | yes |
| netstat          | Exposes network statistics from /proc/net/netstat. This is the same information as netstat -s. | Linux | yes |
| network_route    | Exposes network route statistics. | Linux | no |
| nfs              | Exposes NFS client statistics from /proc/net/rpc/nfs. This is the same information as nfsstat -c. | Linux | yes |
| nfsd             | Exposes NFS kernel server statistics from /proc/net/rpc/nfsd. This is the same information as nfsstat -s. | Linux | yes |
| ntp              | Exposes local NTP daemon health to check time. | any | no |
| nvme             | Exposes NVMe statistics. | Linux | yes |
| os               | Exposes os-release information. | Linux | yes |
| perf             | Exposes perf based metrics (Warning: Metrics are dependent on kernel configuration and settings). | Linux | no |
| powersupplyclass | Collects information on power supplies. | any | yes |
| pressure         | Exposes pressure stall statistics from /proc/pressure/. | Linux (kernel 4.20+ and/or CONFIG_PSI) | yes |
| processes        | Exposes aggregate process statistics from /proc. | Linux | no |
| qdisc            | Exposes queuing discipline statistics. | Linux | no |
| rapl             | Exposes various statistics from /sys/class/powercap. | Linux | yes |
| runit            | Exposes service status from runit. | any | no |
| schedstat        | Exposes task scheduler statistics from /proc/schedstat. | Linux | yes |
| sockstat         | Exposes various statistics from /proc/net/sockstat. | Linux | yes |
| softnet          | Exposes statistics from /proc/net/softnet_stat. | Linux | yes |
| stat             | Exposes various statistics from /proc/stat. This includes boot time, forks and interrupts. | Linux | yes |
| supervisord      | Exposes service status from supervisord. | any | no |
| systemd          | Exposes service and system status from systemd. | Linux | no |
| tapestats        | Exposes tape device stats. | Linux | yes |
| tcpstat          | Exposes TCP connection status information from /proc/net/tcp and /proc/net/tcp6. (Warning: the current version has potential performance issues in high load situations). | Linux | no |
| textfile         | Collects metrics from files in a directory matching the filename pattern *.prom. The files must be using the text format defined here: https://prometheus.io/docs/instrumenting/exposition_formats/ | any | yes |
| thermal          | Exposes thermal statistics. | Darwin | yes |
| thermal_zone     | Exposes thermal zone & cooling device statistics from /sys/class/thermal. | Linux | yes |
| time             | Exposes the current system time. | any | yes |
| timex            | Exposes selected adjtimex(2) system call stats. | Linux | yes |
| udp_queues       | Exposes UDP total lengths of the rx_queue and tx_queue from /proc/net/udp and /proc/net/udp6. | Linux | yes |
| uname            | Exposes system information as provided by the uname system call. | Darwin, FreeBSD, Linux, OpenBSD | yes |
| vmstat           | Exposes statistics from /proc/vmstat. | Linux | yes |
| wifi             | Exposes WiFi device and station statistics. | Linux | no |
| xfs              | Exposes XFS runtime statistics. | Linux (kernel 4.4+) | yes |
| zfs              | Exposes ZFS performance statistics. | Linux, Solaris | yes |
| zoneinfo         | Exposes zone stats. | Linux | no |

```yaml
  # Enables the node_exporter integration, allowing the Agent to automatically
  # collect system metrics from the host UNIX system.
  [enabled: <boolean> | default = false]

  # Sets an explicit value for the instance label when the integration is
  # self-scraped. Overrides inferred values.
  #
  # The default value for this integration is inferred from the agent hostname
  # and HTTP listen port, delimited by a colon.
  [instance: <string>]

  # Automatically collect metrics from this integration. If disabled,
  # the node_exporter integration will be run but not scraped and thus not remote-written. Metrics for the
  # integration will be exposed at /integrations/node_exporter/metrics and can
  # be scraped by an external process.
  [scrape_integration: <boolean> | default = <integrations_config.scrape_integrations>]

  # How often should the metrics be collected? Defaults to
  # prometheus.global.scrape_interval.
  [scrape_interval: <duration> | default = <global_config.scrape_interval>]

  # The timtout before considering the scrape a failure. Defaults to
  # prometheus.global.scrape_timeout.
  [scrape_timeout: <duration> | default = <global_config.scrape_timeout>]

  # Allows for relabeling labels on the target.
  relabel_configs:
    [- <relabel_config> ... ]

  # Relabel metrics coming from the integration, allowing to drop series
  # from the integration that you don't care about.
  metric_relabel_configs:
    [ - <relabel_config> ... ]

  # How frequent to truncate the WAL for this integration.
  [wal_truncate_frequency: <duration> | default = "60m"]

  # Monitor the exporter itself and include those metrics in the results.
  [include_exporter_metrics: <boolean> | default = false]

  # Optionally defines the the list of enabled-by-default collectors.
  # Anything not provided in the list below will be disabled by default,
  # but requires at least one element to be treated as defined.
  #
  # This is useful if you have a very explicit set of collectors you wish
  # to run.
  set_collectors:
    - [<string>]

  # Additional collectors to enable on top of the default set of enabled
  # collectors or on top of the list provided by set_collectors.
  #
  # This is useful if you have a few collectors you wish to run that are
  # not enabled by default, but do not want to explicitly provide an entire
  # list through set_collectors.
  enable_collectors:
    - [<string>]

  # Additional collectors to disable on top of the default set of disabled
  # collectors. Takes precedence over enable_collectors.
  #
  # This is useful if you have a few collectors you do not want to run that
  # are enabled by default, but do not want to explicitly provide an entire
  # list through set_collectors.
  disable_collectors:
    - [<string>]

  # procfs mountpoint.
  [procfs_path: <string> | default = "/proc"]

  # sysfs mountpoint.
  [sysfs_path: <string> | default = "/sys"]

  # rootfs mountpoint. If running in docker, the root filesystem of the host
  # machine should be mounted and this value should be changed to the mount
  # directory.
  [rootfs_path: <string> | default = "/"]

  # Expose expensive bcache priority stats.
  [enable_bcache_priority_stats: <boolean>]

  # Regexp of `bugs` field in cpu info to filter.
  [cpu_bugs_include: <string>]

  # Enable the node_cpu_guest_seconds_total metric.
  [enable_cpu_guest_seconds_metric: <boolean> | default = true]

  # Enable the cpu_info metric for the cpu collector.
  [enable_cpu_info_metric: <boolean> | default = true]

  # Regexp of `flags` field in cpu info to filter.
  [cpu_flags_include: <string>]

  # Regexmp of devices to ignore for diskstats.
  [diskstats_ignored_devices: <string> | default = "^(ram|loop|fd|(h|s|v|xv)d[a-z]|nvme\\d+n\\d+p)\\d+$"]

  # Regexp of ethtool devices to exclude (mutually exclusive with ethtool_device_include)
  [ethtool_device_exclude: <string>]

  # Regexp of ethtool devices to include (mutually exclusive with ethtool_device_exclude)
  [ethtool_device_include: <string>]

  # Regexp of ethtool stats to include.
  [ethtool_metrics_include: <string> | default = ".*"]

  # Regexp of mount points to ignore for filesystem collector.
  [filesystem_mount_points_exclude: <string> | default = "^/(dev|proc|sys|var/lib/docker/.+)($|/)"]

  # Regexp of filesystem types to ignore for filesystem collector.
  [filesystem_fs_types_exclude: <string> | default = "^(autofs|binfmt_misc|bpf|cgroup2?|configfs|debugfs|devpts|devtmpfs|fusectl|hugetlbfs|iso9660|mqueue|nsfs|overlay|proc|procfs|pstore|rpc_pipefs|securityfs|selinuxfs|squashfs|sysfs|tracefs)$"]

  # How long to wait for a mount to respond before marking it as stale.
  [filesystem_mount_timeout: <duration> | default = "5s"]

  # Array of IPVS backend stats labels.
  #
  # The default is [local_address, local_port, remote_address, remote_port, proto, local_mark].
  ipvs_backend_labels:
    [- <string>]

  # NTP server to use for ntp collector
  [ntp_server: <string> | default = "127.0.0.1"]

  # NTP protocol version
  [ntp_protocol_version: <int> | default = 4]

  # Certify that the server address is not a public ntp server.
  [ntp_server_is_local: <boolean> | default = false]

  # IP TTL to use wile sending NTP query.
  [ntp_ip_ttl: <int> | default = 1]

  # Max accumulated distance to the root.
  [ntp_max_distance: <duration> | default = "3466080us"]

  # Offset between local clock and local ntpd time to tolerate.
  [ntp_local_offset_tolerance: <duration> | default = "1ms"]

  # Regexp of net devices to ignore for netclass collector.
  [netclass_ignored_devices: <string> | default = "^$"]

  # Ignore net devices with invalid speed values. This will default to true in
  # node_exporter 2.0.
  [netclass_ignore_invalid_speed_device: <boolean> | default = false]

  # Enable collecting address-info for every device.
  [netdev_address_info: <boolean>]

  # Regexp of net devices to exclude (mutually exclusive with include)
  [netdev_device_exclude: <string> | default = ""]

  # Regexp of net devices to include (mutually exclusive with exclude)
  [netdev_device_include: <string> | default = ""]

  # Regexp of fields to return for netstat collector.
  [netstat_fields: <string> | default = "^(.*_(InErrors|InErrs)|Ip_Forwarding|Ip(6|Ext)_(InOctets|OutOctets)|Icmp6?_(InMsgs|OutMsgs)|TcpExt_(Listen.*|Syncookies.*|TCPSynRetrans|TCPTimeouts)|Tcp_(ActiveOpens|InSegs|OutSegs|OutRsts|PassiveOpens|RetransSegs|CurrEstab)|Udp6?_(InDatagrams|OutDatagrams|NoPorts|RcvbufErrors|SndbufErrors))$"]

  # List of CPUs from which perf metrics should be collected.
  [perf_cpus: <string> | default = ""]

  # Array of perf tracepoints that should be collected.
  perf_tracepoint:
    [- <string>]

  # Regexp of power supplies to ignore for the powersupplyclass collector.
  [powersupply_ignored_supplies: <string> | default = "^$"]

  # Path to runit service directory.
  [runit_service_dir: <string> | default = "/etc/service"]

  # XML RPC endpoint for the supervisord collector.
  #
  # Setting SUPERVISORD_URL in the environment will override the default value.
  # An explicit value in the YAML config takes precedence over the environment
  # variable.
  [supervisord_url: <string> | default = "http://localhost:9001/RPC2"]

  # Regexp of systemd units to include. Units must both match include and not
  # match exclude to be collected.
  [systemd_unit_include: <string> | default = ".+"]

  # Regexp of systemd units to exclude. Units must both match include and not
  # match exclude to be collected.
  [systemd_unit_exclude: <string> | default = ".+\\.(automount|device|mount|scope|slice)"]

  # Enables service unit tasks metrics unit_tasks_current and unit_tasks_max
  [systemd_enable_task_metrics: <boolean> | default = false]

  # Enables service unit metric service_restart_total
  [systemd_enable_restarts_metrics: <boolean> | default = false]

  # Enables service unit metric unit_start_time_seconds
  [systemd_enable_start_time_metrics: <boolean> | default = false]

  # Regexp of tapestats devices to ignore.
  [tapestats_ignored_devices: <string> | default = "^$"]

  # Directory to read *.prom files from for the textfile collector.
  [textfile_directory: <string> | default = ""]

  # Regexp of fields to return for the vmstat collector.
  [vmstat_fields: <string> | default = "^(oom_kill|pgpg|pswp|pg.*fault).*"]
```

'''
'''--- docs/sources/configuration/integrations/postgres-exporter-config.md ---
---
aliases:
- /docs/agent/latest/configuration/integrations/postgres-exporter-config/
title: postgres_exporter_config
---

# postgres_exporter_config

The `postgres_exporter_config` block configures the `postgres_exporter`
integration, which is an embedded version of
[`postgres_exporter`](https://github.com/prometheus-community/postgres_exporter). This
allows for the collection of metrics from Postgres servers.

We strongly recommend that you configure a separate user for the Agent, and give it only the strictly mandatory
security privileges necessary for monitoring your node, as per the [official documentation](https://github.com/prometheus-community/postgres_exporter#running-as-non-superuser).

Full reference of options:

```yaml
  # Enables the postgres_exporter integration, allowing the Agent to automatically
  # collect system metrics from the configured postgres server address
  [enabled: <boolean> | default = false]

  # Sets an explicit value for the instance label when the integration is
  # self-scraped. Overrides inferred values.
  #
  # The default value for this integration is inferred from a truncated version of
  # the first DSN in data_source_names. The truncated DSN includes the hostname
  # and database name (if used) of the server, but does not include any user
  # information.
  #
  # If data_source_names contains more than one entry, the integration will fail to
  # load and a value for instance must be manually provided.
  [instance: <string>]

  # Automatically collect metrics from this integration. If disabled,
  # the postgres_exporter integration will be run but not scraped and thus not
  # remote-written. Metrics for the integration will be exposed at
  # /integrations/postgres_exporter/metrics and can be scraped by an external
  # process.
  [scrape_integration: <boolean> | default = <integrations_config.scrape_integrations>]

  # How often should the metrics be collected? Defaults to
  # prometheus.global.scrape_interval.
  [scrape_interval: <duration> | default = <global_config.scrape_interval>]

  # The timeout before considering the scrape a failure. Defaults to
  # prometheus.global.scrape_timeout.
  [scrape_timeout: <duration> | default = <global_config.scrape_timeout>]

  # Allows for relabeling labels on the target.
  relabel_configs:
    [- <relabel_config> ... ]

  # Relabel metrics coming from the integration, allowing to drop series
  # from the integration that you don't care about.
  metric_relabel_configs:
    [ - <relabel_config> ... ]

  # How frequent to truncate the WAL for this integration.
  [wal_truncate_frequency: <duration> | default = "60m"]

  # Monitor the exporter itself and include those metrics in the results.
  [include_exporter_metrics: <bool> | default = false]

  #
  # Exporter-specific configuration options
  #

  # Data Source Names specifies the Postgres server(s) to connect to. This is
  # REQUIRED but may also be specified by the POSTGRES_EXPORTER_DATA_SOURCE_NAME
  # environment variable, where DSNs the environment variable are separated by
  # commas. If neither are set, the integration will fail to start.
  #
  # The format of this is specified here: https://pkg.go.dev/github.com/lib/pq#ParseURL
  #
  # A working example value for a server with a password is:
  # "postgresql://username:passwword@localhost:5432/database?sslmode=disable"
  #
  # Multiple DSNs may be provided here, allowing for scraping from multiple
  # servers.
  data_source_names:
  - <string>

  # Disables collection of metrics from pg_settings.
  [disable_settings_metrics: <boolean> | default = false]

  # Autodiscover databases to collect metrics from. If false, only collects
  # metrics from databases collected from data_source_names.
  [autodiscover_databases: <boolean> | default = false]

  # Excludes specific databases from being collected when autodiscover_databases
  # is true.
  exclude_databases:
  [ - <string> ]

  # Includes only specific databases (excluding all others) when autodiscover_databases
  # is true.
  include_databases:
  [ - <string> ]

  # Path to a YAML file containing custom queries to run. Check out
  # postgres_exporter's queries.yaml for examples of the format:
  # https://github.com/prometheus-community/postgres_exporter/blob/master/queries.yaml
  [query_path: <string> | default = ""]

  # When true, only exposes metrics supplied from query_path.
  [disable_default_metrics: <boolean> | default = false]
```

'''
'''--- docs/sources/configuration/integrations/process-exporter-config.md ---
---
aliases:
- /docs/agent/latest/configuration/integrations/process-exporter-config/
title: process_exporter_config
---

# process_exporter_config

The `process_exporter_config` block configures the `process_exporter` integration,
which is an embedded version of
[`process-exporter`](https://github.com/ncabatoff/process-exporter)
and allows for collection metrics based on the /proc filesystem on Linux
systems. Note that on non-Linux systems, enabling this exporter is a no-op.

Note that if running the Agent in a container, you will need to bind mount
folders from the host system so the integration can monitor them:

```
docker run \
  -v "/proc:/proc:ro" \
  -v /tmp/agent:/etc/agent \
  -v /path/to/config.yaml:/etc/agent-config/agent.yaml \
  grafana/agent:v0.26.1 \
  --config.file=/etc/agent-config/agent.yaml
```

Replace `/path/to/config.yaml` with the appropriate path on your host system
where an Agent config file can be found.

For running on Kubernetes, ensure to set the equivalent mounts and capabilities
there as well:

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: agent
spec:
  containers:
  - image: grafana/agent:v0.26.1
    name: agent
    args:
    - --config.file=/etc/agent-config/agent.yaml
    volumeMounts:
    - name: procfs
      mountPath: /proc
      readOnly: true
  volumes:
  - name: procfs
    hostPath:
      path: /proc
```

The manifest and Tanka configs provided by this repository do not have the
mounts or capabilities required for running this integration.

An example config for `process_exporter_config` that tracks all processes is the
following:

```
enabled: true
process_names:
- name: "{{.Comm}}"
  cmdline:
  - '.+'
```

Full reference of options:

```yaml
  # Enables the process_exporter integration, allowing the Agent to automatically
  # collect system metrics from the host UNIX system.
  [enabled: <boolean> | default = false]

  # Sets an explicit value for the instance label when the integration is
  # self-scraped. Overrides inferred values.
  #
  # The default value for this integration is inferred from the agent hostname
  # and HTTP listen port, delimited by a colon.
  [instance: <string>]

  # Automatically collect metrics from this integration. If disabled,
  # the process_exporter integration will be run but not scraped and thus not
  # remote-written. Metrics for the integration will be exposed at
  # /integrations/process_exporter/metrics and can be scraped by an external
  # process.
  [scrape_integration: <boolean> | default = <integrations_config.scrape_integrations>]

  # How often should the metrics be collected? Defaults to
  # prometheus.global.scrape_interval.
  [scrape_interval: <duration> | default = <global_config.scrape_interval>]

  # The timeout before considering the scrape a failure. Defaults to
  # prometheus.global.scrape_timeout.
  [scrape_timeout: <duration> | default = <global_config.scrape_timeout>]

  # Allows for relabeling labels on the target.
  relabel_configs:
    [- <relabel_config> ... ]

  # Relabel metrics coming from the integration, allowing to drop series
  # from the integration that you don't care about.
  metric_relabel_configs:
    [ - <relabel_config> ... ]

  # How frequent to truncate the WAL for this integration.
  [wal_truncate_frequency: <duration> | default = "60m"]

  # procfs mountpoint.
  [procfs_path: <string> | default = "/proc"]

  # If a proc is tracked, track with it any children that aren't a part of their
  # own group.
  [track_children: <boolean> | default = true]

  # Report on per-threadname metrics as well.
  [track_threads: <boolean> | default = true]

  # Gather metrics from smaps file, which contains proportional resident memory
  # size.
  [gather_smaps: <boolean> | default = true]

  # Recheck process names on each scrape.
  [recheck_on_scrape: <boolean> | default = false]

  # A collection of matching rules to use for deciding which processes to
  # monitor. Each config can match multiple processes to be tracked as a single
  # process "group."
  process_names:
    [- <process_matcher_config>]
```

## process_matcher_config

```yaml
# The name to use for identifying the process group name in the metric. By
# default, it uses the base path of the executable.
#
# The following template variables are available:
#
# - {{.Comm}}:      Basename of the original executable from /proc/<pid>/stat
# - {{.ExeBase}}:   Basename of the executable from argv[0]
# - {{.ExeFull}}:   Fully qualified path of the executable
# - {{.Username}}:  Username of the effective user
# - {{.Matches}}:   Map containing all regex capture groups resulting from
#                   matching a process with the cmdline rule group.
# - {{.PID}}:       PID of the process. Note that the PID is copied from the
#                   first executable found.
# - {{.StartTime}}: The start time of the process. This is useful when combined
#                   with PID as PIDS get reused over time.
[name: <string> | default = "{{.ExeBase}}"]

# A list of strings that match the base executable name for a process, truncated
# at 15 characters. It is derived from reading the second field of
# /proc/<pid>/stat minus the parens.
#
# If any of the strings match, the process will be tracked.
comm:
  [- <string>]

# A list of strings that match argv[0] for a process. If there are no slashes,
# only the basename of argv[0] needs to match. Otherwise the name must be an
# exact match. For example, "postgres" may match any postgres binary but
# "/usr/local/bin/postgres" can only match a postgres at that path exactly.
#
# If any of the strings match, the process will be tracked.
exe:
  [- <string>]

# A list of regular expressions applied to the argv of the process. Each
# regex here must match the corresponding argv for the process to be tracked.
# The first element that is matched is argv[1].
#
# Regex Captures are added to the .Matches map for use in the name.
cmdline:
  [- <string>]
```

'''
'''--- docs/sources/configuration/integrations/redis-exporter-config.md ---
---
aliases:
- /docs/agent/latest/configuration/integrations/redis-exporter-config/
title: redis_exporter_config
---

# redis_exporter_config

The `redis_exporter_config` block configures the `redis_exporter` integration, which is an embedded version of [`redis_exporter`](https://github.com/oliver006/redis_exporter). This allows for the collection of metrics from Redis servers.

Note that currently, an Agent can only collect metrics from a single Redis server. If you want to collect metrics from multiple Redis servers, you can run multiple Agents and add labels using `relabel_configs` to differentiate between the Redis servers:

```yaml
redis_exporter:
  enabled: true
  redis_addr: "redis-2:6379"
  relabel_configs:
  - source_labels: [__address__]
    target_label: instance
    replacement: redis-2
```

We strongly recommend that you configure a separate user for the Agent, and give it only the strictly mandatory
security privileges necessary for monitoring your node, as per the [official documentation](https://github.com/oliver006/redis_exporter#authenticating-with-redis).

Full reference of options:
```yaml
  # Enables the redis_exporter integration, allowing the Agent to automatically
  # collect system metrics from the configured redis address
  [enabled: <boolean> | default = false]

  # Sets an explicit value for the instance label when the integration is
  # self-scraped. Overrides inferred values.
  #
  # The default value for this integration is inferred from the hostname
  # portion of redis_addr.
  [instance: <string>]

  # Automatically collect metrics from this integration. If disabled,
  # the redis_exporter integration will be run but not scraped and thus not
  # remote-written. Metrics for the integration will be exposed at
  # /integrations/redis_exporter/metrics and can be scraped by an external
  # process.
  [scrape_integration: <boolean> | default = <integrations_config.scrape_integrations>]

  # How often should the metrics be collected? Defaults to
  # prometheus.global.scrape_interval.
  [scrape_interval: <duration> | default = <global_config.scrape_interval>]

  # The timeout before considering the scrape a failure. Defaults to
  # prometheus.global.scrape_timeout.
  [scrape_timeout: <duration> | default = <global_config.scrape_timeout>]

  # Allows for relabeling labels on the target.
  relabel_configs:
    [- <relabel_config> ... ]

  # Relabel metrics coming from the integration, allowing to drop series
  # from the integration that you don't care about.
  metric_relabel_configs:
    [ - <relabel_config> ... ]

  # How frequent to truncate the WAL for this integration.
  [wal_truncate_frequency: <duration> | default = "60m"]

  # Monitor the exporter itself and include those metrics in the results.
  [include_exporter_metrics: <bool> | default = false]

  # exporter-specific configuration options

  # Address of the redis instance.
  redis_addr: <string>

  # User name to use for authentication (Redis ACL for Redis 6.0 and newer).
  [redis_user: <string>]

  # Password of the redis instance.
  [redis_password: <string>]

  # Path of a file containing a passord. If this is defined, it takes precedece
  # over redis_password.
  [redis_password_file: <string>]

  # Namespace for the metrics.
  [namespace: <string> | default = "redis"]

  # What to use for the CONFIG command.
  [config_command: <string> | default = "CONFIG"]

  # Comma separated list of key-patterns to export value and length/size, searched for with SCAN.
  [check_keys: <string>]

  # Comma separated list of LUA regex for grouping keys. When unset, no key
  # groups will be made.
  [check_key_groups: <string>]

  # Check key or key groups batch size hint for the underlying SCAN. Keeping the same name for backwards compatibility, but this applies to both key and key groups batch size configuration.
  [check_key_groups_batch_size: <int> | default = 10000]

  # The maximum number of distinct key groups with the most memory utilization
  # to present as distinct metrics per database. The leftover key groups will be
  # aggregated in the 'overflow' bucket.
  [max_distinct_key_groups: <int> | default = 100]

  # Comma separated list of single keys to export value and length/size.
  [check_single_keys: <string>]

  # Comma separated list of stream-patterns to export info about streams, groups and consumers, searched for with SCAN.
  [check_streams: <string>]

  # Comma separated list of single streams to export info about streams, groups and consumers.
  [check_single_streams: <string>]

  # Comma separated list of individual keys to export counts for.
  [count_keys: <string>]

  # Path to Lua Redis script for collecting extra metrics.
  [script_path: <string>]

  # Timeout for connection to Redis instance (in Golang duration format).
  [connection_timeout: <time.Duration> | default = "15s"]

  # Name of the client key file (including full path) if the server requires TLS client authentication.
  [tls_client_key_file: <string>]

  # Name of the client certificate file (including full path) if the server requires TLS client authentication.
  [tls_client_cert_file: <string>]

  # Name of the CA certificate file (including full path) if the server requires TLS client authentication.
  [tls_ca_cert_file: <string>]

  # Whether to set client name to redis_exporter.
  [set_client_name: <bool>]

  # Whether to scrape Tile38 specific metrics.
  [is_tile38: <bool>]

  # Whether to scrape Client List specific metrics.
  [export_client_list: <bool>]

  # Whether to include the client's port when exporting the client list. Note
  # that including this will increase the cardinality of all redis metrics.
  [export_client_port: <bool>]

  # Whether to also export go runtime metrics.
  [redis_metrics_only: <bool>]

  # Whether to ping the redis instance after connecting.
  [ping_on_connect: <bool>]

  # Whether to include system metrics like e.g. redis_total_system_memory_bytes.
  [incl_system_metrics: <bool>]

  # Whether to to skip TLS verification.
  [skip_tls_verification: <bool>]
```

'''
'''--- docs/sources/configuration/integrations/snmp-config.md ---
---
aliases:
- /docs/agent/latest/configuration/integrations/snmp-config/
title: snmp_exporter_config
---

# snmp config

The `snmp` block configures the `snmp` integration,
which is an embedded version of
[`snmp_exporter`](https://github.com/prometheus/snmp_exporter). This allows collection of SNMP metrics from the network devices with ease.

## Quick configuration example

To get started, define SNMP targets in Grafana agent's integration block:

```yaml
metrics:
  wal_directory: /tmp/wal
integrations:
  snmp:
    enabled: true
    snmp_targets:
      - name: network_switch_1
        address: 192.168.1.2
        module: if_mib
        walk_params: public
      - name: network_router_2
        address: 192.168.1.3
        module: mikrotik
        walk_params: private
    walk_params:
      private:
        version: 2
        auth:
          community: mysecret
      public:
        version: 2
        auth:
          community: public
```

## Prometheus service discovery use case

If you need to scrape SNMP devices in more dynamic environment, and cannot define devices in `snmp_targets` because targets would change over time, you can use service discovery approach. For instance, with [DNS discovery](https://prometheus.io/docs/prometheus/latest/configuration/configuration/#dns_sd_config):

```yaml

metrics:
  wal_directory: /tmp/wal
  configs:
    - name: snmp_targets
      scrape_configs:
        - job_name: 'snmp'
          dns_sd_configs:
            - names:
              - switches.srv.example.org
              - routers.srv.example.org
          params:
            module: [if_mib]
            walk_params: [private]
          metrics_path: /integrations/snmp/metrics
          relabel_configs:
            - source_labels: [__address__]
              target_label: __param_target
            - source_labels: [__param_target]
              target_label: instance
            - replacement: 127.0.0.1:12345 # address must match grafana agent -server.http.address flag
              target_label: __address__
integrations:
  snmp:
    enabled: true
    scrape_integration: false # set autoscrape to off
    walk_params:
      private:
        version: 2
        auth:
          community: secretpassword
```

Full reference of options:

```yaml
  # Enables the snmp integration, allowing the Agent to automatically
  # collect metrics for the specified github objects.
  [enabled: <boolean> | default = false]

  # Sets an explicit value for the instance label when the integration is
  # self-scraped. Overrides inferred values.
  #
  # The default value for this integration is inferred from the hostname portion
  # of api_url.
  [instance: <string>]

  # Automatically collect metrics from this integration. If disabled,
  # the snmp integration will be run but not scraped and thus not
  # remote-written. Metrics for the integration will be exposed at
  # /integrations/snmp/metrics and can be scraped by an external
  # process.
  [scrape_integration: <boolean> | default = <integrations_config.scrape_integrations>]

  # How often should the metrics be collected? Defaults to
  # prometheus.global.scrape_interval.
  [scrape_interval: <duration> | default = <global_config.scrape_interval>]

  # The timeout before considering the scrape a failure. Defaults to
  # prometheus.global.scrape_timeout.
  [scrape_timeout: <duration> | default = <global_config.scrape_timeout>]

  # Allows for relabeling labels on the target.
  relabel_configs:
    [- <relabel_config> ... ]

  # Relabel metrics coming from the integration, allowing to drop series
  # from the integration that you don't care about.
  metric_relabel_configs:
    [ - <relabel_config> ... ]

  # How frequent to truncate the WAL for this integration.
  [wal_truncate_frequency: <duration> | default = "60m"]

  #
  # Exporter-specific configuration options
  #

  # SNMP configuration file with custom modules.
  # See https://github.com/prometheus/snmp_exporter#generating-configuration for more details how to generate custom snmp.yml file.
  # If not defined, embedded snmp_exporter default set of modules is used.
  [config_file: <string> | default = ""]

  # List of SNMP targets to poll
  snmp_targets:
    [- <snmp_target> ... ]

  # Map of SNMP connection profiles that can be used to override default SNMP settings.
  walk_params:
    [ <string>: <walk_param> ... ]

```
## snmp_target config

```yaml
  # Name of a snmp_target
  [name: <string>]

  # The address of SNMP device
  [address: <string>]

  # SNMP module to use for polling
  [module: <string> | default = ""]

  # walk_param config to use for this snmp_target
  [walk_params: <string> | default = ""]
```

## walk_param config

```yaml
  # SNMP version to use. Defaults to 2.
  # 1 will use GETNEXT, 2 and 3 use GETBULK.
  [version: <int> | default = 2]

  # How many objects to request with GET/GETBULK, defaults to 25.
  # May need to be reduced for buggy devices.
  [max_repetitions: <int> | default = 25]

  # How many times to retry a failed request, defaults to 3.
  [retries: <int> | default = 25]

  # Timeout for each SNMP request, defaults to 5s.
  [timeout: <duration> | default = 5s]

  auth:
    # Community string is used with SNMP v1 and v2. Defaults to "public".
    [community: <string> | default = "public"]

    # v3 has different and more complex settings.
    # Which are required depends on the security_level.
    # The equivalent options on NetSNMP commands like snmpbulkwalk
    # and snmpget are also listed. See snmpcmd(1).

    # Required if v3 is used, no default. -u option to NetSNMP.
    [username: <string> | default = "user"]

    # Defaults to noAuthNoPriv. -l option to NetSNMP.
    # Can be noAuthNoPriv, authNoPriv or authPriv.
    [security_level: <string> | default = "noAuthNoPriv"]

    # Has no default. Also known as authKey, -A option to NetSNMP.
    # Required if security_level is authNoPriv or authPriv.
    [password: <string> | default = ""]

    # MD5, SHA, SHA224, SHA256, SHA384, or SHA512. Defaults to MD5. -a option to NetSNMP.
    # Used if security_level is authNoPriv or authPriv.
    [auth_protocol: <string> | default = "MD5"]

    # DES, AES, AES192, or AES256. Defaults to DES. -x option to NetSNMP.
    # Used if security_level is authPriv.
    [priv_protocol: <string> | default = "DES"]

    # Has no default. Also known as privKey, -X option to NetSNMP.
    # Required if security_level is authPriv.
    [priv_password: <string> | default = ""]

    # Has no default. -n option to NetSNMP.
    # Required if context is configured on the device.
    [context_name: <string> | default = ""]

```

## About SNMP modules

SNMP module is the set of SNMP counters to be scraped together from the specific network device.

SNMP modules available can be found in the embedded snmp.yml file [here](https://github.com/grafana/agent/blob/main/pkg/integrations/snmp_exporter/common/snmp.yml). If not specified, `if_mib` module is used.

If you need to use custom SNMP modules, you can [generate](https://github.com/prometheus/snmp_exporter#generating-configuration) your own snmp.yml file and specify it using `config_file` parameter.

'''
'''--- docs/sources/configuration/integrations/statsd-exporter-config.md ---
---
aliases:
- /docs/agent/latest/configuration/integrations/statsd-exporter-config/
title: statsd_exporter_config
---

# statsd_exporter_config

The `statsd_exporter_config` block configures the `statsd_exporter`
integration, which is an embedded version of
[`statsd_exporter`](https://github.com/prometheus/statsd_exporter). This allows
for the collection of statsd metrics and exposing them as Prometheus metrics.

Full reference of options:

```yaml
  # Enables the statsd_exporter integration, allowing the Agent to automatically
  # collect system metrics from the configured statsd server address
  [enabled: <boolean> | default = false]

  # Sets an explicit value for the instance label when the integration is
  # self-scraped. Overrides inferred values.
  #
  # The default value for this integration is inferred from the agent hostname
  # and HTTP listen port, delimited by a colon.
  [instance: <string>]

  # Automatically collect metrics from this integration. If disabled,
  # the statsd_exporter integration will be run but not scraped and thus not
  # remote-written. Metrics for the integration will be exposed at
  # /integrations/statsd_exporter/metrics and can be scraped by an external
  # process.
  [scrape_integration: <boolean> | default = <integrations_config.scrape_integrations>]

  # How often should the metrics be collected? Defaults to
  # prometheus.global.scrape_interval.
  [scrape_interval: <duration> | default = <global_config.scrape_interval>]

  # The timeout before considering the scrape a failure. Defaults to
  # prometheus.global.scrape_timeout.
  [scrape_timeout: <duration> | default = <global_config.scrape_timeout>]

  # Allows for relabeling labels on the target.
  relabel_configs:
    [- <relabel_config> ... ]

  # Relabel metrics coming from the integration, allowing to drop series
  # from the integration that you don't care about.
  metric_relabel_configs:
    [ - <relabel_config> ... ]

  # How frequent to truncate the WAL for this integration.
  [wal_truncate_frequency: <duration> | default = "60m"]

  # Monitor the exporter itself and include those metrics in the results.
  [include_exporter_metrics: <bool> | default = false]

  #
  # Exporter-specific configuration options
  #

  # The UDP address on which to receive statsd metric lines. An empty string
  # will disable UDP collection.
  [listen_udp: <string> | default = ":9125"]

  # The TCP address on which to receive statsd metric lines. An empty string
  # will disable TCP collection.
  [listen_tcp: <string> | default = ":9125"]

  # The Unixgram socket path to receive statsd metric lines. An empty string
  # will disable unixgram collection.
  [listen_unixgram: <string> | default = ""]

  # The permission mode of the unixgram socket, when enabled.
  [unix_socket_mode: <string> | default = "755"]

  # An optional mapping config that can translate dot-separated StatsD metrics
  # into labeled Prometheus metrics. For full instructions on how to write this
  # object, see the official documentation from the statsd_exporter:
  #
  # https://github.com/prometheus/statsd_exporter#metric-mapping-and-configuration
  #
  # Note that a SIGHUP will not reload this config.
  [mapping_config: <statsd_exporter.mapping_config>]

  # Size (in bytes) of the operating system's transmit read buffer associated
  # with the UDP or unixgram connection. Please make sure the kernel parameters
  # net.core.rmem_max is set to a value greater than the value specified.
  [read_buffer: <int> | default = 0]

  # Maximum size of your metric mapping cache. Relies on least recently used
  # replacement policy if max size is reached.
  [cache_size: <int> | default = 1000]

  # Metric mapping cache type. Valid values are "lru" and "random".
  [cache_type: <string> | default = "lru"]

  # Size of internal queue for processing events.
  [event_queue_size: <int> | default = 10000]

  # Number of events to hold in queue before flushing.
  [event_flush_threshold: <int> | default = 1000]

  # Number of events to hold in queue before flushing.
  [event_flush_interval: <duration> | default = "200ms"]

  # Parse DogStatsd style tags.
  [parse_dogstatsd_tags: <bool> | default = true]

  # Parse InfluxDB style tags.
  [parse_influxdb_tags: <bool> | default = true]

  # Parse Librato style tags.
  [parse_librato_tags: <bool> | default = true]

  # Parse SignalFX style tags.
  [parse_signalfx_tags: <bool> | default = true]
```

'''
'''--- docs/sources/configuration/integrations/windows-exporter-config.md ---
---
aliases:
- /docs/agent/latest/configuration/integrations/windows-exporter-config/
title: windows_exporter_config
---

# windows_exporter_config

The `windows_exporter_config` block configures the `windows_exporter`
integration, which is an embedded version of
[`windows_exporter`](https://github.com/grafana/windows_exporter). This allows
for the collection of Windows metrics and exposing them as Prometheus metrics.

Full reference of options:

```yaml
  # Enables the windows_exporter integration, allowing the Agent to automatically
  # collect system metrics from the local windows instance
  [enabled: <boolean> | default = false]

  # Sets an explicit value for the instance label when the integration is
  # self-scraped. Overrides inferred values.
  #
  # The default value for this integration is inferred from the agent hostname
  # and HTTP listen port, delimited by a colon.
  [instance: <string>]

  # Automatically collect metrics from this integration. If disabled,
  # the consul_exporter integration will be run but not scraped and thus not
  # remote-written. Metrics for the integration will be exposed at
  # /integrations/windows_exporter/metrics and can be scraped by an external
  # process.
  [scrape_integration: <boolean> | default = <integrations_config.scrape_integrations>]

  # How often should the metrics be collected? Defaults to
  # prometheus.global.scrape_interval.
  [scrape_interval: <duration> | default = <global_config.scrape_interval>]

  # The timeout before considering the scrape a failure. Defaults to
  # prometheus.global.scrape_timeout.
  [scrape_timeout: <duration> | default = <global_config.scrape_timeout>]

  # Allows for relabeling labels on the target.
  relabel_configs:
    [- <relabel_config> ... ]

  # Relabel metrics coming from the integration, allowing to drop series
  # from the integration that you don't care about.
  metric_relabel_configs:
    [ - <relabel_config> ... ]

  # How frequent to truncate the WAL for this integration.
  [wal_truncate_frequency: <duration> | default = "60m"]

  # Monitor the exporter itself and include those metrics in the results.
  [include_exporter_metrics: <bool> | default = false]

  #
  # Exporter-specific configuration options
  #

  # List of collectors to enable. Any non-experimental collector from the
  # embeded version of windows_exporter can be enabeld here.
  [enabled_collectors: <string> | default = "cpu,cs,logical_disk,net,os,service,system,textfile"]

  # Settings for collectors which accept configuration. Settings specified here
  # are only used if the corresponding collector is enabled in
  # enabled_collectors.

  # Configuration for Exchange Mail Server
  exchange:
    # Comma-separated List of collectors to use. Defaults to all, if not specified.
    # Maps to collectors.exchange.enabled in windows_exporter
    [enabled_list: <string>]

  # Configuration for the IIS web server
  iis:
    # Regexp of sites to whitelist. Site name must both match whitelist and not match blacklist to be included.
    # Maps to collector.iis.site-whitelist in windows_exporter
    [site_whitelist: <string> | default = ".+"]

    # Regexp of sites to blacklist. Site name must both match whitelist and not match blacklist to be included.
    # Maps to collector.iis.site-blacklist in windows_exporter
    [site_blacklist: <string> | default = ""]

    # Regexp of apps to whitelist. App name must both match whitelist and not match blacklist to be included.
    # Maps to collector.iis.app-whitelist in windows_exporter
    [app_whitelist: <string> | default=".+"]

    # Regexp of apps to blacklist. App name must both match whitelist and not match blacklist to be included.
    # Maps to collector.iis.app-blacklist in windows_exporter
    [app_blacklist: <string> | default=".+"]

  # Configuration for reading metrics from a text files in a directory
  text_file:
    # Directory to read text files with metrics from.
    # Maps to collector.textfile.directory in windows_exporter
    [text_file_directory: <string> | default="C:\Program Files\windows_exporter\textfile_inputs"]

  # Configuration for SMTP metrics
  smtp:
    # Regexp of virtual servers to whitelist. Server name must both match whitelist and not match blacklist to be included.
    # Maps to collector.smtp.server-whitelist in windows_exporter
    [whitelist: <string> | default=".+"]

    # Regexp of virtual servers to blacklist. Server name must both match whitelist and not match blacklist to be included.
    # Maps to collector.smtp.server-blacklist in windows_exporter
    [blacklist: <string> | default=""]

  # Configuration for Windows Services
  service:
    # "WQL 'where' clause to use in WMI metrics query. Limits the response to the services you specify and reduces the size of the response.
    # Maps to collector.service.services-where in windows_exporter
    [where_clause: <string> | default=""]

  # Configuration for Windows Processes
  process:
    # Regexp of processes to include. Process name must both match whitelist and not match blacklist to be included.
    # Maps to collector.process.whitelist in windows_exporter
    [whitelist: <string> | default=".+"]

    # Regexp of processes to exclude. Process name must both match whitelist and not match blacklist to be included.
    # Maps to collector.process.blacklist in windows_exporter
    [blacklist: <string> | default=""]

  # Configuration for NICs
  network:
    # Regexp of NIC's to whitelist. NIC name must both match whitelist and not match blacklist to be included.
    # Maps to collector.net.nic-whitelist in windows_exporter
    [whitelist: <string> | default=".+"]

    # Regexp of NIC's to blacklist. NIC name must both match whitelist and not match blacklist to be included.
    # Maps to collector.net.nic-blacklist in windows_exporter
    [blacklist: <string> | default=""]

  # Configuration for Microsoft SQL Server
  mssql:
    # Comma-separated list of mssql WMI classes to use.
    # Maps to collectors.mssql.classes-enabled in windows_exporter
    [enabled_classes: <string> | default="accessmethods,availreplica,bufman,databases,dbreplica,genstats,locks,memmgr,sqlstats,sqlerrors,transactions"]

  # Configuration for Microsoft Queue
  msqm:
    # WQL 'where' clause to use in WMI metrics query. Limits the response to the msmqs you specify and reduces the size of the response.
    # Maps to collector.msmq.msmq-where in windows_exporter
    [where_clause: <string> | default=""]

  # Configuration for disk information
  logical_disk:
    # Regexp of volumes to whitelist. Volume name must both match whitelist and not match blacklist to be included.
    # Maps to collector.logical_disk.volume-whitelist in windows_exporter
    [whitelist: <string> | default=".+"]

    # Regexp of volumes to blacklist. Volume name must both match whitelist and not match blacklist to be included.
    # Maps to collector.logical_disk.volume-blacklist in windows_exporter
    [blacklist: <string> | default=".+"]
```

'''
'''--- docs/sources/configuration/logs-config.md ---
---
aliases:
- /docs/agent/latest/configuration/logs-config/
- /docs/agent/latest/configuration/loki-config/
title: logs_config
weight: 300
---

# logs_config

The `logs_config` block configures how the Agent collects logs and sends them to
a Loki push API endpoint. `logs_config` is identical to how Promtail is
configured, except deprecated fields have been removed and the server_config is
not supported.

Refer to the
[Promtail documentation](https://grafana.com/docs/loki/latest/clients/promtail/configuration/#clients)
for the supported values for these fields.

```yaml
# Directory to store Loki Promtail positions files in. Positions files are
# required to read logs, and are used to store the last read offset of log
# sources. The positions files will be stored in
# <positions_directory>/<logs_instance_config.name>.yml.
#
# Optional only if every config has a positions.filename manually provided.
#
# This directory will be automatically created if it doesn't exist.
[positions_directory: <string>]

# Loki Promtail instances to run for log collection.
configs:
  - [<logs_instance_config>]
```

## logs_instance_config

The `logs_instance_config` block is an individual instance of Promtail with its
own set of scrape rules and where to forward logs. It is identical to how
Promtail is configured, except deprecated fields have been removed and the
`server_config` block is not supported.

```yaml
# Name of this config. Required, and must be unique across all Loki configs.
# The name of the config will be the value of a logs_config label for all
# Loki Promtail metrics.
name: <string>

clients:
  - [<promtail.client_config>]

# Optional configuration for where to store the positions files. If
# positions.filename is left empty, the file will be stored in
# <logs_config.positions_directory>/<logs_instance_config.name>.yml.
#
# The directory of the positions file will automatically be created on start up
# if it doesn't already exist..
[positions: <promtail.position_config>]

scrape_configs:
  - [<promtail.scrape_config>]

[target_config: <promtail.target_config>]
```
> **Note:** More information on the following types can be found on the
> documentation for Promtail:
>
> * [`promtail.client_config`](https://grafana.com/docs/loki/latest/clients/promtail/configuration/#clients)
> * [`promtail.scrape_config`](https://grafana.com/docs/loki/latest/clients/promtail/configuration/#scrape_configs)
> * [`promtail.target_config`](https://grafana.com/docs/loki/latest/clients/promtail/configuration/#target_config)

> **Note:** Backticks in values are not supported.

> **Note:**  Because of how YAML treats backslashes in double-quoted strings,
> all backslashes in a regex expression must be escaped when using double
> quotes. But because of double processing, in Grafana Agent config file
> you must use quadruple backslash (`\\\\`) construction to add backslashes
> into regular expressions, here is example for `name=(\w+)\s` regex:
```
  selector: '{app="my-app"} |~ "name=(\\\\w+)\\\\s"'
```

Using single or double backslash construction produces the error:
```
failed to make file target manager: invalid match stage config: invalid selector syntax for match stage: parse error at line 1, col 40: literal not terminated
```
Using backticks produces the error:
```
invalid match stage config: invalid selector syntax for match stage: parse error at line 1, col 51: syntax error: unexpected IDENTIFIER, expecting STRING"
```

'''
'''--- docs/sources/configuration/metrics-config.md ---
---
aliases:
- /docs/agent/latest/configuration/metrics-config/
- /docs/agent/latest/configuration/prometheus-config/
title: metrics_config
weight: 200
---

# metrics_config

The `metrics_config` block is used to define a collection of metrics
instances. Each instance defines a collection of Prometheus-compatible
scrape_configs and remote_write rules. Most users will only need to
define one instance.

```yaml
# Configures the optional scraping service to cluster agents.
[scraping_service: <scraping_service_config>]

# Configures the gRPC client used for agents to connect to other
# clustered agents.
[scraping_service_client: <scraping_service_client_config>]

# Configure values for all Prometheus instances.
[global: <global_config>]

# Configure the directory used by instances to store their WAL.
#
# The Grafana Agent assumes that all folders within wal_directory are managed by
# the agent itself. This means if you are using a PVC, you must point
# wal_directory to a subdirectory of the PVC mount.
[wal_directory: <string> | default = ""]

# Configures how long ago an abandoned (not associated with an instance) WAL
# may be written to before being eligible to be deleted
[wal_cleanup_age: <duration> | default = "12h"]

# Configures how often checks for abandoned WALs to be deleted are performed.
# A value of 0 disables periodic cleanup of abandoned WALs
[wal_cleanup_period: <duration> | default = "30m"]

# Allows to disable HTTP Keep-Alives when scraping; the Agent will only use
# outgoing each connection for a single request.
[http_disable_keepalives: <boolean> | default = false]

# Allows to configure the maximum amount of time an idle Keep-Alive connection
# can remain idle before closing itself. Zero means no limit.
# The setting is ignored when `http_disable_keepalives` is enabled.
[http_idle_conn_timeout: <duration> | default = "5m"]

# The list of Prometheus instances to launch with the agent.
configs:
  [- <metrics_instance_config>]

# If an instance crashes abnormally, how long should we wait before trying
# to restart it. 0s disables the backoff period and restarts the agent
# immediately.
[instance_restart_backoff: <duration> | default = "5s"]

# How to spawn instances based on instance configs. Supported values: shared,
# distinct.
[instance_mode: <string> | default = "shared"]
```

## scraping_service_config

The `scraping_service` block configures the
[scraping service]({{< relref "scraping-service/" >}}), an operational
mode where configurations are stored centrally in a KV store and a cluster of
agents distribute discovery and scrape load between nodes.

```yaml
# Whether to enable scraping service mode. When enabled, local configs
# cannot be used.
[enabled: <boolean> | default = false]

# Note these next 3 configuration options are confusing. Due to backwards compatibility the naming
# is less than ideal.

# How often should the agent manually refresh the configuration. Useful for if KV change
# events are not sent by an agent.
[reshard_interval: <duration> | default = "1m"]

# The timeout for configuration refreshes. This can occur on cluster events or
# on the reshard interval. A timeout of 0 indicates no timeout.
[reshard_timeout: <duration> | default = "30s"]

# The timeout for a cluster reshard events. A timeout of 0 indicates no timeout.
[cluster_reshard_event_timeout: <duration> | default = "30s"]

# Configuration for the KV store to store configurations.
kvstore: <kvstore_config>

# When set, allows configs pushed to the KV store to specify configuration
# fields that can read secrets from files.
#
# This is disabled by default. When enabled, a malicious user can craft an
# instance config that reads arbitrary files on the machine the Agent runs
# on and sends its contents to a specically crafted remote_write endpoint.
#
# If enabled, ensure that no untrusted users have access to the Agent API.
[dangerous_allow_reading_files: <boolean>]

# Configuration for how agents will cluster together.
lifecycler: <lifecycler_config>
```

## kvstore_config

The `kvstore_config` block configures the KV store used as storage for
configurations in the scraping service mode.

```yaml
# Which underlying KV store to use. Can be either consul or etcd
[store: <string> | default = ""]

# Key prefix to store all configurations with. Must end in /.
[prefix: <string> | default = "configurations/"]

# Configuration for a Consul client. Only applies if store
# is "consul"
consul:
  # The hostname and port of Consul.
  [host: <string> | duration = "localhost:8500"]

  # The ACL Token used to interact with Consul.
  [acltoken: <string>]

  # The HTTP timeout when communicating with Consul
  [httpclienttimeout: <duration> | default = 20s]

  # Whether or not consistent reads to Consul are enabled.
  [consistentreads: <boolean> | default = true]

# Configuration for an ETCD v3 client. Only applies if
# store is "etcd"
etcd:
  # The ETCD endpoints to connect to.
  endpoints:
    - <string>

  # The Dial timeout for the ETCD connection.
  [dial_tmeout: <duration> | default = 10s]

  # The maximum number of retries to do for failed ops to ETCD.
  [max_retries: <int> | default = 10]
```

## lifecycler_config

The `lifecycler_config` block configures the lifecycler; the component that
Agents use to cluster together.

```yaml
# Configures the distributed hash ring storage.
ring:
  # KV store for getting and sending distributed hash ring updates.
  kvstore: <kvstore_config>

  # Specifies when other agents in the clsuter should be considered
  # unhealthy if they haven't sent a heartbeat within this duration.
  [heartbeat_timeout: <duration> | default = "1m"]

# Number of tokens to generate for the distributed hash ring.
[num_tokens: <int> | default = 128]

# How often agents should send a heartbeat to the distributed hash
# ring.
[heartbeat_period: <duration> | default = "5s"]

# How long to wait for tokens from other agents after generating
# a new set to resolve collisions. Useful only when using a gossip
# KV store.
[observe_period: <duration> | default = "0s"]

# Period to wait before joining the ring. 0s means to join immediately.
[join_after: <duration> | default = "0s"]

# Minimum duration to wait before marking the agent as ready to receive
# traffic. Used to work around race conditions for multiple agents exiting
# the distributed hash ring at the same time.
[min_ready_duration: <duration> | default = "1m"]

# Network interfaces to resolve addresses defined by other agents
# registered in distributed hash ring.
[interface_names: <string array> | default = ["eth0", "en0"]]

# Duration to sleep before exiting. Ensures that metrics get scraped
# before the process quits.
[final_sleep: <duration> | default = "30s"]

# File path to store tokens. If empty, tokens will not be stored during
# shutdown and will not be restored at startup.
[tokens_file_path: <string> | default = ""]

# Availability zone of the host the agent is running on. Default is an
# empty string which disables zone awareness for writes.
[availability_zone: <string> | default = ""]
```

## scraping_service_client_config

The `scraping_service_client_config` block configures how clustered Agents will
generate gRPC clients to connect to each other.

```yaml
grpc_client_config:
  # Maximum size in bytes the gRPC client will accept from the connected server.
  [max_recv_msg_size: <int> | default = 104857600]

  # Maximum size in bytes the gRPC client will sent to the connected server.
  [max_send_msg_size: <int> | default = 16777216]

  # Whether messages should be gzipped.
  [use_gzip_compression: <boolean> | default = false]

  # The rate limit for gRPC clients; 0 means no rate limit.
  [rate_limit: <float64> | default = 0]

  # gRPC burst allowed for rate limits.
  [rate_limit_burst: <int> | default = 0]

  # Controls if when a rate limit is hit whether the client should
  # retry the request.
  [backoff_on_ratelimits: <boolean> | default = false]

  # Configures the retry backoff when backoff_on_ratelimits is
  # true.
  backoff_config:
    # The minimum delay when backing off.
    [min_period: <duration> | default = "100ms"]

    # The maximum delay when backing off.
    [max_period: <duration> | default = "10s"]

    # The number of times to backoff and retry before failing.
    [max_retries: <int> | default = 10]
```

## global_config

The `global_config` block configures global values for all launched Prometheus
instances.

```yaml
# How frequently should Prometheus instances scrape.
[scrape_interval: duration | default = "1m"]

# How long to wait before timing out a scrape from a target.
[scrape_timeout: duration | default = "10s"]

# A list of static labels to add for all metrics.
external_labels:
  { <string>: <string> }

# Default set of remote_write endpoints. If an instance doesn't define any
# remote_writes, it will use this list.
remote_write:
  - [<remote_write>]
```

> **Note:** For more information on remote_write, refer to the [Prometheus documentation](https://prometheus.io/docs/prometheus/2.34/configuration/configuration/#remote_write)

## metrics_instance_config

The `metrics_instance_config` block configures an individual metrics
instance, which acts as its own mini Prometheus-compatible agent, though
without support for the TSDB.

```yaml
# Name of the instance. Must be present. Will be added as a label to agent
# metrics.
name: string

# Whether this agent instance should only scrape from targets running on the
# same machine as the agent process.
[host_filter: <boolean> | default = false]

# Relabel configs to apply against discovered targets. The relabeling is
# temporary and just used for filtering targets.
host_filter_relabel_configs:
  [ - <relabel_config> ... ]

# How frequently the WAL truncation process should run. Every iteration of
# the truncation will checkpoint old series and remove old samples. If data
# has not been sent within this window, some of it may be lost.
#
# The size of the WAL will increase with less frequent truncations. Making
# truncations more frequent reduces the size of the WAL but increases the
# chances of data loss when remote_write is failing for longer than the
# specified frequency.
[wal_truncate_frequency: <duration> | default = "60m"]

# The minimum amount of time that series and samples should exist in the WAL
# before being considered for deletion. The consumed disk space of the WAL will
# increase by making this value larger.
#
# Setting this value to 0s is valid, but may delete series before all
# remote_write shards have been able to write all data, and may cause errors on
# slower machines.
[min_wal_time: <duration> | default = "5m"]

# The maximum amount of time that series and samples may exist within the WAL
# before being considered for deletion. Series that have not received writes
# since this period will be removed, and all samples older than this period will
# be removed.
#
# This value is useful in long-running network outages, preventing the WAL from
# growing forever.
#
# Must be larger than min_wal_time.
[max_wal_time: <duration> | default = "4h"]

# Deadline for flushing data when a Prometheus instance shuts down
# before giving up and letting the shutdown proceed.
[remote_flush_deadline: <duration> | default = "1m"]

# When true, writes staleness markers to all active series to
# remote_write.
[write_stale_on_shutdown: <boolean> | default = false]

# A list of scrape configuration rules.
scrape_configs:
  - [<scrape_config>]

# A list of remote_write targets.
remote_write:
  - [<remote_write>]
```

> **Note:** More information on the following types can be found on the Prometheus
> website:
>
> * [`relabel_config`](https://prometheus.io/docs/prometheus/2.34/configuration/configuration/#relabel_config)
> * [`scrape_config`](https://prometheus.io/docs/prometheus/2.34/configuration/configuration/#scrape_config)
> * [`remote_write`](https://prometheus.io/docs/prometheus/2.34/configuration/configuration/#remote_write)

'''
'''--- docs/sources/configuration/scraping-service.md ---
---
aliases:
- /docs/agent/latest/scraping-service/
title: Scraping Service Mode
weight: 600
---

# Scraping Service Mode (Beta)

Scraping Service Mode is a third operational mode of the Grafana Agent
that allows for clustering a set of Agent processes and distributing scrape load
across them.

Determining what to scrape is done by writing instance configuration files to an
[API]({{< relref "../api" >}}), which then stores the configuration files in a KV store backend.
All agents in the cluster **must** use the same KV store so they see the same set
of config files.

Each process of the Grafana Agent can be running multiple independent
"instances" at once, where an "instance" refers to the combination of:

- Service discovery for all `scrape_configs` within that loaded config
- Scrapes metrics from all discovered targets
- Stores data in its own Write-Ahead Log specific to the loaded config
- Remote Writes scraped metrics to the configured `remote_write` destinations
  specified within the loaded config.

The "instance configuration file," then, is the configuration file that
specifies the set of `scrape_configs` and `remote_write` endpoints. For example,
a small instance configuration file looks like:

```yaml
scrape_configs:
  - job_name: self-scrape
    static_configs:
      - targets: ['localhost:9090']
        labels:
          process: 'agent'
remote_write:
  - url: http://cortex:9009/api/prom/push
```

The full set of supported options for an instance configuration file is
available in the
[`metrics-config.md` file]({{< relref "metrics-config" >}}).

Having multiple instance configuration files is necessary for sharding; each
config file is distributed to a particular agent on the cluster based on the
hash of its contents.

When Scraping Service Mode is enabled, Agents **disallow** specifying
instance configurations locally in the configuration file; using the KV store
is required. [`agentctl`](#agentctl) can be used to manually sync
instance configuration files to the Agent's API server.

## Distributed hash ring

Scraping Service Mode uses a Distributed Hash Ring (commonly just called "the
ring") to cluster agents and to shard configurations within that ring. Each
Agent joins the ring with a random distinct set of _tokens_ that are used for
sharding. The default number of generated tokens is 128.

The Distributed Hash Ring is also stored in a KV store. Since a KV store is
also needed for storing configuration files, it is encouraged to re-use
the same KV store for the ring.

When sharding, the Agent currently uses the name of a config file
stored in the KV store for load distribution. Config names are guaranteed to be
unique keys. The hash of the name is used as the _lookup key_ in the ring and
determines which agent (based on token) should be responsible for that config.
"Price is Right" rules are used for the Agent lookup; the Agent owning the token
with the closest value to the key without going over is responsible for the
config.

All Agents are simultaneously watching the KV store for changes to the set of
configuration files. When a config file is added or updated in the configuration
store, each Agent will run the config name hash through their copy of the Hash
Ring to determine if they are responsible for that config.

When an Agent receives a new config that it is responsible for, it launches a
new instance from the instance config. If a config is deleted from the KV store,
this will be detected by the owning Agent and it will stop the metric collection
process for that config file.

When an Agent receives an event for an updated configuration file that they used to
be the owner of but are no longer the owner, the associated instance for that
configuration file is stopped for that Agent. This can happen when the cluster
size changes.

Scraping Service Mode currently does not support replication; only one agent
at a time will be responsible for scraping a certain config.

### Resharding

When a new Agent joins or leaves the cluster, the set of tokens in the ring may
cause configurations to hash to a new Agent. The process of responding to this
action is called "resharding."

Resharding is run:

1. When an Agent joins the ring
2. When an Agent leaves the ring
3. When the KV store sends a notification indicating a config has changed.
4. On a specified interval in case KV change events have not fired.

The resharding process involves each Agent retrieving the full set of
configurations stored in the KV store and determining if:

1. The config owned by the current resharding Agent has changed and needs to
   be reloaded.
2. The config is no longer owned by the current resharding Agent and the
   associated instance should be stopped.
3. The config has been deleted and the associated instance should be stopped.

## Best practices

Because distribution is determined by the number of config files and not how
many targets exist per config file, the best amount of distribution is achieved
when each config file has the lowest amount of targets possible. The best
distribution will be achieved if each config file stored in the KV store is
limited to one static config with only one target.

A better distribution mechanism that distributes based on discovered targets is
planned for the future.

## Example

Here's an example `agent.yaml` config file that uses the same `etcd` server for
both configuration storage and the distributed hash ring storage:

```yaml
server:
  log_level: debug

metrics:
  global:
    scrape_interval: 1m
  scraping_service:
    enabled: true
    kvstore:
      store: etcd
      etcd:
        endpoints:
          - etcd:2379
    lifecycler:
      ring:
        replication_factor: 1
        kvstore:
          store: etcd
          etcd:
            endpoints:
              - etcd:2379
```

Note that there are no instance configs present in this example; instance
configs must be passed to the API for the Agent to start scraping metrics.

## agentctl

`agentctl` is a tool included with this repository that helps users interact
with the new Config Management API. The `agentctl config-sync` subcommand uses
local YAML files as a source of truth and syncs their contents with the API.
Entries in the API not in the synced directory will be deleted.

`agentctl` is distributed in binary form with each release and as a Docker
container with the `grafana/agentctl` image. Tanka configurations that
utilize `grafana/agentctl` and sync a set of configurations to the API
are planned for the future.

'''
'''--- docs/sources/configuration/server-config.md ---
---
aliases:
- /docs/agent/latest/configuration/server-config/
title: server_config
weight: 100
---

# server_config

The `server_config` block configures the Agent's behavior as an HTTP server,
gRPC server, and the log level for the whole process.

The Agent exposes an HTTP server for scraping its own metrics and gRPC for the
scraping service mode.

```yaml
# Log only messages with the given severity or above. Supported values [debug,
# info, warn, error]. This level affects logging for all Agent-level logs, not
# just the HTTP and gRPC server.
#
# Note that some integrations use their own loggers which ignore this
# setting.
[log_level: <string> | default = "info"]

# Log messages with the given format. Supported values [logfmt, json].
# This affects logging for all Agent-levle logs, not just the HTTP and gRPC
# server.
#
# Note that some integrations use their own loggers which ignore this
# setting.
[log_format: <string> | default = "logfmt"]

# TLS configuration for the HTTP server. Reuqired when the
# -server.http.tls-enabled flag is provided, ignored otherwise.
[http_tls_config: <server_tls_config>]

# TLS configuration for the gRPC server. Required when the
# -server.grpc.tls-enabled flag is provided, ignored otherwise.
[grpc_tls_config: <server_tls_config>]
```

## server_tls_config

The `server_tls_config` configures TLS.

```yaml
# File path to the server certificate
[cert_file: <string>]

# File path to the server key
[key_file: <string>]

# Tells the server what is acceptable from the client, this drives the options in client_tls_config
[client_auth_type: <string>]

# File path to the signing CA certificate, needed if CA is not trusted
[client_ca_file: <string>]

# Windows certificate filter allows selecting client CA and server certificate from the Windows Certificate store
[windows_certificate_filter: <windows_certificate_filter_config>]
```

## windows_certificate_filter_config

The `windows_certificate_filter_config` configures the use of the Windows Certificate store. Setting cert_file, key_file, and client_ca_file are invalid settings when using the windows_certificate_filter.

```yaml
# Client configuration, optional. If nothing specific will use the default client ca root
[client: <windows_client_config>]
  
# Name of the store to look for the Client Certificate ex My, CA
server: <windows_server_config>
```

### windows_client_config

```yaml
# Array of issuer common names to check against
issuer_common_names:
  [- <string> ... ]

# Regular expression to match Subject name
[subject_regex: <string>]

# Client Template ID to match in ASN1 format ex "1.2.3"
[template_id: <string>]
```

### windows_server_config

```yaml
# Name of the system store to look for the Server Certificate ex LocalMachine, CurrentUser
system_store: <string>

# Name of the store to look for the Server Certificate ex My, CA
store: <string>

# Array of issuer common names to check against
issuer_common_names:
[- <string> ... ]

# Server Template ID to match in ASN1 format ex "1.2.3"
[template_id: <string>]

# How often to refresh the server certificate ex 5m, 1h
[refresh_interval: <duration>]
```

'''
'''--- docs/sources/configuration/traces-config.md ---
---
aliases:
- /docs/agent/latest/configuration/tempo-config/
- /docs/agent/latest/configuration/traces-config/
title: traces_config
weight: 400
---

# traces_config

The `traces_config` block configures a set of Tempo instances, each of which
configures its own tracing pipeline. Having multiple configs allows you to
configure multiple distinct pipelines, each of which collects spans and sends
them to a different location.

Note that if using multiple configs, you must manually set port numbers for
each receiver, otherwise they will all try to use the same port and fail to
start.

```yaml
configs:
 - [<traces_instance_config>]
 ```

## traces_instance_config

```yaml
# Name configures the name of this Tempo instance. Names must be non-empty and
# unique across all Tempo instances. The value of the name here will appear in
# logs and as a label on metrics.
name: <string>

# This field allows for the general manipulation of tags on spans that pass
# through this agent. A common use may be to add an environment or cluster
# variable.
[attributes: <attributes.config>]

# This field allows to configure grouping spans into batches. Batching helps
# better compress the data and reduce the number of outgoing connections
# required transmit the data.
[batch: <batch.config>]

remote_write:
  # host:port to send traces to
  # Here must be the port of gRPC receiver, not the Tempo default port.
  # Example for cloud instances:  `tempo-us-central1.grafana.net:443`
  # For local / on-premises instances: `localhost:55680` or `tempo.example.com:14250`
  # Note: for non-encrypted connections you must also set `insecure: true`
  - endpoint: <string>

    # Custom HTTP headers to be sent along with each remote write request.
    # Be aware that 'authorization' header will be overwritten in presence
    # of basic_auth.
    headers:
      [ <string>: <string> ... ]

    # Controls whether compression is enabled.
    [ compression: <string> | default = "gzip" | supported = "none", "gzip"]

    # Controls what protocol to use when exporting traces.
    # Only "grpc" is supported in Grafana Cloud.
    [ protocol: <string> | default = "grpc" | supported = "grpc", "http" ]

    # Controls what format to use when exporting traces, in combination with protocol.
    # protocol/format supported combinations are grpc/otlp, http/otlp and grpc/jaeger
    # Only grpc/otlp is supported in Grafana Cloud.
    [ format: <string> | default = "otlp" | supported = "otlp", "jaeger" ]

    # Controls whether or not TLS is required.  See https://godoc.org/google.golang.org/grpc#WithInsecure
    [ insecure: <boolean> | default = false ]

    # Deprecated in favor of tls_config
    # If both `insecure_skip_verify` and `tls_config.insecure_skip_verify` are used,
    # the latter take precedence.
    [ insecure_skip_verify: <bool> | default = false ]

    # Configures opentelemetry exporters to use the OpenTelemetry auth extension `oauth2clientauthextension`.
    # Can not be used in combination with `basic_auth`.
    # See https://github.com/open-telemetry/opentelemetry-collector-contrib/blob/main/extension/oauth2clientauthextension/README.md
    oauth2:
            # Configures the TLS settings specific to the oauth2 client
                    # The client identifier issued to the oauth client
                    [client_id: <string>]
                    # The secret string associated with the oauth client
                    [client_secret: <string>]
                    # The resource server's token endpoint URL
                    [token_url: <string>]
                    # Optional, requested permissions associated with the oauth client
                    [scopes: [<string>]]
                    # Optional, specifies the timeout fetching tokens from the token_url. Default: no timeout
                    [timeout: <duration>]
              tls:
                      # Disable validation of the server certificate.
                              [ insecure: <bool> | default = false ]
                              # Path to the CA cert. For a client this verifies the server certificate. If empty uses system root CA.
                              [ca_file: <string>]
                              # Path to the TLS cert to use for TLS required connections
                              [cert_file: <string>]
                              # Path to the TLS key to use for TLS required connections
                              [key_file: <string>]

    # Controls TLS settings of the exporter's client. See https://github.com/open-telemetry/opentelemetry-collector/blob/v0.21.0/config/configtls/README.md
    # This should be used only if `insecure` is set to false
    tls_config:
      # Path to the CA cert. For a client this verifies the server certificate. If empty uses system root CA.
      [ca_file: <string>]
      # Path to the TLS cert to use for TLS required connections
      [cert_file: <string>]
      # Path to the TLS key to use for TLS required connections
      [key_file: <string>]
      # Disable validation of the server certificate.
      [ insecure_skip_verify: <bool> | default = false ]

    # Sets the `Authorization` header on every trace push with the
    # configured username and password.
    # password and password_file are mutually exclusive.
    basic_auth:
      [ username: <string> ]
      [ password: <secret> ]
      [ password_file: <string> ]

    [ sending_queue: <otlpexporter.sending_queue> ]
    [ retry_on_failure: <otlpexporter.retry_on_failure> ]

# This processor writes a well formatted log line to a logs instance for each span, root, or process
# that passes through the Agent. This allows for automatically building a mechanism for trace
# discovery and building metrics from traces using Loki. It should be considered experimental.
automatic_logging:
  # Indicates where the stream of log lines should go. Either supports writing
  # to a logs instance defined in this same config or to stdout.
  [ backend: <string> | default = "stdout" | supported "stdout", "logs_instance" ]
  # Indicates the logs instance to write logs to.
  # Required if backend is set to logs_instance.
  [ logs_instance_name: <string> ]
  # Log one line per span. Warning! possibly very high volume
  [ spans: <boolean> ]
  # Log one line for every root span of a trace.
  [ roots: <boolean> ]
  # Log one line for every process
  [ processes: <boolean> ]
  # Additional span attributes to log
  [ span_attributes: <string array> ]
  # Additional process attributes to log
  [ process_attributes: <string array> ]
  # Timeout on writing logs to Loki when backend is "logs_instance."
  [ timeout: <duration> | default = 1ms ]
  # Configures a set of key values that will be logged as labels
  # They need to be span or process attributes logged in the log line
  #
  # This feature only applies when `backend = logs_instance`
  #
  # Loki only accepts alphanumeric and "_" as valid characters for labels.
  # Labels are sanitized by replacing invalid characters with underscores.
  [ labels: <string array> ]
  overrides:
    [ logs_instance_tag: <string> | default = "traces" ]
    [ service_key: <string> | default = "svc" ]
    [ span_name_key: <string> | default = "span" ]
    [ status_key: <string> | default = "status" ]
    [ duration_key: <string> | default = "dur" ]
    [ trace_id_key: <string> | default = "tid" ]

# Receiver configurations are mapped directly into the OpenTelemetry receivers
# block. At least one receiver is required.
# The Agent uses OpenTelemetry v0.36.0. Refer to the corresponding receiver's config.
#
# Supported receivers: otlp, jaeger, kafka, opencensus and zipkin.
receivers: <receivers>

# A list of prometheus scrape configs.  Targets discovered through these scrape
# configs have their __address__ matched against the ip on incoming spans. If a
# match is found then relabeling rules are applied.
scrape_configs:
  - [<scrape_config>]
# Defines what method is used when adding k/v to spans.
# Options are `update`, `insert` and `upsert`.
# `update` only modifies an existing k/v and `insert` only appends if the k/v
# is not present. `upsert` does both.
[ prom_sd_operation_type: <string> | default = "upsert" ]
# Configures what methods to use to do association between spans and pods.
# PromSD processor matches the IP address of the metadata labels from the k8s API
# with the IP address obtained from the specified pod association method.
# If a match is found then the span is labeled.
#
# Options are `ip`, `net.host.ip`, `k8s.pod.ip`, `hostname` and `connection`.
#   - `ip`, `net.host.ip` and `k8s.pod.ip`, `hostname` match spans tags.
#   - `connection` inspects the context from the incoming requests (gRPC and HTTP).
#
# Tracing instrumentation is commonly the responsible for tagging spans
# with IP address to the labels mentioned above.
# If running on kubernetes, `k8s.pod.ip` can be automatically attached via the
# downward API. For example, if you're using OTel instrumentation libraries, set 
# OTEL_RESOURCE_ATTRIBUTES=k8s.pod.ip=$(POD_IP) to inject spans with the sender
# pod's IP.
#
# By default, all methods are enabled, and evaluated in the order specified above.
# Order of evaluation is honored when multiple methods are enabled.
prom_sd_pod_associations:
  - [ <string>... ]

# spanmetrics supports aggregating Request, Error and Duration (R.E.D) metrics
# from span data.
#
# spanmetrics generates two metrics from spans and uses remote_write or
# OpenTelemetry Prometheus exporters to serve the metrics locally.
#
# In order to use the remote_write exporter, you have to configure a Prometheus
# instance in the Agent and pass its name to the `metrics_instance` field.
#
# If you want to use the OpenTelemetry Prometheus exporter, you have to
# configure handler_endpoint and then scrape that endpoint.
#
# The first generated metric is `calls`, a counter to compute requests.
# The second generated metric is `latency`, a histogram to compute the
# operation's duration.
#
# If you want to rename the generated metrics, you can configure the `namespace`
# option of prometheus exporter.
#
# This is an experimental feature of Opentelemetry-Collector and the behavior
# may change in the future.
spanmetrics:
  # latency_histogram_buckets and dimensions are the same as the configs in
  # spanmetricsprocessor.
  [ latency_histogram_buckets: <spanmetricsprocessor.latency_histogram_buckets> ]
  [ dimensions: <spanmetricsprocessor.dimensions> ]
  # const_labels are labels that will always get applied to the exported
  # metrics.
  const_labels:
    [ <string>: <string>... ]
  # Metrics are namespaced to `traces_spanmetrics` by default.
  # They can be further namespaced, i.e. `{namespace}_traces_spanmetrics`
  [ namespace: <string> ]
  # metrics_instance is the metrics instance used to remote write metrics.
  [ metrics_instance: <string> ]
  # handler_endpoint defines the endpoint where the OTel prometheus exporter will be exposed.
  [ handler_endpoint: <string> ]

# tail_sampling supports tail-based sampling of traces in the agent.
#
# Policies can be defined that determine what traces are sampled and sent to the
# backends and what traces are dropped.
#
# In order to make a correct sampling decision it's important that the agent has
# a complete trace. This is achieved by waiting a given time for all the spans
# before evaluating the trace.
#
# Tail sampling also supports multi agent deployments, allowing to group all
# spans of a trace in the same agent by load balancing the spans by trace ID
# between the instances.
# * To make use of this feature, check load_balancing below *
tail_sampling:
  # policies define the rules by which traces will be sampled. Multiple policies
  # can be added to the same pipeline.
  policies:
    - [<tailsamplingprocessor.policies>]

  # Time that to wait before making a decision for a trace.
  # Longer wait times reduce the probability of sampling an incomplete trace at
  # the cost of higher memory usage.
  decision_wait: [ <duration> | default="5s" ]

# load_balancing configures load balancing of spans across multi agent deployments.
# It ensures that all spans of a trace are sampled in the same instance.
# It works by exporting spans based on their traceID via consistent hashing.
#
# Enabling this feature is required for tail_sampling to correctly work when
# different agent instances can receive spans for the same trace.
#
# Load balancing works by layering two pipelines and consistently exporting
# spans belonging to a trace to the same agent instance.
# Agent instances need to be able to communicate with each other via gRPC.
#
# Load balancing significantly increases CPU usage. This is because spans are
# exported an additional time between agents.
load_balancing:
  # resolver configures the resolution strategy for the involved backends
  # It can be static, with a fixed list of hostnames, or DNS, with a hostname
  # (and port) that will resolve to all IP addresses.
  resolver:
    static:
      hostnames:
        [ - <string> ... ]
    dns:
      hostname: <string>
      [ port: <int> ]

  # receiver_port is the port the instance will use to receive load balanced traces
  receiver_port: [ <int> | default = 4318 ]

  # Load balancing is done via an otlp exporter.
  # The remaining configuration is common with the remote_write block.
  exporter:
    # Controls whether compression is enabled.
    [ compression: <string> | default = "gzip" | supported = "none", "gzip"]

    # Controls whether or not TLS is required.
    [ insecure: <boolean> | default = false ]

    # Disable validation of the server certificate. Only used when insecure is set
    # to false.
    [ insecure_skip_verify: <bool> | default = false ]

    # Sets the `Authorization` header on every trace push with the
    # configured username and password.
    # password and password_file are mutually exclusive.
    basic_auth:
      [ username: <string> ]
      [ password: <secret> ]
      [ password_file: <string> ]

# service_graphs configures processing of traces for building service graphs in
# the form of prometheus metrics. The generated metrics represent edges between
# nodes in the graph. Nodes are represented by `client` and `server` labels.
#
#  e.g. tempo_service_graph_request_total{client="app", server="db"} 20
#
# Service graphs works by inspecting spans and looking for the tag `span.kind`.
# If it finds the span kind to be client or server, it stores the request in a
# local in-memory store.
#
# That request waits until its corresponding client or server pair span is
# processed or until the maximum waiting time has passed.
# When either of those conditions is reached, the request is processed and
# removed from the local store. If the request is complete by that time, it'll
# be recorded as an edge in the graph.
#
# Service graphs supports multi-agent deployments, allowing to group all spans
# of a trace in the same agent by load balancing the spans by trace ID between
# the instances.
# * To make use of this feature, check load_balancing above *
service_graphs:
  [ enabled: <bool> | default = false ]

  # configures the time the processor will wait since a span is consumed until
  # it's considered expired if its paired has not been processed.
  #
  # increasing the waiting time will increase the percentage of paired spans.
  # retaining unpaired spans for longer will make reaching max_items more likely.
  [ wait: <duration> | default = "10s"]

  # configures the max amount of edges that will be stored in memory.
  #
  # spans that arrive to the processor that do not pair with an already
  # processed span are dropped.
  #
  # a higher max number of items increases the max throughput of processed spans
  # with a higher memory consumption.
  [ max_items: <integer> | default = 10_000 ]
  
  # configures the number of workers that will process completed edges concurrently.
  # as edges are completed, they get queued to be collected as metrics for the graph.
  [ workers: <integer> | default = 10]

  # configures what status codes are considered as successful (e.g. HTTP 404).
  #
  # by default, a request is considered failed in the following cases:
  #   1. HTTP status is not 2XX
  #   1. gRPC status code is not OK
  #   1. span status is Error
  success_codes:
    # http status codes not to be considered as failure
    http:
      [ - <int> ... ]
    # grpc status codes not to be considered as failure
    grpc:
      [ - <int> ... ]
```

> **Note:** More information on the following types can be found on the
> documentation for their respective projects:
>
* [`attributes.config`: OpenTelemetry-Collector](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/b2327211df976e0a57ef0425493448988772a16b/processor/attributesprocessor)
* [`batch.config`: OpenTelemetry-Collector](https://github.com/open-telemetry/opentelemetry-collector/tree/1f5dd9f9a566a937ec15093ca3bc377fba86f5f9/processor/batchprocessor)
* [`otlpexporter.sending_queue`: OpenTelemetry-Collector](https://github.com/open-telemetry/opentelemetry-collector/tree/1f5dd9f9a566a937ec15093ca3bc377fba86f5f9/exporter/otlpexporter)
* [`otlpexporter.retry_on_failure`: OpenTelemetry-Collector](https://github.com/open-telemetry/opentelemetry-collector/tree/1f5dd9f9a566a937ec15093ca3bc377fba86f5f9/exporter/otlpexporter)
* `receivers`:
  * [`jaegerreceiver`: OpenTelemetry-Collector-Contrib](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/b2327211df976e0a57ef0425493448988772a16b/receiver/jaegerreceiver)
  * [`kafkareceiver`: OpenTelemetry-Collector-Contrib](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/b2327211df976e0a57ef0425493448988772a16b/receiver/kafkareceiver)
  * [`otlpreceiver`: OpenTelemetry-Collector](https://github.com/open-telemetry/opentelemetry-collector/tree/1f5dd9f9a566a937ec15093ca3bc377fba86f5f9/receiver/otlpreceiver)
  * [`opencensusreceiver`: OpenTelemetry-Collector-Contrib](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/b2327211df976e0a57ef0425493448988772a16b/receiver/opencensusreceiver)
  * [`zipkinreceiver`: OpenTelemetry-Collector-Contrib](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/b2327211df976e0a57ef0425493448988772a16b/receiver/zipkinreceiver)
* [`scrape_config`: Prometheus](https://prometheus.io/docs/prometheus/2.34/configuration/configuration/#scrape_config)
* [`spanmetricsprocessor.latency_histogram_buckets`: OpenTelemetry-Collector-Contrib](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/b2327211df976e0a57ef0425493448988772a16b/processor/spanmetricsprocessor/config.go#L38-L47)
* [`spanmetricsprocessor.dimensions`: OpenTelemetry-Collector-Contrib](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/b2327211df976e0a57ef0425493448988772a16b/processor/spanmetricsprocessor/config.go#L38-L47)
* [`tailsamplingprocessor.policies`: OpenTelemetry-Collector-Contrib](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/b2327211df976e0a57ef0425493448988772a16b/processor/tailsamplingprocessor)

'''
'''--- docs/sources/cookbook/_index.md ---
---
aliases:
- /docs/agent/latest/cookbook
title: Cookbook
weight: 900
---

## Cookbook 

The cookbook section aims to provide small guides for more advanced use cases, experimental features, or certain concepts around Grafana Agent.

You can find all available entries listed below.

* [Dynamic Configuration]({{< relref "./dynamic-configuration/_index.md" >}})

'''
'''--- docs/sources/cookbook/dynamic-configuration/01_Basics/01_Structure.md ---
---
aliases:
- /docs/agent/latest/dynamic-configuration/structure
title: Structure
weight: 100
---

# 01 Structure

Dynamic Configuration uses a series of files to load templates. This example will show how they all combine together. Running the below command will combine all the templates into the final.yml. Any failure while loading the config will revert to the original config, or if this is the initial load Grafana Agent will quit.

`docker run -v ${PWD}/:/etc/grafana grafana/agentctl:latest template-parse file:///etc/grafana/01_config.yml`

## Dynamic Configuration

[config.yml](https://github.com/grafana/agent/blob/main/docs/sources/cookbook/dynamic-configuration/01_Basics/01_config.yml)

```yaml
template_paths:
  - "file:///etc/grafana/01_assets"
```

Tells the Grafana Agent where to load files from. It is important to note that dynamic configuration does NOT traverse directories. It will look at the directory specified only, if you need more directories then add them to the `template_paths` array. NOTE, if no protocol specified ie `file://` above, then file access will be assumed. `file:///etc/grafana/01_assets` is equivalent to `//etc/grafana/01_assets`

## Agent

Dynamic Configuration will find the first file matching pattern `agent-*.yml` and load that as the base. You can only have one agent template. If multiple matching templates are found then the configuration will fail to load.

[agent-1.yml](https://github.com/grafana/agent/blob/main/docs/sources/cookbook/dynamic-configuration/01_Basics/01_assets/agent-1.yml)

```yaml
server:
  log_level: debug
metrics:
  wal_directory: /tmp/grafana-agent-normal
  global:
    scrape_interval: 60s
    remote_write:
      - url: https://prometheus-us-central1.grafana.net/api/prom/push
        basic_auth:
          username: xyz
          password: secretpassword
integrations:
  node_exporter:
    enabled: true
  agent:
    enabled: true
```

## Server

Dynamic configuration will find the first file matching pattern `server-*.yml` and replace the `Server` config block in
the Agent Configuration. Note that you do NOT include the `server:` tag, dynamic configuration knows by the name that it
is a configuration block.

You can only have 1 server template.

[server-1.yml](https://github.com/grafana/agent/blob/main/docs/sources/cookbook/dynamic-configuration/01_Basics/01_assets/server-1.yml)

```yaml
log_level: info
```

## Final

[final.yml](https://github.com/grafana/agent/blob/main/docs/sources/cookbook/dynamic-configuration/01_Basics/01_assets/final.yml)

In the above example the `log_level: debug` block will be replaced with `log_level: info` from the server-1.yml

'''
'''--- docs/sources/cookbook/dynamic-configuration/01_Basics/01_assets/agent-1.yml ---
server:
  log_level: debug
metrics:
  wal_directory: /tmp/grafana-agent-normal
  global:
    scrape_interval: 60s
    remote_write:
      - url: https://prometheus-us-central1.grafana.net/api/prom/push
        basic_auth:
          username: xyz
          password: secretpassword
integrations:
  node_exporter:
    autoscrape:
      enable: true
  agent:
    autoscrape:
      enable: true

'''
'''--- docs/sources/cookbook/dynamic-configuration/01_Basics/01_assets/final.yml ---
server:
  http_tls_config:
    cert_file: ""
    key_file: ""
    client_auth_type: ""
    client_ca_file: ""
    cipher_suites: []
    curve_preferences: []
    min_version: 0
    max_version: 0
    prefer_server_cipher_suites: false
  grpc_tls_config:
    cert_file: ""
    key_file: ""
    client_auth_type: ""
    client_ca_file: ""
    cipher_suites: []
    curve_preferences: []
    min_version: 0
    max_version: 0
    prefer_server_cipher_suites: false
  log_format: ""
  log_level: info
metrics:
  global:
    scrape_interval: 1m
    scrape_timeout: 10s
    evaluation_interval: 1m
    remote_write:
    - url: https://prometheus-us-central1.grafana.net/api/prom/push
      remote_timeout: 30s
      basic_auth:
        username: "xyx"
        password: <secret>
      follow_redirects: true
      queue_config:
        capacity: 2500
        max_shards: 200
        min_shards: 1
        max_samples_per_send: 500
        batch_send_deadline: 5s
        min_backoff: 30ms
        max_backoff: 100ms
      metadata_config:
        send: true
        send_interval: 1m
        max_samples_per_send: 500
  wal_directory: /tmp/grafana-agent-normal
  wal_cleanup_age: 12h0m0s
  wal_cleanup_period: 30m0s
  scraping_service:
    enabled: false
    reshard_interval: 1m0s
    reshard_timeout: 30s
    cluster_reshard_event_timeout: 30s
    kvstore:
      store: consul
      prefix: configurations/
      consul:
        host: localhost:8500
        acl_token: <secret>
        http_client_timeout: 20s
        consistent_reads: false
        watch_rate_limit: 1
        watch_burst_size: 1
      etcd:
        endpoints: []
        dial_timeout: 10s
        max_retries: 10
        tls_enabled: false
        tls_cert_path: ""
        tls_key_path: ""
        tls_ca_path: ""
        tls_server_name: ""
        tls_insecure_skip_verify: false
        username: ""
        password: <secret>
      multi:
        primary: ""
        secondary: ""
        mirror_enabled: false
        mirror_timeout: 2s
    lifecycler:
      ring:
        kvstore:
          store: consul
          prefix: collectors/
          consul:
            host: localhost:8500
            acl_token: <secret>
            http_client_timeout: 20s
            consistent_reads: false
            watch_rate_limit: 1
            watch_burst_size: 1
          etcd:
            endpoints: []
            dial_timeout: 10s
            max_retries: 10
            tls_enabled: false
            tls_cert_path: ""
            tls_key_path: ""
            tls_ca_path: ""
            tls_server_name: ""
            tls_insecure_skip_verify: false
            username: ""
            password: <secret>
          multi:
            primary: ""
            secondary: ""
            mirror_enabled: false
            mirror_timeout: 2s
        heartbeat_timeout: 1m0s
        replication_factor: 3
        zone_awareness_enabled: false
      num_tokens: 128
      heartbeat_period: 5s
      observe_period: 0s
      join_after: 0s
      min_ready_duration: 1m0s
      interface_names:
      - eth0
      - en0
      final_sleep: 30s
      tokens_file_path: ""
      availability_zone: ""
      unregister_on_shutdown: true
      address: ""
      port: 0
      id: 4c1ed28ad826
    dangerous_allow_reading_files: false
  scraping_service_client:
    grpc_client_config:
      max_recv_msg_size: 104857600
      max_send_msg_size: 16777216
      grpc_compression: ""
      rate_limit: 0
      rate_limit_burst: 0
      backoff_on_ratelimits: false
      backoff_config:
        min_period: 100ms
        max_period: 10s
        max_retries: 10
      tls_enabled: false
      tls_cert_path: ""
      tls_key_path: ""
      tls_ca_path: ""
      tls_server_name: ""
      tls_insecure_skip_verify: false
  instance_restart_backoff: 5s
  instance_mode: shared
integrations:
  metrics:
    autoscrape:
      enable: true
      metrics_instance: default
      scrape_interval: 1m
      scrape_timeout: 10s
  agent: {}

'''
'''--- docs/sources/cookbook/dynamic-configuration/01_Basics/01_assets/server-1.yml ---
log_level: info

'''
'''--- docs/sources/cookbook/dynamic-configuration/01_Basics/01_config.yml ---
template_paths:
  - "file:///etc/grafana/01_assets"
'''
'''--- docs/sources/cookbook/dynamic-configuration/01_Basics/02_Instances.md ---
---
aliases:
- /docs/agent/latest/dynamic-configuration/instances
title: Instances
weight: 110
---

# 02 Instances

Dynamic configuration allows multiple prometheus instances to be loaded with a parent metric. This uses
the same agent-1 and server-1 yml from 01.

`docker run -v ${PWD}/:/etc/grafana grafana/agentctl:latest template-parse file:///etc/grafana/02_config.yml`

## Dynamic Configuration

[config.yml](https://github.com/grafana/agent/blob/main/docs/sources/cookbook/dynamic-configuration/01_Basics/02_config.yml)

Tells the Grafana Agent where to load files from.

## Metrics

Dynamic Configuration will find the first file matching pattern `metrics-*.yml` and load that as the base. You can only have one metrics template.

[metrics-1.yml](https://github.com/grafana/agent/blob/main/docs/sources/cookbook/dynamic-configuration/01_Basics/02_assets/metrics-1.yml)

```yaml
configs:
  - name: default
global:
  scrape_interval: 60s
  scrape_timeout: 20s
wal_directory: /tmp/grafana-agent-wal
```

## Metrics Instances

You can have any number of metrics_instances and they are added to any existing metrics instances defined previously.

[metrics_instances-1.yml](https://github.com/grafana/agent/blob/main/docs/sources/cookbook/dynamic-configuration/01_Basics/02_assets/metrics_instances-1.yml)

```yaml
name: instance1
scrape_configs:
  - job_name: instance1_job
    static_configs:
      - targets:
          - localhost:4000
```

[metrics_instances-2.yml](https://github.com/grafana/agent/blob/main/docs/sources/cookbook/dynamic-configuration/01_Basics/02_assets/metrics_instances-2.yml)

```yaml
name: instance2
scrape_configs:
  - job_name: instance2_job
    static_configs:
      - targets:
          - localhost:5555
```

## Final

[final.yml](https://github.com/grafana/agent/blob/main/docs/sources/cookbook/dynamic-configuration/01_Basics/01_assets/final.yml)

In the above you will see the `final.yml` includes all the instance configurations
- default
- instance1
- instance2

'''
'''--- docs/sources/cookbook/dynamic-configuration/01_Basics/02_assets/agent-1.yml ---
server:
  log_level: debug
metrics:
  wal_directory: /tmp/grafana-agent-normal
  global:
    scrape_interval: 60s
    remote_write:
      - url: https://prometheus-us-central1.grafana.net/api/prom/push
        basic_auth:
          username: xyz
          password: secretpassword
integrations:
  node_exporter: {}
  agent: {}

'''
'''--- docs/sources/cookbook/dynamic-configuration/01_Basics/02_assets/final.yml ---
server:
  http_tls_config:
    cert_file: ""
    key_file: ""
    client_auth_type: ""
    client_ca_file: ""
    cipher_suites: []
    curve_preferences: []
    min_version: 0
    max_version: 0
    prefer_server_cipher_suites: false
  grpc_tls_config:
    cert_file: ""
    key_file: ""
    client_auth_type: ""
    client_ca_file: ""
    cipher_suites: []
    curve_preferences: []
    min_version: 0
    max_version: 0
    prefer_server_cipher_suites: false
  log_format: ""
  log_level: info
metrics:
  global:
    scrape_interval: 1m
    scrape_timeout: 20s
    evaluation_interval: 1m
  wal_directory: /tmp/grafana-agent-wal
  wal_cleanup_age: 12h0m0s
  wal_cleanup_period: 30m0s
  scraping_service:
    enabled: false
    reshard_interval: 1m0s
    reshard_timeout: 30s
    cluster_reshard_event_timeout: 30s
    kvstore:
      store: consul
      prefix: configurations/
      consul:
        host: localhost:8500
        acl_token: <secret>
        http_client_timeout: 20s
        consistent_reads: false
        watch_rate_limit: 1
        watch_burst_size: 1
      etcd:
        endpoints: []
        dial_timeout: 10s
        max_retries: 10
        tls_enabled: false
        tls_cert_path: ""
        tls_key_path: ""
        tls_ca_path: ""
        tls_server_name: ""
        tls_insecure_skip_verify: false
        username: ""
        password: <secret>
      multi:
        primary: ""
        secondary: ""
        mirror_enabled: false
        mirror_timeout: 2s
    lifecycler:
      ring:
        kvstore:
          store: consul
          prefix: collectors/
          consul:
            host: localhost:8500
            acl_token: <secret>
            http_client_timeout: 20s
            consistent_reads: false
            watch_rate_limit: 1
            watch_burst_size: 1
          etcd:
            endpoints: []
            dial_timeout: 10s
            max_retries: 10
            tls_enabled: false
            tls_cert_path: ""
            tls_key_path: ""
            tls_ca_path: ""
            tls_server_name: ""
            tls_insecure_skip_verify: false
            username: ""
            password: <secret>
          multi:
            primary: ""
            secondary: ""
            mirror_enabled: false
            mirror_timeout: 2s
        heartbeat_timeout: 1m0s
        replication_factor: 3
        zone_awareness_enabled: false
      num_tokens: 128
      heartbeat_period: 5s
      observe_period: 0s
      join_after: 0s
      min_ready_duration: 1m0s
      interface_names:
      - eth0
      - en0
      final_sleep: 30s
      tokens_file_path: ""
      availability_zone: ""
      unregister_on_shutdown: true
      address: ""
      port: 0
      id: 04802136a818
    dangerous_allow_reading_files: false
  scraping_service_client:
    grpc_client_config:
      max_recv_msg_size: 104857600
      max_send_msg_size: 16777216
      grpc_compression: ""
      rate_limit: 0
      rate_limit_burst: 0
      backoff_on_ratelimits: false
      backoff_config:
        min_period: 100ms
        max_period: 10s
        max_retries: 10
      tls_enabled: false
      tls_cert_path: ""
      tls_key_path: ""
      tls_ca_path: ""
      tls_server_name: ""
      tls_insecure_skip_verify: false
  configs:
  - name: default
    wal_truncate_frequency: 1h0m0s
    min_wal_time: 5m0s
    max_wal_time: 4h0m0s
    remote_flush_deadline: 1m0s
  - name: instance1
    scrape_configs:
    - job_name: instance1_job
      honor_timestamps: true
      scrape_interval: 1m
      scrape_timeout: 20s
      metrics_path: /metrics
      scheme: http
      follow_redirects: true
      static_configs:
      - targets:
        - localhost:4000
    wal_truncate_frequency: 1h0m0s
    min_wal_time: 5m0s
    max_wal_time: 4h0m0s
    remote_flush_deadline: 1m0s
  - name: instance2
    scrape_configs:
    - job_name: instance2_job
      honor_timestamps: true
      scrape_interval: 1m
      scrape_timeout: 20s
      metrics_path: /metrics
      scheme: http
      follow_redirects: true
      static_configs:
      - targets:
        - localhost:5555
    wal_truncate_frequency: 1h0m0s
    min_wal_time: 5m0s
    max_wal_time: 4h0m0s
    remote_flush_deadline: 1m0s
  instance_restart_backoff: 5s
  instance_mode: shared
integrations:
  metrics:
    autoscrape:
      enable: true
      metrics_instance: default
      scrape_interval: 1m
      scrape_timeout: 20s
  agent: {}

'''
'''--- docs/sources/cookbook/dynamic-configuration/01_Basics/02_assets/metrics-1.yml ---
configs:
- name: default
global:
  scrape_interval: 60s
  scrape_timeout: 20s
wal_directory: /tmp/grafana-agent-wal
'''
'''--- docs/sources/cookbook/dynamic-configuration/01_Basics/02_assets/metrics_instances-1.yml ---
name: instance1
scrape_configs:
  - job_name: instance1_job
    static_configs:
      - targets:
          - localhost:4000
'''
'''--- docs/sources/cookbook/dynamic-configuration/01_Basics/02_assets/metrics_instances-2.yml ---
name: instance2
scrape_configs:
  - job_name: instance2_job
    static_configs:
      - targets:
          - localhost:5555
'''
'''--- docs/sources/cookbook/dynamic-configuration/01_Basics/02_assets/server-1.yml ---
log_level: info

'''
'''--- docs/sources/cookbook/dynamic-configuration/01_Basics/02_config.yml ---
template_paths:
  - "file:///etc/grafana/02_assets"
'''
'''--- docs/sources/cookbook/dynamic-configuration/01_Basics/03_Integrations.md ---
---
aliases:
- /docs/agent/latest/dynamic-configuration/integrations
title: Integrations
weight: 120
---

# 03 Integrations

Dynamic configuration requires the use of `integrations-next` feature flag, to allow arrays of integrations. In this we will load integrations of various types. This is all built on the previous examples.

`docker run -v ${PWD}/:/etc/grafana grafana/agentctl:latest template-parse file:///etc/grafana/03_config.yml`

## Dynamic Configuration

[config.yml](https://github.com/grafana/agent/blob/main/docs/sources/cookbook/dynamic-configuration/01_Basics/03_config.yml)

Tells the Grafana Agent where to load files from.

## Integrations

Integrations are loaded from files matching `integrations-*.yml` and are combined together. You can declare for example multiple sets of `redis_configs` across several files.

[integrations-node.yml](https://github.com/grafana/agent/blob/main/docs/sources/cookbook/dynamic-configuration/01_Basics/03_assets/integrations-node.yml)

Note: You do NOT have to name the above file `integrations-node.yml` with `node`, `integrations-1.yml` would work the same. The name does NOT determine the type of integrations a template can contain and a template can contain integrations of different types.

```yaml
node_exporter: {}
```

[integrations-redis.yml](https://github.com/grafana/agent/blob/main/docs/sources/cookbook/dynamic-configuration/01_Basics/03_assets/integrations-redis.yml)

```yaml
redis_configs:
  - redis_addr: localhost:6379
    autoscrape:
      metric_relabel_configs:
        - source_labels: [__address__]
          target_label: "banana"
          replacement: "apple"
  - redis_addr: localhost:6380
```

## Final

[final.yml](https://github.com/grafana/agent/blob/main/docs/sources/cookbook/dynamic-configuration/01_Basics/03_assets/final.yml)

The final result should have 3 integrations enabled, 1 node_exporter and 2 redis.

'''
'''--- docs/sources/cookbook/dynamic-configuration/01_Basics/03_assets/agent-1.yml ---
server:
  log_level: debug
metrics:
  wal_directory: /tmp/grafana-agent-normal
  global:
    scrape_interval: 60s
    remote_write:
      - url: https://prometheus-us-central1.grafana.net/api/prom/push
        basic_auth:
          username: xyx
          password: secretpassword
integrations:
  node_exporter: {}
  agent: {}

'''
'''--- docs/sources/cookbook/dynamic-configuration/01_Basics/03_assets/final.yml ---
server:
  http_tls_config:
    cert_file: ""
    key_file: ""
    client_auth_type: ""
    client_ca_file: ""
    cipher_suites: []
    curve_preferences: []
    min_version: 0
    max_version: 0
    prefer_server_cipher_suites: false
  grpc_tls_config:
    cert_file: ""
    key_file: ""
    client_auth_type: ""
    client_ca_file: ""
    cipher_suites: []
    curve_preferences: []
    min_version: 0
    max_version: 0
    prefer_server_cipher_suites: false
  log_format: ""
  log_level: info
metrics:
  global:
    scrape_interval: 1m
    scrape_timeout: 20s
    evaluation_interval: 1m
  wal_directory: /tmp/grafana-agent-wal
  wal_cleanup_age: 12h0m0s
  wal_cleanup_period: 30m0s
  scraping_service:
    enabled: false
    reshard_interval: 1m0s
    reshard_timeout: 30s
    cluster_reshard_event_timeout: 30s
    kvstore:
      store: consul
      prefix: configurations/
      consul:
        host: localhost:8500
        acl_token: <secret>
        http_client_timeout: 20s
        consistent_reads: false
        watch_rate_limit: 1
        watch_burst_size: 1
      etcd:
        endpoints: []
        dial_timeout: 10s
        max_retries: 10
        tls_enabled: false
        tls_cert_path: ""
        tls_key_path: ""
        tls_ca_path: ""
        tls_server_name: ""
        tls_insecure_skip_verify: false
        username: ""
        password: <secret>
      multi:
        primary: ""
        secondary: ""
        mirror_enabled: false
        mirror_timeout: 2s
    lifecycler:
      ring:
        kvstore:
          store: consul
          prefix: collectors/
          consul:
            host: localhost:8500
            acl_token: <secret>
            http_client_timeout: 20s
            consistent_reads: false
            watch_rate_limit: 1
            watch_burst_size: 1
          etcd:
            endpoints: []
            dial_timeout: 10s
            max_retries: 10
            tls_enabled: false
            tls_cert_path: ""
            tls_key_path: ""
            tls_ca_path: ""
            tls_server_name: ""
            tls_insecure_skip_verify: false
            username: ""
            password: <secret>
          multi:
            primary: ""
            secondary: ""
            mirror_enabled: false
            mirror_timeout: 2s
        heartbeat_timeout: 1m0s
        replication_factor: 3
        zone_awareness_enabled: false
      num_tokens: 128
      heartbeat_period: 5s
      observe_period: 0s
      join_after: 0s
      min_ready_duration: 1m0s
      interface_names:
      - eth0
      - en0
      final_sleep: 30s
      tokens_file_path: ""
      availability_zone: ""
      unregister_on_shutdown: true
      address: ""
      port: 0
      id: 920e9b32116a
    dangerous_allow_reading_files: false
  scraping_service_client:
    grpc_client_config:
      max_recv_msg_size: 104857600
      max_send_msg_size: 16777216
      grpc_compression: ""
      rate_limit: 0
      rate_limit_burst: 0
      backoff_on_ratelimits: false
      backoff_config:
        min_period: 100ms
        max_period: 10s
        max_retries: 10
      tls_enabled: false
      tls_cert_path: ""
      tls_key_path: ""
      tls_ca_path: ""
      tls_server_name: ""
      tls_insecure_skip_verify: false
  configs:
  - name: default
    wal_truncate_frequency: 1h0m0s
    min_wal_time: 5m0s
    max_wal_time: 4h0m0s
    remote_flush_deadline: 1m0s
  - name: instance1
    scrape_configs:
    - job_name: instance1_job
      honor_timestamps: true
      scrape_interval: 1m
      scrape_timeout: 20s
      metrics_path: /metrics
      scheme: http
      follow_redirects: true
      static_configs:
      - targets:
        - localhost:4000
    wal_truncate_frequency: 1h0m0s
    min_wal_time: 5m0s
    max_wal_time: 4h0m0s
    remote_flush_deadline: 1m0s
  - name: instance2
    scrape_configs:
    - job_name: instance2_job
      honor_timestamps: true
      scrape_interval: 1m
      scrape_timeout: 20s
      metrics_path: /metrics
      scheme: http
      follow_redirects: true
      static_configs:
      - targets:
        - localhost:5555
    wal_truncate_frequency: 1h0m0s
    min_wal_time: 5m0s
    max_wal_time: 4h0m0s
    remote_flush_deadline: 1m0s
  instance_restart_backoff: 5s
  instance_mode: shared
integrations:
  metrics:
    autoscrape:
      enable: true
      metrics_instance: default
      scrape_interval: 1m
      scrape_timeout: 20s
  node_exporter:
    procfs_path: /proc
    sysfs_path: /sys
    rootfs_path: /
    diskstats_ignored_devices: ^(ram|loop|fd|(h|s|v|xv)d[a-z]|nvme\d+n\d+p)\d+$
    ethtool_metrics_include: .*
    filesystem_fs_types_exclude: ^(autofs|binfmt_misc|bpf|cgroup2?|configfs|debugfs|devpts|devtmpfs|fusectl|hugetlbfs|iso9660|mqueue|nsfs|overlay|proc|procfs|pstore|rpc_pipefs|securityfs|selinuxfs|squashfs|sysfs|tracefs)$
    filesystem_mount_points_exclude: ^/(dev|proc|run/credentials/.+|sys|var/lib/docker/.+)($|/)
    filesystem_mount_timeout: 5s
    ntp_ip_ttl: 1
    ntp_local_offset_tolerance: 1ms
    ntp_max_distance: 3.46608s
    ntp_protocol_version: 4
    ntp_server: 127.0.0.1
    netclass_ignored_devices: ^$
    netstat_fields: ^(.*_(InErrors|InErrs)|Ip_Forwarding|Ip(6|Ext)_(InOctets|OutOctets)|Icmp6?_(InMsgs|OutMsgs)|TcpExt_(Listen.*|Syncookies.*|TCPSynRetrans|TCPTimeouts)|Tcp_(ActiveOpens|InSegs|OutSegs|OutRsts|PassiveOpens|RetransSegs|CurrEstab)|Udp6?_(InDatagrams|OutDatagrams|NoPorts|RcvbufErrors|SndbufErrors))$
    powersupply_ignored_supplies: ^$
    runit_service_dir: /etc/service
    supervisord_url: http://localhost:9001/RPC2
    systemd_unit_exclude: .+\.(automount|device|mount|scope|slice)
    systemd_unit_include: .+
    tapestats_ignored_devices: ^$
    vmstat_fields: ^(oom_kill|pgpg|pswp|pg.*fault).*
  redis_configs:
  - autoscrape:
      metric_relabel_configs:
      - source_labels:
        - __address__
        separator: ;
        regex: (.*)
        target_label: banana
        replacement: apple
        action: replace
    include_exporter_metrics: false
    redis_addr: localhost:6379
    namespace: redis
    config_command: CONFIG
    check_key_groups_batch_size: 10000
    max_distinct_key_groups: 100
    connection_timeout: 15s
    set_client_name: true
  - include_exporter_metrics: false
    redis_addr: localhost:6380
    namespace: redis
    config_command: CONFIG
    check_key_groups_batch_size: 10000
    max_distinct_key_groups: 100
    connection_timeout: 15s
    set_client_name: true

'''
'''--- docs/sources/cookbook/dynamic-configuration/01_Basics/03_assets/integrations-node.yml ---
node_exporter: {}
'''
'''--- docs/sources/cookbook/dynamic-configuration/01_Basics/03_assets/integrations-redis.yml ---
redis_configs:
  - redis_addr: localhost:6379
    autoscrape:
      metric_relabel_configs:
        - source_labels: [__address__]
          target_label: "banana"
          replacement: "apple"
  - redis_addr: localhost:6380

'''
'''--- docs/sources/cookbook/dynamic-configuration/01_Basics/03_assets/metrics-1.yml ---
configs:
- name: default
global:
  scrape_interval: 60s
  scrape_timeout: 20s
wal_directory: /tmp/grafana-agent-wal
'''
'''--- docs/sources/cookbook/dynamic-configuration/01_Basics/03_assets/metrics_instances-1.yml ---
name: instance1
scrape_configs:
  - job_name: instance1_job
    static_configs:
      - targets:
          - localhost:4000
'''
'''--- docs/sources/cookbook/dynamic-configuration/01_Basics/03_assets/metrics_instances-2.yml ---
name: instance2
scrape_configs:
  - job_name: instance2_job
    static_configs:
      - targets:
          - localhost:5555
'''
'''--- docs/sources/cookbook/dynamic-configuration/01_Basics/03_assets/server-1.yml ---
log_level: info

'''
'''--- docs/sources/cookbook/dynamic-configuration/01_Basics/03_config.yml ---
template_paths:
  - "file:///etc/grafana/03_assets"
'''
'''--- docs/sources/cookbook/dynamic-configuration/01_Basics/04_Logs_and_Traces.md ---
---
aliases:
- /docs/agent/latest/dynamic-configuration/logs-traces
title: Logs and Traces
weight: 130
---
# 04 Logs and Traces

Logs and Traces can also be templated. This is built ontop of the previous examples.

`docker run -v ${PWD}/:/etc/grafana grafana/agentctl:latest template-parse file:///etc/grafana/04_config.yml`

## Dynamic Configuration

[config.yml](https://github.com/grafana/agent/blob/main/docs/sources/cookbook/dynamic-configuration/01_Basics/04_config.yml)

Tells the Grafana Agent where to load files from.

## Logs

Logs are loaded from a template matching `logs-*.yml`. There can ONLY be 1 template loaded

[logs-1.yml](https://github.com/grafana/agent/blob/main/docs/sources/cookbook/dynamic-configuration/01_Basics/04_assets/logs-1.yml)

```yaml
configs:
  - name: test_logs
    positions:
      filename: /tmp/positions.yaml
    scrape_configs:
      - job_name: test
        pipeline_stages:
          - regex:
            source: filename
            expression: '\\temp\\Logs\\(?P<log_app>.+?)\\'
```

[traces.yml](https://github.com/grafana/agent/blob/main/docs/sources/cookbook/dynamic-configuration/01_Basics/04_assets/traces-1.yml)

```yaml
configs:
  - name: test_traces
    automatic_logging:
      backend: stdout
      loki_name: default
      spans: true
```

## Final

[final.yml](https://github.com/grafana/agent/blob/main/docs/sources/cookbook/dynamic-configuration/01_Basics/04_assets/final.yml)

'''
'''--- docs/sources/cookbook/dynamic-configuration/01_Basics/04_assets/agent-1.yml ---
server:
  log_level: debug
metrics:
  wal_directory: /tmp/grafana-agent-normal
  global:
    scrape_interval: 60s
    remote_write:
      - url: https://prometheus-us-central1.grafana.net/api/prom/push
        basic_auth:
          username: xyz
          password: secretpassword
integrations:
  node_exporter: {}
  agent: {}

'''
'''--- docs/sources/cookbook/dynamic-configuration/01_Basics/04_assets/final.yml ---
server:
  http_tls_config:
    cert_file: ""
    key_file: ""
    client_auth_type: ""
    client_ca_file: ""
    cipher_suites: []
    curve_preferences: []
    min_version: 0
    max_version: 0
    prefer_server_cipher_suites: false
  grpc_tls_config:
    cert_file: ""
    key_file: ""
    client_auth_type: ""
    client_ca_file: ""
    cipher_suites: []
    curve_preferences: []
    min_version: 0
    max_version: 0
    prefer_server_cipher_suites: false
  log_format: ""
  log_level: info
metrics:
  global:
    scrape_interval: 1m
    scrape_timeout: 20s
    evaluation_interval: 1m
  wal_directory: /tmp/grafana-agent-wal
  wal_cleanup_age: 12h0m0s
  wal_cleanup_period: 30m0s
  scraping_service:
    enabled: false
    reshard_interval: 1m0s
    reshard_timeout: 30s
    cluster_reshard_event_timeout: 30s
    kvstore:
      store: consul
      prefix: configurations/
      consul:
        host: localhost:8500
        acl_token: <secret>
        http_client_timeout: 20s
        consistent_reads: false
        watch_rate_limit: 1
        watch_burst_size: 1
      etcd:
        endpoints: []
        dial_timeout: 10s
        max_retries: 10
        tls_enabled: false
        tls_cert_path: ""
        tls_key_path: ""
        tls_ca_path: ""
        tls_server_name: ""
        tls_insecure_skip_verify: false
        username: ""
        password: <secret>
      multi:
        primary: ""
        secondary: ""
        mirror_enabled: false
        mirror_timeout: 2s
    lifecycler:
      ring:
        kvstore:
          store: consul
          prefix: collectors/
          consul:
            host: localhost:8500
            acl_token: <secret>
            http_client_timeout: 20s
            consistent_reads: false
            watch_rate_limit: 1
            watch_burst_size: 1
          etcd:
            endpoints: []
            dial_timeout: 10s
            max_retries: 10
            tls_enabled: false
            tls_cert_path: ""
            tls_key_path: ""
            tls_ca_path: ""
            tls_server_name: ""
            tls_insecure_skip_verify: false
            username: ""
            password: <secret>
          multi:
            primary: ""
            secondary: ""
            mirror_enabled: false
            mirror_timeout: 2s
        heartbeat_timeout: 1m0s
        replication_factor: 3
        zone_awareness_enabled: false
      num_tokens: 128
      heartbeat_period: 5s
      observe_period: 0s
      join_after: 0s
      min_ready_duration: 1m0s
      interface_names:
      - eth0
      - en0
      final_sleep: 30s
      tokens_file_path: ""
      availability_zone: ""
      unregister_on_shutdown: true
      address: ""
      port: 0
      id: 2555e70c377f
    dangerous_allow_reading_files: false
  scraping_service_client:
    grpc_client_config:
      max_recv_msg_size: 104857600
      max_send_msg_size: 16777216
      grpc_compression: ""
      rate_limit: 0
      rate_limit_burst: 0
      backoff_on_ratelimits: false
      backoff_config:
        min_period: 100ms
        max_period: 10s
        max_retries: 10
      tls_enabled: false
      tls_cert_path: ""
      tls_key_path: ""
      tls_ca_path: ""
      tls_server_name: ""
      tls_insecure_skip_verify: false
  configs:
  - name: default
    wal_truncate_frequency: 1h0m0s
    min_wal_time: 5m0s
    max_wal_time: 4h0m0s
    remote_flush_deadline: 1m0s
  - name: instance1
    scrape_configs:
    - job_name: instance1_job
      honor_timestamps: true
      scrape_interval: 1m
      scrape_timeout: 20s
      metrics_path: /metrics
      scheme: http
      follow_redirects: true
      static_configs:
      - targets:
        - localhost:4000
    wal_truncate_frequency: 1h0m0s
    min_wal_time: 5m0s
    max_wal_time: 4h0m0s
    remote_flush_deadline: 1m0s
  - name: instance2
    scrape_configs:
    - job_name: instance2_job
      honor_timestamps: true
      scrape_interval: 1m
      scrape_timeout: 20s
      metrics_path: /metrics
      scheme: http
      follow_redirects: true
      static_configs:
      - targets:
        - localhost:5555
    wal_truncate_frequency: 1h0m0s
    min_wal_time: 5m0s
    max_wal_time: 4h0m0s
    remote_flush_deadline: 1m0s
  instance_restart_backoff: 5s
  instance_mode: shared
integrations:
  metrics:
    autoscrape:
      enable: true
      metrics_instance: default
      scrape_interval: 1m
      scrape_timeout: 20s
  redis_configs:
  - autoscrape:
      metric_relabel_configs:
      - source_labels:
        - __address__
        separator: ;
        regex: (.*)
        target_label: banana
        replacement: apple
        action: replace
    include_exporter_metrics: false
    redis_addr: localhost:6379
    namespace: redis
    config_command: CONFIG
    check_key_groups_batch_size: 10000
    max_distinct_key_groups: 100
    connection_timeout: 15s
    set_client_name: true
  - include_exporter_metrics: false
    redis_addr: localhost:6380
    namespace: redis
    config_command: CONFIG
    check_key_groups_batch_size: 10000
    max_distinct_key_groups: 100
    connection_timeout: 15s
    set_client_name: true
  node_exporter:
    procfs_path: /proc
    sysfs_path: /sys
    rootfs_path: /
    diskstats_ignored_devices: ^(ram|loop|fd|(h|s|v|xv)d[a-z]|nvme\d+n\d+p)\d+$
    ethtool_metrics_include: .*
    filesystem_fs_types_exclude: ^(autofs|binfmt_misc|bpf|cgroup2?|configfs|debugfs|devpts|devtmpfs|fusectl|hugetlbfs|iso9660|mqueue|nsfs|overlay|proc|procfs|pstore|rpc_pipefs|securityfs|selinuxfs|squashfs|sysfs|tracefs)$
    filesystem_mount_points_exclude: ^/(dev|proc|run/credentials/.+|sys|var/lib/docker/.+)($|/)
    filesystem_mount_timeout: 5s
    ntp_ip_ttl: 1
    ntp_local_offset_tolerance: 1ms
    ntp_max_distance: 3.46608s
    ntp_protocol_version: 4
    ntp_server: 127.0.0.1
    netclass_ignored_devices: ^$
    netstat_fields: ^(.*_(InErrors|InErrs)|Ip_Forwarding|Ip(6|Ext)_(InOctets|OutOctets)|Icmp6?_(InMsgs|OutMsgs)|TcpExt_(Listen.*|Syncookies.*|TCPSynRetrans|TCPTimeouts)|Tcp_(ActiveOpens|InSegs|OutSegs|OutRsts|PassiveOpens|RetransSegs|CurrEstab)|Udp6?_(InDatagrams|OutDatagrams|NoPorts|RcvbufErrors|SndbufErrors))$
    powersupply_ignored_supplies: ^$
    runit_servic e_dir: /etc/service
    supervisord_url: http://localhost:9001/RPC2
    systemd_unit_exclude: .+\.(automount|device|mount|scope|slice)
    systemd_unit_include: .+
    tapestats_ignored_devices: ^$
    vmstat_fields: ^(oom_kill|pgpg|pswp|pg.*fault).*
traces:
  configs:
  - name: test_traces
    automatic_logging:
      backend: stdout
      logs_instance_name: default
      spans: true
    load_balancing: null
logs:
  configs:
  - name: test_logs
    positions:
      sync_period: 10s
      filename: /tmp/positions.yaml
      ignore_invalid_yaml: false
    scrape_configs:
    - job_name: test
      pipeline_stages:
      - expression: \\temp\\Logs\\(?P<log_app>.+?)\\
        regex: null
        source: filename
      static_configs: []
    target_config:
      sync_period: 10s
      stdin: false

'''
'''--- docs/sources/cookbook/dynamic-configuration/01_Basics/04_assets/integrations-node.yml ---
node_exporter: {}
'''
'''--- docs/sources/cookbook/dynamic-configuration/01_Basics/04_assets/integrations-redis.yml ---
redis_configs:
  - redis_addr: localhost:6379
    autoscrape:
      metric_relabel_configs:
        - source_labels: [__address__]
          target_label: "banana"
          replacement: "apple"
  - redis_addr: localhost:6380

'''
'''--- docs/sources/cookbook/dynamic-configuration/01_Basics/04_assets/logs-1.yml ---
configs:
  - name: test_logs
    positions:
      filename: /tmp/positions.yaml
    scrape_configs:
      - job_name: test
        pipeline_stages:
          - regex:
            source: filename
            expression: '\\temp\\Logs\\(?P<log_app>.+?)\\'
'''
'''--- docs/sources/cookbook/dynamic-configuration/01_Basics/04_assets/metrics-1.yml ---
configs:
- name: default
global:
  scrape_interval: 60s
  scrape_timeout: 20s
wal_directory: /tmp/grafana-agent-wal
'''
'''--- docs/sources/cookbook/dynamic-configuration/01_Basics/04_assets/metrics_instances-1.yml ---
name: instance1
scrape_configs:
  - job_name: instance1_job
    static_configs:
      - targets:
          - localhost:4000
'''
'''--- docs/sources/cookbook/dynamic-configuration/01_Basics/04_assets/metrics_instances-2.yml ---
name: instance2
scrape_configs:
  - job_name: instance2_job
    static_configs:
      - targets:
          - localhost:5555
'''
'''--- docs/sources/cookbook/dynamic-configuration/01_Basics/04_assets/server-1.yml ---
log_level: info

'''
'''--- docs/sources/cookbook/dynamic-configuration/01_Basics/04_assets/traces-1.yml ---
configs:
  - name: test_traces
    automatic_logging:
      backend: stdout
      loki_name: default
      spans: true
'''
'''--- docs/sources/cookbook/dynamic-configuration/01_Basics/04_config.yml ---
template_paths:
  - "file:///etc/grafana/04_assets"
'''
'''--- docs/sources/cookbook/dynamic-configuration/02_Templates/01_Looping.md ---
---
aliases:
- /docs/agent/latest/dynamic-configuration/looping
title: Looping
weight: 200
---

# 01 Basics of Templating

The templating is based on the excellent [gomplate](https://docs.gomplate.ca/) library. Currently using a custom fork to allow loading gomplate as a library in addition to some new commands. This will NOT try to cover the full range of gomplate, would recommend reading the documentation for full knowledge.

`docker run -v ${PWD}/:/etc/grafana grafana/agentctl:latest template-parse file:///etc/grafana/01_config.yml`

## Looping

[agent-1.yml](https://github.com/grafana/agent/blob/main/docs/sources/cookbook/dynamic-configuration/02_Templates/01_assets/agent-1.yml)

```yaml
server:
  log_level: debug
metrics:
  wal_directory: /tmp/grafana-agent-normal
  global:
    scrape_interval: 60s
    remote_write:
      - url: https://prometheus-us-central1.grafana.net/api/prom/push
        basic_auth:
          username: xyz
          password: secretpassword
  configs:
    - name: default
  {{ range slice "apple" "banana" "pear" }}
    - name: {{ . }}
  {{ end }}
```

The templating engine uses directives that are wrapped in `{{ command }}`, in the above the dynamic configuration engine will loop over the three values, and those values can be accessed by `{{ . }}` which means current value.

## Final

[final.yml](https://github.com/grafana/agent/blob/main/docs/sources/cookbook/dynamic-configuration/02_Templates/01_assets/final.yml)

The final.yml contains 4 prometheus configs

- default
- apple
- banana
- pear

'''
'''--- docs/sources/cookbook/dynamic-configuration/02_Templates/01_assets/agent-1.yml ---
server:
  log_level: debug
metrics:
  wal_directory: /tmp/grafana-agent-normal
  global:
    scrape_interval: 60s
    remote_write:
      - url: https://prometheus-us-central1.grafana.net/api/prom/push
        basic_auth:
          username: xyz
          password: secretpassword
  configs:
    - name: default
  {{ range slice "apple" "banana" "pear" }}
    - name: {{ . }}
  {{ end }}

'''
'''--- docs/sources/cookbook/dynamic-configuration/02_Templates/01_assets/final.yml ---
server:
  http_tls_config:
    cert_file: ""
    key_file: ""
    client_auth_type: ""
    client_ca_file: ""
    cipher_suites: []
    curve_preferences: []
    min_version: 0
    max_version: 0
    prefer_server_cipher_suites: false
  grpc_tls_config:
    cert_file: ""
    key_file: ""
    client_auth_type: ""
    client_ca_file: ""
    cipher_suites: []
    curve_preferences: []
    min_version: 0
    max_version: 0
    prefer_server_cipher_suites: false
  log_format: logfmt
  log_level: debug
metrics:
  global:
    scrape_interval: 1m
    scrape_timeout: 10s
    evaluation_interval: 1m
    remote_write:
    - url: https://prometheus-us-central1.grafana.net/api/prom/push
      remote_timeout: 30s
      name: default-a098e3
      basic_auth:
        username: "xyz"
        password: <secret>
      follow_redirects: true
      queue_config:
        capacity: 2500
        max_shards: 200
        min_shards: 1
        max_samples_per_send: 500
        batch_send_deadline: 5s
        min_backoff: 30ms
        max_backoff: 100ms
      metadata_config:
        send: true
        send_interval: 1m
        max_samples_per_send: 500
  wal_directory: /tmp/grafana-agent-normal
  wal_cleanup_age: 12h0m0s
  wal_cleanup_period: 30m0s
  scraping_service:
    enabled: false
    reshard_interval: 1m0s
    reshard_timeout: 30s
    cluster_reshard_event_timeout: 30s
    kvstore:
      store: consul
      prefix: configurations/
      consul:
        host: localhost:8500
        acl_token: <secret>
        http_client_timeout: 20s
        consistent_reads: false
        watch_rate_limit: 1
        watch_burst_size: 1
      etcd:
        endpoints: []
        dial_timeout: 10s
        max_retries: 10
        tls_enabled: false
        tls_cert_path: ""
        tls_key_path: ""
        tls_ca_path: ""
        tls_server_name: ""
        tls_insecure_skip_verify: false
        username: ""
        password: <secret>
      multi:
        primary: ""
        secondary: ""
        mirror_enabled: false
        mirror_timeout: 2s
    lifecycler:
      ring:
        kvstore:
          store: consul
          prefix: collectors/
          consul:
            host: localhost:8500
            acl_token: <secret>
            http_client_timeout: 20s
            consistent_reads: false
            watch_rate_limit: 1
            watch_burst_size: 1
          etcd:
            endpoints: []
            dial_timeout: 10s
            max_retries: 10
            tls_enabled: false
            tls_cert_path: ""
            tls_key_path: ""
            tls_ca_path: ""
            tls_server_name: ""
            tls_insecure_skip_verify: false
            username: ""
            password: <secret>
          multi:
            primary: ""
            secondary: ""
            mirror_enabled: false
            mirror_timeout: 2s
        heartbeat_timeout: 1m0s
        replication_factor: 3
        zone_awareness_enabled: false
      num_tokens: 128
      heartbeat_period: 5s
      observe_period: 0s
      join_after: 0s
      min_ready_duration: 1m0s
      interface_names:
      - eth0
      - en0
      final_sleep: 30s
      tokens_file_path: ""
      availability_zone: ""
      unregister_on_shutdown: true
      address: ""
      port: 0
      id: 4d5f79f1dd4d
    dangerous_allow_reading_files: false
  scraping_service_client:
    grpc_client_config:
      max_recv_msg_size: 104857600
      max_send_msg_size: 16777216
      grpc_compression: ""
      rate_limit: 0
      rate_limit_burst: 0
      backoff_on_ratelimits: false
      backoff_config:
        min_period: 100ms
        max_period: 10s
        max_retries: 10
      tls_enabled: false
      tls_cert_path: ""
      tls_key_path: ""
      tls_ca_path: ""
      tls_server_name: ""
      tls_insecure_skip_verify: false
  configs:
  - name: default
    remote_write:
    - url: https://prometheus-us-central1.grafana.net/api/prom/push
      remote_timeout: 30s
      name: default-a098e3
      basic_auth:
        username: "xyz"
        password: <secret>
      follow_redirects: true
      queue_config:
        capacity: 2500
        max_shards: 200
        min_shards: 1
        max_samples_per_send: 500
        batch_send_deadline: 5s
        min_backoff: 30ms
        max_backoff: 100ms
      metadata_config:
        send: true
        send_interval: 1m
        max_samples_per_send: 500
    wal_truncate_frequency: 1h0m0s
    min_wal_time: 5m0s
    max_wal_time: 4h0m0s
    remote_flush_deadline: 1m0s
  - name: apple
    remote_write:
    - url: https://prometheus-us-central1.grafana.net/api/prom/push
      remote_timeout: 30s
      name: default-a098e3
      basic_auth:
        username: "xyz"
        password: <secret>
      follow_redirects: true
      queue_config:
        capacity: 2500
        max_shards: 200
        min_shards: 1
        max_samples_per_send: 500
        batch_send_deadline: 5s
        min_backoff: 30ms
        max_backoff: 100ms
      metadata_config:
        send: true
        send_interval: 1m
        max_samples_per_send: 500
    wal_truncate_frequency: 1h0m0s
    min_wal_time: 5m0s
    max_wal_time: 4h0m0s
    remote_flush_deadline: 1m0s
  - name: banana
    remote_write:
    - url: https://prometheus-us-central1.grafana.net/api/prom/push
      remote_timeout: 30s
      name: default-a098e3
      basic_auth:
        username: "xyz"
        password: <secret>
      follow_redirects: true
      queue_config:
        capacity: 2500
        max_shards: 200
        min_shards: 1
        max_samples_per_send: 500
        batch_send_deadline: 5s
        min_backoff: 30ms
        max_backoff: 100ms
      metadata_config:
        send: true
        send_interval: 1m
        max_samples_per_send: 500
    wal_truncate_frequency: 1h0m0s
    min_wal_time: 5m0s
    max_wal_time: 4h0m0s
    remote_flush_deadline: 1m0s
  - name: pear
    remote_write:
    - url: https://prometheus-us-central1.grafana.net/api/prom/push
      remote_timeout: 30s
      name: default-a098e3
      basic_auth:
        username: "xyz"
        password: <secret>
      follow_redirects: true
      queue_config:
        capacity: 2500
        max_shards: 200
        min_shards: 1
        max_samples_per_send: 500
        batch_send_deadline: 5s
        min_backoff: 30ms
        max_backoff: 100ms
      metadata_config:
        send: true
        send_interval: 1m
        max_samples_per_send: 500
    wal_truncate_frequency: 1h0m0s
    min_wal_time: 5m0s
    max_wal_time: 4h0m0s
    remote_flush_deadline: 1m0s
  instance_restart_backoff: 5s
  instance_mode: shared
integrations:
  scrape_integrations: true
  integration_restart_backoff: 5s
  replace_instance_label: true
  use_hostname_label: true

'''
'''--- docs/sources/cookbook/dynamic-configuration/02_Templates/01_config.yml ---
template_paths:
  - "file:///etc/grafana/01_assets"
'''
'''--- docs/sources/cookbook/dynamic-configuration/02_Templates/02_Datasources.md ---
---
aliases:
- /docs/agent/latest/dynamic-configuration/datasources
title: Datasources
weight: 210
---

# 02 Datasources

Datasources are a powerful concept in gomplate. They allow you to reach out to other files, systems and resources to pull data.

`docker run -v ${PWD}/:/etc/grafana grafana/agentctl:latest template-parse file:///etc/grafana/02_config.yml`

## Config

The [config.yml](https://github.com/grafana/agent/blob/main/docs/sources/cookbook/dynamic-configuration/02_Templates/02_config.yml) adds a new field `sources`. Sources can be any number of things defined in the gomplate [datasources](https://docs.gomplate.ca/datasources/) documentation. In this example using fruit.

```yaml
template_paths:
  - "file:///etc/grafana/01_assets"
datasources:
  - name: fruit
    url: "file://etc/grafana/01_assets/fruit.json"
```

[fruit.json](https://github.com/grafana/agent/blob/main/docs/sources/cookbook/dynamic-configuration/02_Templates/02_assets/fruit.json)

```json
["mango","peach","orange"]
```

## Usage

[agent-1.yml](https://github.com/grafana/agent/blob/main/docs/sources/cookbook/dynamic-configuration/02_Templates/02_assets/agent-1.yml)

```yaml
server:
  log_level: debug
metrics:
  wal_directory: /tmp/grafana-agent-normal
  global:
    scrape_interval: 60s
    remote_write:
      - url: https://prometheus-us-central1.grafana.net/api/prom/push
        basic_auth:
          username: xyz
          password: secretpassword
  configs:
    - name: default
  {{ range (datasource "fruit") }}
    - name: {{ . }}
  {{ end }}
```

A Datasource is reference by name and in this case it is an array and used exactly like the looping example.

'''
'''--- docs/sources/cookbook/dynamic-configuration/02_Templates/02_assets/agent-1.yml ---
server:
  log_level: debug
metrics:
  wal_directory: /tmp/grafana-agent-normal
  global:
    scrape_interval: 60s
    remote_write:
      - url: https://prometheus-us-central1.grafana.net/api/prom/push
        basic_auth:
          username: xyz
          password: secretpassword
  configs:
    - name: default
  {{ range (datasource "fruit") }}
    - name: {{ . }}
  {{ end }}

'''
'''--- docs/sources/cookbook/dynamic-configuration/02_Templates/02_assets/final.yml ---
server:
  http_tls_config:
    cert_file: ""
    key_file: ""
    client_auth_type: ""
    client_ca_file: ""
    cipher_suites: []
    curve_preferences: []
    min_version: 0
    max_version: 0
    prefer_server_cipher_suites: false
  grpc_tls_config:
    cert_file: ""
    key_file: ""
    client_auth_type: ""
    client_ca_file: ""
    cipher_suites: []
    curve_preferences: []
    min_version: 0
    max_version: 0
    prefer_server_cipher_suites: false
  log_format: logfmt
  log_level: debug
metrics:
  global:
    scrape_interval: 1m
    scrape_timeout: 10s
    evaluation_interval: 1m
    remote_write:
    - url: https://prometheus-us-central1.grafana.net/api/prom/push
      remote_timeout: 30s
      name: default-a098e3
      basic_auth:
        username: "xyz"
        password: <secret>
      follow_redirects: true
      queue_config:
        capacity: 2500
        max_shards: 200
        min_shards: 1
        max_samples_per_send: 500
        batch_send_deadline: 5s
        min_backoff: 30ms
        max_backoff: 100ms
      metadata_config:
        send: true
        send_interval: 1m
        max_samples_per_send: 500
  wal_directory: /tmp/grafana-agent-normal
  wal_cleanup_age: 12h0m0s
  wal_cleanup_period: 30m0s
  scraping_service:
    enabled: false
    reshard_interval: 1m0s
    reshard_timeout: 30s
    cluster_reshard_event_timeout: 30s
    kvstore:
      store: consul
      prefix: configurations/
      consul:
        host: localhost:8500
        acl_token: <secret>
        http_client_timeout: 20s
        consistent_reads: false
        watch_rate_limit: 1
        watch_burst_size: 1
      etcd:
        endpoints: []
        dial_timeout: 10s
        max_retries: 10
        tls_enabled: false
        tls_cert_path: ""
        tls_key_path: ""
        tls_ca_path: ""
        tls_server_name: ""
        tls_insecure_skip_verify: false
        username: ""
        password: <secret>
      multi:
        primary: ""
        secondary: ""
        mirror_enabled: false
        mirror_timeout: 2s
    lifecycler:
      ring:
        kvstore:
          store: consul
          prefix: collectors/
          consul:
            host: localhost:8500
            acl_token: <secret>
            http_client_timeout: 20s
            consistent_reads: false
            watch_rate_limit: 1
            watch_burst_size: 1
          etcd:
            endpoints: []
            dial_timeout: 10s
            max_retries: 10
            tls_enabled: false
            tls_cert_path: ""
            tls_key_path: ""
            tls_ca_path: ""
            tls_server_name: ""
            tls_insecure_skip_verify: false
            username: ""
            password: <secret>
          multi:
            primary: ""
            secondary: ""
            mirror_enabled: false
            mirror_timeout: 2s
        heartbeat_timeout: 1m0s
        replication_factor: 3
        zone_awareness_enabled: false
      num_tokens: 128
      heartbeat_period: 5s
      observe_period: 0s
      join_after: 0s
      min_ready_duration: 1m0s
      interface_names:
      - eth0
      - en0
      final_sleep: 30s
      tokens_file_path: ""
      availability_zone: ""
      unregister_on_shutdown: true
      address: ""
      port: 0
      id: 7fdd8f46a28a
    dangerous_allow_reading_files: false
  scraping_service_client:
    grpc_client_config:
      max_recv_msg_size: 104857600
      max_send_msg_size: 16777216
      grpc_compression: ""
      rate_limit: 0
      rate_limit_burst: 0
      backoff_on_ratelimits: false
      backoff_config:
        min_period: 100ms
        max_period: 10s
        max_retries: 10
      tls_enabled: false
      tls_cert_path: ""
      tls_key_path: ""
      tls_ca_path: ""
      tls_server_name: ""
      tls_insecure_skip_verify: false
  configs:
  - name: default
    remote_write:
    - url: https://prometheus-us-central1.grafana.net/api/prom/push
      remote_timeout: 30s
      name: default-a098e3
      basic_auth:
        username: "xyz"
        password: <secret>
      follow_redirects: true
      queue_config:
        capacity: 2500
        max_shards: 200
        min_shards: 1
        max_samples_per_send: 500
        batch_send_deadline: 5s
        min_backoff: 30ms
        max_backoff: 100ms
      metadata_config:
        send: true
        send_interval: 1m
        max_samples_per_send: 500
    wal_truncate_frequency: 1h0m0s
    min_wal_time: 5m0s
    max_wal_time: 4h0m0s
    remote_flush_deadline: 1m0s
  - name: mango
    remote_write:
    - url: https://prometheus-us-central1.grafana.net/api/prom/push
      remote_timeout: 30s
      name: default-a098e3
      basic_auth:
        username: "xyz"
        password: <secret>
      follow_redirects: true
      queue_config:
        capacity: 2500
        max_shards: 200
        min_shards: 1
        max_samples_per_send: 500
        batch_send_deadline: 5s
        min_backoff: 30ms
        max_backoff: 100ms
      metadata_config:
        send: true
        send_interval: 1m
        max_samples_per_send: 500
    wal_truncate_frequency: 1h0m0s
    min_wal_time: 5m0s
    max_wal_time: 4h0m0s
    remote_flush_deadline: 1m0s
  - name: peach
    remote_write:
    - url: https://prometheus-us-central1.grafana.net/api/prom/push
      remote_timeout: 30s
      name: default-a098e3
      basic_auth:
        username: "xyz"
        password: <secret>
      follow_redirects: true
      queue_config:
        capacity: 2500
        max_shards: 200
        min_shards: 1
        max_samples_per_send: 500
        batch_send_deadline: 5s
        min_backoff: 30ms
        max_backoff: 100ms
      metadata_config:
        send: true
        send_interval: 1m
        max_samples_per_send: 500
    wal_truncate_frequency: 1h0m0s
    min_wal_time: 5m0s
    max_wal_time: 4h0m0s
    remote_flush_deadline: 1m0s
  - name: orange
    remote_write:
    - url: https://prometheus-us-central1.grafana.net/api/prom/push
      remote_timeout: 30s
      name: default-a098e3
      basic_auth:
        username: "xyz"
        password: <secret>
      follow_redirects: true
      queue_config:
        capacity: 2500
        max_shards: 200
        min_shards: 1
        max_samples_per_send: 500
        batch_send_deadline: 5s
        min_backoff: 30ms
        max_backoff: 100ms
      metadata_config:
        send: true
        send_interval: 1m
        max_samples_per_send: 500
    wal_truncate_frequency: 1h0m0s
    min_wal_time: 5m0s
    max_wal_time: 4h0m0s
    remote_flush_deadline: 1m0s
  instance_restart_backoff: 5s
  instance_mode: shared
integrations:
  scrape_integrations: true
  integration_restart_backoff: 5s
  replace_instance_label: true
  use_hostname_label: true

'''
'''--- docs/sources/cookbook/dynamic-configuration/02_Templates/02_assets/fruit.json ---
["mango","peach","orange"]
'''
'''--- docs/sources/cookbook/dynamic-configuration/02_Templates/02_config.yml ---
template_paths:
  - "file:///etc/grafana/02_assets"
sources:
  - name: fruit
    url: "file:///etc/grafana/02_assets/fruit.json"
'''
'''--- docs/sources/cookbook/dynamic-configuration/02_Templates/03_Datasource_and_Objects.md ---
---
aliases:
- /docs/agent/latest/dynamic-configuration/objects
title: Objects
weight: 220
---

# 02 Datasources

Datasources can also access objects.

`docker run -v ${PWD}/:/etc/grafana grafana/agentctl:latest template-parse file:///etc/grafana/03_config.yml`

## Config

The [config.yml](https://github.com/grafana/agent/blob/main/docs/sources/cookbook/dynamic-configuration/02_Templates/02_config.yml) adds a new field `sources`. Sources can be any number of things defined in the gomplate [datasources](https://docs.gomplate.ca/datasources/) documentation. In this example using fruit.

```yaml
template_paths:
  - "file:///etc/grafana/03_assets"
datasources:
  - name: computers
    url: "file:///etc/grafana/03_assets/computers.json"
```

[computers.json](https://github.com/grafana/agent/blob/main/docs/sources/cookbook/dynamic-configuration/02_Templates/03_assets/computers.json)

```json
[
  {
    "name": "webhost1",
    "ip" : "192.168.1.1",
    "enabled": true
  },
  {
    "name": "webhost2",
    "ip" : "192.168.1.2",
    "enabled": false

  },
  {
    "name": "webhost3",
    "ip" : "192.168.1.3",
    "enabled": true
  }
]
```

## Usage

[agent-1.yml](https://github.com/grafana/agent/blob/main/docs/sources/cookbook/dynamic-configuration/02_Templates/02_assets/agent-1.yml)

```yaml
server:
  log_level: debug
metrics:
  wal_directory: /tmp/grafana-agent-normal
  global:
    scrape_interval: 60s
    remote_write:
      - url: https://prometheus-us-central1.grafana.net/api/prom/push
        basic_auth:
          username: xyz
          password: secretpassword
  configs:
    - name: default
      # Check for length so that if it is 0, we dont write any scrape configs
  {{ if $length := len (datasource "computers") }}
  {{ if gt $length 0 }}
  scrape_configs:
  {{ end }}
  {{ end }}
  {{ range (datasource "computers") }}
  # Only add if the computers are enabled
  # the . references our current object
  {{ if eq .enabled true }}
  - job_name: {{ .name }}
    static_configs:
      - targets:
          - {{ .ip }}
  {{ end }}
  {{ end }}
```

This is a much more complex example, in the above we are doing:

- comparisons
- creating and setting variables
- looping over objects

The final output will only list `webhost1` and `webhost3` since `webhost2` is not enabled.

'''
'''--- docs/sources/cookbook/dynamic-configuration/02_Templates/03_assets/agent-1.yml ---
server:
  log_level: debug
metrics:
  wal_directory: /tmp/grafana-agent-normal
  global:
    scrape_interval: 60s
    remote_write:
      - url: https://prometheus-us-central1.grafana.net/api/prom/push
        basic_auth:
          username: xyz
          password: secretpassword
  configs:
    - name: default
      # Check for length so that if it is 0, we dont write any scrape configs
  {{ if $length := len (datasource "computers") }}
  {{ if gt $length 0 }}
      scrape_configs:
  {{ end }}
  {{ end }}
  {{ range (datasource "computers") }}
    # Only add if the computers are enabled
    # the . references our current object
    {{ if eq .enabled true }}
        - job_name: {{ .name }}
          static_configs:
            - targets:
                - {{ .ip }}
    {{ end }}
  {{ end }}

'''
'''--- docs/sources/cookbook/dynamic-configuration/02_Templates/03_assets/computers.json ---
[
  {
    "name": "webhost1",
    "ip" : "192.168.1.1",
    "enabled": true
  },
  {
    "name": "webhost2",
    "ip" : "192.168.1.2",
    "enabled": false

  },
  {
    "name": "webhost3",
    "ip" : "192.168.1.3",
    "enabled": true
  }
]
'''
'''--- docs/sources/cookbook/dynamic-configuration/02_Templates/03_assets/final.yml ---
server:
  http_tls_config:
    cert_file: ""
    key_file: ""
    client_auth_type: ""
    client_ca_file: ""
    cipher_suites: []
    curve_preferences: []
    min_version: 0
    max_version: 0
    prefer_server_cipher_suites: false
  grpc_tls_config:
    cert_file: ""
    key_file: ""
    client_auth_type: ""
    client_ca_file: ""
    cipher_suites: []
    curve_preferences: []
    min_version: 0
    max_version: 0
    prefer_server_cipher_suites: false
  log_format: logfmt
  log_level: debug
metrics:
  global:
    scrape_interval: 1m
    scrape_timeout: 10s
    evaluation_interval: 1m
    remote_write:
    - url: https://prometheus-us-central1.grafana.net/api/prom/push
      remote_timeout: 30s
      name: default-a098e3
      basic_auth:
        username: "xyz"
        password: <secret>
      follow_redirects: true
      queue_config:
        capacity: 2500
        max_shards: 200
        min_shards: 1
        max_samples_per_send: 500
        batch_send_deadline: 5s
        min_backoff: 30ms
        max_backoff: 100ms
      metadata_config:
        send: true
        send_interval: 1m
        max_samples_per_send: 500
  wal_directory: /tmp/grafana-agent-normal
  wal_cleanup_age: 12h0m0s
  wal_cleanup_period: 30m0s
  scraping_service:
    enabled: false
    reshard_interval: 1m0s
    reshard_timeout: 30s
    cluster_reshard_event_timeout: 30s
    kvstore:
      store: consul
      prefix: configurations/
      consul:
        host: localhost:8500
        acl_token: <secret>
        http_client_timeout: 20s
        consistent_reads: false
        watch_rate_limit: 1
        watch_burst_size: 1
      etcd:
        endpoints: []
        dial_timeout: 10s
        max_retries: 10
        tls_enabled: false
        tls_cert_path: ""
        tls_key_path: ""
        tls_ca_path: ""
        tls_server_name: ""
        tls_insecure_skip_verify: false
        username: ""
        password: <secret>
      multi:
        primary: ""
        secondary: ""
        mirror_enabled: false
        mirror_timeout: 2s
    lifecycler:
      ring:
        kvstore:
          store: consul
          prefix: collectors/
          consul:
            host: localhost:8500
            acl_token: <secret>
            http_client_timeout: 20s
            consistent_reads: false
            watch_rate_limit: 1
            watch_burst_size: 1
          etcd:
            endpoints: []
            dial_timeout: 10s
            max_retries: 10
            tls_enabled: false
            tls_cert_path: ""
            tls_key_path: ""
            tls_ca_path: ""
            tls_server_name: ""
            tls_insecure_skip_verify: false
            username: ""
            password: <secret>
          multi:
            primary: ""
            secondary: ""
            mirror_enabled: false
            mirror_timeout: 2s
        heartbeat_timeout: 1m0s
        replication_factor: 3
        zone_awareness_enabled: false
      num_tokens: 128
      heartbeat_period: 5s
      observe_period: 0s
      join_after: 0s
      min_ready_duration: 1m0s
      interface_names:
      - eth0
      - en0
      final_sleep: 30s
      tokens_file_path: ""
      availability_zone: ""
      unregister_on_shutdown: true
      address: ""
      port: 0
      id: 7538ea8d493e
    dangerous_allow_reading_files: false
  scraping_service_client:
    grpc_client_config:
      max_recv_msg_size: 104857600
      max_send_msg_size: 16777216
      grpc_compression: ""
      rate_limit: 0
      rate_limit_burst: 0
      backoff_on_ratelimits: false
      backoff_config:
        min_period: 100ms
        max_period: 10s
        max_retries: 10
      tls_enabled: false
      tls_cert_path: ""
      tls_key_path: ""
      tls_ca_path: ""
      tls_server_name: ""
      tls_insecure_skip_verify: false
  configs:
  - name: default
    scrape_configs:
    - job_name: webhost1
      honor_timestamps: true
      scrape_interval: 1m
      scrape_timeout: 10s
      metrics_path: /metrics
      scheme: http
      follow_redirects: true
      static_configs:
      - targets:
        - 192.168.1.1
    - job_name: webhost3
      honor_timestamps: true
      scrape_interval: 1m
      scrape_timeout: 10s
      metrics_path: /metrics
      scheme: http
      follow_redirects: true
      static_configs:
      - targets:
        - 192.168.1.3
    remote_write:
    - url: https://prometheus-us-central1.grafana.net/api/prom/push
      remote_timeout: 30s
      name: default-a098e3
      basic_auth:
        username: "xyz"
        password: <secret>
      follow_redirects: true
      queue_config:
        capacity: 2500
        max_shards: 200
        min_shards: 1
        max_samples_per_send: 500
        batch_send_deadline: 5s
        min_backoff: 30ms
        max_backoff: 100ms
      metadata_config:
        send: true
        send_interval: 1m
        max_samples_per_send: 500
    wal_truncate_frequency: 1h0m0s
    min_wal_time: 5m0s
    max_wal_time: 4h0m0s
    remote_flush_deadline: 1m0s
  instance_restart_backoff: 5s
  instance_mode: shared
integrations:
  scrape_integrations: true
  integration_restart_backoff: 5s
  replace_instance_label: true
  use_hostname_label: true

'''
'''--- docs/sources/cookbook/dynamic-configuration/02_Templates/03_config.yml ---
template_paths:
  - "file:///etc/grafana/03_assets"
datasources:
  - name: computers
    url: "file:///etc/grafana/03_assets/computers.json"
'''
'''--- docs/sources/cookbook/dynamic-configuration/03_Advanced_Datasources/01_AWS.md ---
---
aliases:
- /docs/agent/latest/dynamic-configuration/aws
title: Querying AWS
weight: 300
---

# 01 AWS

The AWS datasource assumes that you have appropriate credentials and environment variables set to access AWS resources. The custom fork of gomplate adds a new command to the existing AWS commands.

Unfortunately there is not a specific docker command but generic examples are below.

## Looping

[agent-1.yml](01_assets/agent-1.yml)

```yaml
server:
  log_level: debug
metrics:
  wal_directory: /tmp/grafana-agent-normal
  global:
    scrape_interval: 60s
    remote_write:
      - url: https://prometheus-us-central1.grafana.net/api/prom/push
        basic_auth:
          username: xyz
          password: secretpassword
  configs:
    - name: default
      scrape_configs:
      {{ range $index , $value := aws.EC2Query "tag:service=webhost" -}}
      - job_name: {{ $value.InstanceId }}
        static_configs:
          - targets:
              - {{ $value.PrivateDnsName }}
        {{ end -}}
```

The `aws.EC2Query` command is a new command added for Grafana Agent and takes a string in the [DescribeInstances](https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_DescribeInstances.html) format

## Final

[final.yml](01_assets/final.yml)

'''
'''--- docs/sources/cookbook/dynamic-configuration/03_Advanced_Datasources/01_assets/agent-1.yml ---
server:
  log_level: debug
metrics:
  wal_directory: /tmp/grafana-agent-normal
  global:
    scrape_interval: 60s
    remote_write:
      - url: https://prometheus-us-central1.grafana.net/api/prom/push
        basic_auth:
          username: xyz
          password: secretpassword
  configs:
  - name: default
    scrape_configs:
    {{ range $index , $value := aws.EC2Query "tag:service=webhost" -}}
    - job_name: {{ $value.InstanceId }}
      static_configs:
        - targets:
            - {{ $value.PrivateDnsName }}
      {{ end -}}

'''
'''--- docs/sources/cookbook/dynamic-configuration/03_Advanced_Datasources/01_assets/final.yml ---
server:
  http_tls_config:
    cert_file: ""
    key_file: ""
    client_auth_type: ""
    client_ca_file: ""
    cipher_suites: []
    curve_preferences: []
    min_version: 0
    max_version: 0
    prefer_server_cipher_suites: false
  grpc_tls_config:
    cert_file: ""
    key_file: ""
    client_auth_type: ""
    client_ca_file: ""
    cipher_suites: []
    curve_preferences: []
    min_version: 0
    max_version: 0
    prefer_server_cipher_suites: false
  log_format: logfmt
  log_level: debug
metrics:
  global:
    scrape_interval: 1m
    scrape_timeout: 10s
    evaluation_interval: 1m
    remote_write:
      - url: https://prometheus-us-central1.grafana.net/api/prom/push
        remote_timeout: 30s
        name: default-a098e3
        basic_auth:
          username: "xyz"
          password: <secret>
        follow_redirects: true
        queue_config:
          capacity: 2500
          max_shards: 200
          min_shards: 1
          max_samples_per_send: 500
          batch_send_deadline: 5s
          min_backoff: 30ms
          max_backoff: 100ms
        metadata_config:
          send: true
          send_interval: 1m
          max_samples_per_send: 500
  wal_directory: /tmp/grafana-agent-normal
  wal_cleanup_age: 12h0m0s
  wal_cleanup_period: 30m0s
  scraping_service:
    enabled: false
    reshard_interval: 1m0s
    reshard_timeout: 30s
    cluster_reshard_event_timeout: 30s
    kvstore:
      store: consul
      prefix: configurations/
      consul:
        host: localhost:8500
        acl_token: <secret>
        http_client_timeout: 20s
        consistent_reads: false
        watch_rate_limit: 1
        watch_burst_size: 1
      etcd:
        endpoints: []
        dial_timeout: 10s
        max_retries: 10
        tls_enabled: false
        tls_cert_path: ""
        tls_key_path: ""
        tls_ca_path: ""
        tls_server_name: ""
        tls_insecure_skip_verify: false
        username: ""
        password: <secret>
      multi:
        primary: ""
        secondary: ""
        mirror_enabled: false
        mirror_timeout: 2s
    lifecycler:
      ring:
        kvstore:
          store: consul
          prefix: collectors/
          consul:
            host: localhost:8500
            acl_token: <secret>
            http_client_timeout: 20s
            consistent_reads: false
            watch_rate_limit: 1
            watch_burst_size: 1
          etcd:
            endpoints: []
            dial_timeout: 10s
            max_retries: 10
            tls_enabled: false
            tls_cert_path: ""
            tls_key_path: ""
            tls_ca_path: ""
            tls_server_name: ""
            tls_insecure_skip_verify: false
            username: ""
            password: <secret>
          multi:
            primary: ""
            secondary: ""
            mirror_enabled: false
            mirror_timeout: 2s
        heartbeat_timeout: 1m0s
        replication_factor: 3
        zone_awareness_enabled: false
      num_tokens: 128
      heartbeat_period: 5s
      observe_period: 0s
      join_after: 0s
      min_ready_duration: 1m0s
      interface_names:
        - eth0
        - en0
      final_sleep: 30s
      tokens_file_path: ""
      availability_zone: ""
      unregister_on_shutdown: true
      address: ""
      port: 0
      id: juniper.local
    dangerous_allow_reading_files: false
  scraping_service_client:
    grpc_client_config:
      max_recv_msg_size: 104857600
      max_send_msg_size: 16777216
      grpc_compression: ""
      rate_limit: 0
      rate_limit_burst: 0
      backoff_on_ratelimits: false
      backoff_config:
        min_period: 100ms
        max_period: 10s
        max_retries: 10
      tls_enabled: false
      tls_cert_path: ""
      tls_key_path: ""
      tls_ca_path: ""
      tls_server_name: ""
      tls_insecure_skip_verify: false
  configs:
    - name: default
      scrape_configs:
        - job_name: i-1234512345e
          honor_timestamps: true
          scrape_interval: 1m
          scrape_timeout: 10s
          metrics_path: /metrics
          scheme: http
          follow_redirects: true
          static_configs:
            - targets:
                - ip-192-168-1-1.us-east-2.compute.internal
      remote_write:
        - url: https://prometheus-us-central1.grafana.net/api/prom/push
          remote_timeout: 30s
          name: default-a098e3
          basic_auth:
            username: "xyz"
            password: <secret>
          follow_redirects: true
          queue_config:
            capacity: 2500
            max_shards: 200
            min_shards: 1
            max_samples_per_send: 500
            batch_send_deadline: 5s
            min_backoff: 30ms
            max_backoff: 100ms
          metadata_config:
            send: true
            send_interval: 1m
            max_samples_per_send: 500
      wal_truncate_frequency: 1h0m0s
      min_wal_time: 5m0s
      max_wal_time: 4h0m0s
      remote_flush_deadline: 1m0s
  instance_restart_backoff: 5s
  instance_mode: shared
integrations:
  scrape_integrations: true
  integration_restart_backoff: 5s
  replace_instance_label: true
  use_hostname_label: true

'''
'''--- docs/sources/cookbook/dynamic-configuration/03_Advanced_Datasources/01_config.yml ---
template_paths:
  - "file:///etc/grafana/01_assets"
'''
'''--- docs/sources/cookbook/dynamic-configuration/README.md ---
---
draft: true
---

# Dynamic Configuration Cookbook

The purpose of the cookbook is to guide you through common scenarios of using dynamic configuration. Each folder contains increasingly more complex use cases, but feel free to jump in wherever you feel appropriate.

## Basics

[Basics](01_Basics) covers
- [Structure](01_Basics/01_Structure.md) of how agent and server templates are loaded
- [Instances](01_Basics/02_Instances.md) of metrics and metrics instances are loaded
- [Integrations](01_Basics/03_Integrations.md) of how integrations are loaded
- [Logs and Traces](01_Basics/04_Logs_and_Traces.md) of how traces and logs are loaded

[Templates](02_Templates) covers
- [Looping](02_Templates/01_Looping.md) covers basic command usage and simple loops
- [Datasource](02_Templates/02_Datasources.md) covers usage of datasource which are external datastores you can use to pull in data
- [Datasources and Objects](02_Templates/03_Datasource_and_Objects.md) covers the usage of complex json objects

[Advanced Datasources](03_Advanced_Datasources) covers non file based datasources
- [AWS](03_Advanced_Datasources/01_AWS.md) covers querying EC2 for instances

'''
'''--- docs/sources/cookbook/dynamic-configuration/_index.md ---
---
aliases:
- /docs/agent/latest/dynamic-configuration
title: Dynamic Configuration
weight: 100
---

# Dynamic Configuration Cookbook

The purpose of this cookbook is to guide you through common scenarios of using dynamic configuration. Each section contains increasingly more complex use cases, but feel free to jump in wherever you feel appropriate.

## Basics

The basic section covers
- The [Structure]({{< relref "./01_Basics/01_Structure.md" >}}) of how agent and server templates are loaded
- How metrics [Instances]({{< relref "./01_Basics/02_Instances.md" >}}) are loaded
- How [Integrations]({{< relref "./01_Basics/03_Integrations.md" >}}) are loaded
- How [Logs and Traces]({{< relref "./01_Basics/04_Logs_and_Traces.md" >}}) are loaded

## Templates
The Templates section includes

- [Looping]({{< relref "./02_Templates/01_Looping.md" >}}) with basic command usage and simple loops
- [Datasource]({{< relref "./02_Templates/02_Datasources.md" >}}) covers usage of external datastores you can use to pull in data as new data sources.
- [Datasources and Objects]({{< relref "./02_Templates/03_Datasource_and_Objects.md" >}}) covers the usage of complex json objects

## Advanced
The Advanced section includes
- The [AWS]({{< relref "./03_Advanced_Datasources/01_AWS.md" >}}) example queries EC2 for instances.

'''
'''--- docs/sources/operation-guide/_index.md ---
---
aliases:
- /docs/agent/latest/operation-guide/
title: Operation guide
weight: 700
---

# Operation guide

This guide helps you operate the Grafana Agent.

## Stability

The core of Grafana Agent is considered stable and suitable for production use.
Individual features of Grafana Agent may have stability falling under one of
the three categories:

* Experimental: we are exploring a new use case and would like feedback.
  Experimental features are subject to frequent breaking changes during
  development. Experimental features may be removed with no equivalent
  replacement. Experimental features are always hidden behind feature flags.
  Unless removed, experimental features will eventually graduate to beta.

* Beta: we are working on maturing a specific feature. Beta features may be
  subject to some breaking changes during development. Beta features may be
  replaced by equivalent functionality which covers that same use case. Beta
  features can be used without feature flags. Unless replaced by equivalent
  functionality, beta features will eventually graduate to stable.

* Stable: we believe this functionality is stable, and breaking changes to
  configuration will be rare and well-documented. We will communicate
  deprecation and removal timeline if a stable feature is chosen to be
  removed or replaced. Stable features can be used without feature flags.

There is a best-effort attempt to mark features as one of these three in
documentation; open an issue if it's not clear what the stability of a specific
feature is.

## Horizontal Scaling

There are three options to horizontally scale your deployment of Grafana Agents:

- [Host filtering](#host-filtering) requires you to run one Agent on every
   machine you wish to collect metrics from. Agents will only collect metrics
   from the machines they run on.
- [Hashmod sharding](#hashmod-sharding) allows you to roughly shard the
   discovered set of targets by using hashmod/keep relabel rules.
- The [scraping service]({{< relref "../configuration/scraping-service/" >}}) allows you to cluster Grafana
   Agents and have them distribute per-tenant configs throughout the cluster.

Each has their own set of tradeoffs:

- Host Filtering (Beta)
  - Pros
    - Does not need specialized configs per agent
    - No external dependencies required to operate
  - Cons
    - Can cause significant load on service discovery APIs
    - Requires each Agent to have the same list of scrape configs/remote_writes
- Hashmod sharding (Stable)
  - Pros
    - Exact control on the number of shards to run
    - Smaller load on SD compared to host filtering (as there are a smaller # of
      Agents)
    - No external dependencies required to operate
  - Cons
    - Each Agent must have a specialized config with their shard number inserted
      into the hashmod/keep relabel rule pair.
    - Requires each Agent to have the same list of scrape configs/remote_writes,
      with the exception of the hashmod rule being different.
    - Hashmod is not [consistent hashing](https://en.wikipedia.org/wiki/Consistent_hashing),
      so up to 100% of jobs will move to a new machine when scaling shards.
- Scraping service (Beta)
  - Pros
    - Agents don't have to have a synchronized set of scrape configs / remote_writes
      (they pull from a centralized location).
    - Exact control on the number of shards to run.
    - Uses [consistent hashing](https://en.wikipedia.org/wiki/Consistent_hashing),
      so only 1/N jobs will move to a new machine when scaling shards.
    - Smallest load on SD compared to host filtering, as only one Agent is
      responsible for a config.
  - Cons
    - Centralized configs must discover a [minimal set of targets]({{< relref "../configuration/scraping-service#best-practices" >}})
      to distribute evenly.
    - Requires running a separate KV store to store the centralized configs.
    - Managing centralized configs adds operational burden over managing a config
      file.

## Host filtering (Beta)

Host filtering implements a form of "dumb sharding," where operators may deploy
one Grafana Agent instance per machine in a cluster, all using the same
configuration, and the Grafana Agents will only scrape targets that are
running on the same node as the Agent.

Running with `host_filter: true` means that if you have a target whose host
machine is not also running a Grafana Agent process, _that target will not
be scraped!_

Host filtering is usually paired with a dedicated Agent process that is used for
scraping targets that are running outside of a given cluster. For example, when
running the Grafana Agent on GKE, you would have a DaemonSet with
`host_filter` for scraping in-cluster targets, and a single dedicated Deployment
for scraping other targets that are not running on a cluster node, such as the
Kubernetes control plane API.

If you want to scale your scrape load without host filtering, you may use the
[scraping service]({{< relref "../configuration/scraping-service/" >}}) instead.

The host name of the Agent is determined by reading `$HOSTNAME`. If `$HOSTNAME`
isn't defined, the Agent will use Go's [os.Hostname](https://golang.org/pkg/os/#Hostname)
to determine the hostname.

The following meta-labels are used to determine if a target is running on the
same machine as the target:

- `__address__`
- `__meta_consul_node`
- `__meta_dockerswarm_node_id`
- `__meta_dockerswarm_node_hostname`
- `__meta_dockerswarm_node_address`
- `__meta_kubernetes_pod_node_name`
- `__meta_kubernetes_node_name`
- `__host__`

The final label, `__host__`, isn't a label added by any Prometheus service
discovery mechanism. Rather, `__host__` can be generated by using
`host_filter_relabel_configs`. This allows for custom relabeling
rules to determine the hostname where the predefined ones fail. Relabeling rules
added with `host_filter_relabel_configs` are temporary and just used for the
host_filtering mechanism. Full relabeling rules should be applied in the
appropriate `scrape_config` instead.

Note that scrape_config `relabel_configs` do not apply to the host filtering
logic; only `host_filter_relabel_configs` will work.

If the determined hostname matches any of the meta labels, the discovered target
is allowed. Otherwise, the target is ignored, and will not show up in the
[targets
API]({{< relref "../api#list-current-scrape-targets" >}}).

## Hashmod sharding (Stable)

Grafana Agents can be sharded by using a pair of hashmod/keep relabel rules.
These rules will hash the address of a target and modulus it with the number
of Agent shards that are running.

```yaml
scrape_configs:
- job_name: some_job
  # Add usual service discovery here, such as static_configs
  relabel_configs:
  - source_labels: [__address__]
    modulus:       4    # 4 shards
    target_label:  __tmp_hash
    action:        hashmod
  - source_labels: [__tmp_hash]
    regex:         ^1$  # This is the 2nd shard
    action:        keep
```

Add the `relabel_configs` to all of your scrape_config blocks. Ensure that each
running Agent shard has a different value for the `regex`; the first Agent shard
should have `^0$`, the second should have `^1$`, and so on, up to `^3$`.

This sharding mechanism means each Agent will ignore roughly 1/N of the total
targets, where N is the number of shards. This allows for horizontal scaling the
number of Agents and distributing load between them.

Note that the hashmod used here is not a consistent hashing algorithm; this
means that changing the number of shards may cause any number of targets to move
to a new shard, up to 100%. When moving to a new shard, any existing data in the
WAL from the old machine is effectively discarded.

## Prometheus instances

The Grafana Agent defines a concept of a Prometheus _Instance_, which is
its own mini Prometheus-lite server. The instance runs a combination of
Prometheus service discovery, scraping, a WAL for storage, and `remote_write`.

Instances allow for fine grained control of what data gets scraped and where it
gets sent. Users can easily define two Instances that scrape different subsets
of metrics and send them to two completely different remote_write systems.

Instances are especially relevant to the [scraping service
mode]({{< relref "../configuration/scraping-service/" >}}), where breaking up your scrape configs into
multiple Instances is required for sharding and balancing scrape load across a
cluster of Agents.

## Instance sharing (Stable)

The v0.5.0 release of the Agent introduced the concept of _instance sharing_,
which combines scrape_configs from compatible instance configs into a single,
shared Instance. Instance configs are compatible when they have no differences
in configuration with the exception of what they scrape. `remote_write` configs
may also differ in the order which endpoints are declared, but the unsorted
`remote_writes` must still be an exact match.

In the shared instances mode, the `name` field of `remote_write` configs is
ignored. The resulting `remote_write` configs will have a name identical to the
first six characters of the group name and the first six characters of the hash
from that `remote_write` config separated by a `-`.

The shared instances mode is the new default, and the previous behavior is
deprecated. If you wish to restore the old behavior, set `instance_mode:
distinct` in the
[`metrics_config`]({{< relref "../configuration/metrics-config" >}}) block of
your config file.

Shared instances are completely transparent to the user with the exception of
exposed metrics. With `instance_mode: shared`, metrics for Prometheus components
(WAL, service discovery, remote_write, etc) have a `instance_group_name` label,
which is the hash of all settings used to determine the shared instance. When
`instance_mode: distinct` is set, the metrics for Prometheus components will
instead have an `instance_name` label, which matches the name set on the
individual Instance config. It is recommended to use the default of
`instance_mode: shared` unless you don't mind the performance hit and really
need granular metrics.

Users can use the [targets API]({{< relref "../api#list-current-scrape-targets" >}})
to see all scraped targets, and the name of the shared instance they were
assigned to.

'''
'''--- docs/sources/operator/_index.md ---
---
aliases:
- /docs/agent/latest/operator/
title: Grafana Agent Operator
weight: 500
---

# Grafana Agent Operator (Beta)

The Grafana Agent Operator is a Kubernetes operator that makes it easier to
deploy the Grafana Agent and collect telemetry data from your pods.
It is currently in **Beta**, and is subject to change at any time.

It works by watching for [Kubernetes custom resources](https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/)
that specify how you would like to collect telemetry data from your Kubernetes
cluster and where you would like to send it. They abstract Kubernetes-specific
configuration that is more tedious to perform manually. The Grafana Agent
Operator manages corresponding Grafana Agent deployments in your cluster by
watching for changes against the custom resources.

Metric collection is based on the [Prometheus
Operator](https://github.com/prometheus-operator/prometheus-operator) and
supports the official v1 ServiceMonitor, PodMonitor, and Probe CRDs from the
project. These custom resources represent abstractions for monitoring services,
pods, and ingresses. They are especially useful for Helm users, where manually
writing a generic SD to match all your charts can be difficult (or impossible!)
or where manually writing a specific SD for each chart can be tedious.

'''
'''--- docs/sources/operator/add-custom-scrape-jobs.md ---
---
aliases:
- /docs/agent/latest/operator/add-custom-scrape-jobs/
title: Add custom scrape jobs
weight: 400
---

# Add custom scrape jobs

Sometimes you want to add a scrape job for something that isn't supported by the
standard set of Prometheus Operator CRDs. A common example of this is node-level
metrics.

To do this, you'll need to write custom scrape configs and store it in a
Kubernetes Secret:

```yaml
apiVersion: v1
kind: Secret
metadata:
  name: extra-jobs
  namespace: operator
stringData:
  jobs.yaml: |
    <SCRAPE CONFIGS>
```

Replace `<SCRAPE CONFIGS>` above with the array of Prometheus scrape jobs to
include.

For example, to collect metrics from Kubelet and cAdvisor, use the following:

```yaml
apiVersion: v1
kind: Secret
metadata:
  name: extra-jobs
  namespace: operator
stringData:
  jobs.yaml: |
    - bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      job_name: integrations/kubernetes/kubelet
      kubernetes_sd_configs:
      - role: node
      relabel_configs:
      - replacement: kubernetes.default.svc:443
        target_label: __address__
      - regex: (.+)
        source_labels: [__meta_kubernetes_node_name]
        replacement: /api/v1/nodes/$1/proxy/metrics
        target_label: __metrics_path__
      - action: hashmod
        modulus: $(SHARDS)
        source_labels:
        - __address__
        target_label: __tmp_hash
      - action: keep
        regex: $(SHARD)
        source_labels:
        - __tmp_hash
      scheme: https
      tls_config:
        ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
    - bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      job_name: integrations/kubernetes/cadvisor
      kubernetes_sd_configs:
      - role: node
      relabel_configs:
      - replacement: kubernetes.default.svc:443
        target_label: __address__
      - regex: (.+)
        replacement: /api/v1/nodes/$1/proxy/metrics/cadvisor
        source_labels:
        - __meta_kubernetes_node_name
        target_label: __metrics_path__
      - action: hashmod
        modulus: $(SHARDS)
        source_labels:
        - __address__
        target_label: __tmp_hash
      - action: keep
        regex: $(SHARD)
        source_labels:
        - __tmp_hash
      scheme: https
      tls_config:
        ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
```

Note that you **should** always add these two relabel_configs for each custom job:

```yaml
- action: hashmod
  modulus: $(SHARDS)
  source_labels:
  - __address__
  target_label: __tmp_hash
- action: keep
  regex: $(SHARD)
  source_labels:
  - __tmp_hash
```

These rules ensure if your GrafanaAgent has multiple metrics shards, only one
pod per replica will collect metrics for each job.

Once your Secret is defined, you'll then need to add a `additionalScrapeConfigs`
field to your MetricsInstance:

```yaml
apiVersion: monitoring.grafana.com/v1alpha1
kind: MetricsInstance
metadata:
  labels:
    name: grafana-agent
  name: primary
  namespace: operator
spec:
  additionalScrapeConfigs:
    name: extra-jobs
    key: jobs.yaml
  # ... Other settings ...
```

The Secret **MUST** be in the same namespace as the MetricsInstance.

There is a known [issue](https://github.com/grafana/agent/issues/655) that
currently prevents the Grafana Agent Operator from updating Grafana Agent
deployments when `additionalScrapeConfigs` or the underlying secret changes.
Until the issue is resolved, you should restart the Operator to force it to pick
up the changes.

If you followed the [Getting Started guide]({{< relref "./getting-started.md" >}}),
run the following command to restart your Grafana Agent Operator deployment:

```
kubectl -n default rollout restart deployment/grafana-agent-operator
```

You may need to replace `default` with the namespace you installed the Operator
in if you changed the namespace provided in the guide.

'''
'''--- docs/sources/operator/architecture.md ---
---
aliases:
- /docs/agent/latest/operator/architecture/
title: Operator architecture
weight: 300
---

# Operator architecture

This guide gives a high-level overview of how the Grafana Agent Operator
works.

The Grafana Agent Operator works in two phases:

1. Discover a hierarchy of custom resources
2. Reconcile that hierarchy into a Grafana Agent deployment

## Custom Resource Hierarchy

The root of the custom resource hierarchy is the `GrafanaAgent` resource. It is
primary resource the Operator looks for, and is called the "root" because it
discovers many other sub-resources.

The full hierarchy of custom resources is as follows:

- `GrafanaAgent`
    - `MetricsInstance`
        - `PodMonitor`
        - `Probe`
        - `ServiceMonitor`
    - `LogsInstance`
        - `PodLogs`

Most of the resources above have the ability to reference a ConfigMap or a
Secret. All referenced ConfigMaps or Secrets are added into the resource
hierarchy.

When a hierarchy is established, each item is watched for changes. Any changed
item will cause a reconcile of the root GrafanaAgent resource, either
creating, modifying, or deleting the corresponding Grafana Agent deployment.

A single resource can belong to multiple hierarchies. For example, if two
GrafanaAgents use the same Probe, modifying that Probe will cause both
GrafanaAgents to be reconciled.

## Reconcile

When a resource hierarchy is created, updated, or deleted, a reconcile occurs.
When a GrafanaAgent resource is deleted, the corresponding Grafana Agent
deployment will also be deleted.

Reconciling creates a few cluster resources:

1. A Secret is generated holding the
   [configuration]({{< relref "../configuration/_index.md" >}}) of the Grafana Agent.
2. Another Secret is created holding all referenced Secrets or ConfigMaps from
   the resource hierarchy. This ensures that Secrets referenced from a custom
   resource in another namespace can still be read.
3. A Service is created to govern the created StatefulSets.
4. One StatefulSet per Prometheus shard is created.

PodMonitors, Probes, and ServiceMonitors are turned into individual scrape jobs
which all use Kubernetes SD.

## Sharding and replication

The GrafanaAgent resource can specify a number of shards. Each shard results in
the creation of a StatefulSet with a hashmod + keep relabel_config per job:

```yaml
- source_labels: [__address__]
  target_label: __tmp_hash
  modulus: NUM_SHARDS
  action: hashmod
- source_labels: [__tmp_hash]
  regex: CURRENT_STATEFULSET_SHARD
  action: keep
```

This allows for some decent horizontal scaling capabilities, where each shard
will handle roughly 1/N of the total scrape load. Note that this does not use
consistent hashing, which means changing the number of shards will cause
anywhere between 1/N to N targets to reshuffle.

The sharding mechanism is borrowed from the Prometheus Operator.

The number of replicas can be defined, similarly to the number of shards. This
creates duplicate shards. This must be paired with a remote_write system that
can perform HA duplication. Grafana Cloud and Cortex provide this out of the
box, and the Grafana Agent Operator defaults support these two systems.

The total number of created metrics pods will be product of `numShards *
numReplicas`.

## Labels

Two labels are added by default to every metric:

- `cluster`, representing the `GrafanaAgent` deployment. Holds the value of
  `<GrafanaAgent.metadata.namespace>/<GrafanaAgent.metadata.name>`.
- `__replica__`, representing the replica number of the Agent. This label works
   out of the box with Grafana Cloud and Cortex's [HA
   deduplication](https://cortexmetrics.io/docs/guides/ha-pair-handling/).

The shard number is not added as a label, as sharding is designed to be
transparent on the receiver end.

'''
'''--- docs/sources/operator/custom-resource-quickstart.md ---
---
aliases:
- /docs/agent/latest/operator/custom-resource-quickstart/
title: Custom Resource Quickstart
weight: 120
---
# Grafana Agent Operator Custom Resource Quickstart

In this guide you'll learn how to deploy [Agent Operator]({{< relref "./_index.md" >}})'s custom resources into your Kubernetes cluster.

You'll roll out the following custom resources (CRs):

- A `GrafanaAgent` resource, which discovers one or more `MetricsInstance` and `LogsInstances` resources.
- A `MetricsInstance` resource that defines where to ship collected metrics. Under the hood, this rolls out a Grafana Agent StatefulSet that will scrape and ship metrics to a `remote_write` endpoint.
- A `ServiceMonitor` resource to collect cAdvisor and kubelet metrics. Under the hood, this configures the `MetricsInstance` / Agent StatefulSet.
- A `LogsInstance` resource that defines where to ship collected logs. Under the hood, this rolls out a Grafana Agent DaemonSet that will tail log files on your cluster nodes.
- A `PodLogs` resource to collect container logs from Kubernetes Pods. Under the hood, this configures the`LogsInstance` / Agent DaemonSet.

To learn more about the custom resources Operator provides and their hierarchy, please consult [Operator architecture]({{< relref "./architecture.md" >}}).

> **Note:** Agent Operator is currently in beta and its custom resources are subject to change as the project evolves. It currently supports the metrics and logs subsystems of Grafana Agent. Integrations and traces support is coming soon.

By the end of this guide, you will be scraping and shipping cAdvisor and Kubelet metrics to a Prometheus-compatible metrics endpoint. You'll also be collecting and shipping your Pods' container logs to a Loki-compatible logs endpoint.

## Prerequisites

Before you begin, make sure that you have installed Agent Operator into your cluster. You can learn how to do this in:
- [Installing Grafana Agent Operator with Helm]({{< relref "./helm-getting-started.md" >}})
- [Installing Grafana Agent Operator]({{< relref "./getting-started.md" >}})

## Step 1: Deploy GrafanaAgent resource

In this step you'll roll out a `GrafanaAgent` resource. A `GrafanaAgent` resource discovers `MetricsInstance` and `LogsInstance` resources and defines the Grafana Agent image, Pod requests, limits, affinities, and tolerations. Pod attributes can only be defined at the GrafanaAgent level and are propagated to `MetricsInstance` and `LogsInstance` Pods. To learn more, please see the GrafanaAgent [Custom Resource Definition](https://github.com/grafana/agent/blob/main/production/operator/crds/monitoring.grafana.com_grafanaagents.yaml).

> **Note:** Due to the variety of possible deployment architectures, the official Agent Operator Helm chart does not provide built-in templates for the custom resources described in this quickstart. These must be configured and deployed manually. However, you are encouraged to template and add the following manifests to your own in-house Helm charts and GitOps flows.

Roll out the following manifests in your cluster:

```yaml
apiVersion: monitoring.grafana.com/v1alpha1
kind: GrafanaAgent
metadata:
  name: grafana-agent
  namespace: default
  labels:
    app: grafana-agent
spec:
  image: grafana/agent:v0.26.1
  logLevel: info
  serviceAccountName: grafana-agent
  metrics:
    instanceSelector:
      matchLabels:
        agent: grafana-agent-metrics
    externalLabels:
      cluster: cloud

  logs:
    instanceSelector:
      matchLabels:
        agent: grafana-agent-logs

---

apiVersion: v1
kind: ServiceAccount
metadata:
  name: grafana-agent
  namespace: default

---

apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: grafana-agent
rules:
- apiGroups:
  - ""
  resources:
  - nodes
  - nodes/proxy
  - nodes/metrics
  - services
  - endpoints
  - pods
  - events
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - networking.k8s.io
  resources:
  - ingresses
  verbs:
  - get
  - list
  - watch
- nonResourceURLs:
  - /metrics
  - /metrics/cadvisor
  verbs:
  - get

---

apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: grafana-agent
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: grafana-agent
subjects:
- kind: ServiceAccount
  name: grafana-agent
  namespace: default
```

This creates a ServiceAccount, ClusterRole, and ClusterRoleBinding for the GrafanaAgent resource. It also creates a GrafanaAgent resource and specifies an Agent image version. Finally, the GrafanaAgent resource specifies `MetricsInstance` and `LogsInstance` selectors. These search for MetricsInstances and LogsInstances in the **same namespace** with labels matching `agent: grafana-agent-metrics` and `agent: grafana-agent-logs`, respectively. It also sets a `cluster: cloud` label for all metrics shipped your Prometheus-compatible endpoint. You should change this label to your desired cluster name. To search for MetricsInstances or LogsInstances in a *different* namespace, please use the `instanceNamespaceSelector` field. To learn more about this field, please consult the `GrafanaAgent` [CRD specification](https://github.com/grafana/agent/blob/main/production/operator/crds/monitoring.grafana.com_grafanaagents.yaml#L3789).

The full hierarchy of custom resources is as follows:

- `GrafanaAgent`
  - `MetricsInstance`
    - `PodMonitor`
    - `Probe`
    - `ServiceMonitor`
  - `LogsInstance`
    - `PodLogs`

Deploying a GrafanaAgent resource on its own will not spin up any Agent Pods. Agent Operator will create Agent Pods once MetricsInstance and LogsIntance resources have been created. In the next step, you'll roll out a `MetricsInstance` resource to scrape cAdvisor and Kubelet metrics and ship these to your Prometheus-compatible metrics endpoint.

## Step 2: Deploy a MetricsInstance resource

In this step you'll roll out a MetricsInstance resource. MetricsInstance resources define a `remote_write` sink for metrics and configure one or more selectors to watch for creation and updates to `*Monitor` objects. These objects allow you to define Agent scrape targets via K8s manifests:

- [ServiceMonitors](https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/api.md#servicemonitor)
- [PodMonitors](https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/api.md#podmonitor)
- [Probes](https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/api.md#probe)

Roll out the following manifest into your cluster:

```yaml
apiVersion: monitoring.grafana.com/v1alpha1
kind: MetricsInstance
metadata:
  name: primary
  namespace: default
  labels:
    agent: grafana-agent-metrics
spec:
  remoteWrite:
  - url: your_remote_write_URL
    basicAuth:
      username:
        name: primary-credentials-metrics
        key: username
      password:
        name: primary-credentials-metrics
        key: password

  # Supply an empty namespace selector to look in all namespaces. Remove
  # this to only look in the same namespace as the MetricsInstance CR
  serviceMonitorNamespaceSelector: {}
  serviceMonitorSelector:
    matchLabels:
      instance: primary

  # Supply an empty namespace selector to look in all namespaces. Remove
  # this to only look in the same namespace as the MetricsInstance CR.
  podMonitorNamespaceSelector: {}
  podMonitorSelector:
    matchLabels:
      instance: primary

  # Supply an empty namespace selector to look in all namespaces. Remove
  # this to only look in the same namespace as the MetricsInstance CR.
  probeNamespaceSelector: {}
  probeSelector:
    matchLabels:
      instance: primary
```

Be sure to replace the `remote_write` URL and customize the namespace and label configuration as necessary. This will associate itself with the `agent: grafana-agent` GrafanaAgent resource deployed in the previous step, and watch for creation and updates to `*Monitors` monitors with the the `instance: primary` label.

Once you've rolled out this manifest, create the `basicAuth` credentials using a Kubernetes Secret:

```yaml
apiVersion: v1
kind: Secret
metadata:
  name: primary-credentials-metrics
  namespace: default
stringData:
  username: 'your_cloud_prometheus_username'
  password: 'your_cloud_prometheus_API_key'
```

If you're using Grafana Cloud, you can find your hosted Prometheus endpoint username and password in the [Grafana Cloud Portal](https://grafana.com/profile/org ). You may wish to base64-encode these values yourself. In this case, please use `data` instead of `stringData`.

Once you've rolled out the `MetricsInstance` and its Secret, you can confirm that the MetricsInstance Agent is up and running with `kubectl get pod`. Since we haven't defined any monitors yet, this Agent will not have any scrape targets defined. In the next step, we'll create scrape targets for the cAdvisor and kubelet endpoints exposed by the `kubelet` service in the cluster.

## Step 3: Create ServiceMonitors for kubelet and cAdvisor endpoints

In this step, you'll create ServiceMonitors for kubelet and cAdvisor metrics exposed by the `kubelet` Service. Every node in your cluster exposes kubelet and cadvisor metrics at `/metrics` and `/metrics/cadvisor` respectively. Agent Operator creates a `kubelet` service that exposes these Node endpoints so that they can be scraped using ServiceMonitors.

To scrape these two endpoints, roll out the following two ServiceMonitors in your cluster:

- Kubelet ServiceMonitor

```yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  labels:
    instance: primary
  name: kubelet-monitor
  namespace: default
spec:
  endpoints:
  - bearerTokenFile: /var/run/secrets/kubernetes.io/serviceaccount/token
    honorLabels: true
    interval: 60s
    metricRelabelings:
    - action: keep
      regex: kubelet_cgroup_manager_duration_seconds_count|go_goroutines|kubelet_pod_start_duration_seconds_count|kubelet_runtime_operations_total|kubelet_pleg_relist_duration_seconds_bucket|volume_manager_total_volumes|kubelet_volume_stats_capacity_bytes|container_cpu_usage_seconds_total|container_network_transmit_bytes_total|kubelet_runtime_operations_errors_total|container_network_receive_bytes_total|container_memory_swap|container_network_receive_packets_total|container_cpu_cfs_periods_total|container_cpu_cfs_throttled_periods_total|kubelet_running_pod_count|node_namespace_pod_container:container_cpu_usage_seconds_total:sum_rate|container_memory_working_set_bytes|storage_operation_errors_total|kubelet_pleg_relist_duration_seconds_count|kubelet_running_pods|rest_client_request_duration_seconds_bucket|process_resident_memory_bytes|storage_operation_duration_seconds_count|kubelet_running_containers|kubelet_runtime_operations_duration_seconds_bucket|kubelet_node_config_error|kubelet_cgroup_manager_duration_seconds_bucket|kubelet_running_container_count|kubelet_volume_stats_available_bytes|kubelet_volume_stats_inodes|container_memory_rss|kubelet_pod_worker_duration_seconds_count|kubelet_node_name|kubelet_pleg_relist_interval_seconds_bucket|container_network_receive_packets_dropped_total|kubelet_pod_worker_duration_seconds_bucket|container_start_time_seconds|container_network_transmit_packets_dropped_total|process_cpu_seconds_total|storage_operation_duration_seconds_bucket|container_memory_cache|container_network_transmit_packets_total|kubelet_volume_stats_inodes_used|up|rest_client_requests_total
      sourceLabels:
      - __name__
    - action: replace
      targetLabel: job
      replacement: integrations/kubernetes/kubelet
    port: https-metrics
    relabelings:
    - sourceLabels:
      - __metrics_path__
      targetLabel: metrics_path
    scheme: https
    tlsConfig:
      insecureSkipVerify: true
  namespaceSelector:
    matchNames:
    - default
  selector:
    matchLabels:
      app.kubernetes.io/name: kubelet
```

- cAdvsior ServiceMonitor

```yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  labels:
    instance: primary
  name: cadvisor-monitor
  namespace: default
spec:
  endpoints:
  - bearerTokenFile: /var/run/secrets/kubernetes.io/serviceaccount/token
    honorLabels: true
    honorTimestamps: false
    interval: 60s
    metricRelabelings:
    - action: keep
      regex: kubelet_cgroup_manager_duration_seconds_count|go_goroutines|kubelet_pod_start_duration_seconds_count|kubelet_runtime_operations_total|kubelet_pleg_relist_duration_seconds_bucket|volume_manager_total_volumes|kubelet_volume_stats_capacity_bytes|container_cpu_usage_seconds_total|container_network_transmit_bytes_total|kubelet_runtime_operations_errors_total|container_network_receive_bytes_total|container_memory_swap|container_network_receive_packets_total|container_cpu_cfs_periods_total|container_cpu_cfs_throttled_periods_total|kubelet_running_pod_count|node_namespace_pod_container:container_cpu_usage_seconds_total:sum_rate|container_memory_working_set_bytes|storage_operation_errors_total|kubelet_pleg_relist_duration_seconds_count|kubelet_running_pods|rest_client_request_duration_seconds_bucket|process_resident_memory_bytes|storage_operation_duration_seconds_count|kubelet_running_containers|kubelet_runtime_operations_duration_seconds_bucket|kubelet_node_config_error|kubelet_cgroup_manager_duration_seconds_bucket|kubelet_running_container_count|kubelet_volume_stats_available_bytes|kubelet_volume_stats_inodes|container_memory_rss|kubelet_pod_worker_duration_seconds_count|kubelet_node_name|kubelet_pleg_relist_interval_seconds_bucket|container_network_receive_packets_dropped_total|kubelet_pod_worker_duration_seconds_bucket|container_start_time_seconds|container_network_transmit_packets_dropped_total|process_cpu_seconds_total|storage_operation_duration_seconds_bucket|container_memory_cache|container_network_transmit_packets_total|kubelet_volume_stats_inodes_used|up|rest_client_requests_total
      sourceLabels:
      - __name__
    - action: replace
      targetLabel: job
      replacement: integrations/kubernetes/cadvisor
    path: /metrics/cadvisor
    port: https-metrics
    relabelings:
    - sourceLabels:
      - __metrics_path__
      targetLabel: metrics_path
    scheme: https
    tlsConfig:
      insecureSkipVerify: true
  namespaceSelector:
    matchNames:
    - default
  selector:
    matchLabels:
      app.kubernetes.io/name: kubelet
```

These two ServiceMonitors configure Agent to scrape all the Kubelet and cAdvisor endpoints in your Kubernetes cluster (one of each per Node). In addition, it defines a `job` label which you may change (it is preset here for compatibility with Grafana Cloud's Kubernetes integration), and allowlists a core set of Kubernetes metrics to reduce remote metrics usage. If you don't need this allowlist, you may omit it, however note that your metrics usage will increase significantly.

 When you're done, Agent should now be shipping Kubelet and cAdvisor metrics to your remote Prometheus endpoint.

## Step 4: Deploy LogsInstance and PodLogs resources

In this step, you'll deploy a LogsInstance resource to collect logs from your cluster nodes and ship these to your remote Loki endpoint. Under the hood, Agent Operator will deploy a DaemonSet of Agents in your cluster that will tail log files defined in PodLogs resources.

Deploy the LogsInstance into your cluster:

```yaml
apiVersion: monitoring.grafana.com/v1alpha1
kind: LogsInstance
metadata:
  name: primary
  namespace: default
  labels:
    agent: grafana-agent-logs
spec:
  clients:
  - url: your_remote_logs_URL
    basicAuth:
      username:
        name: primary-credentials-logs
        key: username
      password:
        name: primary-credentials-logs
        key: password

  # Supply an empty namespace selector to look in all namespaces. Remove
  # this to only look in the same namespace as the LogsInstance CR
  podLogsNamespaceSelector: {}
  podLogsSelector:
    matchLabels:
      instance: primary
```

This LogsInstance will pick up PodLogs resources with the `instance: primary` label. Be sure to set the Loki URL to the correct push endpoint (for Grafana Cloud, this will be something like `logs-prod-us-central1.grafana.net/loki/api/v1/push`, however you should check the Cloud Portal to confirm).

Also note that we are using the `agent: grafana-agent-logs` label here, which will associate this LogsInstance with the GrafanaAgent resource defined in Step 1. This means that it will inherit requests, limits, affinities and other properties defined in the GrafanaAgent custom resource.

Create the Secret for the LogsInstance resource:

```yaml
apiVersion: v1
kind: Secret
metadata:
  name: primary-credentials-logs
  namespace: default
stringData:
  username: 'your_username_here'
  password: 'your_password_here'
```

If you're using Grafana Cloud, you can find your hosted Loki endpoint username and password in the [Grafana Cloud Portal](https://grafana.com/profile/org). You may wish to base64-encode these values yourself. In this case, please use `data` instead of `stringData`.

Finally, we'll roll out a PodLogs resource to define our logging targets. Under the hood, Agent Operator will turn this into Agent config for the logs subsystem, and roll it out to the DaemonSet of logging agents.

The following is a minimal working example which you should adapt to your production needs:

```yaml
apiVersion: monitoring.grafana.com/v1alpha1
kind: PodLogs
metadata:
  labels:
    instance: primary
  name: kubernetes-pods
  namespace: default
spec:
  pipelineStages:
    - docker: {}
  namespaceSelector:
    matchNames:
    - default
  selector:
    matchLabels: {}
```

This tails container logs for all Pods in the `default` Namespace. You can restrict the set of Pods matched by using the `matchLabels` selector. You can also set additional `pipelineStages` and create `relabelings` to add or modify log line labels. To learn more about the PodLogs spec and available resource fields, please see the [PodLogs CRD](https://github.com/grafana/agent/blob/main/production/operator/crds/monitoring.grafana.com_podlogs.yaml).

Under the hood, the above PodLogs resource will add the following labels to log lines:

- `namespace`
- `service`
- `pod`
- `container`
- `job`
  - Set to `PodLogs_namespace/PodLogs_name`
- `__path__` (the path to log files)
  - Set to `/var/log/pods/*$1/*.log` where `$1` is `__meta_kubernetes_pod_uid/__meta_kubernetes_pod_container_name`

To learn more about this config format and other available labels, please see the [Promtail Scraping](https://grafana.com/docs/loki/latest/clients/promtail/scraping/#promtail-scraping-service-discovery) reference documentation. Agent Operator will load this config into the LogsInstance agents automatically.

At this point the DaemonSet of logging agents should be tailing your container logs, applying some default labels to the log lines, and shipping them to your remote Loki endpoint.

## Conclusion

At this point you've rolled out the following into your cluster:

- A `GrafanaAgent` resource, which discovers one or more `MetricsInstance` and `LogsInstances` resources.
- A `MetricsInstance`  resource that defines where to ship collected metrics.
- A `ServiceMonitor` resource to collect cAdvisor and kubelet metrics.
- A `LogsInstance` resource that defines where to ship collected logs.
- A `PodLogs` resource to collect container logs from Kubernetes Pods.

You can verify that everything is working correctly by navigating to your Grafana instance and querying your Loki and Prometheus datasources. Operator support for Tempo and traces is coming soon.

'''
'''--- docs/sources/operator/getting-started.md ---
---
aliases:
- /docs/agent/latest/operator/getting-started/
title: Installing Grafana Agent Operator
weight: 100
---

# Installing Grafana Agent Operator

In this guide you'll learn how to deploy the [Grafana Agent Operator]({{< relref "./_index.md" >}}) into your Kubernetes cluster. This guide does *not* use Helm. To learn how to deploy Agent Operator using the [grafana-agent-operator Helm chart](https://github.com/grafana/helm-charts/tree/main/charts/agent-operator), please see [Installing Grafana Agent Operator with Helm]({{< relref "./helm-getting-started.md" >}}).

> **Note:** Agent Operator is currently in beta and its custom resources are subject to change as the project evolves. It currently supports the metrics and logs subsystems of Grafana Agent. Integrations and traces support is coming soon.

By the end of this guide, you'll have deloyed Agent Operator into your cluster.

## Prerequisites

Before you begin, make sure that you have the following available to you:

- A Kubernetes cluster
- The `kubectl` command-line client installed and configured on your machine

## Step 1: Deploy CustomResourceDefinitions

Before you can write custom resources to describe a Grafana Agent deployment,
you _must_ deploy the
[CustomResourceDefinitions](https://kubernetes.io/docs/tasks/extend-kubernetes/custom-resources/custom-resource-definitions/)
to the cluster first. These definitions describe the schema that the custom
resources will conform to. This is also required for the operator to run; it
will fail if it can't find the custom resource definitions of objects it is
looking to use.

The current set of CustomResourceDefinitions can be found in
[production/operator/crds](https://github.com/grafana/agent/tree/main/production/operator/crds). Apply them from the
root of this repository using:

```
kubectl apply -f production/operator/crds
```

This step _must_ be done before installing the Operator, as the Operator will
fail to start if the CRDs do not exist.

### Find information on the supported values for the CustomResourceDefinitions

Once you've deployed the CustomResourceDefinitions
to your Kubernetes cluster, use `kubectl explain <resource>` to get access to
the documentation for each resource. For example, `kubectl explain GrafanaAgent`
will describe the GrafanaAgent CRD, and `kubectl explain GrafanaAgent.spec` will
give you information on its spec field.

## Step 2: Install Agent Operator

Use the following deployment to run the Operator, changing values as desired:

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: grafana-agent-operator
  namespace: default
  labels:
    app: grafana-agent-operator
spec:
  replicas: 1
  selector:
    matchLabels:
      app: grafana-agent-operator
  template:
    metadata:
      labels:
        app: grafana-agent-operator
    spec:
      serviceAccountName: grafana-agent-operator
      containers:
      - name: operator
        image: grafana/agent-operator:v0.26.1
        args:
        - --kubelet-service=default/kubelet
---

apiVersion: v1
kind: ServiceAccount
metadata:
  name: grafana-agent-operator
  namespace: default

---

apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: grafana-agent-operator
rules:
- apiGroups: [monitoring.grafana.com]
  resources:
  - grafanaagents
  - metricsinstances
  - logsinstances
  - podlogs
  - integrations
  verbs: [get, list, watch]
- apiGroups: [monitoring.coreos.com]
  resources:
  - podmonitors
  - probes
  - servicemonitors
  verbs: [get, list, watch]
- apiGroups: [""]
  resources:
  - namespaces
  - nodes
  verbs: [get, list, watch]
- apiGroups: [""]
  resources:
  - secrets
  - services
  - configmaps
  - endpoints
  verbs: [get, list, watch, create, update, patch, delete]
- apiGroups: ["apps"]
  resources:
  - statefulsets
  - daemonsets
  - deployments
  verbs: [get, list, watch, create, update, patch, delete]

---

apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: grafana-agent-operator
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: grafana-agent-operator
subjects:
- kind: ServiceAccount
  name: grafana-agent-operator
  namespace: default
```

### Run Operator locally

Before running locally, _make sure your kubectl context is correct!_
Running locally uses your current kubectl context, and you probably don't want
to accidentally deploy a new Grafana Agent to prod.

CRDs should be installed on the cluster prior to running locally. If you haven't
done this yet, follow [deploying CustomResourceDefinitions](#step-1-deploy-customresourcedefinitions)
first.

Afterwards, you can run the operator using `go run`:

```
go run ./cmd/agent-operator
```

## Conclusion

With Agent Operator up and running, you can move on to setting up a `GrafanaAgent` custom resource. This will discover `MetricsInstance` and `LogsInstance` custom resources and endow them with Pod attributes (like requests and limits) defined in the `GrafanaAgent` spec. To learn how to do this, please see [Custom Resource Quickstart]({{< relref "./custom-resource-quickstart.md" >}}).

'''
'''--- docs/sources/operator/helm-getting-started.md ---
---
aliases:
- /docs/agent/latest/operator/helm-getting-started/
title: Installing Grafana Agent Operator with Helm
weight: 110
---
# Installing Grafana Agent Operator with Helm

In this guide you'll learn how to deploy the [Grafana Agent Operator]({{< relref "./_index.md" >}}) into your Kubernetes cluster using the [grafana-agent-operator Helm chart](https://github.com/grafana/helm-charts/tree/main/charts/agent-operator).

> **Note:** Agent Operator is currently in beta and its custom resources are subject to change as the project evolves. It currently supports the metrics and logs subsystems of Grafana Agent. Integrations and traces support is coming soon.

By the end of this guide, you'll have deloyed Agent Operator into your cluster.

## Prerequisites

Before you begin, make sure that you have the following available to you:

- A Kubernetes cluster
- The `kubectl` command-line client installed and configured on your machine
- The `helm` command-line client installed and configured on your machine

## Install Agent Operator Helm Chart

In this step you'll install the [grafana-agent-operator Helm chart](https://github.com/grafana/helm-charts/tree/main/charts/agent-operator) into your Kubernetes cluster. This will install the latest version of Agent Operator and its [Custom Resource Definitions](https://github.com/grafana/agent/tree/main/production/operator/crds) (CRDs). By default the chart will configure the operator to maintain a Service that allows you scrape kubelets using a `ServiceMonitor`.

Begin by adding and updating the `grafana` Helm chart repo:

```bash
helm repo add grafana https://grafana.github.io/helm-charts
helm repo update
```

Next, install the chart:

```bash
helm install my-release grafana/grafana-agent-operator
```

Replace `my-release` with your desired release name.

If you want to modify the default parameters, you can create a `values.yaml` file and pass it in to `helm install`:

```bash
helm install my-release grafana/grafana-agent-operator -f values.yaml
```

A list of configurable template parameters can be found in the [Helm chart repository](https://github.com/grafana/helm-charts/blob/main/charts/agent-operator/values.yaml).

If you want to deploy Agent Operator into a namespace other than `default`, use the `-n` flag:

```bash
helm install my-release grafana/grafana-agent-operator -f values.yaml -n my-namespace
```

Once you've successfully deployed the Helm release, confirm that Agent Operator is up and running:

```bash
kubectl get pod
kubectl get svc
```

You should see an Agent Operator Pod in `RUNNING` state, and a `kubelet` Service.

## Conclusion

With Agent Operator up and running, you can move on to setting up a `GrafanaAgent` custom resource. This will discover `MetricsInstance` and `LogsInstance` custom resources and endow them with Pod attributes (like requests and limits) defined in the `GrafanaAgent` spec. To learn how to do this, please see [Custom Resource Quickstart]({{< relref "./custom-resource-quickstart.md" >}}).

'''
'''--- docs/sources/set-up/_index.md ---
---
aliases:
- /docs/agent/latest/set-up/
title: Set up Grafana Agent
weight: 100
---

# Set up Grafana Agent

## Overview

If this is your first time using Grafana Agent, use one of the installation options to install Grafana Agent based on the platform you are using. Alternatively, use the quick start guides to help you with the specifics of sending metrics, logs, and traces to the Grafana Stack or Grafana Cloud.

If you have already installed Grafana Agent on your machine, you can jump to the [Configure Grafana Agent]({{< relref "../configuration/_index.md" >}}) section.

To get started with Grafana Agent Operator, refer to the Operator-specific
[documentation](../operator/).

## Installation options

Grafana Agent is currently distributed in plain binary form, Docker container images, a Windows installer, a Homebrew package, and a Kubernetes install script. 

The following architectures receive active support.

 - macOS: Intel Mac or Apple Silicon 
 - Windows: A x64 machine 
 - Linux: AMD64, ARM64, ARMv6, or ARMv7 machines
 - FreeBSD: A AMD64 machine 

In addition, best-effort support is provided for Linux: ppc64le.

Choose from the following platforms and installation options according to which suits your use case best.

### Kubernetes

Deploy Kubernetes manifests from the [`kubernetes` directory](https://github.com/grafana/agent/tree/main/production/kubernetes).
You can manually modify the Kubernetes manifests by downloading them. These manifests do not include Grafana Agent configuration files. 

For sample configuration files, refer to the Grafana Cloud Kubernetes quick start guide: https://grafana.com/docs/grafana-cloud/kubernetes/agent-k8s/.

Advanced users can use the Grafana Agent Operator to deploy the Grafana Agent on Kubernetes.

### Docker

Refer to [Install Grafana Agent on Docker]({{< relref "./install-agent-docker.md" >}}).

### Windows

Refer to [Install Grafana Agent on Windows]({{< relref "./install-agent-on-windows.md" >}}).

### Binary

Refer to [Install the Grafana Agent binary]({{< relref "./install-agent-binary.md" >}}).

### macOS

Refer to [Install Grafana Agent on macOS]({{< relref "./install-agent-macos.md" >}}).

### Grafana Cloud

Use the Grafana Agent [Kubernetes quickstarts](https://grafana.com/docs/grafana-cloud/kubernetes/agent-k8s/) or follow instructions for installing the Grafana Agent in the [Walkthrough](https://grafana.com/docs/grafana-cloud/quickstart/agent_linuxnode/).

### Tanka

For more information, refer to the [Tanka](https://tanka.dev) configurations in our [`production/`](https://github.com/grafana/agent/tree/main/production/tanka/grafana-agent) directory.
'''
'''--- docs/sources/set-up/install-agent-binary.md ---
---
aliases:
- /docs/agent/latest/set-up/install-agent-binary/
title: Install the Grafana Agent binary
weight: 140
---

## Install the Grafana Agent binary

Install Grafana Agent and get it up and running using a binary file. 

### Overview
Binary executables are provided for the most common operating systems. Choose the binary from the Assets list on the Releases page that matches your operating system. 

ppc64le builds are currently considered secondary release targets and do not have the same level of support and testing as other platforms.

### Steps

1. Navigate to [Releases](https://github.com/grafana/agent/releases).
   
   This page includes instructions for downloading static binaries that are published with every release. These releases contain binary executables for Windows, Linux and macOS.

1. Scroll down to the **Assets** section.
1. Download the version that matches your operating system.
1. Extract the package contents into a directory.
1. Enter `chmod +x file name` in your command line to check that it is executable.

'''
'''--- docs/sources/set-up/install-agent-docker.md ---
---
aliases:
- /docs/agent/latest/set-up/install-agent-docker/
title: Run Grafana Agent on Docker
weight: 110
---

## Run Grafana Agent on Docker

Install Grafana Agent and get it up and running on Docker.

### Before you begin

 - Ensure that you have Docker installed.  
 - Ensure that you have created a configuration file. In the case of Docker, you install and run the Grafana Agent with a single command. You therefore need to create a configuration file before running Grafana Agent on Docker. For more information on creating a configuration file, refer to [Create a configuration file]({{< relref "../configuration/create-config-file/" >}}).

### Steps

1. Copy and paste the following commands into your command line.
```
docker run \
  -v /tmp/agent:/etc/agent/data \
  -v /path/to/config.yaml:/etc/agent/agent.yaml \
  grafana/agent:v0.26.1
```

2.  Replace `/tmp/agent` with the folder you want to store WAL data in.
   
    WAL data is where metrics are stored before they are sent to Prometheus. Old WAL data is cleaned up every hour and is used for recovery if the process happens to crash.

3. Replace `/path/to/config.yaml` with a path pointing to a valid configuration file.

Note that using paths on your host machine must be exposed to the Docker
container through a bind mount for the flags to work properly.

### Result

Docker containers run the Grafana Agent using this configuration file.

   

'''
'''--- docs/sources/set-up/install-agent-macos.md ---
---
aliases:
- /docs/agent/latest/set-up/install-agent-macos/
title: Install Grafana Agent on macOS
weight: 130
---
## Install Grafana Agent on macOS

Install Grafana Agent and get it up and running on macOS. 

### Overview
Use Homebrew to install the most recent released version of Grafana using the Homebrew package. You can also install Grafana Agent on macOS using the macOS binary.

### Steps

1. Open a terminal and enter:
   
   ```
   brew update
   brew install grafana-agent
   ```
   
   The brew page downloads and enters the files into:
- /usr/local/Cellar/grafana-agent/[version] (Homebrew v2)
- /opt/homebrew/Cellar/grafana-agent/[version] (Homebrew v3)
  
2. Start Grafana Agent using the command:

    ` brew services start grafana-agent`

    The Grafana Agent configuration file can be found at `$(brew --prefix)/etc/grafana-agent/config.yml`.

3. Enter the following command to upgrade Grafana Agent:

    `brew upgrade grafana-agent`.

    

   
'''
'''--- docs/sources/set-up/install-agent-on-windows.md ---
---
aliases:
- /docs/agent/latest/set-up/install-agent-on-windows/
title: Install Grafana Agent on Windows
weight: 120
---

# Install Grafana Agent on Windows

Install Grafana Agent and get it up and running on Windows.

### Steps

1.  Navigate to [Releases](https://github.com/grafana/agent/releases).
   
    This page includes instructions for downloading static binaries that are published with every release. These releases contain the plain binary alongside system packages for Windows, Red Hat, and Debian Linux.
1. Scroll down to the **Assets** section.
1. Download `grafana-agent-installer.exe`.
   
   You can also download the `grafana-agent-installer.exe` asset directly from https://github.com/grafana/agent/releases/latest/download/grafana-agent-installer.exe.

    Grafana Agent is installed into the default directory `C:\Program Files\Grafana Agent`.
    The [windows_exporter integration](https://github.com/prometheus-community/windows_exporter)
    can be enabled with all default windows_exporter options.

1. Check you can access `http://localhost:12345/-/healthy` and `http://localhost:12345/agent/api/v1/metrics/targets`.

1. (Optional): You can adjust `C:\Program Files\Grafana Agent\agent-config.yaml` to meet your specific needs. After changing the configuration file, restart the Grafana Agent service to load changes to the configuration.
   
   Existing configuration files are kept when re-installing or upgrading the Grafana Agent.

## Silent Installation

You can install Grafana Agent using silent installation as follows.

1. Enter the following in your command line.
   `grafana-agent-installer.exe /S /EnableExporter true /Username xyz /Password password /Url "http://example.com" `

1. Set EnableExporter to enable Windows Exporter. The default is `false`.
1. Enter a Username, Password, and URL to set the global remote_write configuration. 
   
  You do not need to set username, password, and URL if you are not using remote_write. 
  If you are using powershell, use triple quotes `"""http://example.com"""` around the URL parameter around the url parameter.

## Security

A configuration file for the Grafana Agent is provided by default at `C:\Program Files\Grafana Agent`. Depending on your configuration, you can modify the default permissions of the file or move it to another directory.

If you change the location of the configuration file, ensure you complete the following steps.

1. Update the Grafana Agent service to load the new path. 
1. Run the following in an elevated prompt, replacing `<new_path>` with the full path holding `agent-config.yaml`:

```
sc config "Grafana Agent" binpath= "<installed_directory>\agent-windows-amd64.exe -config.file=\"<new_path>\agent-config.yaml\""
```

## Uninstall Grafana Agent

If you installed Grafana Agent using the Windows installer, you can uninstall it using Windows' Remove Programs or `C:\Program Files\Grafana Agent\uninstaller.exe`. 
Uninstalling Grafana Agent will stop the service and remove it from disk. This includes any configuration files in the installation directory. 
Grafana Agent can also be silently uninstalled by executing `uninstall.exe /S` while running as Administrator.

## Logs

When Grafana Agent runs as a Windows Service, it writes logs to Windows Event Logs. When running as executable, Grafana Agent will write to standard out. The logs will be written with the event source name of `Grafana Agent`.

## Pushing Windows logs to Grafana Loki

Grafana Agent can use the embedded [promtail](https://grafana.com/docs/loki/latest/clients/promtail/) to push Windows Event Logs to [Grafana Loki](https://github.com/grafana/loki). Example configuration below:

```yaml
server:
  log_level: debug
logs:
  # Choose a directory to save the last read position of log files at.
  # This directory will be created if it doesn't already exist.
  positions_directory: "C:\\path\\to\\directory"
  configs:
    - name: windows
      # Loki endpoint to push logs to
      clients:
        - url: https://example.com
      scrape_configs:
      - job_name: windows
        windows_events:
          # Note the directory structure must already exist but the file will be created on demand
          bookmark_path: "C:\\path\\to\\bookmark\\directory\\bookmark.xml"
          use_incoming_timestamp: false
          eventlog_name: "Application"
          # Filter for logs
          xpath_query: '*'
          labels:
            job: windows
```

Additional windows_events configuration details can be found [here](https://grafana.com/docs/loki/latest/clients/promtail/configuration/#windows_events).

'''
'''--- docs/sources/set-up/quick-starts.md ---
---
aliases:
- /docs/agent/latest/set-up/quick-starts/
title: Grafana Agent quick starts
weight: 150
---
## Grafana Agent quick starts

The following quick starts help you get up and running with Grafana Agent. Youll learn how to send your metrics, logs, and traces to the Grafana Stack or Grafana Cloud.

### Grafana Stack quick starts

 - [Send metrics to Mimir](https://grafana.com/docs/mimir/latest/operators-guide/getting-started/) using Grafana Agent.

 - [Send traces to Tempo](https://grafana.com/docs/tempo/latest/getting-started/#2-pipeline-grafana-agent) using Grafana Agent.

 - [Send logs to Loki](https://grafana.com/docs/grafana-cloud/logs/collect-logs-with-agent/?pg=hp&plcmt=lt-box-traces) using Grafana Agent.

### Grafana Cloud quick starts

 - [Grafana Agent for Grafana Cloud](https://grafana.com/docs/grafana-cloud/agent/).
- [Monitoring a Linux host](https://grafana.com/docs/grafana-cloud/quickstart/agent_linuxnode/) using the Linux Node integration.

 - [Grafana Agent Kubernetes quickstarts](https://grafana.com/docs/grafana-cloud/kubernetes/agent-k8s/).

'''
'''--- docs/sources/upgrade-guide/_index.md ---
---
aliases:
- /docs/agent/latest/upgrade-guide/
title: Upgrade guide
weight: 800
---

# Upgrade guide

This guide describes all breaking changes that have happened in prior
releases and how to migrate to newer versions.

## Unreleased Changes

These changes will come in a future version.

### Breaking change: Deprecated YAML fields in `server` block removed

The YAML fields which were first [deprecated in the v0.24.0
release](#deprecation-on-yaml-fields-in-server-block-that-have-flags) have now
been removed, replaced by equivalent command line flags. Please refer to the
original deprecation notice for instructions for how to migrate to the command
line flags.

### Breaking change: Reconcile sampling policies between Agent and OTel

Configuring sampling policies in the `tail_sampling` block of the `traces`
block has been changed to be equal with the upstream configuration of the OTel
processor. It now requires that the policy `type` is specified.

Old configuration:

```yaml
traces:
  configs:
    - name: default
    ...
    tail_sampling:
      policies:
      - latency:
          threshold_ms: 100
```

New configuration:

```yaml
traces:
  configs:
    - name: default
    ...
    tail_sampling:
      policies:
      - type: latency
        latency:
          threshold_ms: 100
```

## v0.24.0

### Breaking change: Integrations renamed when `integrations-next` feature flag is used

This change only applies to users utilizing the `integrations-next` feature
flag. Nothing is changed for configuring integrations when the feature flag is
not used.

Most `integrations-next` integrations have been renamed to describe what
telemetry data they generate instead of the projects they are powered by.

* `consul_exporter` is now `consul`
* `dnsmasq_exporter` is now `dnsmasq`
* `elasticsearch_exporter` is now `elasticsearch`
* `github_exporter` is now `github`
* `kafka_exporter` is now `kafka`
* `memcached_exporter` is now `memcached`
* `mongodb_exporter` is now `mongodb`
* `mysqld_exporter` is now `mysql`
  * Note that it is `mysql` and _not_ `mysqld`
* `postgres_exporter` is now `postgres`
* `process_exporter` is now `process`
* `redis_exporter` is now `redis`
* `statsd_exporter` is now `statsd`
* `windows_exporter` is now `windows`

Keys in the `integrations` config block have changed to match the above:

* `integrations.consul_exporter_configs` is now `integrations.consul_configs`
* `integrations.dnsmasq_exporter_configs` is now `integrations.dnsmasq_configs`
* `integrations.elasticsearch_exporter_configs` is now `integrations.elasticsearch_configs`
* `integrations.github_exporter_configs` is now `integrations.github_configs`
* `integrations.kafka_exporter_configs` is now `integrations.kafka_configs`
* `integrations.memcached_exporter_configs` is now `integrations.memcached_configs`
* `integrations.mongodb_exporter_configs` is now `integrations.mongodb_configs`
* `integrations.mysqld_exporter_configs` is now `integrations.mysql_configs`
* `integrations.postgres_exporter_configs` is now `integrations.postgres_configs`
* `integrations.process_exporter` is now `integrations.process`
* `integrations.redis_exporter_configs` is now `integrations.redis_configs`
* `integrations.statsd_exporter` is now `integrations.statsd`
* `integrations.windows_exporter` is now `integrations.windows`

Integrations not listed here have not changed; `node_exporter` still has the
same name.

This change propagates to the label values generated by these integrations. For
example, `job="integrations/redis_exporter` will now be `job="redis"`.

### Breaking change: Grafana Agent Operator supported Agent versions

The v0.24.0 release of Grafana Agent Operator can no longer deploy versions of
Grafana Agent prior to v0.24.0.

### Change: Separating YAML and command line flags

As of this release, we are starting to separate what can be configured within
the YAML file, and what can be configured by command line flag. Previously,
there was a lot of overlap: many things could be set by both command line flag
and configuration file, with command line flags taking precedence.

The configuration file will be used for settings that can be updated at runtime
using the `/-/reload` endpoint or sending SIGHUP. Meanwhile, command line flags
will be used for settings that must remain consistent throughout the process
lifetime, such as the HTTP listen port.

This conceptual change will require some number of breaking changes. This
release focuses on the `server` block of the YAML, which has historically
caused the most issues with the `/-/reload` endpoint working correctly.

There may be more breaking changes in the future as we identify more settings
that must be static and moved to flags. These changes will either be moving a
YAML field to a flag or moving a flag to a YAML field. After we are done with
this migration, there will be no overlap between flags and the YAML file.

### Deprecation on YAML fields in `server` block that have flags

The `server` block is the most impacted by the separation of flags/fields.
Instead of making a breaking change immediately, we are deprecating these
fields.

> **NOTE**: These deprecated fields will be removed in the v0.26.0 release. We
> will communicate when other deprecated features will be removed when a
> timeline is established.

The following fields are now deprecated in favor of command line flags:

* `server.register_instrumentation`
* `server.graceful_shutdown_timeout`
* `server.log_source_ips_enabled`
* `server.log_source_ips_header`
* `server.log_source_ips_regex`
* `server.http_listen_network`
* `server.http_listen_address`
* `server.http_listen_port`
* `server.http_listen_conn_limit`
* `server.http_server_read_timeout`
* `server.http_server_write_timout`
* `server.http_server_idle_timeout`
* `server.grpc_listen_network`
* `server.grpc_listen_address`
* `server.grpc_listen_port`
* `server.grpc_listen_conn_limit`
* `server.grpc_server_max_recv_msg_size`
* `server.grpc_server_max_send_msg_size`
* `server.grpc_server_max_concurrent_streams`
* `server.grpc_server_max_connection_idle`
* `server.grpc_server_max_connection_age`
* `server.grpc_server_max_connection_age_grace`
* `server.grpc_server_keepalive_time`
* `server.grpc_server_keepalive_timeout`
* `server.grpc_server_min_time_between_pings`
* `server.grpc_server_ping_without_stream_allowed`

This is most of the fields; the remaining non-deprecated fields are
`server.log_level`, `server.log_format`, `server.http_tls_config`, and
`server.grpc_tls_config`, which support dynamic updating.

### Breaking change: Removing support for dynamically updating deprecated server fields

`/-/reload` will now fail if any of the deprecated server block fields have
changed. It is still valid to change a non-deprecated field (i.e., changing the
log level).

### Breaking change: Server-specific command line flags have changed

The following flags are _new_:

* `-server.http.enable-tls`
* `-server.grpc.enable-tls`
* `-server.http.address`
* `-server.grpc.address`

The following flags have been _removed_:

* `-log.level` (replacement: use YAML field `server.log_level`)
* `-log.format` (replacement: use YAML field `server.log_format`)
* `-server.http-tls-cert-path` (replacement: use YAML field `server.http_tls_config`)
* `-server.http-tls-key-path` (replacement: use YAML field `server.http_tls_config`)
* `-server.http-tls-client-auth` (replacement: use YAML field `server.http_tls_config`)
* `-server.http-tls-ca-path` (replacement: use YAML field `server.http_tls_config`)
* `-server.grpc-tls-cert-path` (replacement: use YAML field `server.grpc_tls_config`)
* `-server.grpc-tls-key-path` (replacement: use YAML field `server.grpc_tls_config`)
* `-server.grpc-tls-client-auth` (replacement: use YAML field `server.grpc_tls_config`)
* `-server.grpc-tls-ca-path` (replacement: use YAML field `server.grpc_tls_config`)
* `-server.http-listen-address` (replacement: use the new `-server.http.address` flag, which combines host and port)
* `-server.http-listen-port` (replacement: use the new  `-server.http.address` flag, which combines host and port)
* `-server.grpc-listen-address` (replacement: use the new `-server.grpc.address` flag, which combines host and port)
* `-server.grpc-listen-port` (replacement: use the new `-server.grpc.address` flag, which combines host and port)
* `-server.path-prefix` (no replacement; this flag was unsupported and caused undefined behavior when set)

The following flags have been _renamed_:

* `-server.log-source-ips-enabled` has been renamed to `-server.log.source-ips.enabled`
* `-server.log-source-ips-header` has been renamed to `-server.log.source-ips.header`
* `-server.log-source-ips-regex` has been renamed to `-server.log.source-ips.regex`
* `-server.http-listen-network` has been renamed to `-server.http.network`
* `-server.http-conn-limit` has been renamed to `-server.http.conn-limit`
* `-server.http-read-timeout` has been renamed to `-server.http.read-timeout`
* `-server.http-write-timeout` has been renamed to `-server.http.write-timeout`
* `-server.http-idle-timeout` has been renamed to `-server.http.idle-timeout`
* `-server.grpc-listen-network` has been renamed to `-server.grpc.network`
* `-server.grpc-conn-limit` has been renamed to `-server.grpc.conn-limit`
* `-server.grpc-max-recv-msg-size-bytes` has been renamed to `-server.grpc.max-recv-msg-size-bytes`
* `-server.grpc-max-send-msg-size-bytes` has been renamed to `-server.grpc.max-send-msg-size-bytes`
* `-server.grpc-max-concurrent-streams` has been renamed to `-server.grpc.max-concurrent-streams`

### Breaking change: New TLS flags required for enabling TLS

The two new flags, `-server.http.enable-tls` and `-server.grpc.enable-tls` now
must be provided for TLS support to be enabled.

This is a change over the previous behavior where TLS was automatically enabled
when a certificate pair was provided.

### Breaking change: Default HTTP/gRPC address changes

The HTTP and gRPC listen addresses now default to `127.0.0.1:12345` and
`127.0.0.1:12346` respectively.

If running inside of a container, you must change these to `0.0.0.0` to
externally communicate with the agent's HTTP server.

The listen addresses may be changed via `-server.http.address` and
`-server.grpc.address` respectively.

### Breaking change: Removal of `-reload-addr` and `-reload-port` flags

The `-reload-addr` and `-reload-port` flags have been removed. They were
initially added to workaround an issue where reloading a changed server block
would cause the primary HTTP server to restart. As the HTTP server settings are
now static, this can no longer happen, and as such the flags have been removed.

### Change: In-memory autoscrape for integrations-next

This change is only relevant to those using the `integrations-next` feature flag.

In-memory connections will now be used for autoscraping-enabled integrations.
This is a change over the previous behavior where autoscraping integrations
would connect to themselves over the network. As a result of this change, the
`integrations.client_config` field is no longer necessary and has been removed.

## v0.22.0

### `node_exporter` integration deprecated field names

The following field names for the `node_exporter` integration are now deprecated:

* `netdev_device_whitelist` is deprecated in favor of `netdev_device_include`.
* `netdev_device_blacklist` is deprecated in favor of `netdev_device_exclude`.
* `systemd_unit_whitelist` is deprecated in favor of `systemd_unit_include`.
* `systemd_unit_blacklist` is deprecated in favor of `systemd_unit_exclude`.
* `filesystem_ignored_mount_points` is deprecated in favor of
  `filesystem_mount_points_exclude`.
* `filesystem_ignored_fs_types` is deprecated in favor of
  `filesystem_fs_types_exclude`.

This change aligns with the equivalent flag names also being deprecated in the
upstream node_exporter.

Support for the old field names will be removed in a future version. A warning
will be logged if using the old field names when the integration is enabled.

## v0.21.2, v0.20.1

### Disabling of config retrieval enpoints

These two patch releases, as part of a fix for
[CVE-2021-41090](https://github.com/grafana/agent/security/advisories/GHSA-9c4x-5hgq-q3wh),
disable the `/-/config` and `/agent/api/v1/configs/{name}` endpoints by
default. Pass the `--config.enable-read-api` flag at the command line to
re-enable them.

## v0.21.0

### Integrations: Change in how instance labels are handled (Breaking change)

Integrations will now use a SUO-specific `instance` label value. Integrations
that apply to a whole machine or agent will continue to use `<agent machine
hostname>:<agent listen port>`, but integrations that connect to an external
system will now infer an appropriate value based on the config for that specific
integration. Please refer to the documentation for each integration for which
defaults are used.

*Note:* In some cases, a default value for `instance` cannot be inferred. This
is the case for mongodb_exporter and postgres_exporter if more than one SUO is
being connected to. In these cases, the instance value can be manually set by
configuring the `instance` field on the integration. This can also be useful if
two agents infer the same value for instance for the same integration.

As part of this change, the `agent_hostname` label is permanently affixed to
self-scraped integrations and cannot be disabled. This disambigutates multiple
agents using the same instance label for an integration, and allows users to
identify which agents need to be updated with an override for `instance`.

Both `use_hostname_label` and `replace_instance_label` are now both deprecated
and ignored from the YAML file, permanently treated as true. A future release
will remove these fields, causing YAML errors on load instead of being silently
ignored.

## v0.20.0

### Traces: Changes to receiver's TLS config (Breaking change).

Upgrading to OpenTelemetry v0.36.0 contains a change in the receivers TLS config.
TLS params have been changed from being squashed to being in its own block.
This affect the jaeger receiver's `remote_sampling` config.

Example old config:

```yaml
receivers:
  jaeger:
    protocols:
      grpc: null,
    remote_sampling:
      strategy_file: <file_path>
      insecure: true
```

Example new config:

```yaml
receivers:
  jaeger:
    protocols:
      grpc: null,
    remote_sampling:
      strategy_file: <file_path>
      tls:
        insecure: true
```

### Traces: push_config is no longer supported (Breaking change)

`push_config` was deprecated in favor of `remote_write` in v0.14.0, while
maintaining backwards compatibility.
Refer to the [deprecation announcement](#tempo-push_config-deprecation) for how to upgrade.

### Traces: legacy OTLP gRPC port no longer default port

OTLP gRPC receivers listen at port `4317` by default, instead of at port `55680`.
This goes in line with OTLP legacy port deprecation.

To upgrade, point the client instrumentation push endpoint to `:4317` if using
the default OTLP gRPC endpoint.

## v0.19.0

### Traces: Deprecation of "tempo" in config and metrics. (Deprecation)

The term `tempo` in the config has been deprecated of favor of `traces`. This
change is to make intent clearer.

Example old config:

```yaml
tempo:
  configs:
    - name: default
      receivers:
        jaeger:
          protocols:
            thrift_http:
```

Example of new config:
```yaml
traces:
  configs:
    - name: default
      receivers:
        jaeger:
          protocols:
            thrift_http:
```

Any tempo metrics have been renamed from `tempo_*` to `traces_*`.

### Tempo: split grouping by trace from tail sampling config (Breaking change)

Load balancing traces between agent instances has been moved from an embedded
functionality in tail sampling to its own configuration block.
This is done due to more processor benefiting from receiving consistently
receiving all spans for a trace in the same agent to be processed, such as
service graphs.

As a consequence, `tail_sampling.load_balancing` has been deprecated in favor of
a `load_balancing` block. Also, `port` has been renamed to `receiver_port` and
moved to the new `load_balancing` block.

Example old config:

```yaml
tail_sampling:
  policies:
    - always_sample:
  port: 4318
  load_balancing:
    exporter:
      insecure: true
    resolver:
      dns:
        hostname: agent
        port: 4318
```

Example new config:

```yaml
tail_sampling:
  policies:
    - always_sample:
load_balancing:
  exporter:
    insecure: true
  resolver:
    dns:
      hostname: agent
      port: 4318
  receiver_port: 4318
```

### Operator: Rename of Prometheus to Metrics (Breaking change)

As a part of the deprecation of "Prometheus," all Operator CRDs and fields with
"Prometheus" in the name have changed to "Metrics."

This includes:

- The `PrometheusInstance` CRD is now `MetricsInstance` (referenced by
  `metricsinstances` and not `metrics-instances` within ClusterRoles).
- The `Prometheus` field of the `GrafanaAgent` resource is now `Metrics`
- `PrometheusExternalLabelName` is now `MetricsExternalLabelName`

This is a hard breaking change, and all fields must change accordingly for the
operator to continue working.

Note that old CRDs with the old hyphenated names must be deleted (`kubectl
delete crds/{grafana-agents,prometheus-instances}`) for ClusterRoles to work
correctly.

To do a zero-downtime upgrade of the Operator when there is a breaking change,
refer to the new `agentctl operator-detatch` command: this will iterate through
all of your objects and remove any OwnerReferences to a CRD, allowing you to
delete your Operator CRDs or CRs.

### Operator: Rename of CRD paths (Breaking change)

`prometheus-instances` and `grafana-agents` have been renamed to
`metricsinstances` and `grafanaagents` respectively. This is to remain
consistent with how Kubernetes names multi-word objects.

As a result, you will need to update your ClusterRoles to change the path of
resources.

To do a zero-downtime upgrade of the Operator when there is a breaking change,
refer to the new `agentctl operator-detatch` command: this will iterate through
all of your objects and remove any OwnerReferences to a CRD, allowing you to
delete your Operator CRDs or CRs.

Example old ClusterRole:

```yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: grafana-agent-operator
rules:
- apiGroups: [monitoring.grafana.com]
  resources:
  - grafana-agents
  - prometheus-instances
  verbs: [get, list, watch]
```

Example new ClusterRole:

```yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: grafana-agent-operator
rules:
- apiGroups: [monitoring.grafana.com]
  resources:
  - grafanaagents
  - metricsinstances
  verbs: [get, list, watch]
```

### Metrics: Deprecation of "prometheus" in config. (Deprecation)

The term `prometheus` in the config has been deprecated of favor of `metrics`. This
change is to make it clearer when referring to Prometheus or another
Prometheus-like database, and configuration of Grafana Agent to send metrics to
one of those systems.

Old configs will continue to work for now, but support for the old format will
eventually be removed. To migrate your config, change the `prometheus` key to
`metrics`.

Example old config:

```yaml
prometheus:
  configs:
    - name: default
      host_filter: false
      scrape_configs:
        - job_name: local_scrape
          static_configs:
            - targets: ['127.0.0.1:12345']
              labels:
                cluster: 'localhost'
      remote_write:
        - url: http://localhost:9009/api/prom/push
```

Example new config:

```yaml
metrics:
  configs:
    - name: default
      host_filter: false
      scrape_configs:
        - job_name: local_scrape
          static_configs:
            - targets: ['127.0.0.1:12345']
              labels:
                cluster: 'localhost'
      remote_write:
        - url: http://localhost:9009/api/prom/push
```

### Tempo: prom_instance rename (Breaking change)

As part of `prometheus` being renamed to `metrics`, the spanmetrics
`prom_instance` field has been renamed to `metrics_instance`. This is a breaking
change, and the old name will no longer work.

Example old config:

```yaml
tempo:
  configs:
  - name: default
    spanmetrics:
      prom_instance: default
```

Example new config:

```yaml
tempo:
  configs:
  - name: default
    spanmetrics:
      metrics_instance: default
```

### Logs: Deprecation of "loki" in config. (Deprecation)

The term `loki` in the config has been deprecated of favor of `logs`. This
change is to make it clearer when referring to Grafana Loki, and
configuration of Grafana Agent to send logs to Grafana Loki.

Old configs will continue to work for now, but support for the old format will
eventually be removed. To migrate your config, change the `loki` key to `logs`.

Example old config:

```yaml
loki:
  positions_directory: /tmp/loki-positions
  configs:
  - name: default
    clients:
      - url: http://localhost:3100/loki/api/v1/push
    scrape_configs:
    - job_name: system
      static_configs:
      - targets: ['localhost']
        labels:
          job: varlogs
          __path__: /var/log/*log
```

Example new config:

```yaml
logs:
  positions_directory: /tmp/loki-positions
  configs:
  - name: default
    clients:
      - url: http://localhost:3100/loki/api/v1/push
    scrape_configs:
    - job_name: system
      static_configs:
      - targets: ['localhost']
        labels:
          job: varlogs
          __path__: /var/log/*log
```

#### Tempo: Deprecation of "loki" in config. (Deprecation)

As part of the `loki` to `logs` rename, parts of the automatic_logging component
in Tempo have been updated to refer to `logs_instance` instead.

Old configurations using `loki_name`, `loki_tag`, or `backend: loki` will
continue to work as of this version, but support for the old config format
will eventually be removed.

Example old config:

```yaml
tempo:
  configs:
  - name: default
    automatic_logging:
      backend: loki
      loki_name: default
      spans: true
      processes: true
      roots: true
    overrides:
      loki_tag: tempo
```

Example new config:

```yaml
tempo:
  configs:
  - name: default
    automatic_logging:
      backend: logs_instance
      logs_instance_name: default
      spans: true
      processes: true
      roots: true
    overrides:
      logs_instance_tag: tempo
```

## v0.18.0

### Tempo: Remote write TLS config

Tempo `remote_write` now supports configuring TLS settings in the trace
exporter's client. `insecure_skip_verify` is moved into this setting's block.

Old configurations with `insecure_skip_verify` outside `tls_config` will continue
to work as of this version, but support will eventually be removed.
If both `insecure_skip_verify` and `tls_config.insecure_skip_verify` are used,
then the latter take precedence.

Example old config:

```
tempo:
  configs:
    - name: default
      remote_write:
        - endpoint: otel-collector:55680
          insecure: true
          insecure_skip_verify: true
```

Example new config:

```
tempo:
  configs:
    - name: default
      remote_write:
        - endpoint: otel-collector:55680
          insecure: true
          tls_config:
            insecure_skip_verify: true
```

## v0.15.0

### Tempo: `automatic_logging` changes

Tempo automatic logging previously assumed that the operator wanted to log
to a Loki instance. With the addition of an option to log to stdout a new
field is required to maintain the old behavior.

Example old config:

```
tempo:
  configs:
  - name: default
    automatic_logging:
      loki_name: <some loki instance>
```

Example new config:

```
tempo:
  configs:
  - name: default
    automatic_logging:
      backend: loki
      loki_name: <some loki instance>
```

## v0.14.0

### Scraping Service security change

v0.14.0 changes the default behavior of the scraping service config management
API to reject all configuration files that read credentials from a file on disk.
This prevents malicious users from crafting an instance config file that read
arbitrary files on disk and send their contents to remote endpoints.

To revert to the old behavior, add `dangerous_allow_reading_files: true` in your
`scraping_service` config.

Example old config:

```yaml
prometheus:
  scraping_service:
    # ...
```

Example new config:

```yaml
prometheus:
  scraping_service:
    dangerous_allow_reading_files: true
    # ...
```

### SigV4 config change

v0.14.0 updates the internal Prometheus dependency to 2.26.0, which includes
native support for SigV4, but uses a slightly different configuration structure
than the Grafana Agent did.

To migrate, remove the `enabled` key from your `sigv4` configs. If `enabled` was
the only key, define sigv4 as an empty object: `sigv4: {}`.

Example old config:

```yaml
sigv4:
  enabled: true
  region: us-east-1
```

Example new config:

```yaml
sigv4:
  region: us-east-1
```

### Tempo: `push_config` deprecation

`push_config` is now deprecated in favor of a `remote_write` array which allows for sending spans to multiple endpoints.
`push_config` will be removed in a future release, and it is recommended to migrate to `remote_write` as soon as possible.

To migrate, move the batch options outside the `push_config` block.
Then, add a `remote_write` array and move the remaining of your `push_config` block inside it.

Example old config:

```yaml
tempo:
  configs:
    - name: default
      receivers:
        otlp:
          protocols:
            gpc:
      push_config:
        endpoint: otel-collector:55680
        insecure: true
        batch:
          timeout: 5s
          send_batch_size: 100
```

Example migrated config:

```yaml
tempo:
  configs:
    - name: default
      receivers:
        otlp:
          protocols:
            gpc:
      remote_write:
        - endpoint: otel-collector:55680
          insecure: true
      batch:
        timeout: 5s
        send_batch_size: 100
```

## v0.12.0

v0.12.0 had two breaking changes: the `tempo` and `loki` sections have been changed to require a list of `tempo`/`loki` configs rather than just one.

### Tempo Config Change

The Tempo config (`tempo` in the config file) has been changed to store
configs within a `configs` list. This allows for defining multiple Tempo
instances for collecting traces and forwarding them to different OTLP
endpoints.

To migrate, add a `configs:` array and move your existing config inside of it.
Give the element a `name: default` field.

Each config must have a unique non-empty name. `default` is recommended for users
that don't have other configs. The name of the config will be added as a
`tempo_config` label for metrics.

Example old config:

```yaml
tempo:
  receivers:
    jaeger:
      protocols:
        thrift_http:
  attributes:
    actions:
    - action: upsert
      key: env
      value: prod
  push_config:
    endpoint: otel-collector:55680
    insecure: true
    batch:
      timeout: 5s
      send_batch_size: 100
```

Example migrated config:

```yaml
tempo:
  configs:
  - name: default
    receivers:
      jaeger:
        protocols:
          thrift_http:
    attributes:
      actions:
      - action: upsert
        key: env
        value: prod
    push_config:
      endpoint: otel-collector:55680
      insecure: true
      batch:
        timeout: 5s
        send_batch_size: 100
```

### Loki Promtail Config Change

The Loki Promtail config (`loki` in the config file) has been changed to store
configs within a `configs` list. This allows for defining multiple Loki
Promtail instances for collecting logs and forwarding them to different Loki
servers.

To migrate, add a `configs:` array and move your existing config inside of it.
Give the element a `name: default` field.

Each config must have a unique non-empty name. `default` is recommended for users
that don't have other configs. The name of the config will be added as a
`loki_config` label for Loki Promtail metrics.

Example old config:

```yaml
loki:
  positions:
    filename: /tmp/positions.yaml
  clients:
    - url: http://loki:3100/loki/api/v1/push
  scrape_configs:
  - job_name: system
    static_configs:
      - targets:
        - localhost
        labels:
          job: varlogs
          __path__: /var/log/*log
```

Example migrated config:

```yaml
loki:
  configs:
  - name: default
    positions:
      filename: /tmp/positions.yaml
    clients:
      - url: http://loki:3100/loki/api/v1/push
    scrape_configs:
    - job_name: system
      static_configs:
        - targets:
          - localhost
          labels:
            job: varlogs
            __path__: /var/log/*log
```

'''
'''--- example/docker-compose/README.md ---
# Example

This directory contains a Docker Compose 3 environment that can be used to test
Grafana Agent.

By default, the following services are exposed:

1. Cortex for storing metrics (localhost:9009)
2. Grafana for visualizing telemetry (localhost:3000)
3. Loki for storing logs (localhost:3100)
4. Tempo for storing traces (localhost:3200)
5. Avalanche for a sample /metrics endpoint to scrape (localhost:9001).

Run the following to bring up the environment:

```
docker-compose up -d
```

By default, the Docker Compose environment doesn't include a Grafana Agent
container. This lets you test the agent externally, especially useful when
validating code changes. You can enable the included Grafana Agent by passing
`agent` to the profiles list: `docker compose --profile=agent up -d`. When
running, the Agent exposes its HTTP endpoint at localhost:12345. This address
can be changed with the `--server.http.address` flag (e.g.,
`--server.http.address=127.0.0.1:8000`).

The Docker Compose environment heavily relies on profiles to enable optional
features. You can pass multiple profiles by passing the flag multiple times:
`docker compose --profile agent --profile integrations up -d`.

## Running Integrations

The Docker Compose environment includes example services to point integrations
at (e.g., mysql, redis, consul, etc.). You can run all integrations using the
`integrations` profile, or run individual services with a profile name matching
the integration (i.e., enabling the `dnsmasq_exporter` profile to specifically
enable the dnsmasq service).

Enabling specific integration profiles is useful when you only want to test a
single integration, as the `integrations` profile can be resource intensive.

## Visualizing

Grafana is exposed at `http://localhost:3000`, and includes some useful
dashboards:

* The `Agent` dashboard gives a very high-level overview of running agents.

* The `Agent Prometheus Remote Write` dashboard visualizes the current state of
  writing metrics to Cortex.

* The `Agent Tracing Pipeline` dashbaord visualizes the current state of the
  tracing pipeline (if spans are being processed).

* The `Agent Operational` dashboard shows resource consumption of Grafana
  Agent. Not all panels will have data here, as they rely on metrics from other
  sources (i.e., cAdvisor).

'''
'''--- example/docker-compose/grafana/dashboards/agent-operational.json ---
{
   "annotations": {
      "list": [ ]
   },
   "editable": true,
   "gnetId": null,
   "graphTooltip": 0,
   "hideControls": false,
   "links": [ ],
   "refresh": "30s",
   "rows": [
      {
         "collapse": false,
         "height": "250px",
         "panels": [
            {
               "aliasColors": { },
               "bars": false,
               "dashLength": 10,
               "dashes": false,
               "datasource": "$datasource",
               "fill": 1,
               "id": 1,
               "legend": {
                  "avg": false,
                  "current": false,
                  "max": false,
                  "min": false,
                  "show": true,
                  "total": false,
                  "values": false
               },
               "lines": true,
               "linewidth": 1,
               "links": [ ],
               "nullPointMode": "null as zero",
               "percentage": false,
               "pointradius": 5,
               "points": false,
               "renderer": "flot",
               "seriesOverrides": [ ],
               "spaceLength": 10,
               "span": 2,
               "stack": false,
               "steppedLine": false,
               "targets": [
                  {
                     "expr": "rate(go_gc_duration_seconds_count{cluster=~\"$cluster\", namespace=~\"$namespace\", container=~\"$container\", pod=~\"$pod\"}[5m])",
                     "format": "time_series",
                     "intervalFactor": 2,
                     "legendFormat": "{{pod}}",
                     "legendLink": null,
                     "step": 10
                  }
               ],
               "thresholds": [ ],
               "timeFrom": null,
               "timeShift": null,
               "title": "GCs",
               "tooltip": {
                  "shared": true,
                  "sort": 2,
                  "value_type": "individual"
               },
               "type": "graph",
               "xaxis": {
                  "buckets": null,
                  "mode": "time",
                  "name": null,
                  "show": true,
                  "values": [ ]
               },
               "yaxes": [
                  {
                     "format": "short",
                     "label": null,
                     "logBase": 1,
                     "max": null,
                     "min": 0,
                     "show": true
                  },
                  {
                     "format": "short",
                     "label": null,
                     "logBase": 1,
                     "max": null,
                     "min": null,
                     "show": false
                  }
               ]
            },
            {
               "aliasColors": { },
               "bars": false,
               "dashLength": 10,
               "dashes": false,
               "datasource": "$datasource",
               "fill": 1,
               "id": 2,
               "legend": {
                  "avg": false,
                  "current": false,
                  "max": false,
                  "min": false,
                  "show": true,
                  "total": false,
                  "values": false
               },
               "lines": true,
               "linewidth": 1,
               "links": [ ],
               "nullPointMode": "null as zero",
               "percentage": false,
               "pointradius": 5,
               "points": false,
               "renderer": "flot",
               "seriesOverrides": [ ],
               "spaceLength": 10,
               "span": 2,
               "stack": false,
               "steppedLine": false,
               "targets": [
                  {
                     "expr": "go_memstats_heap_inuse_bytes{cluster=~\"$cluster\", namespace=~\"$namespace\", container=~\"$container\", pod=~\"$pod\"}",
                     "format": "time_series",
                     "intervalFactor": 2,
                     "legendFormat": "{{pod}}",
                     "legendLink": null,
                     "step": 10
                  }
               ],
               "thresholds": [ ],
               "timeFrom": null,
               "timeShift": null,
               "title": "Go Heap",
               "tooltip": {
                  "shared": true,
                  "sort": 2,
                  "value_type": "individual"
               },
               "type": "graph",
               "xaxis": {
                  "buckets": null,
                  "mode": "time",
                  "name": null,
                  "show": true,
                  "values": [ ]
               },
               "yaxes": [
                  {
                     "format": "decbytes",
                     "label": null,
                     "logBase": 1,
                     "max": null,
                     "min": 0,
                     "show": true
                  },
                  {
                     "format": "short",
                     "label": null,
                     "logBase": 1,
                     "max": null,
                     "min": null,
                     "show": false
                  }
               ]
            },
            {
               "aliasColors": { },
               "bars": false,
               "dashLength": 10,
               "dashes": false,
               "datasource": "$datasource",
               "fill": 1,
               "id": 3,
               "legend": {
                  "avg": false,
                  "current": false,
                  "max": false,
                  "min": false,
                  "show": true,
                  "total": false,
                  "values": false
               },
               "lines": true,
               "linewidth": 1,
               "links": [ ],
               "nullPointMode": "null as zero",
               "percentage": false,
               "pointradius": 5,
               "points": false,
               "renderer": "flot",
               "seriesOverrides": [ ],
               "spaceLength": 10,
               "span": 2,
               "stack": false,
               "steppedLine": false,
               "targets": [
                  {
                     "expr": "go_goroutines{cluster=~\"$cluster\", namespace=~\"$namespace\", container=~\"$container\", pod=~\"$pod\"}",
                     "format": "time_series",
                     "intervalFactor": 2,
                     "legendFormat": "{{pod}}",
                     "legendLink": null,
                     "step": 10
                  }
               ],
               "thresholds": [ ],
               "timeFrom": null,
               "timeShift": null,
               "title": "Goroutines",
               "tooltip": {
                  "shared": true,
                  "sort": 2,
                  "value_type": "individual"
               },
               "type": "graph",
               "xaxis": {
                  "buckets": null,
                  "mode": "time",
                  "name": null,
                  "show": true,
                  "values": [ ]
               },
               "yaxes": [
                  {
                     "format": "short",
                     "label": null,
                     "logBase": 1,
                     "max": null,
                     "min": 0,
                     "show": true
                  },
                  {
                     "format": "short",
                     "label": null,
                     "logBase": 1,
                     "max": null,
                     "min": null,
                     "show": false
                  }
               ]
            },
            {
               "aliasColors": { },
               "bars": false,
               "dashLength": 10,
               "dashes": false,
               "datasource": "$datasource",
               "fill": 1,
               "id": 4,
               "legend": {
                  "avg": false,
                  "current": false,
                  "max": false,
                  "min": false,
                  "show": true,
                  "total": false,
                  "values": false
               },
               "lines": true,
               "linewidth": 1,
               "links": [ ],
               "nullPointMode": "null as zero",
               "percentage": false,
               "pointradius": 5,
               "points": false,
               "renderer": "flot",
               "seriesOverrides": [ ],
               "spaceLength": 10,
               "span": 2,
               "stack": false,
               "steppedLine": false,
               "targets": [
                  {
                     "expr": "rate(container_cpu_usage_seconds_total{cluster=~\"$cluster\", namespace=~\"$namespace\", container=~\"$container\", pod=~\"$pod\"}[5m])",
                     "format": "time_series",
                     "intervalFactor": 2,
                     "legendFormat": "{{pod}}",
                     "legendLink": null,
                     "step": 10
                  }
               ],
               "thresholds": [ ],
               "timeFrom": null,
               "timeShift": null,
               "title": "CPU",
               "tooltip": {
                  "shared": true,
                  "sort": 2,
                  "value_type": "individual"
               },
               "type": "graph",
               "xaxis": {
                  "buckets": null,
                  "mode": "time",
                  "name": null,
                  "show": true,
                  "values": [ ]
               },
               "yaxes": [
                  {
                     "format": "short",
                     "label": null,
                     "logBase": 1,
                     "max": null,
                     "min": 0,
                     "show": true
                  },
                  {
                     "format": "short",
                     "label": null,
                     "logBase": 1,
                     "max": null,
                     "min": null,
                     "show": false
                  }
               ]
            },
            {
               "aliasColors": { },
               "bars": false,
               "dashLength": 10,
               "dashes": false,
               "datasource": "$datasource",
               "fill": 1,
               "id": 5,
               "legend": {
                  "avg": false,
                  "current": false,
                  "max": false,
                  "min": false,
                  "show": true,
                  "total": false,
                  "values": false
               },
               "lines": true,
               "linewidth": 1,
               "links": [ ],
               "nullPointMode": "null as zero",
               "percentage": false,
               "pointradius": 5,
               "points": false,
               "renderer": "flot",
               "seriesOverrides": [ ],
               "spaceLength": 10,
               "span": 2,
               "stack": false,
               "steppedLine": false,
               "targets": [
                  {
                     "expr": "container_memory_working_set_bytes{cluster=~\"$cluster\", namespace=~\"$namespace\", container=~\"$container\", pod=~\"$pod\"}",
                     "format": "time_series",
                     "intervalFactor": 2,
                     "legendFormat": "{{pod}}",
                     "legendLink": null,
                     "step": 10
                  }
               ],
               "thresholds": [ ],
               "timeFrom": null,
               "timeShift": null,
               "title": "WSS",
               "tooltip": {
                  "shared": true,
                  "sort": 2,
                  "value_type": "individual"
               },
               "type": "graph",
               "xaxis": {
                  "buckets": null,
                  "mode": "time",
                  "name": null,
                  "show": true,
                  "values": [ ]
               },
               "yaxes": [
                  {
                     "format": "short",
                     "label": null,
                     "logBase": 1,
                     "max": null,
                     "min": 0,
                     "show": true
                  },
                  {
                     "format": "short",
                     "label": null,
                     "logBase": 1,
                     "max": null,
                     "min": null,
                     "show": false
                  }
               ]
            },
            {
               "aliasColors": { },
               "bars": false,
               "dashLength": 10,
               "dashes": false,
               "datasource": "$datasource",
               "fill": 1,
               "id": 6,
               "legend": {
                  "avg": false,
                  "current": false,
                  "max": false,
                  "min": false,
                  "show": true,
                  "total": false,
                  "values": false
               },
               "lines": true,
               "linewidth": 1,
               "links": [ ],
               "nullPointMode": "null as zero",
               "percentage": false,
               "pointradius": 5,
               "points": false,
               "renderer": "flot",
               "seriesOverrides": [ ],
               "spaceLength": 10,
               "span": 2,
               "stack": false,
               "steppedLine": false,
               "targets": [
                  {
                     "expr": "rate(promtail_custom_bad_words_total{cluster=~\"$cluster\", exported_namespace=~\"$namespace\", exported_job=~\"$job\"}[5m])",
                     "format": "time_series",
                     "intervalFactor": 2,
                     "legendFormat": "{{job}}",
                     "legendLink": null,
                     "step": 10
                  }
               ],
               "thresholds": [ ],
               "timeFrom": null,
               "timeShift": null,
               "title": "Bad Words",
               "tooltip": {
                  "shared": true,
                  "sort": 2,
                  "value_type": "individual"
               },
               "type": "graph",
               "xaxis": {
                  "buckets": null,
                  "mode": "time",
                  "name": null,
                  "show": true,
                  "values": [ ]
               },
               "yaxes": [
                  {
                     "format": "short",
                     "label": null,
                     "logBase": 1,
                     "max": null,
                     "min": 0,
                     "show": true
                  },
                  {
                     "format": "short",
                     "label": null,
                     "logBase": 1,
                     "max": null,
                     "min": null,
                     "show": false
                  }
               ]
            }
         ],
         "repeat": null,
         "repeatIteration": null,
         "repeatRowId": null,
         "showTitle": true,
         "title": "General",
         "titleSize": "h6"
      },
      {
         "collapse": false,
         "height": "250px",
         "panels": [
            {
               "aliasColors": { },
               "bars": false,
               "dashLength": 10,
               "dashes": false,
               "datasource": "$datasource",
               "fill": 1,
               "id": 7,
               "legend": {
                  "avg": false,
                  "current": false,
                  "max": false,
                  "min": false,
                  "show": true,
                  "total": false,
                  "values": false
               },
               "lines": true,
               "linewidth": 1,
               "links": [ ],
               "nullPointMode": "null as zero",
               "percentage": false,
               "pointradius": 5,
               "points": false,
               "renderer": "flot",
               "seriesOverrides": [ ],
               "spaceLength": 10,
               "span": 6,
               "stack": false,
               "steppedLine": false,
               "targets": [
                  {
                     "expr": "sum by (pod) (rate(container_network_receive_bytes_total{cluster=~\"$cluster\", namespace=~\"$namespace\", pod=~\"$pod\"}[5m]))",
                     "format": "time_series",
                     "intervalFactor": 2,
                     "legendFormat": "{{pod}}",
                     "legendLink": null,
                     "step": 10
                  }
               ],
               "thresholds": [ ],
               "timeFrom": null,
               "timeShift": null,
               "title": "RX by Pod",
               "tooltip": {
                  "shared": true,
                  "sort": 2,
                  "value_type": "individual"
               },
               "type": "graph",
               "xaxis": {
                  "buckets": null,
                  "mode": "time",
                  "name": null,
                  "show": true,
                  "values": [ ]
               },
               "yaxes": [
                  {
                     "format": "short",
                     "label": null,
                     "logBase": 1,
                     "max": null,
                     "min": 0,
                     "show": true
                  },
                  {
                     "format": "short",
                     "label": null,
                     "logBase": 1,
                     "max": null,
                     "min": null,
                     "show": false
                  }
               ]
            },
            {
               "aliasColors": { },
               "bars": false,
               "dashLength": 10,
               "dashes": false,
               "datasource": "$datasource",
               "fill": 1,
               "id": 8,
               "legend": {
                  "avg": false,
                  "current": false,
                  "max": false,
                  "min": false,
                  "show": true,
                  "total": false,
                  "values": false
               },
               "lines": true,
               "linewidth": 1,
               "links": [ ],
               "nullPointMode": "null as zero",
               "percentage": false,
               "pointradius": 5,
               "points": false,
               "renderer": "flot",
               "seriesOverrides": [ ],
               "spaceLength": 10,
               "span": 6,
               "stack": false,
               "steppedLine": false,
               "targets": [
                  {
                     "expr": "sum by (pod) (rate(container_network_transmit_bytes_total{cluster=~\"$cluster\", namespace=~\"$namespace\", pod=~\"$pod\"}[5m]))",
                     "format": "time_series",
                     "intervalFactor": 2,
                     "legendFormat": "{{pod}}",
                     "legendLink": null,
                     "step": 10
                  }
               ],
               "thresholds": [ ],
               "timeFrom": null,
               "timeShift": null,
               "title": "TX by Pod",
               "tooltip": {
                  "shared": true,
                  "sort": 2,
                  "value_type": "individual"
               },
               "type": "graph",
               "xaxis": {
                  "buckets": null,
                  "mode": "time",
                  "name": null,
                  "show": true,
                  "values": [ ]
               },
               "yaxes": [
                  {
                     "format": "short",
                     "label": null,
                     "logBase": 1,
                     "max": null,
                     "min": 0,
                     "show": true
                  },
                  {
                     "format": "short",
                     "label": null,
                     "logBase": 1,
                     "max": null,
                     "min": null,
                     "show": false
                  }
               ]
            }
         ],
         "repeat": null,
         "repeatIteration": null,
         "repeatRowId": null,
         "showTitle": true,
         "title": "Network",
         "titleSize": "h6"
      },
      {
         "collapse": false,
         "height": "250px",
         "panels": [
            {
               "aliasColors": { },
               "bars": false,
               "dashLength": 10,
               "dashes": false,
               "datasource": "$datasource",
               "fill": 1,
               "id": 9,
               "legend": {
                  "avg": false,
                  "current": false,
                  "max": false,
                  "min": false,
                  "show": true,
                  "total": false,
                  "values": false
               },
               "lines": true,
               "linewidth": 1,
               "links": [ ],
               "nullPointMode": "null as zero",
               "percentage": false,
               "pointradius": 5,
               "points": false,
               "renderer": "flot",
               "seriesOverrides": [ ],
               "spaceLength": 10,
               "span": 2,
               "stack": false,
               "steppedLine": false,
               "targets": [
                  {
                     "expr": "(sum by (pod) (avg_over_time(go_memstats_heap_inuse_bytes{cluster=~\"$cluster\", namespace=~\"$namespace\", container=~\"$container\", pod=~\"$pod\"}[1m])))\n/\n(sum by (pod) (agent_wal_storage_active_series{cluster=~\"$cluster\", namespace=~\"$namespace\", container=~\"$container\", pod=~\"$pod\"}))\n",
                     "format": "time_series",
                     "intervalFactor": 2,
                     "legendFormat": "{{pod}}",
                     "legendLink": null,
                     "step": 10
                  }
               ],
               "thresholds": [ ],
               "timeFrom": null,
               "timeShift": null,
               "title": "Bytes/Series/Pod",
               "tooltip": {
                  "shared": true,
                  "sort": 2,
                  "value_type": "individual"
               },
               "type": "graph",
               "xaxis": {
                  "buckets": null,
                  "mode": "time",
                  "name": null,
                  "show": true,
                  "values": [ ]
               },
               "yaxes": [
                  {
                     "format": "decbytes",
                     "label": null,
                     "logBase": 1,
                     "max": null,
                     "min": 0,
                     "show": true
                  },
                  {
                     "format": "short",
                     "label": null,
                     "logBase": 1,
                     "max": null,
                     "min": null,
                     "show": false
                  }
               ]
            },
            {
               "aliasColors": { },
               "bars": false,
               "dashLength": 10,
               "dashes": false,
               "datasource": "$datasource",
               "fill": 1,
               "id": 10,
               "legend": {
                  "avg": false,
                  "current": false,
                  "max": false,
                  "min": false,
                  "show": true,
                  "total": false,
                  "values": false
               },
               "lines": true,
               "linewidth": 1,
               "links": [ ],
               "nullPointMode": "null as zero",
               "percentage": false,
               "pointradius": 5,
               "points": false,
               "renderer": "flot",
               "seriesOverrides": [ ],
               "spaceLength": 10,
               "span": 2,
               "stack": false,
               "steppedLine": false,
               "targets": [
                  {
                     "expr": "(sum by (container) (avg_over_time(go_memstats_heap_inuse_bytes{cluster=~\"$cluster\", namespace=~\"$namespace\", container=~\"$container\", pod=~\"$pod\"}[1m])))\n/\n(sum by (container) (agent_wal_storage_active_series{cluster=~\"$cluster\", namespace=~\"$namespace\", container=~\"$container\", pod=~\"$pod\"}))\n",
                     "format": "time_series",
                     "intervalFactor": 2,
                     "legendFormat": "{{container}}",
                     "legendLink": null,
                     "step": 10
                  }
               ],
               "thresholds": [ ],
               "timeFrom": null,
               "timeShift": null,
               "title": "Bytes/Series",
               "tooltip": {
                  "shared": true,
                  "sort": 2,
                  "value_type": "individual"
               },
               "type": "graph",
               "xaxis": {
                  "buckets": null,
                  "mode": "time",
                  "name": null,
                  "show": true,
                  "values": [ ]
               },
               "yaxes": [
                  {
                     "format": "decbytes",
                     "label": null,
                     "logBase": 1,
                     "max": null,
                     "min": 0,
                     "show": true
                  },
                  {
                     "format": "short",
                     "label": null,
                     "logBase": 1,
                     "max": null,
                     "min": null,
                     "show": false
                  }
               ]
            },
            {
               "aliasColors": { },
               "bars": false,
               "dashLength": 10,
               "dashes": false,
               "datasource": "$datasource",
               "fill": 1,
               "id": 11,
               "legend": {
                  "avg": false,
                  "current": false,
                  "max": false,
                  "min": false,
                  "show": true,
                  "total": false,
                  "values": false
               },
               "lines": true,
               "linewidth": 1,
               "links": [ ],
               "nullPointMode": "null as zero",
               "percentage": false,
               "pointradius": 5,
               "points": false,
               "renderer": "flot",
               "seriesOverrides": [ ],
               "spaceLength": 10,
               "span": 2,
               "stack": false,
               "steppedLine": false,
               "targets": [
                  {
                     "expr": "sum by (pod) (agent_wal_storage_active_series{cluster=~\"$cluster\", namespace=~\"$namespace\", container=~\"$container\", pod=~\"$pod\"})",
                     "format": "time_series",
                     "intervalFactor": 2,
                     "legendFormat": "{{pod}}",
                     "legendLink": null,
                     "step": 10
                  }
               ],
               "thresholds": [ ],
               "timeFrom": null,
               "timeShift": null,
               "title": "Series/Pod",
               "tooltip": {
                  "shared": true,
                  "sort": 2,
                  "value_type": "individual"
               },
               "type": "graph",
               "xaxis": {
                  "buckets": null,
                  "mode": "time",
                  "name": null,
                  "show": true,
                  "values": [ ]
               },
               "yaxes": [
                  {
                     "format": "short",
                     "label": null,
                     "logBase": 1,
                     "max": null,
                     "min": 0,
                     "show": true
                  },
                  {
                     "format": "short",
                     "label": null,
                     "logBase": 1,
                     "max": null,
                     "min": null,
                     "show": false
                  }
               ]
            },
            {
               "aliasColors": { },
               "bars": false,
               "dashLength": 10,
               "dashes": false,
               "datasource": "$datasource",
               "fill": 1,
               "id": 12,
               "legend": {
                  "avg": false,
                  "current": false,
                  "max": false,
                  "min": false,
                  "show": true,
                  "total": false,
                  "values": false
               },
               "lines": true,
               "linewidth": 1,
               "links": [ ],
               "nullPointMode": "null as zero",
               "percentage": false,
               "pointradius": 5,
               "points": false,
               "renderer": "flot",
               "seriesOverrides": [ ],
               "spaceLength": 10,
               "span": 2,
               "stack": false,
               "steppedLine": false,
               "targets": [
                  {
                     "expr": "sum by (instance_group_name) (agent_wal_storage_active_series{cluster=~\"$cluster\", namespace=~\"$namespace\", container=~\"$container\", pod=~\"$pod\"})",
                     "format": "time_series",
                     "intervalFactor": 2,
                     "legendFormat": "{{instance_group_name}}",
                     "legendLink": null,
                     "step": 10
                  }
               ],
               "thresholds": [ ],
               "timeFrom": null,
               "timeShift": null,
               "title": "Series/Config",
               "tooltip": {
                  "shared": true,
                  "sort": 2,
                  "value_type": "individual"
               },
               "type": "graph",
               "xaxis": {
                  "buckets": null,
                  "mode": "time",
                  "name": null,
                  "show": true,
                  "values": [ ]
               },
               "yaxes": [
                  {
                     "format": "short",
                     "label": null,
                     "logBase": 1,
                     "max": null,
                     "min": 0,
                     "show": true
                  },
                  {
                     "format": "short",
                     "label": null,
                     "logBase": 1,
                     "max": null,
                     "min": null,
                     "show": false
                  }
               ]
            },
            {
               "aliasColors": { },
               "bars": false,
               "dashLength": 10,
               "dashes": false,
               "datasource": "$datasource",
               "fill": 1,
               "id": 13,
               "legend": {
                  "avg": false,
                  "current": false,
                  "max": false,
                  "min": false,
                  "show": true,
                  "total": false,
                  "values": false
               },
               "lines": true,
               "linewidth": 1,
               "links": [ ],
               "nullPointMode": "null as zero",
               "percentage": false,
               "pointradius": 5,
               "points": false,
               "renderer": "flot",
               "seriesOverrides": [ ],
               "spaceLength": 10,
               "span": 2,
               "stack": false,
               "steppedLine": false,
               "targets": [
                  {
                     "expr": "sum by (container) (agent_wal_storage_active_series{cluster=~\"$cluster\", namespace=~\"$namespace\", container=~\"$container\", pod=~\"$pod\"})",
                     "format": "time_series",
                     "intervalFactor": 2,
                     "legendFormat": "{{container}}",
                     "legendLink": null,
                     "step": 10
                  }
               ],
               "thresholds": [ ],
               "timeFrom": null,
               "timeShift": null,
               "title": "Series",
               "tooltip": {
                  "shared": true,
                  "sort": 2,
                  "value_type": "individual"
               },
               "type": "graph",
               "xaxis": {
                  "buckets": null,
                  "mode": "time",
                  "name": null,
                  "show": true,
                  "values": [ ]
               },
               "yaxes": [
                  {
                     "format": "short",
                     "label": null,
                     "logBase": 1,
                     "max": null,
                     "min": 0,
                     "show": true
                  },
                  {
                     "format": "short",
                     "label": null,
                     "logBase": 1,
                     "max": null,
                     "min": null,
                     "show": false
                  }
               ]
            }
         ],
         "repeat": null,
         "repeatIteration": null,
         "repeatRowId": null,
         "showTitle": true,
         "title": "Prometheus Read",
         "titleSize": "h6"
      }
   ],
   "schemaVersion": 14,
   "style": "dark",
   "tags": [
      "grafana-agent-mixin"
   ],
   "templating": {
      "list": [
         {
            "current": {
               "text": "default",
               "value": "default"
            },
            "hide": 0,
            "label": "Data Source",
            "name": "datasource",
            "options": [ ],
            "query": "prometheus",
            "refresh": 1,
            "regex": "",
            "type": "datasource"
         },
         {
            "allValue": ".+",
            "current": {
               "selected": true,
               "text": "All",
               "value": "$__all"
            },
            "datasource": "$datasource",
            "hide": 0,
            "includeAll": true,
            "label": "cluster",
            "multi": true,
            "name": "cluster",
            "options": [ ],
            "query": "label_values(agent_build_info, cluster)",
            "refresh": 1,
            "regex": "",
            "sort": 2,
            "tagValuesQuery": "",
            "tags": [ ],
            "tagsQuery": "",
            "type": "query",
            "useTags": false
         },
         {
            "allValue": ".+",
            "current": {
               "selected": true,
               "text": "All",
               "value": "$__all"
            },
            "datasource": "$datasource",
            "hide": 0,
            "includeAll": true,
            "label": "namespace",
            "multi": true,
            "name": "namespace",
            "options": [ ],
            "query": "label_values(agent_build_info, namespace)",
            "refresh": 1,
            "regex": "",
            "sort": 2,
            "tagValuesQuery": "",
            "tags": [ ],
            "tagsQuery": "",
            "type": "query",
            "useTags": false
         },
         {
            "allValue": ".+",
            "current": {
               "selected": true,
               "text": "All",
               "value": "$__all"
            },
            "datasource": "$datasource",
            "hide": 0,
            "includeAll": true,
            "label": "container",
            "multi": true,
            "name": "container",
            "options": [ ],
            "query": "label_values(agent_build_info, container)",
            "refresh": 1,
            "regex": "",
            "sort": 2,
            "tagValuesQuery": "",
            "tags": [ ],
            "tagsQuery": "",
            "type": "query",
            "useTags": false
         },
         {
            "allValue": "grafana-agent-.*",
            "current": {
               "selected": true,
               "text": "All",
               "value": "$__all"
            },
            "datasource": "$datasource",
            "hide": 0,
            "includeAll": true,
            "label": "pod",
            "multi": true,
            "name": "pod",
            "options": [ ],
            "query": "label_values(agent_build_info{container=~\"$container\"}, pod)",
            "refresh": 1,
            "regex": "",
            "sort": 2,
            "tagValuesQuery": "",
            "tags": [ ],
            "tagsQuery": "",
            "type": "query",
            "useTags": false
         }
      ]
   },
   "time": {
      "from": "now-1h",
      "to": "now"
   },
   "timepicker": {
      "refresh_intervals": [
         "5s",
         "10s",
         "30s",
         "1m",
         "5m",
         "15m",
         "30m",
         "1h",
         "2h",
         "1d"
      ],
      "time_options": [
         "5m",
         "15m",
         "1h",
         "6h",
         "12h",
         "24h",
         "2d",
         "7d",
         "30d"
      ]
   },
   "timezone": "",
   "title": "Agent Operational",
   "uid": "",
   "version": 0
}

'''
'''--- example/docker-compose/grafana/dashboards/agent-remote-write.json ---
{
   "__inputs": [ ],
   "__requires": [ ],
   "annotations": {
      "list": [ ]
   },
   "editable": true,
   "gnetId": null,
   "graphTooltip": 0,
   "hideControls": false,
   "id": null,
   "links": [ ],
   "refresh": "30s",
   "rows": [
      {
         "collapse": false,
         "collapsed": false,
         "panels": [
            {
               "aliasColors": { },
               "bars": false,
               "dashLength": 10,
               "dashes": false,
               "datasource": "$datasource",
               "fill": 1,
               "fillGradient": 0,
               "gridPos": { },
               "id": 2,
               "legend": {
                  "alignAsTable": false,
                  "avg": false,
                  "current": false,
                  "max": false,
                  "min": false,
                  "rightSide": false,
                  "show": true,
                  "sideWidth": null,
                  "total": false,
                  "values": false
               },
               "lines": true,
               "linewidth": 1,
               "links": [ ],
               "nullPointMode": "null",
               "percentage": false,
               "pointradius": 5,
               "points": false,
               "renderer": "flot",
               "repeat": null,
               "seriesOverrides": [ ],
               "spaceLength": 10,
               "span": 6,
               "stack": false,
               "steppedLine": false,
               "targets": [
                  {
                     "expr": "(\n  prometheus_remote_storage_highest_timestamp_in_seconds{cluster=~\"$cluster\", namespace=~\"$namespace\", container=~\"$container\"}\n  -\n  ignoring(url, remote_name) group_right(pod)\n  prometheus_remote_storage_queue_highest_sent_timestamp_seconds{cluster=~\"$cluster\", namespace=~\"$namespace\", container=~\"$container\"}\n)\n",
                     "format": "time_series",
                     "intervalFactor": 2,
                     "legendFormat": "{{cluster}}:{{pod}}-{{instance_group_name}}-{{url}}",
                     "refId": "A"
                  }
               ],
               "thresholds": [ ],
               "timeFrom": null,
               "timeShift": null,
               "title": "Highest Timestamp In vs. Highest Timestamp Sent",
               "tooltip": {
                  "shared": true,
                  "sort": 0,
                  "value_type": "individual"
               },
               "type": "graph",
               "xaxis": {
                  "buckets": null,
                  "mode": "time",
                  "name": null,
                  "show": true,
                  "values": [ ]
               },
               "yaxes": [
                  {
                     "format": "short",
                     "label": null,
                     "logBase": 1,
                     "max": null,
                     "min": null,
                     "show": true
                  },
                  {
                     "format": "short",
                     "label": null,
                     "logBase": 1,
                     "max": null,
                     "min": null,
                     "show": true
                  }
               ]
            },
            {
               "aliasColors": { },
               "bars": false,
               "dashLength": 10,
               "dashes": false,
               "datasource": "$datasource",
               "fill": 1,
               "fillGradient": 0,
               "gridPos": { },
               "id": 3,
               "legend": {
                  "alignAsTable": false,
                  "avg": false,
                  "current": false,
                  "max": false,
                  "min": false,
                  "rightSide": false,
                  "show": true,
                  "sideWidth": null,
                  "total": false,
                  "values": false
               },
               "lines": true,
               "linewidth": 1,
               "links": [ ],
               "nullPointMode": "null",
               "percentage": false,
               "pointradius": 5,
               "points": false,
               "renderer": "flot",
               "repeat": null,
               "seriesOverrides": [ ],
               "spaceLength": 10,
               "span": 6,
               "stack": false,
               "steppedLine": false,
               "targets": [
                  {
                     "expr": "rate(prometheus_remote_storage_sent_batch_duration_seconds_sum{cluster=~\"$cluster\", namespace=~\"$namespace\", container=~\"$container\"}[1m]) / rate(prometheus_remote_storage_sent_batch_duration_seconds_count{cluster=~\"$cluster\", namespace=~\"$namespace\", container=~\"$container\"}[1m])",
                     "format": "time_series",
                     "intervalFactor": 2,
                     "legendFormat": "mean {{cluster}}:{{pod}}-{{instance_group_name}}-{{url}}",
                     "refId": "A"
                  },
                  {
                     "expr": "histogram_quantile(0.99, rate(prometheus_remote_storage_sent_batch_duration_seconds_bucket{cluster=~\"$cluster\", namespace=~\"$namespace\", container=~\"$container\"}[1m]))",
                     "format": "time_series",
                     "intervalFactor": 2,
                     "legendFormat": "p99 {{cluster}}:{{pod}}-{{instance_group_name}}-{{url}}",
                     "refId": "B"
                  }
               ],
               "thresholds": [ ],
               "timeFrom": null,
               "timeShift": null,
               "title": "Latency [1m]",
               "tooltip": {
                  "shared": true,
                  "sort": 0,
                  "value_type": "individual"
               },
               "type": "graph",
               "xaxis": {
                  "buckets": null,
                  "mode": "time",
                  "name": null,
                  "show": true,
                  "values": [ ]
               },
               "yaxes": [
                  {
                     "format": "short",
                     "label": null,
                     "logBase": 1,
                     "max": null,
                     "min": null,
                     "show": true
                  },
                  {
                     "format": "short",
                     "label": null,
                     "logBase": 1,
                     "max": null,
                     "min": null,
                     "show": true
                  }
               ]
            }
         ],
         "repeat": null,
         "repeatIteration": null,
         "repeatRowId": null,
         "showTitle": true,
         "title": "Timestamps",
         "titleSize": "h6",
         "type": "row"
      },
      {
         "collapse": false,
         "collapsed": false,
         "panels": [
            {
               "aliasColors": { },
               "bars": false,
               "dashLength": 10,
               "dashes": false,
               "datasource": "$datasource",
               "fill": 1,
               "fillGradient": 0,
               "gridPos": { },
               "id": 4,
               "legend": {
                  "alignAsTable": false,
                  "avg": false,
                  "current": false,
                  "max": false,
                  "min": false,
                  "rightSide": false,
                  "show": true,
                  "sideWidth": null,
                  "total": false,
                  "values": false
               },
               "lines": true,
               "linewidth": 1,
               "links": [ ],
               "nullPointMode": "null",
               "percentage": false,
               "pointradius": 5,
               "points": false,
               "renderer": "flot",
               "repeat": null,
               "seriesOverrides": [ ],
               "spaceLength": 10,
               "span": 6,
               "stack": false,
               "steppedLine": false,
               "targets": [
                  {
                     "expr": "rate(agent_wal_samples_appended_total{cluster=~\"$cluster\", namespace=~\"$namespace\", container=~\"$container\"}[5m])",
                     "format": "time_series",
                     "intervalFactor": 2,
                     "legendFormat": "{{cluster}}:{{pod}}-{{instance_group_name}}-{{url}}",
                     "refId": "A"
                  }
               ],
               "thresholds": [ ],
               "timeFrom": null,
               "timeShift": null,
               "title": "Rate in [5m]",
               "tooltip": {
                  "shared": true,
                  "sort": 0,
                  "value_type": "individual"
               },
               "type": "graph",
               "xaxis": {
                  "buckets": null,
                  "mode": "time",
                  "name": null,
                  "show": true,
                  "values": [ ]
               },
               "yaxes": [
                  {
                     "format": "short",
                     "label": null,
                     "logBase": 1,
                     "max": null,
                     "min": null,
                     "show": true
                  },
                  {
                     "format": "short",
                     "label": null,
                     "logBase": 1,
                     "max": null,
                     "min": null,
                     "show": true
                  }
               ]
            },
            {
               "aliasColors": { },
               "bars": false,
               "dashLength": 10,
               "dashes": false,
               "datasource": "$datasource",
               "fill": 1,
               "fillGradient": 0,
               "gridPos": { },
               "id": 5,
               "legend": {
                  "alignAsTable": false,
                  "avg": false,
                  "current": false,
                  "max": false,
                  "min": false,
                  "rightSide": false,
                  "show": true,
                  "sideWidth": null,
                  "total": false,
                  "values": false
               },
               "lines": true,
               "linewidth": 1,
               "links": [ ],
               "nullPointMode": "null",
               "percentage": false,
               "pointradius": 5,
               "points": false,
               "renderer": "flot",
               "repeat": null,
               "seriesOverrides": [ ],
               "spaceLength": 10,
               "span": 6,
               "stack": false,
               "steppedLine": false,
               "targets": [
                  {
                     "expr": "rate(prometheus_remote_storage_succeeded_samples_total{cluster=~\"$cluster\", namespace=~\"$namespace\", container=~\"$container\"}[5m]) or rate(prometheus_remote_storage_samples_total{cluster=~\"$cluster\", namespace=~\"$namespace\", container=~\"$container\"}[5m])",
                     "format": "time_series",
                     "intervalFactor": 2,
                     "legendFormat": "{{cluster}}:{{pod}}-{{instance_group_name}}-{{url}}",
                     "refId": "A"
                  }
               ],
               "thresholds": [ ],
               "timeFrom": null,
               "timeShift": null,
               "title": "Rate succeeded [5m]",
               "tooltip": {
                  "shared": true,
                  "sort": 0,
                  "value_type": "individual"
               },
               "type": "graph",
               "xaxis": {
                  "buckets": null,
                  "mode": "time",
                  "name": null,
                  "show": true,
                  "values": [ ]
               },
               "yaxes": [
                  {
                     "format": "short",
                     "label": null,
                     "logBase": 1,
                     "max": null,
                     "min": null,
                     "show": true
                  },
                  {
                     "format": "short",
                     "label": null,
                     "logBase": 1,
                     "max": null,
                     "min": null,
                     "show": true
                  }
               ]
            },
            {
               "aliasColors": { },
               "bars": false,
               "dashLength": 10,
               "dashes": false,
               "datasource": "$datasource",
               "fill": 1,
               "fillGradient": 0,
               "gridPos": { },
               "id": 6,
               "legend": {
                  "alignAsTable": false,
                  "avg": false,
                  "current": false,
                  "max": false,
                  "min": false,
                  "rightSide": false,
                  "show": true,
                  "sideWidth": null,
                  "total": false,
                  "values": false
               },
               "lines": true,
               "linewidth": 1,
               "links": [ ],
               "nullPointMode": "null",
               "percentage": false,
               "pointradius": 5,
               "points": false,
               "renderer": "flot",
               "repeat": null,
               "seriesOverrides": [ ],
               "spaceLength": 10,
               "span": 6,
               "stack": false,
               "steppedLine": false,
               "targets": [
                  {
                     "expr": "prometheus_remote_storage_samples_pending{cluster=~\"$cluster\", namespace=~\"$namespace\", container=~\"$container\"}",
                     "format": "time_series",
                     "intervalFactor": 2,
                     "legendFormat": "{{cluster}}:{{pod}}-{{instance_group_name}}-{{url}}",
                     "refId": "A"
                  }
               ],
               "thresholds": [ ],
               "timeFrom": null,
               "timeShift": null,
               "title": "Pending Samples",
               "tooltip": {
                  "shared": true,
                  "sort": 0,
                  "value_type": "individual"
               },
               "type": "graph",
               "xaxis": {
                  "buckets": null,
                  "mode": "time",
                  "name": null,
                  "show": true,
                  "values": [ ]
               },
               "yaxes": [
                  {
                     "format": "short",
                     "label": null,
                     "logBase": 1,
                     "max": null,
                     "min": null,
                     "show": true
                  },
                  {
                     "format": "short",
                     "label": null,
                     "logBase": 1,
                     "max": null,
                     "min": null,
                     "show": true
                  }
               ]
            },
            {
               "aliasColors": { },
               "bars": false,
               "dashLength": 10,
               "dashes": false,
               "datasource": "$datasource",
               "fill": 1,
               "fillGradient": 0,
               "gridPos": { },
               "id": 7,
               "legend": {
                  "alignAsTable": false,
                  "avg": false,
                  "current": false,
                  "max": false,
                  "min": false,
                  "rightSide": false,
                  "show": true,
                  "sideWidth": null,
                  "total": false,
                  "values": false
               },
               "lines": true,
               "linewidth": 1,
               "links": [ ],
               "nullPointMode": "null",
               "percentage": false,
               "pointradius": 5,
               "points": false,
               "renderer": "flot",
               "repeat": null,
               "seriesOverrides": [ ],
               "spaceLength": 10,
               "span": 6,
               "stack": false,
               "steppedLine": false,
               "targets": [
                  {
                     "expr": "rate(prometheus_remote_storage_samples_dropped_total{cluster=~\"$cluster\", namespace=~\"$namespace\", container=~\"$container\"}[5m])",
                     "format": "time_series",
                     "intervalFactor": 2,
                     "legendFormat": "{{cluster}}:{{pod}}-{{instance_group_name}}-{{url}}",
                     "refId": "A"
                  }
               ],
               "thresholds": [ ],
               "timeFrom": null,
               "timeShift": null,
               "title": "Dropped Samples",
               "tooltip": {
                  "shared": true,
                  "sort": 0,
                  "value_type": "individual"
               },
               "type": "graph",
               "xaxis": {
                  "buckets": null,
                  "mode": "time",
                  "name": null,
                  "show": true,
                  "values": [ ]
               },
               "yaxes": [
                  {
                     "format": "short",
                     "label": null,
                     "logBase": 1,
                     "max": null,
                     "min": null,
                     "show": true
                  },
                  {
                     "format": "short",
                     "label": null,
                     "logBase": 1,
                     "max": null,
                     "min": null,
                     "show": true
                  }
               ]
            },
            {
               "aliasColors": { },
               "bars": false,
               "dashLength": 10,
               "dashes": false,
               "datasource": "$datasource",
               "fill": 1,
               "fillGradient": 0,
               "gridPos": { },
               "id": 8,
               "legend": {
                  "alignAsTable": false,
                  "avg": false,
                  "current": false,
                  "max": false,
                  "min": false,
                  "rightSide": false,
                  "show": true,
                  "sideWidth": null,
                  "total": false,
                  "values": false
               },
               "lines": true,
               "linewidth": 1,
               "links": [ ],
               "nullPointMode": "null",
               "percentage": false,
               "pointradius": 5,
               "points": false,
               "renderer": "flot",
               "repeat": null,
               "seriesOverrides": [ ],
               "spaceLength": 10,
               "span": 6,
               "stack": false,
               "steppedLine": false,
               "targets": [
                  {
                     "expr": "rate(prometheus_remote_storage_samples_failed_total{cluster=~\"$cluster\", namespace=~\"$namespace\", container=~\"$container\"}[5m])",
                     "format": "time_series",
                     "intervalFactor": 2,
                     "legendFormat": "{{cluster}}:{{pod}}-{{instance_group_name}}-{{url}}",
                     "refId": "A"
                  }
               ],
               "thresholds": [ ],
               "timeFrom": null,
               "timeShift": null,
               "title": "Failed Samples",
               "tooltip": {
                  "shared": true,
                  "sort": 0,
                  "value_type": "individual"
               },
               "type": "graph",
               "xaxis": {
                  "buckets": null,
                  "mode": "time",
                  "name": null,
                  "show": true,
                  "values": [ ]
               },
               "yaxes": [
                  {
                     "format": "short",
                     "label": null,
                     "logBase": 1,
                     "max": null,
                     "min": null,
                     "show": true
                  },
                  {
                     "format": "short",
                     "label": null,
                     "logBase": 1,
                     "max": null,
                     "min": null,
                     "show": true
                  }
               ]
            },
            {
               "aliasColors": { },
               "bars": false,
               "dashLength": 10,
               "dashes": false,
               "datasource": "$datasource",
               "fill": 1,
               "fillGradient": 0,
               "gridPos": { },
               "id": 9,
               "legend": {
                  "alignAsTable": false,
                  "avg": false,
                  "current": false,
                  "max": false,
                  "min": false,
                  "rightSide": false,
                  "show": true,
                  "sideWidth": null,
                  "total": false,
                  "values": false
               },
               "lines": true,
               "linewidth": 1,
               "links": [ ],
               "nullPointMode": "null",
               "percentage": false,
               "pointradius": 5,
               "points": false,
               "renderer": "flot",
               "repeat": null,
               "seriesOverrides": [ ],
               "spaceLength": 10,
               "span": 6,
               "stack": false,
               "steppedLine": false,
               "targets": [
                  {
                     "expr": "rate(prometheus_remote_storage_samples_retried_total{cluster=~\"$cluster\", namespace=~\"$namespace\", container=~\"$container\"}[5m])",
                     "format": "time_series",
                     "intervalFactor": 2,
                     "legendFormat": "{{cluster}}:{{pod}}-{{instance_group_name}}-{{url}}",
                     "refId": "A"
                  }
               ],
               "thresholds": [ ],
               "timeFrom": null,
               "timeShift": null,
               "title": "Retried Samples",
               "tooltip": {
                  "shared": true,
                  "sort": 0,
                  "value_type": "individual"
               },
               "type": "graph",
               "xaxis": {
                  "buckets": null,
                  "mode": "time",
                  "name": null,
                  "show": true,
                  "values": [ ]
               },
               "yaxes": [
                  {
                     "format": "short",
                     "label": null,
                     "logBase": 1,
                     "max": null,
                     "min": null,
                     "show": true
                  },
                  {
                     "format": "short",
                     "label": null,
                     "logBase": 1,
                     "max": null,
                     "min": null,
                     "show": true
                  }
               ]
            }
         ],
         "repeat": null,
         "repeatIteration": null,
         "repeatRowId": null,
         "showTitle": true,
         "title": "Samples",
         "titleSize": "h6",
         "type": "row"
      },
      {
         "collapse": false,
         "collapsed": false,
         "panels": [
            {
               "aliasColors": { },
               "bars": false,
               "dashLength": 10,
               "dashes": false,
               "datasource": "$datasource",
               "fill": 1,
               "fillGradient": 0,
               "gridPos": { },
               "id": 10,
               "legend": {
                  "alignAsTable": false,
                  "avg": false,
                  "current": false,
                  "max": false,
                  "min": false,
                  "rightSide": false,
                  "show": true,
                  "sideWidth": null,
                  "total": false,
                  "values": false
               },
               "lines": true,
               "linewidth": 1,
               "links": [ ],
               "minSpan": 6,
               "nullPointMode": "null",
               "percentage": false,
               "pointradius": 5,
               "points": false,
               "renderer": "flot",
               "repeat": null,
               "seriesOverrides": [ ],
               "spaceLength": 10,
               "span": 12,
               "stack": false,
               "steppedLine": false,
               "targets": [
                  {
                     "expr": "prometheus_remote_storage_shards{cluster=~\"$cluster\", namespace=~\"$namespace\", container=~\"$container\"}",
                     "format": "time_series",
                     "intervalFactor": 2,
                     "legendFormat": "{{cluster}}:{{pod}}-{{instance_group_name}}-{{url}}",
                     "refId": "A"
                  }
               ],
               "thresholds": [ ],
               "timeFrom": null,
               "timeShift": null,
               "title": "Current Shards",
               "tooltip": {
                  "shared": true,
                  "sort": 0,
                  "value_type": "individual"
               },
               "type": "graph",
               "xaxis": {
                  "buckets": null,
                  "mode": "time",
                  "name": null,
                  "show": true,
                  "values": [ ]
               },
               "yaxes": [
                  {
                     "format": "short",
                     "label": null,
                     "logBase": 1,
                     "max": null,
                     "min": null,
                     "show": true
                  },
                  {
                     "format": "short",
                     "label": null,
                     "logBase": 1,
                     "max": null,
                     "min": null,
                     "show": true
                  }
               ]
            },
            {
               "aliasColors": { },
               "bars": false,
               "dashLength": 10,
               "dashes": false,
               "datasource": "$datasource",
               "fill": 1,
               "fillGradient": 0,
               "gridPos": { },
               "id": 11,
               "legend": {
                  "alignAsTable": false,
                  "avg": false,
                  "current": false,
                  "max": false,
                  "min": false,
                  "rightSide": false,
                  "show": true,
                  "sideWidth": null,
                  "total": false,
                  "values": false
               },
               "lines": true,
               "linewidth": 1,
               "links": [ ],
               "nullPointMode": "null",
               "percentage": false,
               "pointradius": 5,
               "points": false,
               "renderer": "flot",
               "repeat": null,
               "seriesOverrides": [ ],
               "spaceLength": 10,
               "span": 4,
               "stack": false,
               "steppedLine": false,
               "targets": [
                  {
                     "expr": "prometheus_remote_storage_shards_max{cluster=~\"$cluster\", namespace=~\"$namespace\", container=~\"$container\"}",
                     "format": "time_series",
                     "intervalFactor": 2,
                     "legendFormat": "{{cluster}}:{{pod}}-{{instance_group_name}}-{{url}}",
                     "refId": "A"
                  }
               ],
               "thresholds": [ ],
               "timeFrom": null,
               "timeShift": null,
               "title": "Max Shards",
               "tooltip": {
                  "shared": true,
                  "sort": 0,
                  "value_type": "individual"
               },
               "type": "graph",
               "xaxis": {
                  "buckets": null,
                  "mode": "time",
                  "name": null,
                  "show": true,
                  "values": [ ]
               },
               "yaxes": [
                  {
                     "format": "short",
                     "label": null,
                     "logBase": 1,
                     "max": null,
                     "min": null,
                     "show": true
                  },
                  {
                     "format": "short",
                     "label": null,
                     "logBase": 1,
                     "max": null,
                     "min": null,
                     "show": true
                  }
               ]
            },
            {
               "aliasColors": { },
               "bars": false,
               "dashLength": 10,
               "dashes": false,
               "datasource": "$datasource",
               "fill": 1,
               "fillGradient": 0,
               "gridPos": { },
               "id": 12,
               "legend": {
                  "alignAsTable": false,
                  "avg": false,
                  "current": false,
                  "max": false,
                  "min": false,
                  "rightSide": false,
                  "show": true,
                  "sideWidth": null,
                  "total": false,
                  "values": false
               },
               "lines": true,
               "linewidth": 1,
               "links": [ ],
               "nullPointMode": "null",
               "percentage": false,
               "pointradius": 5,
               "points": false,
               "renderer": "flot",
               "repeat": null,
               "seriesOverrides": [ ],
               "spaceLength": 10,
               "span": 4,
               "stack": false,
               "steppedLine": false,
               "targets": [
                  {
                     "expr": "prometheus_remote_storage_shards_min{cluster=~\"$cluster\", namespace=~\"$namespace\", container=~\"$container\"}",
                     "format": "time_series",
                     "intervalFactor": 2,
                     "legendFormat": "{{cluster}}:{{pod}}-{{instance_group_name}}-{{url}}",
                     "refId": "A"
                  }
               ],
               "thresholds": [ ],
               "timeFrom": null,
               "timeShift": null,
               "title": "Min Shards",
               "tooltip": {
                  "shared": true,
                  "sort": 0,
                  "value_type": "individual"
               },
               "type": "graph",
               "xaxis": {
                  "buckets": null,
                  "mode": "time",
                  "name": null,
                  "show": true,
                  "values": [ ]
               },
               "yaxes": [
                  {
                     "format": "short",
                     "label": null,
                     "logBase": 1,
                     "max": null,
                     "min": null,
                     "show": true
                  },
                  {
                     "format": "short",
                     "label": null,
                     "logBase": 1,
                     "max": null,
                     "min": null,
                     "show": true
                  }
               ]
            },
            {
               "aliasColors": { },
               "bars": false,
               "dashLength": 10,
               "dashes": false,
               "datasource": "$datasource",
               "fill": 1,
               "fillGradient": 0,
               "gridPos": { },
               "id": 13,
               "legend": {
                  "alignAsTable": false,
                  "avg": false,
                  "current": false,
                  "max": false,
                  "min": false,
                  "rightSide": false,
                  "show": true,
                  "sideWidth": null,
                  "total": false,
                  "values": false
               },
               "lines": true,
               "linewidth": 1,
               "links": [ ],
               "nullPointMode": "null",
               "percentage": false,
               "pointradius": 5,
               "points": false,
               "renderer": "flot",
               "repeat": null,
               "seriesOverrides": [ ],
               "spaceLength": 10,
               "span": 4,
               "stack": false,
               "steppedLine": false,
               "targets": [
                  {
                     "expr": "prometheus_remote_storage_shards_desired{cluster=~\"$cluster\", namespace=~\"$namespace\", container=~\"$container\"}",
                     "format": "time_series",
                     "intervalFactor": 2,
                     "legendFormat": "{{cluster}}:{{pod}}-{{instance_group_name}}-{{url}}",
                     "refId": "A"
                  }
               ],
               "thresholds": [ ],
               "timeFrom": null,
               "timeShift": null,
               "title": "Desired Shards",
               "tooltip": {
                  "shared": true,
                  "sort": 0,
                  "value_type": "individual"
               },
               "type": "graph",
               "xaxis": {
                  "buckets": null,
                  "mode": "time",
                  "name": null,
                  "show": true,
                  "values": [ ]
               },
               "yaxes": [
                  {
                     "format": "short",
                     "label": null,
                     "logBase": 1,
                     "max": null,
                     "min": null,
                     "show": true
                  },
                  {
                     "format": "short",
                     "label": null,
                     "logBase": 1,
                     "max": null,
                     "min": null,
                     "show": true
                  }
               ]
            }
         ],
         "repeat": null,
         "repeatIteration": null,
         "repeatRowId": null,
         "showTitle": true,
         "title": "Shards",
         "titleSize": "h6",
         "type": "row"
      },
      {
         "collapse": false,
         "collapsed": false,
         "panels": [
            {
               "aliasColors": { },
               "bars": false,
               "dashLength": 10,
               "dashes": false,
               "datasource": "$datasource",
               "fill": 1,
               "fillGradient": 0,
               "gridPos": { },
               "id": 14,
               "legend": {
                  "alignAsTable": false,
                  "avg": false,
                  "current": false,
                  "max": false,
                  "min": false,
                  "rightSide": false,
                  "show": true,
                  "sideWidth": null,
                  "total": false,
                  "values": false
               },
               "lines": true,
               "linewidth": 1,
               "links": [ ],
               "nullPointMode": "null",
               "percentage": false,
               "pointradius": 5,
               "points": false,
               "renderer": "flot",
               "repeat": null,
               "seriesOverrides": [ ],
               "spaceLength": 10,
               "span": 6,
               "stack": false,
               "steppedLine": false,
               "targets": [
                  {
                     "expr": "prometheus_remote_storage_shard_capacity{cluster=~\"$cluster\", namespace=~\"$namespace\", container=~\"$container\"}",
                     "format": "time_series",
                     "intervalFactor": 2,
                     "legendFormat": "{{cluster}}:{{pod}}-{{instance_group_name}}-{{url}}",
                     "refId": "A"
                  }
               ],
               "thresholds": [ ],
               "timeFrom": null,
               "timeShift": null,
               "title": "Shard Capacity",
               "tooltip": {
                  "shared": true,
                  "sort": 0,
                  "value_type": "individual"
               },
               "type": "graph",
               "xaxis": {
                  "buckets": null,
                  "mode": "time",
                  "name": null,
                  "show": true,
                  "values": [ ]
               },
               "yaxes": [
                  {
                     "format": "short",
                     "label": null,
                     "logBase": 1,
                     "max": null,
                     "min": null,
                     "show": true
                  },
                  {
                     "format": "short",
                     "label": null,
                     "logBase": 1,
                     "max": null,
                     "min": null,
                     "show": true
                  }
               ]
            }
         ],
         "repeat": null,
         "repeatIteration": null,
         "repeatRowId": null,
         "showTitle": true,
         "title": "Shard Details",
         "titleSize": "h6",
         "type": "row"
      },
      {
         "collapse": false,
         "collapsed": false,
         "panels": [
            {
               "aliasColors": { },
               "bars": false,
               "dashLength": 10,
               "dashes": false,
               "datasource": "$datasource",
               "fill": 1,
               "fillGradient": 0,
               "gridPos": { },
               "id": 15,
               "legend": {
                  "alignAsTable": false,
                  "avg": false,
                  "current": false,
                  "max": false,
                  "min": false,
                  "rightSide": false,
                  "show": true,
                  "sideWidth": null,
                  "total": false,
                  "values": false
               },
               "lines": true,
               "linewidth": 1,
               "links": [ ],
               "nullPointMode": "null",
               "percentage": false,
               "pointradius": 5,
               "points": false,
               "renderer": "flot",
               "repeat": null,
               "seriesOverrides": [ ],
               "spaceLength": 10,
               "span": 6,
               "stack": false,
               "steppedLine": false,
               "targets": [
                  {
                     "expr": "prometheus_wal_watcher_current_segment{cluster=~\"$cluster\", namespace=~\"$namespace\", container=~\"$container\"}",
                     "format": "time_series",
                     "intervalFactor": 2,
                     "legendFormat": "{{cluster}}:{{pod}}-{{instance_group_name}}-{{url}}",
                     "refId": "A"
                  }
               ],
               "thresholds": [ ],
               "timeFrom": null,
               "timeShift": null,
               "title": "Remote Write Current Segment",
               "tooltip": {
                  "shared": true,
                  "sort": 0,
                  "value_type": "individual"
               },
               "type": "graph",
               "xaxis": {
                  "buckets": null,
                  "mode": "time",
                  "name": null,
                  "show": true,
                  "values": [ ]
               },
               "yaxes": [
                  {
                     "format": "none",
                     "label": null,
                     "logBase": 1,
                     "max": null,
                     "min": null,
                     "show": true
                  },
                  {
                     "format": "short",
                     "label": null,
                     "logBase": 1,
                     "max": null,
                     "min": null,
                     "show": true
                  }
               ]
            }
         ],
         "repeat": null,
         "repeatIteration": null,
         "repeatRowId": null,
         "showTitle": true,
         "title": "Segments",
         "titleSize": "h6",
         "type": "row"
      },
      {
         "collapse": false,
         "collapsed": false,
         "panels": [
            {
               "aliasColors": { },
               "bars": false,
               "dashLength": 10,
               "dashes": false,
               "datasource": "$datasource",
               "fill": 1,
               "fillGradient": 0,
               "gridPos": { },
               "id": 16,
               "legend": {
                  "alignAsTable": false,
                  "avg": false,
                  "current": false,
                  "max": false,
                  "min": false,
                  "rightSide": false,
                  "show": true,
                  "sideWidth": null,
                  "total": false,
                  "values": false
               },
               "lines": true,
               "linewidth": 1,
               "links": [ ],
               "nullPointMode": "null",
               "percentage": false,
               "pointradius": 5,
               "points": false,
               "renderer": "flot",
               "repeat": null,
               "seriesOverrides": [ ],
               "spaceLength": 10,
               "span": 6,
               "stack": false,
               "steppedLine": false,
               "targets": [
                  {
                     "expr": "rate(prometheus_remote_storage_enqueue_retries_total{cluster=~\"$cluster\", namespace=~\"$namespace\", container=~\"$container\"}[5m])",
                     "format": "time_series",
                     "intervalFactor": 2,
                     "legendFormat": "{{cluster}}:{{pod}}-{{instance_group_name}}-{{url}}",
                     "refId": "A"
                  }
               ],
               "thresholds": [ ],
               "timeFrom": null,
               "timeShift": null,
               "title": "Enqueue Retries",
               "tooltip": {
                  "shared": true,
                  "sort": 0,
                  "value_type": "individual"
               },
               "type": "graph",
               "xaxis": {
                  "buckets": null,
                  "mode": "time",
                  "name": null,
                  "show": true,
                  "values": [ ]
               },
               "yaxes": [
                  {
                     "format": "short",
                     "label": null,
                     "logBase": 1,
                     "max": null,
                     "min": null,
                     "show": true
                  },
                  {
                     "format": "short",
                     "label": null,
                     "logBase": 1,
                     "max": null,
                     "min": null,
                     "show": true
                  }
               ]
            }
         ],
         "repeat": null,
         "repeatIteration": null,
         "repeatRowId": null,
         "showTitle": true,
         "title": "Misc. Rates",
         "titleSize": "h6",
         "type": "row"
      }
   ],
   "schemaVersion": 14,
   "style": "dark",
   "tags": [
      "grafana-agent-mixin"
   ],
   "templating": {
      "list": [
         {
            "hide": 0,
            "label": null,
            "name": "datasource",
            "options": [ ],
            "query": "prometheus",
            "refresh": 1,
            "regex": "",
            "type": "datasource"
         },
         {
            "allValue": null,
            "current": {
               "text": {
                  "selected": true,
                  "text": "All",
                  "value": "$__all"
               },
               "value": {
                  "selected": true,
                  "text": "All",
                  "value": "$__all"
               }
            },
            "datasource": "$datasource",
            "hide": 0,
            "includeAll": true,
            "label": null,
            "multi": false,
            "name": "cluster",
            "options": [ ],
            "query": "label_values(agent_build_info, cluster)",
            "refresh": 2,
            "regex": "",
            "sort": 0,
            "tagValuesQuery": "",
            "tags": [ ],
            "tagsQuery": "",
            "type": "query",
            "useTags": false
         },
         {
            "allValue": null,
            "current": {
               "text": {
                  "selected": true,
                  "text": "All",
                  "value": "$__all"
               },
               "value": {
                  "selected": true,
                  "text": "All",
                  "value": "$__all"
               }
            },
            "datasource": "$datasource",
            "hide": 0,
            "includeAll": true,
            "label": null,
            "multi": false,
            "name": "namespace",
            "options": [ ],
            "query": "label_values(agent_build_info, namespace)",
            "refresh": 2,
            "regex": "",
            "sort": 0,
            "tagValuesQuery": "",
            "tags": [ ],
            "tagsQuery": "",
            "type": "query",
            "useTags": false
         },
         {
            "allValue": null,
            "current": {
               "text": {
                  "selected": true,
                  "text": "All",
                  "value": "$__all"
               },
               "value": {
                  "selected": true,
                  "text": "All",
                  "value": "$__all"
               }
            },
            "datasource": "$datasource",
            "hide": 0,
            "includeAll": true,
            "label": null,
            "multi": false,
            "name": "container",
            "options": [ ],
            "query": "label_values(agent_build_info, container)",
            "refresh": 2,
            "regex": "",
            "sort": 0,
            "tagValuesQuery": "",
            "tags": [ ],
            "tagsQuery": "",
            "type": "query",
            "useTags": false
         },
         {
            "allValue": null,
            "current": {
               "text": {
                  "selected": true,
                  "text": "All",
                  "value": "$__all"
               },
               "value": {
                  "selected": true,
                  "text": "All",
                  "value": "$__all"
               }
            },
            "datasource": "$datasource",
            "hide": 0,
            "includeAll": true,
            "label": null,
            "multi": false,
            "name": "pod",
            "options": [ ],
            "query": "label_values(agent_build_info{container=~\"$container\"}, pod)",
            "refresh": 2,
            "regex": "",
            "sort": 0,
            "tagValuesQuery": "",
            "tags": [ ],
            "tagsQuery": "",
            "type": "query",
            "useTags": false
         },
         {
            "allValue": null,
            "current": { },
            "datasource": "$datasource",
            "hide": 0,
            "includeAll": true,
            "label": null,
            "multi": false,
            "name": "url",
            "options": [ ],
            "query": "label_values(prometheus_remote_storage_shards{cluster=~\"$cluster\", pod=~\"$pod\"}, url)",
            "refresh": 2,
            "regex": "",
            "sort": 0,
            "tagValuesQuery": "",
            "tags": [ ],
            "tagsQuery": "",
            "type": "query",
            "useTags": false
         }
      ]
   },
   "time": {
      "from": "now-1h",
      "to": "now"
   },
   "timepicker": {
      "refresh_intervals": [
         "5s",
         "10s",
         "30s",
         "1m",
         "5m",
         "15m",
         "30m",
         "1h",
         "2h",
         "1d"
      ],
      "time_options": [
         "5m",
         "15m",
         "1h",
         "6h",
         "12h",
         "24h",
         "2d",
         "7d",
         "30d"
      ]
   },
   "timezone": "",
   "title": "Agent Prometheus Remote Write",
   "version": 0
}

'''
'''--- example/docker-compose/grafana/dashboards/agent-tracing-pipeline.json ---
{
   "__inputs": [ ],
   "__requires": [ ],
   "annotations": {
      "list": [ ]
   },
   "editable": true,
   "gnetId": null,
   "graphTooltip": 0,
   "hideControls": false,
   "id": null,
   "links": [ ],
   "refresh": "30s",
   "rows": [
      {
         "collapse": false,
         "collapsed": false,
         "panels": [
            {
               "aliasColors": { },
               "bars": false,
               "dashLength": 10,
               "dashes": false,
               "datasource": "$datasource",
               "fill": 0,
               "fillGradient": 0,
               "gridPos": { },
               "id": 2,
               "interval": "1m",
               "legend": {
                  "alignAsTable": false,
                  "avg": false,
                  "current": false,
                  "max": false,
                  "min": false,
                  "rightSide": false,
                  "show": false,
                  "sideWidth": null,
                  "total": false,
                  "values": false
               },
               "lines": true,
               "linewidth": 1,
               "links": [ ],
               "nullPointMode": "null",
               "percentage": false,
               "pointradius": 5,
               "points": false,
               "renderer": "flot",
               "repeat": null,
               "seriesOverrides": [ ],
               "spaceLength": 10,
               "span": 3,
               "stack": false,
               "steppedLine": false,
               "targets": [
                  {
                     "expr": "rate(traces_receiver_accepted_spans{cluster=~\"$cluster\",namespace=~\"$namespace\",container=~\"$container\",pod=~\"$pod\",receiver!=\"otlp/lb\"}[$__rate_interval])\n",
                     "format": "time_series",
                     "intervalFactor": 2,
                     "legendFormat": "{{ pod }} - {{ receiver }}/{{ transport }}",
                     "refId": "A"
                  }
               ],
               "thresholds": [ ],
               "timeFrom": null,
               "timeShift": null,
               "title": "Accepted spans",
               "tooltip": {
                  "shared": true,
                  "sort": 0,
                  "value_type": "individual"
               },
               "type": "graph",
               "xaxis": {
                  "buckets": null,
                  "mode": "time",
                  "name": null,
                  "show": true,
                  "values": [ ]
               },
               "yaxes": [
                  {
                     "format": "short",
                     "label": null,
                     "logBase": 1,
                     "max": null,
                     "min": null,
                     "show": true
                  },
                  {
                     "format": "short",
                     "label": null,
                     "logBase": 1,
                     "max": null,
                     "min": null,
                     "show": true
                  }
               ]
            },
            {
               "aliasColors": { },
               "bars": false,
               "dashLength": 10,
               "dashes": false,
               "datasource": "$datasource",
               "fill": 0,
               "fillGradient": 0,
               "gridPos": { },
               "id": 3,
               "interval": "1m",
               "legend": {
                  "alignAsTable": false,
                  "avg": false,
                  "current": false,
                  "max": false,
                  "min": false,
                  "rightSide": false,
                  "show": false,
                  "sideWidth": null,
                  "total": false,
                  "values": false
               },
               "lines": true,
               "linewidth": 1,
               "links": [ ],
               "nullPointMode": "null",
               "percentage": false,
               "pointradius": 5,
               "points": false,
               "renderer": "flot",
               "repeat": null,
               "seriesOverrides": [ ],
               "spaceLength": 10,
               "span": 3,
               "stack": false,
               "steppedLine": false,
               "targets": [
                  {
                     "expr": "rate(traces_receiver_refused_spans{cluster=~\"$cluster\",namespace=~\"$namespace\",container=~\"$container\",pod=~\"$pod\",receiver!=\"otlp/lb\"}[$__rate_interval])\n",
                     "format": "time_series",
                     "intervalFactor": 2,
                     "legendFormat": "{{ pod }} - {{ receiver }}/{{ transport }}",
                     "refId": "A"
                  }
               ],
               "thresholds": [ ],
               "timeFrom": null,
               "timeShift": null,
               "title": "Refused spans",
               "tooltip": {
                  "shared": true,
                  "sort": 0,
                  "value_type": "individual"
               },
               "type": "graph",
               "xaxis": {
                  "buckets": null,
                  "mode": "time",
                  "name": null,
                  "show": true,
                  "values": [ ]
               },
               "yaxes": [
                  {
                     "format": "short",
                     "label": null,
                     "logBase": 1,
                     "max": null,
                     "min": null,
                     "show": true
                  },
                  {
                     "format": "short",
                     "label": null,
                     "logBase": 1,
                     "max": null,
                     "min": null,
                     "show": true
                  }
               ]
            },
            {
               "aliasColors": { },
               "bars": false,
               "dashLength": 10,
               "dashes": false,
               "datasource": "$datasource",
               "fill": 0,
               "fillGradient": 0,
               "gridPos": { },
               "id": 4,
               "interval": "1m",
               "legend": {
                  "alignAsTable": false,
                  "avg": false,
                  "current": false,
                  "max": false,
                  "min": false,
                  "rightSide": false,
                  "show": false,
                  "sideWidth": null,
                  "total": false,
                  "values": false
               },
               "lines": true,
               "linewidth": 1,
               "links": [ ],
               "nullPointMode": "null",
               "percentage": false,
               "pointradius": 5,
               "points": false,
               "renderer": "flot",
               "repeat": null,
               "seriesOverrides": [ ],
               "spaceLength": 10,
               "span": 3,
               "stack": false,
               "steppedLine": false,
               "targets": [
                  {
                     "expr": "rate(traces_exporter_sent_spans{cluster=~\"$cluster\",namespace=~\"$namespace\",container=~\"$container\",pod=~\"$pod\",exporter!=\"otlp\"}[$__rate_interval])\n",
                     "format": "time_series",
                     "intervalFactor": 2,
                     "legendFormat": "{{ pod }} - {{ exporter }}",
                     "refId": "A"
                  }
               ],
               "thresholds": [ ],
               "timeFrom": null,
               "timeShift": null,
               "title": "Exported spans",
               "tooltip": {
                  "shared": true,
                  "sort": 0,
                  "value_type": "individual"
               },
               "type": "graph",
               "xaxis": {
                  "buckets": null,
                  "mode": "time",
                  "name": null,
                  "show": true,
                  "values": [ ]
               },
               "yaxes": [
                  {
                     "format": "short",
                     "label": null,
                     "logBase": 1,
                     "max": null,
                     "min": null,
                     "show": true
                  },
                  {
                     "format": "short",
                     "label": null,
                     "logBase": 1,
                     "max": null,
                     "min": null,
                     "show": true
                  }
               ]
            },
            {
               "aliasColors": { },
               "bars": false,
               "dashLength": 10,
               "dashes": false,
               "datasource": "$datasource",
               "fill": 0,
               "fillGradient": 0,
               "gridPos": { },
               "id": 5,
               "interval": "1m",
               "legend": {
                  "alignAsTable": false,
                  "avg": false,
                  "current": false,
                  "max": false,
                  "min": false,
                  "rightSide": false,
                  "show": false,
                  "sideWidth": null,
                  "total": false,
                  "values": false
               },
               "lines": true,
               "linewidth": 1,
               "links": [ ],
               "nullPointMode": "null",
               "percentage": false,
               "pointradius": 5,
               "points": false,
               "renderer": "flot",
               "repeat": null,
               "seriesOverrides": [ ],
               "spaceLength": 10,
               "span": 3,
               "stack": false,
               "steppedLine": false,
               "targets": [
                  {
                     "expr": "rate(traces_exporter_send_failed_spans{cluster=~\"$cluster\",namespace=~\"$namespace\",container=~\"$container\",pod=~\"$pod\",exporter!=\"otlp\"}[$__rate_interval])\n",
                     "format": "time_series",
                     "intervalFactor": 2,
                     "legendFormat": "{{ pod }} - {{ exporter }}",
                     "refId": "A"
                  }
               ],
               "thresholds": [ ],
               "timeFrom": null,
               "timeShift": null,
               "title": "Exported failed spans",
               "tooltip": {
                  "shared": true,
                  "sort": 0,
                  "value_type": "individual"
               },
               "type": "graph",
               "xaxis": {
                  "buckets": null,
                  "mode": "time",
                  "name": null,
                  "show": true,
                  "values": [ ]
               },
               "yaxes": [
                  {
                     "format": "short",
                     "label": null,
                     "logBase": 1,
                     "max": null,
                     "min": null,
                     "show": true
                  },
                  {
                     "format": "short",
                     "label": null,
                     "logBase": 1,
                     "max": null,
                     "min": null,
                     "show": true
                  }
               ]
            },
            {
               "aliasColors": { },
               "bars": false,
               "dashLength": 10,
               "dashes": false,
               "datasource": "$datasource",
               "fill": 1,
               "fillGradient": 0,
               "gridPos": { },
               "id": 6,
               "interval": "1m",
               "legend": {
                  "alignAsTable": false,
                  "avg": false,
                  "current": false,
                  "max": false,
                  "min": false,
                  "rightSide": false,
                  "show": true,
                  "sideWidth": null,
                  "total": false,
                  "values": false
               },
               "lines": true,
               "linewidth": 1,
               "links": [ ],
               "nullPointMode": "null",
               "percentage": false,
               "pointradius": 5,
               "points": false,
               "renderer": "flot",
               "repeat": null,
               "seriesOverrides": [ ],
               "spaceLength": 10,
               "span": 6,
               "stack": false,
               "steppedLine": false,
               "targets": [
                  {
                     "expr": "sum(rate(traces_receiver_accepted_spans{cluster=~\"$cluster\",namespace=~\"$namespace\",container=~\"$container\",pod=~\"$pod\",receiver!=\"otlp/lb\"}[$__rate_interval]))\n",
                     "format": "time_series",
                     "intervalFactor": 2,
                     "legendFormat": "Accepted",
                     "refId": "A"
                  },
                  {
                     "expr": "sum(rate(traces_receiver_refused_spans{cluster=~\"$cluster\",namespace=~\"$namespace\",container=~\"$container\",pod=~\"$pod\",receiver!=\"otlp/lb\"}[$__rate_interval]))\n",
                     "format": "time_series",
                     "intervalFactor": 2,
                     "legendFormat": "Refused",
                     "refId": "B"
                  }
               ],
               "thresholds": [ ],
               "timeFrom": null,
               "timeShift": null,
               "title": "Received spans",
               "tooltip": {
                  "shared": true,
                  "sort": 0,
                  "value_type": "individual"
               },
               "type": "graph",
               "xaxis": {
                  "buckets": null,
                  "mode": "time",
                  "name": null,
                  "show": true,
                  "values": [ ]
               },
               "yaxes": [
                  {
                     "format": "short",
                     "label": null,
                     "logBase": 1,
                     "max": null,
                     "min": null,
                     "show": true
                  },
                  {
                     "format": "short",
                     "label": null,
                     "logBase": 1,
                     "max": null,
                     "min": null,
                     "show": true
                  }
               ]
            },
            {
               "aliasColors": { },
               "bars": false,
               "dashLength": 10,
               "dashes": false,
               "datasource": "$datasource",
               "fill": 1,
               "fillGradient": 0,
               "gridPos": { },
               "id": 7,
               "interval": "1m",
               "legend": {
                  "alignAsTable": false,
                  "avg": false,
                  "current": false,
                  "max": false,
                  "min": false,
                  "rightSide": false,
                  "show": true,
                  "sideWidth": null,
                  "total": false,
                  "values": false
               },
               "lines": true,
               "linewidth": 1,
               "links": [ ],
               "nullPointMode": "null",
               "percentage": false,
               "pointradius": 5,
               "points": false,
               "renderer": "flot",
               "repeat": null,
               "seriesOverrides": [ ],
               "spaceLength": 10,
               "span": 6,
               "stack": false,
               "steppedLine": false,
               "targets": [
                  {
                     "expr": "sum(rate(traces_exporter_sent_spans{cluster=~\"$cluster\",namespace=~\"$namespace\",container=~\"$container\",pod=~\"$pod\",exporter!=\"otlp\"}[$__rate_interval]))\n",
                     "format": "time_series",
                     "intervalFactor": 2,
                     "legendFormat": "Sent",
                     "refId": "A"
                  },
                  {
                     "expr": "sum(rate(traces_exporter_send_failed_spans{cluster=~\"$cluster\",namespace=~\"$namespace\",container=~\"$container\",pod=~\"$pod\",exporter!=\"otlp\"}[$__rate_interval]))\n",
                     "format": "time_series",
                     "intervalFactor": 2,
                     "legendFormat": "Send failed",
                     "refId": "B"
                  }
               ],
               "thresholds": [ ],
               "timeFrom": null,
               "timeShift": null,
               "title": "Exported spans",
               "tooltip": {
                  "shared": true,
                  "sort": 0,
                  "value_type": "individual"
               },
               "type": "graph",
               "xaxis": {
                  "buckets": null,
                  "mode": "time",
                  "name": null,
                  "show": true,
                  "values": [ ]
               },
               "yaxes": [
                  {
                     "format": "short",
                     "label": null,
                     "logBase": 1,
                     "max": null,
                     "min": null,
                     "show": true
                  },
                  {
                     "format": "short",
                     "label": null,
                     "logBase": 1,
                     "max": null,
                     "min": null,
                     "show": true
                  }
               ]
            }
         ],
         "repeat": null,
         "repeatIteration": null,
         "repeatRowId": null,
         "showTitle": true,
         "title": "Write / Read",
         "titleSize": "h6",
         "type": "row"
      },
      {
         "collapse": false,
         "collapsed": false,
         "panels": [
            {
               "aliasColors": { },
               "bars": false,
               "dashLength": 10,
               "dashes": false,
               "datasource": "$datasource",
               "fill": 1,
               "fillGradient": 0,
               "gridPos": { },
               "id": 8,
               "interval": "1m",
               "legend": {
                  "alignAsTable": false,
                  "avg": false,
                  "current": false,
                  "max": false,
                  "min": false,
                  "rightSide": false,
                  "show": true,
                  "sideWidth": null,
                  "total": false,
                  "values": false
               },
               "lines": true,
               "linewidth": 1,
               "links": [ ],
               "nullPointMode": "null",
               "percentage": false,
               "pointradius": 5,
               "points": false,
               "renderer": "flot",
               "repeat": null,
               "seriesOverrides": [ ],
               "spaceLength": 10,
               "span": 3,
               "stack": true,
               "steppedLine": false,
               "targets": [
                  {
                     "expr": "rate(traces_loadbalancer_backend_outcome{cluster=~\"$cluster\",namespace=~\"$namespace\",success=\"true\",container=~\"$container\",pod=~\"$pod\"}[$__rate_interval])\n",
                     "format": "time_series",
                     "intervalFactor": 2,
                     "legendFormat": "{{ pod }}",
                     "refId": "A"
                  }
               ],
               "thresholds": [ ],
               "timeFrom": null,
               "timeShift": null,
               "title": "Load-balanced spans",
               "tooltip": {
                  "shared": true,
                  "sort": 0,
                  "value_type": "individual"
               },
               "type": "graph",
               "xaxis": {
                  "buckets": null,
                  "mode": "time",
                  "name": null,
                  "show": true,
                  "values": [ ]
               },
               "yaxes": [
                  {
                     "format": "short",
                     "label": null,
                     "logBase": 1,
                     "max": null,
                     "min": null,
                     "show": true
                  },
                  {
                     "format": "short",
                     "label": null,
                     "logBase": 1,
                     "max": null,
                     "min": null,
                     "show": true
                  }
               ]
            },
            {
               "aliasColors": { },
               "bars": false,
               "dashLength": 10,
               "dashes": false,
               "datasource": "$datasource",
               "fill": 0,
               "fillGradient": 0,
               "gridPos": { },
               "id": 9,
               "interval": "1m",
               "legend": {
                  "alignAsTable": false,
                  "avg": false,
                  "current": false,
                  "max": false,
                  "min": false,
                  "rightSide": false,
                  "show": false,
                  "sideWidth": null,
                  "total": false,
                  "values": false
               },
               "lines": true,
               "linewidth": 1,
               "links": [ ],
               "nullPointMode": "null",
               "percentage": false,
               "pointradius": 5,
               "points": false,
               "renderer": "flot",
               "repeat": null,
               "seriesOverrides": [ ],
               "spaceLength": 10,
               "span": 3,
               "stack": false,
               "steppedLine": false,
               "targets": [
                  {
                     "expr": "traces_loadbalancer_num_backends{cluster=~\"$cluster\",namespace=~\"$namespace\",container=~\"$container\",pod=~\"$pod\"}\n",
                     "format": "time_series",
                     "intervalFactor": 2,
                     "legendFormat": "{{ pod }}",
                     "refId": "A"
                  }
               ],
               "thresholds": [ ],
               "timeFrom": null,
               "timeShift": null,
               "title": "Number of peers",
               "tooltip": {
                  "shared": true,
                  "sort": 0,
                  "value_type": "individual"
               },
               "type": "graph",
               "xaxis": {
                  "buckets": null,
                  "mode": "time",
                  "name": null,
                  "show": true,
                  "values": [ ]
               },
               "yaxes": [
                  {
                     "format": "short",
                     "label": null,
                     "logBase": 1,
                     "max": null,
                     "min": null,
                     "show": true
                  },
                  {
                     "format": "short",
                     "label": null,
                     "logBase": 1,
                     "max": null,
                     "min": null,
                     "show": true
                  }
               ]
            },
            {
               "aliasColors": { },
               "bars": false,
               "dashLength": 10,
               "dashes": false,
               "datasource": "$datasource",
               "fill": 1,
               "fillGradient": 0,
               "gridPos": { },
               "id": 10,
               "interval": "1m",
               "legend": {
                  "alignAsTable": false,
                  "avg": false,
                  "current": false,
                  "max": false,
                  "min": false,
                  "rightSide": false,
                  "show": true,
                  "sideWidth": null,
                  "total": false,
                  "values": false
               },
               "lines": true,
               "linewidth": 1,
               "links": [ ],
               "nullPointMode": "null",
               "percentage": false,
               "pointradius": 5,
               "points": false,
               "renderer": "flot",
               "repeat": null,
               "seriesOverrides": [ ],
               "spaceLength": 10,
               "span": 3,
               "stack": false,
               "steppedLine": false,
               "targets": [
                  {
                     "expr": "sum(rate(traces_receiver_accepted_spans{cluster=~\"$cluster\",namespace=~\"$namespace\",container=~\"$container\",pod=~\"$pod\",receiver=\"otlp/lb\"}[$__rate_interval]))\n",
                     "format": "time_series",
                     "intervalFactor": 2,
                     "legendFormat": "Accepted",
                     "refId": "A"
                  },
                  {
                     "expr": "sum(rate(traces_receiver_refused_spans{cluster=~\"$cluster\",namespace=~\"$namespace\",container=~\"$container\",pod=~\"$pod\",receiver=\"otlp/lb\"}[$__rate_interval]))\n",
                     "format": "time_series",
                     "intervalFactor": 2,
                     "legendFormat": "Refused",
                     "refId": "B"
                  }
               ],
               "thresholds": [ ],
               "timeFrom": null,
               "timeShift": null,
               "title": "Received spans",
               "tooltip": {
                  "shared": true,
                  "sort": 0,
                  "value_type": "individual"
               },
               "type": "graph",
               "xaxis": {
                  "buckets": null,
                  "mode": "time",
                  "name": null,
                  "show": true,
                  "values": [ ]
               },
               "yaxes": [
                  {
                     "format": "short",
                     "label": null,
                     "logBase": 1,
                     "max": null,
                     "min": null,
                     "show": true
                  },
                  {
                     "format": "short",
                     "label": null,
                     "logBase": 1,
                     "max": null,
                     "min": null,
                     "show": true
                  }
               ]
            },
            {
               "aliasColors": { },
               "bars": false,
               "dashLength": 10,
               "dashes": false,
               "datasource": "$datasource",
               "fill": 1,
               "fillGradient": 0,
               "gridPos": { },
               "id": 11,
               "interval": "1m",
               "legend": {
                  "alignAsTable": false,
                  "avg": false,
                  "current": false,
                  "max": false,
                  "min": false,
                  "rightSide": false,
                  "show": true,
                  "sideWidth": null,
                  "total": false,
                  "values": false
               },
               "lines": true,
               "linewidth": 1,
               "links": [ ],
               "nullPointMode": "null",
               "percentage": false,
               "pointradius": 5,
               "points": false,
               "renderer": "flot",
               "repeat": null,
               "seriesOverrides": [ ],
               "spaceLength": 10,
               "span": 3,
               "stack": false,
               "steppedLine": false,
               "targets": [
                  {
                     "expr": "sum(rate(traces_exporter_sent_spans{cluster=~\"$cluster\",namespace=~\"$namespace\",container=~\"$container\",pod=~\"$pod\",exporter=\"otlp\"}[$__rate_interval]))\n",
                     "format": "time_series",
                     "intervalFactor": 2,
                     "legendFormat": "Sent",
                     "refId": "A"
                  },
                  {
                     "expr": "sum(rate(traces_exporter_send_failed_spans{cluster=~\"$cluster\",namespace=~\"$namespace\",container=~\"$container\",pod=~\"$pod\",exporter=\"otlp\"}[$__rate_interval]))\n",
                     "format": "time_series",
                     "intervalFactor": 2,
                     "legendFormat": "Send failed",
                     "refId": "B"
                  }
               ],
               "thresholds": [ ],
               "timeFrom": null,
               "timeShift": null,
               "title": "Exported spans",
               "tooltip": {
                  "shared": true,
                  "sort": 0,
                  "value_type": "individual"
               },
               "type": "graph",
               "xaxis": {
                  "buckets": null,
                  "mode": "time",
                  "name": null,
                  "show": true,
                  "values": [ ]
               },
               "yaxes": [
                  {
                     "format": "short",
                     "label": null,
                     "logBase": 1,
                     "max": null,
                     "min": null,
                     "show": true
                  },
                  {
                     "format": "short",
                     "label": null,
                     "logBase": 1,
                     "max": null,
                     "min": null,
                     "show": true
                  }
               ]
            }
         ],
         "repeat": null,
         "repeatIteration": null,
         "repeatRowId": null,
         "showTitle": true,
         "title": "Load balancing",
         "titleSize": "h6",
         "type": "row"
      }
   ],
   "schemaVersion": 14,
   "style": "dark",
   "tags": [
      "grafana-agent-mixin"
   ],
   "templating": {
      "list": [
         {
            "hide": 0,
            "label": null,
            "name": "datasource",
            "options": [ ],
            "query": "prometheus",
            "refresh": 1,
            "regex": "",
            "type": "datasource"
         },
         {
            "allValue": null,
            "current": {
               "text": {
                  "selected": true,
                  "text": "All",
                  "value": "$__all"
               },
               "value": {
                  "selected": true,
                  "text": "All",
                  "value": "$__all"
               }
            },
            "datasource": "$datasource",
            "hide": 0,
            "includeAll": true,
            "label": null,
            "multi": false,
            "name": "cluster",
            "options": [ ],
            "query": "label_values(agent_build_info, cluster)",
            "refresh": 2,
            "regex": "",
            "sort": 0,
            "tagValuesQuery": "",
            "tags": [ ],
            "tagsQuery": "",
            "type": "query",
            "useTags": false
         },
         {
            "allValue": null,
            "current": {
               "text": {
                  "selected": true,
                  "text": "All",
                  "value": "$__all"
               },
               "value": {
                  "selected": true,
                  "text": "All",
                  "value": "$__all"
               }
            },
            "datasource": "$datasource",
            "hide": 0,
            "includeAll": true,
            "label": null,
            "multi": false,
            "name": "namespace",
            "options": [ ],
            "query": "label_values(agent_build_info, namespace)",
            "refresh": 2,
            "regex": "",
            "sort": 0,
            "tagValuesQuery": "",
            "tags": [ ],
            "tagsQuery": "",
            "type": "query",
            "useTags": false
         },
         {
            "allValue": null,
            "current": {
               "text": {
                  "selected": true,
                  "text": "All",
                  "value": "$__all"
               },
               "value": {
                  "selected": true,
                  "text": "All",
                  "value": "$__all"
               }
            },
            "datasource": "$datasource",
            "hide": 0,
            "includeAll": true,
            "label": null,
            "multi": false,
            "name": "container",
            "options": [ ],
            "query": "label_values(agent_build_info, container)",
            "refresh": 2,
            "regex": "",
            "sort": 0,
            "tagValuesQuery": "",
            "tags": [ ],
            "tagsQuery": "",
            "type": "query",
            "useTags": false
         },
         {
            "allValue": null,
            "current": {
               "text": {
                  "selected": true,
                  "text": "All",
                  "value": "$__all"
               },
               "value": {
                  "selected": true,
                  "text": "All",
                  "value": "$__all"
               }
            },
            "datasource": "$datasource",
            "hide": 0,
            "includeAll": true,
            "label": null,
            "multi": false,
            "name": "pod",
            "options": [ ],
            "query": "label_values(agent_build_info{container=~\"$container\"}, pod)",
            "refresh": 2,
            "regex": "",
            "sort": 0,
            "tagValuesQuery": "",
            "tags": [ ],
            "tagsQuery": "",
            "type": "query",
            "useTags": false
         }
      ]
   },
   "time": {
      "from": "now-1h",
      "to": "now"
   },
   "timepicker": {
      "refresh_intervals": [
         "5s",
         "10s",
         "30s",
         "1m",
         "5m",
         "15m",
         "30m",
         "1h",
         "2h",
         "1d"
      ],
      "time_options": [
         "5m",
         "15m",
         "1h",
         "6h",
         "12h",
         "24h",
         "2d",
         "7d",
         "30d"
      ]
   },
   "timezone": "",
   "title": "Agent Tracing Pipeline",
   "version": 0
}

'''
'''--- example/docker-compose/grafana/dashboards/agent.json ---
{
   "annotations": {
      "list": [ ]
   },
   "editable": true,
   "gnetId": null,
   "graphTooltip": 0,
   "hideControls": false,
   "links": [ ],
   "refresh": "30s",
   "rows": [
      {
         "collapse": false,
         "height": "250px",
         "panels": [
            {
               "aliasColors": { },
               "bars": false,
               "dashLength": 10,
               "dashes": false,
               "datasource": "$datasource",
               "fill": 1,
               "id": 1,
               "legend": {
                  "avg": false,
                  "current": false,
                  "max": false,
                  "min": false,
                  "show": true,
                  "total": false,
                  "values": false
               },
               "lines": true,
               "linewidth": 1,
               "links": [ ],
               "nullPointMode": "null as zero",
               "percentage": false,
               "pointradius": 5,
               "points": false,
               "renderer": "flot",
               "seriesOverrides": [ ],
               "spaceLength": 10,
               "span": 12,
               "stack": false,
               "steppedLine": false,
               "styles": [
                  {
                     "alias": "Time",
                     "dateFormat": "YYYY-MM-DD HH:mm:ss",
                     "pattern": "Time",
                     "type": "hidden"
                  },
                  {
                     "alias": "Count",
                     "colorMode": null,
                     "colors": [ ],
                     "dateFormat": "YYYY-MM-DD HH:mm:ss",
                     "decimals": 2,
                     "link": false,
                     "linkTargetBlank": false,
                     "linkTooltip": "Drill down",
                     "linkUrl": "",
                     "pattern": "Value #A",
                     "thresholds": [ ],
                     "type": "hidden",
                     "unit": "short"
                  },
                  {
                     "alias": "Uptime",
                     "colorMode": null,
                     "colors": [ ],
                     "dateFormat": "YYYY-MM-DD HH:mm:ss",
                     "decimals": 2,
                     "link": false,
                     "linkTargetBlank": false,
                     "linkTooltip": "Drill down",
                     "linkUrl": "",
                     "pattern": "Value #B",
                     "thresholds": [ ],
                     "type": "number",
                     "unit": "short"
                  },
                  {
                     "alias": "Container",
                     "colorMode": null,
                     "colors": [ ],
                     "dateFormat": "YYYY-MM-DD HH:mm:ss",
                     "decimals": 2,
                     "link": false,
                     "linkTargetBlank": false,
                     "linkTooltip": "Drill down",
                     "linkUrl": "",
                     "pattern": "container",
                     "thresholds": [ ],
                     "type": "number",
                     "unit": "short"
                  },
                  {
                     "alias": "Pod",
                     "colorMode": null,
                     "colors": [ ],
                     "dateFormat": "YYYY-MM-DD HH:mm:ss",
                     "decimals": 2,
                     "link": false,
                     "linkTargetBlank": false,
                     "linkTooltip": "Drill down",
                     "linkUrl": "",
                     "pattern": "pod",
                     "thresholds": [ ],
                     "type": "number",
                     "unit": "short"
                  },
                  {
                     "alias": "Version",
                     "colorMode": null,
                     "colors": [ ],
                     "dateFormat": "YYYY-MM-DD HH:mm:ss",
                     "decimals": 2,
                     "link": false,
                     "linkTargetBlank": false,
                     "linkTooltip": "Drill down",
                     "linkUrl": "",
                     "pattern": "version",
                     "thresholds": [ ],
                     "type": "number",
                     "unit": "short"
                  },
                  {
                     "alias": "",
                     "colorMode": null,
                     "colors": [ ],
                     "dateFormat": "YYYY-MM-DD HH:mm:ss",
                     "decimals": 2,
                     "pattern": "/.*/",
                     "thresholds": [ ],
                     "type": "string",
                     "unit": "short"
                  }
               ],
               "targets": [
                  {
                     "expr": "count by (pod, container, version) (agent_build_info{cluster=~\"$cluster\", namespace=~\"$namespace\", container=~\"$container\"})",
                     "format": "table",
                     "instant": true,
                     "intervalFactor": 2,
                     "legendFormat": "",
                     "refId": "A",
                     "step": 10
                  },
                  {
                     "expr": "max by (pod, container) (time() - process_start_time_seconds{cluster=~\"$cluster\", namespace=~\"$namespace\", container=~\"$container\"})",
                     "format": "table",
                     "instant": true,
                     "intervalFactor": 2,
                     "legendFormat": "",
                     "refId": "B",
                     "step": 10
                  }
               ],
               "thresholds": [ ],
               "timeFrom": null,
               "timeShift": null,
               "title": "Agent Stats",
               "tooltip": {
                  "shared": true,
                  "sort": 2,
                  "value_type": "individual"
               },
               "transform": "table",
               "type": "table",
               "xaxis": {
                  "buckets": null,
                  "mode": "time",
                  "name": null,
                  "show": true,
                  "values": [ ]
               },
               "yaxes": [
                  {
                     "format": "short",
                     "label": null,
                     "logBase": 1,
                     "max": null,
                     "min": 0,
                     "show": true
                  },
                  {
                     "format": "short",
                     "label": null,
                     "logBase": 1,
                     "max": null,
                     "min": null,
                     "show": false
                  }
               ]
            }
         ],
         "repeat": null,
         "repeatIteration": null,
         "repeatRowId": null,
         "showTitle": true,
         "title": "Agent Stats",
         "titleSize": "h6"
      },
      {
         "collapse": false,
         "height": "250px",
         "panels": [
            {
               "aliasColors": { },
               "bars": false,
               "dashLength": 10,
               "dashes": false,
               "datasource": "$datasource",
               "fill": 1,
               "id": 2,
               "legend": {
                  "avg": false,
                  "current": false,
                  "max": false,
                  "min": false,
                  "show": true,
                  "total": false,
                  "values": false
               },
               "lines": true,
               "linewidth": 1,
               "links": [ ],
               "nullPointMode": "null as zero",
               "percentage": false,
               "pointradius": 5,
               "points": false,
               "renderer": "flot",
               "seriesOverrides": [ ],
               "spaceLength": 10,
               "span": 6,
               "stack": false,
               "steppedLine": false,
               "targets": [
                  {
                     "expr": "sum(rate(prometheus_target_sync_length_seconds_sum{cluster=~\"$cluster\", namespace=~\"$namespace\", container=~\"$container\"}[5m])) by (pod, scrape_job) * 1e3",
                     "format": "time_series",
                     "intervalFactor": 2,
                     "legendFormat": "{{pod}}/{{scrape_job}}",
                     "legendLink": null,
                     "step": 10
                  }
               ],
               "thresholds": [ ],
               "timeFrom": null,
               "timeShift": null,
               "title": "Target Sync",
               "tooltip": {
                  "shared": true,
                  "sort": 2,
                  "value_type": "individual"
               },
               "type": "graph",
               "xaxis": {
                  "buckets": null,
                  "mode": "time",
                  "name": null,
                  "show": true,
                  "values": [ ]
               },
               "yaxes": [
                  {
                     "format": "ms",
                     "label": null,
                     "logBase": 1,
                     "max": null,
                     "min": 0,
                     "show": true
                  },
                  {
                     "format": "short",
                     "label": null,
                     "logBase": 1,
                     "max": null,
                     "min": null,
                     "show": false
                  }
               ]
            },
            {
               "aliasColors": { },
               "bars": false,
               "dashLength": 10,
               "dashes": false,
               "datasource": "$datasource",
               "fill": 10,
               "id": 3,
               "legend": {
                  "avg": false,
                  "current": false,
                  "max": false,
                  "min": false,
                  "show": true,
                  "total": false,
                  "values": false
               },
               "lines": true,
               "linewidth": 0,
               "links": [ ],
               "nullPointMode": "null as zero",
               "percentage": false,
               "pointradius": 5,
               "points": false,
               "renderer": "flot",
               "seriesOverrides": [ ],
               "spaceLength": 10,
               "span": 6,
               "stack": true,
               "steppedLine": false,
               "targets": [
                  {
                     "expr": "sum by (pod) (prometheus_sd_discovered_targets{cluster=~\"$cluster\", namespace=~\"$namespace\", container=~\"$container\"})",
                     "format": "time_series",
                     "intervalFactor": 2,
                     "legendFormat": "{{pod}}",
                     "legendLink": null,
                     "step": 10
                  }
               ],
               "thresholds": [ ],
               "timeFrom": null,
               "timeShift": null,
               "title": "Targets",
               "tooltip": {
                  "shared": true,
                  "sort": 2,
                  "value_type": "individual"
               },
               "type": "graph",
               "xaxis": {
                  "buckets": null,
                  "mode": "time",
                  "name": null,
                  "show": true,
                  "values": [ ]
               },
               "yaxes": [
                  {
                     "format": "short",
                     "label": null,
                     "logBase": 1,
                     "max": null,
                     "min": 0,
                     "show": true
                  },
                  {
                     "format": "short",
                     "label": null,
                     "logBase": 1,
                     "max": null,
                     "min": null,
                     "show": false
                  }
               ]
            }
         ],
         "repeat": null,
         "repeatIteration": null,
         "repeatRowId": null,
         "showTitle": true,
         "title": "Prometheus Discovery",
         "titleSize": "h6"
      },
      {
         "collapse": false,
         "height": "250px",
         "panels": [
            {
               "aliasColors": { },
               "bars": false,
               "dashLength": 10,
               "dashes": false,
               "datasource": "$datasource",
               "fill": 1,
               "id": 4,
               "legend": {
                  "avg": false,
                  "current": false,
                  "max": false,
                  "min": false,
                  "show": true,
                  "total": false,
                  "values": false
               },
               "lines": true,
               "linewidth": 1,
               "links": [ ],
               "nullPointMode": "null as zero",
               "percentage": false,
               "pointradius": 5,
               "points": false,
               "renderer": "flot",
               "seriesOverrides": [ ],
               "spaceLength": 10,
               "span": 4,
               "stack": false,
               "steppedLine": false,
               "targets": [
                  {
                     "expr": "rate(prometheus_target_interval_length_seconds_sum{cluster=~\"$cluster\", namespace=~\"$namespace\", container=~\"$container\"}[5m])\n/\nrate(prometheus_target_interval_length_seconds_count{cluster=~\"$cluster\", namespace=~\"$namespace\", container=~\"$container\"}[5m])\n* 1e3\n",
                     "format": "time_series",
                     "intervalFactor": 2,
                     "legendFormat": "{{pod}} {{interval}} configured",
                     "legendLink": null,
                     "step": 10
                  }
               ],
               "thresholds": [ ],
               "timeFrom": null,
               "timeShift": null,
               "title": "Average Scrape Interval Duration",
               "tooltip": {
                  "shared": true,
                  "sort": 2,
                  "value_type": "individual"
               },
               "type": "graph",
               "xaxis": {
                  "buckets": null,
                  "mode": "time",
                  "name": null,
                  "show": true,
                  "values": [ ]
               },
               "yaxes": [
                  {
                     "format": "ms",
                     "label": null,
                     "logBase": 1,
                     "max": null,
                     "min": 0,
                     "show": true
                  },
                  {
                     "format": "short",
                     "label": null,
                     "logBase": 1,
                     "max": null,
                     "min": null,
                     "show": false
                  }
               ]
            },
            {
               "aliasColors": { },
               "bars": false,
               "dashLength": 10,
               "dashes": false,
               "datasource": "$datasource",
               "fill": 10,
               "id": 5,
               "legend": {
                  "avg": false,
                  "current": false,
                  "max": false,
                  "min": false,
                  "show": true,
                  "total": false,
                  "values": false
               },
               "lines": true,
               "linewidth": 0,
               "links": [ ],
               "nullPointMode": "null as zero",
               "percentage": false,
               "pointradius": 5,
               "points": false,
               "renderer": "flot",
               "seriesOverrides": [ ],
               "spaceLength": 10,
               "span": 4,
               "stack": true,
               "steppedLine": false,
               "targets": [
                  {
                     "expr": "sum by (job) (rate(prometheus_target_scrapes_exceeded_sample_limit_total{cluster=~\"$cluster\", namespace=~\"$namespace\", container=~\"$container\"}[1m]))",
                     "format": "time_series",
                     "intervalFactor": 2,
                     "legendFormat": "exceeded sample limit: {{job}}",
                     "legendLink": null,
                     "step": 10
                  },
                  {
                     "expr": "sum by (job) (rate(prometheus_target_scrapes_sample_duplicate_timestamp_total{cluster=~\"$cluster\", namespace=~\"$namespace\", container=~\"$container\"}[1m]))",
                     "format": "time_series",
                     "intervalFactor": 2,
                     "legendFormat": "duplicate timestamp: {{job}}",
                     "legendLink": null,
                     "step": 10
                  },
                  {
                     "expr": "sum by (job) (rate(prometheus_target_scrapes_sample_out_of_bounds_total{cluster=~\"$cluster\", namespace=~\"$namespace\", container=~\"$container\"}[1m]))",
                     "format": "time_series",
                     "intervalFactor": 2,
                     "legendFormat": "out of bounds: {{job}}",
                     "legendLink": null,
                     "step": 10
                  },
                  {
                     "expr": "sum by (job) (rate(prometheus_target_scrapes_sample_out_of_order_total{cluster=~\"$cluster\", namespace=~\"$namespace\", container=~\"$container\"}[1m]))",
                     "format": "time_series",
                     "intervalFactor": 2,
                     "legendFormat": "out of order: {{job}}",
                     "legendLink": null,
                     "step": 10
                  }
               ],
               "thresholds": [ ],
               "timeFrom": null,
               "timeShift": null,
               "title": "Scrape failures",
               "tooltip": {
                  "shared": true,
                  "sort": 2,
                  "value_type": "individual"
               },
               "type": "graph",
               "xaxis": {
                  "buckets": null,
                  "mode": "time",
                  "name": null,
                  "show": true,
                  "values": [ ]
               },
               "yaxes": [
                  {
                     "format": "short",
                     "label": null,
                     "logBase": 1,
                     "max": null,
                     "min": 0,
                     "show": true
                  },
                  {
                     "format": "short",
                     "label": null,
                     "logBase": 1,
                     "max": null,
                     "min": null,
                     "show": false
                  }
               ]
            },
            {
               "aliasColors": { },
               "bars": false,
               "dashLength": 10,
               "dashes": false,
               "datasource": "$datasource",
               "fill": 10,
               "id": 6,
               "legend": {
                  "avg": false,
                  "current": false,
                  "max": false,
                  "min": false,
                  "show": true,
                  "total": false,
                  "values": false
               },
               "lines": true,
               "linewidth": 0,
               "links": [ ],
               "nullPointMode": "null as zero",
               "percentage": false,
               "pointradius": 5,
               "points": false,
               "renderer": "flot",
               "seriesOverrides": [ ],
               "spaceLength": 10,
               "span": 4,
               "stack": true,
               "steppedLine": false,
               "targets": [
                  {
                     "expr": "sum by (job, instance_group_name) (rate(agent_wal_samples_appended_total{cluster=~\"$cluster\", namespace=~\"$namespace\", container=~\"$container\"}[5m]))",
                     "format": "time_series",
                     "intervalFactor": 2,
                     "legendFormat": "{{job}} {{instance_group_name}}",
                     "legendLink": null,
                     "step": 10
                  }
               ],
               "thresholds": [ ],
               "timeFrom": null,
               "timeShift": null,
               "title": "Appended Samples",
               "tooltip": {
                  "shared": true,
                  "sort": 2,
                  "value_type": "individual"
               },
               "type": "graph",
               "xaxis": {
                  "buckets": null,
                  "mode": "time",
                  "name": null,
                  "show": true,
                  "values": [ ]
               },
               "yaxes": [
                  {
                     "format": "short",
                     "label": null,
                     "logBase": 1,
                     "max": null,
                     "min": 0,
                     "show": true
                  },
                  {
                     "format": "short",
                     "label": null,
                     "logBase": 1,
                     "max": null,
                     "min": null,
                     "show": false
                  }
               ]
            }
         ],
         "repeat": null,
         "repeatIteration": null,
         "repeatRowId": null,
         "showTitle": true,
         "title": "Prometheus Retrieval",
         "titleSize": "h6"
      }
   ],
   "schemaVersion": 14,
   "style": "dark",
   "tags": [
      "grafana-agent-mixin"
   ],
   "templating": {
      "list": [
         {
            "current": {
               "text": "default",
               "value": "default"
            },
            "hide": 0,
            "label": "Data Source",
            "name": "datasource",
            "options": [ ],
            "query": "prometheus",
            "refresh": 1,
            "regex": "",
            "type": "datasource"
         },
         {
            "allValue": ".+",
            "current": {
               "selected": true,
               "text": "All",
               "value": "$__all"
            },
            "datasource": "$datasource",
            "hide": 0,
            "includeAll": true,
            "label": "cluster",
            "multi": true,
            "name": "cluster",
            "options": [ ],
            "query": "label_values(agent_build_info, cluster)",
            "refresh": 1,
            "regex": "",
            "sort": 2,
            "tagValuesQuery": "",
            "tags": [ ],
            "tagsQuery": "",
            "type": "query",
            "useTags": false
         },
         {
            "allValue": ".+",
            "current": {
               "selected": true,
               "text": "All",
               "value": "$__all"
            },
            "datasource": "$datasource",
            "hide": 0,
            "includeAll": true,
            "label": "namespace",
            "multi": true,
            "name": "namespace",
            "options": [ ],
            "query": "label_values(agent_build_info, namespace)",
            "refresh": 1,
            "regex": "",
            "sort": 2,
            "tagValuesQuery": "",
            "tags": [ ],
            "tagsQuery": "",
            "type": "query",
            "useTags": false
         },
         {
            "allValue": ".+",
            "current": {
               "selected": true,
               "text": "All",
               "value": "$__all"
            },
            "datasource": "$datasource",
            "hide": 0,
            "includeAll": true,
            "label": "container",
            "multi": true,
            "name": "container",
            "options": [ ],
            "query": "label_values(agent_build_info, container)",
            "refresh": 1,
            "regex": "",
            "sort": 2,
            "tagValuesQuery": "",
            "tags": [ ],
            "tagsQuery": "",
            "type": "query",
            "useTags": false
         },
         {
            "allValue": "grafana-agent-.*",
            "current": {
               "selected": true,
               "text": "All",
               "value": "$__all"
            },
            "datasource": "$datasource",
            "hide": 0,
            "includeAll": true,
            "label": "pod",
            "multi": true,
            "name": "pod",
            "options": [ ],
            "query": "label_values(agent_build_info{container=~\"$container\"}, pod)",
            "refresh": 1,
            "regex": "",
            "sort": 2,
            "tagValuesQuery": "",
            "tags": [ ],
            "tagsQuery": "",
            "type": "query",
            "useTags": false
         }
      ]
   },
   "time": {
      "from": "now-1h",
      "to": "now"
   },
   "timepicker": {
      "refresh_intervals": [
         "5s",
         "10s",
         "30s",
         "1m",
         "5m",
         "15m",
         "30m",
         "1h",
         "2h",
         "1d"
      ],
      "time_options": [
         "5m",
         "15m",
         "1h",
         "6h",
         "12h",
         "24h",
         "2d",
         "7d",
         "30d"
      ]
   },
   "timezone": "",
   "title": "Agent",
   "uid": "",
   "version": 0
}

'''
'''--- example/docker-compose/grafana/datasources/datasource.yml ---
apiVersion: 1

deleteDatasources:
  - name: Cortex

datasources:
- name: Cortex
  type: prometheus
  access: proxy
  orgId: 1
  url: http://cortex:9009/api/prom
  basicAuth: false
  isDefault: false
  version: 1
  editable: false
- name: Tempo
  type: tempo
  access: proxy
  orgId: 1
  url: http://tempo:3200
  basicAuth: false
  isDefault: false
  version: 1
  editable: false
  apiVersion: 1
  uid: tempo
- name: Loki
  type: loki
  access: proxy 
  orgId: 1
  url: http://loki:3100
  basicAuth: false
  isDefault: false
  version: 1
  editable: false
  jsonData:
    derivedFields:
      - datasourceUid: tempo
        matcherRegex: tid=(\w+)
        name: TraceID
        url: $${__value.raw}

'''
'''--- example/docker-compose/jsonnetfile.json ---
{
  "version": 1,
  "dependencies": [
    {
      "source": {
        "local": {
          "directory": "../../production/grafana-agent-mixin"
        }
      },
      "version": ""
    }
  ],
  "legacyImports": true
}

'''
'''--- example/docker-compose/jsonnetfile.lock.json ---
{
  "version": 1,
  "dependencies": [
    {
      "source": {
        "git": {
          "remote": "https://github.com/grafana/grafonnet-lib.git",
          "subdir": "grafonnet"
        }
      },
      "version": "3626fc4dc2326931c530861ac5bebe39444f6cbf",
      "sum": "gF8foHByYcB25jcUOBqP6jxk0OPifQMjPvKY0HaCk6w="
    },
    {
      "source": {
        "git": {
          "remote": "https://github.com/grafana/jsonnet-libs.git",
          "subdir": "grafana-builder"
        }
      },
      "version": "4452566af0a58f25cda10b3e568fac979fda85c3",
      "sum": "0KkygBQd/AFzUvVzezE4qF/uDYgrwUXVpZfINBti0oc="
    },
    {
      "source": {
        "local": {
          "directory": "../../production/grafana-agent-mixin"
        }
      },
      "version": ""
    }
  ],
  "legacyImports": false
}

'''
'''--- example/docker-compose/load-generator/load-generator.json ---
{
    "topology": {
      "services": [
        {
          "serviceName": "frontend",
          "tagSets": [
            {
              "weight": 1,
              "tags": {
                "version": "v127",
                "region": "us-east-1"
              },
              "tagGenerators": [],
              "inherit": [],
              "maxLatency": 100
            },
            {
              "weight": 1,
              "tags": {
                "version": "v125",
                "region": "us-east-1"
              },
              "tagGenerators": [],
              "inherit": [],
              "maxLatency": 100
            },
            {
              "weight": 2,
              "tags": {
                "version": "v125",
                "region": "us-west-1"
              },
              "tagGenerators": [],
              "inherit": [],
              "maxLatency": 100
            }
          ],
          "routes": [
            {
              "route": "/product",
              "downstreamCalls": {
                "productcatalogservice": "/GetProducts",
                "recommendationservice": "/GetRecommendations",
                "adservice": "/AdRequest"
              },
              "tagSets": [
                {
                  "weight": 1,
                  "tags": {
                    "starter": "charmander"
                  },
                  "tagGenerators": [
                    {
                      "rand": {
                        "seed": 179867746078676,
                        "nextNextGaussian": 0,
                        "haveNextNextGaussian": false
                      },
                      "tagGen": {},
                      "valLength": 16,
                      "numTags": 50,
                      "numVals": 3000
                    }
                  ],
                  "inherit": []
                },
                {
                  "weight": 1,
                  "tags": {
                    "starter": "squirtle"
                  },
                  "tagGenerators": [],
                  "inherit": []
                },
                {
                  "weight": 1,
                  "tags": {
                    "starter": "bulbasaur"
                  },
                  "tagGenerators": [],
                  "inherit": []
                }
              ]
            },
            {
              "route": "/cart",
              "downstreamCalls": {
                "cartservice": "/GetCart",
                "recommendationservice": "/GetRecommendations"
              },
              "tagSets": []
            },
            {
              "route": "/checkout",
              "downstreamCalls": {
                "checkoutservice": "/PlaceOrder"
              },
              "tagSets": [
                {
                  "tags": {},
                  "tagGenerators": [],
                  "inherit": [],
                  "maxLatency": 800
                }
              ]
            },
            {
              "route": "/shipping",
              "downstreamCalls": {
                "shippingservice": "/GetQuote"
              },
              "tagSets": [
                {
                  "tags": {},
                  "tagGenerators": [],
                  "inherit": [],
                  "maxLatency": 50
                }
              ]
            },
            {
              "route": "/currency",
              "downstreamCalls": {
                "currencyservice": "/GetConversion"
              },
              "tagSets": [
                {
                  "tags": {},
                  "tagGenerators": [],
                  "inherit": [],
                  "maxLatency": 50
                }
              ]
            }
          ],
          "instances": [
            "frontend-6b654dbf57-zq8dt",
            "frontend-d847fdcf5-j6s2f",
            "frontend-79d8c8d6c8-9sbff"
          ],
          "mergedTagSets": {},
          "random": {
            "seed": 187004238864083,
            "nextNextGaussian": 0,
            "haveNextNextGaussian": false
          }
        },
        {
          "serviceName": "productcatalogservice",
          "tagSets": [
            {
              "tags": {
                "version": "v52"
              },
              "tagGenerators": [],
              "inherit": [
                "region"
              ]
            }
          ],
          "routes": [
            {
              "route": "/GetProducts",
              "downstreamCalls": {},
              "tagSets": [
                {
                  "tags": {},
                  "tagGenerators": [],
                  "inherit": [
                    "starter"
                  ],
                  "maxLatency": 100
                }
              ]
            },
            {
              "route": "/SearchProducts",
              "downstreamCalls": {},
              "tagSets": [
                {
                  "weight": 15,
                  "tags": {
                    "error": true,
                    "http.status_code": 503
                  },
                  "tagGenerators": [],
                  "inherit": [],
                  "maxLatency": 400
                },
                {
                  "weight": 85,
                  "tags": {},
                  "tagGenerators": [],
                  "inherit": [],
                  "maxLatency": 400
                }
              ]
            }
          ],
          "instances": [
            "productcatalogservice-6b654dbf57-zq8dt",
            "productcatalogservice-d847fdcf5-j6s2f"
          ],
          "mergedTagSets": {},
          "random": {
            "seed": 238238032670139,
            "nextNextGaussian": 0,
            "haveNextNextGaussian": false
          }
        },
        {
          "serviceName": "recommendationservice",
          "tagSets": [
            {
              "tags": {
                "version": "v234",
                "region": "us-east-1"
              },
              "tagGenerators": [],
              "inherit": []
            }
          ],
          "routes": [
            {
              "route": "/GetRecommendations",
              "downstreamCalls": {
                "productcatalogservice": "/GetProducts"
              },
              "tagSets": [
                {
                  "tags": {},
                  "tagGenerators": [],
                  "inherit": [],
                  "maxLatency": 200
                }
              ]
            }
          ],
          "instances": [
            "recommendationservice-6b654dbf57-zq8dt",
            "recommendationservice-d847fdcf5-j6s2f"
          ],
          "mergedTagSets": {},
          "random": {
            "seed": 66295214032801,
            "nextNextGaussian": 0,
            "haveNextNextGaussian": false
          }
        },
        {
          "serviceName": "cartservice",
          "tagSets": [
            {
              "tags": {
                "version": "v5",
                "region": "us-east-1"
              },
              "tagGenerators": [],
              "inherit": []
            }
          ],
          "routes": [
            {
              "route": "/GetCart",
              "downstreamCalls": {},
              "tagSets": [
                {
                  "tags": {},
                  "tagGenerators": [],
                  "inherit": [],
                  "maxLatency": 200
                }
              ]
            }
          ],
          "instances": [
            "cartservice-6b654dbf57-zq8dt",
            "cartservice-d847fdcf5-j6s2f"
          ],
          "mergedTagSets": {},
          "random": {
            "seed": 234194353561392,
            "nextNextGaussian": 0,
            "haveNextNextGaussian": false
          }
        },
        {
          "serviceName": "checkoutservice",
          "tagSets": [
            {
              "tags": {
                "version": "v37",
                "region": "us-east-1"
              },
              "tagGenerators": [],
              "inherit": [],
              "maxLatency": 500
            }
          ],
          "routes": [
            {
              "route": "/PlaceOrder",
              "downstreamCalls": {
                "paymentservice": "/CreditCardInfo",
                "shippingservice": "/Address",
                "currencyservice": "/GetConversion",
                "cartservice": "/GetCart",
                "emailservice": "/SendOrderConfirmation"
              },
              "tagSets": [
                {
                  "weight": 25,
                  "tags": {
                    "error": true,
                    "http.status_code": 503
                  },
                  "tagGenerators": [],
                  "inherit": []
                },
                {
                  "weight": 85,
                  "tags": {},
                  "tagGenerators": [],
                  "inherit": []
                }
              ]
            }
          ],
          "instances": [
            "checkoutservice-6b654dbf57-zq8dt",
            "checkoutservice-d847fdcf5-j6s2f"
          ],
          "mergedTagSets": {},
          "random": {
            "seed": 60782549660568,
            "nextNextGaussian": 0,
            "haveNextNextGaussian": false
          }
        },
        {
          "serviceName": "paymentservice",
          "tagSets": [
            {
              "tags": {
                "version": "v177",
                "region": "us-east-1"
              },
              "tagGenerators": [],
              "inherit": []
            }
          ],
          "routes": [
            {
              "route": "/ChargeRequest",
              "downstreamCalls": {
                "paymentservice": "/CreditCardInfo"
              },
              "tagSets": [
                {
                  "tags": {},
                  "tagGenerators": [],
                  "inherit": [],
                  "maxLatency": 700
                }
              ]
            },
            {
              "route": "/CreditCardInfo",
              "downstreamCalls": {},
              "tagSets": [
                {
                  "tags": {},
                  "tagGenerators": [],
                  "inherit": [],
                  "maxLatency": 50
                }
              ]
            }
          ],
          "instances": [
            "paymentservice-6b654dbf57-zq8dt",
            "paymentservice-d847fdcf5-j6s2f"
          ],
          "mergedTagSets": {},
          "random": {
            "seed": 174850031049111,
            "nextNextGaussian": 0,
            "haveNextNextGaussian": false
          }
        },
        {
          "serviceName": "shippingservice",
          "tagSets": [
            {
              "tags": {
                "version": "v127",
                "region": "us-east-1"
              },
              "tagGenerators": [],
              "inherit": []
            }
          ],
          "routes": [
            {
              "route": "/GetQuote",
              "downstreamCalls": {
                "shippingservice": "/Address"
              },
              "tagSets": [
                {
                  "tags": {},
                  "tagGenerators": [],
                  "inherit": [],
                  "maxLatency": 250
                }
              ]
            },
            {
              "route": "/ShipOrder",
              "downstreamCalls": {
                "shippingservice": "/Address"
              },
              "tagSets": [
                {
                  "tags": {},
                  "tagGenerators": [],
                  "inherit": [],
                  "maxLatency": 500
                }
              ]
            },
            {
              "route": "/Address",
              "downstreamCalls": {},
              "tagSets": [
                {
                  "tags": {},
                  "tagGenerators": [],
                  "inherit": [],
                  "maxLatency": 100
                }
              ]
            }
          ],
          "instances": [
            "shippingservice-6b654dbf57-zq8dt",
            "shippingservice-d847fdcf5-j6s2f"
          ],
          "mergedTagSets": {},
          "random": {
            "seed": 107892261530518,
            "nextNextGaussian": 0,
            "haveNextNextGaussian": false
          }
        },
        {
          "serviceName": "emailservice",
          "tagSets": [
            {
              "tags": {
                "version": "v27",
                "region": "us-east-1"
              },
              "tagGenerators": [],
              "inherit": [],
              "maxLatency": 500
            }
          ],
          "routes": [
            {
              "route": "/SendOrderConfirmation",
              "downstreamCalls": {
                "emailservice": "/OrderResult"
              },
              "tagSets": [
                {
                  "weight": 15,
                  "tags": {
                    "error": true,
                    "http.status_code": 503
                  },
                  "tagGenerators": [],
                  "inherit": []
                },
                {
                  "weight": 85,
                  "tags": {},
                  "tagGenerators": [],
                  "inherit": []
                }
              ]
            },
            {
              "route": "/OrderResult",
              "downstreamCalls": {},
              "tagSets": [
                {
                  "tags": {},
                  "tagGenerators": [],
                  "inherit": [],
                  "maxLatency": 100
                }
              ]
            }
          ],
          "instances": [
            "emailservice-6b654dbf57-zq8dt",
            "emailservice-d847fdcf5-j6s2f"
          ],
          "mergedTagSets": {},
          "random": {
            "seed": 61175057559946,
            "nextNextGaussian": 0,
            "haveNextNextGaussian": false
          }
        },
        {
          "serviceName": "currencyservice",
          "tagSets": [
            {
              "tags": {
                "version": "v27",
                "region": "us-east-1"
              },
              "tagGenerators": [],
              "inherit": []
            }
          ],
          "routes": [
            {
              "route": "/GetConversion",
              "downstreamCalls": {
                "currencyservice": "/Money"
              },
              "tagSets": [
                {
                  "tags": {},
                  "tagGenerators": [],
                  "inherit": [],
                  "maxLatency": 100
                }
              ]
            },
            {
              "route": "/Money",
              "downstreamCalls": {},
              "tagSets": [
                {
                  "tags": {},
                  "tagGenerators": [],
                  "inherit": [],
                  "maxLatency": 100
                }
              ]
            }
          ],
          "instances": [
            "currencyservice-6b654dbf57-zq8dt",
            "currencyservice-d847fdcf5-j6s2f"
          ],
          "mergedTagSets": {},
          "random": {
            "seed": 66219471499700,
            "nextNextGaussian": 0,
            "haveNextNextGaussian": false
          }
        },
        {
          "serviceName": "adservice",
          "tagSets": [
            {
              "tags": {},
              "tagGenerators": [],
              "inherit": [],
              "maxLatency": 500
            }
          ],
          "routes": [
            {
              "route": "/AdRequest",
              "downstreamCalls": {},
              "tagSets": []
            },
            {
              "route": "/Ad",
              "downstreamCalls": {},
              "tagSets": []
            }
          ],
          "instances": [
            "adservice-6b654dbf57-zq8dt",
            "adservice-d847fdcf5-j6s2f"
          ],
          "mergedTagSets": {},
          "random": {
            "seed": 22694143111805,
            "nextNextGaussian": 0,
            "haveNextNextGaussian": false
          }
        }
      ]
    },
    "rootRoutes": [
      {
        "service": "frontend",
        "route": "/product",
        "tracesPerHour": 288
      },
      {
        "service": "frontend",
        "route": "/cart",
        "tracesPerHour": 1440
      },
      {
        "service": "frontend",
        "route": "/shipping",
        "tracesPerHour": 48
      },
      {
        "service": "frontend",
        "route": "/currency",
        "tracesPerHour": 20
      },
      {
        "service": "frontend",
        "route": "/checkout",
        "tracesPerHour": 48
      }
    ]
  }
'''
'''--- example/k3d/README.md ---
# `k3d` Examples

## Agent Environment

The `k3d` example uses `k3d` and `tanka` to produce a Kubernetes environment
that implements a full Grafana Agent environment for testing.

### Requirements

- A Unix-y command line (macOS or Linux will do).
- Kubectl
- Docker
- [Tanka >= v0.9.2](https://github.com/grafana/tanka)
- [k3d >= v4.0.0,<= v5.2.2](https://github.com/rancher/k3d)
- [jsonnet-bundler >= v0.4.0](https://github.com/jsonnet-bundler/jsonnet-bundler)

### Getting Started

Build latest agent images with `make agent-image agentctl-image` in the project root directory if there are local changes to test.

Run the following to create your cluster:

```bash
# Create a new k3d cluster
./scripts/create.bash

# Import images into k3d if they are not available on docker hub
k3d image import -c agent-k3d grafana/agent:main
k3d image import -c agent-k3d grafana/agentctl:main

# Ensure jsonnet is up to date before applying environment
jb install
tk apply ./environment

# Navigate to grafana.k3d.localhost:30080 in your browser to view dashboards

# Delete the k3d cluster when you're done with it
k3d cluster delete agent-k3d
```

## Smoke Test Environment

The smoke test environment is used to validate samples end to end.

### Running

Smoke Test environment is invoked via `/scripts/smoke-test.bash`

This tool will spin up cluster of Grafana Agent, Cortex, Avalanche, Smoke and [Crow](../../tools/crow/README.md) instances. The Smoke deployment will then periodically kill instances and check for any failed alerts. At the end of the duration (default 3h) it will end the testing.

For users who do not have access to the `us.gcr.io/kubernetes-dev` container registry, do the following to run the smoke test:

* Build the Smoke and Crow images locally (from the root project directory):
```
make grafana-agent-crow-image agent-smoke-image
```
* Run the smoke test using `/scripts/smoke-test.bash` script.
* `Smoke` and `Crow` pods will fail because the images are not imported into the cluster. Import them running:
```
k3d image import -c agent-smoke-test us.gcr.io/kubernetes-dev/grafana/agent-smoke:main
k3d image import -c agent-smoke-test us.gcr.io/kubernetes-dev/grafana/agent-crow:main
```

### What to look for?

These alerts are viewable [here](http://prometheus.k3d.localhost:50080/alerts).

Prometheus alerts are triggered:
- If any Crow instances are not running or Crow samples are not being propagated correctly.
- If any Vulture instances are not running or Vulture samples are not being propagated correctly.
- If any Grafana Agents are not running or Grafana Agent limits are outside their norm.

NOTE: The alerts might be in pending until the system settles down.

![](./assets/pending_alert.png)

An alert firing will look similar to the below.

![](./assets/alert_firing.png)

If at the end of the test any issues are found they will look similar to the below.

![](./assets/console_failure.png)

### How to trigger an alert?

Changing the avalanche setting for label_count to 1000, located [here](../../production/tanka/grafana-agent/smoke/avalanche/main.libsonnet). This will ensure the [GrafanaAgentMemHigh](http://prometheus.k3d.localhost:50080/graph?g0.expr=ALERTS%7Balertname%3D%22GrafanaAgentMemHigh%22%7D&g0.tab=1&g0.stacked=0&g0.show_exemplars=0.g0.range_input=1h.) alert exceeds the limit.

![](./assets/trigger_change.png)

### Architecture

By default, a k3d cluster will be created running the following instances

- agent-single - single instance
- agent-cluster - 3 Grafana Agents in clustered configuration
- crow-cluster - serves the agent cluster
- crow-single - serves the single agent
- cortex
- avalanche - selection of avalanche instances serving traffic
- smoke - scales avalanche replicas and introduces chaos by deleting agent pods during testing
- vulture - emits traces and checks if are stored properly
- tempo

Crow and Vulture instances will check to see if the metrics and traces that were scraped shows up in the prometheus endpoint and then will emit metrics on the success of those metrics. This success/failure result will trigger an alert if it is incorrect.

### Metrics Flow

![](./assets/metrics_flow.png)

### Traces Flow

![](./assets/traces_flow.png)

### Avalanche

Avalanche is used to add some additional load on the system and general testing.

'''
'''--- example/k3d/environment/spec.json ---
{
  "apiVersion": "tanka.dev/v1alpha1",
  "kind": "Environment",
  "metadata": {
    "name": "default"
  },
  "spec": {
    "apiServer": "https://0.0.0.0:50443",
    "namespace": "default"
  }
}

'''
'''--- example/k3d/jsonnetfile.json ---
{
  "version": 1,
  "dependencies": [
    {
      "source": {
        "git": {
          "remote": "https://github.com/grafana/cortex-jsonnet.git",
          "subdir": "cortex-mixin"
        }
      },
      "version": "master"
    },
    {
      "source": {
        "git": {
          "remote": "https://github.com/grafana/jsonnet-libs.git",
          "subdir": "ksonnet-util"
        }
      },
      "version": "master"
    },
    {
      "source": {
        "git": {
          "remote": "https://github.com/grafana/tempo.git",
          "subdir": "operations/jsonnet/microservices"
        }
      },
      "version": "main"
    },
    {
      "source": {
        "git": {
          "remote": "https://github.com/grafana/tempo.git",
          "subdir": "operations/jsonnet/single-binary"
        }
      },
      "version": "main"
    },
    {
      "source": {
        "git": {
          "remote": "https://github.com/jsonnet-libs/k8s-alpha.git",
          "subdir": "1.14"
        }
      },
      "version": "master"
    },
    {
      "source": {
        "local": {
          "directory": "../../production/tanka/grafana-agent"
        }
      },
      "version": ""
    },
    {
      "source": {
        "local": {
          "directory": "../../production/grafana-agent-mixin"
        }
      },
      "version": ""
    }
  ],
  "legacyImports": true
}

'''
'''--- example/k3d/jsonnetfile.lock.json ---
{
  "version": 1,
  "dependencies": [
    {
      "source": {
        "git": {
          "remote": "https://github.com/grafana/cortex-jsonnet.git",
          "subdir": "cortex-mixin"
        }
      },
      "version": "56cb5e3d73950b977ba2e4bfd7e46e2acb0b77b2",
      "sum": "CcTh9gpP5UlOs0f8xrqT8f677c4GbkM5AGvl1yWcnyc="
    },
    {
      "source": {
        "git": {
          "remote": "https://github.com/grafana/grafonnet-lib.git",
          "subdir": "grafonnet"
        }
      },
      "version": "3626fc4dc2326931c530861ac5bebe39444f6cbf",
      "sum": "gF8foHByYcB25jcUOBqP6jxk0OPifQMjPvKY0HaCk6w="
    },
    {
      "source": {
        "git": {
          "remote": "https://github.com/grafana/jsonnet-libs.git",
          "subdir": "grafana-builder"
        }
      },
      "version": "b9cc0f3529833096c043084c04bc7b3562a134c4",
      "sum": "slxrtftVDiTlQK22ertdfrg4Epnq97gdrLI63ftUfaE="
    },
    {
      "source": {
        "git": {
          "remote": "https://github.com/grafana/jsonnet-libs.git",
          "subdir": "ksonnet-util"
        }
      },
      "version": "f62b65014b2c443b234af31e4e1754278e66cef9",
      "sum": "A9MKQ++75leyWJR3rxL2mduAr6S9pByQZYmX0OICu2E="
    },
    {
      "source": {
        "git": {
          "remote": "https://github.com/grafana/jsonnet-libs.git",
          "subdir": "mixin-utils"
        }
      },
      "version": "b9cc0f3529833096c043084c04bc7b3562a134c4",
      "sum": "mtTAh8vSa4Eb8ojviyZ9zE2pPq5OgwhK75qsEWkifhI="
    },
    {
      "source": {
        "git": {
          "remote": "https://github.com/grafana/tempo.git",
          "subdir": "operations/jsonnet/microservices"
        }
      },
      "version": "1bf54e94e74e94cd6f68c5c01b9a19eea7ec43bf",
      "sum": "gOPXxIkGZH5Vm+fSnQP/qeJU1rIkIN5ZI7CSLXFFf/k="
    },
    {
      "source": {
        "git": {
          "remote": "https://github.com/grafana/tempo.git",
          "subdir": "operations/jsonnet/single-binary"
        }
      },
      "version": "07e9ef2f1c25a63ac6061307a3a8453b81b5e417",
      "sum": "0f7vj8dSS9a9CRPf8O9LowMHqieUm9bqgfq6uHJGIF4="
    },
    {
      "source": {
        "git": {
          "remote": "https://github.com/jsonnet-libs/k8s-alpha.git",
          "subdir": "1.14"
        }
      },
      "version": "5e7ef40fd1366a02e25f3216a6711848b3f92e07",
      "sum": "PAkcO1sAnVTYotl1GoSOfYNyuU3PtUO/5hgzz2wDotc="
    },
    {
      "source": {
        "local": {
          "directory": "../../production/tanka/grafana-agent"
        }
      },
      "version": ""
    },
    {
      "source": {
        "local": {
          "directory": "../../production/grafana-agent-mixin"
        }
      },
      "version": ""
    }
  ],
  "legacyImports": false
}

'''
'''--- example/k3d/lib/load-generator/load-generator-config.json ---
{
  "topology": {
    "services": [
      {
        "serviceName": "frontend",
        "tagSets": [
          {
            "weight": 1,
            "tags": {
              "version": "v127",
              "region": "us-east-1"
            },
            "tagGenerators": [],
            "inherit": [],
            "maxLatency": 100
          },
          {
            "weight": 1,
            "tags": {
              "version": "v125",
              "region": "us-east-1"
            },
            "tagGenerators": [],
            "inherit": [],
            "maxLatency": 100
          },
          {
            "weight": 2,
            "tags": {
              "version": "v125",
              "region": "us-west-1"
            },
            "tagGenerators": [],
            "inherit": [],
            "maxLatency": 100
          }
        ],
        "routes": [
          {
            "route": "/product",
            "downstreamCalls": {
              "productcatalogservice": "/GetProducts",
              "recommendationservice": "/GetRecommendations",
              "adservice": "/AdRequest"
            },
            "tagSets": [
              {
                "weight": 1,
                "tags": {
                  "starter": "charmander"
                },
                "tagGenerators": [
                  {
                    "rand": {
                      "seed": 179867746078676,
                      "nextNextGaussian": 0,
                      "haveNextNextGaussian": false
                    },
                    "tagGen": {},
                    "valLength": 16,
                    "numTags": 50,
                    "numVals": 3000
                  }
                ],
                "inherit": []
              },
              {
                "weight": 1,
                "tags": {
                  "starter": "squirtle"
                },
                "tagGenerators": [],
                "inherit": []
              },
              {
                "weight": 1,
                "tags": {
                  "starter": "bulbasaur"
                },
                "tagGenerators": [],
                "inherit": []
              }
            ]
          },
          {
            "route": "/cart",
            "downstreamCalls": {
              "cartservice": "/GetCart",
              "recommendationservice": "/GetRecommendations"
            },
            "tagSets": []
          },
          {
            "route": "/checkout",
            "downstreamCalls": {
              "checkoutservice": "/PlaceOrder"
            },
            "tagSets": [
              {
                "tags": {},
                "tagGenerators": [],
                "inherit": [],
                "maxLatency": 800
              }
            ]
          },
          {
            "route": "/shipping",
            "downstreamCalls": {
              "shippingservice": "/GetQuote"
            },
            "tagSets": [
              {
                "tags": {},
                "tagGenerators": [],
                "inherit": [],
                "maxLatency": 50
              }
            ]
          },
          {
            "route": "/currency",
            "downstreamCalls": {
              "currencyservice": "/GetConversion"
            },
            "tagSets": [
              {
                "tags": {},
                "tagGenerators": [],
                "inherit": [],
                "maxLatency": 50
              }
            ]
          }
        ],
        "instances": [
          "frontend-6b654dbf57-zq8dt",
          "frontend-d847fdcf5-j6s2f",
          "frontend-79d8c8d6c8-9sbff"
        ],
        "mergedTagSets": {},
        "random": {
          "seed": 187004238864083,
          "nextNextGaussian": 0,
          "haveNextNextGaussian": false
        }
      },
      {
        "serviceName": "productcatalogservice",
        "tagSets": [
          {
            "tags": {
              "version": "v52"
            },
            "tagGenerators": [],
            "inherit": [
              "region"
            ]
          }
        ],
        "routes": [
          {
            "route": "/GetProducts",
            "downstreamCalls": {},
            "tagSets": [
              {
                "tags": {},
                "tagGenerators": [],
                "inherit": [
                  "starter"
                ],
                "maxLatency": 100
              }
            ]
          },
          {
            "route": "/SearchProducts",
            "downstreamCalls": {},
            "tagSets": [
              {
                "weight": 15,
                "tags": {
                  "error": true,
                  "http.status_code": 503
                },
                "tagGenerators": [],
                "inherit": [],
                "maxLatency": 400
              },
              {
                "weight": 85,
                "tags": {},
                "tagGenerators": [],
                "inherit": [],
                "maxLatency": 400
              }
            ]
          }
        ],
        "instances": [
          "productcatalogservice-6b654dbf57-zq8dt",
          "productcatalogservice-d847fdcf5-j6s2f"
        ],
        "mergedTagSets": {},
        "random": {
          "seed": 238238032670139,
          "nextNextGaussian": 0,
          "haveNextNextGaussian": false
        }
      },
      {
        "serviceName": "recommendationservice",
        "tagSets": [
          {
            "tags": {
              "version": "v234",
              "region": "us-east-1"
            },
            "tagGenerators": [],
            "inherit": []
          }
        ],
        "routes": [
          {
            "route": "/GetRecommendations",
            "downstreamCalls": {
              "productcatalogservice": "/GetProducts"
            },
            "tagSets": [
              {
                "tags": {},
                "tagGenerators": [],
                "inherit": [],
                "maxLatency": 200
              }
            ]
          }
        ],
        "instances": [
          "recommendationservice-6b654dbf57-zq8dt",
          "recommendationservice-d847fdcf5-j6s2f"
        ],
        "mergedTagSets": {},
        "random": {
          "seed": 66295214032801,
          "nextNextGaussian": 0,
          "haveNextNextGaussian": false
        }
      },
      {
        "serviceName": "cartservice",
        "tagSets": [
          {
            "tags": {
              "version": "v5",
              "region": "us-east-1"
            },
            "tagGenerators": [],
            "inherit": []
          }
        ],
        "routes": [
          {
            "route": "/GetCart",
            "downstreamCalls": {},
            "tagSets": [
              {
                "tags": {},
                "tagGenerators": [],
                "inherit": [],
                "maxLatency": 200
              }
            ]
          }
        ],
        "instances": [
          "cartservice-6b654dbf57-zq8dt",
          "cartservice-d847fdcf5-j6s2f"
        ],
        "mergedTagSets": {},
        "random": {
          "seed": 234194353561392,
          "nextNextGaussian": 0,
          "haveNextNextGaussian": false
        }
      },
      {
        "serviceName": "checkoutservice",
        "tagSets": [
          {
            "tags": {
              "version": "v37",
              "region": "us-east-1"
            },
            "tagGenerators": [],
            "inherit": [],
            "maxLatency": 500
          }
        ],
        "routes": [
          {
            "route": "/PlaceOrder",
            "downstreamCalls": {
              "paymentservice": "/CreditCardInfo",
              "shippingservice": "/Address",
              "currencyservice": "/GetConversion",
              "cartservice": "/GetCart",
              "emailservice": "/SendOrderConfirmation"
            },
            "tagSets": [
              {
                "weight": 25,
                "tags": {
                  "error": true,
                  "http.status_code": 503
                },
                "tagGenerators": [],
                "inherit": []
              },
              {
                "weight": 85,
                "tags": {},
                "tagGenerators": [],
                "inherit": []
              }
            ]
          }
        ],
        "instances": [
          "checkoutservice-6b654dbf57-zq8dt",
          "checkoutservice-d847fdcf5-j6s2f"
        ],
        "mergedTagSets": {},
        "random": {
          "seed": 60782549660568,
          "nextNextGaussian": 0,
          "haveNextNextGaussian": false
        }
      },
      {
        "serviceName": "paymentservice",
        "tagSets": [
          {
            "tags": {
              "version": "v177",
              "region": "us-east-1"
            },
            "tagGenerators": [],
            "inherit": []
          }
        ],
        "routes": [
          {
            "route": "/ChargeRequest",
            "downstreamCalls": {
              "paymentservice": "/CreditCardInfo"
            },
            "tagSets": [
              {
                "tags": {},
                "tagGenerators": [],
                "inherit": [],
                "maxLatency": 700
              }
            ]
          },
          {
            "route": "/CreditCardInfo",
            "downstreamCalls": {},
            "tagSets": [
              {
                "tags": {},
                "tagGenerators": [],
                "inherit": [],
                "maxLatency": 50
              }
            ]
          }
        ],
        "instances": [
          "paymentservice-6b654dbf57-zq8dt",
          "paymentservice-d847fdcf5-j6s2f"
        ],
        "mergedTagSets": {},
        "random": {
          "seed": 174850031049111,
          "nextNextGaussian": 0,
          "haveNextNextGaussian": false
        }
      },
      {
        "serviceName": "shippingservice",
        "tagSets": [
          {
            "tags": {
              "version": "v127",
              "region": "us-east-1"
            },
            "tagGenerators": [],
            "inherit": []
          }
        ],
        "routes": [
          {
            "route": "/GetQuote",
            "downstreamCalls": {
              "shippingservice": "/Address"
            },
            "tagSets": [
              {
                "tags": {},
                "tagGenerators": [],
                "inherit": [],
                "maxLatency": 250
              }
            ]
          },
          {
            "route": "/ShipOrder",
            "downstreamCalls": {
              "shippingservice": "/Address"
            },
            "tagSets": [
              {
                "tags": {},
                "tagGenerators": [],
                "inherit": [],
                "maxLatency": 500
              }
            ]
          },
          {
            "route": "/Address",
            "downstreamCalls": {},
            "tagSets": [
              {
                "tags": {},
                "tagGenerators": [],
                "inherit": [],
                "maxLatency": 100
              }
            ]
          }
        ],
        "instances": [
          "shippingservice-6b654dbf57-zq8dt",
          "shippingservice-d847fdcf5-j6s2f"
        ],
        "mergedTagSets": {},
        "random": {
          "seed": 107892261530518,
          "nextNextGaussian": 0,
          "haveNextNextGaussian": false
        }
      },
      {
        "serviceName": "emailservice",
        "tagSets": [
          {
            "tags": {
              "version": "v27",
              "region": "us-east-1"
            },
            "tagGenerators": [],
            "inherit": [],
            "maxLatency": 500
          }
        ],
        "routes": [
          {
            "route": "/SendOrderConfirmation",
            "downstreamCalls": {
              "emailservice": "/OrderResult"
            },
            "tagSets": [
              {
                "weight": 15,
                "tags": {
                  "error": true,
                  "http.status_code": 503
                },
                "tagGenerators": [],
                "inherit": []
              },
              {
                "weight": 85,
                "tags": {},
                "tagGenerators": [],
                "inherit": []
              }
            ]
          },
          {
            "route": "/OrderResult",
            "downstreamCalls": {},
            "tagSets": [
              {
                "tags": {},
                "tagGenerators": [],
                "inherit": [],
                "maxLatency": 100
              }
            ]
          }
        ],
        "instances": [
          "emailservice-6b654dbf57-zq8dt",
          "emailservice-d847fdcf5-j6s2f"
        ],
        "mergedTagSets": {},
        "random": {
          "seed": 61175057559946,
          "nextNextGaussian": 0,
          "haveNextNextGaussian": false
        }
      },
      {
        "serviceName": "currencyservice",
        "tagSets": [
          {
            "tags": {
              "version": "v27",
              "region": "us-east-1"
            },
            "tagGenerators": [],
            "inherit": []
          }
        ],
        "routes": [
          {
            "route": "/GetConversion",
            "downstreamCalls": {
              "currencyservice": "/Money"
            },
            "tagSets": [
              {
                "tags": {},
                "tagGenerators": [],
                "inherit": [],
                "maxLatency": 100
              }
            ]
          },
          {
            "route": "/Money",
            "downstreamCalls": {},
            "tagSets": [
              {
                "tags": {},
                "tagGenerators": [],
                "inherit": [],
                "maxLatency": 100
              }
            ]
          }
        ],
        "instances": [
          "currencyservice-6b654dbf57-zq8dt",
          "currencyservice-d847fdcf5-j6s2f"
        ],
        "mergedTagSets": {},
        "random": {
          "seed": 66219471499700,
          "nextNextGaussian": 0,
          "haveNextNextGaussian": false
        }
      },
      {
        "serviceName": "adservice",
        "tagSets": [
          {
            "tags": {},
            "tagGenerators": [],
            "inherit": [],
            "maxLatency": 500
          }
        ],
        "routes": [
          {
            "route": "/AdRequest",
            "downstreamCalls": {},
            "tagSets": []
          },
          {
            "route": "/Ad",
            "downstreamCalls": {},
            "tagSets": []
          }
        ],
        "instances": [
          "adservice-6b654dbf57-zq8dt",
          "adservice-d847fdcf5-j6s2f"
        ],
        "mergedTagSets": {},
        "random": {
          "seed": 22694143111805,
          "nextNextGaussian": 0,
          "haveNextNextGaussian": false
        }
      }
    ]
  },
  "rootRoutes": [
    {
      "service": "frontend",
      "route": "/product",
      "tracesPerHour": 288
    },
    {
      "service": "frontend",
      "route": "/cart",
      "tracesPerHour": 1440
    },
    {
      "service": "frontend",
      "route": "/shipping",
      "tracesPerHour": 48
    },
    {
      "service": "frontend",
      "route": "/currency",
      "tracesPerHour": 20
    },
    {
      "service": "frontend",
      "route": "/checkout",
      "tracesPerHour": 48
    }
  ]
}
'''
'''--- example/k3d/smoke/spec.json ---
{
  "apiVersion": "tanka.dev/v1alpha1",
  "kind": "Environment",
  "metadata": {
    "name": "default"
  },
  "spec": {
    "apiServer": "https://0.0.0.0:50443",
    "namespace": "default"
  }
}

'''
'''--- operations/agent-flow-mixin/jsonnetfile.json ---
{
  "version": 1,
  "dependencies": [],
  "legacyImports": true
}

'''
'''--- operations/river-jsonnet/README.md ---
# `river-jsonnet` library

The `river-jsonnet` library makes it possible to return River-formatted config
files using Jsonnet.

To manifest a River configuration file, call `river.manifestRiver(value)`.

Field names from objects are expected to follow one of the three forms:

* `<name>` for River attributes (e.g., `foobar`).
* `block <name>` for unlabeled River blocks (e.g., `block exporter.node`)
* `block <name> <label>` for labeled River blocks (.e.g, `block metrics.remote_write default`).

Instead of following these naming conventions, helper functions are provided to
make it easier:

* `river.attr(name)` returns a field name that can be used as an attribute.
* `river.block(name, label="")` returns a field name that represents a block.

In addition to the helper functions, `river.expr(literal)` is used to inject a
literal River expression, so that `river.expr('env("HOME")')` is manifested as
the literal River expression `env("HOME")`.

## Limitations

* Manifested River files always have attributes and object keys in
  lexicographic sort order, regardless of how they were defined in Jsonnet.
* The resulting River files are not pretty-printed to how the formatter would
  print files.

## Example

```jsonnet
local river = import 'github.com/grafana/agent/operations/river-jsonnet/main.libsonnet';

river.manifestRiver({
  attr_1: "Hello, world!",

  [river.block("some_block", "foobar")]: {
    expr: river.expr('env("HOME")'),
    inner_attr_1: [0, 1, 2, 3],
    inner_attr_2: {
      first_name: "John",
      last_name: "Smith",
    },
  },
})
```

results in

```river
attr_1 = "Hello, world"
some_block "foobar" {
  expr = env("HOME")
  inner_attr_1 = [0, 1, 2, 3]
  inner_attr_2 = {
    "first_name" = "John",
    "last_name" = "Smith",
  }
}
```

'''
'''--- operations/river-jsonnet/jsonnetfile.json ---
{
  "version": 1,
  "dependencies": [],
  "legacyImports": true
}

'''
'''--- packaging/linux_packages_test.go ---
//go:build !nonetwork && !nodocker && !race && packaging
// +build !nonetwork,!nodocker,!race,packaging

package packaging_test

import (
	"archive/tar"
	"bytes"
	"fmt"
	"io"
	"os"
	"os/exec"
	"path/filepath"
	"runtime"
	"testing"

	"github.com/ory/dockertest/v3"
	"github.com/ory/dockertest/v3/docker"
	"github.com/stretchr/testify/require"
)

// TestLinuxPackages runs the entire test suite for the Linux packages.
func TestLinuxPackages(t *testing.T) {
	fmt.Println("Building packages (this may take a while...)")
	buildPackages(t)

	dockerPool, err := dockertest.NewPool("")
	require.NoError(t, err)

	tt := []struct {
		name string
		f    func(*testing.T, Environment)
	}{
		{"install package", EnvironmentTestInstall},
		{"ensure existing config doesn't get overridden", EnvironmentTestConfigPersistence},
		{"test data folder permissions", EnvironmentTestDataFolderPermissions},

		// TODO: a test to verify that the systemd service works would be nice, but not
		// required.
		//
		// An implementation of the test would have to consider what host platforms it
		// works on; bind mounting /sys/fs/cgroup and using the host systemd wouldn't
		// work on macOS or Windows.
	}

	for _, tc := range tt {
		t.Run(tc.name+"/rpm", func(t *testing.T) {
			tc.f(t, RPMEnvironment(t, dockerPool))
		})
		t.Run(tc.name+"/deb", func(t *testing.T) {
			tc.f(t, DEBEnvironment(t, dockerPool))
		})
	}
}

func buildPackages(t *testing.T) {
	t.Helper()

	wd, err := os.Getwd()
	require.NoError(t, err)
	root, err := filepath.Abs(filepath.Join(wd, ".."))
	require.NoError(t, err)

	cmd := exec.Command("make", fmt.Sprintf("dist-packages-%s", runtime.GOARCH))
	cmd.Env = append(
		os.Environ(),
		"RELEASE_TAG=v0.0.0",
		"DOCKER_OPTS=",
	)
	cmd.Dir = root
	cmd.Stderr = os.Stderr
	require.NoError(t, cmd.Run())
}

func EnvironmentTestInstall(t *testing.T, env Environment) {
	res := env.Install()
	require.Equal(t, 0, res.ExitCode, "installing failed")

	res = env.ExecScript(`[ -f /usr/bin/grafana-agent ]`)
	require.Equal(t, 0, res.ExitCode, "expected grafana-agent to be installed")
	res = env.ExecScript(`[ -f /usr/bin/grafana-agentctl ]`)
	require.Equal(t, 0, res.ExitCode, "expected grafana-agentctl to be installed")
	res = env.ExecScript(`[ -f /etc/grafana-agent.yaml ]`)
	require.Equal(t, 0, res.ExitCode, "expected grafana agent configuration file to exist")

	res = env.Uninstall()
	require.Equal(t, 0, res.ExitCode, "uninstalling failed")

	res = env.ExecScript(`[ -f /usr/bin/grafana-agent ]`)
	require.Equal(t, 1, res.ExitCode, "expected grafana-agent to be uninstalled")
	res = env.ExecScript(`[ -f /usr/bin/grafana-agentctl ]`)
	require.Equal(t, 1, res.ExitCode, "expected grafana-agentctl to be uninstalled")
	// NOTE(rfratto): we don't check for what happens to the config file here,
	// sicne the behavior is inconsistent: rpm uninstalls it, but deb doesn't.
}

func EnvironmentTestConfigPersistence(t *testing.T, env Environment) {
	res := env.ExecScript(`echo -n "keepalive" > /etc/grafana-agent.yaml`)
	require.Equal(t, 0, res.ExitCode, "failed to write config file")

	res = env.Install()
	require.Equal(t, 0, res.ExitCode, "installation failed")

	res = env.ExecScript(`cat /etc/grafana-agent.yaml`)
	require.Equal(t, "keepalive", res.Stdout, "Expected existing file to not be overridden")
}

func EnvironmentTestDataFolderPermissions(t *testing.T, env Environment) {
	// Installing should create /var/lib/grafana-agent, assign it to the
	// grafana-agent user and group, and set its permissions to 0770.
	res := env.Install()
	require.Equal(t, 0, res.ExitCode, "installation failed")

	res = env.ExecScript(`[ -d /var/lib/grafana-agent ]`)
	require.Equal(t, 0, res.ExitCode, "Expected /var/lib/grafana-agent to have been created during install")

	res = env.ExecScript(`stat -c '%a:%U:%G' /var/lib/grafana-agent`)
	require.Equal(t, "770:grafana-agent:grafana-agent\n", res.Stdout, "wrong permissions for data folder")
	require.Equal(t, 0, res.ExitCode, "stat'ing data folder failed")
}

type Environment struct {
	Install    func() ExecResult
	Uninstall  func() ExecResult
	ExecScript func(string) ExecResult
}

type ExecResult struct {
	Stdout, Stderr string
	ExitCode       int
}

// RPMEnvironment creates an Environment to install the agent RPM against.
func RPMEnvironment(t *testing.T, pool *dockertest.Pool) Environment {
	t.Helper()

	container := environmentContainer(
		t,
		pool,
		"./testdata/centos-systemd.Dockerfile",
		"agent-test-centos-systemd",
		fmt.Sprintf("../dist/grafana-agent-0.0.0-1.%s.rpm", runtime.GOARCH),
	)

	return Environment{
		Install: func() ExecResult {
			filename := fmt.Sprintf("/tmp/grafana-agent-0.0.0-1.%s.rpm", runtime.GOARCH)
			return containerExec(t, container, "rpm", "-i", filename)
		},
		Uninstall: func() ExecResult {
			return containerExec(t, container, "rpm", "-e", "grafana-agent")
		},
		ExecScript: func(script string) ExecResult {
			return containerExec(t, container, "/bin/bash", "-c", script)
		},
	}
}

// DEBEnvironment creates an Environment to install the agent RPM against.
func DEBEnvironment(t *testing.T, pool *dockertest.Pool) Environment {
	t.Helper()

	container := environmentContainer(
		t,
		pool,
		"./testdata/debian-systemd.Dockerfile",
		"agent-test-debian-systemd",
		fmt.Sprintf("../dist/grafana-agent-0.0.0-1.%s.deb", runtime.GOARCH),
	)

	return Environment{
		Install: func() ExecResult {
			filename := fmt.Sprintf("/tmp/grafana-agent-0.0.0-1.%s.deb", runtime.GOARCH)
			return containerExec(t, container, "dpkg", "--force-confold", "-i", filename)
		},
		Uninstall: func() ExecResult {
			return containerExec(t, container, "dpkg", "-r", "grafana-agent")
		},
		ExecScript: func(script string) ExecResult {
			return containerExec(t, container, "/bin/bash", "-c", script)
		},
	}
}

func environmentContainer(t *testing.T, pool *dockertest.Pool, dockerfile string, name string, packagePath string) *dockertest.Resource {
	t.Helper()

	container, err := pool.BuildAndRunWithOptions(
		dockerfile,
		&dockertest.RunOptions{
			Name:       name,
			Entrypoint: []string{"/bin/bash"},
			Tty:        true,
			Mounts:     []string{"/sys/fs/cgroup:/sys/fs/cgroup:ro"},
			PortBindings: map[docker.Port][]docker.PortBinding{
				"9009/tcp": {{HostIP: "0.0.0.0", HostPort: "0"}},
			},
		},
		func(hc *docker.HostConfig) {
			hc.Tmpfs = map[string]string{
				"/run":      "rw",
				"/run/lock": "rw",
			}
		},
	)
	require.NoError(t, err)
	t.Cleanup(func() {
		_ = container.Close()
	})

	packageFile, err := buildTar(packagePath)
	require.NoError(t, err)
	err = pool.Client.UploadToContainer(container.Container.ID, docker.UploadToContainerOptions{
		InputStream: packageFile,
		Path:        "/tmp",
	})
	require.NoError(t, err)

	return container
}

func buildTar(path string) (io.Reader, error) {
	f, err := os.Open(path)
	if err != nil {
		return nil, err
	}
	defer f.Close()

	fi, err := f.Stat()
	if err != nil {
		return nil, err
	}

	var buf bytes.Buffer
	w := tar.NewWriter(&buf)
	defer w.Close()

	err = w.WriteHeader(&tar.Header{
		Typeflag: tar.TypeReg,
		Name:     filepath.Base(path),
		Size:     fi.Size(),
		ModTime:  fi.ModTime(),
		Mode:     0600,
	})
	if err != nil {
		return nil, err
	}

	_, err = io.Copy(w, f)
	return &buf, err
}

func containerExec(t *testing.T, res *dockertest.Resource, cmd ...string) ExecResult {
	t.Helper()

	var stdout, stderr bytes.Buffer

	exitCode, err := res.Exec(cmd, dockertest.ExecOptions{
		StdOut: &stdout,
		StdErr: &stderr,
	})
	require.NoError(t, err)

	return ExecResult{
		Stdout:   stdout.String(),
		Stderr:   stderr.String(),
		ExitCode: exitCode,
	}
}

'''
'''--- packaging/rpm/gpg-sign.sh ---
#!/usr/bin/env bash

# We are not using fpm's signing functionality because it does not work anymore
# https://github.com/jordansissel/fpm/issues/1626

set -euxo pipefail
shopt -s extglob

# Write GPG key to GPG keyring
printf "%s" "${GPG_PUBLIC_KEY}" > /tmp/gpg-public-key
gpg --import /tmp/gpg-public-key
printf "%s" "${GPG_PRIVATE_KEY}" | gpg --import --no-tty --batch --yes --passphrase "${GPG_PASSPHRASE}"

rpm --import /tmp/gpg-public-key

echo "%_gpg_name Grafana <info@grafana.com>
%_signature gpg
%_gpg_path /root/.gnupg
%_gpgbin /usr/bin/gpg
%__gpg /usr/bin/gpg
%__gpg_sign_cmd     %{__gpg} \
         gpg --no-tty --batch --yes --no-verbose --no-armor \
         --passphrase ${GPG_PASSPHRASE} \
         --pinentry-mode loopback \
         %{?_gpg_digest_algo:--digest-algo %{_gpg_digest_algo}} \
         --no-secmem-warning \
         -u \"%{_gpg_name}\" -sbo %{__signature_filename} %{__plaintext_filename}
" > ~/.rpmmacros

for f in dist/*.rpm; do
  rpm --addsign "${f}"
  rpm --checksig "${f}"
done

'''
'''--- pkg/agentctl/cardinality.go ---
package agentctl

import (
	"github.com/prometheus/prometheus/tsdb/record"
	"github.com/prometheus/prometheus/tsdb/wal"
)

// Cardinality represents some metric by name and the number of times that metric is used
// with a different combination of unique labels.
type Cardinality struct {
	Metric    string
	Instances int
}

// FindCardinality searches the WAL and returns the cardinality of all __name__
// series within the WAL for any given series with the label job=<job> and
// instance=<instance>. All other series are ignored.
func FindCardinality(walDir string, job string, instance string) ([]Cardinality, error) {
	w, err := wal.Open(nil, walDir)
	if err != nil {
		return nil, err
	}
	defer w.Close()

	cardinality := map[string]int{}

	err = walIterate(w, func(r *wal.Reader) error {
		return collectCardinality(r, job, instance, cardinality)
	})
	if err != nil {
		return nil, err
	}

	res := make([]Cardinality, 0, len(cardinality))
	for k, v := range cardinality {
		res = append(res, Cardinality{Metric: k, Instances: v})
	}
	return res, nil
}

func collectCardinality(r *wal.Reader, job, instance string, cardinality map[string]int) error {
	var dec record.Decoder

	for r.Next() {
		rec := r.Record()

		switch dec.Type(rec) {
		case record.Series:
			series, err := dec.Series(rec, nil)
			if err != nil {
				return err
			}
			for _, s := range series {
				var (
					jobLabel      = s.Labels.Get("job")
					instanceLabel = s.Labels.Get("instance")
				)

				if jobLabel == job && instanceLabel == instance {
					cardinality[s.Labels.Get("__name__")]++
				}
			}
		}
	}

	return r.Err()
}

'''
'''--- pkg/agentctl/cardinality_test.go ---
package agentctl

import (
	"sort"
	"strings"
	"testing"

	"github.com/stretchr/testify/require"
)

func TestCardinality(t *testing.T) {
	walDir := setupTestWAL(t)

	cardinality, err := FindCardinality(walDir, "test-job", "test-instance")
	sort.Slice(cardinality, func(i, j int) bool {
		return strings.Compare(cardinality[i].Metric, cardinality[j].Metric) == -1
	})

	require.NoError(t, err)
	require.Equal(t, []Cardinality{
		{Metric: "metric_0", Instances: 2},
		{Metric: "metric_1", Instances: 3}, // metric_1 has a duplicate hash so it's the only metric with 3 instances
		{Metric: "metric_2", Instances: 2},
		{Metric: "metric_3", Instances: 2},
		{Metric: "metric_4", Instances: 2},
		{Metric: "metric_5", Instances: 2},
		{Metric: "metric_6", Instances: 2},
		{Metric: "metric_7", Instances: 2},
		{Metric: "metric_8", Instances: 2},
		{Metric: "metric_9", Instances: 2},
	}, cardinality)
}

'''
'''--- pkg/agentctl/samples.go ---
package agentctl

import (
	"fmt"
	"time"

	"github.com/prometheus/prometheus/model/labels"
	"github.com/prometheus/prometheus/model/timestamp"
	"github.com/prometheus/prometheus/promql/parser"
	"github.com/prometheus/prometheus/tsdb/chunks"
	"github.com/prometheus/prometheus/tsdb/record"
	"github.com/prometheus/prometheus/tsdb/wal"
)

// SampleStats are statistics for samples for a series within the WAL. Each
// instance represents a unique series based on its labels, and holds the range
// of timestamps found for all samples including the total number of samples
// for that series.
type SampleStats struct {
	Labels  labels.Labels
	From    time.Time
	To      time.Time
	Samples int64
}

// FindSamples searches the WAL and returns a summary of samples of series
// matching the given label selector.
func FindSamples(walDir string, selectorStr string) ([]*SampleStats, error) {
	w, err := wal.Open(nil, walDir)
	if err != nil {
		return nil, err
	}
	defer w.Close()

	selector, err := parser.ParseMetricSelector(selectorStr)
	if err != nil {
		return nil, err
	}

	var (
		labelsByRef = make(map[chunks.HeadSeriesRef]labels.Labels)

		minTSByRef       = make(map[chunks.HeadSeriesRef]int64)
		maxTSByRef       = make(map[chunks.HeadSeriesRef]int64)
		sampleCountByRef = make(map[chunks.HeadSeriesRef]int64)
	)

	// get the references matching label selector
	err = walIterate(w, func(r *wal.Reader) error {
		return collectSeries(r, selector, labelsByRef)
	})
	if err != nil {
		return nil, fmt.Errorf("could not collect series: %w", err)
	}

	// find related samples
	err = walIterate(w, func(r *wal.Reader) error {
		return collectSamples(r, labelsByRef, minTSByRef, maxTSByRef, sampleCountByRef)
	})
	if err != nil {
		return nil, fmt.Errorf("could not collect samples: %w", err)
	}

	series := make([]*SampleStats, 0, len(labelsByRef))
	for ref, labels := range labelsByRef {
		series = append(series, &SampleStats{
			Labels:  labels,
			Samples: sampleCountByRef[ref],
			From:    timestamp.Time(minTSByRef[ref]),
			To:      timestamp.Time(maxTSByRef[ref]),
		})
	}

	return series, nil
}

func collectSeries(r *wal.Reader, selector labels.Selector, labelsByRef map[chunks.HeadSeriesRef]labels.Labels) error {
	var dec record.Decoder

	for r.Next() {
		rec := r.Record()

		switch dec.Type(rec) {
		case record.Series:
			series, err := dec.Series(rec, nil)
			if err != nil {
				return err
			}
			for _, s := range series {
				if selector.Matches(s.Labels) {
					labelsByRef[s.Ref] = s.Labels.Copy()
				}
			}
		}
	}

	return r.Err()
}

func collectSamples(r *wal.Reader, labelsByRef map[chunks.HeadSeriesRef]labels.Labels, minTS, maxTS, sampleCount map[chunks.HeadSeriesRef]int64) error {
	var dec record.Decoder

	for r.Next() {
		rec := r.Record()

		switch dec.Type(rec) {
		case record.Samples:
			samples, err := dec.Samples(rec, nil)
			if err != nil {
				return err
			}

			for _, s := range samples {
				// skip unmatched series
				if _, ok := labelsByRef[s.Ref]; !ok {
					continue
				}

				// determine min/max TS
				if ts, ok := minTS[s.Ref]; !ok || ts > s.T {
					minTS[s.Ref] = s.T
				}
				if ts, ok := maxTS[s.Ref]; !ok || ts < s.T {
					maxTS[s.Ref] = s.T
				}

				sampleCount[s.Ref]++
			}
		}
	}

	return r.Err()
}

'''
'''--- pkg/agentctl/sync.go ---
package agentctl

import (
	"context"
	"errors"
	"fmt"
	"os"
	"path/filepath"
	"strings"

	"github.com/go-kit/log"
	"github.com/go-kit/log/level"
	"github.com/grafana/agent/pkg/client"
	"github.com/grafana/agent/pkg/metrics/instance"
)

// ConfigSync loads YAML files from a directory and syncs them to the
// provided PrometheusClient API. All YAML files will be synced and
// must be valid.
//
// The base name of the YAML file (i.e., without the file extension)
// is used as the config name.
//
// ConfigSync will completely overwrite the set of active configs
// present in the provided PrometheusClient - configs present in the
// API but not in the directory will be deleted.
func ConfigSync(logger log.Logger, cli client.PrometheusClient, dir string, dryRun bool) error {
	if logger == nil {
		logger = log.NewNopLogger()
	}

	ctx := context.Background()
	cfgs, err := ConfigsFromDirectory(dir)
	if err != nil {
		return err
	}

	if dryRun {
		level.Info(logger).Log("msg", "config files validated successfully")
		return nil
	}

	uploaded := make(map[string]struct{}, len(cfgs))
	var hadErrors bool

	for _, cfg := range cfgs {
		level.Info(logger).Log("msg", "uploading config", "name", cfg.Name)
		err := cli.PutConfiguration(ctx, cfg.Name, cfg)
		if err != nil {
			level.Error(logger).Log("msg", "failed to upload config", "name", cfg.Name, "err", err)
			hadErrors = true
		}
		uploaded[cfg.Name] = struct{}{}
	}

	existing, err := cli.ListConfigs(ctx)
	if err != nil {
		return fmt.Errorf("could not list configs: %w", err)
	}

	// Delete configs from the existing API list that we didn't upload.
	for _, existing := range existing.Configs {
		if _, existsLocally := uploaded[existing]; !existsLocally {
			level.Info(logger).Log("msg", "deleting config", "name", existing)
			err := cli.DeleteConfiguration(ctx, existing)
			if err != nil {
				level.Error(logger).Log("msg", "failed to delete outdated config", "name", existing, "err", err)
				hadErrors = true
			}
		}
	}

	if hadErrors {
		return errors.New("one or more configurations failed to be modified; check the logs for more details")
	}

	return nil
}

// ConfigsFromDirectory parses all YAML files from a directory and
// loads each as an instance.Config.
func ConfigsFromDirectory(dir string) ([]*instance.Config, error) {
	var files []string
	err := filepath.Walk(dir, func(path string, info os.FileInfo, err error) error {
		if err != nil {
			return err
		}
		if info.IsDir() {
			if dir == path {
				return nil
			}
			return filepath.SkipDir
		}

		if strings.HasSuffix(path, ".yaml") || strings.HasSuffix(path, ".yml") {
			files = append(files, path)
		}
		return nil
	})
	if err != nil {
		return nil, err
	}

	var configs []*instance.Config
	for _, file := range files {
		cfg, err := configFromFile(file)
		if err != nil {
			return nil, err
		}
		configs = append(configs, cfg)
	}

	return configs, nil
}

func configFromFile(path string) (*instance.Config, error) {
	var (
		fileName   = filepath.Base(path)
		configName = strings.TrimSuffix(fileName, filepath.Ext(fileName))
	)

	f, err := os.Open(path)
	if f != nil {
		defer f.Close()
	}
	if err != nil {
		return nil, err
	}

	cfg, err := instance.UnmarshalConfig(f)
	if err != nil {
		return nil, err
	}
	cfg.Name = configName
	return cfg, nil
}

'''
'''--- pkg/agentctl/sync_test.go ---
package agentctl

import (
	"context"
	"errors"
	"testing"

	"github.com/grafana/agent/pkg/metrics/cluster/configapi"
	"github.com/grafana/agent/pkg/metrics/instance"
	"github.com/stretchr/testify/require"
)

func TestConfigSync_EmptyStore(t *testing.T) {
	cli := &mockFuncPromClient{}
	cli.ListConfigsFunc = func(_ context.Context) (*configapi.ListConfigurationsResponse, error) {
		return &configapi.ListConfigurationsResponse{}, nil
	}

	var putConfigs []string
	cli.PutConfigurationFunc = func(_ context.Context, name string, _ *instance.Config) error {
		putConfigs = append(putConfigs, name)
		return nil
	}

	err := ConfigSync(nil, cli, "./testdata", false)
	require.NoError(t, err)

	expect := []string{
		"agent-1",
		"agent-2",
		"agent-3",
	}
	require.Equal(t, expect, putConfigs)
}

func TestConfigSync_PrepopulatedStore(t *testing.T) {
	cli := &mockFuncPromClient{}
	cli.ListConfigsFunc = func(_ context.Context) (*configapi.ListConfigurationsResponse, error) {
		return &configapi.ListConfigurationsResponse{
			Configs: []string{"delete-a", "agent-1", "delete-b", "delete-c"},
		}, nil
	}

	var putConfigs []string
	cli.PutConfigurationFunc = func(_ context.Context, name string, _ *instance.Config) error {
		putConfigs = append(putConfigs, name)
		return nil
	}

	var deletedConfigs []string
	cli.DeleteConfigurationFunc = func(_ context.Context, name string) error {
		deletedConfigs = append(deletedConfigs, name)
		return nil
	}

	err := ConfigSync(nil, cli, "./testdata", false)
	require.NoError(t, err)

	expectUpdated := []string{
		"agent-1",
		"agent-2",
		"agent-3",
	}
	require.Equal(t, expectUpdated, putConfigs)

	expectDeleted := []string{
		"delete-a",
		"delete-b",
		"delete-c",
	}
	require.Equal(t, expectDeleted, deletedConfigs)
}

func TestConfigSync_DryRun(t *testing.T) {
	cli := &mockFuncPromClient{}
	cli.ListConfigsFunc = func(_ context.Context) (*configapi.ListConfigurationsResponse, error) {
		return &configapi.ListConfigurationsResponse{
			Configs: []string{"delete-a", "agent-1", "delete-b", "delete-c"},
		}, nil
	}

	cli.PutConfigurationFunc = func(_ context.Context, name string, _ *instance.Config) error {
		t.FailNow()
		return nil
	}

	cli.DeleteConfigurationFunc = func(_ context.Context, name string) error {
		t.FailNow()
		return nil
	}

	err := ConfigSync(nil, cli, "./testdata", true)
	require.NoError(t, err)
}

type mockFuncPromClient struct {
	InstancesFunc           func(ctx context.Context) ([]string, error)
	ListConfigsFunc         func(ctx context.Context) (*configapi.ListConfigurationsResponse, error)
	GetConfigurationFunc    func(ctx context.Context, name string) (*instance.Config, error)
	PutConfigurationFunc    func(ctx context.Context, name string, cfg *instance.Config) error
	DeleteConfigurationFunc func(ctx context.Context, name string) error
}

func (m mockFuncPromClient) Instances(ctx context.Context) ([]string, error) {
	if m.InstancesFunc != nil {
		return m.InstancesFunc(ctx)
	}
	return nil, errors.New("not implemented")
}

func (m mockFuncPromClient) ListConfigs(ctx context.Context) (*configapi.ListConfigurationsResponse, error) {
	if m.ListConfigsFunc != nil {
		return m.ListConfigsFunc(ctx)
	}
	return nil, errors.New("not implemented")
}

func (m mockFuncPromClient) GetConfiguration(ctx context.Context, name string) (*instance.Config, error) {
	if m.GetConfigurationFunc != nil {
		return m.GetConfigurationFunc(ctx, name)
	}
	return nil, errors.New("not implemented")
}

func (m mockFuncPromClient) PutConfiguration(ctx context.Context, name string, cfg *instance.Config) error {
	if m.PutConfigurationFunc != nil {
		return m.PutConfigurationFunc(ctx, name, cfg)
	}
	return errors.New("not implemented")
}

func (m mockFuncPromClient) DeleteConfiguration(ctx context.Context, name string) error {
	if m.DeleteConfigurationFunc != nil {
		return m.DeleteConfigurationFunc(ctx, name)
	}
	return errors.New("not implemented")
}

'''
'''--- pkg/agentctl/wal_iterator.go ---
package agentctl

import (
	"github.com/prometheus/prometheus/tsdb/record"
	"github.com/prometheus/prometheus/tsdb/wal"
)

// walIterate iterates over the latest checkpoint in the provided WAL and all
// of the segments in the WAL and calls f for each of them.
func walIterate(w *wal.WAL, f func(r *wal.Reader) error) error {
	checkpoint, checkpointIdx, err := wal.LastCheckpoint(w.Dir())
	if err != nil && err != record.ErrNotFound {
		return err
	}

	startIdx, last, err := wal.Segments(w.Dir())
	if err != nil {
		return err
	}

	if checkpoint != "" {
		sr, err := wal.NewSegmentsReader(checkpoint)
		if err != nil {
			return err
		}
		err = f(wal.NewReader(sr))
		_ = sr.Close()
		if err != nil {
			return err
		}

		startIdx = checkpointIdx + 1
	}

	for i := startIdx; i <= last; i++ {
		s, err := wal.OpenReadSegment(wal.SegmentName(w.Dir(), i))
		if err != nil {
			return err
		}
		sr := wal.NewSegmentBufReader(s)
		err = f(wal.NewReader(sr))
		_ = sr.Close()
		if err != nil {
			return err
		}
	}

	return nil
}

'''
'''--- pkg/agentctl/walstats.go ---
package agentctl

import (
	"math"
	"time"

	"github.com/prometheus/prometheus/model/timestamp"
	"github.com/prometheus/prometheus/tsdb/chunks"
	"github.com/prometheus/prometheus/tsdb/record"
	"github.com/prometheus/prometheus/tsdb/wal"
)

// WALStats stores statistics on the whole WAL.
type WALStats struct {
	// From holds the first timestamp for the oldest sample found within the WAL.
	From time.Time

	// To holds the last timestamp for the newest sample found within the WAL.
	To time.Time

	// CheckpointNumber is the segment number of the most recently created
	// checkpoint.
	CheckpointNumber int

	// FirstSegment is the segment number of the first (oldest) non-checkpoint
	// segment file found within the WAL folder.
	FirstSegment int

	// FirstSegment is the segment number of the last (newest) non-checkpoint
	// segment file found within the WAL folder.
	LastSegment int

	// InvalidRefs is the number of samples with a ref ID to which there is no
	// series defined.
	InvalidRefs int

	// HashCollisions is the total number of times there has been a hash
	// collision. A hash collision is any instance in which a hash of labels
	// is defined by two ref IDs.
	//
	// For the Grafana Agent, a hash collision has no negative side effects
	// on data sent to the remote_write endpoint but may have a noticeable inpact
	// on memory while the collision exists.
	HashCollisions int

	// Targets holds stats on specific scrape targets.
	Targets []WALTargetStats
}

// Series returns the number of series across all targets.
func (s WALStats) Series() int {
	var series int
	for _, t := range s.Targets {
		series += t.Series
	}
	return series
}

// Samples returns the number of Samples across all targets.
func (s WALStats) Samples() int {
	var samples int
	for _, t := range s.Targets {
		samples += t.Samples
	}
	return samples
}

// WALTargetStats aggregates statistics on scrape targets across the entirety
// of the WAL and its checkpoints.
type WALTargetStats struct {
	// Job corresponds to the "job" label on the scraped target.
	Job string

	// Instance corresponds to the "instance" label on the scraped target.
	Instance string

	// Series is the total number of series for the scraped target. It is
	// equivalent to the total cardinality.
	Series int

	// Samples is the total number of samples for the scraped target.
	Samples int
}

// CalculateStats calculates the statistics of the WAL for the given directory.
// walDir must be a folder containing segment files and checkpoint directories.
func CalculateStats(walDir string) (WALStats, error) {
	w, err := wal.Open(nil, walDir)
	if err != nil {
		return WALStats{}, err
	}
	defer w.Close()

	return newWALStatsCalculator(w).Calculate()
}

type walStatsCalculator struct {
	w *wal.WAL

	fromTime    int64
	toTime      int64
	invalidRefs int

	stats []*WALTargetStats

	statsLookup map[chunks.HeadSeriesRef]*WALTargetStats

	// hash -> # ref IDs with that hash
	hashInstances map[uint64]int
}

func newWALStatsCalculator(w *wal.WAL) *walStatsCalculator {
	return &walStatsCalculator{
		w:             w,
		fromTime:      math.MaxInt64,
		statsLookup:   make(map[chunks.HeadSeriesRef]*WALTargetStats),
		hashInstances: make(map[uint64]int),
	}
}

func (c *walStatsCalculator) Calculate() (WALStats, error) {
	var (
		stats WALStats
		err   error
	)

	_, checkpointIdx, err := wal.LastCheckpoint(c.w.Dir())
	if err != nil && err != record.ErrNotFound {
		return stats, err
	}

	firstSegment, lastSegment, err := wal.Segments(c.w.Dir())
	if err != nil {
		return stats, err
	}

	stats.FirstSegment = firstSegment
	stats.LastSegment = lastSegment
	stats.CheckpointNumber = checkpointIdx

	// Iterate over the WAL and collect stats. This must be done before the rest
	// of the function as readWAL populates internal state used for calculating
	// stats.
	err = walIterate(c.w, c.readWAL)
	if err != nil {
		return stats, err
	}

	// Fill in the rest of the stats
	stats.From = timestamp.Time(c.fromTime)
	stats.To = timestamp.Time(c.toTime)
	stats.InvalidRefs = c.invalidRefs

	for _, hashCount := range c.hashInstances {
		if hashCount > 1 {
			stats.HashCollisions++
		}
	}

	for _, tgt := range c.stats {
		stats.Targets = append(stats.Targets, *tgt)
	}

	return stats, nil
}

func (c *walStatsCalculator) readWAL(r *wal.Reader) error {
	var dec record.Decoder

	for r.Next() {
		rec := r.Record()

		// We ignore other record types here; we only write records and samples
		// but we don't want to return an error for an unexpected record type;
		// doing so would prevent users from getting stats on a traditional
		// Prometheus WAL, which would be nice to support.
		switch dec.Type(rec) {
		case record.Series:
			series, err := dec.Series(rec, nil)
			if err != nil {
				return err
			}
			for _, s := range series {
				var (
					jobLabel      = s.Labels.Get("job")
					instanceLabel = s.Labels.Get("instance")
				)

				// Find or create the WALTargetStats for this job/instance pair.
				var stats *WALTargetStats
				for _, wts := range c.stats {
					if wts.Job == jobLabel && wts.Instance == instanceLabel {
						stats = wts
						break
					}
				}
				if stats == nil {
					stats = &WALTargetStats{Job: jobLabel, Instance: instanceLabel}
					c.stats = append(c.stats, stats)
				}

				// Every time we get a new series, we want to increment the series
				// count for the specific job/instance pair, store the ref ID so
				// samples can mofidy the stats, and then store the hash of our
				// labels to detect collisions (or flapping series).
				stats.Series++
				c.statsLookup[s.Ref] = stats
				c.hashInstances[s.Labels.Hash()]++
			}
		case record.Samples:
			samples, err := dec.Samples(rec, nil)
			if err != nil {
				return err
			}
			for _, s := range samples {
				if s.T < c.fromTime {
					c.fromTime = s.T
				}
				if s.T > c.toTime {
					c.toTime = s.T
				}

				stats := c.statsLookup[s.Ref]
				if stats == nil {
					c.invalidRefs++
					continue
				}
				stats.Samples++
			}
		}
	}

	return r.Err()
}

// BySeriesCount can sort a slice of target stats by the count of
// series. The slice is sorted in descending order.
type BySeriesCount []WALTargetStats

func (s BySeriesCount) Len() int           { return len(s) }
func (s BySeriesCount) Less(i, j int) bool { return s[i].Series > s[j].Series }
func (s BySeriesCount) Swap(i, j int)      { s[i], s[j] = s[j], s[i] }

'''
'''--- pkg/agentctl/walstats_test.go ---
package agentctl

import (
	"fmt"
	"io/ioutil"
	"os"
	"path/filepath"
	"testing"

	"github.com/go-kit/log"
	"github.com/prometheus/client_golang/prometheus"
	"github.com/prometheus/prometheus/model/labels"
	"github.com/prometheus/prometheus/model/timestamp"
	"github.com/prometheus/prometheus/tsdb/chunks"
	"github.com/prometheus/prometheus/tsdb/record"
	"github.com/prometheus/prometheus/tsdb/wal"
	"github.com/stretchr/testify/require"
)

func TestWALStats(t *testing.T) {
	walDir := setupTestWAL(t)
	stats, err := CalculateStats(walDir)
	require.NoError(t, err)

	// Test From, To separately since comparing time.Time objects can be flaky
	require.Equal(t, int64(1), timestamp.FromTime(stats.From))
	require.Equal(t, int64(20), timestamp.FromTime(stats.To))

	require.Equal(t, WALStats{
		From:             stats.From,
		To:               stats.To,
		CheckpointNumber: 1,
		FirstSegment:     0,
		LastSegment:      3,
		HashCollisions:   1,
		InvalidRefs:      1,
		Targets: []WALTargetStats{{
			Instance: "test-instance",
			Job:      "test-job",
			Samples:  20,
			Series:   21,
		}},
	}, stats)
}

// setupTestWAL creates a test WAL with consistent sample data.
// The WAL will be deleted when the test finishes.
//
// The directory the WAL is in is returned.
func setupTestWAL(t *testing.T) string {
	l := log.NewNopLogger()

	walDir, err := ioutil.TempDir(os.TempDir(), "wal")
	require.NoError(t, err)
	t.Cleanup(func() {
		os.RemoveAll(walDir)
	})

	reg := prometheus.NewRegistry()
	w, err := wal.NewSize(log.NewNopLogger(), reg, filepath.Join(walDir, "wal"), wal.DefaultSegmentSize, true)
	require.NoError(t, err)
	defer w.Close()

	// First, create a few series of 10 metrics. Each metric will have a
	// cardinality of 2, for a total of 20 series.
	var series []record.RefSeries
	addSeries := func(name string) {
		baseLabels := []string{"__name__", name, "job", "test-job", "instance", "test-instance"}
		labelsInitial := append(baseLabels, "initial", "yes")
		labelsNotInitial := append(baseLabels, "initial", "no")

		series = append(
			series,
			record.RefSeries{Ref: chunks.HeadSeriesRef(len(series)) + 1, Labels: labels.FromStrings(labelsInitial...)},
			record.RefSeries{Ref: chunks.HeadSeriesRef(len(series)) + 2, Labels: labels.FromStrings(labelsNotInitial...)},
		)
	}
	for i := 0; i < 10; i++ {
		addSeries(fmt.Sprintf("metric_%d", i))
	}
	// Force in a duplicate hash
	series = append(series, record.RefSeries{
		Ref:    99,
		Labels: labels.FromStrings("__name__", "metric_1", "job", "test-job", "instance", "test-instance", "initial", "yes"),
	})

	// Encode the samples to the WAL and create a new segment.
	var encoder record.Encoder
	buf := encoder.Series(series, nil)
	err = w.Log(buf)
	require.NoError(t, err)
	require.NoError(t, w.NextSegment())

	// Checkpoint the previous segment.
	_, err = wal.Checkpoint(l, w, 0, 1, func(_ chunks.HeadSeriesRef) bool { return true }, 0)
	require.NoError(t, err)
	require.NoError(t, w.NextSegment())

	// Create some samples and then make a new segment.
	var samples []record.RefSample
	for i := 0; i < 20; i++ {
		samples = append(samples, record.RefSample{
			Ref: chunks.HeadSeriesRef(i + 1),
			T:   int64(i + 1),
			V:   1,
		})
	}
	// Force in an invalid ref
	samples = append(samples, record.RefSample{Ref: 404, T: 1, V: 1})

	buf = encoder.Samples(samples, nil)
	err = w.Log(buf)
	require.NoError(t, err)
	require.NoError(t, w.NextSegment())

	return w.Dir()
}

'''
'''--- pkg/agentproto/agent.pb.go ---
// Code generated by protoc-gen-gogo. DO NOT EDIT.
// source: pkg/agentproto/agent.proto

package agentproto

import (
	context "context"
	fmt "fmt"
	proto "github.com/gogo/protobuf/proto"
	empty "github.com/golang/protobuf/ptypes/empty"
	grpc "google.golang.org/grpc"
	codes "google.golang.org/grpc/codes"
	status "google.golang.org/grpc/status"
	io "io"
	math "math"
	math_bits "math/bits"
	reflect "reflect"
	strings "strings"
)

// Reference imports to suppress errors if they are not otherwise used.
var _ = proto.Marshal
var _ = fmt.Errorf
var _ = math.Inf

// This is a compile-time assertion to ensure that this generated file
// is compatible with the proto package it is being compiled against.
// A compilation error at this line likely means your copy of the
// proto package needs to be updated.
const _ = proto.GoGoProtoPackageIsVersion3 // please upgrade the proto package

type ReshardRequest struct {
}

func (m *ReshardRequest) Reset()      { *m = ReshardRequest{} }
func (*ReshardRequest) ProtoMessage() {}
func (*ReshardRequest) Descriptor() ([]byte, []int) {
	return fileDescriptor_11e9fe65e2a59325, []int{0}
}
func (m *ReshardRequest) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *ReshardRequest) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	if deterministic {
		return xxx_messageInfo_ReshardRequest.Marshal(b, m, deterministic)
	} else {
		b = b[:cap(b)]
		n, err := m.MarshalToSizedBuffer(b)
		if err != nil {
			return nil, err
		}
		return b[:n], nil
	}
}
func (m *ReshardRequest) XXX_Merge(src proto.Message) {
	xxx_messageInfo_ReshardRequest.Merge(m, src)
}
func (m *ReshardRequest) XXX_Size() int {
	return m.Size()
}
func (m *ReshardRequest) XXX_DiscardUnknown() {
	xxx_messageInfo_ReshardRequest.DiscardUnknown(m)
}

var xxx_messageInfo_ReshardRequest proto.InternalMessageInfo

func init() {
	proto.RegisterType((*ReshardRequest)(nil), "agentproto.ReshardRequest")
}

func init() { proto.RegisterFile("pkg/agentproto/agent.proto", fileDescriptor_11e9fe65e2a59325) }

var fileDescriptor_11e9fe65e2a59325 = []byte{
	// 221 bytes of a gzipped FileDescriptorProto
	0x1f, 0x8b, 0x08, 0x00, 0x00, 0x00, 0x00, 0x00, 0x02, 0xff, 0xe2, 0x92, 0x2a, 0xc8, 0x4e, 0xd7,
	0x4f, 0x4c, 0x4f, 0xcd, 0x2b, 0x29, 0x28, 0xca, 0x2f, 0xc9, 0x87, 0x30, 0xf5, 0xc0, 0x6c, 0x21,
	0x2e, 0x84, 0xb8, 0x94, 0x74, 0x7a, 0x7e, 0x7e, 0x7a, 0x4e, 0xaa, 0x3e, 0x98, 0x97, 0x54, 0x9a,
	0xa6, 0x9f, 0x9a, 0x5b, 0x50, 0x52, 0x09, 0x51, 0xa8, 0x24, 0xc0, 0xc5, 0x17, 0x94, 0x5a, 0x9c,
	0x91, 0x58, 0x94, 0x12, 0x94, 0x5a, 0x58, 0x9a, 0x5a, 0x5c, 0x62, 0x14, 0xc0, 0xc5, 0x1f, 0x9c,
	0x5c, 0x94, 0x58, 0x90, 0x99, 0x97, 0x1e, 0x9c, 0x5a, 0x54, 0x96, 0x99, 0x9c, 0x2a, 0x64, 0xcb,
	0xc5, 0x0e, 0x55, 0x24, 0x24, 0xa5, 0x87, 0x30, 0x59, 0x0f, 0x55, 0xa7, 0x94, 0x98, 0x1e, 0xc4,
	0x26, 0x3d, 0x98, 0x4d, 0x7a, 0xae, 0x20, 0x9b, 0x9c, 0x62, 0x2f, 0x3c, 0x94, 0x63, 0xb8, 0xf1,
	0x50, 0x8e, 0xe1, 0xc3, 0x43, 0x39, 0xc6, 0x86, 0x47, 0x72, 0x8c, 0x2b, 0x1e, 0xc9, 0x31, 0x9e,
	0x78, 0x24, 0xc7, 0x78, 0xe1, 0x91, 0x1c, 0xe3, 0x83, 0x47, 0x72, 0x8c, 0x2f, 0x1e, 0xc9, 0x31,
	0x7c, 0x78, 0x24, 0xc7, 0x38, 0xe1, 0xb1, 0x1c, 0xc3, 0x85, 0xc7, 0x72, 0x0c, 0x37, 0x1e, 0xcb,
	0x31, 0x44, 0xa9, 0xa7, 0x67, 0x96, 0x64, 0x94, 0x26, 0xe9, 0x25, 0xe7, 0xe7, 0xea, 0xa7, 0x17,
	0x25, 0xa6, 0x25, 0xe6, 0x25, 0x42, 0xbc, 0xa8, 0x8f, 0xea, 0xef, 0x24, 0x36, 0x30, 0x65, 0x0c,
	0x08, 0x00, 0x00, 0xff, 0xff, 0x0b, 0x79, 0x37, 0xd4, 0x10, 0x01, 0x00, 0x00,
}

func (this *ReshardRequest) Equal(that interface{}) bool {
	if that == nil {
		return this == nil
	}

	that1, ok := that.(*ReshardRequest)
	if !ok {
		that2, ok := that.(ReshardRequest)
		if ok {
			that1 = &that2
		} else {
			return false
		}
	}
	if that1 == nil {
		return this == nil
	} else if this == nil {
		return false
	}
	return true
}
func (this *ReshardRequest) GoString() string {
	if this == nil {
		return "nil"
	}
	s := make([]string, 0, 4)
	s = append(s, "&agentproto.ReshardRequest{")
	s = append(s, "}")
	return strings.Join(s, "")
}
func valueToGoStringAgent(v interface{}, typ string) string {
	rv := reflect.ValueOf(v)
	if rv.IsNil() {
		return "nil"
	}
	pv := reflect.Indirect(rv).Interface()
	return fmt.Sprintf("func(v %v) *%v { return &v } ( %#v )", typ, typ, pv)
}

// Reference imports to suppress errors if they are not otherwise used.
var _ context.Context
var _ grpc.ClientConn

// This is a compile-time assertion to ensure that this generated file
// is compatible with the grpc package it is being compiled against.
const _ = grpc.SupportPackageIsVersion4

// ScrapingServiceClient is the client API for ScrapingService service.
//
// For semantics around ctx use and closing/ending streaming RPCs, please refer to https://godoc.org/google.golang.org/grpc#ClientConn.NewStream.
type ScrapingServiceClient interface {
	// Reshard tells the implementing service to reshard all of its running
	// configs.
	Reshard(ctx context.Context, in *ReshardRequest, opts ...grpc.CallOption) (*empty.Empty, error)
}

type scrapingServiceClient struct {
	cc *grpc.ClientConn
}

func NewScrapingServiceClient(cc *grpc.ClientConn) ScrapingServiceClient {
	return &scrapingServiceClient{cc}
}

func (c *scrapingServiceClient) Reshard(ctx context.Context, in *ReshardRequest, opts ...grpc.CallOption) (*empty.Empty, error) {
	out := new(empty.Empty)
	err := c.cc.Invoke(ctx, "/agentproto.ScrapingService/Reshard", in, out, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

// ScrapingServiceServer is the server API for ScrapingService service.
type ScrapingServiceServer interface {
	// Reshard tells the implementing service to reshard all of its running
	// configs.
	Reshard(context.Context, *ReshardRequest) (*empty.Empty, error)
}

// UnimplementedScrapingServiceServer can be embedded to have forward compatible implementations.
type UnimplementedScrapingServiceServer struct {
}

func (*UnimplementedScrapingServiceServer) Reshard(ctx context.Context, req *ReshardRequest) (*empty.Empty, error) {
	return nil, status.Errorf(codes.Unimplemented, "method Reshard not implemented")
}

func RegisterScrapingServiceServer(s *grpc.Server, srv ScrapingServiceServer) {
	s.RegisterService(&_ScrapingService_serviceDesc, srv)
}

func _ScrapingService_Reshard_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(ReshardRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(ScrapingServiceServer).Reshard(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/agentproto.ScrapingService/Reshard",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(ScrapingServiceServer).Reshard(ctx, req.(*ReshardRequest))
	}
	return interceptor(ctx, in, info, handler)
}

var _ScrapingService_serviceDesc = grpc.ServiceDesc{
	ServiceName: "agentproto.ScrapingService",
	HandlerType: (*ScrapingServiceServer)(nil),
	Methods: []grpc.MethodDesc{
		{
			MethodName: "Reshard",
			Handler:    _ScrapingService_Reshard_Handler,
		},
	},
	Streams:  []grpc.StreamDesc{},
	Metadata: "pkg/agentproto/agent.proto",
}

func (m *ReshardRequest) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *ReshardRequest) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *ReshardRequest) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	return len(dAtA) - i, nil
}

func encodeVarintAgent(dAtA []byte, offset int, v uint64) int {
	offset -= sovAgent(v)
	base := offset
	for v >= 1<<7 {
		dAtA[offset] = uint8(v&0x7f | 0x80)
		v >>= 7
		offset++
	}
	dAtA[offset] = uint8(v)
	return base
}
func (m *ReshardRequest) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	return n
}

func sovAgent(x uint64) (n int) {
	return (math_bits.Len64(x|1) + 6) / 7
}
func sozAgent(x uint64) (n int) {
	return sovAgent(uint64((x << 1) ^ uint64((int64(x) >> 63))))
}
func (this *ReshardRequest) String() string {
	if this == nil {
		return "nil"
	}
	s := strings.Join([]string{`&ReshardRequest{`,
		`}`,
	}, "")
	return s
}
func valueToStringAgent(v interface{}) string {
	rv := reflect.ValueOf(v)
	if rv.IsNil() {
		return "nil"
	}
	pv := reflect.Indirect(rv).Interface()
	return fmt.Sprintf("*%v", pv)
}
func (m *ReshardRequest) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowAgent
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: ReshardRequest: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: ReshardRequest: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		default:
			iNdEx = preIndex
			skippy, err := skipAgent(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthAgent
			}
			if (iNdEx + skippy) < 0 {
				return ErrInvalidLengthAgent
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func skipAgent(dAtA []byte) (n int, err error) {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return 0, ErrIntOverflowAgent
			}
			if iNdEx >= l {
				return 0, io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		wireType := int(wire & 0x7)
		switch wireType {
		case 0:
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return 0, ErrIntOverflowAgent
				}
				if iNdEx >= l {
					return 0, io.ErrUnexpectedEOF
				}
				iNdEx++
				if dAtA[iNdEx-1] < 0x80 {
					break
				}
			}
			return iNdEx, nil
		case 1:
			iNdEx += 8
			return iNdEx, nil
		case 2:
			var length int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return 0, ErrIntOverflowAgent
				}
				if iNdEx >= l {
					return 0, io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				length |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if length < 0 {
				return 0, ErrInvalidLengthAgent
			}
			iNdEx += length
			if iNdEx < 0 {
				return 0, ErrInvalidLengthAgent
			}
			return iNdEx, nil
		case 3:
			for {
				var innerWire uint64
				var start int = iNdEx
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return 0, ErrIntOverflowAgent
					}
					if iNdEx >= l {
						return 0, io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					innerWire |= (uint64(b) & 0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				innerWireType := int(innerWire & 0x7)
				if innerWireType == 4 {
					break
				}
				next, err := skipAgent(dAtA[start:])
				if err != nil {
					return 0, err
				}
				iNdEx = start + next
				if iNdEx < 0 {
					return 0, ErrInvalidLengthAgent
				}
			}
			return iNdEx, nil
		case 4:
			return iNdEx, nil
		case 5:
			iNdEx += 4
			return iNdEx, nil
		default:
			return 0, fmt.Errorf("proto: illegal wireType %d", wireType)
		}
	}
	panic("unreachable")
}

var (
	ErrInvalidLengthAgent = fmt.Errorf("proto: negative length found during unmarshaling")
	ErrIntOverflowAgent   = fmt.Errorf("proto: integer overflow")
)

'''
'''--- pkg/agentproto/func.go ---
package agentproto

import (
	"context"

	empty "github.com/golang/protobuf/ptypes/empty"
)

// FuncScrapingServiceServer is an implementation of ScrapingServiceServer that
// uses function fields to implement the interface. Useful for tests.
type FuncScrapingServiceServer struct {
	ReshardFunc func(context.Context, *ReshardRequest) (*empty.Empty, error)
}

// Reshard implements ScrapingServiceServer.
func (f *FuncScrapingServiceServer) Reshard(ctx context.Context, req *ReshardRequest) (*empty.Empty, error) {
	if f.ReshardFunc != nil {
		return f.ReshardFunc(ctx, req)
	}
	panic("ReshardFunc is nil")
}

'''
'''--- pkg/build/build.go ---
package build

import "github.com/prometheus/common/version"

// Version information passed to Prometheus version package.
// Package path as used by linker changes based on vendoring being used or not,
// so it's easier just to use stable Agent path, and pass it to
// Prometheus in the code.
var (
	Version   string
	Revision  string
	Branch    string
	BuildUser string
	BuildDate string
)

func init() {
	version.Version = Version
	version.Revision = Revision
	version.Branch = Branch
	version.BuildUser = BuildUser
	version.BuildDate = BuildDate
}

'''
'''--- pkg/client/client.go ---
// Package client provides a client interface to the Agent HTTP
// API.
package client

import (
	"bytes"
	"context"
	"encoding/json"
	"fmt"
	"io"
	"net/http"
	"strings"

	"github.com/grafana/agent/pkg/metrics/cluster/configapi"
	"github.com/grafana/agent/pkg/metrics/instance"
	"gopkg.in/yaml.v2"
)

// Client is a collection of all subsystem clients.
type Client struct {
	PrometheusClient
}

// New creates a new Client.
func New(addr string) *Client {
	return &Client{
		PrometheusClient: &prometheusClient{addr: addr},
	}
}

// PrometheusClient is the client interface to the API exposed by the
// Prometheus subsystem of the Grafana Agent.
type PrometheusClient interface {
	// Instances runs the list of currently running instances.
	Instances(ctx context.Context) ([]string, error)

	// The following methods are for the scraping service mode
	// only and will fail when not enabled on the Agent.

	// ListConfigs runs the list of instance configs stored in the config
	// management KV store.
	ListConfigs(ctx context.Context) (*configapi.ListConfigurationsResponse, error)

	// GetConfiguration returns a named configuration from the config
	// management KV store.
	GetConfiguration(ctx context.Context, name string) (*instance.Config, error)

	// PutConfiguration adds or updates a named configuration into the
	// config management KV store.
	PutConfiguration(ctx context.Context, name string, cfg *instance.Config) error

	// DeleteConfiguration removes a named configuration from the config
	// management KV store.
	DeleteConfiguration(ctx context.Context, name string) error
}

type prometheusClient struct {
	addr string
}

func (c *prometheusClient) Instances(ctx context.Context) ([]string, error) {
	url := fmt.Sprintf("%s/agent/api/v1/metrics/instances", c.addr)

	resp, err := c.doRequest(ctx, "GET", url, nil)
	if err != nil {
		return nil, err
	}

	var data []string
	err = unmarshalPrometheusAPIResponse(resp.Body, &data)
	return data, err
}

func (c *prometheusClient) ListConfigs(ctx context.Context) (*configapi.ListConfigurationsResponse, error) {
	url := fmt.Sprintf("%s/agent/api/v1/configs", c.addr)

	resp, err := c.doRequest(ctx, "GET", url, nil)
	if err != nil {
		return nil, err
	}

	var data configapi.ListConfigurationsResponse
	err = unmarshalPrometheusAPIResponse(resp.Body, &data)
	return &data, err
}

func (c *prometheusClient) GetConfiguration(ctx context.Context, name string) (*instance.Config, error) {
	url := fmt.Sprintf("%s/agent/api/v1/configs/%s", c.addr, name)

	resp, err := c.doRequest(ctx, "GET", url, nil)
	if err != nil {
		return nil, err
	}

	var data configapi.GetConfigurationResponse
	if err := unmarshalPrometheusAPIResponse(resp.Body, &data); err != nil {
		return nil, err
	}

	var config instance.Config
	err = yaml.NewDecoder(strings.NewReader(data.Value)).Decode(&config)
	return &config, err
}

func (c *prometheusClient) PutConfiguration(ctx context.Context, name string, cfg *instance.Config) error {
	url := fmt.Sprintf("%s/agent/api/v1/config/%s", c.addr, name)

	bb, err := instance.MarshalConfig(cfg, false)
	if err != nil {
		return err
	}

	resp, err := c.doRequest(ctx, "POST", url, bytes.NewReader(bb))
	if err != nil {
		return err
	}

	return unmarshalPrometheusAPIResponse(resp.Body, nil)
}

func (c *prometheusClient) DeleteConfiguration(ctx context.Context, name string) error {
	url := fmt.Sprintf("%s/agent/api/v1/config/%s", c.addr, name)

	resp, err := c.doRequest(ctx, "DELETE", url, nil)
	if err != nil {
		return err
	}

	return unmarshalPrometheusAPIResponse(resp.Body, nil)
}

func (c *prometheusClient) doRequest(ctx context.Context, method string, url string, body io.Reader) (*http.Response, error) {
	req, err := http.NewRequestWithContext(ctx, method, url, body)
	if err != nil {
		return nil, err
	}
	return http.DefaultClient.Do(req)
}

// unmarshalPrometheusAPIResponse will unmarshal a response from the Prometheus
// subsystem API.
//
// r will be closed after this method is called.
func unmarshalPrometheusAPIResponse(r io.ReadCloser, v interface{}) error {
	defer func() {
		_ = r.Close()
	}()

	resp := struct {
		Status string          `json:"status"`
		Data   json.RawMessage `json:"data"`
	}{}

	err := json.NewDecoder(r).Decode(&resp)
	if err != nil {
		return fmt.Errorf("could not read response: %w", err)
	}

	if v != nil && resp.Status == "success" {
		err := json.Unmarshal(resp.Data, v)
		if err != nil {
			return fmt.Errorf("unmarshaling response: %w", err)
		}
	} else if resp.Status == "error" {
		var errResp configapi.ErrorResponse
		err := json.Unmarshal(resp.Data, &errResp)
		if err != nil {
			return fmt.Errorf("unmarshaling error: %w", err)
		}

		return fmt.Errorf("%s", errResp.Error)
	}

	if resp.Status != "success" && resp.Status != "error" {
		return fmt.Errorf("unknown API response status: %s", resp.Status)
	}

	return nil
}

'''
'''--- pkg/client/grafanacloud/client.go ---
// Package grafanacloud provides an interface to the Grafana Cloud API.
package grafanacloud

import (
	"context"
	"fmt"
	"net/http"
	"strings"

	"gopkg.in/yaml.v2"
)

const defaultAPIURL = "https://integrations-api.grafana.net"

// Client is a grafanacloud API client.
type Client struct {
	c      *http.Client
	apiKey string
	apiURL string
}

// NewClient creates a new Grafana Cloud client. All requests made will be
// performed using the provided http.Client c. If c is nil, the default
// http client will be used instead.
//
// apiKey will be used to authenticate against the apiURL.
func NewClient(c *http.Client, apiKey, apiURL string) *Client {
	if c == nil {
		c = http.DefaultClient
	}
	if apiURL == "" {
		apiURL = defaultAPIURL
	}
	return &Client{c: c, apiKey: apiKey, apiURL: apiURL}
}

// AgentConfig generates a Grafana Agent config from the given stack.
// The config is returned as a string in YAML form.
func (c *Client) AgentConfig(ctx context.Context, stackID, platforms string) (string, error) {
	url := fmt.Sprintf("%s/stacks/%s/agent_config", c.apiURL, stackID)
	if platforms != "" {
		url = fmt.Sprintf("%s?platforms=%s", url, platforms)
	}
	req, err := http.NewRequestWithContext(ctx, "GET", url, nil)

	if err != nil {
		return "", fmt.Errorf("failed to generate request: %w", err)
	}
	req.Header.Add("Authorization", "Bearer "+c.apiKey)

	resp, err := c.c.Do(req)
	if err != nil {
		return "", fmt.Errorf("failed to make request: %w", err)
	}
	defer resp.Body.Close()

	// Even though the API returns json, we'll parse it as YAML here so we can
	// re-encode it with the same order it was decoded in.
	payload := struct {
		Status string        `yaml:"status"`
		Data   yaml.MapSlice `yaml:"data"`
		Error  string        `yaml:"error"`
	}{}

	dec := yaml.NewDecoder(resp.Body)
	dec.SetStrict(true)
	if err := dec.Decode(&payload); err != nil {
		if resp.StatusCode != 200 {
			return "", fmt.Errorf("unexpected status code %d", resp.StatusCode)
		}

		return "", fmt.Errorf("failed to read response: %w", err)
	}

	if payload.Status != "success" {
		return "", fmt.Errorf("request was not successful: %s", payload.Error)
	}

	// Convert the data to YAML
	var sb strings.Builder
	if err := yaml.NewEncoder(&sb).Encode(payload.Data); err != nil {
		return "", fmt.Errorf("failed to generate YAML config: %w", err)
	}

	return sb.String(), nil
}

'''
'''--- pkg/client/grafanacloud/client_test.go ---
package grafanacloud

import (
	"context"
	"crypto/tls"
	"fmt"
	"net"
	"net/http"
	"net/http/httptest"
	"testing"

	"github.com/stretchr/testify/assert"
	"github.com/stretchr/testify/require"
)

const (
	testSecret  = "secret-key"
	testStackID = "12345"
)

func TestClient_AgentConfig(t *testing.T) {
	httpClient := testClient(t, http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
		assert.Equal(t, "/stacks/"+testStackID+"/agent_config", r.URL.Path)
		assert.Equal(t, "Bearer "+testSecret, r.Header.Get("Authorization"))

		_, err := w.Write([]byte(`{
			"status": "success",
			"data": {
				"server": {
					"log_level": "debug"
				},
				"integrations": {
					"agent": {
						"enabled": true
					}
				}
			}
		}`))
		assert.NoError(t, err)
	}))

	cli := NewClient(httpClient, testSecret, "")
	cfg, err := cli.AgentConfig(context.Background(), testStackID, "")
	require.NoError(t, err)
	fmt.Println(cfg)

	expect := `
server:
  log_level: debug
integrations:
  agent:
    enabled: true
`

	require.YAMLEq(t, expect, cfg)
}

func TestClient_AgentConfig_Error(t *testing.T) {
	httpClient := testClient(t, http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
		w.WriteHeader(http.StatusNotFound)
	}))

	cli := NewClient(httpClient, testSecret, "")
	_, err := cli.AgentConfig(context.Background(), testStackID, "")
	require.Error(t, err, "unexpected status code 404")
}

func TestClient_AgentConfig_ErrorMessage(t *testing.T) {
	httpClient := testClient(t, http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
		w.WriteHeader(http.StatusBadRequest)
		_, err := w.Write([]byte(`{
			"status": "error",
			"error": "Something went wrong"
		}`))
		assert.NoError(t, err)
	}))

	cli := NewClient(httpClient, testSecret, "")
	_, err := cli.AgentConfig(context.Background(), testStackID, "")
	require.Error(t, err, "request was not successful: Something went wrong")
}

func TestClient_AgentConfig_PlatformsFlag(t *testing.T) {
	httpClient := testClient(t, http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
		assert.Equal(t, "/stacks/"+testStackID+"/agent_config", r.URL.Path)
		assert.Equal(t, "platforms=foo,bar", r.URL.RawQuery)
		assert.Equal(t, "Bearer "+testSecret, r.Header.Get("Authorization"))

		_, err := w.Write([]byte(`{
			"status": "success",
			"data": {
				"server": {
					"log_level": "debug"
				},
				"integrations": {
					"agent": {
						"enabled": true
					}
				}
			}
		}`))
		assert.NoError(t, err)
	}))
	cli := NewClient(httpClient, testSecret, "")
	cfg, err := cli.AgentConfig(context.Background(), testStackID, "foo,bar")
	require.NoError(t, err)
	fmt.Println(cfg)

	expect := `
server:
  log_level: debug
integrations:
  agent:
    enabled: true
`

	require.YAMLEq(t, expect, cfg)
}

func testClient(t *testing.T, handler http.HandlerFunc) *http.Client {
	h := httptest.NewTLSServer(handler)
	t.Cleanup(func() {
		h.Close()
	})

	return &http.Client{
		Transport: &http.Transport{
			TLSClientConfig: &tls.Config{
				InsecureSkipVerify: true,
			},
			DialContext: func(ctx context.Context, network, addr string) (net.Conn, error) {
				return net.Dial(network, h.Listener.Addr().String())
			},
		},
	}
}

'''
'''--- pkg/cluster/cluster.go ---
// Package cluster enables an agent-wide cluster mechanism which subsystems can
// use to determine ownership of some key.
package cluster

import (
	"fmt"

	"github.com/rfratto/ckit"
	"github.com/rfratto/ckit/peer"
	"github.com/rfratto/ckit/shard"
)

// NOTE(rfratto): pkg/cluster currently isn't wired in yet, but will be used
// for the implementation of RFC-0003. Try to remember to remove this comment
// once it gets used :)

// Node is a read-only view of a cluster node.
type Node interface {
	// Lookup determines the set of replicationFactor owners for a given key.
	// peer.Peer.Self can be used to determine if the local node is the owner,
	// allowing for short-circuiting logic to connect directly to the local node
	// instead of using the network.
	//
	// Callers can use github.com/rfratto/ckit/shard.StringKey or
	// shard.NewKeyBuilder to create a key.
	Lookup(key shard.Key, replicationFactor int, op shard.Op) ([]peer.Peer, error)

	// Observe registers an Observer to receive notifications when the set of
	// Peers for a Node changes.
	Observe(ckit.Observer)

	// Peers returns the current set of peers for a Node.
	Peers() []peer.Peer
}

// NewLocalNode returns a Node which forms a single-node cluster and never
// connects to other nodes.
//
// selfAddr is the address for a Node to use to connect to itself over gRPC.
func NewLocalNode(selfAddr string) Node {
	p := peer.Peer{
		Name:  "local",
		Addr:  selfAddr,
		Self:  true,
		State: peer.StateParticipant,
	}

	return &localNode{self: p}
}

type localNode struct{ self peer.Peer }

func (ln *localNode) Lookup(key shard.Key, replicationFactor int, op shard.Op) ([]peer.Peer, error) {
	if replicationFactor == 0 {
		return nil, nil
	} else if replicationFactor > 1 {
		return nil, fmt.Errorf("need %d nodes; only 1 available", replicationFactor)
	}

	return []peer.Peer{ln.self}, nil
}

func (ln *localNode) Observe(ckit.Observer) {
	// no-op: the cluster will never change for a local-only node.
}

func (ln *localNode) Peers() []peer.Peer {
	return []peer.Peer{ln.self}
}

'''
'''--- pkg/cluster/cluster_test.go ---
package cluster

import (
	"testing"

	"github.com/rfratto/ckit/peer"
	"github.com/rfratto/ckit/shard"
	"github.com/stretchr/testify/require"
)

func TestLocalNode_Lookup(t *testing.T) {
	t.Run("replicationFactor 0 returns nothing", func(t *testing.T) {
		ln := NewLocalNode("localhost:8888")
		res, err := ln.Lookup(0, 0, shard.OpReadWrite)
		require.NoError(t, err)
		require.Len(t, res, 0)
	})

	t.Run("replicationFactor 1 returns self", func(t *testing.T) {
		ln := NewLocalNode("localhost:8888")
		res, err := ln.Lookup(0, 1, shard.OpReadWrite)

		require.NoError(t, err)

		expect := []peer.Peer{{
			Name:  "local",
			Addr:  "localhost:8888",
			Self:  true,
			State: peer.StateParticipant,
		}}
		require.Equal(t, expect, res)
	})

	t.Run("replicationFactor >1 returns error", func(t *testing.T) {
		ln := NewLocalNode("localhost:8888")
		res, err := ln.Lookup(0, 2, shard.OpReadWrite)
		require.EqualError(t, err, "need 2 nodes; only 1 available")
		require.Nil(t, res)
	})
}

func TestLocalNode_Peers(t *testing.T) {
	t.Run("always returns self", func(t *testing.T) {
		ln := NewLocalNode("localhost:8888")

		expect := []peer.Peer{{
			Name:  "local",
			Addr:  "localhost:8888",
			Self:  true,
			State: peer.StateParticipant,
		}}
		require.Equal(t, expect, ln.Peers())
	})
}

'''
'''--- pkg/cluster/gossip.go ---
package cluster

import (
	"context"
	"fmt"
	"io"
	stdlog "log"
	"net"
	"os"

	"github.com/go-kit/log"
	"github.com/grafana/dskit/flagext"
	"github.com/hashicorp/go-discover"
	"github.com/hashicorp/go-discover/provider/k8s"
	"github.com/rfratto/ckit"
	"github.com/rfratto/ckit/advertise"
	"github.com/rfratto/ckit/clientpool"
	"github.com/rfratto/ckit/peer"
	"github.com/rfratto/ckit/shard"
	"go.uber.org/atomic"
	"google.golang.org/grpc"
)

// extraDiscoverProviders used in tests.
var extraDiscoverProviders map[string]discover.Provider

// tokensPerNode is used to decide how many tokens each node should be given in
// the hash ring. All nodes must use the same value, otherwise they will have
// different views of the ring and assign work differently.
//
// Using 256 tokens strikes a good balance between distribution accuracy and
// memory consumption. A cluster of 1,000 nodes with 256 tokens per node
// requires 6MB for the hash ring, while 12MB is used for 512 tokens per node.
//
// Distribution accuracy measures how close a node was to being responsible for
// exactly 1/N keys during simulation. Simulation tests used a cluster of 10
// nodes and hashing 100,000 random keys:
//
//    256 tokens per node: min 94.0%, median 96.3%, max 115.3%
//    512 tokens per node: min 96.1%, median 99.9%, max 103.2%
//
// While 512 tokens per node is closer to perfect distribution, 256 tokens per
// node is good enough, optimizing for lower memory usage.
const tokensPerNode = 256

// GossipConfig controls clustering of Agents through gRPC-based gossip.
// GossipConfig cannot be changed at runtime.
type GossipConfig struct {
	// Name of the node within the cluster. Must be unique cluster-wide.
	NodeName string

	// host:port address to advertise to peers to connect to. When unset, the
	// first discovered IP from AdvertiseInterfaces will be used to find.
	AdvertiseAddr string

	// Slice of interface names to infer an advertise IP from. Must be set if
	// AdvertiseAddr is unset.
	AdvertiseInterfaces flagext.StringSlice

	// List of one or more host:port peer addresses to connect to. Mutually
	// exclusive with DiscoverPeers.
	//
	// If an agent connects to no peers, it will form a one-node cluster until a
	// peer connects to it explicitly.
	JoinPeers flagext.StringSlice

	// Discover peers to connect to using go-discover. Mutually exclusive with
	// JoinPeers.
	DiscoverPeers string

	// Client pool to use for connecting to peers.
	Pool *clientpool.Pool
}

// DefaultGossipConfig holds default GossipConfig options.
var DefaultGossipConfig = GossipConfig{
	AdvertiseInterfaces: advertise.DefaultInterfaces,
}

// ApplyDefaults mutates c with default settings applied. defaultPort is
// added as the default port for addresses that do not have port numbers
// assigned.
//
// An error will be returned if the configuration is invalid or if an error
// occurred while applying defaults.
func (c *GossipConfig) ApplyDefaults(defaultPort int) error {
	if c.NodeName == "" {
		hn, err := os.Hostname()
		if err != nil {
			return fmt.Errorf("generating node name: %w", err)
		}
		c.NodeName = hn
	}

	if c.AdvertiseAddr == "" {
		if len(c.AdvertiseInterfaces) == 0 {
			return fmt.Errorf("one of advertise address or advertise interfaces must be set")
		}

		addr, err := advertise.FirstAddress(c.AdvertiseInterfaces)
		if err != nil {
			return fmt.Errorf("determining advertise address: %w", err)
		}
		c.AdvertiseAddr = fmt.Sprintf("%s:%d", addr.String(), defaultPort)
	} else {
		c.AdvertiseAddr = appendDefaultPort(c.AdvertiseAddr, defaultPort)
	}

	if len(c.JoinPeers) > 0 && c.DiscoverPeers != "" {
		return fmt.Errorf("at most one of join peers and discover peers may be set")
	} else if c.DiscoverPeers != "" {
		providers := make(map[string]discover.Provider, len(discover.Providers)+1)
		for k, v := range discover.Providers {
			providers[k] = v
		}
		// Extra providers used by tests
		for k, v := range extraDiscoverProviders {
			providers[k] = v
		}

		// Custom providers that aren't enabled by default
		providers["k8s"] = &k8s.Provider{}

		d, err := discover.New(discover.WithProviders(providers))
		if err != nil {
			return fmt.Errorf("bootstrapping peer discovery: %w", err)
		}

		addrs, err := d.Addrs(c.DiscoverPeers, stdlog.New(io.Discard, "", 0)) // TODO(rfratto): log to log.Logger?
		if err != nil {
			return fmt.Errorf("discovering peers: %w", err)
		}
		c.JoinPeers = addrs
	}

	for i := range c.JoinPeers {
		// Default to using the same advertise port as the local node. This may
		// break in some cases, so the user should make sure the port numbers
		// align on as much nodes as possible.
		c.JoinPeers[i] = appendDefaultPort(c.JoinPeers[i], defaultPort)
	}

	return nil
}

func appendDefaultPort(addr string, port int) string {
	_, _, err := net.SplitHostPort(addr)
	if err == nil {
		// No error means there was a port in the string
		return addr
	}
	return fmt.Sprintf("%s:%d", addr, port)
}

// GossipNode is a Node which uses gRPC and gossip to discover peers.
type GossipNode struct {
	// NOTE(rfratto): GossipNode is a *very* thin wrapper over ckit.Node, but it
	// still abstracted out as its own type to have more agent-specific control
	// over the exposed API.

	cfg       *GossipConfig
	innerNode *ckit.Node
	log       log.Logger
	sharder   shard.Sharder

	started atomic.Bool
}

// NewGossipNode creates an unstarted GossipNode. The GossipNode will register
// itself as a gRPC service to srv. GossipConfig is expected to be valid and
// have already had ApplyDefaults called on it.
//
// GossipNode operations are unavailable until the node is started.
func NewGossipNode(l log.Logger, srv *grpc.Server, c *GossipConfig) (*GossipNode, error) {
	if l == nil {
		l = log.NewNopLogger()
	}

	sharder := shard.Ring(tokensPerNode)

	ckitConfig := ckit.Config{
		Name:          c.NodeName,
		AdvertiseAddr: c.AdvertiseAddr,
		Sharder:       sharder,
		Log:           l,
		Pool:          c.Pool,
	}

	inner, err := ckit.NewNode(srv, ckitConfig)
	if err != nil {
		return nil, err
	}

	return &GossipNode{
		cfg:       c,
		innerNode: inner,
		log:       l,
		sharder:   sharder,
	}, nil
}

// ChangeState changes the state of n. ChangeState will block until the state
// change has been receieved by another node; cancel the context to stop
// waiting. ChangeState will fail if the current state cannot move to the
// target state.
//
// Nodes must be a StateParticipant to receive writes.
func (n *GossipNode) ChangeState(ctx context.Context, to peer.State) error {
	if !n.started.Load() {
		return fmt.Errorf("node not started")
	}
	return n.innerNode.ChangeState(ctx, to)
}

// CurrentState returns the current state of the node. Note that other nodes
// may have an older view of the state while a state change propagates
// throughout the cluster.
func (n *GossipNode) CurrentState() peer.State {
	return n.innerNode.CurrentState()
}

// Lookup implements Node and returns numOwners Peers that are responsible for
// key. Only peers in StateParticipant are considered during a lookup; if no
// peers are in StateParticipant, the Lookup will fail.
func (n *GossipNode) Lookup(key shard.Key, numOwners int, op shard.Op) ([]peer.Peer, error) {
	if !n.started.Load() {
		return nil, fmt.Errorf("node not started")
	}
	return n.sharder.Lookup(key, numOwners, op)
}

// Observe registers o to be informed when the cluster changes, including peers
// appearing, disapearing, or changing state.
//
// Calls will have to filter events if they are only interested in a subset of
// changes.
func (n *GossipNode) Observe(o ckit.Observer) {
	n.innerNode.Observe(o)
}

// Peers returns the current set of Peers.
func (n *GossipNode) Peers() []peer.Peer {
	return n.innerNode.Peers()
}

// Start starts the node. Start will connect to peers if configured to do so.
//
// Start must only be called after the gRPC server is running, otherwise Start
// will block forever.
func (n *GossipNode) Start() (err error) {
	defer func() {
		if err == nil {
			n.started.Store(true)
		}
	}()
	return n.innerNode.Start(n.cfg.JoinPeers)
}

// Stop leaves the cluster and terminates n. n cannot be re-used after
// stopping.
//
// It is advisble to ChangeState to StateTerminating and StateGone before
// stopping so the local node has an opportunity to move work to other nodes.
func (n *GossipNode) Stop() error {
	return n.innerNode.Stop()
}

'''
'''--- pkg/cluster/gossip_test.go ---
package cluster

import (
	"fmt"
	stdlog "log"
	"net"
	"os"
	"strings"
	"testing"

	"github.com/hashicorp/go-discover"
	"github.com/rfratto/ckit/advertise"
	"github.com/stretchr/testify/require"
)

// NOTE(rfratto): we don't test methods against GossipNode that just shim to
// ckit, since we can rely on the existing ckit tests for correctness.

const examplePort = 8888

func TestConfig_ApplyDefaults(t *testing.T) {
	ifaces, err := net.Interfaces()
	require.NoError(t, err)

	var advertiseInterfaces []string
	for _, iface := range ifaces {
		if iface.Flags != net.FlagLoopback {
			advertiseInterfaces = append(advertiseInterfaces, iface.Name)
		}
	}

	defaultConfig := DefaultGossipConfig
	defaultConfig.AdvertiseInterfaces = advertiseInterfaces

	setTestProviders(t, map[string]discover.Provider{
		"static": &staticProvider{},
	})

	hostName, err := os.Hostname()
	require.NoError(t, err, "failed to get hostname for test assertions")

	t.Run("node name defaults to hostname", func(t *testing.T) {
		gc := defaultConfig
		gc.NodeName = ""

		err := gc.ApplyDefaults(examplePort)
		require.NoError(t, err)
		require.Equal(t, hostName, gc.NodeName)
	})

	t.Run("node name can be overridden", func(t *testing.T) {
		gc := defaultConfig
		gc.NodeName = "foobar"

		err := gc.ApplyDefaults(examplePort)
		require.NoError(t, err)
		require.Equal(t, "foobar", gc.NodeName)
	})

	t.Run("one of advertise addr or advertise interfaces must be set", func(t *testing.T) {
		gc := defaultConfig
		gc.AdvertiseInterfaces = nil

		err := gc.ApplyDefaults(examplePort)
		require.EqualError(t, err, "one of advertise address or advertise interfaces must be set")
	})

	t.Run("advertise address is inferred from advertise interfaces", func(t *testing.T) {
		gc := defaultConfig
		gc.AdvertiseInterfaces = advertiseInterfaces

		err := gc.ApplyDefaults(examplePort)
		require.NoError(t, err)

		expect, err := advertise.FirstAddress(gc.AdvertiseInterfaces)
		require.NoError(t, err)
		require.Equal(t, fmt.Sprintf("%s:%d", expect, examplePort), gc.AdvertiseAddr)
	})

	t.Run("explicit advertise address can be set", func(t *testing.T) {
		gc := defaultConfig
		gc.AdvertiseAddr = "foobar:9999"

		err := gc.ApplyDefaults(examplePort)
		require.NoError(t, err)
		require.Equal(t, "foobar:9999", gc.AdvertiseAddr)
	})

	t.Run("explicit adervise address can use default port", func(t *testing.T) {
		gc := defaultConfig
		gc.AdvertiseAddr = "foobar"

		err := gc.ApplyDefaults(examplePort)
		require.NoError(t, err)
		require.Equal(t, fmt.Sprintf("foobar:%d", examplePort), gc.AdvertiseAddr)
	})

	t.Run("join peers and discover peers can't both be set", func(t *testing.T) {
		gc := defaultConfig
		gc.JoinPeers = []string{"foobar:9999"}
		gc.DiscoverPeers = `provider=static addrs=fizzbuzz:5555`

		err := gc.ApplyDefaults(examplePort)
		require.EqualError(t, err, "at most one of join peers and discover peers may be set")
	})

	t.Run("explicit join peers can be set", func(t *testing.T) {
		gc := defaultConfig
		gc.JoinPeers = []string{"foobar:9999"}

		err := gc.ApplyDefaults(examplePort)
		require.NoError(t, err)
		require.Equal(t, []string{"foobar:9999"}, []string(gc.JoinPeers))
	})

	t.Run("join peers can be discovered", func(t *testing.T) {
		gc := defaultConfig
		gc.DiscoverPeers = `provider=static addrs=fizzbuzz:5555`

		err := gc.ApplyDefaults(examplePort)
		require.NoError(t, err)
		require.Equal(t, []string{"fizzbuzz:5555"}, []string(gc.JoinPeers))
	})

	t.Run("peers can use default port", func(t *testing.T) {
		gc := defaultConfig
		gc.JoinPeers = []string{"foobar"}

		err := gc.ApplyDefaults(examplePort)
		require.NoError(t, err)
		require.Equal(t, []string{fmt.Sprintf("foobar:%d", examplePort)}, []string(gc.JoinPeers))
	})

	t.Run("discovered peers can use default port", func(t *testing.T) {
		gc := defaultConfig
		gc.DiscoverPeers = `provider=static addrs=fizzbuzz`

		err := gc.ApplyDefaults(examplePort)
		require.NoError(t, err)
		require.Equal(t, []string{fmt.Sprintf("fizzbuzz:%d", examplePort)}, []string(gc.JoinPeers))
	})
}

func setTestProviders(t *testing.T, set map[string]discover.Provider) {
	t.Helper()

	restore := extraDiscoverProviders
	t.Cleanup(func() {
		extraDiscoverProviders = restore
	})
	extraDiscoverProviders = set
}

type staticProvider struct{}

var _ discover.Provider = (*staticProvider)(nil)

func (sp *staticProvider) Addrs(args map[string]string, l *stdlog.Logger) ([]string, error) {
	if args["provider"] != "static" {
		return nil, fmt.Errorf("discover-static: invalid provider " + args["provider"])
	}
	if rawSet, ok := args["addrs"]; ok {
		return strings.Split(rawSet, ","), nil
	}
	return nil, nil
}

func (sp *staticProvider) Help() string {
	return `static:

    provider: "static"
		addrs:    Comma-separated list of addresses to return`
}

'''
'''--- pkg/config/config.go ---
package config

import (
	"bytes"
	"errors"
	"flag"
	"fmt"
	"io/ioutil"
	"os"
	"strings"
	"testing"
	"unicode"

	"github.com/drone/envsubst/v2"
	"github.com/go-kit/log"
	"github.com/go-kit/log/level"
	"github.com/grafana/agent/pkg/config/features"
	"github.com/grafana/agent/pkg/logs"
	"github.com/grafana/agent/pkg/metrics"
	"github.com/grafana/agent/pkg/server"
	"github.com/grafana/agent/pkg/traces"
	"github.com/grafana/agent/pkg/util"
	"github.com/grafana/dskit/kv/consul"
	"github.com/prometheus/common/config"
	"github.com/prometheus/common/version"
	"github.com/stretchr/testify/require"
	"gopkg.in/yaml.v2"
)

var (
	featRemoteConfigs    = features.Feature("remote-configs")
	featIntegrationsNext = features.Feature("integrations-next")
	featDynamicConfig    = features.Feature("dynamic-config")
	featExtraMetrics     = features.Feature("extra-scrape-metrics")

	allFeatures = []features.Feature{
		featRemoteConfigs,
		featIntegrationsNext,
		featDynamicConfig,
		featExtraMetrics,
	}
)

var (
	fileTypeYAML    = "yaml"
	fileTypeDynamic = "dynamic"

	fileTypes = []string{fileTypeYAML, fileTypeDynamic}
)

// DefaultConfig holds default settings for all the subsystems.
var DefaultConfig = Config{
	// All subsystems with a DefaultConfig should be listed here.
	Server:                server.DefaultConfig,
	ServerFlags:           server.DefaultFlags,
	Metrics:               metrics.DefaultConfig,
	Integrations:          DefaultVersionedIntegrations,
	EnableConfigEndpoints: false,
	EnableUsageReport:     true,
}

// Config contains underlying configurations for the agent
type Config struct {
	Server       server.Config         `yaml:"server,omitempty"`
	Metrics      metrics.Config        `yaml:"metrics,omitempty"`
	Integrations VersionedIntegrations `yaml:"integrations,omitempty"`
	Traces       traces.Config         `yaml:"traces,omitempty"`
	Logs         *logs.Config          `yaml:"logs,omitempty"`

	// Flag-only fields
	ServerFlags server.Flags `yaml:"-"`

	// Deprecated fields user has used. Generated during UnmarshalYAML.
	Deprecations []string `yaml:"-"`

	// Remote config options
	BasicAuthUser     string `yaml:"-"`
	BasicAuthPassFile string `yaml:"-"`

	// Toggle for config endpoint(s)
	EnableConfigEndpoints bool `yaml:"-"`

	// Report enabled features options
	EnableUsageReport bool     `yaml:"-"`
	EnabledFeatures   []string `yaml:"-"`
}

// UnmarshalYAML implements yaml.Unmarshaler.
func (c *Config) UnmarshalYAML(unmarshal func(interface{}) error) error {
	// Apply defaults to the config from our struct and any defaults inherited
	// from flags before unmarshaling.
	*c = DefaultConfig
	util.DefaultConfigFromFlags(c)

	type baseConfig Config

	type config struct {
		baseConfig `yaml:",inline"`

		// Deprecated field names:
		Prometheus *metrics.Config `yaml:"prometheus,omitempty"`
		Loki       *logs.Config    `yaml:"loki,omitempty"`
		Tempo      *traces.Config  `yaml:"tempo,omitempty"`
	}

	var fc config
	fc.baseConfig = baseConfig(*c)

	if err := unmarshal(&fc); err != nil {
		return err
	}

	// Migrate old fields to the new name
	if fc.Prometheus != nil && fc.Metrics.Unmarshaled && fc.Prometheus.Unmarshaled {
		return fmt.Errorf("at most one of prometheus and metrics should be specified")
	} else if fc.Prometheus != nil && fc.Prometheus.Unmarshaled {
		fc.Deprecations = append(fc.Deprecations, "`prometheus` has been deprecated in favor of `metrics`")
		fc.Metrics = *fc.Prometheus
		fc.Prometheus = nil
	}

	if fc.Logs != nil && fc.Loki != nil {
		return fmt.Errorf("at most one of loki and logs should be specified")
	} else if fc.Logs == nil && fc.Loki != nil {
		fc.Deprecations = append(fc.Deprecations, "`loki` has been deprecated in favor of `logs`")
		fc.Logs = fc.Loki
		fc.Loki = nil
	}

	if fc.Tempo != nil && fc.Traces.Unmarshaled {
		return fmt.Errorf("at most one of tempo and traces should be specified")
	} else if fc.Tempo != nil && fc.Tempo.Unmarshaled {
		fc.Deprecations = append(fc.Deprecations, "`tempo` has been deprecated in favor of `traces`")
		fc.Traces = *fc.Tempo
		fc.Tempo = nil
	}

	*c = Config(fc.baseConfig)
	return nil
}

// MarshalYAML implements yaml.Marshaler.
func (c Config) MarshalYAML() (interface{}, error) {
	var buf bytes.Buffer

	enc := yaml.NewEncoder(&buf)
	enc.SetHook(func(in interface{}) (ok bool, out interface{}, err error) {
		// Obscure the password fields for known types that do not obscure passwords.
		switch v := in.(type) {
		case consul.Config:
			v.ACLToken = "<secret>"
			return true, v, nil
		default:
			return false, nil, nil
		}
	})

	type config Config
	if err := enc.Encode((config)(c)); err != nil {
		return nil, err
	}

	// Use a yaml.MapSlice rather than a map[string]interface{} so
	// order of keys is retained compared to just calling MarshalConfig.
	var m yaml.MapSlice
	if err := yaml.Unmarshal(buf.Bytes(), &m); err != nil {
		return nil, err
	}
	return m, nil
}

// LogDeprecations will log use of any deprecated fields to l as warn-level
// messages.
func (c *Config) LogDeprecations(l log.Logger) {
	for _, d := range c.Deprecations {
		level.Warn(l).Log("msg", fmt.Sprintf("DEPRECATION NOTICE: %s", d))
	}
}

// Validate validates the config, flags, and sets default values.
func (c *Config) Validate(fs *flag.FlagSet) error {
	if err := c.Metrics.ApplyDefaults(); err != nil {
		return err
	}

	// Need to propagate the listen address to the host and grpcPort
	_, grpcPort, err := c.ServerFlags.GRPC.ListenHostPort()
	if err != nil {
		return err
	}
	c.Metrics.ServiceConfig.Lifecycler.ListenPort = grpcPort

	if err := c.Integrations.ApplyDefaults(&c.ServerFlags, &c.Metrics); err != nil {
		return err
	}

	// since the Traces config might rely on an existing Loki config
	// this check is made here to look for cross config issues before we attempt to load
	if err := c.Traces.Validate(c.Logs); err != nil {
		return err
	}

	c.Metrics.ServiceConfig.APIEnableGetConfiguration = c.EnableConfigEndpoints

	// Don't validate flags if there's no FlagSet. Used for testing.
	if fs == nil {
		return nil
	}
	deps := []features.Dependency{
		{Flag: "config.url.basic-auth-user", Feature: featRemoteConfigs},
		{Flag: "config.url.basic-auth-password-file", Feature: featRemoteConfigs},
	}
	return features.Validate(fs, deps)
}

// RegisterFlags registers flags in underlying configs
func (c *Config) RegisterFlags(f *flag.FlagSet) {
	c.Metrics.RegisterFlags(f)
	c.ServerFlags.RegisterFlags(f)

	f.StringVar(&c.BasicAuthUser, "config.url.basic-auth-user", "",
		"basic auth username for fetching remote config. (requires remote-configs experiment to be enabled")
	f.StringVar(&c.BasicAuthPassFile, "config.url.basic-auth-password-file", "",
		"path to file containing basic auth password for fetching remote config. (requires remote-configs experiment to be enabled")

	f.BoolVar(&c.EnableConfigEndpoints, "config.enable-read-api", false, "Enables the /-/config and /agent/api/v1/configs/{name} APIs. Be aware that secrets could be exposed by enabling these endpoints!")
}

// LoadFile reads a file and passes the contents to Load
func LoadFile(filename string, expandEnvVars bool, c *Config) error {
	buf, err := ioutil.ReadFile(filename)
	if err != nil {
		return fmt.Errorf("error reading config file %w", err)
	}
	return LoadBytes(buf, expandEnvVars, c)
}

// LoadRemote reads a config from url
func LoadRemote(url string, expandEnvVars bool, c *Config) error {
	remoteOpts := &remoteOpts{}
	if c.BasicAuthUser != "" && c.BasicAuthPassFile != "" {
		remoteOpts.HTTPClientConfig = &config.HTTPClientConfig{
			BasicAuth: &config.BasicAuth{
				Username:     c.BasicAuthUser,
				PasswordFile: c.BasicAuthPassFile,
			},
		}
	}

	if remoteOpts.HTTPClientConfig != nil {
		dir, err := os.Getwd()
		if err != nil {
			return fmt.Errorf("failed to get current working directory: %w", err)
		}
		remoteOpts.HTTPClientConfig.SetDirectory(dir)
	}

	rc, err := newRemoteConfig(url, remoteOpts)
	if err != nil {
		return fmt.Errorf("error reading remote config: %w", err)
	}
	// fall back to file if no scheme is passed
	if rc == nil {
		return LoadFile(url, expandEnvVars, c)
	}
	bb, err := rc.retrieve()
	if err != nil {
		return fmt.Errorf("error retrieving remote config: %w", err)
	}
	return LoadBytes(bb, expandEnvVars, c)
}

// LoadDynamicConfiguration is used to load configuration from a variety of sources using
// dynamic loader, this is a templated approach
func LoadDynamicConfiguration(url string, expandvar bool, c *Config) error {
	if expandvar {
		return errors.New("expand var is not supported when using dynamic configuration, use gomplate env instead")
	}
	cmf, err := NewDynamicLoader()
	if err != nil {
		return err
	}
	err = cmf.LoadConfigByPath(url)
	if err != nil {
		return err
	}

	err = cmf.ProcessConfigs(c)
	if err != nil {
		return fmt.Errorf("error processing config templates %w", err)
	}
	return nil
}

// LoadBytes unmarshals a config from a buffer. Defaults are not
// applied to the file and must be done manually if LoadBytes
// is called directly.
func LoadBytes(buf []byte, expandEnvVars bool, c *Config) error {
	// (Optionally) expand with environment variables
	if expandEnvVars {
		s, err := envsubst.Eval(string(buf), getenv)
		if err != nil {
			return fmt.Errorf("unable to substitute config with environment variables: %w", err)
		}
		buf = []byte(s)
	}
	// Unmarshal yaml config
	return yaml.UnmarshalStrict(buf, c)
}

// getenv is a wrapper around os.Getenv that ignores patterns that are numeric
// regex capture groups (ie "${1}").
func getenv(name string) string {
	numericName := true

	for _, r := range name {
		if !unicode.IsDigit(r) {
			numericName = false
			break
		}
	}

	if numericName {
		// We need to add ${} back in since envsubst removes it.
		return fmt.Sprintf("${%s}", name)
	}
	return os.Getenv(name)
}

// Load loads a config file from a flagset. Flags will be registered
// to the flagset before parsing them with the values specified by
// args.
func Load(fs *flag.FlagSet, args []string) (*Config, error) {
	return load(fs, args, func(path, fileType string, expandArgs bool, c *Config) error {
		switch fileType {
		case fileTypeYAML:
			if features.Enabled(fs, featRemoteConfigs) {
				return LoadRemote(path, expandArgs, c)
			}
			return LoadFile(path, expandArgs, c)
		case fileTypeDynamic:
			if !features.Enabled(fs, featDynamicConfig) {
				return fmt.Errorf("feature %q must be enabled to use file type %s", featDynamicConfig, fileTypeDynamic)
			} else if !features.Enabled(fs, featIntegrationsNext) {
				return fmt.Errorf("feature %q must be enabled to use file type %s", featIntegrationsNext, fileTypeDynamic)
			} else if features.Enabled(fs, featRemoteConfigs) {
				return fmt.Errorf("feature %q can not be enabled with file type %s", featRemoteConfigs, fileTypeDynamic)
			} else if expandArgs {
				return fmt.Errorf("-config.expand-env can not be used with file type %s", fileTypeDynamic)
			}
			return LoadDynamicConfiguration(path, expandArgs, c)
		default:
			return fmt.Errorf("unknown file type %q. accepted values: %s", fileType, strings.Join(fileTypes, ", "))
		}
	})
}

type loaderFunc func(path string, fileType string, expandArgs bool, target *Config) error

// load allows for tests to inject a function for retrieving the config file that
// doesn't require having a literal file on disk.
func load(fs *flag.FlagSet, args []string, loader loaderFunc) (*Config, error) {
	var (
		cfg = DefaultConfig

		printVersion     bool
		file             string
		fileType         string
		configExpandEnv  bool
		disableReporting bool
	)

	fs.StringVar(&file, "config.file", "", "configuration file to load")
	fs.StringVar(&fileType, "config.file.type", "yaml", fmt.Sprintf("Type of file pointed to by -config.file flag. Supported values: %s. %s requires dynamic-config and integrations-next features to be enabled.", strings.Join(fileTypes, ", "), fileTypeDynamic))
	fs.BoolVar(&printVersion, "version", false, "Print this build's version information.")
	fs.BoolVar(&configExpandEnv, "config.expand-env", false, "Expands ${var} in config according to the values of the environment variables.")
	fs.BoolVar(&disableReporting, "disable-reporting", false, "Disable reporting of enabled feature flags to Grafana.")
	cfg.RegisterFlags(fs)

	features.Register(fs, allFeatures)

	if err := fs.Parse(args); err != nil {
		return nil, fmt.Errorf("error parsing flags: %w", err)
	}

	if printVersion {
		fmt.Println(version.Print("agent"))
		os.Exit(0)
	}

	if file == "" {
		return nil, fmt.Errorf("-config.file flag required")
	} else if err := loader(file, fileType, configExpandEnv, &cfg); err != nil {
		return nil, fmt.Errorf("error loading config file %s: %w", file, err)
	}

	// Parse the flags again to override any YAML values with command line flag
	// values.
	if err := fs.Parse(args); err != nil {
		return nil, fmt.Errorf("error parsing flags: %w", err)
	}

	// Complete unmarshaling integrations using the version from the flag. This
	// MUST be called before ApplyDefaults.
	version := integrationsVersion1
	if features.Enabled(fs, featIntegrationsNext) {
		version = integrationsVersion2
	}

	if err := cfg.Integrations.setVersion(version); err != nil {
		return nil, fmt.Errorf("error loading config file %s: %w", file, err)
	}

	if features.Enabled(fs, featExtraMetrics) {
		cfg.Metrics.Global.ExtraMetrics = true
	}

	if disableReporting {
		cfg.EnableUsageReport = false
	} else {
		cfg.EnabledFeatures = features.GetAllEnabled(fs)
	}

	// Finally, apply defaults to config that wasn't specified by file or flag
	if err := cfg.Validate(fs); err != nil {
		return nil, fmt.Errorf("error in config file: %w", err)
	}
	return &cfg, nil
}

// CheckSecret is a helper function to ensure the original value is overwritten with <secret>
func CheckSecret(t *testing.T, rawCfg string, originalValue string) {
	var cfg = &Config{}
	err := LoadBytes([]byte(rawCfg), false, cfg)
	require.NoError(t, err)
	bb, err := yaml.Marshal(cfg)
	require.NoError(t, err)
	scrubbedCfg := string(bb)
	require.True(t, strings.Contains(scrubbedCfg, "<secret>"))
	require.False(t, strings.Contains(scrubbedCfg, originalValue))
}

'''
'''--- pkg/config/config_test.go ---
package config

import (
	"flag"
	"net/url"
	"strings"
	"testing"
	"time"

	commonCfg "github.com/prometheus/common/config"

	"github.com/stretchr/testify/assert"

	"github.com/grafana/agent/pkg/metrics"
	"github.com/grafana/agent/pkg/metrics/instance"
	"github.com/grafana/agent/pkg/util"
	"github.com/prometheus/common/model"
	promCfg "github.com/prometheus/prometheus/config"
	"github.com/prometheus/prometheus/model/labels"
	"github.com/stretchr/testify/require"
	"gopkg.in/yaml.v2"
)

// TestConfig_FlagDefaults makes sure that default values of flags are kept
// when parsing the config.
func TestConfig_FlagDefaults(t *testing.T) {
	cfg := `
metrics:
  wal_directory: /tmp/wal
  global:
    scrape_timeout: 33s`

	fs := flag.NewFlagSet("test", flag.ExitOnError)
	c, err := load(fs, []string{"-config.file", "test"}, func(_, _ string, _ bool, c *Config) error {
		return LoadBytes([]byte(cfg), false, c)
	})
	require.NoError(t, err)
	require.NotEmpty(t, c.Metrics.ServiceConfig.Lifecycler.InfNames)
	require.NotZero(t, c.Metrics.ServiceConfig.Lifecycler.NumTokens)
	require.NotZero(t, c.Metrics.ServiceConfig.Lifecycler.HeartbeatPeriod)
	require.True(t, c.ServerFlags.RegisterInstrumentation)
}

// TestConfig_ConfigAPIFlag makes sure that the read API flag is passed
// when parsing the config.
func TestConfig_ConfigAPIFlag(t *testing.T) {
	t.Run("Disabled", func(t *testing.T) {
		cfg := `{}`
		fs := flag.NewFlagSet("test", flag.ExitOnError)
		c, err := load(fs, []string{"-config.file", "test"}, func(_, _ string, _ bool, c *Config) error {
			return LoadBytes([]byte(cfg), false, c)
		})
		require.NoError(t, err)
		require.False(t, c.EnableConfigEndpoints)
		require.False(t, c.Metrics.ServiceConfig.APIEnableGetConfiguration)
	})
	t.Run("Enabled", func(t *testing.T) {
		cfg := `{}`
		fs := flag.NewFlagSet("test", flag.ExitOnError)
		c, err := load(fs, []string{"-config.file", "test", "-config.enable-read-api"}, func(_, _ string, _ bool, c *Config) error {
			return LoadBytes([]byte(cfg), false, c)
		})
		require.NoError(t, err)
		require.True(t, c.EnableConfigEndpoints)
		require.True(t, c.Metrics.ServiceConfig.APIEnableGetConfiguration)
	})
}

func TestConfig_OverrideDefaultsOnLoad(t *testing.T) {
	cfg := `
metrics:
  wal_directory: /tmp/wal
  global:
    scrape_timeout: 33s`
	expect := instance.GlobalConfig{
		Prometheus: promCfg.GlobalConfig{
			ScrapeInterval:     model.Duration(1 * time.Minute),
			ScrapeTimeout:      model.Duration(33 * time.Second),
			EvaluationInterval: model.Duration(1 * time.Minute),
		},
	}

	fs := flag.NewFlagSet("test", flag.ExitOnError)
	c, err := load(fs, []string{"-config.file", "test"}, func(_, _ string, _ bool, c *Config) error {
		return LoadBytes([]byte(cfg), false, c)
	})
	require.NoError(t, err)
	require.Equal(t, expect, c.Metrics.Global)
}

func TestConfig_OverrideByEnvironmentOnLoad(t *testing.T) {
	cfg := `
metrics:
  wal_directory: /tmp/wal
  global:
    scrape_timeout: ${SCRAPE_TIMEOUT}`
	expect := instance.GlobalConfig{
		Prometheus: promCfg.GlobalConfig{
			ScrapeInterval:     model.Duration(1 * time.Minute),
			ScrapeTimeout:      model.Duration(33 * time.Second),
			EvaluationInterval: model.Duration(1 * time.Minute),
		},
	}
	t.Setenv("SCRAPE_TIMEOUT", "33s")

	fs := flag.NewFlagSet("test", flag.ExitOnError)
	c, err := load(fs, []string{"-config.file", "test"}, func(_, _ string, _ bool, c *Config) error {
		return LoadBytes([]byte(cfg), true, c)
	})
	require.NoError(t, err)
	require.Equal(t, expect, c.Metrics.Global)
}

func TestConfig_OverrideByEnvironmentOnLoad_NoDigits(t *testing.T) {
	cfg := `
metrics:
  wal_directory: /tmp/wal
  global:
    external_labels:
      foo: ${1}`
	expect := labels.Labels{{Name: "foo", Value: "${1}"}}

	fs := flag.NewFlagSet("test", flag.ExitOnError)
	c, err := load(fs, []string{"-config.file", "test"}, func(_, _ string, _ bool, c *Config) error {
		return LoadBytes([]byte(cfg), true, c)
	})
	require.NoError(t, err)
	require.Equal(t, expect, c.Metrics.Global.Prometheus.ExternalLabels)
}

func TestConfig_FlagsAreAccepted(t *testing.T) {
	cfg := `
metrics:
  global:
    scrape_timeout: 33s`

	fs := flag.NewFlagSet("test", flag.ExitOnError)
	args := []string{
		"-config.file", "test",
		"-metrics.wal-directory", "/tmp/wal",
		"-config.expand-env",
	}

	c, err := load(fs, args, func(_, _ string, _ bool, c *Config) error {
		return LoadBytes([]byte(cfg), false, c)
	})
	require.NoError(t, err)
	require.Equal(t, "/tmp/wal", c.Metrics.WALDir)
}

func TestConfig_StrictYamlParsing(t *testing.T) {
	t.Run("duplicate key", func(t *testing.T) {
		cfg := `
metrics:
  wal_directory: /tmp/wal
  global:
    scrape_timeout: 10s
    scrape_timeout: 15s`
		var c Config
		err := LoadBytes([]byte(cfg), false, &c)
		require.Error(t, err)
	})

	t.Run("non existing key", func(t *testing.T) {
		cfg := `
metrics:
  wal_directory: /tmp/wal
  global:
  scrape_timeout: 10s`
		var c Config
		err := LoadBytes([]byte(cfg), false, &c)
		require.Error(t, err)
	})
}

func TestConfig_Defaults(t *testing.T) {
	var c Config
	err := LoadBytes([]byte(`{}`), false, &c)
	require.NoError(t, err)

	require.Equal(t, metrics.DefaultConfig, c.Metrics)
	require.Equal(t, DefaultVersionedIntegrations, c.Integrations)
}

func TestConfig_TracesLokiValidates(t *testing.T) {
	tests := []struct {
		cfg string
	}{
		{
			cfg: `
loki:
  configs:
  - name: default
    positions:
      filename: /tmp/positions.yaml
    clients:
    - url: http://loki:3100/loki/api/v1/push
traces:
  configs:
  - name: default
    automatic_logging:
      backend: loki
      loki_name: default
      spans: true`,
		},
		{
			cfg: `
loki:
  configs:
  - name: default
    positions:
      filename: /tmp/positions.yaml
    clients:
    - url: http://loki:3100/loki/api/v1/push
traces:
  configs:
  - name: default
    automatic_logging:
      backend: stdout
      loki_name: doesnt_exist
      spans: true`,
		},
	}

	for _, tc := range tests {
		fs := flag.NewFlagSet("test", flag.ExitOnError)
		_, err := load(fs, []string{"-config.file", "test"}, func(_, _ string, _ bool, c *Config) error {
			return LoadBytes([]byte(tc.cfg), false, c)
		})

		require.NoError(t, err)
	}
}

func TestConfig_LokiNameMigration(t *testing.T) {
	input := util.Untab(`
loki:
  configs:
  - name: foo
    positions:
      filename: /tmp/positions.yaml
    clients:
    - url: http://loki:3100/loki/api/v1/push
`)
	var cfg Config
	require.NoError(t, LoadBytes([]byte(input), false, &cfg))
	require.NoError(t, cfg.Validate(nil))

	require.NotNil(t, cfg.Logs)
	require.Equal(t, "foo", cfg.Logs.Configs[0].Name)
	require.Equal(t, []string{"`loki` has been deprecated in favor of `logs`"}, cfg.Deprecations)
}

func TestConfig_PrometheusNonNil(t *testing.T) {
	tt := []struct {
		name  string
		input string
	}{
		{
			name:  "missing",
			input: `{}`,
		},
		{
			name:  "null",
			input: `metrics: null`,
		},
	}

	for _, tc := range tt {
		t.Run(tc.name, func(t *testing.T) {
			var cfg Config
			require.NoError(t, LoadBytes([]byte(tc.input), false, &cfg))
			require.NoError(t, cfg.Validate(nil))

			require.NotNil(t, cfg.Metrics)
		})
	}
}

func TestConfig_PrometheusNameMigration(t *testing.T) {
	input := util.Untab(`
prometheus:
	wal_directory: /tmp
  configs:
  - name: default
`)
	var cfg Config
	require.NoError(t, LoadBytes([]byte(input), false, &cfg))
	require.NoError(t, cfg.Validate(nil))

	require.Equal(t, "default", cfg.Metrics.Configs[0].Name)
	require.Equal(t, "/tmp", cfg.Metrics.WALDir)
	require.Equal(t, []string{"`prometheus` has been deprecated in favor of `metrics`"}, cfg.Deprecations)
}

func TestConfig_TracesLokiFailsValidation(t *testing.T) {
	tests := []struct {
		cfg           string
		expectedError string
	}{
		{
			cfg: `
loki:
  configs:
  - name: foo
    positions:
      filename: /tmp/positions.yaml
    clients:
    - url: http://loki:3100/loki/api/v1/push
traces:
  configs:
  - name: default
    automatic_logging:
      backend: logs_instance
      logs_instance_name: default
      spans: true`,
			expectedError: "error in config file: failed to validate automatic_logging for traces config default: specified logs config default not found in agent config",
		},
	}

	for _, tc := range tests {
		fs := flag.NewFlagSet("test", flag.ExitOnError)
		_, err := load(fs, []string{"-config.file", "test"}, func(_, _ string, _ bool, c *Config) error {
			return LoadBytes([]byte(tc.cfg), false, c)
		})

		require.EqualError(t, err, tc.expectedError)
	}
}

func TestConfig_TempoNameMigration(t *testing.T) {
	input := util.Untab(`
tempo:
  configs:
  - name: default
    automatic_logging:
      backend: stdout
      loki_name: doesnt_exist
      spans: true`)
	var cfg Config
	require.NoError(t, LoadBytes([]byte(input), false, &cfg))
	require.NoError(t, cfg.Validate(nil))

	require.NotNil(t, cfg.Traces)

	require.Equal(t, "default", cfg.Traces.Configs[0].Name)
	require.Equal(t, []string{"`tempo` has been deprecated in favor of `traces`"}, cfg.Deprecations)
}

func TestConfig_TempoTracesDuplicateMigration(t *testing.T) {
	input := util.Untab(`
traces:
  configs:
  - name: default
    automatic_logging:
      backend: stdout
      loki_name: doesnt_exist
      spans: true
tempo:
  configs:
  - name: default
    automatic_logging:
      backend: stdout
      loki_name: doesnt_exist
      spans: true`)
	var cfg Config
	require.EqualError(t, LoadBytes([]byte(input), false, &cfg), "at most one of tempo and traces should be specified")
}

func TestConfig_ExpandEnvRegex(t *testing.T) {
	cfg := `
logs:
  configs:
  - name: default
    positions:
      filename: /tmp/positions.yaml
    scrape_configs:
      - job_name: test
        pipeline_stages:
        - regex:
          source: filename
          expression: '\\temp\\Logs\\(?P<log_app>.+?)\\'`
	fs := flag.NewFlagSet("test", flag.ExitOnError)
	myCfg, err := load(fs, []string{"-config.file", "test"}, func(_, _ string, _ bool, c *Config) error {
		return LoadBytes([]byte(cfg), true, c)
	})
	require.NoError(t, err)
	pipelineStages := myCfg.Logs.Configs[0].ScrapeConfig[0].PipelineStages[0].(map[interface{}]interface{})
	expected := `\\temp\\Logs\\(?P<log_app>.+?)\\`
	require.Equal(t, expected, pipelineStages["expression"].(string))
}

func TestConfig_ObscureSecrets(t *testing.T) {
	cfgText := `
metrics:
  wal_directory: /tmp
  scraping_service:
    enabled: true
    kvstore:
      store: consul
      consul:
        acl_token: verysecret
    lifecycler:
      ring:
        kvstore:
          store: consul
          consul:
            acl_token: verysecret
`

	var cfg Config
	require.NoError(t, LoadBytes([]byte(cfgText), false, &cfg))

	require.Equal(t, "verysecret", cfg.Metrics.ServiceConfig.KVStore.Consul.ACLToken)
	require.Equal(t, "verysecret", cfg.Metrics.ServiceConfig.Lifecycler.RingConfig.KVStore.Consul.ACLToken)

	bb, err := yaml.Marshal(&cfg)
	require.NoError(t, err)

	require.False(t, strings.Contains(string(bb), "verysecret"), "secrets did not get obscured")
	require.True(t, strings.Contains(string(bb), "<secret>"), "secrets did not get obscured properly")

	// Re-validate that the config object has not changed
	require.Equal(t, "verysecret", cfg.Metrics.ServiceConfig.KVStore.Consul.ACLToken)
	require.Equal(t, "verysecret", cfg.Metrics.ServiceConfig.Lifecycler.RingConfig.KVStore.Consul.ACLToken)
}

func TestConfig_RemoteWriteDefaults(t *testing.T) {
	cfg := `
metrics:
  global:
    remote_write:
      - name: "foo"
        url: "https://test/url"`

	var c Config
	err := LoadBytes([]byte(cfg), false, &c)
	require.NoError(t, err)

	expected := &promCfg.DefaultRemoteWriteConfig
	expected.Name = "foo"
	testURL, _ := url.Parse("https://test/url")
	expected.URL = &commonCfg.URL{
		URL: testURL,
	}
	require.Equal(t, expected, c.Metrics.Global.RemoteWrite[0])
	require.True(t, c.Metrics.Global.RemoteWrite[0].SendExemplars)
}

func TestLoadDynamicConfigurationExpandError(t *testing.T) {
	err := LoadDynamicConfiguration("", true, nil)
	assert.Error(t, err)
	assert.True(t, strings.Contains(err.Error(), "expand var is not supported when using dynamic configuration, use gomplate env instead"))
}

'''
'''--- pkg/config/dynamicconfig.go ---
package config

// LoaderConfig is used by dynamic configuration
type LoaderConfig struct {
	// Sources is used to define sources for variables using gomplate
	Sources []Datasource `yaml:"datasources"`

	// TemplatePaths is the "directory" to look for templates in, they will be found and matched to configs but various
	// naming conventions. They can be S3/gcp, or file based resources. The directory structure is NOT walked.
	TemplatePaths []string `yaml:"template_paths"`

	AgentFilter           string `yaml:"agent_filter,omitempty"`
	ServerFilter          string `yaml:"server_filter,omitempty"`
	MetricsFilter         string `yaml:"metrics_filter,omitempty"`
	MetricsInstanceFilter string `yaml:"metrics_instance_filter,omitempty"`
	IntegrationsFilter    string `yaml:"integrations_filter,omitempty"`
	LogsFilter            string `yaml:"logs_filter,omitempty"`
	TracesFilter          string `yaml:"traces_filter,omitempty"`
}

// Datasource is used for gomplate and can be used for a variety of resources.
type Datasource struct {
	Name string `yaml:"name"`
	URL  string `yaml:"url"`
}

'''
'''--- pkg/config/dynamicloader.go ---
package config

import (
	"context"
	"fmt"
	"io/fs"
	"io/ioutil"
	"net/url"
	"path/filepath"
	"strings"

	v2 "github.com/grafana/agent/pkg/integrations/v2"
	"github.com/grafana/agent/pkg/logs"
	"github.com/grafana/agent/pkg/metrics"
	"github.com/grafana/agent/pkg/metrics/instance"
	"github.com/grafana/agent/pkg/server"
	"github.com/grafana/agent/pkg/traces"
	"github.com/hairyhenderson/go-fsimpl"
	"github.com/hairyhenderson/go-fsimpl/blobfs"
	"github.com/hairyhenderson/go-fsimpl/filefs"
	"github.com/hairyhenderson/gomplate/v3/data"
	"github.com/hairyhenderson/gomplate/v3/loader"
	"github.com/hashicorp/go-multierror"
	"gopkg.in/yaml.v2"
)

// DynamicLoader is used to load configs from a variety of sources and squash them together.
// This is used by the dynamic configuration feature to load configurations from a set of templates and then run them through
// gomplate producing an end result.
type DynamicLoader struct {
	loader *loader.ConfigLoader
	mux    fsimpl.FSMux
	cfg    *LoaderConfig
}

// NewDynamicLoader instantiates a new DynamicLoader.
func NewDynamicLoader() (*DynamicLoader, error) {
	return &DynamicLoader{
		mux: newFSProvider(),
	}, nil
}

// LoadConfig loads an already created LoaderConfig into the DynamicLoader.
func (c *DynamicLoader) LoadConfig(cfg LoaderConfig) error {
	sources := make(map[string]*data.Source)
	for _, v := range cfg.Sources {
		sourceURL, err := url.Parse(v.URL)
		if err != nil {
			return err
		}
		sources[v.Name] = &data.Source{
			URL:   sourceURL,
			Alias: v.Name,
		}
	}
	// Set Defaults
	if cfg.IntegrationsFilter == "" {
		cfg.IntegrationsFilter = "integrations-*.yml"
	}
	if cfg.AgentFilter == "" {
		cfg.AgentFilter = "agent-*.yml"
	}
	if cfg.ServerFilter == "" {
		cfg.ServerFilter = "server-*.yml"
	}
	if cfg.MetricsFilter == "" {
		cfg.MetricsFilter = "metrics-*.yml"
	}
	if cfg.MetricsInstanceFilter == "" {
		cfg.MetricsInstanceFilter = "metrics_instances-*.yml"
	}
	if cfg.LogsFilter == "" {
		cfg.LogsFilter = "logs-*.yml"
	}
	if cfg.TracesFilter == "" {
		cfg.TracesFilter = "traces-*.yml"
	}
	cl := loader.NewConfigLoader(context.Background(), sources)
	c.loader = cl
	c.cfg = &cfg
	return nil
}

// LoadConfigByPath creates a config based on a path.
func (c *DynamicLoader) LoadConfigByPath(path string) error {
	var buf []byte
	var err error
	switch {
	case strings.HasPrefix(path, "file://"):
		// It takes some work arounds to parse all windows paths as url so treating it differently now is easier
		// otherwise we could parse path and then pivot
		stripPath := strings.ReplaceAll(path, "file://", "")
		buf, err = ioutil.ReadFile(stripPath)
		if err != nil {
			return err
		}
	case strings.HasPrefix(path, "s3://"):
		blobURL, err := url.Parse(path)
		if err != nil {
			return err
		}
		buf, err = data.ReadBlob(*blobURL)
		if err != nil {
			return err
		}
	default:
		return fmt.Errorf("config path must start with file:// or s3://, not %s", path)
	}

	cl := &LoaderConfig{}
	err = yaml.Unmarshal(buf, cl)
	if err != nil {
		return err
	}
	return c.LoadConfig(*cl)
}

// ProcessConfigs loads the configurations in a predetermined order to handle functioning correctly.
func (c *DynamicLoader) ProcessConfigs(cfg *Config) error {
	if c.cfg == nil {
		return fmt.Errorf("LoadConfig or LoadConfigByPath must be called")
	}
	var returnErr error

	err := c.processAgent(cfg)
	returnErr = errorAppend(returnErr, err)

	serverConfig, err := c.processServer()
	returnErr = errorAppend(returnErr, err)
	if serverConfig != nil {
		cfg.Server = *serverConfig
	}

	metricConfig, err := c.processMetrics()
	returnErr = errorAppend(returnErr, err)
	if metricConfig != nil {
		cfg.Metrics = *metricConfig
	}

	instancesConfigs, err := c.processMetricInstances()
	returnErr = errorAppend(returnErr, err)
	cfg.Metrics.Configs = append(cfg.Metrics.Configs, instancesConfigs...)

	logsCfg, err := c.processLogs()
	returnErr = errorAppend(returnErr, err)
	if logsCfg != nil {
		cfg.Logs = logsCfg
	}

	traceConfigs, err := c.processTraces()
	returnErr = errorAppend(returnErr, err)
	if traceConfigs != nil {
		cfg.Traces = *traceConfigs
	}

	integrations, err := c.processIntegrations()
	returnErr = errorAppend(returnErr, err)

	cfg.Integrations.ExtraIntegrations = append(cfg.Integrations.ExtraIntegrations, integrations...)

	return returnErr
}

func (c *DynamicLoader) processAgent(cfg *Config) error {
	var returnError error
	found := 0
	for _, path := range c.cfg.TemplatePaths {
		filesContents, err := c.retrieveMatchingFileContents(path, c.cfg.AgentFilter, "agent")
		returnError = errorAppend(returnError, err)
		found = len(filesContents) + found
		if len(filesContents) == 1 {
			err = LoadBytes([]byte(filesContents[0]), false, cfg)
			returnError = errorAppend(returnError, err)
		}
	}
	if found > 1 {
		returnError = errorAppend(returnError, fmt.Errorf("found %d agent templates; expected 0 or 1", found))
	}
	// If we didnt find anything we still want to unmarshal the cfg to get defaults
	if found == 0 {
		_ = LoadBytes([]byte("{}"), false, cfg)
	}
	return returnError
}

func (c *DynamicLoader) processServer() (*server.Config, error) {
	var returnError error
	found := 0
	var cfg *server.Config
	for _, path := range c.cfg.TemplatePaths {
		filesContents, err := c.retrieveMatchingFileContents(path, c.cfg.ServerFilter, "server")
		returnError = errorAppend(returnError, err)
		found = len(filesContents) + found
		if len(filesContents) == 1 {
			cfg = &server.Config{}
			err = yaml.Unmarshal([]byte(filesContents[0]), cfg)
			returnError = errorAppend(returnError, err)
		}
	}
	if found > 1 {
		returnError = errorAppend(returnError, fmt.Errorf("found %d server templates; expected 0 or 1", found))
	}
	return cfg, returnError
}

func (c *DynamicLoader) processMetrics() (*metrics.Config, error) {
	var returnError error
	found := 0
	var cfg *metrics.Config
	for _, path := range c.cfg.TemplatePaths {
		filesContents, err := c.retrieveMatchingFileContents(path, c.cfg.MetricsFilter, "metrics")
		returnError = errorAppend(returnError, err)
		found = len(filesContents) + found
		if len(filesContents) == 1 {
			cfg = &metrics.Config{}
			err = yaml.Unmarshal([]byte(filesContents[0]), cfg)
			returnError = errorAppend(returnError, err)
		}
	}
	if found > 1 {
		returnError = errorAppend(returnError, fmt.Errorf("found %d metrics templates; expected 0 or 1", found))
	}
	return cfg, returnError
}

func (c *DynamicLoader) processMetricInstances() ([]instance.Config, error) {
	var returnError error
	var configs []instance.Config
	for _, path := range c.cfg.TemplatePaths {
		filesContents, err := c.retrieveMatchingFileContents(path, c.cfg.MetricsInstanceFilter, "metrics instances")
		returnError = errorAppend(returnError, err)
		for _, c := range filesContents {
			cfg := &instance.Config{}
			err = yaml.Unmarshal([]byte(c), cfg)
			returnError = errorAppend(returnError, err)
			configs = append(configs, *cfg)
		}
	}

	return configs, returnError
}

func (c *DynamicLoader) processIntegrations() ([]v2.Config, error) {
	var returnError error
	var configs []v2.Config
	for _, path := range c.cfg.TemplatePaths {
		filesContents, err := c.retrieveMatchingFileContents(path, c.cfg.IntegrationsFilter, "integrations")
		returnError = errorAppend(returnError, err)
		for _, c := range filesContents {
			intConfigs, err := unmarshalYamlToExporters(c)
			if err != nil {
				returnError = errorAppend(returnError, err)
				continue
			}
			configs = append(configs, intConfigs...)
		}
	}
	return configs, returnError
}

func (c *DynamicLoader) processLogs() (*logs.Config, error) {
	var returnError error
	found := 0
	var cfg *logs.Config
	for _, path := range c.cfg.TemplatePaths {
		filesContents, err := c.retrieveMatchingFileContents(path, c.cfg.LogsFilter, "logs")
		returnError = errorAppend(returnError, err)
		found = len(filesContents) + found
		if len(filesContents) == 1 {
			cfg = &logs.Config{}
			err = yaml.Unmarshal([]byte(filesContents[0]), cfg)
			returnError = errorAppend(returnError, err)
		}
	}
	if found > 1 {
		returnError = errorAppend(returnError, fmt.Errorf("found %d logs templates; expected 0 or 1", found))
	}
	return cfg, returnError
}

func (c *DynamicLoader) processTraces() (*traces.Config, error) {
	var returnError error
	found := 0
	var cfg *traces.Config
	for _, path := range c.cfg.TemplatePaths {
		filesContents, err := c.retrieveMatchingFileContents(path, c.cfg.TracesFilter, "traces")
		returnError = errorAppend(returnError, err)
		found = len(filesContents) + found
		if len(filesContents) == 1 {
			cfg = &traces.Config{}
			err = yaml.Unmarshal([]byte(filesContents[0]), cfg)
			returnError = errorAppend(returnError, err)
		}
	}
	if found > 1 {
		returnError = errorAppend(returnError, fmt.Errorf("found %d traces templates; expected 0 or 1", found))
	}
	return cfg, returnError
}

// retrieveMatchingFileContents retrieves the contents of files based on path and pattern
// the pattern is the same as used by filepath.Match.
func (c *DynamicLoader) retrieveMatchingFileContents(path, pattern, name string) ([]string, error) {
	var filesContents []string
	handler, err := c.mux.Lookup(path)
	if err != nil {
		return nil, err
	}
	files, err := fs.ReadDir(handler, ".")
	if err != nil {
		return nil, err
	}
	for _, f := range files {
		// We don't recurse into directories, mainly due to not wanting to deal with symlinks and other oddities
		// its likely we will revisit
		if f.IsDir() {
			continue
		}
		matched, err := filepath.Match(pattern, f.Name())
		if err != nil {
			return nil, err
		}
		if matched {
			contents, err := fs.ReadFile(handler, f.Name())
			if err != nil {
				return nil, err
			}
			processedConfigString, err := c.loader.GenerateTemplate(name, string(contents))
			if err != nil {
				return nil, err
			}
			filesContents = append(filesContents, processedConfigString)
		}
	}
	return filesContents, nil
}

// unmarshalYamlToExporters attempts to convert the contents of yaml string into a set of exporters and then return
// those configurations.
func unmarshalYamlToExporters(contents string) ([]v2.Config, error) {
	o := &v2.SubsystemOptions{}
	err := yaml.Unmarshal([]byte(contents), o)
	if err != nil {
		return nil, err
	}
	return o.Configs, nil
}

func newFSProvider() fsimpl.FSMux {
	mux := fsimpl.NewMux()
	mux.Add(filefs.FS)
	mux.Add(blobfs.FS)
	return mux
}

// errorAppend is a wrapper around multierror.Append that is needed since multierror will create a new error. In this case
// we only want to create a new error if newErr is not nil
func errorAppend(root error, newErr error) error {
	if newErr == nil {
		return root
	}
	return multierror.Append(root, newErr)
}

'''
'''--- pkg/config/dynamicloader_configs_test.go ---
//nolint:golint,goconst
package config

import (
	"strings"
	"testing"

	"github.com/grafana/agent/pkg/integrations/node_exporter"
	"github.com/grafana/agent/pkg/integrations/windows_exporter"

	v2 "github.com/grafana/agent/pkg/integrations/v2"
	"github.com/stretchr/testify/assert"
	"github.com/stretchr/testify/require"
)

func TestConfigMaker(t *testing.T) {
	configStr := `wal_directory: /tmp/wal`
	tDir := generatePath(t)
	writeFile(t, tDir, "metrics-1.yml", configStr)
	fileFS := generateFilePath(tDir)
	loaderCfg := LoaderConfig{
		Sources:       nil,
		TemplatePaths: []string{fileFS},
	}
	cmf := generateLoader(t, loaderCfg)
	configs, err := cmf.processMetrics()
	require.NoError(t, err)
	assert.NotNil(t, configs)
	assert.Equal(t, configs.WALDir, "/tmp/wal")
}

func TestConfigMakerWithFakeFiles(t *testing.T) {
	configStr := `wal_directory: /tmp/wal`
	tDir := generatePath(t)
	writeFile(t, tDir, "metrics-1.yml", configStr)
	writeFile(t, tDir, "fake.yml", configStr)
	fileFS := generateFilePath(tDir)
	loaderCfg := LoaderConfig{
		Sources:       nil,
		TemplatePaths: []string{fileFS},
	}
	cmf := generateLoader(t, loaderCfg)
	configs, err := cmf.processMetrics()
	require.NoError(t, err)
	assert.NotNil(t, configs)
	assert.Equal(t, configs.WALDir, "/tmp/wal")
}

func TestConfigMakerWithMultipleMetrics(t *testing.T) {
	configStr := `wal_directory: /tmp/wal`
	tDir := generatePath(t)
	writeFile(t, tDir, "metrics-1.yml", configStr)
	writeFile(t, tDir, "metrics-2.yml", configStr)

	fileFS := generateFilePath(tDir)
	loaderCfg := LoaderConfig{
		Sources:       nil,
		TemplatePaths: []string{fileFS},
	}
	cmf := generateLoader(t, loaderCfg)
	_, err := cmf.processMetrics()
	assert.Error(t, err)
	assert.True(t, strings.Contains(err.Error(), "found 2 metrics templates; expected 0 or 1"))
}

func TestConfigMakerWithMetricsAndInstances(t *testing.T) {
	configStr := `wal_directory: /tmp/wal`
	tDir := generatePath(t)
	writeFile(t, tDir, "metrics-1.yml", configStr)
	writeFile(t, tDir, "metrics_instances-1.yml", "name: t1")
	writeFile(t, tDir, "metrics_instances-2.yml", "name: t2")
	writeFile(t, tDir, "server-1.yml", `
http_listen_port: 12345
log_level: debug
`)
	fileFS := generateFilePath(tDir)

	loaderCfg := LoaderConfig{
		Sources:       nil,
		TemplatePaths: []string{fileFS},
	}
	cmf := generateLoader(t, loaderCfg)
	cfg := &Config{}
	err := cmf.ProcessConfigs(cfg)
	require.NoError(t, err)
	assert.Len(t, cfg.Metrics.Configs, 2)
}

func TestConfigMakerWithExporter(t *testing.T) {
	configStr := `
windows:
  enabled_collectors: one,two,three
`
	tDir := generatePath(t)
	writeFile(t, tDir, "integrations-1.yml", configStr)
	fileFS := generateFilePath(tDir)

	loaderCfg := LoaderConfig{
		Sources:       nil,
		TemplatePaths: []string{fileFS},
	}
	cmf := generateLoader(t, loaderCfg)
	configs, err := cmf.processIntegrations()
	require.NoError(t, err)
	require.Len(t, configs, 1)
	wincfg, _ := configs[0].(v2.UpgradedConfig).LegacyConfig()
	assert.True(t, wincfg.(*windows_exporter.Config).EnabledCollectors == "one,two,three")
}

func TestConfigMakerWithMultipleExporter(t *testing.T) {
	configStr := `
windows:
  enabled_collectors: one,two,three
  instance: testinstance
node_exporter:
  autoscrape:
    enable: false
`
	tDir := generatePath(t)
	writeFile(t, tDir, "integrations-1.yml", configStr)
	fileFS := generateFilePath(tDir)

	loaderCfg := LoaderConfig{
		Sources:       nil,
		TemplatePaths: []string{fileFS},
	}
	cmf := generateLoader(t, loaderCfg)
	configs, err := cmf.processIntegrations()
	require.NoError(t, err)
	assert.Len(t, configs, 2)
	for _, cfg := range configs {
		switch v := cfg.(type) {
		default:
			t.Errorf("unexpected type %T", v)
		case v2.UpgradedConfig:
			oldConfig, _ := v.LegacyConfig()
			switch oc := oldConfig.(type) {
			case *windows_exporter.Config:
				assert.True(t, "one,two,three" == oc.EnabledCollectors)
			case *node_exporter.Config:
				assert.NotNil(t, v)
			}
		}
	}
}

func TestLoadingFromS3(t *testing.T) {
	configStr := `
windows:
  enabled_collectors: one,two,three
  instance: testinstance
`
	u := pushFilesToFakeS3(t, "integrations-1.yml", configStr)
	s3Url := "s3://mybucket/?region=us-east-1&disableSSL=true&s3ForcePathStyle=true&endpoint=" + u.Host
	loaderCfg := LoaderConfig{
		Sources:       nil,
		TemplatePaths: []string{s3Url},
	}
	cmf := generateLoader(t, loaderCfg)
	cfg, err := cmf.processIntegrations()
	require.NoError(t, err)
	assert.Len(t, cfg, 1)
	oc, _ := cfg[0].(v2.UpgradedConfig).LegacyConfig()
	winCfg := oc.(*windows_exporter.Config)
	assert.True(t, winCfg.EnabledCollectors == "one,two,three")
}

func TestMultiplex(t *testing.T) {
	configStr := `
redis_configs:
- redis_addr: localhost:6379
  autoscrape:
    metric_relabel_configs: 
    - source_labels: [__address__]
      target_label: "banana"
      replacement: "apple"
- redis_addr: localhost:6380
`
	tDir := generatePath(t)
	writeFile(t, tDir, "integrations-1.yml", configStr)
	fileFS := generateFilePath(tDir)

	loaderCfg := LoaderConfig{
		Sources:       nil,
		TemplatePaths: []string{fileFS},
	}
	cmf := generateLoader(t, loaderCfg)
	cfg := &Config{}

	err := cmf.ProcessConfigs(cfg)
	require.NoError(t, err)
	assert.Len(t, cfg.Integrations.ExtraIntegrations, 2)
}

func TestAgentAddIntegrations(t *testing.T) {
	configStr := `
server:
  log_level: debug
metrics:
  wal_directory: /tmp/grafana-agent-normal
  global:
    scrape_interval: 60s
    remote_write:
    - url: https://www.example.com
integrations:
  node_exporter: {}
`
	addIntegration := `
windows: {}
`
	tDir := generatePath(t)
	writeFile(t, tDir, "agent-1.yml", configStr)
	writeFile(t, tDir, "integrations-windows.yml", addIntegration)
	fileFS := generateFilePath(tDir)
	loaderCfg := LoaderConfig{
		Sources:       nil,
		TemplatePaths: []string{fileFS},
	}
	cmf := generateLoader(t, loaderCfg)
	cfg := &Config{}
	err := cmf.ProcessConfigs(cfg)
	require.NoError(t, err)
	// Since the normal agent uses deferred parsing this is required to load the integration from agent-1.yml
	err = cfg.Integrations.setVersion(integrationsVersion2)
	require.NoError(t, err)
	assert.True(t, cfg.ServerFlags.HTTP.ListenAddress == "127.0.0.1:12345")
	assert.True(t, cfg.Server.LogLevel.String() == "debug")
	assert.True(t, cfg.Metrics.WALDir == "/tmp/grafana-agent-normal")
	assert.True(t, cfg.Metrics.Global.RemoteWrite[0].URL.String() == "https://www.example.com")
	assert.False(t, cfg.Integrations.IsZero())
	// ExtraIngrations should be 1 from the integrations-windows.yml
	// the node_exporter integration in the agent-1.yml is in the configV2
	assert.Len(t, cfg.Integrations.ExtraIntegrations, 1)
	assert.Len(t, cfg.Integrations.configV2.Configs, 2)
}

func TestFilterOverrides(t *testing.T) {
	agentStr := `
server:
  log_level: debug
metrics:
  wal_directory: /tmp/grafana-agent-normal
  global:
    scrape_interval: 60s
    remote_write:
    - url: https://www.example.com
integrations:
  windows: {}
`
	serverStr := `
http_tls_config:
  cert_file: /fake/file.cert
  key_file: /fake/file.key
`
	metricsStr := `
wal_directory: /tmp/grafana-agent-normal
global:
  scrape_interval: 60s
  remote_write:
  - url: https://www.example.com
`
	metricsInstanceStr := `
name: t1
`
	integrationStr := `
node_exporter: {}
`
	tracesStr := `
configs:
- name: test_traces
  automatic_logging:
    backend: stdout
    loki_name: default
    spans: true
`
	logsStr := `
configs:
- name: test_logs
  positions:
    filename: /tmp/positions.yaml
  scrape_configs:
    - job_name: test
      pipeline_stages:
      - regex:
        source: filename
        expression: '\\temp\\Logs\\(?P<log_app>.+?)\\'
`
	tDir := generatePath(t)
	writeFile(t, tDir, "a-1.yml", agentStr)
	writeFile(t, tDir, "s-1.yml", serverStr)
	writeFile(t, tDir, "m-1.yml", metricsStr)
	writeFile(t, tDir, "mi-1.yml", metricsInstanceStr)
	writeFile(t, tDir, "i-1.yml", integrationStr)
	writeFile(t, tDir, "t-1.yml", tracesStr)
	writeFile(t, tDir, "l-1.yml", logsStr)
	fileFS := generateFilePath(tDir)
	loaderCfg := LoaderConfig{
		Sources:               nil,
		TemplatePaths:         []string{fileFS},
		AgentFilter:           "a-*.yml",
		ServerFilter:          "s-*.yml",
		MetricsFilter:         "m-*.yml",
		MetricsInstanceFilter: "mi-*.yml",
		IntegrationsFilter:    "i-*.yml",
		LogsFilter:            "l-*.yml",
		TracesFilter:          "t-*.yml",
	}
	cmf := generateLoader(t, loaderCfg)
	cfg := &Config{}
	err := cmf.ProcessConfigs(cfg)
	require.NoError(t, err)
	// Since the normal agent uses deferred parsing this is required to load the integration from agent-1.yml
	err = cfg.Integrations.setVersion(integrationsVersion2)
	require.NoError(t, err)
	// Test server override
	assert.Equal(t, "/fake/file.cert", cfg.Server.HTTP.TLSConfig.TLSCertPath)
	assert.Equal(t, "/fake/file.key", cfg.Server.HTTP.TLSConfig.TLSKeyPath)
	// Test metric
	assert.True(t, cfg.Metrics.WALDir == "/tmp/grafana-agent-normal")
	// Test Metric Instances
	assert.True(t, cfg.Metrics.Configs[0].Name == "t1")
	// Test Integrations
	assert.Len(t, cfg.Integrations.ExtraIntegrations, 1)
	assert.Len(t, cfg.Integrations.configV2.Configs, 2)
	// Test Traces
	assert.True(t, cfg.Traces.Configs[0].Name == "test_traces")
	// Test Logs
	assert.True(t, cfg.Logs.Configs[0].Name == "test_logs")
}

'''
'''--- pkg/config/dynamicloader_template_test.go ---
//nolint:golint,goconst
package config

import (
	"bytes"
	"fmt"
	"io/ioutil"
	"net/http/httptest"
	"net/url"
	"os"
	"path/filepath"
	"runtime"
	"testing"

	"github.com/stretchr/testify/require"

	"github.com/grafana/agent/pkg/util/subset"
	"gopkg.in/yaml.v2"

	_ "github.com/grafana/agent/pkg/integrations/install"
	v2 "github.com/grafana/agent/pkg/integrations/v2"
	"github.com/grafana/agent/pkg/integrations/windows_exporter"
	"github.com/johannesboyne/gofakes3"
	"github.com/johannesboyne/gofakes3/backend/s3mem"
	"github.com/stretchr/testify/assert"
)

func TestConfigMakerWithExporterWithTemplate(t *testing.T) {
	configStr := `
windows:
  enabled_collectors: {{ (datasource "vars").value }}
  instance: testinstance
`
	tDir := generatePath(t)
	writeFile(t, tDir, "vars.yaml", "value: banana")
	writeFile(t, tDir, "integrations-1.yml", configStr)
	fileFS := generateFilePath(tDir)

	loaderCfg := LoaderConfig{
		Sources: []Datasource{{
			Name: "vars",
			URL:  generateFilePath(filepath.Join(tDir, "vars.yaml")),
		}},
		TemplatePaths: []string{fileFS},
	}
	cmf := generateLoader(t, loaderCfg)
	configs, err := cmf.processIntegrations()
	require.NoError(t, err)
	assert.Len(t, configs, 1)
	wincfg, _ := configs[0].(v2.UpgradedConfig).LegacyConfig()
	assert.True(t, wincfg.(*windows_exporter.Config).EnabledCollectors == "banana")
}

func TestLoadingFromS3LoadingVarsLocally(t *testing.T) {
	configStr := `
windows:
  enabled_collectors: {{ (datasource "vars").value }}
  instance: testinstance
`
	tDir := generatePath(t)
	writeFile(t, tDir, "vars.yaml", "value: banana")
	u := pushFilesToFakeS3(t, "integrations-1.yml", configStr)
	s3Url := "s3://mybucket/?region=us-east-1&disableSSL=true&s3ForcePathStyle=true&endpoint=" + u.Host
	loaderCfg := LoaderConfig{
		Sources: []Datasource{{
			Name: "vars",
			URL:  fmt.Sprintf("file:///%s", filepath.Join(tDir, "vars.yaml")),
		}},
		TemplatePaths: []string{s3Url},
	}
	cmf := generateLoader(t, loaderCfg)
	cfg, err := cmf.processIntegrations()
	require.NoError(t, err)
	assert.Len(t, cfg, 1)
	oc, _ := cfg[0].(v2.UpgradedConfig).LegacyConfig()
	winCfg := oc.(*windows_exporter.Config)
	assert.True(t, winCfg.EnabledCollectors == "banana")
}

func TestLoadingFromS3LoadingVarsLocallyWithRange(t *testing.T) {
	configStr := `
windows:
  enabled_collectors: banana
  instance: testinstance
  autoscrape:
    metric_relabel_configs: {{ range (datasource "vars").value }}
    - source_labels: [__address__]
      target_label: {{ . }}
      replacement: "{{ . }}-value"
    {{ end }}
`
	tDir := generatePath(t)
	writeFile(t, tDir, "vars.yaml", "value: [banana,apple,pear]")
	u := pushFilesToFakeS3(t, "integrations-1.yml", configStr)

	s3Url := "s3://mybucket/?region=us-east-1&disableSSL=true&s3ForcePathStyle=true&endpoint=" + u.Host
	loaderCfg := LoaderConfig{
		Sources: []Datasource{{
			Name: "vars",
			URL:  fmt.Sprintf("file:///%s", filepath.Join(tDir, "vars.yaml")),
		}},
		TemplatePaths: []string{s3Url},
	}
	cmf := generateLoader(t, loaderCfg)
	cfg := &Config{}
	err := cmf.ProcessConfigs(cfg)
	require.NoError(t, err)
	assert.Len(t, cfg.Integrations.ExtraIntegrations, 1)
	_ = cfg.Integrations.setVersion(integrationsVersion2)
	expectBase := `
integrations:
  windows:
    autoscrape:
      metric_relabel_configs:
      - target_label: banana
      - target_label: apple
      - target_label: pear
`
	outBytes, err := yaml.Marshal(cfg)
	require.NoError(t, err)
	assert.NoError(t, subset.YAMLAssert([]byte(expectBase), outBytes))
}

func writeFile(t *testing.T, directory string, path string, contents string) {
	fullpath := filepath.Join(directory, path)
	err := ioutil.WriteFile(fullpath, []byte(contents), 0666)
	require.NoError(t, err)
}

func generateLoader(t *testing.T, lc LoaderConfig) *DynamicLoader {
	cmf, err := NewDynamicLoader()
	require.NoError(t, err)
	err = cmf.LoadConfig(lc)
	require.NoError(t, err)
	return cmf
}

func generateFilePath(directory string) string {
	if runtime.GOOS == "windows" {
		// The URL scheme needs an additional / on windows
		return fmt.Sprintf("file:///%s", directory)
	}
	return fmt.Sprintf("file://%s", directory)
}

func generatePath(t *testing.T) string {
	tDir, err := os.MkdirTemp("", "*-test")
	require.NoError(t, err)
	t.Cleanup(func() { _ = os.RemoveAll(tDir) })
	return tDir
}

func pushFilesToFakeS3(t *testing.T, filename string, filecontents string) *url.URL {
	t.Setenv("AWS_ANON", "true")

	backend := s3mem.New()
	faker := gofakes3.New(backend)

	srv := httptest.NewServer(faker.Server())
	_ = backend.CreateBucket("mybucket")
	t.Cleanup(srv.Close)
	_, err := backend.PutObject(
		"mybucket",
		filename,
		map[string]string{"Content-Type": "application/yaml"},
		bytes.NewBufferString(filecontents),
		int64(len(filecontents)),
	)
	assert.NoError(t, err)
	u, err := url.Parse(srv.URL)
	assert.NoError(t, err)
	return u
}

'''
'''--- pkg/config/features/features.go ---
// Package features enables a way to encode enabled features in a
// flag.FlagSet.
package features

import (
	"flag"
	"fmt"
	"sort"
	"strings"
)

// Feature is an experimental feature. Features are case-insensitive.
type Feature string

const setFlagName = "enable-features"

// Register sets a flag in fs to track enabled features. The list of possible
// features is enumerated by ff. ff must contain a unique set of case-insensitive
// features. Register will panic if ff is invalid.
func Register(fs *flag.FlagSet, ff []Feature) {
	var (
		cache = make(map[Feature]struct{}, len(ff))
		names = make([]string, len(ff))
	)
	for i, f := range ff {
		normalized := normalize(f)
		if _, found := cache[normalized]; found {
			panic(fmt.Sprintf("case-insensitive feature %q registered twice", normalized))
		}
		cache[normalized] = struct{}{}
		names[i] = string(normalized)
	}

	help := fmt.Sprintf("Comma-delimited list of features to enable. Valid values: %s", strings.Join(names, ", "))

	s := set{valid: cache, validString: strings.Join(names, ", ")}
	fs.Var(&s, setFlagName, help)
}

func normalize(f Feature) Feature {
	return Feature(strings.ToLower(string(f)))
}

// Enabled returns true if a feature is enabled. Enable will panic if fs has
// not been passed to Register or name is an unknown feature.
func Enabled(fs *flag.FlagSet, name Feature) bool {
	name = normalize(name)

	f := fs.Lookup(setFlagName)
	if f == nil {
		panic("feature flag not registered to fs")
	}
	s, ok := f.Value.(*set)
	if !ok {
		panic("registered feature flag not appropriate type")
	}

	if _, valid := s.valid[name]; !valid {
		panic(fmt.Sprintf("unknown feature %q", name))
	}
	_, enabled := s.enabled[name]
	return enabled
}

// Dependency marks a Flag as depending on a specific feature being enabled.
type Dependency struct {
	// Flag must be a flag name from a FlagSet.
	Flag string
	// Feature which must be enabled for Flag to be provided at the command line.
	Feature Feature
}

// Validate returns an error if any flags from deps were used without the
// corresponding feature being enabled.
//
// If deps references a flag that is not in fs, Validate will panic.
func Validate(fs *flag.FlagSet, deps []Dependency) error {
	depLookup := make(map[string]Dependency, len(deps))

	for _, dep := range deps {
		if fs.Lookup(dep.Flag) == nil {
			panic(fmt.Sprintf("flag %q does not exist in fs", dep.Flag))
		}
		depLookup[dep.Flag] = dep

		// Ensure that the feature also exists. We ignore the result here;
		// we just want to propagate the panic behavior.
		_ = Enabled(fs, dep.Feature)
	}

	var err error

	// Iterate over all the flags that were passed at the command line.
	// Flags that were passed and are present in deps MUST also have their
	// corresponding feature enabled.
	fs.Visit(func(f *flag.Flag) {
		// If we have an error to return, stop iterating.
		if err != nil {
			return
		}

		dep, ok := depLookup[f.Name]
		if !ok {
			return
		}

		// Flag was provided and exists in deps.
		if !Enabled(fs, dep.Feature) {
			err = fmt.Errorf("flag %q requires feature %q to be provided in --%s", f.Name, dep.Feature, setFlagName)
		}
	})

	return err
}

// GetAllEnabled returns the list of all enabled features
func GetAllEnabled(fs *flag.FlagSet) []string {
	f := fs.Lookup(setFlagName)
	if f == nil {
		panic("feature flag not registered to fs")
	}
	s, ok := f.Value.(*set)
	if !ok {
		panic("registered feature flag not appropriate type")
	}
	var enabled []string
	for feature := range s.enabled {
		enabled = append(enabled, string(feature))
	}
	return enabled
}

// set implements flag.Value and holds the set of enabled features.
// set should be provided to a flag.FlagSet with:
//
//  var s features.set
//  fs.Var(&s, features.SetFlag, "")
type set struct {
	valid       map[Feature]struct{}
	validString string // Comma-delimited list of acceptable values

	enabled map[Feature]struct{}
}

// Set implements flag.Value.
func (s *set) String() string {
	res := make([]string, 0, len(s.enabled))
	for k := range s.enabled {
		res = append(res, string(k))
	}
	sort.Strings(res)
	return strings.Join(res, ",")
}

// Set implements flag.Value.
func (s *set) Set(in string) error {
	slice := strings.Split(in, ",")

	m := make(map[Feature]struct{}, len(slice))
	for _, input := range slice {
		f := normalize(Feature(input))
		if _, valid := s.valid[f]; !valid {
			return fmt.Errorf("unknown feature %q. possible options: %s", f, s.validString)
		} else if _, ok := m[f]; ok {
			return fmt.Errorf("%q already set", f)
		}
		m[f] = struct{}{}
	}

	s.enabled = m
	return nil
}

'''
'''--- pkg/config/features/features_test.go ---
package features

import (
	"flag"
	"fmt"
	"strings"
	"testing"

	"github.com/stretchr/testify/require"
)

func Example() {
	var (
		testFeature = Feature("test-feature")

		// Set of flags which require a specific feature to be enabled.
		dependencies = []Dependency{
			{Flag: "protected", Feature: testFeature},
		}
	)

	fs := flag.NewFlagSet("feature-flags", flag.PanicOnError)
	fs.String("protected", "", `Requires "test-feature" to be enabled to set.`)
	Register(fs, []Feature{testFeature})

	if err := fs.Parse([]string{"--protected", "foo"}); err != nil {
		fmt.Println(err)
	}

	err := Validate(fs, dependencies)
	if err != nil {
		fmt.Println(err)
	} else {
		fmt.Println("Everything is valid!")
	}
	// Output: flag "protected" requires feature "test-feature" to be provided in --enable-features
}

var (
	exampleFeature  = Feature("test-feature")
	exampleFeatures = []Feature{exampleFeature}
)

func TestFeatures_Flag(t *testing.T) {
	fs := flag.NewFlagSet(t.Name(), flag.PanicOnError)
	Register(fs, exampleFeatures)

	f := fs.Lookup(setFlagName)
	require.Equal(t,
		"Comma-delimited list of features to enable. Valid values: test-feature",
		f.Usage,
	)

	t.Run("Exact match", func(t *testing.T) {
		err := f.Value.Set(string(exampleFeature))
		require.NoError(t, err)
		require.True(t, Enabled(fs, exampleFeature))
	})

	t.Run("Case insensitive", func(t *testing.T) {
		err := f.Value.Set(strings.ToUpper(string(exampleFeature)))
		require.NoError(t, err)
		require.True(t, Enabled(fs, exampleFeature))
	})

	t.Run("Feature does not exist", func(t *testing.T) {
		err := f.Value.Set(fmt.Sprintf("%s,bad-feature", exampleFeature))
		require.EqualError(t, err, `unknown feature "bad-feature". possible options: test-feature`)
	})
}

func TestValidate(t *testing.T) {
	tt := []struct {
		name    string
		input   []string
		enabled bool
		expect  error
	}{
		{
			name:    "Not enabled and not provided",
			input:   []string{},
			enabled: false,
			expect:  nil,
		},
		{
			name:    "Not enabled but provided",
			input:   []string{"--example-value", "foo"},
			enabled: false,
			expect:  fmt.Errorf(`flag "example-value" requires feature "test-feature" to be provided in --enable-features`),
		},
		{
			name: "Enabled and provided",
			input: []string{
				"--enable-features=test-feature",
				"--example-value", "foo",
			},
			enabled: true,
			expect:  nil,
		},
		{
			name: "Enabled and not provided",
			input: []string{
				"--enable-features=test-feature",
			},
			enabled: true,
			expect:  nil,
		},
	}

	for _, tc := range tt {
		t.Run(tc.name, func(t *testing.T) {
			var exampleValue string

			fs := flag.NewFlagSet(t.Name(), flag.PanicOnError)
			fs.StringVar(&exampleValue, "example-value", "", "")
			Register(fs, exampleFeatures)

			err := fs.Parse(tc.input)
			require.NoError(t, err)
			require.Equal(t, tc.enabled, Enabled(fs, exampleFeature))

			err = Validate(fs, []Dependency{{
				Flag:    "example-value",
				Feature: exampleFeature,
			}})
			if tc.expect == nil {
				require.NoError(t, err)
			} else {
				require.EqualError(t, err, tc.expect.Error())
			}
		})
	}
}

'''
'''--- pkg/config/integrations.go ---
package config

import (
	"fmt"
	"reflect"

	"github.com/go-kit/log"
	"github.com/gorilla/mux"
	v1 "github.com/grafana/agent/pkg/integrations"
	v2 "github.com/grafana/agent/pkg/integrations/v2"
	"github.com/grafana/agent/pkg/metrics"
	"github.com/grafana/agent/pkg/server"
	"github.com/grafana/agent/pkg/util"
	"github.com/prometheus/statsd_exporter/pkg/level"
	"gopkg.in/yaml.v2"
)

type integrationsVersion int

const (
	integrationsVersion1 integrationsVersion = iota
	integrationsVersion2
)

// DefaultVersionedIntegrations is the default config for integrations.
var DefaultVersionedIntegrations = VersionedIntegrations{
	version:  integrationsVersion1,
	configV1: &v1.DefaultManagerConfig,
}

// VersionedIntegrations abstracts the subsystem configs for integrations v1
// and v2. VersionedIntegrations can only be unmarshaled as part of Load.
type VersionedIntegrations struct {
	version integrationsVersion
	raw     util.RawYAML

	configV1 *v1.ManagerConfig
	configV2 *v2.SubsystemOptions

	// ExtraIntegrations is used when adding any integrations NOT in the default agent configuration
	ExtraIntegrations []v2.Config
}

var (
	_ yaml.Unmarshaler = (*VersionedIntegrations)(nil)
	_ yaml.Marshaler   = (*VersionedIntegrations)(nil)
)

// UnmarshalYAML implements yaml.Unmarshaler. Full unmarshaling is deferred until
// setVersion is invoked.
func (c *VersionedIntegrations) UnmarshalYAML(unmarshal func(interface{}) error) error {
	c.configV1 = nil
	c.configV2 = nil
	return unmarshal(&c.raw)
}

// MarshalYAML implements yaml.Marshaler.
func (c VersionedIntegrations) MarshalYAML() (interface{}, error) {
	switch {
	case c.configV1 != nil:
		return c.configV1, nil
	case c.configV2 != nil:
		return c.configV2, nil
	default:
		return c.raw, nil
	}
}

// IsZero implements yaml.IsZeroer.
func (c VersionedIntegrations) IsZero() bool {
	switch {
	case c.configV1 != nil:
		return reflect.ValueOf(*c.configV1).IsZero()
	case c.configV2 != nil:
		return reflect.ValueOf(*c.configV2).IsZero()
	default:
		return len(c.raw) == 0
	}
}

// ApplyDefaults applies defaults to the subsystem based on globals.
func (c *VersionedIntegrations) ApplyDefaults(sflags *server.Flags, mcfg *metrics.Config) error {
	if c.version != integrationsVersion2 {
		return c.configV1.ApplyDefaults(sflags, mcfg)
	}
	return c.configV2.ApplyDefaults(mcfg)
}

// setVersion completes the deferred unmarshal and unmarshals the raw YAML into
// the subsystem config for version v.
func (c *VersionedIntegrations) setVersion(v integrationsVersion) error {
	c.version = v

	switch c.version {
	case integrationsVersion1:
		cfg := v1.DefaultManagerConfig
		c.configV1 = &cfg
		return yaml.UnmarshalStrict(c.raw, c.configV1)
	case integrationsVersion2:
		cfg := v2.DefaultSubsystemOptions
		// this is needed for dynamic configuration, the unmarshal doesnt work correctly if
		// this is not nil.
		c.configV1 = nil
		c.configV2 = &cfg
		err := yaml.UnmarshalStrict(c.raw, c.configV2)
		if err != nil {
			return err
		}
		c.configV2.Configs = append(c.configV2.Configs, c.ExtraIntegrations...)
		return nil
	default:
		panic(fmt.Sprintf("unknown integrations version %d", c.version))
	}
}

// IntegrationsGlobals is a global struct shared across integrations.
type IntegrationsGlobals = v2.Globals

// Integrations is an abstraction over both the v1 and v2 systems.
type Integrations interface {
	ApplyConfig(*VersionedIntegrations, IntegrationsGlobals) error
	WireAPI(*mux.Router)
	Stop()
}

// NewIntegrations creates a new subsystem. globals should be provided regardless
// of useV2. globals.SubsystemOptions will be automatically set if cfg.Version
// is set to IntegrationsVersion2.
func NewIntegrations(logger log.Logger, cfg *VersionedIntegrations, globals IntegrationsGlobals) (Integrations, error) {
	if cfg.version != integrationsVersion2 {
		instance, err := v1.NewManager(*cfg.configV1, logger, globals.Metrics.InstanceManager(), globals.Metrics.Validate)
		if err != nil {
			return nil, err
		}
		return &v1Integrations{Manager: instance}, nil
	}

	level.Warn(logger).Log("msg", "integrations-next is enabled. integrations-next is subject to change")

	globals.SubsystemOpts = *cfg.configV2
	instance, err := v2.NewSubsystem(logger, globals)
	if err != nil {
		return nil, err
	}
	return &v2Integrations{Subsystem: instance}, nil
}

type v1Integrations struct{ *v1.Manager }

func (s *v1Integrations) ApplyConfig(cfg *VersionedIntegrations, _ IntegrationsGlobals) error {
	return s.Manager.ApplyConfig(*cfg.configV1)
}

type v2Integrations struct{ *v2.Subsystem }

func (s *v2Integrations) ApplyConfig(cfg *VersionedIntegrations, globals IntegrationsGlobals) error {
	globals.SubsystemOpts = *cfg.configV2
	return s.Subsystem.ApplyConfig(globals)
}

'''
'''--- pkg/config/integrations_test.go ---
package config

import (
	"flag"
	"testing"

	"github.com/stretchr/testify/require"

	_ "github.com/grafana/agent/pkg/integrations/install" // Install integrations for tests
)

func TestIntegrations_v1(t *testing.T) {
	cfg := `
metrics:
  wal_directory: /tmp/wal

integrations:
  agent:
    enabled: true`

	fs := flag.NewFlagSet("test", flag.ExitOnError)
	c, err := load(fs, []string{"-config.file", "test"}, func(_, _ string, _ bool, c *Config) error {
		return LoadBytes([]byte(cfg), false, c)
	})
	require.NoError(t, err)
	require.NotNil(t, c.Integrations.configV1)
}

func TestIntegrations_v2(t *testing.T) {
	cfg := `
metrics:
  wal_directory: /tmp/wal

integrations:
  agent:
    autoscrape:
      enable: false`

	fs := flag.NewFlagSet("test", flag.ExitOnError)
	c, err := load(fs, []string{"-config.file", "test", "-enable-features=integrations-next"}, func(_, _ string, _ bool, c *Config) error {
		return LoadBytes([]byte(cfg), false, c)
	})
	require.NoError(t, err)
	require.NotNil(t, c.Integrations.configV2)
}

'''
'''--- pkg/config/remote_config.go ---
package config

import (
	"fmt"
	"io/ioutil"
	"net/http"
	"net/url"

	"github.com/prometheus/common/config"
)

// supported remote config provider schemes
const (
	httpScheme  = "http"
	httpsScheme = "https"
)

// remoteOpts struct contains agent remote config options
type remoteOpts struct {
	url              *url.URL
	HTTPClientConfig *config.HTTPClientConfig
}

// remoteProvider interface should be implemented by config providers
type remoteProvider interface {
	retrieve() ([]byte, error)
}

// newRemoteConfig constructs a new remote configuration provider. The rawURL is parsed
// and a provider is constructed based on the URL's scheme.
func newRemoteConfig(rawURL string, opts *remoteOpts) (remoteProvider, error) {
	u, err := url.Parse(rawURL)
	if err != nil {
		return nil, fmt.Errorf("error parsing rawURL %s: %w", rawURL, err)
	}
	if opts == nil {
		// Default provider opts
		opts = &remoteOpts{}
	}
	opts.url = u

	switch u.Scheme {
	case "":
		// if no scheme, assume local file path, return nil and let caller handle.
		return nil, nil
	case httpScheme, httpsScheme:
		httpP, err := newHTTPProvider(opts)
		if err != nil {
			return nil, fmt.Errorf("error constructing httpProvider: %w", err)
		}
		return httpP, nil
	default:
		return nil, fmt.Errorf("remote config scheme not supported: %s", u.Scheme)
	}
}

// Remote Config Providers
// httpProvider - http/https provider
type httpProvider struct {
	myURL      *url.URL
	httpClient *http.Client
}

// newHTTPProvider constructs an new httpProvider
func newHTTPProvider(opts *remoteOpts) (*httpProvider, error) {
	httpClientConfig := config.HTTPClientConfig{}
	if opts.HTTPClientConfig != nil {
		err := opts.HTTPClientConfig.Validate()
		if err != nil {
			return nil, err
		}
		httpClientConfig = *opts.HTTPClientConfig
	}
	httpClient, err := config.NewClientFromConfig(httpClientConfig, "remote-config")
	if err != nil {
		return nil, err
	}
	return &httpProvider{
		myURL:      opts.url,
		httpClient: httpClient,
	}, nil
}

// retrieve implements remoteProvider and fetches the config
func (p httpProvider) retrieve() ([]byte, error) {
	response, err := p.httpClient.Get(p.myURL.String())
	if err != nil {
		return nil, fmt.Errorf("request failed: %w", err)
	}
	defer response.Body.Close()

	if response.StatusCode/100 != 2 {
		return nil, fmt.Errorf("error fetching config: status code: %d", response.StatusCode)
	}
	bb, err := ioutil.ReadAll(response.Body)
	if err != nil {
		return nil, err
	}
	return bb, nil
}

'''
'''--- pkg/config/remote_config_test.go ---
package config

import (
	"fmt"
	"net/http"
	"net/http/httptest"
	"os"
	"testing"

	"github.com/prometheus/common/config"
	"github.com/stretchr/testify/assert"
	"github.com/stretchr/testify/require"
)

func TestRemoteConfigHTTP(t *testing.T) {
	testCfg := `
metrics:
  global:
    scrape_timeout: 33s
`

	svr := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
		if r.URL.Path == "/agent.yml" {
			_, _ = w.Write([]byte(testCfg))
		}
	}))

	svrWithBasicAuth := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
		user, pass, _ := r.BasicAuth()
		if user != "foo" && pass != "bar" {
			w.WriteHeader(http.StatusUnauthorized)
			return
		}
		if r.URL.Path == "/agent.yml" {
			_, _ = w.Write([]byte(testCfg))
		}
	}))

	tempDir := t.TempDir()
	err := os.WriteFile(fmt.Sprintf("%s/password-file.txt", tempDir), []byte("bar"), 0644)
	require.NoError(t, err)

	passwdFileCfg := &config.HTTPClientConfig{
		BasicAuth: &config.BasicAuth{
			Username:     "foo",
			PasswordFile: fmt.Sprintf("%s/password-file.txt", tempDir),
		},
	}
	dir, err := os.Getwd()
	require.NoError(t, err)
	passwdFileCfg.SetDirectory(dir)

	type args struct {
		rawURL string
		opts   *remoteOpts
	}
	tests := []struct {
		name    string
		args    args
		want    []byte
		wantErr bool
	}{
		{
			name: "httpScheme config",
			args: args{
				rawURL: fmt.Sprintf("%s/agent.yml", svr.URL),
			},
			want:    []byte(testCfg),
			wantErr: false,
		},
		{
			name: "httpScheme config with basic auth",
			args: args{
				rawURL: fmt.Sprintf("%s/agent.yml", svrWithBasicAuth.URL),
				opts: &remoteOpts{
					HTTPClientConfig: &config.HTTPClientConfig{
						BasicAuth: &config.BasicAuth{
							Username: "foo",
							Password: "bar",
						},
					},
				},
			},
			want:    []byte(testCfg),
			wantErr: false,
		},
		{
			name: "httpScheme config with basic auth password file",
			args: args{
				rawURL: fmt.Sprintf("%s/agent.yml", svrWithBasicAuth.URL),
				opts: &remoteOpts{
					HTTPClientConfig: passwdFileCfg,
				},
			},
			want:    []byte(testCfg),
			wantErr: false,
		},
		{
			name: "unsupported scheme throws error",
			args: args{
				rawURL: "ssh://unsupported/scheme",
			},
			want:    nil,
			wantErr: true,
		},
		{
			name: "invalid url throws error",
			args: args{
				rawURL: "://invalid/url",
			},
			want:    nil,
			wantErr: true,
		},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			rc, err := newRemoteConfig(tt.args.rawURL, tt.args.opts)
			if tt.wantErr {
				assert.Error(t, err)
				return
			}
			assert.NoError(t, err)
			bb, err := rc.retrieve()
			assert.NoError(t, err)
			assert.Equal(t, string(tt.want), string(bb))
		})
	}
}

'''
'''--- pkg/crow/crow.go ---
// Package crow implements a correctness checker tool similar to Loki Canary.
// Inspired by Cortex test-exporter.
package crow

import (
	"context"
	"errors"
	"flag"
	"fmt"
	"math"
	"math/rand"
	"net/http"
	"strings"
	"sync"
	"time"

	"github.com/go-kit/log"
	"github.com/go-kit/log/level"
	"github.com/opentracing-contrib/go-stdlib/nethttp"
	"github.com/prometheus/client_golang/api"
	promapi "github.com/prometheus/client_golang/api/prometheus/v1"
	"github.com/prometheus/client_golang/prometheus"
	"github.com/prometheus/client_golang/prometheus/promhttp"
	commonCfg "github.com/prometheus/common/config"
	"github.com/prometheus/common/model"
	"github.com/weaveworks/common/user"
)

// Config for the Crow metrics checker.
type Config struct {
	PrometheusAddr string // Base URL of Prometheus server
	NumSamples     int    // Number of samples to generate
	UserID         string // User ID to use for auth when querying.
	PasswordFile   string // Password File for auth when querying.
	ExtraSelectors string // Extra selectors for queries, i.e., cluster="prod"
	OrgID          string // Org ID to inject in X-Org-ScopeID header when querying.

	// Querying Params

	QueryTimeout  time.Duration // Timeout for querying
	QueryDuration time.Duration // Time before and after sample to search
	QueryStep     time.Duration // Step between samples in search

	// Validation Params

	MaxValidations    int           // Maximum amount of times to search for a sample
	MaxTimestampDelta time.Duration // Maximum timestamp delta to use for validating.
	ValueEpsilon      float64       // Maximum epsilon to use for validating.

	// Logger to use. If nil, logs will be discarded.
	Log log.Logger
}

// RegisterFlags registers flags for the config to the given FlagSet.
func (c *Config) RegisterFlags(f *flag.FlagSet) {
	c.RegisterFlagsWithPrefix(f, "")
}

// RegisterFlagsWithPrefix registers flags for the config to the given FlagSet and
// prefixing each flag with the given prefix. prefix, if non-empty, should end
// in `.`.
func (c *Config) RegisterFlagsWithPrefix(f *flag.FlagSet, prefix string) {
	f.StringVar(&c.PrometheusAddr, prefix+"prometheus-addr", DefaultConfig.PrometheusAddr, "Root URL of the Prometheus API to query against")
	f.IntVar(&c.NumSamples, prefix+"generate-samples", DefaultConfig.NumSamples, "Number of samples to generate when being scraped")
	f.StringVar(&c.UserID, prefix+"user-id", DefaultConfig.UserID, "UserID to use with basic auth.")
	f.StringVar(&c.PasswordFile, prefix+"password-file", DefaultConfig.PasswordFile, "Password file to use with basic auth.")
	f.StringVar(&c.ExtraSelectors, prefix+"extra-selectors", DefaultConfig.ExtraSelectors, "Extra selectors to include in queries, useful for identifying different instances of this job.")
	f.StringVar(&c.OrgID, prefix+"org-id", DefaultConfig.OrgID, "Org ID to inject in X-Org-ScopeID header when querying. Useful for querying multi-tenated Cortex directly.")

	f.DurationVar(&c.QueryTimeout, prefix+"query-timeout", DefaultConfig.QueryTimeout, "timeout for querying")
	f.DurationVar(&c.QueryDuration, prefix+"query-duration", DefaultConfig.QueryDuration, "time before and after sample to search")
	f.DurationVar(&c.QueryStep, prefix+"query-step", DefaultConfig.QueryStep, "step between samples when searching")

	f.IntVar(&c.MaxValidations, prefix+"max-validations", DefaultConfig.MaxValidations, "Maximum number of times to try validating a sample")
	f.DurationVar(&c.MaxTimestampDelta, prefix+"max-timestamp-delta", DefaultConfig.MaxTimestampDelta, "maximum difference from the stored timestamp from the validating sample to allow")
	f.Float64Var(&c.ValueEpsilon, prefix+"sample-epsilon", DefaultConfig.ValueEpsilon, "maximum difference from the stored value from the validating sample to allow")
}

// DefaultConfig holds defaults for Crow settings.
var DefaultConfig = Config{
	MaxValidations: 5,
	NumSamples:     10,

	QueryTimeout:  150 * time.Millisecond,
	QueryDuration: 2 * time.Second,
	QueryStep:     100 * time.Millisecond,

	// MaxTimestampDelta is set to 750ms to allow some buffer for a slow network
	// before the scrape goes through.
	MaxTimestampDelta: 750 * time.Millisecond,
	ValueEpsilon:      0.0001,
}

// Crow is a correctness checker that validates scraped metrics reach a
// Prometheus-compatible server with the same values and roughly the same
// timestamp.
//
// Crow exposes two sets of metrics:
//
// 1. Test metrics, where each scrape generates a validation job.
// 2. State metrics, exposing state of the Crow checker itself.
//
// These two metrics should be exposed via different endpoints, and only state
// metrics are safe to be manually collected from.
//
// Collecting from the set of test metrics generates a validation job, where
// Crow will query the Prometheus API to ensure the metrics that were scraped
// were written with (approximately) the same timestamp as the scrape time
// and with (approximately) the same floating point values exposed in the
// scrape.
//
// If a set of test metrics were not found and retries have been exhausted,
// or if the metrics were found but the values did not match, the error
// counter will increase.
type Crow struct {
	cfg Config
	m   *metrics

	promClient promapi.API

	wg   sync.WaitGroup
	quit chan struct{}

	pendingMtx sync.Mutex
	pending    []*sample
	sampleCh   chan []*sample
}

// New creates a new Crow.
func New(cfg Config) (*Crow, error) {
	c, err := newCrow(cfg)
	if err != nil {
		return nil, err
	}

	c.wg.Add(1)
	go c.runLoop()
	return c, nil
}

func newCrow(cfg Config) (*Crow, error) {
	if cfg.Log == nil {
		cfg.Log = log.NewNopLogger()
	}

	if cfg.PrometheusAddr == "" {
		return nil, fmt.Errorf("Crow must be configured with a URL to use for querying Prometheus")
	}

	apiCfg := api.Config{
		Address:      cfg.PrometheusAddr,
		RoundTripper: api.DefaultRoundTripper,
	}
	if cfg.UserID != "" && cfg.PasswordFile != "" {
		apiCfg.RoundTripper = commonCfg.NewBasicAuthRoundTripper(cfg.UserID, "", cfg.PasswordFile, api.DefaultRoundTripper)
	}
	if cfg.OrgID != "" {
		apiCfg.RoundTripper = &nethttp.Transport{
			RoundTripper: promhttp.RoundTripperFunc(func(req *http.Request) (*http.Response, error) {
				_ = user.InjectOrgIDIntoHTTPRequest(user.InjectOrgID(context.Background(), cfg.OrgID), req)
				return apiCfg.RoundTripper.RoundTrip(req)
			}),
		}
	}

	cli, err := api.NewClient(apiCfg)
	if err != nil {
		return nil, fmt.Errorf("failed to create prometheus client: %w", err)
	}

	c := &Crow{
		cfg:        cfg,
		m:          newMetrics(),
		promClient: promapi.NewAPI(cli),

		quit: make(chan struct{}),

		sampleCh: make(chan []*sample),
	}
	return c, nil
}

func (c *Crow) runLoop() {
	defer c.wg.Done()

	ticker := time.NewTicker(250 * time.Millisecond)
	defer ticker.Stop()

	for {
		select {
		case <-c.quit:
			return
		case samples := <-c.sampleCh:
			c.m.totalScrapes.Inc()
			c.m.totalSamples.Add(float64(len(samples)))

			c.appendSamples(samples)
		case <-ticker.C:
			c.checkPending()
		}
	}
}

// appendSamples queues samples to be checked.
func (c *Crow) appendSamples(samples []*sample) {
	c.pendingMtx.Lock()
	defer c.pendingMtx.Unlock()
	c.pending = append(c.pending, samples...)
	c.m.pendingSets.Set(float64(len(c.pending)))
}

// checkPending iterates over all pending samples. Samples that are ready
// are immediately validated. Samples are requeued if they're not ready or
// not found during validation.
func (c *Crow) checkPending() {
	c.pendingMtx.Lock()
	defer c.pendingMtx.Unlock()

	now := time.Now().UTC()

	requeued := []*sample{}
	for _, s := range c.pending {
		if !s.Ready(now) {
			requeued = append(requeued, s)
			continue
		}

		err := c.validate(s)
		if err == nil {
			c.m.totalResults.WithLabelValues("success").Inc()
			continue
		}

		s.ValidationAttempt++
		if s.ValidationAttempt < c.cfg.MaxValidations {
			requeued = append(requeued, s)
			continue
		}

		var vf errValidationFailed
		if errors.As(err, &vf) {
			switch {
			case vf.mismatch:
				c.m.totalResults.WithLabelValues("mismatch").Inc()
			case vf.missing:
				c.m.totalResults.WithLabelValues("missing").Inc()
			default:
				c.m.totalResults.WithLabelValues("unknown").Inc()
			}
		}
	}
	c.pending = requeued
	c.m.pendingSets.Set(float64(len(c.pending)))
}

type errValidationFailed struct {
	missing  bool
	mismatch bool
}

func (e errValidationFailed) Error() string {
	switch {
	case e.missing:
		return "validation failed: sample missing"
	case e.mismatch:
		return "validation failed: sample does not match"
	default:
		return "validation failed"
	}
}

// validate validates a sample. If the sample should be requeued (i.e.,
// couldn't be found), returns true.
func (c *Crow) validate(b *sample) error {
	ctx, cancel := context.WithTimeout(context.Background(), c.cfg.QueryTimeout)
	defer cancel()

	labels := make([]string, 0, len(b.Labels))
	for k, v := range b.Labels {
		labels = append(labels, fmt.Sprintf(`%s="%s"`, k, v))
	}
	if c.cfg.ExtraSelectors != "" {
		labels = append(labels, c.cfg.ExtraSelectors)
	}

	query := fmt.Sprintf("%s{%s}", validationSampleName, strings.Join(labels, ","))
	level.Debug(c.cfg.Log).Log("msg", "querying for sample", "query", query)

	val, _, err := c.promClient.QueryRange(ctx, query, promapi.Range{
		Start: b.ScrapeTime.UTC().Add(-c.cfg.QueryDuration),
		End:   b.ScrapeTime.UTC().Add(+c.cfg.QueryDuration),
		Step:  c.cfg.QueryStep,
	})

	if err != nil {
		level.Error(c.cfg.Log).Log("msg", "failed to query for sample", "query", query, "err", err)
	} else if m, ok := val.(model.Matrix); ok {
		return c.validateInMatrix(query, b, m)
	}

	return errValidationFailed{missing: true}
}

func (c *Crow) validateInMatrix(query string, b *sample, m model.Matrix) error {
	var found, matches bool

	for _, ss := range m {
		for _, sp := range ss.Values {
			ts := time.Unix(0, sp.Timestamp.UnixNano())
			dist := b.ScrapeTime.Sub(ts)
			if dist < 0 {
				dist = -dist
			}

			if dist <= c.cfg.MaxTimestampDelta {
				found = true
				matches = math.Abs(float64(sp.Value)-b.Value) <= c.cfg.ValueEpsilon
			}

			level.Debug(c.cfg.Log).Log(
				"msg", "compared query to stored sample",
				"query", query,
				"sample", ss.Metric,
				"ts", sp.Timestamp, "expect_ts", b.ScrapeTime,
				"value", sp.Value, "expect_value", b.Value,
			)

			if found && matches {
				break
			}
		}
	}

	if !found || !matches {
		return errValidationFailed{
			missing:  !found,
			mismatch: found && !matches,
		}
	}
	return nil
}

// TestMetrics exposes a collector of test metrics. Each collection will
// schedule a validation job.
func (c *Crow) TestMetrics() prometheus.Collector {
	return &sampleGenerator{
		numSamples: c.cfg.NumSamples,
		sendCh:     c.sampleCh,

		r: rand.New(rand.NewSource(time.Now().Unix())),
	}
}

// StateMetrics exposes metrics of Crow itself. These metrics are not validated
// for presence in the remote system.
func (c *Crow) StateMetrics() prometheus.Collector { return c.m }

// Stop stops crow. Panics if Stop is called more than once.
func (c *Crow) Stop() {
	close(c.quit)
	c.wg.Wait()
}

'''
'''--- pkg/crow/metrics.go ---
package crow

import "github.com/prometheus/client_golang/prometheus"

type metrics struct {
	totalScrapes prometheus.Counter
	totalSamples prometheus.Counter
	totalResults *prometheus.CounterVec
	pendingSets  prometheus.Gauge

	cachedCollectors []prometheus.Collector
}

func newMetrics() *metrics {
	var m metrics

	m.totalScrapes = prometheus.NewCounter(prometheus.CounterOpts{
		Name: "crow_test_scrapes_total",
		Help: "Total number of generated test sample sets",
	})

	m.totalSamples = prometheus.NewCounter(prometheus.CounterOpts{
		Name: "crow_test_samples_total",
		Help: "Total number of generated test samples",
	})

	m.totalResults = prometheus.NewCounterVec(prometheus.CounterOpts{
		Name: "crow_test_sample_results_total",
		Help: "Total validation results of test samples",
	}, []string{"result"}) // result is either "success", "missing", "mismatch", or "unknown"

	m.pendingSets = prometheus.NewGauge(prometheus.GaugeOpts{
		Name: "crow_test_pending_validations",
		Help: "Total number of pending validations to perform",
	})

	return &m
}

func (m *metrics) collectors() []prometheus.Collector {
	if m.cachedCollectors == nil {
		m.cachedCollectors = []prometheus.Collector{
			m.totalScrapes,
			m.totalSamples,
			m.totalResults,
			m.pendingSets,
		}
	}
	return m.cachedCollectors
}

func (m *metrics) Describe(ch chan<- *prometheus.Desc) {
	for _, c := range m.collectors() {
		c.Describe(ch)
	}
}

func (m *metrics) Collect(ch chan<- prometheus.Metric) {
	for _, c := range m.collectors() {
		c.Collect(ch)
	}
}

'''
'''--- pkg/crow/samples.go ---
package crow

import (
	"fmt"
	"math/rand"
	"time"

	"github.com/prometheus/client_golang/prometheus"
)

type sample struct {
	ScrapeTime time.Time
	Labels     prometheus.Labels
	Value      float64

	// How many times this sample has attempted to be validated. Starts at 0.
	ValidationAttempt int
}

// Ready checks if this sample is ready to be validated.
func (s *sample) Ready(now time.Time) bool {
	backoff := sampleBackoff(s.ValidationAttempt)
	return now.After(s.ScrapeTime.Add(backoff))
}

func sampleBackoff(attempt int) time.Duration {
	// Exponential backoff from 1s up to 1s + (250ms * 2^attempt).
	return time.Second + (250 * time.Millisecond * 1 << attempt)
}

type sampleGenerator struct {
	numSamples int
	sendCh     chan<- []*sample
	r          *rand.Rand
}

const validationSampleName = "crow_validation_sample"

func (sg *sampleGenerator) Describe(ch chan<- *prometheus.Desc) {
	ch <- prometheus.NewDesc(
		validationSampleName, "Sample to validate",
		[]string{"sample_num"},
		prometheus.Labels{},
	)
}

func (sg *sampleGenerator) Collect(ch chan<- prometheus.Metric) {
	var (
		scrapeTime = time.Now()

		sampleLabel = "sample_num"
		desc        = prometheus.NewDesc(
			validationSampleName, "Sample to validate",
			[]string{sampleLabel},
			prometheus.Labels{},
		)

		usedLabels = map[string]struct{}{}
		samples    = make([]*sample, sg.numSamples)
	)

	for s := 0; s < sg.numSamples; s++ {
	GenLabel:
		labelSuffix := make([]byte, 1)
		_, _ = sg.r.Read(labelSuffix)
		label := fmt.Sprintf("sample_%x", labelSuffix)
		if _, exist := usedLabels[label]; exist {
			goto GenLabel
		}
		usedLabels[label] = struct{}{}

		samples[s] = &sample{
			ScrapeTime: scrapeTime,
			Labels:     prometheus.Labels{sampleLabel: label},
			Value:      float64(sg.r.Int63n(1_000_000)),
		}
		ch <- prometheus.MustNewConstMetric(
			desc,
			prometheus.GaugeValue,
			samples[s].Value, samples[s].Labels[sampleLabel],
		)
	}

	sg.sendCh <- samples
}

'''
'''--- pkg/crow/samples_test.go ---
package crow

import (
	"fmt"
	"math/rand"
	"strings"
	"testing"
	"time"

	"github.com/prometheus/client_golang/prometheus"
	"github.com/prometheus/common/expfmt"
	"github.com/stretchr/testify/require"
)

func Test_sample_Ready(t *testing.T) {
	tt := []struct {
		sample sample
		now    time.Time
		expect bool
	}{
		{
			sample: sample{
				ScrapeTime:        time.Unix(100, 0).UTC(),
				ValidationAttempt: 0,
			},
			now:    time.Unix(100, 0).UTC(),
			expect: false,
		},
		{
			sample: sample{
				ScrapeTime:        time.Unix(100, 0).UTC(),
				ValidationAttempt: 0,
			},
			now:    time.Unix(500, 0).UTC(),
			expect: true,
		},
	}

	for _, tc := range tt {
		ready := tc.sample.Ready(tc.now)
		require.Equal(t, tc.expect, ready)
	}
}

func Test_sampleBackoff(t *testing.T) {
	tt := []struct {
		attempt int
		expect  time.Duration
	}{
		{attempt: 0, expect: 1250 * time.Millisecond},
		{attempt: 1, expect: 1500 * time.Millisecond},
		{attempt: 2, expect: 2000 * time.Millisecond},
		{attempt: 3, expect: 3000 * time.Millisecond},
		{attempt: 4, expect: 5000 * time.Millisecond},
		{attempt: 5, expect: 9000 * time.Millisecond},
	}

	for _, tc := range tt {
		t.Run(fmt.Sprintf("%d", tc.attempt), func(t *testing.T) {
			actual := sampleBackoff(tc.attempt)
			require.Equal(t, tc.expect, actual)
		})
	}
}

func Test_sampleGenerator(t *testing.T) {
	var (
		reg = prometheus.NewRegistry()
	)

	gen := sampleGenerator{
		numSamples: 10,
		sendCh:     make(chan<- []*sample, 10),
		r:          rand.New(rand.NewSource(0)),
	}
	reg.MustRegister(&gen)

	mfs, err := reg.Gather()
	require.NoError(t, err)

	var sb strings.Builder
	enc := expfmt.NewEncoder(&sb, expfmt.FmtText)
	for _, mf := range mfs {
		require.NoError(t, enc.Encode(mf))
	}

	expect := `# HELP crow_validation_sample Sample to validate
# TYPE crow_validation_sample gauge
crow_validation_sample{sample_num="sample_01"} 393152
crow_validation_sample{sample_num="sample_14"} 943416
crow_validation_sample{sample_num="sample_2f"} 980153
crow_validation_sample{sample_num="sample_51"} 637646
crow_validation_sample{sample_num="sample_55"} 976708
crow_validation_sample{sample_num="sample_94"} 995827
crow_validation_sample{sample_num="sample_c2"} 376202
crow_validation_sample{sample_num="sample_fa"} 126063
crow_validation_sample{sample_num="sample_fc"} 422456
crow_validation_sample{sample_num="sample_fd"} 197794
`
	require.Equal(t, expect, sb.String())
}

'''
'''--- pkg/flow/componenttest/componenttest.go ---
// Package componenttest provides utilities for testing Flow components.
package componenttest

import (
	"context"
	"fmt"
	"os"
	"reflect"
	"sync"
	"time"

	"github.com/prometheus/client_golang/prometheus"

	"github.com/go-kit/log"
	"github.com/grafana/agent/component"
)

// A Controller is a testing controller which controls a single component.
type Controller struct {
	reg component.Registration
	log log.Logger

	onRun   sync.Once
	running chan struct{}

	innerMut sync.Mutex
	inner    component.Component

	exportsMut sync.Mutex
	exports    component.Exports
	exportsCh  chan struct{}
}

// NewControllerFromID returns a new testing Controller for the component with
// the provided name.
func NewControllerFromID(l log.Logger, componentName string) (*Controller, error) {
	if l == nil {
		l = log.NewNopLogger()
	}

	reg, ok := component.Get(componentName)
	if !ok {
		return nil, fmt.Errorf("no such component %q", componentName)
	}

	return &Controller{
		reg: reg,
		log: l,

		running:   make(chan struct{}, 1),
		exportsCh: make(chan struct{}, 1),
	}, nil
}

func (c *Controller) onStateChange(e component.Exports) {
	c.exportsMut.Lock()
	changed := !reflect.DeepEqual(c.exports, e)
	c.exports = e
	c.exportsMut.Unlock()

	if !changed {
		return
	}

	select {
	case c.exportsCh <- struct{}{}:
	default:
	}
}

// WaitRunning blocks until the Controller is running up to the provided
// timeout.
func (c *Controller) WaitRunning(timeout time.Duration) error {
	select {
	case <-time.After(timeout):
		return fmt.Errorf("timed out waiting for the controller to start running")
	case <-c.running:
		return nil
	}
}

// WaitExports blocks until new Exports are available up to the provided
// timeout.
func (c *Controller) WaitExports(timeout time.Duration) error {
	select {
	case <-time.After(timeout):
		return fmt.Errorf("timed out waiting for exports")
	case <-c.exportsCh:
		return nil
	}
}

// Exports gets the most recent exports for a component.
func (c *Controller) Exports() component.Exports {
	c.exportsMut.Lock()
	defer c.exportsMut.Unlock()
	return c.exports
}

// Run starts the controller, building and running the component. Run blocks
// until ctx is canceled, the component exits, or if there was an error.
//
// Run may only be called once per Controller.
func (c *Controller) Run(ctx context.Context, args component.Arguments) error {
	dataPath, err := os.MkdirTemp("", "controller-*")
	if err != nil {
		return err
	}
	defer func() {
		_ = os.RemoveAll(dataPath)
	}()

	run, err := c.buildComponent(dataPath, args)
	if err != nil {
		return err
	}

	c.onRun.Do(func() { close(c.running) })
	return run.Run(ctx)
}

func (c *Controller) buildComponent(dataPath string, args component.Arguments) (component.Component, error) {
	c.innerMut.Lock()
	defer c.innerMut.Unlock()

	opts := component.Options{
		ID:            c.reg.Name + ".test",
		Logger:        c.log,
		DataPath:      dataPath,
		OnStateChange: c.onStateChange,
		Registerer:    prometheus.NewRegistry(),
	}

	inner, err := c.reg.Build(opts, args)
	if err != nil {
		return nil, err
	}

	c.inner = inner
	return inner, nil
}

// Update updates the running component. Should only be called after Run.
func (c *Controller) Update(args component.Arguments) error {
	c.innerMut.Lock()
	defer c.innerMut.Unlock()

	if c.inner == nil {
		return fmt.Errorf("component is not running")
	}
	return c.inner.Update(args)
}

'''
'''--- pkg/flow/componenttest/context.go ---
package componenttest

import (
	"context"
	"testing"
)

// TestContext returns a context which cancels itself when t finishes.
func TestContext(t *testing.T) context.Context {
	ctx, cancel := context.WithCancel(context.Background())
	t.Cleanup(cancel)
	return ctx
}

'''
'''--- pkg/flow/config.go ---
package flow

import (
	"fmt"
	"strings"

	"github.com/grafana/agent/pkg/flow/logging"
	"github.com/grafana/agent/pkg/river/ast"
	"github.com/grafana/agent/pkg/river/diag"
	"github.com/grafana/agent/pkg/river/parser"
	"github.com/grafana/agent/pkg/river/vm"
)

// File holds the contents of a parsed Flow file.
type File struct {
	Name string    // File name given to ReadFile.
	Node *ast.File // Raw File node.

	Logging logging.Options

	// Components holds the list of raw River AST blocks describing components.
	// The Flow controller can interpret them.
	Components []*ast.BlockStmt
}

// ReadFile parses the River file specified by bb into a File. name should be
// the name of the file used for reporting errors.
func ReadFile(name string, bb []byte) (*File, error) {
	node, err := parser.ParseFile(name, bb)
	if err != nil {
		return nil, err
	}

	// Look for predefined non-components blocks (i.e., logging), and store
	// everything else into a list of components.
	//
	// TODO(rfratto): should this code be brought into a helper somewhere? Maybe
	// in ast?
	var (
		loggerBlock *ast.BlockStmt
		components  []*ast.BlockStmt
	)

	for _, stmt := range node.Body {
		switch stmt := stmt.(type) {
		case *ast.AttributeStmt:
			return nil, diag.Diagnostic{
				Severity: diag.SeverityLevelError,
				StartPos: ast.StartPos(stmt.Name).Position(),
				EndPos:   ast.EndPos(stmt.Name).Position(),
				Message:  "unrecognized attribute " + stmt.Name.Name,
			}

		case *ast.BlockStmt:
			fullName := strings.Join(stmt.Name, ".")
			switch fullName {
			case "logging":
				loggerBlock = stmt
			default:
				components = append(components, stmt)
			}

		default:
			return nil, diag.Diagnostic{
				Severity: diag.SeverityLevelError,
				StartPos: ast.StartPos(stmt).Position(),
				EndPos:   ast.EndPos(stmt).Position(),
				Message:  fmt.Sprintf("unsupported statement type %T", stmt),
			}
		}
	}

	loggingOpts := logging.DefaultOptions
	if loggerBlock != nil {
		if err := vm.New(loggerBlock.Body).Evaluate(nil, &loggingOpts); err != nil {
			return nil, err
		}
	}

	return &File{
		Name:       name,
		Node:       node,
		Logging:    loggingOpts,
		Components: components,
	}, nil
}

'''
'''--- pkg/flow/config_test.go ---
package flow_test

import (
	"strings"
	"testing"

	"github.com/grafana/agent/pkg/flow"
	"github.com/grafana/agent/pkg/river/ast"
	"github.com/stretchr/testify/require"

	_ "github.com/grafana/agent/pkg/flow/internal/testcomponents" // Include test components
)

func TestReadFile(t *testing.T) {
	content := `
		testcomponents.tick "ticker_a" {
			frequency = "1s"
		}

		testcomponents.passthrough "static" {
			input = "hello, world!"
		}
	`

	f, err := flow.ReadFile(t.Name(), []byte(content))
	require.NoError(t, err)
	require.NotNil(t, f)

	require.Len(t, f.Components, 2)
	require.Equal(t, "testcomponents.tick.ticker_a", getBlockID(f.Components[0]))
	require.Equal(t, "testcomponents.passthrough.static", getBlockID(f.Components[1]))
}

func TestReadFile_Defaults(t *testing.T) {
	f, err := flow.ReadFile(t.Name(), []byte(``))
	require.NotNil(t, f)
	require.NoError(t, err)

	require.Len(t, f.Components, 0)
}

func getBlockID(b *ast.BlockStmt) string {
	var parts []string
	parts = append(parts, b.Name...)
	if b.Label != "" {
		parts = append(parts, b.Label)
	}
	return strings.Join(parts, ".")
}

'''
'''--- pkg/flow/flow.go ---
// Package flow implements the Flow component graph system. Flow configuration
// files are parsed from River, which contain a listing of components to run.
//
// Components
//
// Each component has a set of arguments (River attributes and blocks) and
// optionally a set of exported fields. Components can reference the exports of
// other components using River expressions.
//
// See the top-level component package for more information on components, and
// subpackages for defined components.
//
// Component Health
//
// A component will have various health states during its lifetime:
//
//     1. Unknown:   The initial health state for new components.
//     2. Healthy:   A healthy component
//     3. Unhealthy: An unhealthy component.
//     4. Exited:    A component which is no longer running.
//
// Health states are paired with a time for when the health state was generated
// and a message providing more detail for the health state.
//
// Components can report their own health states. The health state reported by
// a component is merged with the Flow-level health of that component: an error
// when evaluating the configuration for a component will always be reported as
// unhealthy until the next successful evaluation.
//
// Component Evaluation
//
// The process of converting the River block associated with a component into
// the appropriate Go struct is called "component evaluation."
//
// Components are only evaluated after all components they reference have been
// evaluated; cyclic dependencies are invalid.
//
// If a component updates its Exports at runtime, other components which directly
// or indirectly reference the updated component will have their Arguments
// re-evaluated.
//
// The arguments and exports for a component will be left in their last valid
// state if a component shuts down or is given an invalid config. This prevents
// a domino effect of a single failed component taking down other components
// which are otherwise healthy.
package flow

import (
	"context"
	"fmt"
	"io"
	"sync"

	"github.com/go-kit/log/level"
	"github.com/grafana/agent/pkg/flow/internal/controller"
	"github.com/grafana/agent/pkg/flow/logging"
	"github.com/prometheus/client_golang/prometheus"
)

// Options holds static options for a flow controller.
type Options struct {
	// Logger for components to use. A no-op logger will be created if this is
	// nil.
	Logger *logging.Logger

	// Directory where components can write data. Components will create
	// subdirectories for component-specific data.
	DataPath string

	// Reg is the prometheus register to use
	Reg prometheus.Registerer
}

// Flow is the Flow system.
type Flow struct {
	log  *logging.Logger
	opts Options

	updateQueue *controller.Queue
	sched       *controller.Scheduler
	loader      *controller.Loader

	cancel       context.CancelFunc
	exited       chan struct{}
	loadFinished chan struct{}

	loadMut    sync.RWMutex
	loadedOnce bool
}

// New creates and starts a new Flow controller. Call Close to stop
// the controller.
func New(o Options) *Flow {
	c, ctx := newFlow(o)
	go c.run(ctx)
	return c
}

func newFlow(o Options) (*Flow, context.Context) {
	ctx, cancel := context.WithCancel(context.Background())
	log := o.Logger
	if log == nil {
		var err error
		log, err = logging.New(io.Discard, logging.DefaultOptions)
		if err != nil {
			// This shouldn't happen unless there's a bug
			panic(err)
		}
	}

	var (
		queue  = controller.NewQueue()
		sched  = controller.NewScheduler()
		loader = controller.NewLoader(controller.ComponentGlobals{
			Logger:   log,
			DataPath: o.DataPath,
			OnExportsChange: func(cn *controller.ComponentNode) {
				// Changed components should be queued for reevaluation.
				queue.Enqueue(cn)
			},
			Registerer: o.Reg,
		})
	)

	return &Flow{
		log:  log,
		opts: o,

		updateQueue: queue,
		sched:       sched,
		loader:      loader,

		cancel:       cancel,
		exited:       make(chan struct{}, 1),
		loadFinished: make(chan struct{}, 1),
	}, ctx
}

func (c *Flow) run(ctx context.Context) {
	defer close(c.exited)
	defer level.Debug(c.log).Log("msg", "flow controller exiting")

	ctx, cancel := context.WithCancel(ctx)
	defer cancel()

	for {
		select {
		case <-ctx.Done():
			return

		case <-c.updateQueue.Chan():
			// We need to pop _everything_ from the queue and evaluate each of them.
			// If we only pop a single element, other components may sit waiting for
			// evaluation forever.
			for {
				updated := c.updateQueue.TryDequeue()
				if updated == nil {
					break
				}

				level.Debug(c.log).Log("msg", "handling component with updated state", "node_id", updated.NodeID())
				c.loader.EvaluateDependencies(nil, updated)
			}

		case <-c.loadFinished:
			level.Info(c.log).Log("msg", "scheduling loaded components")

			components := c.loader.Components()
			runnables := make([]controller.RunnableNode, 0, len(components))
			for _, uc := range components {
				runnables = append(runnables, uc)
			}
			err := c.sched.Synchronize(runnables)
			if err != nil {
				level.Error(c.log).Log("msg", "failed to load components", "err", err)
			}
		}
	}
}

// LoadFile synchronizes the state of the controller with the current config
// file. Components in the graph will be marked as unhealthy if there was an
// error encountered during Load.
//
// The controller will only start running components after Load is called once
// without any configuration errors.
func (c *Flow) LoadFile(f *File) error {
	c.loadMut.Lock()
	defer c.loadMut.Unlock()

	err := c.log.Update(f.Logging)
	if err != nil {
		return fmt.Errorf("error updating logger: %w", err)
	}

	diags := c.loader.Apply(nil, f.Components)
	if !c.loadedOnce && diags.HasErrors() {
		// The first call to Load should not run any components if there were
		// errors in the configuration file.
		return diags
	}
	c.loadedOnce = true

	select {
	case c.loadFinished <- struct{}{}:
	default:
		// A refresh is already scheduled
	}
	return diags.ErrorOrNil()
}

// Close closes the controller and all running components.
func (c *Flow) Close() error {
	c.cancel()
	<-c.exited
	return c.sched.Close()
}

'''
'''--- pkg/flow/flow_http.go ---
package flow

import (
	"bytes"
	"fmt"
	"io"
	"net/http"

	"github.com/go-kit/log/level"
	"github.com/grafana/agent/pkg/flow/internal/controller"
	"github.com/grafana/agent/pkg/flow/internal/dag"
	"github.com/grafana/agent/pkg/flow/internal/graphviz"
	"github.com/grafana/agent/pkg/river/token"
	"github.com/grafana/agent/pkg/river/token/builder"
)

// GraphHandler returns an http.HandlerFunc which renders the current graph's
// DAG as an SVG. Graphviz must be installed for this function to work.
func (f *Flow) GraphHandler() http.HandlerFunc {
	return func(w http.ResponseWriter, _ *http.Request) {
		g := f.loader.Graph()
		dot := dag.MarshalDOT(g)

		svgBytes, err := graphviz.Dot(dot, "svg")
		if err != nil {
			http.Error(w, err.Error(), http.StatusInternalServerError)
			return
		}
		_, err = io.Copy(w, bytes.NewReader(svgBytes))
		if err != nil {
			level.Error(f.log).Log("msg", "failed to write svg graph", "err", err)
		}
	}
}

// ConfigHandler returns an http.HandlerFunc which will render the most
// recently loaded configuration file as River.
func (f *Flow) ConfigHandler() http.HandlerFunc {
	return func(w http.ResponseWriter, r *http.Request) {
		debugInfo := r.URL.Query().Get("debug") == "1"

		var buf bytes.Buffer
		_, err := f.configBytes(&buf, debugInfo)
		if err != nil {
			http.Error(w, err.Error(), http.StatusInternalServerError)
		} else {
			_, _ = io.Copy(w, &buf)
		}
	}
}

// ScopeHandler returns an http.HandlerFunc which will render the scope used
// for variable references throughout River expressions.
func (f *Flow) ScopeHandler() http.HandlerFunc {
	return func(w http.ResponseWriter, _ *http.Request) {
		be := builder.NewExpr()
		be.SetValue(f.loader.Variables())

		var buf bytes.Buffer
		_, err := be.WriteTo(&buf)
		if err != nil {
			http.Error(w, err.Error(), http.StatusInternalServerError)
		} else {
			_, _ = io.Copy(w, &buf)
		}
	}
}

// configBytes dumps the current state of the flow config as River.
func (f *Flow) configBytes(w io.Writer, debugInfo bool) (n int64, err error) {
	file := builder.NewFile()

	blocks := f.loader.WriteBlocks(debugInfo)
	for _, block := range blocks {
		var id controller.ComponentID
		id = append(id, block.Name...)
		if block.Label != "" {
			id = append(id, block.Label)
		}

		comment := fmt.Sprintf("// Component %s:", id.String())
		file.Body().AppendTokens([]builder.Token{
			{Tok: token.COMMENT, Lit: comment},
		})

		file.Body().AppendBlock(block)
		file.Body().AppendTokens([]builder.Token{
			{Tok: token.LITERAL, Lit: "\n"},
		})
	}

	return file.WriteTo(w)
}

'''
'''--- pkg/flow/flow_http_test.go ---
package flow

import (
	"bytes"
	"testing"

	_ "github.com/grafana/agent/pkg/flow/internal/testcomponents" // Import testcomponents
	"github.com/stretchr/testify/require"
)

func Test_configBytes(t *testing.T) {
	configFile := `
		testcomponents.tick "ticker_a" {
			frequency = "1s"
		}

		testcomponents.passthrough "static" {
			input = "hello, world!"
		}
	`

	file, err := ReadFile(t.Name(), []byte(configFile))
	require.NotNil(t, file)
	require.NoError(t, err)

	f, _ := newFlow(testOptions(t))

	err = f.LoadFile(file)
	require.NoError(t, err)

	var buf bytes.Buffer
	_, _ = f.configBytes(&buf, false)
	actual := buf.String()

	// Exported fields aren't reported for testcomponents.tick.ticker_a because
	// the controller isn't running, so all of its exports are the zero value and
	// get omitted from the result.
	expect :=
		`// Component testcomponents.tick.ticker_a:
testcomponents.tick "ticker_a" {
	frequency = "1s"
}

// Component testcomponents.passthrough.static:
testcomponents.passthrough "static" {
	input = "hello, world!"

	// Exported fields:
	output = "hello, world!"
}`

	require.Equal(t, expect, actual)
}

'''
'''--- pkg/flow/flow_test.go ---
package flow

import (
	"os"
	"testing"

	"github.com/grafana/agent/component"
	"github.com/grafana/agent/pkg/flow/internal/controller"
	"github.com/grafana/agent/pkg/flow/internal/dag"
	"github.com/grafana/agent/pkg/flow/internal/testcomponents"
	"github.com/grafana/agent/pkg/flow/logging"
	"github.com/stretchr/testify/require"
)

var testFile = `
	testcomponents.tick "ticker" {
		frequency = "1s"
	}

	testcomponents.passthrough "static" {
		input = "hello, world!"
	}

	testcomponents.passthrough "ticker" {
		input = testcomponents.tick.ticker.tick_time
	}

	testcomponents.passthrough "forwarded" {
		input = testcomponents.passthrough.ticker.output
	}
`

func TestController_LoadFile_Evaluation(t *testing.T) {
	ctrl, _ := newFlow(testOptions(t))

	// Use testFile from graph_builder_test.go.
	f, err := ReadFile(t.Name(), []byte(testFile))
	require.NoError(t, err)
	require.NotNil(t, f)

	err = ctrl.LoadFile(f)
	require.NoError(t, err)
	require.Len(t, ctrl.loader.Components(), 4)

	// Check the inputs and outputs of things that should be immediately resolved
	// without having to run the components.
	in, out := getFields(t, ctrl.loader.Graph(), "testcomponents.passthrough.static")
	require.Equal(t, "hello, world!", in.(testcomponents.PassthroughConfig).Input)
	require.Equal(t, "hello, world!", out.(testcomponents.PassthroughExports).Output)
}

func getFields(t *testing.T, g *dag.Graph, nodeID string) (component.Arguments, component.Exports) {
	t.Helper()

	n := g.GetByID(nodeID)
	require.NotNil(t, n, "couldn't find node %q in graph", nodeID)

	uc := n.(*controller.ComponentNode)
	return uc.Arguments(), uc.Exports()
}

func testOptions(t *testing.T) Options {
	t.Helper()

	l, err := logging.New(os.Stderr, logging.DefaultOptions)
	require.NoError(t, err)

	return Options{
		Logger:   l,
		DataPath: t.TempDir(),
		Reg:      nil,
	}
}

'''
'''--- pkg/flow/internal/controller/component.go ---
package controller

import (
	"context"
	"errors"
	"fmt"
	"path/filepath"
	"reflect"
	"strings"
	"sync"
	"time"

	"github.com/go-kit/log"
	"github.com/go-kit/log/level"
	"github.com/grafana/agent/component"
	"github.com/grafana/agent/pkg/flow/internal/dag"
	"github.com/grafana/agent/pkg/river/ast"
	"github.com/grafana/agent/pkg/river/vm"
	"github.com/prometheus/client_golang/prometheus"
	"go.uber.org/atomic"
)

// ComponentID is a fully-qualified name of a component. Each element in
// ComponentID corresponds to a fragment of the period-delimited string;
// "remote.http.example" is ComponentID{"remote", "http", "example"}.
type ComponentID []string

// BlockComponentID returns the ComponentID specified by an River block.
func BlockComponentID(b *ast.BlockStmt) ComponentID {
	id := make(ComponentID, 0, len(b.Name)+1) // add 1 for the optional label
	id = append(id, b.Name...)
	if b.Label != "" {
		id = append(id, b.Label)
	}
	return id
}

// String returns the string representation of a component ID.
func (id ComponentID) String() string {
	return strings.Join(id, ".")
}

// Equals returns true if id == other.
func (id ComponentID) Equals(other ComponentID) bool {
	if len(id) != len(other) {
		return false
	}
	for i := 0; i < len(id); i++ {
		if id[i] != other[i] {
			return false
		}
	}
	return true
}

// ComponentGlobals are used by ComponentNodes to build managed components. All
// ComponentNodes should use the same ComponentGlobals.
type ComponentGlobals struct {
	Logger          log.Logger              // Logger shared between all managed components.
	DataPath        string                  // Shared directory where component data may be stored
	OnExportsChange func(cn *ComponentNode) // Invoked when the managed component updated its exports
	Registerer      prometheus.Registerer   // Registerer for serving agent and component metrics
}

// ComponentNode is a controller node which manages a user-defined component.
//
// ComponentNode manages the underlying component and caches its current
// arguments and exports. ComponentNode manages the arguments for the component
// from a River block.
type ComponentNode struct {
	id              ComponentID
	nodeID          string // Cached from id.String() to avoid allocating new strings every time NodeID is called.
	reg             component.Registration
	managedOpts     component.Options
	register        *wrappedRegisterer
	exportsType     reflect.Type
	onExportsChange func(cn *ComponentNode) // Informs controller that we changed our exports

	mut     sync.RWMutex
	block   *ast.BlockStmt // Current River block to derive args from
	eval    *vm.Evaluator
	managed component.Component // Inner managed component
	args    component.Arguments // Evaluated arguments for the managed component

	doingEval atomic.Bool

	// NOTE(rfratto): health and exports have their own mutex because they may be
	// set asynchronously while mut is still being held (i.e., when calling Evaluate
	// and the managed component immediately creates new exports)

	healthMut  sync.RWMutex
	evalHealth component.Health // Health of the last evaluate
	runHealth  component.Health // Health of running the component

	exportsMut sync.RWMutex
	exports    component.Exports // Evaluated exports for the managed component

}

var (
	_ dag.Node = (*ComponentNode)(nil)
)

// NewComponentNode creates a new ComponentNode from an initial ast.BlockStmt.
// The underlying managed component isn't created until Evaluate is called.
func NewComponentNode(globals ComponentGlobals, b *ast.BlockStmt) *ComponentNode {
	var (
		id     = BlockComponentID(b)
		nodeID = id.String()
	)

	reg, ok := component.Get(ComponentID(b.Name).String())
	if !ok {
		// NOTE(rfratto): It's normally not possible to get to this point; the
		// blocks should have been validated by the graph loader in advance to
		// guarantee that b is an expected component.
		panic("NewComponentNode: could not find registration for component " + nodeID)
	}

	initHealth := component.Health{
		Health:     component.HealthTypeUnknown,
		Message:    "component created",
		UpdateTime: time.Now(),
	}

	cn := &ComponentNode{
		id:              id,
		nodeID:          nodeID,
		reg:             reg,
		exportsType:     getExportsType(reg),
		onExportsChange: globals.OnExportsChange,

		block: b,
		eval:  vm.New(b.Body),

		// Prepopulate arguments and exports with their zero values.
		args:    reg.Args,
		exports: reg.Exports,

		evalHealth: initHealth,
		runHealth:  initHealth,
	}
	cn.managedOpts = getManagedOptions(globals, cn)

	return cn
}

func getManagedOptions(globals ComponentGlobals, cn *ComponentNode) component.Options {
	wrapped := newWrappedRegisterer()
	cn.register = wrapped
	return component.Options{
		ID:            cn.nodeID,
		Logger:        log.With(globals.Logger, "component", cn.nodeID),
		DataPath:      filepath.Join(globals.DataPath, cn.nodeID),
		OnStateChange: cn.setExports,
		Registerer: prometheus.WrapRegistererWith(prometheus.Labels{
			"component_id": cn.nodeID,
		}, wrapped),
	}
}

func getExportsType(reg component.Registration) reflect.Type {
	if reg.Exports != nil {
		return reflect.TypeOf(reg.Exports)
	}
	return nil
}

// ID returns the component ID of the managed component from its River block.
func (cn *ComponentNode) ID() ComponentID { return cn.id }

// NodeID implements dag.Node and returns the unique ID for this node. The
// NodeID is the string representation of the component's ID from its River
// block.
func (cn *ComponentNode) NodeID() string { return cn.nodeID }

// UpdateBlock updates the River block used to construct arguments for the
// managed component. The new block isn't used until the next time Evaluate is
// invoked.
//
// UpdateBlock will panic if the block does not match the component ID of the
// ComponentNode.
func (cn *ComponentNode) UpdateBlock(b *ast.BlockStmt) {
	if !BlockComponentID(b).Equals(cn.id) {
		panic("UpdateBlock called with an River block with a different component ID")
	}

	cn.mut.Lock()
	defer cn.mut.Unlock()
	cn.block = b
	cn.eval = vm.New(b.Body)
}

// getBlock gets the block currently used by this component. This is only used
// internally for getting the block name and label and the return value should
// not be modified.
func (cn *ComponentNode) getBlock() *ast.BlockStmt {
	cn.mut.RLock()
	defer cn.mut.RUnlock()
	return cn.block
}

// Evaluate updates the arguments for the managed component by re-evaluating
// its River block with the provided scope. The managed component will be built
// the first time Evaluate is called.
//
// Evaluate will return an error if the River block cannot be evaluated or if
// decoding to arguments fails.
func (cn *ComponentNode) Evaluate(scope *vm.Scope) error {
	err := cn.evaluate(scope)

	switch err {
	case nil:
		cn.setEvalHealth(component.HealthTypeHealthy, "component evaluated")
	default:
		msg := fmt.Sprintf("component evaluation failed: %s", err)
		cn.setEvalHealth(component.HealthTypeUnhealthy, msg)
	}

	return err
}

func (cn *ComponentNode) evaluate(scope *vm.Scope) error {
	cn.mut.Lock()
	defer cn.mut.Unlock()

	cn.doingEval.Store(true)
	defer cn.doingEval.Store(false)

	args := cn.reg.CloneArguments()
	if err := cn.eval.Evaluate(scope, args); err != nil {
		return fmt.Errorf("decoding River: %w", err)
	}

	// args is always a pointer to the args type, so we want to deference it since
	// components expect a non-pointer.
	argsCopy := reflect.ValueOf(args).Elem().Interface()

	if cn.managed == nil {
		// We haven't built the managed component successfully yet.
		managed, err := cn.reg.Build(cn.managedOpts, argsCopy)
		if err != nil {
			return fmt.Errorf("building component: %w", err)
		}
		cn.managed = managed
		cn.args = argsCopy

		return nil
	}

	if reflect.DeepEqual(cn.args, args) {
		// Ignore components which haven't changed. This reduces the cost of
		// calling evaluate for components where evaluation is expensive (e.g., if
		// re-evaluating requires re-starting some internal logic).
		return nil
	}

	// Update the existing managed component
	if err := cn.managed.Update(argsCopy); err != nil {
		return fmt.Errorf("updating component: %w", err)
	}

	cn.args = argsCopy
	return nil
}

// Run runs the managed component in the calling goroutine until ctx is
// canceled. Evaluate must have been called at least once without retuning an
// error before calling Run.
//
// Run will immediately return ErrUnevaluated if Evaluate has never been called
// successfully. Otherwise, Run will return nil.
func (cn *ComponentNode) Run(ctx context.Context) error {
	cn.mut.RLock()
	managed := cn.managed
	cn.mut.RUnlock()

	if managed == nil {
		return ErrUnevaluated
	}

	cn.setRunHealth(component.HealthTypeHealthy, "started component")
	err := cn.managed.Run(ctx)

	var exitMsg string
	log := cn.managedOpts.Logger
	if err != nil {
		level.Error(log).Log("msg", "component exited with error", "err", err)
		exitMsg = fmt.Sprintf("component shut down with error: %s", err)
	} else {
		level.Info(log).Log("msg", "component exited")
		exitMsg = "component shut down normally"
	}

	cn.setRunHealth(component.HealthTypeExited, exitMsg)
	return err
}

// ErrUnevaluated is returned if ComponentNode.Run is called before a managed
// component is built.
var ErrUnevaluated = errors.New("managed component not built")

// Arguments returns the current arguments of the managed component.
func (cn *ComponentNode) Arguments() component.Arguments {
	cn.mut.RLock()
	defer cn.mut.RUnlock()
	return cn.args
}

// Exports returns the current set of exports from the managed component.
// Exports returns nil if the managed component does not have exports.
func (cn *ComponentNode) Exports() component.Exports {
	cn.exportsMut.RLock()
	defer cn.exportsMut.RUnlock()
	return cn.exports
}

// setExports is called whenever the managed component updates. e must be the
// same type as the registered exports type of the managed component.
func (cn *ComponentNode) setExports(e component.Exports) {
	if cn.exportsType == nil {
		panic(fmt.Sprintf("Component %s called OnStateChange but never registered an Exports type", cn.nodeID))
	}
	if reflect.TypeOf(e) != cn.exportsType {
		panic(fmt.Sprintf("Component %s changed Exports types from %T to %T", cn.nodeID, cn.reg.Exports, e))
	}

	// Some components may aggressively reexport values even though no exposed
	// state has changed. This may be done for components which always supply
	// exports whenever their arguments are evaluated without tracking internal
	// state to see if anything actually changed.
	//
	// To avoid needlessly reevaluating components we'll ignore unchanged
	// exports.
	var changed bool

	cn.exportsMut.Lock()
	if !reflect.DeepEqual(cn.exports, e) {
		changed = true
		cn.exports = e
	}
	cn.exportsMut.Unlock()

	if cn.doingEval.Load() {
		// Optimization edge case: some components supply exports when they're
		// being evaluated.
		//
		// Since components that are being evaluated will always cause their
		// dependencies to also be evaluated, there's no reason to call
		// onExportsChange here.
		return
	}

	if changed {
		// Inform the controller that we have new exports.
		cn.onExportsChange(cn)
	}
}

// CurrentHealth returns the current health of the ComponentNode.
//
// The health of a ComponentNode is tracked from three parts, in descending
// precedence order:
//
//     1. Exited health from a call to Run()
//     2. Unhealthy status from last call to Evaluate
//     3. Health reported by the managed component (if any)
//     4. Latest health from Run() or Evaluate(), if the managed component does not
//        report health.
func (cn *ComponentNode) CurrentHealth() component.Health {
	cn.healthMut.RLock()
	defer cn.healthMut.RUnlock()

	// A component which stopped running takes precedence over all other health
	// states
	if cn.runHealth.Health == component.HealthTypeExited {
		return cn.runHealth
	}

	// Next, an unhealthy evaluate takes precedence over the real health of a
	// component.
	if cn.evalHealth.Health != component.HealthTypeHealthy {
		return cn.evalHealth
	}

	// Then, the health of a managed component takes precedence if it is exposed.
	hc, _ := cn.managed.(component.HealthComponent)
	if hc != nil {
		return hc.CurrentHealth()
	}

	// Finally, we return the newer health between eval and run
	latestHealth := cn.evalHealth
	if cn.runHealth.UpdateTime.After(latestHealth.UpdateTime) {
		latestHealth = cn.runHealth
	}
	return latestHealth
}

// DebugInfo returns debugging information from the managed component (if any).
func (cn *ComponentNode) DebugInfo() interface{} {
	cn.mut.RLock()
	defer cn.mut.RUnlock()

	if dc, ok := cn.managed.(component.DebugComponent); ok {
		return dc.DebugInfo()
	}
	return nil
}

// setEvalHealth sets the internal health from a call to Evaluate. See Health
// for information on how overall health is calculated.
func (cn *ComponentNode) setEvalHealth(t component.HealthType, msg string) {
	cn.healthMut.Lock()
	defer cn.healthMut.Unlock()

	cn.evalHealth = component.Health{
		Health:     t,
		Message:    msg,
		UpdateTime: time.Now(),
	}
}

// setRunHealth sets the internal health from a call to Run. See Health for
// information on how overall health is calculated.
func (cn *ComponentNode) setRunHealth(t component.HealthType, msg string) {
	cn.healthMut.Lock()
	defer cn.healthMut.Unlock()

	cn.runHealth = component.Health{
		Health:     t,
		Message:    msg,
		UpdateTime: time.Now(),
	}
}

'''
'''--- pkg/flow/internal/controller/component_references.go ---
package controller

import (
	"fmt"

	"github.com/grafana/agent/pkg/flow/internal/dag"
	"github.com/grafana/agent/pkg/river/ast"
	"github.com/grafana/agent/pkg/river/diag"
	"github.com/grafana/agent/pkg/river/vm"
)

// Traversal describes accessing a sequence of fields relative to a component.
// Traversal only include uninterrupted sequences of field accessors; for an
// expression "component.field_a.field_b.field_c[0].inner_field", the Traversal
// will be (field_a, field_b, field_c).
type Traversal []*ast.Ident

// Reference describes an River expression reference to a ComponentNode.
type Reference struct {
	Target *ComponentNode // Component being referenced

	// Traversal describes which nested field relative to Target is being
	// accessed.
	Traversal Traversal
}

// ComponentReferences returns the list of references a component is making to
// other components.
func ComponentReferences(cn *ComponentNode, g *dag.Graph) ([]Reference, diag.Diagnostics) {
	var (
		traversals = componentTraversals(cn)

		diags diag.Diagnostics
	)

	refs := make([]Reference, 0, len(traversals))
	for _, t := range traversals {
		// We use an empty scope to determine if a reference refers to something in
		// the stdlib, since vm.Scope.Lookup will search the scope tree + the
		// stdlib.
		//
		// Any call to an stdlib function is ignored.
		var emptyScope vm.Scope
		if _, ok := emptyScope.Lookup(t[0].Name); ok && len(t) == 1 {
			continue
		}

		ref, resolveDiags := resolveTraversal(t, g)
		diags = append(diags, resolveDiags...)
		if resolveDiags.HasErrors() {
			continue
		}
		refs = append(refs, ref)
	}

	return refs, diags
}

// componentTraversals gets the set of Traverals for a given component.
func componentTraversals(cn *ComponentNode) []Traversal {
	cn.mut.RLock()
	defer cn.mut.RUnlock()
	return expressionsFromBody(cn.block.Body)
}

// expressionsFromSyntaxBody recurses through body and finds all variable
// references.
func expressionsFromBody(body ast.Body) []Traversal {
	var w traversalWalker
	ast.Walk(&w, body)

	// Flush after the walk in case there was an in-progress traversal.
	w.flush()
	return w.traversals
}

type traversalWalker struct {
	traversals []Traversal

	buildTraversal   bool      // Whether
	currentTraversal Traversal // currentTraversal being built.
}

func (tw *traversalWalker) Visit(node ast.Node) ast.Visitor {
	switch n := node.(type) {
	case *ast.IdentifierExpr:
		// Identifiers always start new traversals. Pop the last one.
		tw.flush()
		tw.buildTraversal = true
		tw.currentTraversal = append(tw.currentTraversal, n.Ident)

	case *ast.AccessExpr:
		ast.Walk(tw, n.Value)

		// Fields being accessed should get only added to the traversal if one is
		// being built. This will be false for accesses like a().foo.
		if tw.buildTraversal {
			tw.currentTraversal = append(tw.currentTraversal, n.Name)
		}
		return nil

	case *ast.IndexExpr:
		// Indexing interrupts traversals so we flush after walking the value.
		ast.Walk(tw, n.Value)
		tw.flush()
		ast.Walk(tw, n.Index)
		return nil

	case *ast.CallExpr:
		// Calls interrupt traversals so we flush after walking the value.
		ast.Walk(tw, n.Value)
		tw.flush()
		for _, arg := range n.Args {
			ast.Walk(tw, arg)
		}
		return nil
	}

	return tw
}

// flush will flush the in-progress traversal to the traversals list and unset
// the buildTraversal state.
func (tw *traversalWalker) flush() {
	if tw.buildTraversal && len(tw.currentTraversal) > 0 {
		tw.traversals = append(tw.traversals, tw.currentTraversal)
	}
	tw.buildTraversal = false
	tw.currentTraversal = nil
}

func resolveTraversal(t Traversal, g *dag.Graph) (Reference, diag.Diagnostics) {
	var (
		diags diag.Diagnostics

		partial = ComponentID{t[0].Name}
		rem     = t[1:]
	)

	for {
		if n := g.GetByID(partial.String()); n != nil {
			return Reference{
				Target:    n.(*ComponentNode),
				Traversal: rem,
			}, nil
		}

		if len(rem) == 0 {
			// Stop: there's no more elements to look at in the traversal.
			break
		}

		// Append the next name in the traversal to our partial reference.
		partial = append(partial, rem[0].Name)
		rem = rem[1:]
	}

	diags = append(diags, diag.Diagnostic{
		Severity: diag.SeverityLevelError,
		Message:  fmt.Sprintf("component %q does not exist", partial),
		StartPos: ast.StartPos(t[0]).Position(),
		EndPos:   ast.StartPos(t[len(t)-1]).Position(),
	})
	return Reference{}, diags
}

'''
'''--- pkg/flow/internal/controller/component_write.go ---
package controller

import (
	"reflect"

	"github.com/grafana/agent/pkg/river/token"
	"github.com/grafana/agent/pkg/river/token/builder"
)

// WriteComponent generates a token/builder Block from a component. Health and
// debug info will be included if debugInfo is true.
func WriteComponent(cn *ComponentNode, debugInfo bool) *builder.Block {
	b := builder.NewBlock(cn.getBlock().Name, cn.getBlock().Label)

	if args := cn.Arguments(); args != nil {
		b.Body().AppendFrom(args)
	}

	// We ignore zero value exports since the zero values for fields don't get
	// written back out to the user.
	if exports := cn.Exports(); exports != nil && !exportsZeroValue(exports) {
		b.Body().AppendTokens([]builder.Token{
			{Tok: token.LITERAL, Lit: "\n"},
			{Tok: token.COMMENT, Lit: "// Exported fields:"},
		})

		b.Body().AppendFrom(exports)
	}

	if debugInfo {
		b.Body().AppendTokens([]builder.Token{
			{Tok: token.LITERAL, Lit: "\n"},
			{Tok: token.COMMENT, Lit: "// Debug info:"},
		})

		healthBlock := builder.NewBlock([]string{"health"}, "")
		healthBlock.Body().AppendFrom(cn.CurrentHealth())
		b.Body().AppendBlock(healthBlock)

		if di := cn.DebugInfo(); di != nil {
			statusBlock := builder.NewBlock([]string{"status"}, "")
			statusBlock.Body().AppendFrom(di)
			b.Body().AppendBlock(statusBlock)
		}
	}

	return b
}

func exportsZeroValue(v interface{}) bool {
	return reflect.ValueOf(v).IsZero()
}

'''
'''--- pkg/flow/internal/controller/component_write_test.go ---
package controller

import (
	"fmt"
	"strings"
	"testing"
	"time"

	"github.com/go-kit/log"
	_ "github.com/grafana/agent/pkg/flow/internal/testcomponents" // Import test components
	"github.com/grafana/agent/pkg/river/ast"
	"github.com/grafana/agent/pkg/river/parser"
	"github.com/grafana/agent/pkg/river/token/builder"
	"github.com/stretchr/testify/require"
)

func TestWriteComponent(t *testing.T) {
	config := `
		testcomponents.passthrough "example" {
			input = "Hello, world!"
		}
	`

	blocks := loadFile(t, []byte(config))

	cn := NewComponentNode(ComponentGlobals{
		Logger:          log.NewNopLogger(),
		DataPath:        t.TempDir(),
		OnExportsChange: func(cn *ComponentNode) { /* no-op */ },
	}, blocks[0])

	// Evaluate the component so we're sure it's built
	err := cn.Evaluate(nil)
	require.NoError(t, err)

	outBlock := WriteComponent(cn, false)
	actual := marshalBlock(outBlock)

	expect := `
testcomponents.passthrough "example" {
	input = "Hello, world!"

	// Exported fields:
	output = "Hello, world!"
}`

	// Remove leading and trailing whitespace so we don't have to get too picky
	// about how we format the expected string.
	expect = strings.TrimSpace(expect)
	actual = strings.TrimSpace(actual)
	require.Equal(t, expect, actual)
}

func TestWriteComponent_DebugInfo(t *testing.T) {
	config := `
		testcomponents.passthrough "example" {
			input = "Hello, world!"
		}
	`

	blocks := loadFile(t, []byte(config))

	cn := NewComponentNode(ComponentGlobals{
		Logger:          log.NewNopLogger(),
		DataPath:        t.TempDir(),
		OnExportsChange: func(cn *ComponentNode) { /* no-op */ },
	}, blocks[0])

	// Evaluate the component so we're sure it's built
	err := cn.Evaluate(nil)
	require.NoError(t, err)

	outBlock := WriteComponent(cn, true)
	actual := marshalBlock(outBlock)

	expect := fmt.Sprintf(`
testcomponents.passthrough "example" {
	input = "Hello, world!"

	// Exported fields:
	output = "Hello, world!"

	// Debug info:
	health {
		state       = "healthy"
		message     = "component evaluated"
		update_time = %q
	}

	status {
		component_version = "v0.1-beta.0"
	}
}`, cn.evalHealth.UpdateTime.Format(time.RFC3339Nano))

	// Remove leading and trailing whitespace so we don't have to get too picky
	// about how we format the expected string.
	expect = strings.TrimSpace(expect)
	actual = strings.TrimSpace(actual)
	require.Equal(t, expect, actual)
}

func loadFile(t *testing.T, bb []byte) []*ast.BlockStmt {
	file, err := parser.ParseFile(t.Name(), bb)
	require.NoError(t, err)

	var blocks []*ast.BlockStmt

	for _, stmt := range file.Body {
		switch stmt := stmt.(type) {
		case *ast.BlockStmt:
			blocks = append(blocks, stmt)
		default:
			require.FailNow(t, "%s: non-block statement unexpected", ast.StartPos(stmt).Position())
		}
	}

	return blocks
}

func marshalBlock(b *builder.Block) string {
	f := builder.NewFile()
	f.Body().AppendBlock(b)
	return string(f.Bytes())
}

'''
'''--- pkg/flow/internal/controller/loader.go ---
package controller

import (
	"errors"
	"fmt"
	"strings"
	"sync"
	"time"

	"github.com/go-kit/log"
	"github.com/go-kit/log/level"
	"github.com/grafana/agent/component"
	"github.com/grafana/agent/pkg/flow/internal/dag"
	"github.com/grafana/agent/pkg/river/ast"
	"github.com/grafana/agent/pkg/river/diag"
	"github.com/grafana/agent/pkg/river/token/builder"
	"github.com/grafana/agent/pkg/river/vm"
	"github.com/hashicorp/go-multierror"

	_ "github.com/grafana/agent/pkg/flow/internal/testcomponents" // Include test components
)

// The Loader builds and evaluates ComponentNodes from River blocks.
type Loader struct {
	log     log.Logger
	globals ComponentGlobals

	mut        sync.RWMutex
	graph      *dag.Graph
	components []*ComponentNode
	cache      *valueCache
	blocks     []*ast.BlockStmt // Most recently loaded blocks, used for writing
	cm         *controllerMetrics
}

// NewLoader creates a new Loader. Components built by the Loader will be built
// with co for their options.
func NewLoader(globals ComponentGlobals) *Loader {
	l := &Loader{
		log:     globals.Logger,
		globals: globals,

		graph: &dag.Graph{},
		cache: newValueCache(),
		cm:    newControllerMetrics(globals.Registerer),
	}
	cc := newControllerCollector(l)
	if globals.Registerer != nil {
		globals.Registerer.MustRegister(cc)
	}
	return l
}

// Apply loads a new set of components into the Loader. Apply will drop any
// previously loaded component which is not described in the set of River
// blocks.
//
// Apply will reuse existing components if there is an existing component which
// matches the component ID specified by any of the provided River blocks.
// Reused components will be updated to point at the new River block.
//
// Apply will perform an evaluation of all loaded components before returning.
// The provided parentContext can be used to provide global variables and
// functions to components. A child context will be constructed from the parent
// to expose values of other components.
func (l *Loader) Apply(parentScope *vm.Scope, blocks []*ast.BlockStmt) diag.Diagnostics {
	start := time.Now()
	l.mut.Lock()
	defer l.mut.Unlock()
	l.cm.controllerEvaluation.Set(1)
	defer l.cm.controllerEvaluation.Set(0)

	var (
		diags    diag.Diagnostics
		newGraph dag.Graph
	)

	populateDiags := l.populateGraph(&newGraph, blocks)
	diags = append(diags, populateDiags...)

	wireDiags := l.wireGraphEdges(&newGraph)
	diags = append(diags, wireDiags...)

	// Validate graph to detect cycles
	err := dag.Validate(&newGraph)
	if err != nil {
		diags = append(diags, multierrToDiags(err)...)
		return diags
	}

	// Perform a transitive reduction of the graph to clean it up.
	dag.Reduce(&newGraph)

	var (
		components   = make([]*ComponentNode, 0, len(blocks))
		componentIDs = make([]ComponentID, 0, len(blocks))
	)

	// Evaluate all of the components.
	_ = dag.WalkTopological(&newGraph, newGraph.Leaves(), func(n dag.Node) error {
		c := n.(*ComponentNode)

		components = append(components, c)
		componentIDs = append(componentIDs, c.ID())

		if err := l.evaluate(parentScope, n.(*ComponentNode)); err != nil {
			var evalDiags diag.Diagnostics
			if errors.As(err, &evalDiags) {
				diags = append(diags, evalDiags...)
			} else {
				diags.Add(diag.Diagnostic{
					Severity: diag.SeverityLevelError,
					Message:  fmt.Sprintf("Failed to build component: %s", err),
					StartPos: ast.StartPos(n.(*ComponentNode).block).Position(),
					EndPos:   ast.EndPos(n.(*ComponentNode).block).Position(),
				})
			}
		}
		return nil
	})

	l.components = components
	l.graph = &newGraph
	l.cache.SyncIDs(componentIDs)
	l.blocks = blocks
	l.cm.componentEvaluationTime.Observe(time.Since(start).Seconds())
	return diags
}

func (l *Loader) populateGraph(g *dag.Graph, blocks []*ast.BlockStmt) diag.Diagnostics {
	// Fill our graph with components.
	var (
		diags    diag.Diagnostics
		blockMap = make(map[string]*ast.BlockStmt, len(blocks))
	)
	for _, block := range blocks {
		var c *ComponentNode
		id := BlockComponentID(block).String()

		if orig, redefined := blockMap[id]; redefined {
			diags.Add(diag.Diagnostic{
				Severity: diag.SeverityLevelError,
				Message:  fmt.Sprintf("Component %s already declared at %s", id, ast.StartPos(orig).Position()),
				StartPos: block.NamePos.Position(),
				EndPos:   block.NamePos.Add(len(id) - 1).Position(),
			})
			continue
		}
		blockMap[id] = block

		if exist := l.graph.GetByID(id); exist != nil {
			// Re-use the existing component and update its block
			c = exist.(*ComponentNode)
			c.UpdateBlock(block)
		} else {
			componentName := strings.Join(block.Name, ".")
			if _, exists := component.Get(componentName); !exists {
				diags.Add(diag.Diagnostic{
					Severity: diag.SeverityLevelError,
					Message:  fmt.Sprintf("Unrecognized component name %q", componentName),
					StartPos: block.NamePos.Position(),
					EndPos:   block.NamePos.Add(len(componentName) - 1).Position(),
				})
				continue
			}

			// Create a new component
			c = NewComponentNode(l.globals, block)
		}

		g.Add(c)
	}

	return diags
}

func (l *Loader) wireGraphEdges(g *dag.Graph) diag.Diagnostics {
	var diags diag.Diagnostics

	for _, n := range g.Nodes() {
		refs, nodeDiags := ComponentReferences(n.(*ComponentNode), g)
		for _, ref := range refs {
			g.AddEdge(dag.Edge{From: n, To: ref.Target})
		}
		diags = append(diags, nodeDiags...)
	}

	return diags
}

// Variables returns the Variables the Loader exposes for other Flow components
// to reference.
func (l *Loader) Variables() map[string]interface{} {
	return l.cache.BuildContext(nil).Variables
}

// Components returns the current set of loaded components.
func (l *Loader) Components() []*ComponentNode {
	l.mut.RLock()
	defer l.mut.RUnlock()
	return l.components
}

// Graph returns a copy of the DAG managed by the Loader.
func (l *Loader) Graph() *dag.Graph {
	l.mut.RLock()
	defer l.mut.RUnlock()
	return l.graph.Clone()
}

// WriteBlocks returns a set of evaluated token/builder blocks for each loaded
// component. Components are returned in the order they were supplied to Apply
// (i.e., the original order from the config file) and not topological order.
//
// Blocks will include health and debug information if debugInfo is true.
func (l *Loader) WriteBlocks(debugInfo bool) []*builder.Block {
	l.mut.RLock()
	defer l.mut.RUnlock()

	blocks := make([]*builder.Block, 0, len(l.components))

	for _, b := range l.blocks {
		id := BlockComponentID(b).String()
		node, _ := l.graph.GetByID(id).(*ComponentNode)
		if node == nil {
			continue
		}

		blocks = append(blocks, WriteComponent(node, debugInfo))
	}

	return blocks
}

// EvaluateDependencies re-evaluates components which depend directly or
// indirectly on c. EvaluateDependencies should be called whenever a component
// updates its exports.
//
// The provided parentContext can be used to provide global variables and
// functions to components. A child context will be constructed from the parent
// to expose values of other components.
func (l *Loader) EvaluateDependencies(parentScope *vm.Scope, c *ComponentNode) {
	l.mut.RLock()
	defer l.mut.RUnlock()

	l.cm.controllerEvaluation.Set(1)
	defer l.cm.controllerEvaluation.Set(0)
	start := time.Now()

	// Make sure we're in-sync with the current exports of c.
	l.cache.CacheExports(c.ID(), c.Exports())

	_ = dag.WalkReverse(l.graph, []dag.Node{c}, func(n dag.Node) error {
		if n == c {
			// Skip over the starting component; the starting component passed to
			// EvaluateDependencies had its exports changed and none of its input
			// arguments will need re-evaluation.
			return nil
		}
		_ = l.evaluate(parentScope, n.(*ComponentNode))
		return nil
	})

	l.cm.componentEvaluationTime.Observe(time.Since(start).Seconds())
}

// evaluate constructs the final context for c and evaluates it. mut must be
// held when calling evaluate.
func (l *Loader) evaluate(parent *vm.Scope, c *ComponentNode) error {
	ectx := l.cache.BuildContext(parent)
	err := c.Evaluate(ectx)
	// Always update the cache both the arguments and exports, since both might
	// change when a component gets re-evaluated. We also want to cache the arguments and exports in case of an error
	l.cache.CacheArguments(c.ID(), c.Arguments())
	l.cache.CacheExports(c.ID(), c.Exports())
	if err != nil {
		level.Error(l.log).Log("msg", "failed to evaluate component", "component", c.NodeID(), "err", err)
		return err
	}
	return nil
}

func multierrToDiags(errors error) diag.Diagnostics {
	var diags diag.Diagnostics
	for _, err := range errors.(*multierror.Error).Errors {
		// TODO(rfratto): should this include position information?
		diags.Add(diag.Diagnostic{
			Severity: diag.SeverityLevelError,
			Message:  err.Error(),
		})
	}
	return diags
}

'''
'''--- pkg/flow/internal/controller/loader_test.go ---
package controller_test

import (
	"errors"
	"strings"
	"testing"

	"github.com/go-kit/log"
	"github.com/grafana/agent/pkg/flow/internal/controller"
	"github.com/grafana/agent/pkg/flow/internal/dag"
	"github.com/grafana/agent/pkg/river/ast"
	"github.com/grafana/agent/pkg/river/diag"
	"github.com/grafana/agent/pkg/river/parser"
	"github.com/prometheus/client_golang/prometheus"
	"github.com/stretchr/testify/require"
)

func TestLoader(t *testing.T) {
	testFile := `
		testcomponents.tick "ticker" {
			frequency = "1s"
		}

		testcomponents.passthrough "static" {
			input = "hello, world!"
		}

		testcomponents.passthrough "ticker" {
			input = testcomponents.tick.ticker.tick_time
		}

		testcomponents.passthrough "forwarded" {
			input = testcomponents.passthrough.ticker.output
		}
	`

	// corresponds to testFile
	testGraphDefinition := graphDefinition{
		Nodes: []string{
			"testcomponents.tick.ticker",
			"testcomponents.passthrough.static",
			"testcomponents.passthrough.ticker",
			"testcomponents.passthrough.forwarded",
		},
		OutEdges: []edge{
			{From: "testcomponents.passthrough.ticker", To: "testcomponents.tick.ticker"},
			{From: "testcomponents.passthrough.forwarded", To: "testcomponents.passthrough.ticker"},
		},
	}

	newGlobals := func() controller.ComponentGlobals {
		return controller.ComponentGlobals{
			Logger:          log.NewNopLogger(),
			DataPath:        t.TempDir(),
			OnExportsChange: func(cn *controller.ComponentNode) { /* no-op */ },
			Registerer:      prometheus.NewRegistry(),
		}
	}

	t.Run("New Graph", func(t *testing.T) {
		l := controller.NewLoader(newGlobals())
		diags := applyFromContent(t, l, []byte(testFile))
		require.NoError(t, diags.ErrorOrNil())
		requireGraph(t, l.Graph(), testGraphDefinition)
	})

	t.Run("Copy existing components and delete stale ones", func(t *testing.T) {
		startFile := `
			// Component that should be copied over to the new graph
			testcomponents.tick "ticker" {
				frequency = "1s"
			}

			// Component that will not exist in the new graph
			testcomponents.tick "remove_me" {
				frequency = "1m"
			}
		`
		l := controller.NewLoader(newGlobals())
		diags := applyFromContent(t, l, []byte(startFile))
		origGraph := l.Graph()
		require.NoError(t, diags.ErrorOrNil())

		diags = applyFromContent(t, l, []byte(testFile))
		require.NoError(t, diags.ErrorOrNil())
		newGraph := l.Graph()

		// Ensure that nodes were copied over and not recreated
		require.Equal(t, origGraph.GetByID("testcomponents.tick.ticker"), newGraph.GetByID("testcomponents.tick.ticker"))
		require.Nil(t, newGraph.GetByID("testcomponents.tick.remove_me")) // The new graph shouldn't have the old node
	})

	t.Run("Load with invalid components", func(t *testing.T) {
		invalidFile := `
			doesnotexist "bad_component" {
			}
		`
		l := controller.NewLoader(newGlobals())
		diags := applyFromContent(t, l, []byte(invalidFile))
		require.ErrorContains(t, diags.ErrorOrNil(), `Unrecognized component name "doesnotexist`)
	})

	t.Run("Partial load with invalid reference", func(t *testing.T) {
		invalidFile := `
			testcomponents.tick "ticker" {
				frequency = "1s"
			}

			testcomponents.passthrough "valid" {
				input = testcomponents.tick.ticker.tick_time
			}

			testcomponents.passthrough "invalid" {
				input = testcomponents.tick.doesnotexist.tick_time
			}
		`
		l := controller.NewLoader(newGlobals())
		diags := applyFromContent(t, l, []byte(invalidFile))
		require.Error(t, diags.ErrorOrNil())

		requireGraph(t, l.Graph(), graphDefinition{
			Nodes: []string{
				"testcomponents.tick.ticker",
				"testcomponents.passthrough.valid",
				"testcomponents.passthrough.invalid",
			},
			OutEdges: []edge{
				{From: "testcomponents.passthrough.valid", To: "testcomponents.tick.ticker"},
			},
		})
	})

	t.Run("File has cycles", func(t *testing.T) {
		invalidFile := `
			testcomponents.tick "ticker" {
				frequency = "1s"
			}

			testcomponents.passthrough "static" {
				input = testcomponents.passthrough.forwarded.output
			}

			testcomponents.passthrough "ticker" {
				input = testcomponents.passthrough.static.output
			}

			testcomponents.passthrough "forwarded" {
				input = testcomponents.passthrough.ticker.output
			}
		`
		l := controller.NewLoader(newGlobals())
		diags := applyFromContent(t, l, []byte(invalidFile))
		require.Error(t, diags.ErrorOrNil())
	})
}

// TestScopeWithFailingComponent is used to ensure that the scope is filled out, even if the component
// fails to properly start.
func TestScopeWithFailingComponent(t *testing.T) {
	testFile := `
		testcomponents.tick "ticker" {
			frequenc = "1s"
		}

		testcomponents.passthrough "static" {
			input = "hello, world!"
		}

		testcomponents.passthrough "ticker" {
			input = testcomponents.tick.ticker.tick_time
		}

		testcomponents.passthrough "forwarded" {
			input = testcomponents.passthrough.ticker.output
		}
	`
	newGlobals := func() controller.ComponentGlobals {
		return controller.ComponentGlobals{
			Logger:          log.NewNopLogger(),
			DataPath:        t.TempDir(),
			OnExportsChange: func(cn *controller.ComponentNode) { /* no-op */ },
			Registerer:      prometheus.NewRegistry(),
		}
	}

	l := controller.NewLoader(newGlobals())
	diags := applyFromContent(t, l, []byte(testFile))
	require.Error(t, diags.ErrorOrNil())
	require.Len(t, diags, 1)
	require.True(t, strings.Contains(diags.Error(), "Failed to build component: decoding River: missing required attribute \"frequency\""))
}

func applyFromContent(t *testing.T, l *controller.Loader, bb []byte) diag.Diagnostics {
	t.Helper()

	var diags diag.Diagnostics

	file, err := parser.ParseFile(t.Name(), bb)

	var parseDiags diag.Diagnostics
	if errors.As(err, &parseDiags); parseDiags.HasErrors() {
		return parseDiags
	}

	var blocks []*ast.BlockStmt
	for _, stmt := range file.Body {
		switch stmt := stmt.(type) {
		case *ast.BlockStmt:
			blocks = append(blocks, stmt)
		default:
			diags = append(diags, diag.Diagnostic{
				Severity: diag.SeverityLevelError,
				Message:  "unexpected statement",
				StartPos: ast.StartPos(stmt).Position(),
				EndPos:   ast.EndPos(stmt).Position(),
			})
		}
	}
	if diags.HasErrors() {
		return diags
	}

	applyDiags := l.Apply(nil, blocks)
	diags = append(diags, applyDiags...)

	return diags
}

type graphDefinition struct {
	Nodes    []string
	OutEdges []edge
}

type edge struct{ From, To string }

func requireGraph(t *testing.T, g *dag.Graph, expect graphDefinition) {
	t.Helper()

	var (
		actualNodes []string
		actualEdges []edge
	)

	for _, n := range g.Nodes() {
		actualNodes = append(actualNodes, n.NodeID())
	}
	require.ElementsMatch(t, expect.Nodes, actualNodes, "List of nodes do not match")

	for _, e := range g.Edges() {
		actualEdges = append(actualEdges, edge{
			From: e.From.NodeID(),
			To:   e.To.NodeID(),
		})
	}
	require.ElementsMatch(t, expect.OutEdges, actualEdges, "List of edges do not match")
}

'''
'''--- pkg/flow/internal/controller/metrics.go ---
package controller

import "github.com/prometheus/client_golang/prometheus"

// controllerMetrics contains the metrics for components controller
type controllerMetrics struct {
	r prometheus.Registerer

	controllerEvaluation    prometheus.Gauge
	componentEvaluationTime prometheus.Histogram
}

// newControllerMetrics inits the metrics for the components controller
func newControllerMetrics(r prometheus.Registerer) *controllerMetrics {
	cm := controllerMetrics{r: r}

	cm.controllerEvaluation = prometheus.NewGauge(prometheus.GaugeOpts{
		Name: "agent_component_controller_evaluating",
		Help: "Tracks if the controller is currently in the middle of a graph evaluation",
	})

	cm.componentEvaluationTime = prometheus.NewHistogram(
		prometheus.HistogramOpts{
			Name: "agent_component_evaluation_seconds",
			Help: "Time spent performing component evaluation",
		},
	)

	if r != nil {
		r.MustRegister(
			cm.controllerEvaluation,
			cm.componentEvaluationTime,
		)
	}
	return &cm
}

type controllerCollector struct {
	l                      *Loader
	runningComponentsTotal *prometheus.Desc
}

func newControllerCollector(l *Loader) prometheus.Collector {
	return &controllerCollector{
		l: l,
		runningComponentsTotal: prometheus.NewDesc(
			"agent_component_controller_running_components_total",
			"Total number of running components.",
			[]string{"health_type"},
			nil,
		),
	}
}

func (cc *controllerCollector) Collect(ch chan<- prometheus.Metric) {
	componentsByHealth := make(map[string]int)

	for _, component := range cc.l.Components() {
		health := component.CurrentHealth().Health.String()
		componentsByHealth[health]++
		component.register.Collect(ch)
	}

	for health, count := range componentsByHealth {
		ch <- prometheus.MustNewConstMetric(cc.runningComponentsTotal, prometheus.GaugeValue, float64(count), health)
	}
}

func (cc *controllerCollector) Describe(ch chan<- *prometheus.Desc) {
	ch <- cc.runningComponentsTotal
}

'''
'''--- pkg/flow/internal/controller/queue.go ---
package controller

import "sync"

// Queue is an unordered queue of components.
//
// Queue is intended for tracking components that have updated their Exports
// for later reevaluation.
type Queue struct {
	mut    sync.Mutex
	queued map[*ComponentNode]struct{}

	updateCh chan struct{}
}

// NewQueue returns a new unordered component queue.
func NewQueue() *Queue {
	return &Queue{
		updateCh: make(chan struct{}, 1),
		queued:   make(map[*ComponentNode]struct{}),
	}
}

// Enqueue inserts a new component into the Queue. Enqueue is a no-op if the
// component is already in the Queue.
func (q *Queue) Enqueue(c *ComponentNode) {
	q.mut.Lock()
	defer q.mut.Unlock()
	q.queued[c] = struct{}{}
	select {
	case q.updateCh <- struct{}{}:
	default:
	}
}

// Chan returns a channel which is written to when the queue is non-empty.
func (q *Queue) Chan() <-chan struct{} { return q.updateCh }

// TryDequeue dequeues a randomly queued component. TryDequeue will return nil
// if the queue is empty.
func (q *Queue) TryDequeue() *ComponentNode {
	q.mut.Lock()
	defer q.mut.Unlock()

	for c := range q.queued {
		delete(q.queued, c)
		return c
	}

	return nil
}

'''
'''--- pkg/flow/internal/controller/queue_test.go ---
package controller

import (
	"testing"

	"github.com/stretchr/testify/require"
)

func TestEnqueueDequeue(t *testing.T) {
	tn := &ComponentNode{}
	q := NewQueue()
	q.Enqueue(tn)
	require.Lenf(t, q.queued, 1, "queue should be 1")
	fn := q.TryDequeue()
	require.True(t, fn == tn)
}

'''
'''--- pkg/flow/internal/controller/scheduler.go ---
package controller

import (
	"context"
	"fmt"
	"sync"
)

// RunnableNode is any dag.Node which can also be ran.
type RunnableNode interface {
	NodeID() string
	Run(ctx context.Context) error
}

// Scheduler runs components.
type Scheduler struct {
	ctx     context.Context
	cancel  context.CancelFunc
	running sync.WaitGroup

	tasksMut sync.Mutex
	tasks    map[string]*task
}

// NewScheduler creates a new Scheduler. Call Synchronize to manage the set of
// components which are running.
//
// Call Close to stop the Scheduler and all running components.
func NewScheduler() *Scheduler {
	ctx, cancel := context.WithCancel(context.Background())
	return &Scheduler{
		ctx:    ctx,
		cancel: cancel,

		tasks: make(map[string]*task),
	}
}

// Synchronize synchronizes the running components to those defined by rr.
//
// New RunnableNodes will be launched as new goroutines. RunnableNodes already
// managed by Scheduler will be kept running, while running RunnableNodes that
// are not in rr will be shut down and removed.
//
// Existing components will be restarted if they stopped since the previous
// call to Synchronize.
func (s *Scheduler) Synchronize(rr []RunnableNode) error {
	s.tasksMut.Lock()
	defer s.tasksMut.Unlock()

	if s.ctx.Err() != nil {
		return fmt.Errorf("Scheduler is closed")
	}

	newRunnables := make(map[string]RunnableNode, len(rr))
	for _, r := range rr {
		newRunnables[r.NodeID()] = r
	}

	// Stop tasks that are not defined in rr.
	var stopping sync.WaitGroup
	for id, t := range s.tasks {
		if _, keep := newRunnables[id]; keep {
			continue
		}

		stopping.Add(1)
		go func(t *task) {
			defer stopping.Done()
			t.Stop()
		}(t)
	}

	// Launch new runnables that have appeared.
	for id, r := range newRunnables {
		if _, exist := s.tasks[id]; exist {
			continue
		}

		var (
			nodeID      = id
			newRunnable = r
		)

		opts := taskOptions{
			Context:  s.ctx,
			Runnable: newRunnable,
			OnDone: func() {
				defer s.running.Done()

				s.tasksMut.Lock()
				defer s.tasksMut.Unlock()
				delete(s.tasks, nodeID)
			},
		}

		s.running.Add(1)
		s.tasks[nodeID] = newTask(opts)
	}

	// Wait for all stopping runnables to exit.
	stopping.Wait()
	return nil
}

// Close stops the Scheduler and returns after all running goroutines have
// exited.
func (s *Scheduler) Close() error {
	s.cancel()
	s.running.Wait()
	return nil
}

// task is a scheduled runnable.
type task struct {
	ctx    context.Context
	cancel context.CancelFunc
	exited chan struct{}
}

type taskOptions struct {
	Context  context.Context
	Runnable RunnableNode
	OnDone   func()
}

// newTask creates and starts a new task.
func newTask(opts taskOptions) *task {
	ctx, cancel := context.WithCancel(opts.Context)

	t := &task{
		ctx:    ctx,
		cancel: cancel,
		exited: make(chan struct{}),
	}

	go func() {
		defer opts.OnDone()
		defer close(t.exited)
		_ = opts.Runnable.Run(t.ctx)
	}()
	return t
}

func (t *task) Stop() {
	t.cancel()
	<-t.exited
}

'''
'''--- pkg/flow/internal/controller/scheduler_test.go ---
package controller_test

import (
	"context"
	"sync"
	"testing"

	"github.com/grafana/agent/component"
	"github.com/grafana/agent/pkg/flow/internal/controller"
	"github.com/stretchr/testify/require"
)

func TestScheduler_Synchronize(t *testing.T) {
	t.Run("Can start new jobs", func(t *testing.T) {
		var started, finished sync.WaitGroup
		started.Add(3)
		finished.Add(3)

		runFunc := func(ctx context.Context) error {
			defer finished.Done()
			started.Done()

			<-ctx.Done()
			return nil
		}

		sched := controller.NewScheduler()
		sched.Synchronize([]controller.RunnableNode{
			fakeRunnable{ID: "component-a", Component: mockComponent{RunFunc: runFunc}},
			fakeRunnable{ID: "component-b", Component: mockComponent{RunFunc: runFunc}},
			fakeRunnable{ID: "component-c", Component: mockComponent{RunFunc: runFunc}},
		})

		started.Wait()
		require.NoError(t, sched.Close())
		finished.Wait()
	})

	t.Run("Ignores existing jobs", func(t *testing.T) {
		var started sync.WaitGroup
		started.Add(1)

		runFunc := func(ctx context.Context) error {
			started.Done()
			<-ctx.Done()
			return nil
		}

		sched := controller.NewScheduler()

		for i := 0; i < 10; i++ {
			// If a new runnable is created, runFunc will panic since the WaitGroup
			// only supports 1 goroutine.
			sched.Synchronize([]controller.RunnableNode{
				fakeRunnable{ID: "component-a", Component: mockComponent{RunFunc: runFunc}},
			})
		}

		started.Wait()
		require.NoError(t, sched.Close())
	})

	t.Run("Removes stale jobs", func(t *testing.T) {
		var started, finished sync.WaitGroup
		started.Add(1)
		finished.Add(1)

		runFunc := func(ctx context.Context) error {
			defer finished.Done()
			started.Done()
			<-ctx.Done()
			return nil
		}

		sched := controller.NewScheduler()

		sched.Synchronize([]controller.RunnableNode{
			fakeRunnable{ID: "component-a", Component: mockComponent{RunFunc: runFunc}},
		})
		started.Wait()

		sched.Synchronize([]controller.RunnableNode{})

		finished.Wait()
		require.NoError(t, sched.Close())
	})
}

type fakeRunnable struct {
	ID        string
	Component component.Component
}

var _ controller.RunnableNode = fakeRunnable{}

func (fr fakeRunnable) NodeID() string                { return fr.ID }
func (fr fakeRunnable) Run(ctx context.Context) error { return fr.Component.Run(ctx) }

type mockComponent struct {
	RunFunc    func(ctx context.Context) error
	UpdateFunc func(newConfig component.Arguments) error
}

var _ component.Component = (*mockComponent)(nil)

func (mc mockComponent) Run(ctx context.Context) error              { return mc.RunFunc(ctx) }
func (mc mockComponent) Update(newConfig component.Arguments) error { return mc.UpdateFunc(newConfig) }

'''
'''--- pkg/flow/internal/controller/value_cache.go ---
package controller

import (
	"sync"

	"github.com/grafana/agent/component"
	"github.com/grafana/agent/pkg/river/vm"
)

// valueCache caches component arguments and exports to expose as variables for
// River expressions.
//
// The current state of valueCache can then be built into a *vm.Scope for other
// components to be evaluated.
type valueCache struct {
	mut        sync.RWMutex
	components map[string]ComponentID // NodeID -> ComponentID
	args       map[string]interface{} // NodeID -> component arguments value
	exports    map[string]interface{} // NodeID -> component exports value
}

// newValueCache cretes a new ValueCache.
func newValueCache() *valueCache {
	return &valueCache{
		components: make(map[string]ComponentID),
		args:       make(map[string]interface{}),
		exports:    make(map[string]interface{}),
	}
}

// CacheArguments will cache the provided arguments by the given id. args may
// be nil to store an empty object.
func (vc *valueCache) CacheArguments(id ComponentID, args component.Arguments) {
	vc.mut.Lock()
	defer vc.mut.Unlock()

	nodeID := id.String()
	vc.components[nodeID] = id

	var argsVal interface{} = make(map[string]interface{})
	if args != nil {
		argsVal = args
	}
	vc.args[nodeID] = argsVal
}

// CacheExports will cache the provided exports using the given id. exports may
// be nil to store an empty object.
func (vc *valueCache) CacheExports(id ComponentID, exports component.Exports) {
	vc.mut.Lock()
	defer vc.mut.Unlock()

	nodeID := id.String()
	vc.components[nodeID] = id

	var exportsVal interface{} = make(map[string]interface{})
	if exports != nil {
		exportsVal = exports
	}
	vc.exports[nodeID] = exportsVal
}

// SyncIDs will removed any cached values for any Component ID which is not in
// ids. SyncIDs should be called with the current set of components after the
// graph is updated.
func (vc *valueCache) SyncIDs(ids []ComponentID) {
	expectMap := make(map[string]ComponentID, len(ids))
	for _, id := range ids {
		expectMap[id.String()] = id
	}

	vc.mut.Lock()
	defer vc.mut.Unlock()

	for id := range vc.components {
		if _, keep := expectMap[id]; keep {
			continue
		}
		delete(vc.components, id)
		delete(vc.args, id)
		delete(vc.exports, id)
	}
}

// BuildContext builds a vm.Scope based on the current set of cached values.
// The arguments and exports for the same ID are merged into one object.
func (vc *valueCache) BuildContext(parent *vm.Scope) *vm.Scope {
	vc.mut.RLock()
	defer vc.mut.RUnlock()

	scope := &vm.Scope{
		Parent:    parent,
		Variables: make(map[string]interface{}),
	}

	// First, partition components by River block name.
	var componentsByBlockName = make(map[string][]ComponentID)
	for _, id := range vc.components {
		blockName := id[0]
		componentsByBlockName[blockName] = append(componentsByBlockName[blockName], id)
	}

	// Then, convert each partition into a single value.
	for blockName, ids := range componentsByBlockName {
		scope.Variables[blockName] = vc.buildValue(ids, 1)
	}

	return scope
}

// buildValue recursively converts the set of user components into a single
// value. offset is used to determine which element in the userComponentName
// we're looking at.
func (vc *valueCache) buildValue(from []ComponentID, offset int) interface{} {
	// We can't recurse anymore; return the node directly.
	if len(from) == 1 && offset >= len(from[0]) {
		name := from[0].String()

		// TODO(rfratto): should we allow arguments to be returned so users can
		// reference arguments as well as exports?
		exports, ok := vc.exports[name]
		if !ok {
			exports = make(map[string]interface{})
		}
		return exports
	}

	attrs := make(map[string]interface{})

	// First, partition the components by their label.
	var componentsByLabel = make(map[string][]ComponentID)
	for _, id := range from {
		blockName := id[offset]
		componentsByLabel[blockName] = append(componentsByLabel[blockName], id)
	}

	// Then, convert each partition into a single value.
	for label, ids := range componentsByLabel {
		attrs[label] = vc.buildValue(ids, offset+1)
	}
	return attrs
}

'''
'''--- pkg/flow/internal/controller/value_cache_test.go ---
package controller

import (
	"testing"

	"github.com/stretchr/testify/require"
)

func TestValueCache(t *testing.T) {
	vc := newValueCache()

	type fooArgs struct {
		Something bool `river:"something,attr"`
	}
	type fooExports struct {
		SomethingElse bool `river:"something_else,attr"`
	}

	type barArgs struct {
		Number int `river:"number,attr"`
	}

	// Emulate values from the following River file:
	//
	//     foo {
	//       something = true
	//
	//       // Exported fields:
	//       // something_else = true
	//     }
	//
	//     bar "label_a" {
	//       number = 12
	//     }
	//
	//     bar "label_b" {
	//       number = 34
	//     }
	//
	// and expects to generate the equivalent to the following River object:
	//
	//     {
	//      	foo = {
	//      		something_else = true,
	//      	},
	//
	//      	bar = {
	//      		label_a = {},
	//      		label_b = {},
	//      	}
	//     }
	//
	// For now, only exports are placed in generated objects, which is why the
	// bar values are empty and the foo object only contains the exports.

	vc.CacheArguments(ComponentID{"foo"}, fooArgs{Something: true})
	vc.CacheExports(ComponentID{"foo"}, fooExports{SomethingElse: true})
	vc.CacheArguments(ComponentID{"bar", "label_a"}, barArgs{Number: 12})
	vc.CacheArguments(ComponentID{"bar", "label_b"}, barArgs{Number: 34})

	res := vc.BuildContext(nil)

	var (
		expectKeys = []string{"foo", "bar"}
		actualKeys []string
	)
	for varName := range res.Variables {
		actualKeys = append(actualKeys, varName)
	}
	require.ElementsMatch(t, expectKeys, actualKeys)

	type object = map[string]interface{}

	expectFoo := fooExports{SomethingElse: true}
	expectBar := object{
		"label_a": object{}, // no exports for bar
		"label_b": object{}, // no exports for bar
	}
	require.Equal(t, expectFoo, res.Variables["foo"])
	require.Equal(t, expectBar, res.Variables["bar"])
}

'''
'''--- pkg/flow/internal/controller/wrap_registerer.go ---
package controller

import (
	"sync"

	"github.com/prometheus/client_golang/prometheus"
)

type wrappedRegisterer struct {
	mut                sync.RWMutex
	internalCollectors map[prometheus.Collector]struct{}
}

// newWrappedRegisterer creates a wrapped register
func newWrappedRegisterer() *wrappedRegisterer {
	return &wrappedRegisterer{internalCollectors: make(map[prometheus.Collector]struct{})}
}

// Describe implements the interface
func (w *wrappedRegisterer) Describe(descs chan<- *prometheus.Desc) {
	w.mut.RLock()
	defer w.mut.RUnlock()

	for c := range w.internalCollectors {
		c.Describe(descs)
	}
}

// Collect implements the interface
func (w *wrappedRegisterer) Collect(metrics chan<- prometheus.Metric) {
	w.mut.RLock()
	defer w.mut.RUnlock()

	for c := range w.internalCollectors {
		c.Collect(metrics)
	}
}

// Register implements the interface
func (w *wrappedRegisterer) Register(collector prometheus.Collector) error {
	w.mut.Lock()
	defer w.mut.Unlock()

	w.internalCollectors[collector] = struct{}{}
	return nil
}

// MustRegister implements the interface
func (w *wrappedRegisterer) MustRegister(collector ...prometheus.Collector) {
	w.mut.Lock()
	defer w.mut.Unlock()

	for _, c := range collector {
		w.internalCollectors[c] = struct{}{}
	}
}

// Unregister implements the interface
func (w *wrappedRegisterer) Unregister(collector prometheus.Collector) bool {
	w.mut.Lock()
	defer w.mut.Unlock()

	delete(w.internalCollectors, collector)
	return true
}

'''
'''--- pkg/flow/internal/dag/dag.go ---
// Package dag defines a Directed Acyclic Graph.
package dag

import "fmt"

// Node is an individual Vertex in the DAG.
type Node interface {
	// NodeID returns the display name of the Node.
	NodeID() string
}

// Edge is a directed connection between two Nodes.
type Edge struct{ From, To Node }

// Graph is a Directed Acyclic Graph. The zero value is ready for use. Graph
// cannot be modified concurrently.
type Graph struct {
	nodeByID map[string]Node
	nodes    nodeSet
	outEdges map[Node]nodeSet // Outgoing edges for a given Node
	inEdges  map[Node]nodeSet // Incoming edges for a given Node
}

type nodeSet map[Node]struct{}

// Add adds n into ns if it doesn't already exist.
func (ns nodeSet) Add(n Node) { ns[n] = struct{}{} }

// Remove removes n from ns if it exists.
func (ns nodeSet) Remove(n Node) { delete(ns, n) }

// Has returns true if ns includes n.
func (ns nodeSet) Has(n Node) bool {
	_, ok := ns[n]
	return ok
}

// Clone returns a copy of ns.
func (ns nodeSet) Clone() nodeSet {
	newSet := make(nodeSet, len(ns))
	for node := range ns {
		newSet[node] = struct{}{}
	}
	return newSet
}

// init prepares g for writing.
func (g *Graph) init() {
	if g.nodeByID == nil {
		g.nodeByID = make(map[string]Node)
	}
	if g.nodes == nil {
		g.nodes = make(nodeSet)
	}
	if g.outEdges == nil {
		g.outEdges = make(map[Node]nodeSet)
	}
	if g.inEdges == nil {
		g.inEdges = make(map[Node]nodeSet)
	}
}

// Add adds a new Node into g. Add is a no-op if n already exists in g.
//
// Add will panic if there is another node in g with the same NodeID as n.
func (g *Graph) Add(n Node) {
	g.init()

	if other, ok := g.nodeByID[n.NodeID()]; ok && other != n {
		panic(fmt.Sprintf("Graph.Add: Node ID %q is already in use by another Node", n.NodeID()))
	}
	g.nodes.Add(n)
	g.nodeByID[n.NodeID()] = n
}

// GetByID returns a node from an ID. Returns nil if the ID does not exist in
// the graph.
func (g *Graph) GetByID(id string) Node { return g.nodeByID[id] }

// Remove removes a Node from g. Remove is a no-op if n does not exist in g.
//
// Remove also removes any edge to or from n.
func (g *Graph) Remove(n Node) {
	if !g.nodes.Has(n) {
		return
	}

	delete(g.nodeByID, n.NodeID())
	g.nodes.Remove(n)

	// Remove all the outgoing edges from n.
	delete(g.outEdges, n)

	// Remove n from any edge where it is the target.
	for _, ns := range g.inEdges {
		ns.Remove(n)
	}
}

// AddEdge adds a new Edge into g. AddEdge does not prevent cycles from being
// introduced; cycles must be detected separately.
//
// AddEdge will panic if either node in the edge doesn't exist in g.
func (g *Graph) AddEdge(e Edge) {
	g.init()

	if !g.nodes.Has(e.From) || !g.nodes.Has(e.To) {
		panic("AddEdge called with a node that doesn't exist in graph")
	}

	inSet, ok := g.inEdges[e.To]
	if !ok {
		inSet = make(nodeSet)
		g.inEdges[e.To] = inSet
	}
	inSet.Add(e.From)

	outSet, ok := g.outEdges[e.From]
	if !ok {
		outSet = make(nodeSet)
		g.outEdges[e.From] = outSet
	}
	outSet.Add(e.To)
}

// RemoveEdge removes an edge e from g. RemoveEdge is a no-op if e doesn't
// exist in g.
func (g *Graph) RemoveEdge(e Edge) {
	inSet, ok := g.inEdges[e.To]
	if ok {
		delete(inSet, e.From)
	}

	outSet, ok := g.outEdges[e.From]
	if ok {
		delete(outSet, e.To)
	}
}

// Nodes returns the set of Nodes in g.
func (g *Graph) Nodes() []Node {
	nodes := make([]Node, 0, len(g.nodes))
	for n := range g.nodes {
		nodes = append(nodes, n)
	}
	return nodes
}

// Edges returns the set of all edges in g.
func (g *Graph) Edges() []Edge {
	var edges []Edge
	for from, tos := range g.outEdges {
		for to := range tos {
			edges = append(edges, Edge{From: from, To: to})
		}
	}
	return edges
}

// Dependants returns the list of Nodes that depend on n: all Nodes for which
// an edge to n is defined.
func (g *Graph) Dependants(n Node) []Node {
	sourceDependants := g.inEdges[n]
	dependants := make([]Node, 0, len(sourceDependants))
	for dep := range sourceDependants {
		dependants = append(dependants, dep)
	}
	return dependants
}

// Dependencies returns the list of Nodes that n depends on: all Nodes for
// which an edge from n is defined.
func (g *Graph) Dependencies(n Node) []Node {
	sourceDependencies := g.outEdges[n]
	dependencies := make([]Node, 0, len(sourceDependencies))
	for dep := range sourceDependencies {
		dependencies = append(dependencies, dep)
	}
	return dependencies
}

// Roots returns the set of Nodes in g that have no dependants. This is useful
// for walking g.
func (g *Graph) Roots() []Node {
	var res []Node

	for n := range g.nodes {
		if len(g.inEdges[n]) == 0 {
			res = append(res, n)
		}
	}

	return res
}

// Leaves returns the set of Nodes in g that have no dependencies. This is
// useful for walking g in reverse.
func (g *Graph) Leaves() []Node {
	var res []Node

	for n := range g.nodes {
		if len(g.outEdges[n]) == 0 {
			res = append(res, n)
		}
	}

	return res
}

// Clone returns a copy of g.
func (g *Graph) Clone() *Graph {
	newGraph := &Graph{
		nodes: g.nodes.Clone(),

		nodeByID: make(map[string]Node, len(g.nodeByID)),
		outEdges: make(map[Node]nodeSet, len(g.outEdges)),
		inEdges:  make(map[Node]nodeSet, len(g.outEdges)),
	}

	for key, value := range g.nodeByID {
		newGraph.nodeByID[key] = value
	}
	for node, set := range g.outEdges {
		newGraph.outEdges[node] = set.Clone()
	}
	for node, set := range g.inEdges {
		newGraph.inEdges[node] = set.Clone()
	}

	return newGraph
}

'''
'''--- pkg/flow/internal/dag/marshal.go ---
package dag

import (
	"bytes"
	"fmt"
	"sort"
)

// MarshalDOT marshals g into the Graphviz DOT format.
func MarshalDOT(g *Graph) []byte {
	var buf bytes.Buffer

	fmt.Fprintln(&buf, "digraph {")
	fmt.Fprintf(&buf, "\trankdir=%q\n", "LR")

	fmt.Fprintf(&buf, "\n\t// Vertices:\n")
	for _, n := range sortedNodeNames(g.Nodes()) {
		fmt.Fprintf(&buf, "\t%q\n", n)
	}

	fmt.Fprintf(&buf, "\n\t// Edges:\n")
	for _, edge := range sortedEdges(g.Edges()) {
		fmt.Fprintf(&buf, "\t%q -> %q\n", edge.From.NodeID(), edge.To.NodeID())
	}

	fmt.Fprintf(&buf, "}")
	return buf.Bytes()
}

func sortedNodeNames(nn []Node) []string {
	names := make([]string, len(nn))
	for i, n := range nn {
		names[i] = n.NodeID()
	}
	sort.Strings(names)
	return names
}

func sortedEdges(edge []Edge) []Edge {
	res := make([]Edge, len(edge))
	copy(res, edge)

	sort.Slice(res, func(i, j int) bool {
		var (
			fromNodeI = res[i].From.NodeID()
			fromNodeJ = res[j].From.NodeID()

			toNodeI = res[i].To.NodeID()
			toNodeJ = res[j].To.NodeID()
		)

		// Sort first by from nodes, then by to nodes
		if fromNodeI != fromNodeJ {
			return fromNodeI < fromNodeJ
		}
		return toNodeI < toNodeJ
	})

	return res
}

'''
'''--- pkg/flow/internal/dag/marshal_test.go ---
package dag_test

import (
	"testing"

	"github.com/grafana/agent/pkg/flow/internal/dag"
	"github.com/stretchr/testify/require"
)

func TestMarshalDOT(t *testing.T) {
	var (
		nodeA = stringNode("a")
		nodeB = stringNode("b")
		nodeC = stringNode("c")
	)

	var g dag.Graph
	g.Add(nodeA)
	g.Add(nodeB)
	g.Add(nodeC)

	g.AddEdge(dag.Edge{From: nodeA, To: nodeB})
	g.AddEdge(dag.Edge{From: nodeA, To: nodeC})

	expect := `digraph {
	rankdir="LR"

	// Vertices:
	"a"
	"b"
	"c"

	// Edges:
	"a" -> "b"
	"a" -> "c"
}`

	marshaled := dag.MarshalDOT(&g)
	require.Equal(t, expect, string(marshaled))
}

type stringNode string

func (s stringNode) NodeID() string { return string(s) }

'''
'''--- pkg/flow/internal/dag/ops.go ---
package dag

import (
	"fmt"
	"strings"

	"github.com/hashicorp/go-multierror"
)

// Reduce performs a transitive reduction on g. A transitive reduction removes
// as many edges as possible while maintaining the same "reachability" as the
// original graph: any node N reachable from node S will still be reachable
// after a reduction.
func Reduce(g *Graph) {
	// A direct edge between two vertices can be removed if that same target
	// vertex is indirectly reachable through another edge.
	//
	// To detect this, we iterate through all vertices in the graph, performing a
	// depth-first search at its dependencies. If the target vertex is reachable
	// from the source vertex, the edge is removed.
	for source := range g.nodes {
		_ = Walk(g, g.Dependencies(source), func(direct Node) error {
			// Iterate over (direct, indirect) edges and remove (source, indirect)
			// edges if they exist. This is a safe operation because other is still
			// reachable by source via its (source, direct) edge.
			for indirect := range g.outEdges[direct] {
				g.RemoveEdge(Edge{From: source, To: indirect})
			}
			return nil
		})
	}
}

// Validate checks that the graph doesn't contain cycles
func Validate(g *Graph) error {
	var err error

	// Check cycles using strongly connected components algorithm
	for _, cycle := range StronglyConnectedComponents(g) {
		if len(cycle) > 1 {
			cycleStr := make([]string, len(cycle))
			for i, node := range cycle {
				cycleStr[i] = node.NodeID()
			}
			err = multierror.Append(err, fmt.Errorf("cycle: %s", strings.Join(cycleStr, ", ")))
		}
	}

	// Check self references
	for _, e := range g.Edges() {
		if e.From == e.To {
			err = multierror.Append(err, fmt.Errorf("self reference: %s", e.From.NodeID()))
		}
	}

	return err
}

'''
'''--- pkg/flow/internal/dag/ops_test.go ---
package dag

import "testing"

func TestValidateWithoutCycle(t *testing.T) {
	var g Graph
	var (
		nodeA = stringNode("a")
		nodeB = stringNode("b")
		nodeC = stringNode("c")
	)
	g.Add(nodeA)
	g.Add(nodeB)
	g.Add(nodeC)
	g.AddEdge(Edge{nodeC, nodeA})
	g.AddEdge(Edge{nodeC, nodeB})

	if err := Validate(&g); err != nil {
		t.Fatalf("non errors expected, got: %s", err)
	}
}

func TestValidateWithCycle(t *testing.T) {
	var g Graph
	var (
		nodeA = stringNode("a")
		nodeB = stringNode("b")
		nodeC = stringNode("c")
	)
	g.Add(nodeA)
	g.Add(nodeB)
	g.Add(nodeC)
	g.AddEdge(Edge{nodeC, nodeB})
	g.AddEdge(Edge{nodeC, nodeA})
	g.AddEdge(Edge{nodeA, nodeB})
	g.AddEdge(Edge{nodeB, nodeA})

	if err := Validate(&g); err == nil {
		t.Fatal("graph with cycles")
	}
}

func TestValidateSelfReference(t *testing.T) {
	var g Graph
	var (
		nodeA = stringNode("a")
	)
	g.Add(nodeA)
	g.AddEdge(Edge{nodeA, nodeA})

	if err := Validate(&g); err == nil {
		t.Fatal("graph with self reference")
	}
}

'''
'''--- pkg/flow/internal/dag/tarjan.go ---
package dag

// StronglyConnectedComponents returns the list of strongly connected components
// of the graph using Tarjan algorithm.
func StronglyConnectedComponents(g *Graph) [][]Node {
	nodes := g.Nodes()
	t := tarjan{
		nodes:   make(map[Node]int, len(nodes)),
		lowLink: make(map[Node]int, len(nodes)),
	}

	for _, n := range g.Nodes() {
		// Calculate strong connect components for non-visited nodes
		if t.nodes[n] == 0 {
			t.tarjan(g, n)
		}
	}
	return t.result
}

// tarjan represents Tarjan algorithm to find
// strongly connected component finding.
//
// https://en.wikipedia.org/wiki/Tarjan%27s_strongly_connected_components_algorithm
type tarjan struct {
	index   int
	nodes   map[Node]int
	lowLink map[Node]int
	stack   []Node

	result [][]Node
}

func (t *tarjan) tarjan(g *Graph, n Node) {
	t.visit(n)
	for succ := range g.outEdges[n] {
		if t.nodes[succ] == 0 {
			// Successor not visited, recurse on it
			t.tarjan(g, succ)
			t.lowLink[n] = min(t.lowLink[n], t.lowLink[succ])
		} else if t.onStack(succ) {
			// Successor is in stack and hence in the current SCC
			t.lowLink[n] = min(t.lowLink[n], t.nodes[succ])
		}
	}

	// If n is a root node, pop the stack and generate an SCC
	if t.lowLink[n] == t.nodes[n] {
		// Start a new strongly connected component
		var scc []Node
		for {
			succ := t.pop()
			// Add w to current strongly connected component.
			scc = append(scc, succ)
			if succ == n {
				break
			}
		}
		// Add current strongly connected component to result
		t.result = append(t.result, scc)
	}
}

// visit marks node as visited and pushes to the stack
func (t *tarjan) visit(n Node) {
	t.index++
	t.nodes[n] = t.index
	t.lowLink[n] = t.index
	t.push(n)
}

func min(a, b int) int {
	if a <= b {
		return a
	}
	return b
}

// push adds a node to the stack
func (t *tarjan) push(n Node) {
	t.stack = append(t.stack, n)
}

// pop removes a node from the stack
func (t *tarjan) pop() Node {
	n := len(t.stack)
	if n == 0 {
		return nil
	}
	node := t.stack[n-1]
	t.stack = t.stack[:n-1]
	return node
}

// onStack checks if node is in stack
func (t *tarjan) onStack(n Node) bool {
	for _, e := range t.stack {
		if n == e {
			return true
		}
	}
	return false
}

'''
'''--- pkg/flow/internal/dag/tarjan_test.go ---
package dag

import (
	"reflect"
	"sort"
	"testing"
)

func TestGraphStronglyConnected(t *testing.T) {
	var g Graph
	var (
		nodeA = stringNode("a")
		nodeB = stringNode("b")
	)
	g.Add(nodeA)
	g.Add(nodeB)
	g.AddEdge(Edge{nodeA, nodeB})
	g.AddEdge(Edge{nodeB, nodeA})

	actual := sortSlice(StronglyConnectedComponents(&g))
	expected := [][]Node{{nodeA, nodeB}}
	if !reflect.DeepEqual(actual, expected) {
		t.Fatalf("error calculating strongly connected components: expected %s, got %s", expected, actual)
	}
}

func TestGraphNotStronglyConnected(t *testing.T) {
	var g Graph
	var (
		nodeA = stringNode("a")
		nodeB = stringNode("b")
	)
	g.Add(nodeA)
	g.Add(nodeB)
	g.AddEdge(Edge{nodeA, nodeB})

	actual := sortSlice(StronglyConnectedComponents(&g))
	expected := [][]Node{{nodeA}, {nodeB}}
	if !reflect.DeepEqual(actual, expected) {
		t.Fatalf("error calculating strongly connected components: expected %s, got %s", expected, actual)
	}
}

func TestGraphStronglyConnectedMulti(t *testing.T) {
	var g Graph
	var (
		nodeA = stringNode("a")
		nodeB = stringNode("b")
		nodeC = stringNode("c")
		nodeD = stringNode("d")
		nodeE = stringNode("e")
	)
	g.Add(nodeA)
	g.Add(nodeB)
	g.AddEdge(Edge{nodeA, nodeB})
	g.AddEdge(Edge{nodeB, nodeA})
	g.Add(nodeC)
	g.Add(nodeD)
	g.Add(nodeE)
	g.AddEdge(Edge{nodeC, nodeD})
	g.AddEdge(Edge{nodeD, nodeE})
	g.AddEdge(Edge{nodeE, nodeC})

	actual := sortSlice(StronglyConnectedComponents(&g))
	expected := [][]Node{{nodeA, nodeB}, {nodeC, nodeD, nodeE}}
	if !reflect.DeepEqual(actual, expected) {
		t.Fatalf("error calculating strongly connected components: expected %s, got %s", expected, actual)
	}
}

func sortSlice(nodeSets [][]Node) [][]Node {
	var sorted [][]Node

	// Sort nodes of the detected cycle by id
	for _, ns := range nodeSets {
		sort.Slice(ns, func(i, j int) bool {
			return ns[i].NodeID() < ns[j].NodeID()
		})
		sorted = append(sorted, ns)
	}
	// Sort the final slice by the first element of the cycle
	sort.Slice(sorted, func(i, j int) bool {
		return sorted[i][0].NodeID() < sorted[j][0].NodeID()
	})
	return sorted
}

type stringNode string

func (s stringNode) NodeID() string { return string(s) }

'''
'''--- pkg/flow/internal/dag/walk.go ---
package dag

// WalkFunc is a function that gets invoked when walking a Graph. Walking will
// stop if WalkFunc returns a non-nil error.
type WalkFunc func(n Node) error

// Walk performs a depth-first walk of outgoing edges for all nodes in start,
// invoking the provided fn for each node. Walk returns the error returned by
// fn.
//
// Nodes unreachable from start will not be passed to fn.
func Walk(g *Graph, start []Node, fn WalkFunc) error {
	var (
		visited   = make(nodeSet)
		unchecked = make([]Node, 0, len(start))
	)

	// Prefill the set of unchecked nodes with our start set.
	unchecked = append(unchecked, start...)

	// Iterate through unchecked nodes, visiting each in turn and adding outgoing
	// edges to the unchecked list until all reachable nodes have been processed.
	for len(unchecked) > 0 {
		check := unchecked[len(unchecked)-1]
		unchecked = unchecked[:len(unchecked)-1]

		if visited.Has(check) {
			continue
		}
		visited.Add(check)

		if err := fn(check); err != nil {
			return err
		}

		for n := range g.outEdges[check] {
			unchecked = append(unchecked, n)
		}
	}

	return nil
}

// WalkReverse performs a depth-first walk of incoming edges for all nodes in
// start, invoking the provided fn for each node. Walk returns the error
// returned by fn.
//
// Nodes unreachable from start will not be passed to fn.
func WalkReverse(g *Graph, start []Node, fn WalkFunc) error {
	var (
		visited   = make(nodeSet)
		unchecked = make([]Node, 0, len(start))
	)

	// Prefill the set of unchecked nodes with our start set.
	unchecked = append(unchecked, start...)

	// Iterate through unchecked nodes, visiting each in turn and adding incoming
	// edges to the unchecked list until all reachable nodes have been processed.
	for len(unchecked) > 0 {
		check := unchecked[len(unchecked)-1]
		unchecked = unchecked[:len(unchecked)-1]

		if visited.Has(check) {
			continue
		}
		visited.Add(check)

		if err := fn(check); err != nil {
			return err
		}

		for n := range g.inEdges[check] {
			unchecked = append(unchecked, n)
		}
	}

	return nil
}

// WalkTopological performs a topological walk of all nodes in start in
// dependency order: a node will not be visited until its outgoing edges are
// visited first.
//
// Nodes will not be passed to fn if they are not reachable from start or if
// not all of their outgoing edges are reachable from start.
func WalkTopological(g *Graph, start []Node, fn WalkFunc) error {
	// NOTE(rfratto): WalkTopological is an implementation of Kahn's algorithm
	// which leaves g unmodified.

	var (
		visited   = make(nodeSet)
		unchecked = make([]Node, 0, len(start))

		remainingDeps = make(map[Node]int)
	)

	// Pre-fill the set of nodes to check from the start list.
	unchecked = append(unchecked, start...)

	for len(unchecked) > 0 {
		check := unchecked[len(unchecked)-1]
		unchecked = unchecked[:len(unchecked)-1]

		if visited.Has(check) {
			continue
		}
		visited.Add(check)

		if err := fn(check); err != nil {
			return err
		}

		// Iterate through the incoming edges to check and queue nodes if we're the
		// last edge to be walked.
		for n := range g.inEdges[check] {
			// remainingDeps starts with the number of edges, and we subtract one for
			// each outgoing edge that's visited.
			if _, ok := remainingDeps[n]; !ok {
				remainingDeps[n] = len(g.outEdges[n])
			}
			remainingDeps[n]--

			// Only enqueue the incoming edge once all of its outgoing edges have
			// been consumed. This prevents it from being visited before its
			// dependencies.
			if remainingDeps[n] == 0 {
				unchecked = append(unchecked, n)
			}
		}
	}

	return nil
}

'''
'''--- pkg/flow/internal/graphviz/graphviz.go ---
// Package graphviz implements some graphviz utilities. Graphviz must be
// installed for these to work.
package graphviz

import (
	"bytes"
	"fmt"
	"os/exec"
)

// NotFoundError is generated when a Graphviz tool could not be found.
type NotFoundError struct {
	ToolName string
}

func (e NotFoundError) Error() string {
	return fmt.Sprintf("Failed to execute %s. Is Graphviz installed?", e.ToolName)
}

// Dot renders the DOT-language input with the provided format.
func Dot(in []byte, format string) ([]byte, error) {
	dotPath, err := exec.LookPath("dot")
	if err != nil {
		return nil, NotFoundError{ToolName: "dot"}
	}

	cmd := exec.Command(dotPath, "-T"+format)
	cmd.Stdin = bytes.NewReader(in)
	return cmd.Output()
}

'''
'''--- pkg/flow/internal/graphviz/grpahviz_test.go ---
package graphviz_test

import (
	"os/exec"
	"testing"

	"github.com/grafana/agent/pkg/flow/internal/graphviz"
	"github.com/stretchr/testify/require"
)

func TestGraphviz(t *testing.T) {
	_, err := exec.LookPath("dot")
	if err != nil {
		t.Skip("Skipping because graphviz is not installed")
	}

	testDot := `
		digraph G {
			a -> b 
			a -> c
		}
	`

	resp, err := graphviz.Dot([]byte(testDot), "dot")
	require.NoError(t, err)

	// We don't test the entire output of dot since it will do a lot of mutations
	// on even a simple graph (setting positions, sizes, etc.). However, we at least
	// make sure that it contains something we've expected, like the name of the
	// graph itself.
	require.Contains(t, string(resp), "digraph G")
}

'''
'''--- pkg/flow/internal/testcomponents/doc.go ---
// Package testcomponents contains components useful for testing. They are not
// intended to be exposed by end users and so this package should only be
// imported in tests.
package testcomponents

'''
'''--- pkg/flow/internal/testcomponents/passthrough.go ---
package testcomponents

import (
	"context"

	"github.com/go-kit/log"
	"github.com/go-kit/log/level"
	"github.com/grafana/agent/component"
)

func init() {
	component.Register(component.Registration{
		Name:    "testcomponents.passthrough",
		Args:    PassthroughConfig{},
		Exports: PassthroughExports{},

		Build: func(opts component.Options, args component.Arguments) (component.Component, error) {
			return NewPassthrough(opts, args.(PassthroughConfig))
		},
	})
}

// PassthroughConfig configures the testcomponents.passthrough component.
type PassthroughConfig struct {
	Input string `river:"input,attr"`
}

// PassthroughExports describes exported fields for the
// testcomponents.passthrough component.
type PassthroughExports struct {
	Output string `river:"output,attr,optional"`
}

// Passthrough implements the testcomponents.passthrough component, where it
// always emits its input as an output.
type Passthrough struct {
	opts component.Options
	log  log.Logger
}

// NewPassthrough creates a new passthrough component.
func NewPassthrough(o component.Options, cfg PassthroughConfig) (*Passthrough, error) {
	t := &Passthrough{opts: o, log: o.Logger}
	if err := t.Update(cfg); err != nil {
		return nil, err
	}
	return t, nil
}

var (
	_ component.Component      = (*Passthrough)(nil)
	_ component.DebugComponent = (*Passthrough)(nil)
)

// Run implements Component.
func (t *Passthrough) Run(ctx context.Context) error {
	<-ctx.Done()
	return nil
}

// Update implements Component.
func (t *Passthrough) Update(args component.Arguments) error {
	c := args.(PassthroughConfig)

	level.Info(t.log).Log("msg", "passing through value", "value", c.Input)
	t.opts.OnStateChange(PassthroughExports{Output: c.Input})
	return nil
}

// DebugInfo implements DebugComponent.
func (t *Passthrough) DebugInfo() interface{} {
	// Useless, but for demonstration purposes shows how to export debug
	// information. Real components would want to use something interesting here
	// which allow the user to investigate issues of the internal state of a
	// component.
	return passthroughDebugInfo{
		ComponentVersion: "v0.1-beta.0",
	}
}

type passthroughDebugInfo struct {
	ComponentVersion string `river:"component_version,attr"`
}

'''
'''--- pkg/flow/internal/testcomponents/tick.go ---
package testcomponents

import (
	"context"
	"fmt"
	"sync"
	"time"

	"github.com/go-kit/log"
	"github.com/go-kit/log/level"
	"github.com/grafana/agent/component"
)

func init() {
	component.Register(component.Registration{
		Name:    "testcomponents.tick",
		Args:    TickConfig{},
		Exports: TickExports{},

		Build: func(opts component.Options, args component.Arguments) (component.Component, error) {
			return NewTick(opts, args.(TickConfig))
		},
	})
}

// TickConfig configures the testcomponents.tick component.
type TickConfig struct {
	Frequency time.Duration `river:"frequency,attr"`
}

// TickExports describes exported fields for the testcomponents.tick component.
type TickExports struct {
	Time time.Time `river:"tick_time,attr,optional"`
}

// Tick implements the testcomponents.tick component, where the wallclock time
// will be emitted on a given frequency.
type Tick struct {
	opts component.Options
	log  log.Logger

	cfgMut sync.Mutex
	cfg    TickConfig
}

// NewTick creates a new testcomponents.tick component.
func NewTick(o component.Options, cfg TickConfig) (*Tick, error) {
	t := &Tick{opts: o, log: o.Logger}
	if err := t.Update(cfg); err != nil {
		return nil, err
	}
	return t, nil
}

var (
	_ component.Component = (*Tick)(nil)
)

// Run implements Component.
func (t *Tick) Run(ctx context.Context) error {
	for {
		select {
		case <-ctx.Done():
			return nil
		case <-time.After(t.getNextTick()):
			level.Info(t.log).Log("msg", "ticked")
			t.opts.OnStateChange(TickExports{Time: time.Now()})
		}
	}
}

func (t *Tick) getNextTick() time.Duration {
	t.cfgMut.Lock()
	defer t.cfgMut.Unlock()
	return t.cfg.Frequency
}

// Update implements Component.
func (t *Tick) Update(args component.Arguments) error {
	t.cfgMut.Lock()
	defer t.cfgMut.Unlock()

	cfg := args.(TickConfig)
	if cfg.Frequency == 0 {
		return fmt.Errorf("frequency must not be 0")
	}

	level.Info(t.log).Log("msg", "setting tick frequency", "freq", cfg.Frequency)
	t.cfg = cfg
	return nil
}

'''
'''--- pkg/flow/logging/config.go ---
package logging

import (
	"encoding"
	"fmt"

	"github.com/go-kit/log/level"
	"github.com/grafana/agent/pkg/river"
)

// Options is a set of options used to construct and configure a Logger.
type Options struct {
	Level  Level  `river:"level,attr,optional"`
	Format Format `river:"format,attr,optional"`

	// TODO: log sink parameter (e.g., to use the Windows Event logger)
}

// DefaultOptions holds defaults for creating a Logger.
var DefaultOptions = Options{
	Level:  LevelDefault,
	Format: FormatDefault,
}

var _ river.Unmarshaler = (*Options)(nil)

// UnmarshalRiver implements river.Unmarshaler.
func (o *Options) UnmarshalRiver(f func(interface{}) error) error {
	*o = DefaultOptions

	type options Options
	return f((*options)(o))
}

// Level represents how verbose logging should be.
type Level string

// Supported log levels
const (
	LevelDebug Level = "debug"
	LevelInfo  Level = "info"
	LevelWarn  Level = "warn"
	LevelError Level = "error"

	LevelDefault = LevelInfo
)

var (
	_ encoding.TextMarshaler   = LevelDefault
	_ encoding.TextUnmarshaler = (*Level)(nil)
)

// MarshalText implements encoding.TextMarshaler.
func (ll Level) MarshalText() (text []byte, err error) {
	return []byte(ll), nil
}

// UnmarshalText implements encoding.TextUnmarshaler.
func (ll *Level) UnmarshalText(text []byte) error {
	switch Level(text) {
	case "":
		*ll = LevelDefault
	case LevelDebug, LevelInfo, LevelWarn, LevelError:
		*ll = Level(text)
	default:
		return fmt.Errorf("unrecognized log level %q", string(text))
	}
	return nil
}

// Filter returns a go-kit logging filter from the level.
func (ll Level) Filter() level.Option {
	switch ll {
	case LevelDebug:
		return level.AllowDebug()
	case LevelInfo:
		return level.AllowInfo()
	case LevelWarn:
		return level.AllowWarn()
	case LevelError:
		return level.AllowError()
	default:
		return level.AllowAll()
	}
}

// Format represents a text format to use when writing logs.
type Format string

// Supported log formats.
const (
	FormatLogfmt Format = "logfmt"
	FormatJSON   Format = "json"

	FormatDefault = FormatLogfmt
)

var (
	_ encoding.TextMarshaler   = FormatDefault
	_ encoding.TextUnmarshaler = (*Format)(nil)
)

// MarshalText implements encoding.TextMarshaler.
func (ll Format) MarshalText() (text []byte, err error) {
	return []byte(ll), nil
}

// UnmarshalText implements encoding.TextUnmarshaler.
func (ll *Format) UnmarshalText(text []byte) error {
	switch Format(text) {
	case "":
		*ll = FormatDefault
	case FormatLogfmt, FormatJSON:
		*ll = Format(text)
	default:
		return fmt.Errorf("unrecognized log format %q", string(text))
	}
	return nil
}

'''
'''--- pkg/flow/logging/logger.go ---
package logging

import (
	"fmt"
	"io"
	"sync"

	"github.com/go-kit/log"
	"github.com/go-kit/log/level"
)

// Logger implements the github.com/go-kit/log.Logger interface. It supports
// being dynamically updated at runtime.
type Logger struct {
	w io.Writer

	mut sync.RWMutex
	l   log.Logger
}

// New creates a New logger with the default log level and format.
func New(w io.Writer, o Options) (*Logger, error) {
	inner, err := buildLogger(w, o)
	if err != nil {
		return nil, err
	}

	return &Logger{w: w, l: inner}, nil
}

// Log implements log.Logger.
func (l *Logger) Log(kvps ...interface{}) error {
	l.mut.RLock()
	defer l.mut.RUnlock()
	return l.l.Log(kvps...)
}

// Update re-configures the options used for the logger.
func (l *Logger) Update(o Options) error {
	newLogger, err := buildLogger(l.w, o)
	if err != nil {
		return err
	}

	l.mut.Lock()
	defer l.mut.Unlock()
	l.l = newLogger
	return nil
}

func buildLogger(w io.Writer, o Options) (log.Logger, error) {
	var l log.Logger

	switch o.Format {
	case FormatLogfmt:
		l = log.NewLogfmtLogger(log.NewSyncWriter(w))
	case FormatJSON:
		l = log.NewJSONLogger(log.NewSyncWriter(w))
	default:
		return nil, fmt.Errorf("unrecognized log format %q", o.Format)
	}

	l = level.NewFilter(l, o.Level.Filter())

	l = log.With(l, "ts", log.DefaultTimestampUTC)
	return l, nil
}

'''
'''--- pkg/flow/rivertypes/optional_secret.go ---
package rivertypes

import (
	"fmt"

	"github.com/grafana/agent/pkg/river"
	"github.com/grafana/agent/pkg/river/token"
	"github.com/grafana/agent/pkg/river/token/builder"
)

// OptionalSecret holds a potentially sensitive value. When IsSecret is true,
// the OptionalSecret's Value will be treated as sensitive and will be hidden
// from users when rendering River.
//
// OptionalSecrets may be converted from river strings and the Secret type,
// which will set IsSecret accordingly.
//
// Additionally, OptionalSecrets may be converted into the Secret type
// regardless of the value of IsSecret. OptionalSecret can be converted into a
// string as long as IsSecret is false.
type OptionalSecret struct {
	IsSecret bool
	Value    string
}

var (
	_ river.Capsule                = OptionalSecret{}
	_ river.ConvertibleIntoCapsule = OptionalSecret{}
	_ river.ConvertibleFromCapsule = (*OptionalSecret)(nil)

	_ builder.Tokenizer = OptionalSecret{}
)

// RiverCapsule marks OptionalSecret as a RiverCapsule.
func (s OptionalSecret) RiverCapsule() {}

// ConvertInto converts the OptionalSecret and stores it into the Go value
// pointed at by dst. OptionalSecrets can always be converted into *Secret.
// OptionalSecrets can only be converted into *string if IsSecret is false. In
// other cases, this method will return an explicit error or
// river.ErrNoConversion.
func (s OptionalSecret) ConvertInto(dst interface{}) error {
	switch dst := dst.(type) {
	case *Secret:
		*dst = Secret(s.Value)
		return nil
	case *string:
		if s.IsSecret {
			return fmt.Errorf("secrets may not be converted into strings")
		}
		*dst = s.Value
		return nil
	}

	return river.ErrNoConversion
}

// ConvertFrom converts the src value and stores it into the OptionalSecret s.
// Secrets and strings can be converted into an OptionalSecret. In other
// casees, this method will return river.ErrNoConversion.
func (s *OptionalSecret) ConvertFrom(src interface{}) error {
	switch src := src.(type) {
	case Secret:
		*s = OptionalSecret{IsSecret: true, Value: string(src)}
		return nil
	case string:
		*s = OptionalSecret{Value: src}
		return nil
	}

	return river.ErrNoConversion
}

// RiverTokenize returns a set of custom tokens to represent this value in
// River text.
func (s OptionalSecret) RiverTokenize() []builder.Token {
	if s.IsSecret {
		return []builder.Token{{Tok: token.LITERAL, Lit: "(secret)"}}
	}
	return []builder.Token{{
		Tok: token.STRING,
		Lit: fmt.Sprintf("%q", s.Value),
	}}
}

'''
'''--- pkg/flow/rivertypes/optional_secret_test.go ---
package rivertypes_test

import (
	"testing"

	"github.com/grafana/agent/pkg/flow/rivertypes"
	"github.com/grafana/agent/pkg/river/token/builder"
	"github.com/stretchr/testify/require"
)

func TestOptionalSecret(t *testing.T) {
	t.Run("non-sensitive conversion to string is allowed", func(t *testing.T) {
		input := rivertypes.OptionalSecret{IsSecret: false, Value: "testval"}

		var s string
		err := decodeTo(t, input, &s)
		require.NoError(t, err)
		require.Equal(t, "testval", s)
	})

	t.Run("sensitive conversion to string is disallowed", func(t *testing.T) {
		input := rivertypes.OptionalSecret{IsSecret: true, Value: "testval"}

		var s string
		err := decodeTo(t, input, &s)
		require.NotNil(t, err)
		require.Contains(t, err.Error(), "secrets may not be converted into strings")
	})

	t.Run("non-sensitive conversion to secret is allowed", func(t *testing.T) {
		input := rivertypes.OptionalSecret{IsSecret: false, Value: "testval"}

		var s rivertypes.Secret
		err := decodeTo(t, input, &s)
		require.NoError(t, err)
		require.Equal(t, rivertypes.Secret("testval"), s)
	})

	t.Run("sensitive conversion to secret is allowed", func(t *testing.T) {
		input := rivertypes.OptionalSecret{IsSecret: true, Value: "testval"}

		var s rivertypes.Secret
		err := decodeTo(t, input, &s)
		require.NoError(t, err)
		require.Equal(t, rivertypes.Secret("testval"), s)
	})

	t.Run("conversion from string is allowed", func(t *testing.T) {
		var s rivertypes.OptionalSecret
		err := decodeTo(t, string("Hello, world!"), &s)
		require.NoError(t, err)

		expect := rivertypes.OptionalSecret{
			IsSecret: false,
			Value:    "Hello, world!",
		}
		require.Equal(t, expect, s)
	})

	t.Run("conversion from secret is allowed", func(t *testing.T) {
		var s rivertypes.OptionalSecret
		err := decodeTo(t, rivertypes.Secret("Hello, world!"), &s)
		require.NoError(t, err)

		expect := rivertypes.OptionalSecret{
			IsSecret: true,
			Value:    "Hello, world!",
		}
		require.Equal(t, expect, s)
	})
}

func TestOptionalSecret_Write(t *testing.T) {
	tt := []struct {
		name   string
		value  interface{}
		expect string
	}{
		{"non-sensitive", rivertypes.OptionalSecret{Value: "foobar"}, `"foobar"`},
		{"sensitive", rivertypes.OptionalSecret{IsSecret: true, Value: "foobar"}, `(secret)`},
		{"non-sensitive pointer", &rivertypes.OptionalSecret{Value: "foobar"}, `"foobar"`},
		{"sensitive pointer", &rivertypes.OptionalSecret{IsSecret: true, Value: "foobar"}, `(secret)`},
	}

	for _, tc := range tt {
		t.Run(tc.name, func(t *testing.T) {
			be := builder.NewExpr()
			be.SetValue(tc.value)
			require.Equal(t, tc.expect, string(be.Bytes()))
		})
	}
}

'''
'''--- pkg/flow/rivertypes/secret.go ---
package rivertypes

import (
	"fmt"

	"github.com/grafana/agent/pkg/river"
	"github.com/grafana/agent/pkg/river/token"
	"github.com/grafana/agent/pkg/river/token/builder"
)

// Secret is a River capsule holding a sensitive string. The contents of a
// Secret are never displayed to the user when rendering River.
//
// Secret allows itself to be converted from a string River value, but never
// the inverse. This ensures that a user can't accidentally leak a sensitive
// value.
type Secret string

var (
	_ river.Capsule                = Secret("")
	_ river.ConvertibleIntoCapsule = Secret("")
	_ river.ConvertibleFromCapsule = (*Secret)(nil)

	_ builder.Tokenizer = Secret("")
)

// RiverCapsule marks Secret as a RiverCapsule.
func (s Secret) RiverCapsule() {}

// ConvertInto converts the Secret and stores it into the Go value pointed at
// by dst. Secrets can be converted into *OptionalSecret. In other cases, this
// method will return an explicit error or river.ErrNoConversion.
func (s Secret) ConvertInto(dst interface{}) error {
	switch dst := dst.(type) {
	case *OptionalSecret:
		*dst = OptionalSecret{IsSecret: true, Value: string(s)}
		return nil
	case *string:
		return fmt.Errorf("secrets may not be converted into strings")
	}

	return river.ErrNoConversion
}

// ConvertFrom converts the src value and stores it into the Secret s.
// OptionalSecrets and strings can be converted into a Secret. In other casees,
// this method will return river.ErrNoConversion.
func (s *Secret) ConvertFrom(src interface{}) error {
	switch src := src.(type) {
	case OptionalSecret:
		*s = Secret(src.Value)
		return nil
	case string:
		*s = Secret(src)
		return nil
	}

	return river.ErrNoConversion
}

// RiverTokenize returns a set of custom tokens to represent this value in
// River text.
func (s Secret) RiverTokenize() []builder.Token {
	return []builder.Token{{Tok: token.LITERAL, Lit: "(secret)"}}
}

'''
'''--- pkg/flow/rivertypes/secret_test.go ---
package rivertypes_test

import (
	"testing"

	"github.com/grafana/agent/pkg/flow/rivertypes"
	"github.com/grafana/agent/pkg/river/parser"
	"github.com/grafana/agent/pkg/river/vm"
	"github.com/stretchr/testify/require"
)

func TestSecret(t *testing.T) {
	t.Run("strings can be converted to secret", func(t *testing.T) {
		var s rivertypes.Secret
		err := decodeTo(t, string("Hello, world!"), &s)
		require.NoError(t, err)
		require.Equal(t, rivertypes.Secret("Hello, world!"), s)
	})

	t.Run("secrets cannot be converted to strings", func(t *testing.T) {
		var s string
		err := decodeTo(t, rivertypes.Secret("Hello, world!"), &s)
		require.NotNil(t, err)
		require.Contains(t, err.Error(), "secrets may not be converted into strings")
	})

	t.Run("secrets can be passed to secrets", func(t *testing.T) {
		var s rivertypes.Secret
		err := decodeTo(t, rivertypes.Secret("Hello, world!"), &s)
		require.NoError(t, err)
		require.Equal(t, rivertypes.Secret("Hello, world!"), s)
	})
}

func decodeTo(t *testing.T, input interface{}, target interface{}) error {
	t.Helper()

	expr, err := parser.ParseExpression("val")
	require.NoError(t, err)

	eval := vm.New(expr)
	return eval.Evaluate(&vm.Scope{
		Variables: map[string]interface{}{
			"val": input,
		},
	}, target)
}

'''
'''--- pkg/integrations/agent/agent.go ---
// Package agent is an "example" integration that has very little functionality,
// but is still useful in practice. The Agent integration re-exposes the Agent's
// own metrics endpoint and allows the Agent to scrape itself.
package agent

import (
	"context"
	"net/http"

	"github.com/go-kit/log"
	"github.com/grafana/agent/pkg/integrations"
	"github.com/grafana/agent/pkg/integrations/config"
	"github.com/prometheus/client_golang/prometheus/promhttp"
)

// Config controls the Agent integration.
type Config struct{}

// Name returns the name of the integration that this config represents.
func (c *Config) Name() string {
	return "agent"
}

// InstanceKey returns the hostname of the machine.
func (c *Config) InstanceKey(agentKey string) (string, error) {
	return agentKey, nil
}

// NewIntegration converts this config into an instance of an integration.
func (c *Config) NewIntegration(_ log.Logger) (integrations.Integration, error) {
	return New(c), nil
}

func init() {
	integrations.RegisterIntegration(&Config{})
}

// Integration is the Agent integration. The Agent integration scrapes the
// Agent's own metrics.
type Integration struct {
	c *Config
}

// New creates a new Agent integration.
func New(c *Config) *Integration {
	return &Integration{c: c}
}

// MetricsHandler satisfies Integration.RegisterRoutes.
func (i *Integration) MetricsHandler() (http.Handler, error) {
	return promhttp.Handler(), nil
}

// ScrapeConfigs satisfies Integration.ScrapeConfigs.
func (i *Integration) ScrapeConfigs() []config.ScrapeConfig {
	return []config.ScrapeConfig{{
		JobName:     i.c.Name(),
		MetricsPath: "/metrics",
	}}
}

// Run satisfies Integration.Run.
func (i *Integration) Run(ctx context.Context) error {
	// We don't need to do anything here, so we can just wait for the context to
	// finish.
	<-ctx.Done()
	return ctx.Err()
}

'''
'''--- pkg/integrations/apache_http/apache_http.go ---
// Package apache_http embeds https://github.com/Lusitaniae/apache_exporter
package apache_http //nolint:golint

import (
	"fmt"
	"net/url"

	ae "github.com/Lusitaniae/apache_exporter/collector"
	"github.com/go-kit/log"
	"github.com/go-kit/log/level"
	"github.com/grafana/agent/pkg/integrations"
)

// DefaultConfig holds the default settings for the apache_http integration
var DefaultConfig = Config{
	ApacheAddr:         "http://localhost/server-status?auto",
	ApacheHostOverride: "",
	ApacheInsecure:     false,
}

// Config controls the apache_http integration.
type Config struct {
	ApacheAddr         string `yaml:"scrape_uri,omitempty"`
	ApacheHostOverride string `yaml:"host_override,omitempty"`
	ApacheInsecure     bool   `yaml:"insecure,omitempty"`
}

// UnmarshalYAML implements yaml.Unmarshaler for Config
func (c *Config) UnmarshalYAML(unmarshal func(interface{}) error) error {
	*c = DefaultConfig

	type plain Config
	return unmarshal((*plain)(c))
}

// Name returns the name of the integration this config is for.
func (c *Config) Name() string {
	return "apache_http"
}

// InstanceKey returns the addr of the apache server.
func (c *Config) InstanceKey(agentKey string) (string, error) {
	u, err := url.Parse(c.ApacheAddr)
	if err != nil {
		return "", err
	}
	return fmt.Sprintf("%s:%s", u.Hostname(), u.Port()), nil
}

// NewIntegration converts the config into an integration instance.
func (c *Config) NewIntegration(logger log.Logger) (integrations.Integration, error) {
	return New(logger, c)
}

func init() {
	integrations.RegisterIntegration(&Config{})
}

// New creates a new apache_http integration. The integration scrapes metrics
// from a Apache HTTP server.
func New(logger log.Logger, c *Config) (integrations.Integration, error) {
	conf := &ae.Config{
		ScrapeURI:    c.ApacheAddr,
		HostOverride: c.ApacheHostOverride,
		Insecure:     c.ApacheInsecure,
	}

	//check scrape URI
	_, err := url.ParseRequestURI(conf.ScrapeURI)
	if err != nil {
		level.Error(logger).Log("msg", "scrape_uri is invalid", "err", err)
		return nil, err
	}
	aeExporter := ae.NewExporter(logger, conf)

	return integrations.NewCollectorIntegration(
		c.Name(),
		integrations.WithCollectors(aeExporter),
	), nil
}

'''
'''--- pkg/integrations/cadvisor/cadvisor.go ---
//go:build linux
// +build linux

package cadvisor //nolint:golint

import (
	"context"
	"fmt"
	"net/http"
	"strings"
	"time"

	"github.com/go-kit/log"
	"github.com/google/cadvisor/cache/memory"
	"github.com/google/cadvisor/container"
	v2 "github.com/google/cadvisor/info/v2"
	"github.com/google/cadvisor/manager"
	"github.com/google/cadvisor/metrics"
	"github.com/google/cadvisor/storage"
	"github.com/google/cadvisor/utils/sysfs"
	"k8s.io/klog/v2"
	"k8s.io/utils/clock"

	"github.com/grafana/agent/pkg/integrations"

	// Register container providers

	"github.com/google/cadvisor/container/containerd"
	_ "github.com/google/cadvisor/container/containerd/install" // register containerd container plugin
	_ "github.com/google/cadvisor/container/crio/install"       // register crio container plugin
	"github.com/google/cadvisor/container/docker"
	_ "github.com/google/cadvisor/container/docker/install" // register docker container plugin
	"github.com/google/cadvisor/container/raw"
	_ "github.com/google/cadvisor/container/systemd/install" // register systemd container plugin
)

// Matching the default disabled set from cadvisor - https://github.com/google/cadvisor/blob/3c6e3093c5ca65c57368845ddaea2b4ca6bc0da8/cmd/cadvisor.go#L78-L93
// Note: This *could* be kept in sync with upstream by using the following. However, that would require importing the github.com/google/cadvisor/cmd package, which introduces some dependency conflicts that weren't worth the hassle IMHO.
// var disabledMetrics = *flag.Lookup("disable_metrics").Value.(*container.MetricSet)
var disabledMetrics = container.MetricSet{
	container.MemoryNumaMetrics:              struct{}{},
	container.NetworkTcpUsageMetrics:         struct{}{},
	container.NetworkUdpUsageMetrics:         struct{}{},
	container.NetworkAdvancedTcpUsageMetrics: struct{}{},
	container.ProcessSchedulerMetrics:        struct{}{},
	container.ProcessMetrics:                 struct{}{},
	container.HugetlbUsageMetrics:            struct{}{},
	container.ReferencedMemoryMetrics:        struct{}{},
	container.CPUTopologyMetrics:             struct{}{},
	container.ResctrlMetrics:                 struct{}{},
	container.CPUSetMetrics:                  struct{}{},
}

// GetIncludedMetrics applies some logic to determine the final set of metrics to be scraped and returned by the cAdvisor integration
func (c *Config) GetIncludedMetrics() (container.MetricSet, error) {
	var enabledMetrics, includedMetrics container.MetricSet

	if c.DisabledMetrics != nil {
		if err := disabledMetrics.Set(strings.Join(c.DisabledMetrics, ",")); err != nil {
			return includedMetrics, fmt.Errorf("failed to set disabled metrics: %w", err)
		}
	}

	if c.EnabledMetrics != nil {
		if err := enabledMetrics.Set(strings.Join(c.EnabledMetrics, ",")); err != nil {
			return includedMetrics, fmt.Errorf("failed to set enabled metrics: %w", err)
		}
	}

	if len(enabledMetrics) > 0 {
		includedMetrics = enabledMetrics
	} else {
		includedMetrics = container.AllMetrics.Difference(disabledMetrics)
	}

	return includedMetrics, nil
}

// NewIntegration creates a new cadvisor integration
func (c *Config) NewIntegration(logger log.Logger) (integrations.Integration, error) {
	return New(logger, c)
}

// Integration implements the cadvisor integration
type Integration struct {
	c *Config
	i *integrations.CollectorIntegration
}

// Run holds all the configuration logic for globals, as well as starting the resource manager and registering the collectors with the collector integration
func (i *Integration) Run(ctx context.Context) error {
	// Do gross global configs. This works, so long as there is only one instance of the cAdvisor integration
	// per host.

	// klog
	klog.SetLogger(i.c.logger)

	// Containerd
	containerd.ArgContainerdEndpoint = &i.c.Containerd
	containerd.ArgContainerdNamespace = &i.c.ContainerdNamespace

	// Docker
	docker.ArgDockerEndpoint = &i.c.Docker
	docker.ArgDockerTLS = &i.c.DockerTLS
	docker.ArgDockerCert = &i.c.DockerTLSCert
	docker.ArgDockerKey = &i.c.DockerTLSKey
	docker.ArgDockerCA = &i.c.DockerTLSCA

	// Raw
	raw.DockerOnly = &i.c.DockerOnly

	// Only using in-memory storage, with no backup storage for cadvisor stats
	memoryStorage := memory.New(i.c.StorageDuration, []storage.StorageDriver{})

	sysFs := sysfs.NewRealSysFs()

	var collectorHTTPClient http.Client

	includedMetrics, err := i.c.GetIncludedMetrics()
	if err != nil {
		return fmt.Errorf("unable to determine included metrics: %w", err)
	}

	rm, err := manager.New(memoryStorage, sysFs, manager.HousekeepingConfigFlags, includedMetrics, &collectorHTTPClient, i.c.RawCgroupPrefixAllowlist, i.c.EnvMetadataAllowlist, i.c.PerfEventsConfig, time.Duration(i.c.ResctrlInterval))
	if err != nil {
		return fmt.Errorf("failed to create a manager: %w", err)
	}

	if err := rm.Start(); err != nil {
		return fmt.Errorf("failed to start manager: %w", err)
	}

	containerLabelFunc := metrics.DefaultContainerLabels
	if !i.c.StoreContainerLabels {
		containerLabelFunc = metrics.BaseContainerLabels(i.c.AllowlistedContainerLabels)
	}

	machCol := metrics.NewPrometheusMachineCollector(rm, includedMetrics)
	// This is really just a concatenation of the defaults found at;
	// https://github.com/google/cadvisor/tree/f89291a53b80b2c3659fff8954c11f1fc3de8a3b/cmd/internal/api/versions.go#L536-L540
	// https://github.com/google/cadvisor/tree/f89291a53b80b2c3659fff8954c11f1fc3de8a3b/cmd/internal/http/handlers.go#L109-L110
	// AFAIK all we are ever doing is the "default" metrics request, and we don't need to support the "docker" request type.
	reqOpts := v2.RequestOptions{
		IdType:    v2.TypeName,
		Count:     1,
		Recursive: true,
	}
	contCol := metrics.NewPrometheusCollector(rm, containerLabelFunc, includedMetrics, clock.RealClock{}, reqOpts)
	integrations.WithCollectors(machCol, contCol)(i.i)

	<-ctx.Done()

	if err := rm.Stop(); err != nil {
		return fmt.Errorf("failed to stop manager: %w", err)
	}
	return nil
}

// New creates a new cadvisor integration
func New(logger log.Logger, c *Config) (integrations.Integration, error) {
	c.logger = logger

	ci := integrations.NewCollectorIntegration(c.Name())
	integration := Integration{
		c: c,
		i: ci,
	}
	integrations.WithRunner(integration.Run)(ci)
	return ci, nil
}

'''
'''--- pkg/integrations/cadvisor/cadvisor_stub.go ---
//go:build !linux
// +build !linux

package cadvisor //nolint:golint

import (
	"github.com/grafana/agent/pkg/integrations"

	"github.com/go-kit/log"
	"github.com/go-kit/log/level"
)

// NewIntegration creates a new cadvisor integration
func (c *Config) NewIntegration(logger log.Logger) (integrations.Integration, error) {
	level.Warn(logger).Log("msg", "the cadvisor integration only works on linux; enabling it on other platforms will do nothing")
	return &integrations.StubIntegration{}, nil
}

'''
'''--- pkg/integrations/cadvisor/cadvisor_test.go ---
//go:build !nonetwork && !nodocker && linux
// +build !nonetwork,!nodocker,linux

package cadvisor

import (
	"context"
	"testing"

	"github.com/grafana/agent/pkg/util"
	"github.com/stretchr/testify/require"
	"gopkg.in/yaml.v3"
)

func TestConfig_DockerOnly(t *testing.T) {
	t.Run("docker_only with default configuration is successful", func(t *testing.T) {
		// Run it once with the default config, expecting success.
		defaultCfg := `docker_only: true`

		var cfg Config
		err := yaml.Unmarshal([]byte(defaultCfg), &cfg)
		require.NoError(t, err)

		ig, err := cfg.NewIntegration(util.TestLogger(t))
		require.NoError(t, err)

		ctx, cancel := context.WithCancel(context.Background())
		cancel()
		require.NoError(t, ig.Run(ctx))
	})
}

'''
'''--- pkg/integrations/cadvisor/common.go ---
package cadvisor

import (
	"time"

	"github.com/go-kit/log"
	"github.com/grafana/agent/pkg/integrations"
	integrations_v2 "github.com/grafana/agent/pkg/integrations/v2"
	"github.com/grafana/agent/pkg/integrations/v2/metricsutils"
)

const name = "cadvisor"

// DefaultConfig holds the default settings for the cadvisor integration
var DefaultConfig = Config{
	// Common cadvisor config defaults
	StoreContainerLabels: true,
	ResctrlInterval:      0,

	StorageDuration: 2 * time.Minute,

	// Containerd config defaults
	Containerd:          "/run/containerd/containerd.sock",
	ContainerdNamespace: "k8s.io",

	// Docker config defaults
	Docker:        "unix:///var/run/docker.sock",
	DockerTLS:     false,
	DockerTLSCert: "cert.pem",
	DockerTLSKey:  "key.pem",
	DockerTLSCA:   "ca.pem",

	// Raw config defaults
	DockerOnly: false,
}

// Config controls cadvisor
type Config struct {
	// Common cadvisor config options
	// StoreContainerLabels converts container labels and environment variables into labels on prometheus metrics for each container. If false, then only metrics exported are container name, first alias, and image name.
	StoreContainerLabels bool `yaml:"store_container_labels,omitempty"`

	// AllowlistedContainerLabels list of container labels to be converted to labels on prometheus metrics for each container. store_container_labels must be set to false for this to take effect.
	AllowlistedContainerLabels []string `yaml:"allowlisted_container_labels,omitempty"`

	// EnvMetadataAllowlist list of environment variable keys matched with specified prefix that needs to be collected for containers, only support containerd and docker runtime for now.
	EnvMetadataAllowlist []string `yaml:"env_metadata_allowlist,omitempty"`

	// RawCgroupPrefixAllowlist list of cgroup path prefix that needs to be collected even when -docker_only is specified.
	RawCgroupPrefixAllowlist []string `yaml:"raw_cgroup_prefix_allowlist,omitempty"`

	// PerfEventsConfig path to a JSON file containing configuration of perf events to measure. Empty value disabled perf events measuring.
	PerfEventsConfig string `yaml:"perf_events_config,omitempty"`

	// ResctrlInterval resctrl mon groups updating interval. Zero value disables updating mon groups.
	ResctrlInterval int `yaml:"resctrl_interval,omitempty"`

	// DisableMetrics list of `metrics` to be disabled.
	DisabledMetrics []string `yaml:"disabled_metrics,omitempty"`

	// EnableMetrics list of `metrics` to be enabled. If set, overrides 'disable_metrics'.
	EnabledMetrics []string `yaml:"enabled_metrics,omitempty"`

	// StorageDuration length of time to keep data stored in memory (Default: 2m)
	StorageDuration time.Duration `yaml:"storage_duration,omitempty"`

	// Containerd config options
	// Containerd containerd endpoint
	Containerd string `yaml:"containerd,omitempty"`

	// ContainerdNamespace containerd namespace
	ContainerdNamespace string `yaml:"containerd_namespace,omitempty"`

	// Docker config options
	// Docker docker endpoint
	Docker string `yaml:"docker,omitempty"`

	// DockerTLS use TLS to connect to docker
	DockerTLS bool `yaml:"docker_tls,omitempty"`

	// DockerTLSCert path to client certificate
	DockerTLSCert string `yaml:"docker_tls_cert,omitempty"`

	// DockerTLSKey path to private key
	DockerTLSKey string `yaml:"docker_tls_key,omitempty"`

	// DockerTLSCA path to trusted CA
	DockerTLSCA string `yaml:"docker_tls_ca,omitempty"`

	// Raw config options
	// DockerOnly only report docker containers in addition to root stats
	DockerOnly bool `yaml:"docker_only,omitempty"`

	// Hold on to the logger passed to config.NewIntegration, to be passed to klog, as yet another unsafe global that needs to be set.
	logger log.Logger //nolint:unused,structcheck // logger is only used on linux
}

// UnmarshalYAML implements yaml.Unmarshaler for Config
func (c *Config) UnmarshalYAML(unmarshal func(interface{}) error) error {
	*c = DefaultConfig

	type plain Config
	err := unmarshal((*plain)(c))
	if err != nil {
		return err
	}

	// In the cadvisor cmd, these are passed as CSVs, and turned into slices using strings.split. As a result the
	// default values are always a slice with 1 or more elements.
	// See: https://github.com/google/cadvisor/blob/v0.43.0/cmd/cadvisor.go#L136
	if len(c.AllowlistedContainerLabels) == 0 {
		c.AllowlistedContainerLabels = []string{""}
	}
	if len(c.RawCgroupPrefixAllowlist) == 0 {
		c.RawCgroupPrefixAllowlist = []string{""}
	}
	if len(c.EnvMetadataAllowlist) == 0 {
		c.EnvMetadataAllowlist = []string{""}
	}
	return nil
}

// Name returns the name of the integration that this config represents.
func (c *Config) Name() string {
	return name
}

// InstanceKey returns the agentKey
func (c *Config) InstanceKey(agentKey string) (string, error) {
	return agentKey, nil
}

func init() {
	integrations.RegisterIntegration(&Config{})
	integrations_v2.RegisterLegacy(&Config{}, integrations_v2.TypeSingleton, metricsutils.Shim)
}

'''
'''--- pkg/integrations/collector_integration.go ---
package integrations

import (
	"context"
	"fmt"
	"net/http"

	"github.com/grafana/agent/pkg/integrations/config"
	"github.com/prometheus/client_golang/prometheus"
	"github.com/prometheus/client_golang/prometheus/promhttp"
	"github.com/prometheus/common/version"
)

// CollectorIntegration is an integration exposing metrics from one or more Prometheus collectors.
type CollectorIntegration struct {
	name                   string
	cs                     []prometheus.Collector
	includeExporterMetrics bool
	runner                 func(context.Context) error
}

// NewCollectorIntegration creates a basic integration that exposes metrics from multiple prometheus.Collector.
func NewCollectorIntegration(name string, configs ...CollectorIntegrationConfig) *CollectorIntegration {
	i := &CollectorIntegration{
		name: name,
		runner: func(ctx context.Context) error {
			// We don't need to do anything by default, so we can just wait for the context to finish.
			<-ctx.Done()
			return ctx.Err()
		},
	}
	for _, configure := range configs {
		configure(i)
	}
	return i
}

// CollectorIntegrationConfig defines constructor configuration for NewCollectorIntegration
type CollectorIntegrationConfig func(integration *CollectorIntegration)

// WithCollectors adds more collectors to the CollectorIntegration being created.
func WithCollectors(cs ...prometheus.Collector) CollectorIntegrationConfig {
	return func(i *CollectorIntegration) {
		i.cs = append(i.cs, cs...)
	}
}

// WithRunner replaces the runner of the CollectorIntegration.
// The runner function should run while the context provided is not done.
func WithRunner(runner func(context.Context) error) CollectorIntegrationConfig {
	return func(i *CollectorIntegration) {
		i.runner = runner
	}
}

// WithExporterMetricsIncluded can enable the exporter metrics if the flag provided is enabled.
func WithExporterMetricsIncluded(included bool) CollectorIntegrationConfig {
	return func(i *CollectorIntegration) {
		i.includeExporterMetrics = included
	}
}

// MetricsHandler returns the HTTP handler for the integration.
func (i *CollectorIntegration) MetricsHandler() (http.Handler, error) {
	r := prometheus.NewRegistry()
	for _, c := range i.cs {
		if err := r.Register(c); err != nil {
			return nil, fmt.Errorf("couldn't register %s: %w", i.name, err)
		}
	}

	// Register <integration name>_build_info metrics, generally useful for
	// dashboards that depend on them for discovering targets.
	if err := r.Register(version.NewCollector(i.name)); err != nil {
		return nil, fmt.Errorf("couldn't register %s: %w", i.name, err)
	}

	handler := promhttp.HandlerFor(
		r,
		promhttp.HandlerOpts{
			ErrorHandling: promhttp.ContinueOnError,
		},
	)

	if i.includeExporterMetrics {
		// Note that we have to use reg here to use the same promhttp metrics for
		// all expositions.
		handler = promhttp.InstrumentMetricHandler(r, handler)
	}

	return handler, nil
}

// ScrapeConfigs satisfies Integration.ScrapeConfigs.
func (i *CollectorIntegration) ScrapeConfigs() []config.ScrapeConfig {
	return []config.ScrapeConfig{{
		JobName:     i.name,
		MetricsPath: "/metrics",
	}}
}

// Run satisfies Integration.Run.
func (i *CollectorIntegration) Run(ctx context.Context) error {
	return i.runner(ctx)
}

'''
'''--- pkg/integrations/config/config.go ---
// Package config provides common configuration structs shared among
// implementations of integrations.Integration.
package config

import (
	"net/url"
	"time"

	"github.com/prometheus/prometheus/model/relabel"
)

// Common is a set of common options shared by all integrations. It should be
// utilised by an integration's config by inlining the common options:
//
//   type IntegrationConfig struct {
//     Common config.Common `yaml:",inline"`
//   }
type Common struct {
	Enabled              bool              `yaml:"enabled,omitempty"`
	InstanceKey          *string           `yaml:"instance,omitempty"`
	ScrapeIntegration    *bool             `yaml:"scrape_integration,omitempty"`
	ScrapeInterval       time.Duration     `yaml:"scrape_interval,omitempty"`
	ScrapeTimeout        time.Duration     `yaml:"scrape_timeout,omitempty"`
	RelabelConfigs       []*relabel.Config `yaml:"relabel_configs,omitempty"`
	MetricRelabelConfigs []*relabel.Config `yaml:"metric_relabel_configs,omitempty"`
	WALTruncateFrequency time.Duration     `yaml:"wal_truncate_frequency,omitempty"`
}

// ScrapeConfig is a subset of options used by integrations to inform how samples
// should be scraped. It is utilized by the integrations.Manager to define a full
// Prometheus-compatible ScrapeConfig.
type ScrapeConfig struct {
	// JobName should be a unique name indicating the collection of samples to be
	// scraped. It will be prepended by "integrations/" when used by the integrations
	// manager.
	JobName string

	// MetricsPath is the path relative to the integration where metrics are exposed.
	// It should match a route added to the router provided in Integration.RegisterRoutes.
	// The path will be prepended by "/integrations/<integration name>" when read by
	// the integrations manager.
	MetricsPath string

	// QueryParams is a set of query parameters, that if set, will be appended to
	// MetricsPath and used for scraping the integration's target.
	QueryParams url.Values
}

'''
'''--- pkg/integrations/consul_exporter/consul_exporter.go ---
// Package consul_exporter embeds https://github.com/prometheus/consul_exporter
package consul_exporter //nolint:golint

import (
	"fmt"
	"net/url"
	"time"

	"github.com/go-kit/log"
	"github.com/grafana/agent/pkg/integrations"
	integrations_v2 "github.com/grafana/agent/pkg/integrations/v2"
	"github.com/grafana/agent/pkg/integrations/v2/metricsutils"
	consul_api "github.com/hashicorp/consul/api"
	"github.com/prometheus/consul_exporter/pkg/exporter"
)

// DefaultConfig holds the default settings for the consul_exporter integration.
var DefaultConfig = Config{
	Server:        "http://localhost:8500",
	Timeout:       500 * time.Millisecond,
	AllowStale:    true,
	KVFilter:      ".*",
	HealthSummary: true,
}

// Config controls the consul_exporter integration.
type Config struct {
	Server             string        `yaml:"server,omitempty"`
	CAFile             string        `yaml:"ca_file,omitempty"`
	CertFile           string        `yaml:"cert_file,omitempty"`
	KeyFile            string        `yaml:"key_file,omitempty"`
	ServerName         string        `yaml:"server_name,omitempty"`
	Timeout            time.Duration `yaml:"timeout,omitempty"`
	InsecureSkipVerify bool          `yaml:"insecure_skip_verify,omitempty"`
	RequestLimit       int           `yaml:"concurrent_request_limit,omitempty"`
	AllowStale         bool          `yaml:"allow_stale,omitempty"`
	RequireConsistent  bool          `yaml:"require_consistent,omitempty"`

	KVPrefix      string `yaml:"kv_prefix,omitempty"`
	KVFilter      string `yaml:"kv_filter,omitempty"`
	HealthSummary bool   `yaml:"generate_health_summary,omitempty"`
}

// UnmarshalYAML implements yaml.Unmarshaler for Config.
func (c *Config) UnmarshalYAML(unmarshal func(interface{}) error) error {
	*c = DefaultConfig

	type plain Config
	return unmarshal((*plain)(c))
}

// Name returns the name of the integration.
func (c *Config) Name() string {
	return "consul_exporter"
}

// InstanceKey returns the hostname:port of the Consul server.
func (c *Config) InstanceKey(agentKey string) (string, error) {
	u, err := url.Parse(c.Server)
	if err != nil {
		return "", fmt.Errorf("could not parse url: %w", err)
	}
	return u.Host, nil
}

// NewIntegration converts the config into an instance of an integration.
func (c *Config) NewIntegration(l log.Logger) (integrations.Integration, error) {
	return New(l, c)
}

func init() {
	integrations.RegisterIntegration(&Config{})
	integrations_v2.RegisterLegacy(&Config{}, integrations_v2.TypeMultiplex, metricsutils.NewNamedShim("consul"))
}

// New creates a new consul_exporter integration. The integration scrapes
// metrics from a consul process.
func New(log log.Logger, c *Config) (integrations.Integration, error) {
	var (
		consulOpts = exporter.ConsulOpts{
			CAFile:       c.CAFile,
			CertFile:     c.CertFile,
			Insecure:     c.InsecureSkipVerify,
			KeyFile:      c.KeyFile,
			RequestLimit: c.RequestLimit,
			ServerName:   c.ServerName,
			Timeout:      c.Timeout,
			URI:          c.Server,
		}
		queryOptions = consul_api.QueryOptions{
			AllowStale:        c.AllowStale,
			RequireConsistent: c.RequireConsistent,
		}
	)

	e, err := exporter.New(consulOpts, queryOptions, c.KVPrefix, c.KVFilter, c.HealthSummary, log)
	if err != nil {
		return nil, err
	}

	return integrations.NewCollectorIntegration(c.Name(), integrations.WithCollectors(e)), nil
}

'''
'''--- pkg/integrations/dnsmasq_exporter/dnsmasq_exporter.go ---
// Package dnsmasq_exporter embeds https://github.com/google/dnsmasq_exporter
package dnsmasq_exporter //nolint:golint

import (
	"github.com/go-kit/log"
	"github.com/google/dnsmasq_exporter/collector"
	"github.com/grafana/agent/pkg/integrations"
	integrations_v2 "github.com/grafana/agent/pkg/integrations/v2"
	"github.com/grafana/agent/pkg/integrations/v2/metricsutils"
	"github.com/miekg/dns"
)

// DefaultConfig is the default config for dnsmasq_exporter.
var DefaultConfig = Config{
	DnsmasqAddress: "localhost:53",
	LeasesPath:     "/var/lib/misc/dnsmasq.leases",
}

// Config controls the dnsmasq_exporter integration.
type Config struct {
	// DnsmasqAddress is the address of the dnsmasq server (host:port).
	DnsmasqAddress string `yaml:"dnsmasq_address,omitempty"`

	// Path to the dnsmasq leases file.
	LeasesPath string `yaml:"leases_path,omitempty"`
}

// Name returns the name of the integration that this config is for.
func (c *Config) Name() string {
	return "dnsmasq_exporter"
}

// InstanceKey returns the address of the dnsmasq server.
func (c *Config) InstanceKey(agentKey string) (string, error) {
	return c.DnsmasqAddress, nil
}

// NewIntegration converts this config into an instance of an integration.
func (c *Config) NewIntegration(l log.Logger) (integrations.Integration, error) {
	return New(l, c)
}

// UnmarshalYAML implements yaml.Unmarshaler for Config.
func (c *Config) UnmarshalYAML(unmarshal func(interface{}) error) error {
	*c = DefaultConfig

	type plain Config
	return unmarshal((*plain)(c))
}

func init() {
	integrations.RegisterIntegration(&Config{})
	integrations_v2.RegisterLegacy(&Config{}, integrations_v2.TypeMultiplex, metricsutils.NewNamedShim("dnsmasq"))
}

// New creates a new dnsmasq_exporter integration. The integration scrapes metrics
// from a dnsmasq server.
func New(log log.Logger, c *Config) (integrations.Integration, error) {
	exporter := collector.New(log, &dns.Client{
		SingleInflight: true,
	}, c.DnsmasqAddress, c.LeasesPath)

	return integrations.NewCollectorIntegration(c.Name(), integrations.WithCollectors(exporter)), nil
}

'''
'''--- pkg/integrations/ebpf_exporter/common.go ---
package ebpf

import (
	"github.com/grafana/agent/pkg/integrations"
	integrations_v2 "github.com/grafana/agent/pkg/integrations/v2"
	"github.com/grafana/agent/pkg/integrations/v2/metricsutils"

	ebpf_config "github.com/cloudflare/ebpf_exporter/config"
)

func init() {
	integrations.RegisterIntegration(&Config{})
	integrations_v2.RegisterLegacy(&Config{}, integrations_v2.TypeSingleton, metricsutils.NewNamedShim("ebpf"))
}

// Config controls the eBPF integration.
type Config struct {
	Programs []ebpf_config.Program `yaml:"programs,omitempty"`
}

// UnmarshalYAML implements yaml.Unmarshaler for Config.
func (c *Config) UnmarshalYAML(unmarshal func(interface{}) error) error {
	type plain Config

	return unmarshal((*plain)(c))
}

// Name returns the name of the integration that this config represents.
func (c *Config) Name() string {
	return "ebpf"
}

// InstanceKey returns a set identifier for the ebpf_exporter integration.
func (c *Config) InstanceKey(_ string) (string, error) {
	return c.Name(), nil
}

'''
'''--- pkg/integrations/ebpf_exporter/ebpf.go ---
//go:build linux && amd64 && !noebpf
// +build linux,amd64,!noebpf

package ebpf

import (
	"fmt"

	ebpf_config "github.com/cloudflare/ebpf_exporter/config"
	"github.com/cloudflare/ebpf_exporter/exporter"
	"github.com/go-kit/log"
	"github.com/grafana/agent/pkg/integrations"
)

// New sets up an ebpf exporter from a given config.
func New(logger log.Logger, c *Config) (integrations.Integration, error) {
	exp, err := exporter.New(ebpf_config.Config{Programs: c.Programs})
	if err != nil {
		return nil, fmt.Errorf("failed to create ebpf exporter with input config: %s", err)
	}

	err = exp.Attach()
	if err != nil {
		return nil, fmt.Errorf("failed to attach ebpf exporter: %s", err)
	}

	return integrations.NewCollectorIntegration(
		c.Name(),
		integrations.WithCollectors(exp),
	), nil
}

// NewIntegration creates a new ebpf_exporter instance.
func (c *Config) NewIntegration(logger log.Logger) (integrations.Integration, error) {
	return New(logger, c)
}

'''
'''--- pkg/integrations/ebpf_exporter/ebpf_stub.go ---
//go:build !linux || !amd64 || noebpf
// +build !linux !amd64 noebpf

package ebpf

import (
	"github.com/grafana/agent/pkg/integrations"

	"github.com/go-kit/log"
	"github.com/go-kit/log/level"
)

// NewIntegration creates a new ebpf_exporter.
func (c *Config) NewIntegration(logger log.Logger) (integrations.Integration, error) {
	level.Warn(logger).Log("msg", "the ebpf integration is not available; enabling it will do nothing")
	return &integrations.StubIntegration{}, nil
}

'''
'''--- pkg/integrations/ebpf_exporter/ebpf_test.go ---
package ebpf

import (
	"testing"

	"github.com/stretchr/testify/require"
	"gopkg.in/yaml.v3"
)

func TestEBPFConfig(t *testing.T) {
	yamlCfg := `
programs:
# Count timers fired in the kernel
- name: cachestat
  metrics:
  counters:
  - name: page_cache_ops_total
    help: Page cache operation counters by type
    table: counts
    labels:
    - name: op
      size: 8
      decoders:
      - name: ksym
  kprobes:
    add_to_page_cache_lru: do_count
    mark_page_accessed: do_count
  code: |
    #include <uapi/linux/ptrace.h>
    struct key_t {
      u64 ip;
      char command[128];
    };
    BPF_HASH(counts, struct key_t);
    int do_count(struct pt_regs *ctx) {
      struct key_t key = { .ip = PT_REGS_IP(ctx) - 1 };
      bpf_get_current_comm(&key.command, sizeof(key.command));
      counts.increment(key);
      return 0;
    }
`
	var cfg Config
	err := yaml.Unmarshal([]byte(yamlCfg), &cfg)
	require.NoError(t, err)
	require.Len(t, cfg.Programs, 1)
	require.Equal(t, cfg.Programs[0].Name, "cachestat")
	require.Len(t, cfg.Programs[0].Kprobes, 2)
	require.NotEmpty(t, cfg.Programs[0].Code)
}

'''
'''--- pkg/integrations/elasticsearch_exporter/elasticsearch_exporter.go ---
// Package elasticsearch_exporter instantiates the exporter from github.com/justwatchcom/elasticsearch_exporter - replaced for github.com/prometheus-community/elasticsearch_exporter
// Using the YAML config provided by the agent
package elasticsearch_exporter //nolint:golint

import (
	"context"
	"fmt"
	"net/http"
	"net/url"
	"time"

	"github.com/go-kit/log"
	"github.com/go-kit/log/level"
	"github.com/grafana/agent/pkg/integrations"
	integrations_v2 "github.com/grafana/agent/pkg/integrations/v2"
	"github.com/grafana/agent/pkg/integrations/v2/metricsutils"
	"github.com/prometheus/client_golang/prometheus"

	"github.com/prometheus-community/elasticsearch_exporter/collector"
	"github.com/prometheus-community/elasticsearch_exporter/pkg/clusterinfo"
)

// DefaultConfig holds the default settings for the elasticsearch_exporter
// integration.
var DefaultConfig = Config{
	Address:                   "http://localhost:9200",
	Timeout:                   5 * time.Second,
	Node:                      "_local",
	ExportClusterInfoInterval: 5 * time.Minute,
}

// Config controls the elasticsearch_exporter integration.
type Config struct {
	// HTTP API address of an Elasticsearch node.
	Address string `yaml:"address,omitempty"`
	// Timeout for trying to get stats from Elasticsearch.
	Timeout time.Duration `yaml:"timeout,omitempty"`
	// Export stats for all nodes in the cluster. If used, this flag will override the flag es.node.
	AllNodes bool `yaml:"all,omitempty"`
	// Node's name of which metrics should be exposed.
	Node string `yaml:"node,omitempty"`
	// Export stats for indices in the cluster.
	ExportIndices bool `yaml:"indices,omitempty"`
	// Export stats for settings of all indices of the cluster.
	ExportIndicesSettings bool `yaml:"indices_settings,omitempty"`
	// Export stats for cluster settings.
	ExportClusterSettings bool `yaml:"cluster_settings,omitempty"`
	// Export stats for shards in the cluster (implies indices).
	ExportShards bool `yaml:"shards,omitempty"`
	// Export stats for the cluster snapshots.
	ExportSnapshots bool `yaml:"snapshots,omitempty"`
	// Cluster info update interval for the cluster label.
	ExportClusterInfoInterval time.Duration `yaml:"clusterinfo_interval,omitempty"`
	// Path to PEM file that contains trusted Certificate Authorities for the Elasticsearch connection.
	CA string `yaml:"ca,omitempty"`
	// Path to PEM file that contains the private key for client auth when connecting to Elasticsearch.
	ClientPrivateKey string `yaml:"client_private_key,omitempty"`
	// Path to PEM file that contains the corresponding cert for the private key to connect to Elasticsearch.
	ClientCert string `yaml:"client_cert,omitempty"`
	// Skip SSL verification when connecting to Elasticsearch.
	InsecureSkipVerify bool `yaml:"ssl_skip_verify,omitempty"`
}

// UnmarshalYAML implements yaml.Unmarshaler for Config
func (c *Config) UnmarshalYAML(unmarshal func(interface{}) error) error {
	*c = DefaultConfig

	type plain Config
	return unmarshal((*plain)(c))
}

// Name returns the name of the integration that this config represents.
func (c *Config) Name() string {
	return "elasticsearch_exporter"
}

// InstanceKey returns the hostname:port of the elasticsearch node being queried.
func (c *Config) InstanceKey(agentKey string) (string, error) {
	u, err := url.Parse(c.Address)
	if err != nil {
		return "", fmt.Errorf("could not parse url: %w", err)
	}
	return u.Host, nil
}

// NewIntegration creates a new elasticsearch_exporter
func (c *Config) NewIntegration(logger log.Logger) (integrations.Integration, error) {
	return New(logger, c)
}

func init() {
	integrations.RegisterIntegration(&Config{})
	integrations_v2.RegisterLegacy(&Config{}, integrations_v2.TypeMultiplex, metricsutils.NewNamedShim("elasticsearch"))
}

// New creates a new elasticsearch_exporter
// This function replicates the main() function of github.com/justwatchcom/elasticsearch_exporter
// but uses yaml configuration instead of kingpin flags.
func New(logger log.Logger, c *Config) (integrations.Integration, error) {
	if c.Address == "" {
		return nil, fmt.Errorf("empty elasticsearch_address provided")
	}
	esURL, err := url.Parse(c.Address)
	if err != nil {
		return nil, fmt.Errorf("failed to parse elasticsearch_address: %w", err)
	}

	// returns nil if not provided and falls back to simple TCP.
	tlsConfig := createTLSConfig(c.CA, c.ClientCert, c.ClientPrivateKey, c.InsecureSkipVerify)

	httpClient := &http.Client{
		Timeout: c.Timeout,
		Transport: &http.Transport{
			TLSClientConfig: tlsConfig,
			Proxy:           http.ProxyFromEnvironment,
		},
	}

	clusterInfoRetriever := clusterinfo.New(logger, httpClient, esURL, c.ExportClusterInfoInterval)

	collectors := []prometheus.Collector{
		clusterInfoRetriever,
		collector.NewClusterHealth(logger, httpClient, esURL),
		collector.NewNodes(logger, httpClient, esURL, c.AllNodes, c.Node),
	}

	if c.ExportIndices || c.ExportShards {
		iC := collector.NewIndices(logger, httpClient, esURL, c.ExportShards)
		collectors = append(collectors, iC)
		if registerErr := clusterInfoRetriever.RegisterConsumer(iC); registerErr != nil {
			return nil, fmt.Errorf("failed to register indices collector in cluster info: %w", err)
		}
	}

	if c.ExportShards {
		collectors = append(collectors, collector.NewSnapshots(logger, httpClient, esURL))
	}

	if c.ExportClusterSettings {
		collectors = append(collectors, collector.NewClusterSettings(logger, httpClient, esURL))
	}

	if c.ExportIndicesSettings {
		collectors = append(collectors, collector.NewIndicesSettings(logger, httpClient, esURL))
	}

	start := func(ctx context.Context) error {
		// start the cluster info retriever
		switch runErr := clusterInfoRetriever.Run(ctx); runErr {
		case nil:
			level.Info(logger).Log(
				"msg", "started cluster info retriever",
				"interval", c.ExportClusterInfoInterval.String(),
			)
		case clusterinfo.ErrInitialCallTimeout:
			level.Info(logger).Log("msg", "initial cluster info call timed out")
		default:
			level.Error(logger).Log("msg", "failed to run cluster info retriever", "err", err)
			return err
		}

		// Wait until we're done
		<-ctx.Done()
		return ctx.Err()
	}

	return integrations.NewCollectorIntegration(c.Name(),
		integrations.WithCollectors(collectors...),
		integrations.WithRunner(start),
	), nil
}

'''
'''--- pkg/integrations/elasticsearch_exporter/tls.go ---
package elasticsearch_exporter //nolint:golint

import (
	"crypto/tls"
	"crypto/x509"
	"io/ioutil"
	"log"
)

// this file was copied as is from
// http://github.com/justwatchcom/elasticsearch_exporter/blob/c4c7d2bf2ed55725515dd27df4fd41b6c0b5c33c/tls.go

func createTLSConfig(pemFile, pemCertFile, pemPrivateKeyFile string, insecureSkipVerify bool) *tls.Config {
	tlsConfig := tls.Config{}
	if insecureSkipVerify {
		// pem settings are irrelevant if we're skipping verification anyway
		tlsConfig.InsecureSkipVerify = true
	}
	if len(pemFile) > 0 {
		rootCerts, err := loadCertificatesFrom(pemFile)
		if err != nil {
			log.Fatalf("Couldn't load root certificate from %s. Got %s.", pemFile, err)
			return nil
		}
		tlsConfig.RootCAs = rootCerts
	}
	if len(pemCertFile) > 0 && len(pemPrivateKeyFile) > 0 {
		clientPrivateKey, err := loadPrivateKeyFrom(pemCertFile, pemPrivateKeyFile)
		if err != nil {
			log.Fatalf("Couldn't setup client authentication. Got %s.", err)
			return nil
		}
		tlsConfig.Certificates = []tls.Certificate{*clientPrivateKey}
	}
	return &tlsConfig
}

func loadCertificatesFrom(pemFile string) (*x509.CertPool, error) {
	caCert, err := ioutil.ReadFile(pemFile)
	if err != nil {
		return nil, err
	}
	certificates := x509.NewCertPool()
	certificates.AppendCertsFromPEM(caCert)
	return certificates, nil
}

func loadPrivateKeyFrom(pemCertFile, pemPrivateKeyFile string) (*tls.Certificate, error) {
	privateKey, err := tls.LoadX509KeyPair(pemCertFile, pemPrivateKeyFile)
	if err != nil {
		return nil, err
	}
	return &privateKey, nil
}

'''
'''--- pkg/integrations/github_exporter/github_exporter.go ---
package github_exporter //nolint:golint

import (
	"fmt"
	"net/url"

	"github.com/go-kit/log"
	"github.com/go-kit/log/level"
	"github.com/grafana/agent/pkg/integrations"
	integrations_v2 "github.com/grafana/agent/pkg/integrations/v2"
	"github.com/grafana/agent/pkg/integrations/v2/metricsutils"
	gh_config "github.com/infinityworks/github-exporter/config"
	"github.com/infinityworks/github-exporter/exporter"
	config_util "github.com/prometheus/common/config"
)

// DefaultConfig holds the default settings for the github_exporter integration
var DefaultConfig = Config{
	APIURL: "https://api.github.com",
}

// Config controls github_exporter
type Config struct {
	// URL for the github API
	APIURL string `yaml:"api_url,omitempty"`

	// A list of github repositories for which to collect metrics.
	Repositories []string `yaml:"repositories,omitempty"`

	// A list of github organizations for which to collect metrics.
	Organizations []string `yaml:"organizations,omitempty"`

	// A list of github users for which to collect metrics.
	Users []string `yaml:"users,omitempty"`

	// A github authentication token that allows the API to be queried more often.
	APIToken config_util.Secret `yaml:"api_token,omitempty"`

	// A path to a file containing a github authentication token that allows the API to be queried more often. If supplied, this supercedes `api_token`
	APITokenFile string `yaml:"api_token_file,omitempty"`
}

// UnmarshalYAML implements yaml.Unmarshaler for Config
func (c *Config) UnmarshalYAML(unmarshal func(interface{}) error) error {
	*c = DefaultConfig

	type plain Config
	return unmarshal((*plain)(c))
}

// Name returns the name of the integration that this config represents.
func (c *Config) Name() string {
	return "github_exporter"
}

// InstanceKey returns the hostname:port of the GitHub API server.
func (c *Config) InstanceKey(agentKey string) (string, error) {
	u, err := url.Parse(c.APIURL)
	if err != nil {
		return "", fmt.Errorf("could not parse url: %w", err)
	}
	return u.Host, nil
}

// NewIntegration creates a new github_exporter
func (c *Config) NewIntegration(logger log.Logger) (integrations.Integration, error) {
	return New(logger, c)
}

func init() {
	integrations.RegisterIntegration(&Config{})
	integrations_v2.RegisterLegacy(&Config{}, integrations_v2.TypeMultiplex, metricsutils.NewNamedShim("github"))
}

// New creates a new github_exporter integration.
func New(logger log.Logger, c *Config) (integrations.Integration, error) {
	conf := gh_config.Config{}
	err := conf.SetAPIURL(c.APIURL)
	if err != nil {
		level.Error(logger).Log("msg", "api url is invalid", "err", err)
		return nil, err
	}
	conf.SetRepositories(c.Repositories)
	conf.SetOrganisations(c.Organizations)
	conf.SetUsers(c.Users)
	if c.APIToken != "" {
		conf.SetAPIToken(string(c.APIToken))
	}
	if c.APITokenFile != "" {
		err = conf.SetAPITokenFromFile(c.APITokenFile)
		if err != nil {
			level.Error(logger).Log("msg", "unable to load Github API token from file", "err", err)
			return nil, err
		}
	}

	ghExporter := exporter.Exporter{
		APIMetrics: exporter.AddMetrics(),
		Config:     conf,
	}

	return integrations.NewCollectorIntegration(
		c.Name(),
		integrations.WithCollectors(&ghExporter),
	), nil
}

'''
'''--- pkg/integrations/github_exporter/github_test.go ---
package github_exporter //nolint:golint

import (
	"testing"

	"github.com/grafana/agent/pkg/config"
	// register github_exporter
)

func TestConfig_SecretGithub(t *testing.T) {
	stringCfg := `
prometheus:
  wal_directory: /tmp/agent
integrations:
  github_exporter:
    enabled: true
    api_token: secret_api`
	config.CheckSecret(t, stringCfg, "secret_api")
}

'''
'''--- pkg/integrations/handler_integration.go ---
package integrations

import (
	"context"
	"net/http"

	"github.com/grafana/agent/pkg/integrations/config"
)

// NewHandlerIntegration creates a new named integration that will call handler
// when metrics are needed.
func NewHandlerIntegration(name string, handler http.Handler) Integration {
	return &handlerIntegration{name: name, handler: handler}
}

type handlerIntegration struct {
	name    string
	handler http.Handler
}

func (hi *handlerIntegration) MetricsHandler() (http.Handler, error) {
	return hi.handler, nil
}

func (hi *handlerIntegration) ScrapeConfigs() []config.ScrapeConfig {
	return []config.ScrapeConfig{{
		JobName:     hi.name,
		MetricsPath: "/metrics",
	}}
}

func (hi *handlerIntegration) Run(ctx context.Context) error {
	<-ctx.Done()
	return nil
}

'''
'''--- pkg/integrations/install/install.go ---
// Package install registers all in-source integrations for use.
package install

import (
	//
	// v1 integrations
	//

	_ "github.com/grafana/agent/pkg/integrations/agent"                  // register agent
	_ "github.com/grafana/agent/pkg/integrations/apache_http"            // regisapache_httprter
	_ "github.com/grafana/agent/pkg/integrations/cadvisor"               // register cadvisor
	_ "github.com/grafana/agent/pkg/integrations/consul_exporter"        // register consul_exporter
	_ "github.com/grafana/agent/pkg/integrations/dnsmasq_exporter"       // register dnsmasq_exporter
	_ "github.com/grafana/agent/pkg/integrations/ebpf_exporter"          // register ebpf_exporter
	_ "github.com/grafana/agent/pkg/integrations/elasticsearch_exporter" // register elasticsearch_exporter
	_ "github.com/grafana/agent/pkg/integrations/github_exporter"        // register github_exporter
	_ "github.com/grafana/agent/pkg/integrations/kafka_exporter"         // register kafka_exporter
	_ "github.com/grafana/agent/pkg/integrations/memcached_exporter"     // register memcached_exporter
	_ "github.com/grafana/agent/pkg/integrations/mongodb_exporter"       // register mongodb_exporter
	_ "github.com/grafana/agent/pkg/integrations/mysqld_exporter"        // register mysqld_exporter
	_ "github.com/grafana/agent/pkg/integrations/node_exporter"          // register node_exporter
	_ "github.com/grafana/agent/pkg/integrations/postgres_exporter"      // register postgres_exporter
	_ "github.com/grafana/agent/pkg/integrations/process_exporter"       // register process_exporter
	_ "github.com/grafana/agent/pkg/integrations/redis_exporter"         // register redis_exporter
	_ "github.com/grafana/agent/pkg/integrations/snmp_exporter"          // register snmp_exporter
	_ "github.com/grafana/agent/pkg/integrations/statsd_exporter"        // register statsd_exporter
	_ "github.com/grafana/agent/pkg/integrations/windows_exporter"       // register windows_exporter

	//
	// v2 integrations
	//

	_ "github.com/grafana/agent/pkg/integrations/v2/agent" // register agent
	_ "github.com/grafana/agent/pkg/integrations/v2/apache_http"
	_ "github.com/grafana/agent/pkg/integrations/v2/app_agent_receiver" // register app_agent_receiver
	_ "github.com/grafana/agent/pkg/integrations/v2/eventhandler"
	_ "github.com/grafana/agent/pkg/integrations/v2/snmp_exporter"
	_ "github.com/grafana/agent/pkg/integrations/v2/vmware_exporter"
)

'''
'''--- pkg/integrations/install/install_test.go ---
package install

import (
	"fmt"
	"strings"
	"testing"

	v1 "github.com/grafana/agent/pkg/integrations"
	v2 "github.com/grafana/agent/pkg/integrations/v2"
	"github.com/stretchr/testify/require"
)

// TestV1_Shims ensures that every v1 integration has a v2 counterpart.
func TestV1_Shims(t *testing.T) {
	var (
		v2Integrations      = make(map[string]v2.Config) // Native v2 integrations
		shimmedIntegrations = make(map[string]v1.Config) // Shimmed v1 integrations
	)

	for _, v2Integration := range v2.Registered() {
		uc, ok := v2Integration.(v2.UpgradedConfig)
		if !ok {
			v2Integrations[v2Integration.Name()] = v2Integration
			continue
		}

		v1Integration, _ := uc.LegacyConfig()
		shimmedIntegrations[v1Integration.Name()] = v1Integration
	}

	for _, v1Integration := range v1.RegisteredIntegrations() {
		t.Run(v1Integration.Name(), func(t *testing.T) {
			_, v2Native := v2Integrations[v1Integration.Name()]
			_, shimmed := shimmedIntegrations[v1Integration.Name()]
			require.True(t, shimmed || v2Native, "integration not shimmed to v2 or does not have a native counterpart")
		})
	}
}

// TestV2_NoExporterSuffix ensures that v2 integrations do not have a name
// ending in _exporter. The test may be updated to exclude specific
// integrations from this requirement.
func TestV2_NoExporterSuffix(t *testing.T) {
	exceptions := map[string]struct{}{
		"node_exporter": {}, // node_exporter is an exception because its name is well-understood
	}

	var invalidNames []string

	for _, v2Integration := range v2.Registered() {
		name := v2Integration.Name()
		if _, excluded := exceptions[name]; excluded {
			continue
		}

		if strings.HasSuffix(name, "_exporter") {
			invalidNames = append(invalidNames, name)
		}
	}

	if len(invalidNames) > 0 {
		require.FailNow(
			t,
			"Found v2 integrations named with unexpected _exporter suffix",
			fmt.Sprintf("The following integrations must not end in _exporter: %s. Either drop the suffix or add them as an exception in this test.", strings.Join(invalidNames, ", ")),
		)
	}
}

'''
'''--- pkg/integrations/integration.go ---
package integrations

import (
	"context"
	"net/http"

	"github.com/go-kit/log"
	"github.com/grafana/agent/pkg/integrations/config"
)

// Config provides the configuration and constructor for an integration.
type Config interface {
	// Name returns the name of the integration and the key that will be used to
	// pull the configuration from the Agent config YAML.
	Name() string

	// InstanceKey should return the key the reprsents the config, which will be
	// used to populate the value of the `instance` label for metrics.
	//
	// InstanceKey is given an agentKey that represents the agent process. This
	// may be used if the integration being configured applies to an entire
	// machine.
	//
	// This method may not be invoked if the instance key for a Config is
	// overridden.
	InstanceKey(agentKey string) (string, error)

	// NewIntegration returns an integration for the given with the given logger.
	NewIntegration(l log.Logger) (Integration, error)
}

// An Integration is a process that integrates with some external system and
// pulls telemetry data.
type Integration interface {
	// MetricsHandler returns an http.Handler that will return metrics.
	MetricsHandler() (http.Handler, error)

	// ScrapeConfigs returns a set of scrape configs that determine where metrics
	// can be scraped.
	ScrapeConfigs() []config.ScrapeConfig

	// Run should start the integration and do any required tasks, if necessary.
	// For example, an Integration that requires a persistent connection to a
	// database would establish that connection here. If the integration doesn't
	// need to do anything, it should wait for the ctx to be canceled.
	//
	// An error will be returned if the integration failed. Integrations should
	// not return the ctx error.
	Run(ctx context.Context) error
}

'''
'''--- pkg/integrations/kafka_exporter/kafka_exporter.go ---
package kafka_exporter //nolint:golint

import (
	"fmt"

	config_util "github.com/prometheus/common/config"

	"github.com/Shopify/sarama"
	kafka_exporter "github.com/davidmparrott/kafka_exporter/v2/exporter"
	"github.com/go-kit/log"
	"github.com/grafana/agent/pkg/integrations"
	integrations_v2 "github.com/grafana/agent/pkg/integrations/v2"
	"github.com/grafana/agent/pkg/integrations/v2/metricsutils"
)

// DefaultConfig holds the default settings for the kafka_lag_exporter
// integration.
var DefaultConfig = Config{
	UseSASLHandshake:        true,
	KafkaVersion:            sarama.V2_0_0_0.String(),
	MetadataRefreshInterval: "1m",
	AllowConcurrent:         true,
	MaxOffsets:              1000,
	PruneIntervalSeconds:    30,
	TopicsFilter:            ".*",
	GroupFilter:             ".*",
}

// Config controls kafka_exporter
type Config struct {
	// Address array (host:port) of Kafka server
	KafkaURIs []string `yaml:"kafka_uris,omitempty"`

	// Connect using SASL/PLAIN
	UseSASL bool `yaml:"use_sasl,omitempty"`

	// Only set this to false if using a non-Kafka SASL proxy
	UseSASLHandshake bool `yaml:"use_sasl_handshake,omitempty"`

	// SASL user name
	SASLUsername string `yaml:"sasl_username,omitempty"`

	// SASL user password
	SASLPassword config_util.Secret `yaml:"sasl_password,omitempty"`

	// The SASL SCRAM SHA algorithm sha256 or sha512 as mechanism
	SASLMechanism string `yaml:"sasl_mechanism,omitempty"`

	// Connect using TLS
	UseTLS bool `yaml:"use_tls,omitempty"`

	// The optional certificate authority file for TLS client authentication
	CAFile string `yaml:"ca_file,omitempty"`

	// The optional certificate file for TLS client authentication
	CertFile string `yaml:"cert_file,omitempty"`

	// The optional key file for TLS client authentication
	KeyFile string `yaml:"key_file,omitempty"`

	// If true, the server's certificate will not be checked for validity. This will make your HTTPS connections insecure
	InsecureSkipVerify bool `yaml:"insecure_skip_verify,omitempty"`

	// Kafka broker version
	KafkaVersion string `yaml:"kafka_version,omitempty"`

	// if you need to use a group from zookeeper
	UseZooKeeperLag bool `yaml:"use_zookeeper_lag,omitempty"`

	// Address array (hosts) of zookeeper server.
	ZookeeperURIs []string `yaml:"zookeeper_uris,omitempty"`

	// Kafka cluster name
	ClusterName string `yaml:"kafka_cluster_name,omitempty"`

	// Metadata refresh interval
	MetadataRefreshInterval string `yaml:"metadata_refresh_interval,omitempty"`

	// If true, all scrapes will trigger kafka operations otherwise, they will share results. WARN: This should be disabled on large clusters
	AllowConcurrent bool `yaml:"allow_concurrency,omitempty"`

	// Maximum number of offsets to store in the interpolation table for a partition
	MaxOffsets int `yaml:"max_offsets,omitempty"`

	// How frequently should the interpolation table be pruned, in seconds
	PruneIntervalSeconds int `yaml:"prune_interval_seconds,omitempty"`

	// Regex filter for topics to be monitored
	TopicsFilter string `yaml:"topics_filter_regex,omitempty"`

	// Regex filter for consumer groups to be monitored
	GroupFilter string `yaml:"groups_filter_regex,omitempty"`
}

// UnmarshalYAML implements yaml.Unmarshaler for Config
func (c *Config) UnmarshalYAML(unmarshal func(interface{}) error) error {
	*c = DefaultConfig

	type plain Config
	return unmarshal((*plain)(c))
}

// Name returns the name of the integration that this config represents.
func (c *Config) Name() string {
	return "kafka_exporter"
}

// InstanceKey returns the hostname:port of the first Kafka node, if any. If
// there is not exactly one Kafka node, the user must manually provide
// their own value for instance key in the common config.
func (c *Config) InstanceKey(agentKey string) (string, error) {
	if len(c.KafkaURIs) != 1 {
		return "", fmt.Errorf("an automatic value for `instance` cannot be determined from %d kafka servers, manually provide one for this integration", len(c.KafkaURIs))
	}

	return c.KafkaURIs[0], nil
}

// NewIntegration creates a new elasticsearch_exporter
func (c *Config) NewIntegration(logger log.Logger) (integrations.Integration, error) {
	return New(logger, c)
}

func init() {
	integrations.RegisterIntegration(&Config{})
	integrations_v2.RegisterLegacy(&Config{}, integrations_v2.TypeMultiplex, metricsutils.NewNamedShim("kafka"))
}

// New creates a new kafka_exporter integration.
func New(logger log.Logger, c *Config) (integrations.Integration, error) {
	if len(c.KafkaURIs) == 0 || c.KafkaURIs[0] == "" {
		return nil, fmt.Errorf("empty kafka_uris provided")
	}
	if c.UseTLS && (c.CertFile == "" || c.KeyFile == "") {
		return nil, fmt.Errorf("tls is enabled but key pair was not provided")
	}
	if c.UseSASL && (c.SASLPassword == "" || c.SASLUsername == "") {
		return nil, fmt.Errorf("SASL is enabled but username or password was not provided")
	}
	if c.UseZooKeeperLag && (len(c.ZookeeperURIs) == 0 || c.ZookeeperURIs[0] == "") {
		return nil, fmt.Errorf("zookeeper lag is enabled but no zookeeper uri was provided")
	}

	options := kafka_exporter.Options{
		Uri:                      c.KafkaURIs,
		UseSASL:                  c.UseSASL,
		UseSASLHandshake:         c.UseSASLHandshake,
		SaslUsername:             c.SASLUsername,
		SaslPassword:             string(c.SASLPassword),
		SaslMechanism:            c.SASLMechanism,
		UseTLS:                   c.UseTLS,
		TlsCAFile:                c.CAFile,
		TlsCertFile:              c.CertFile,
		TlsKeyFile:               c.KeyFile,
		TlsInsecureSkipTLSVerify: c.InsecureSkipVerify,
		KafkaVersion:             c.KafkaVersion,
		UseZooKeeperLag:          c.UseZooKeeperLag,
		UriZookeeper:             c.ZookeeperURIs,
		Labels:                   c.ClusterName,
		MetadataRefreshInterval:  c.MetadataRefreshInterval,
		AllowConcurrent:          c.AllowConcurrent,
		MaxOffsets:               c.MaxOffsets,
		PruneIntervalSeconds:     c.PruneIntervalSeconds,
	}

	newExporter, err := kafka_exporter.New(logger, options, c.TopicsFilter, c.GroupFilter)
	if err != nil {
		return nil, fmt.Errorf("could not instantiate kafka lag exporter: %w", err)
	}

	return integrations.NewCollectorIntegration(
		c.Name(),
		integrations.WithCollectors(newExporter),
	), nil
}

'''
'''--- pkg/integrations/kafka_exporter/kafka_test.go ---
package kafka_exporter //nolint:golint

import (
	"testing"

	"github.com/grafana/agent/pkg/config"
)

func TestConfig_SecretKafkaPassword(t *testing.T) {
	stringCfg := `
prometheus:
  wal_directory: /tmp/agent
integrations:
  kafka_exporter:
    enabled: true
    sasl_password: secret_password
`
	config.CheckSecret(t, stringCfg, "secret_password")
}

'''
'''--- pkg/integrations/manager.go ---
package integrations

import (
	"context"
	"fmt"
	"net/http"
	"path"
	"strings"
	"sync"
	"time"

	config_util "github.com/prometheus/common/config"

	"github.com/go-kit/log"
	"github.com/go-kit/log/level"
	"github.com/gorilla/mux"
	"github.com/grafana/agent/pkg/metrics"
	"github.com/grafana/agent/pkg/metrics/instance"
	"github.com/grafana/agent/pkg/metrics/instance/configstore"
	"github.com/grafana/agent/pkg/server"
	"github.com/grafana/agent/pkg/util"
	"github.com/prometheus/client_golang/prometheus"
	"github.com/prometheus/client_golang/prometheus/promauto"
	"github.com/prometheus/common/model"
	promConfig "github.com/prometheus/prometheus/config"
	"github.com/prometheus/prometheus/discovery"
	"github.com/prometheus/prometheus/model/relabel"
)

var (
	integrationAbnormalExits = promauto.NewCounterVec(prometheus.CounterOpts{
		Name: "agent_metrics_integration_abnormal_exits_total",
		Help: "Total number of times an agent integration exited unexpectedly, causing it to be restarted.",
	}, []string{"integration_name"})
)

// DefaultManagerConfig holds the default settings for integrations.
var DefaultManagerConfig = ManagerConfig{
	ScrapeIntegrations:        true,
	IntegrationRestartBackoff: 5 * time.Second,

	// Deprecated fields which keep their previous defaults:
	UseHostnameLabel:     true,
	ReplaceInstanceLabel: true,
}

// ManagerConfig holds the configuration for all integrations.
type ManagerConfig struct {
	// When true, scrapes metrics from integrations.
	ScrapeIntegrations bool `yaml:"scrape_integrations,omitempty"`

	// The integration configs is merged with the manager config struct so we
	// don't want to export it here; we'll manually unmarshal it in UnmarshalYAML.
	Integrations Configs `yaml:"-"`

	// Extra labels to add for all integration samples
	Labels model.LabelSet `yaml:"labels,omitempty"`

	// Prometheus RW configs to use for all integrations.
	PrometheusRemoteWrite []*promConfig.RemoteWriteConfig `yaml:"prometheus_remote_write,omitempty"`

	IntegrationRestartBackoff time.Duration `yaml:"integration_restart_backoff,omitempty"`

	// ListenPort tells the integration Manager which port the Agent is
	// listening on for generating Prometheus instance configs.
	ListenPort int `yaml:"-"`

	// ListenHost tells the integration Manager which port the Agent is
	// listening on for generating Prometheus instance configs
	ListenHost string `yaml:"-"`

	TLSConfig config_util.TLSConfig `yaml:"http_tls_config,omitempty"`

	// This is set to true if the Server TLSConfig Cert and Key path are set
	ServerUsingTLS bool `yaml:"-"`

	// We use this config to check if we need to reload integrations or not
	// The Integrations Configs don't have prometheus defaults applied which
	// can cause us skip reload when scrape configs change
	PrometheusGlobalConfig promConfig.GlobalConfig `yaml:"-"`

	//
	// Deprecated and ignored fields.
	//

	ReplaceInstanceLabel bool `yaml:"replace_instance_label,omitempty"` // DEPRECATED, unused
	UseHostnameLabel     bool `yaml:"use_hostname_label,omitempty"`     // DEPRECATED, unused
}

// MarshalYAML implements yaml.Marshaler for ManagerConfig.
func (c ManagerConfig) MarshalYAML() (interface{}, error) {
	return MarshalYAML(c)
}

// UnmarshalYAML implements yaml.Unmarshaler for ManagerConfig.
func (c *ManagerConfig) UnmarshalYAML(unmarshal func(interface{}) error) error {
	*c = DefaultManagerConfig
	return UnmarshalYAML(c, unmarshal)
}

// DefaultRelabelConfigs returns the set of relabel configs that should be
// prepended to all RelabelConfigs for an integration.
func (c *ManagerConfig) DefaultRelabelConfigs(instanceKey string) []*relabel.Config {
	return []*relabel.Config{{
		SourceLabels: model.LabelNames{model.AddressLabel},
		Action:       relabel.Replace,
		Separator:    ";",
		Regex:        relabel.MustNewRegexp("(.*)"),
		Replacement:  instanceKey,
		TargetLabel:  model.InstanceLabel,
	}}
}

// ApplyDefaults applies default settings to the ManagerConfig and validates
// that it can be used.
//
// If any integrations are enabled and are configured to be scraped, the
// Prometheus configuration must have a WAL directory configured.
func (c *ManagerConfig) ApplyDefaults(sflags *server.Flags, mcfg *metrics.Config) error {
	host, port, err := sflags.HTTP.ListenHostPort()
	if err != nil {
		return fmt.Errorf("reading HTTP host:port: %w", err)
	}

	c.ListenHost = host
	c.ListenPort = port
	c.ServerUsingTLS = sflags.HTTP.UseTLS

	if len(c.PrometheusRemoteWrite) == 0 {
		c.PrometheusRemoteWrite = mcfg.Global.RemoteWrite
	}
	c.PrometheusGlobalConfig = mcfg.Global.Prometheus

	for _, ic := range c.Integrations {
		if !ic.Common.Enabled {
			continue
		}

		scrapeIntegration := c.ScrapeIntegrations
		if common := ic.Common; common.ScrapeIntegration != nil {
			scrapeIntegration = *common.ScrapeIntegration
		}

		// WAL must be configured if an integration is going to be scraped.
		if scrapeIntegration && mcfg.WALDir == "" {
			return fmt.Errorf("no wal_directory configured")
		}
	}

	return nil
}

// Manager manages a set of integrations and runs them.
type Manager struct {
	logger log.Logger

	cfgMut sync.RWMutex
	cfg    ManagerConfig

	hostname string

	ctx    context.Context
	cancel context.CancelFunc
	wg     sync.WaitGroup

	im        instance.Manager
	validator configstore.Validator

	integrationsMut sync.RWMutex
	integrations    map[string]*integrationProcess

	handlerMut   sync.Mutex
	handlerCache map[string]handlerCacheEntry
}

// NewManager creates a new integrations manager. NewManager must be given an
// InstanceManager which is responsible for accepting instance configs to
// scrape and send metrics from running integrations.
func NewManager(cfg ManagerConfig, logger log.Logger, im instance.Manager, validate configstore.Validator) (*Manager, error) {
	ctx, cancel := context.WithCancel(context.Background())

	m := &Manager{
		logger: logger,

		ctx:    ctx,
		cancel: cancel,

		im:        im,
		validator: validate,

		integrations: make(map[string]*integrationProcess, len(cfg.Integrations)),

		handlerCache: make(map[string]handlerCacheEntry),
	}

	var err error
	m.hostname, err = instance.Hostname()
	if err != nil {
		return nil, err
	}

	if err := m.ApplyConfig(cfg); err != nil {
		return nil, fmt.Errorf("failed applying config: %w", err)
	}
	return m, nil
}

// ApplyConfig updates the configuration of the integrations subsystem.
func (m *Manager) ApplyConfig(cfg ManagerConfig) error {
	var failed bool

	m.cfgMut.Lock()
	defer m.cfgMut.Unlock()

	m.integrationsMut.Lock()
	defer m.integrationsMut.Unlock()

	// The global prometheus config settings don't get applied to integrations until later. This
	// causes us to skip reload when those settings change.
	if util.CompareYAML(m.cfg, cfg) && util.CompareYAML(m.cfg.PrometheusGlobalConfig, cfg.PrometheusGlobalConfig) {
		level.Debug(m.logger).Log("msg", "Integrations config is unchanged skipping apply")
		return nil
	}
	level.Debug(m.logger).Log("msg", "Applying integrations config changes")

	select {
	case <-m.ctx.Done():
		return fmt.Errorf("Manager already stopped")
	default:
		// No-op
	}

	// Iterate over our integrations. New or changed integrations will be
	// started, with their existing counterparts being shut down.
	for _, ic := range cfg.Integrations {
		if !ic.Common.Enabled {
			continue
		}
		// Key is used to identify the instance of this integration within the
		// instance manager and within our set of running integrations.
		key := integrationKey(ic.Name())

		// Look for an existing integration with the same key. If it exists and
		// is unchanged, we have nothing to do. Otherwise, we're going to recreate
		// it with the new settings, so we'll need to stop it.
		if p, exist := m.integrations[key]; exist {
			if util.CompareYAML(p.cfg, ic) {
				continue
			}
			p.stop()
			delete(m.integrations, key)
		}

		l := log.With(m.logger, "integration", ic.Name())
		i, err := ic.NewIntegration(l)
		if err != nil {
			level.Error(m.logger).Log("msg", "failed to initialize integration. it will not run or be scraped", "integration", ic.Name(), "err", err)
			failed = true

			// If this integration was running before, its instance won't be cleaned
			// up since it's now removed from the map. We need to clean it up here.
			_ = m.im.DeleteConfig(key)
			continue
		}

		// Find what instance label should be used to represent this integration.
		var instanceKey string
		if kp := ic.Common.InstanceKey; kp != nil {
			// Common config takes precedence.
			instanceKey = strings.TrimSpace(*kp)
		} else {
			instanceKey, err = ic.InstanceKey(fmt.Sprintf("%s:%d", m.hostname, cfg.ListenPort))
			if err != nil {
				level.Error(m.logger).Log("msg", "failed to get instance key for integration. it will not run or be scraped", "integration", ic.Name(), "err", err)
				failed = true

				// If this integration was running before, its instance won't be cleaned
				// up since it's now removed from the map. We need to clean it up here.
				_ = m.im.DeleteConfig(key)
				continue
			}
		}

		// Create, start, and register the new integration.
		ctx, cancel := context.WithCancel(m.ctx)
		p := &integrationProcess{
			log:         m.logger,
			cfg:         ic,
			i:           i,
			instanceKey: instanceKey,

			ctx:  ctx,
			stop: cancel,

			wg:   &m.wg,
			wait: m.instanceBackoff,
		}
		go p.Run()
		m.integrations[key] = p
	}

	// Delete instances and processed that have been removed in between calls to
	// ApplyConfig.
	for key, process := range m.integrations {
		foundConfig := false
		for _, ic := range cfg.Integrations {
			if integrationKey(ic.Name()) == key {
				// If this is disabled then we should delete from integrations
				if !ic.Common.Enabled {
					break
				}
				foundConfig = true
				break
			}
		}
		if foundConfig {
			continue
		}

		_ = m.im.DeleteConfig(key)
		process.stop()
		delete(m.integrations, key)
	}

	// Re-apply configs to our instance manager for all running integrations.
	// Generated scrape configs may change in between calls to ApplyConfig even
	// if the configs for the integration didn't.
	for key, p := range m.integrations {
		shouldCollect := cfg.ScrapeIntegrations
		if common := p.cfg.Common; common.ScrapeIntegration != nil {
			shouldCollect = *common.ScrapeIntegration
		}

		switch shouldCollect {
		case true:
			instanceConfig := m.instanceConfigForIntegration(p, cfg)
			if err := m.validator(&instanceConfig); err != nil {
				level.Error(p.log).Log("msg", "failed to validate generated scrape config for integration. integration will not be scraped", "err", err, "integration", p.cfg.Name())
				failed = true
				break
			}

			if err := m.im.ApplyConfig(instanceConfig); err != nil {
				level.Error(p.log).Log("msg", "failed to apply integration. integration will not be scraped", "err", err, "integration", p.cfg.Name())
				failed = true
			}
		case false:
			// If a previous instance of the config was being scraped, we need to
			// delete it here. Calling DeleteConfig when nothing is running is a safe
			// operation.
			_ = m.im.DeleteConfig(key)
		}
	}

	m.cfg = cfg

	if failed {
		return fmt.Errorf("not all integrations were correctly updated")
	}
	return nil
}

// integrationProcess is a running integration.
type integrationProcess struct {
	log         log.Logger
	ctx         context.Context
	stop        context.CancelFunc
	cfg         UnmarshaledConfig
	instanceKey string // Value for the `instance` label
	i           Integration

	wg   *sync.WaitGroup
	wait func(cfg Config, err error)
}

// Run runs the integration until the process is canceled.
func (p *integrationProcess) Run() {
	defer func() {
		if r := recover(); r != nil {
			err := fmt.Errorf("%v", r)
			level.Error(p.log).Log("msg", "integration has panicked. THIS IS A BUG!", "err", err, "integration", p.cfg.Name())
		}
	}()

	p.wg.Add(1)
	defer p.wg.Done()

	for {
		err := p.i.Run(p.ctx)
		if err != nil && err != context.Canceled {
			p.wait(p.cfg, err)
		} else {
			level.Info(p.log).Log("msg", "stopped integration", "integration", p.cfg.Name())
			break
		}
	}
}

func (m *Manager) instanceBackoff(cfg Config, err error) {
	m.cfgMut.RLock()
	defer m.cfgMut.RUnlock()

	integrationAbnormalExits.WithLabelValues(cfg.Name()).Inc()
	level.Error(m.logger).Log("msg", "integration stopped abnormally, restarting after backoff", "err", err, "integration", cfg.Name(), "backoff", m.cfg.IntegrationRestartBackoff)
	time.Sleep(m.cfg.IntegrationRestartBackoff)
}

func (m *Manager) instanceConfigForIntegration(p *integrationProcess, cfg ManagerConfig) instance.Config {
	common := p.cfg.Common
	relabelConfigs := append(cfg.DefaultRelabelConfigs(p.instanceKey), common.RelabelConfigs...)

	schema := "http"
	// Check for HTTPS support
	var httpClientConfig config_util.HTTPClientConfig
	if cfg.ServerUsingTLS {
		schema = "https"
		httpClientConfig.TLSConfig = cfg.TLSConfig
	}

	var scrapeConfigs []*promConfig.ScrapeConfig

	for _, isc := range p.i.ScrapeConfigs() {
		sc := &promConfig.ScrapeConfig{
			JobName:                 fmt.Sprintf("integrations/%s", isc.JobName),
			MetricsPath:             path.Join("/integrations", p.cfg.Name(), isc.MetricsPath),
			Params:                  isc.QueryParams,
			Scheme:                  schema,
			HonorLabels:             false,
			HonorTimestamps:         true,
			ScrapeInterval:          model.Duration(common.ScrapeInterval),
			ScrapeTimeout:           model.Duration(common.ScrapeTimeout),
			ServiceDiscoveryConfigs: m.scrapeServiceDiscovery(cfg),
			RelabelConfigs:          relabelConfigs,
			MetricRelabelConfigs:    common.MetricRelabelConfigs,
			HTTPClientConfig:        httpClientConfig,
		}

		scrapeConfigs = append(scrapeConfigs, sc)
	}

	instanceCfg := instance.DefaultConfig
	instanceCfg.Name = integrationKey(p.cfg.Name())
	instanceCfg.ScrapeConfigs = scrapeConfigs
	instanceCfg.RemoteWrite = cfg.PrometheusRemoteWrite
	if common.WALTruncateFrequency > 0 {
		instanceCfg.WALTruncateFrequency = common.WALTruncateFrequency
	}
	return instanceCfg
}

// integrationKey returns the key for an integration Config, used for its
// instance name and name in the process cache.
func integrationKey(name string) string {
	return fmt.Sprintf("integration/%s", name)
}

func (m *Manager) scrapeServiceDiscovery(cfg ManagerConfig) discovery.Configs {
	// A blank host somehow works, but it then requires a sever name to be set under tls.
	newHost := cfg.ListenHost
	if newHost == "" {
		newHost = "127.0.0.1"
	}
	localAddr := fmt.Sprintf("%s:%d", newHost, cfg.ListenPort)
	labels := model.LabelSet{}
	labels[model.LabelName("agent_hostname")] = model.LabelValue(m.hostname)
	for k, v := range cfg.Labels {
		labels[k] = v
	}

	return discovery.Configs{
		discovery.StaticConfig{{
			Targets: []model.LabelSet{{model.AddressLabel: model.LabelValue(localAddr)}},
			Labels:  labels,
		}},
	}
}

// WireAPI hooks up /metrics routes per-integration.
func (m *Manager) WireAPI(r *mux.Router) {
	r.HandleFunc("/integrations/{name}/metrics", func(rw http.ResponseWriter, r *http.Request) {
		m.integrationsMut.RLock()
		defer m.integrationsMut.RUnlock()

		key := integrationKey(mux.Vars(r)["name"])
		handler := m.loadHandler(key)
		handler.ServeHTTP(rw, r)
	})
}

// loadHandler will perform a dynamic lookup of an HTTP handler for an
// integration. loadHandler should be called with a read lock on the
// integrations mutex.
func (m *Manager) loadHandler(key string) http.Handler {
	m.handlerMut.Lock()
	defer m.handlerMut.Unlock()

	// Search the integration by name to see if it's still running.
	p, ok := m.integrations[key]
	if !ok {
		delete(m.handlerCache, key)
		return http.NotFoundHandler()
	}

	// Now look in the cache for a handler for the running process.
	cacheEntry, ok := m.handlerCache[key]
	if ok && cacheEntry.process == p {
		return cacheEntry.handler
	}

	// New integration process that hasn't been scraped before. Generate
	// a handler for it and cache it.
	handler, err := p.i.MetricsHandler()
	if err != nil {
		level.Error(m.logger).Log("msg", "could not create http handler for integration", "integration", p.cfg.Name(), "err", err)
		return http.HandlerFunc(internalServiceError)
	}

	cacheEntry = handlerCacheEntry{handler: handler, process: p}
	m.handlerCache[key] = cacheEntry
	return cacheEntry.handler
}

func internalServiceError(w http.ResponseWriter, r *http.Request) {
	http.Error(w, "500 Internal Server Error", http.StatusInternalServerError)
}

// Stop stops the manager and all of its integrations. Blocks until all running
// integrations exit.
func (m *Manager) Stop() {
	m.cancel()
	m.wg.Wait()
}

type handlerCacheEntry struct {
	handler http.Handler
	process *integrationProcess
}

'''
'''--- pkg/integrations/manager_test.go ---
package integrations

import (
	"context"
	"fmt"
	"net/http"
	"testing"
	"time"

	"github.com/cortexproject/cortex/pkg/util/test"
	"github.com/go-kit/log"
	"github.com/grafana/agent/pkg/integrations/config"
	"github.com/grafana/agent/pkg/metrics/instance"
	"github.com/prometheus/client_golang/prometheus/promhttp"
	"github.com/prometheus/common/model"
	promConfig "github.com/prometheus/prometheus/config"
	"github.com/prometheus/prometheus/model/labels"
	"github.com/prometheus/prometheus/model/relabel"
	"github.com/stretchr/testify/require"
	"go.uber.org/atomic"
	"gopkg.in/yaml.v2"
)

const mockIntegrationName = "integration/mock"

func noOpValidator(*instance.Config) error { return nil }

// TestConfig_MarshalEmptyIntegrations ensures that an empty set of integrations
// can be marshaled correctly.
func TestConfig_MarshalEmptyIntegrations(t *testing.T) {
	cfgText := `
scrape_integrations: true
replace_instance_label: true
integration_restart_backoff: 5s
use_hostname_label: true
`
	var (
		cfg        ManagerConfig
		listenPort = 12345
		listenHost = "127.0.0.1"
	)
	require.NoError(t, yaml.Unmarshal([]byte(cfgText), &cfg))

	// Listen port must be set before applying defaults. Normally applied by the
	// config package.
	cfg.ListenPort = listenPort
	cfg.ListenHost = listenHost

	outBytes, err := yaml.Marshal(cfg)
	require.NoError(t, err, "Failed creating integration")
	require.YAMLEq(t, cfgText, string(outBytes))
}

// Test that embedded integration fields in the struct can be unmarshaled and
// remarshaled back out to text.
func TestConfig_Remarshal(t *testing.T) {
	RegisterIntegration(&testIntegrationA{})
	cfgText := `
scrape_integrations: true
replace_instance_label: true
integration_restart_backoff: 5s
use_hostname_label: true
test:
  text: Hello, world!
  truth: true
`
	var (
		cfg        ManagerConfig
		listenPort = 12345
		listenHost = "127.0.0.1"
	)
	require.NoError(t, yaml.Unmarshal([]byte(cfgText), &cfg))

	// Listen port must be set before applying defaults. Normally applied by the
	// config package.
	cfg.ListenPort = listenPort
	cfg.ListenHost = listenHost

	outBytes, err := yaml.Marshal(cfg)
	require.NoError(t, err, "Failed creating integration")
	require.YAMLEq(t, cfgText, string(outBytes))
}

func TestConfig_AddressRelabels(t *testing.T) {
	cfgText := `
agent:
  enabled: true
`

	var (
		cfg        ManagerConfig
		listenPort = 12345
		listenHost = "127.0.0.1"
	)
	require.NoError(t, yaml.Unmarshal([]byte(cfgText), &cfg))

	// Listen port must be set before applying defaults. Normally applied by the
	// config package.
	cfg.ListenPort = listenPort
	cfg.ListenHost = listenHost

	expectHostname, _ := instance.Hostname()
	relabels := cfg.DefaultRelabelConfigs(expectHostname + ":12345")

	// Ensure that the relabel configs are functional
	require.Len(t, relabels, 1)
	result := relabel.Process(labels.FromStrings("__address__", "127.0.0.1"), relabels...)

	require.Equal(t, result.Get("instance"), expectHostname+":12345")
}

func TestManager_instanceConfigForIntegration(t *testing.T) {
	mock := newMockIntegration()
	icfg := mockConfig{Integration: mock}

	im := instance.NewBasicManager(instance.DefaultBasicManagerConfig, log.NewNopLogger(), mockInstanceFactory)
	m, err := NewManager(mockManagerConfig(), log.NewNopLogger(), im, noOpValidator)
	require.NoError(t, err)
	defer m.Stop()

	p := &integrationProcess{instanceKey: "key", cfg: makeUnmarshaledConfig(icfg, true), i: mock}
	cfg := m.instanceConfigForIntegration(p, mockManagerConfig())

	// Validate that the generated MetricsPath is a valid URL path
	require.Len(t, cfg.ScrapeConfigs, 1)
	require.Equal(t, "/integrations/mock/metrics", cfg.ScrapeConfigs[0].MetricsPath)
}

func makeUnmarshaledConfig(cfg Config, enabled bool) UnmarshaledConfig {
	return UnmarshaledConfig{Config: cfg, Common: config.Common{Enabled: enabled}}
}

// TestManager_NoIntegrationsScrape ensures that configs don't get generates
// when the ScrapeIntegrations flag is disabled.
func TestManager_NoIntegrationsScrape(t *testing.T) {
	mock := newMockIntegration()
	icfg := mockConfig{Integration: mock}

	im := instance.NewBasicManager(instance.DefaultBasicManagerConfig, log.NewNopLogger(), mockInstanceFactory)

	cfg := mockManagerConfig()
	cfg.ScrapeIntegrations = false
	cfg.Integrations = append(cfg.Integrations, makeUnmarshaledConfig(&icfg, true))

	m, err := NewManager(cfg, log.NewNopLogger(), im, noOpValidator)
	require.NoError(t, err)
	defer m.Stop()

	// Normally we'd use test.Poll here, but since im.ListConfigs starts out with a
	// length of zero, test.Poll would immediately pass. Instead we want to wait for a
	// bit to make sure that the length of ListConfigs doesn't become non-zero.
	time.Sleep(time.Second)
	require.Zero(t, len(im.ListConfigs()))
}

// TestManager_NoIntegrationScrape ensures that configs don't get generates
// when the ScrapeIntegration flag is disabled on the integration.
func TestManager_NoIntegrationScrape(t *testing.T) {
	mock := newMockIntegration()
	icfg := mockConfig{Integration: mock}
	noScrape := false

	im := instance.NewBasicManager(instance.DefaultBasicManagerConfig, log.NewNopLogger(), mockInstanceFactory)

	cfg := mockManagerConfig()
	cfg.Integrations = append(cfg.Integrations, UnmarshaledConfig{
		Config: icfg,
		Common: config.Common{ScrapeIntegration: &noScrape},
	})

	m, err := NewManager(cfg, log.NewNopLogger(), im, noOpValidator)
	require.NoError(t, err)
	defer m.Stop()

	time.Sleep(time.Second)
	require.Zero(t, len(im.ListConfigs()))
}

// TestManager_StartsIntegrations tests that, when given an integration to
// launch, TestManager applies a config and runs the integration.
func TestManager_StartsIntegrations(t *testing.T) {
	mock := newMockIntegration()
	icfg := mockConfig{Integration: mock}

	cfg := mockManagerConfig()
	cfg.Integrations = append(cfg.Integrations, makeUnmarshaledConfig(icfg, true))

	im := instance.NewBasicManager(instance.DefaultBasicManagerConfig, log.NewNopLogger(), mockInstanceFactory)
	m, err := NewManager(cfg, log.NewNopLogger(), im, noOpValidator)
	require.NoError(t, err)
	defer m.Stop()

	test.Poll(t, time.Second, 1, func() interface{} {
		return len(im.ListConfigs())
	})

	// Check that the instance was set to run
	test.Poll(t, time.Second, 1, func() interface{} {
		return int(mock.startedCount.Load())
	})
}

func TestManager_RestartsIntegrations(t *testing.T) {
	mock := newMockIntegration()
	icfg := mockConfig{Integration: mock}

	cfg := mockManagerConfig()
	cfg.Integrations = append(cfg.Integrations, makeUnmarshaledConfig(icfg, true))

	im := instance.NewBasicManager(instance.DefaultBasicManagerConfig, log.NewNopLogger(), mockInstanceFactory)
	m, err := NewManager(cfg, log.NewNopLogger(), im, noOpValidator)
	require.NoError(t, err)
	defer m.Stop()

	mock.err <- fmt.Errorf("I can't believe this horrible error happened")

	test.Poll(t, time.Second, 2, func() interface{} {
		return int(mock.startedCount.Load())
	})
}

func TestManager_GracefulStop(t *testing.T) {
	mock := newMockIntegration()
	icfg := mockConfig{Integration: mock}

	cfg := mockManagerConfig()
	cfg.Integrations = append(cfg.Integrations, makeUnmarshaledConfig(icfg, true))

	im := instance.NewBasicManager(instance.DefaultBasicManagerConfig, log.NewNopLogger(), mockInstanceFactory)
	m, err := NewManager(cfg, log.NewNopLogger(), im, noOpValidator)
	require.NoError(t, err)

	test.Poll(t, time.Second, 1, func() interface{} {
		return int(mock.startedCount.Load())
	})

	m.Stop()

	time.Sleep(500 * time.Millisecond)
	require.Equal(t, 1, int(mock.startedCount.Load()), "graceful shutdown should not have restarted the Integration")

	test.Poll(t, time.Second, false, func() interface{} {
		return mock.running.Load()
	})
}

func TestManager_IntegrationEnabledToDisabledReload(t *testing.T) {
	mock := newMockIntegration()
	icfg := mockConfig{Integration: mock}
	cfg := mockManagerConfig()
	cfg.Integrations = append(cfg.Integrations, makeUnmarshaledConfig(icfg, true))

	im := instance.NewBasicManager(instance.DefaultBasicManagerConfig, log.NewNopLogger(), mockInstanceFactory)
	m, err := NewManager(cfg, log.NewNopLogger(), im, noOpValidator)
	require.NoError(t, err)

	// Test for Enabled -> Disabled
	_ = m.ApplyConfig(generateMockConfigWithEnabledFlag(false))
	require.Len(t, m.integrations, 0, "Integration was disabled so should be removed from map")
	_, err = m.im.GetInstance(mockIntegrationName)
	require.Error(t, err, "This mock should not exist")

	// test for Disabled -> Enabled
	_ = m.ApplyConfig(generateMockConfigWithEnabledFlag(true))
	require.Len(t, m.integrations, 1, "Integration was enabled so should be here")
	_, err = m.im.GetInstance(mockIntegrationName)
	require.NoError(t, err, "This mock should exist")
	require.Len(t, m.im.ListInstances(), 1, "This instance should exist")
}

func TestManager_IntegrationDisabledToEnabledReload(t *testing.T) {
	mock := newMockIntegration()
	icfg := mockConfig{Integration: mock}

	cfg := mockManagerConfig()
	cfg.Integrations = append(cfg.Integrations, UnmarshaledConfig{
		Config: icfg,
		Common: config.Common{Enabled: false},
	})

	im := instance.NewBasicManager(instance.DefaultBasicManagerConfig, log.NewNopLogger(), mockInstanceFactory)
	m, err := NewManager(cfg, log.NewNopLogger(), im, noOpValidator)
	require.NoError(t, err)
	require.Len(t, m.integrations, 0, "Integration was disabled so should be removed from map")
	_, err = m.im.GetInstance(mockIntegrationName)
	require.Error(t, err, "This mock should not exist")

	// test for Disabled -> Enabled

	_ = m.ApplyConfig(generateMockConfigWithEnabledFlag(true))
	require.Len(t, m.integrations, 1, "Integration was enabled so should be here")
	_, err = m.im.GetInstance(mockIntegrationName)
	require.NoError(t, err, "This mock should exist")
	require.Len(t, m.im.ListInstances(), 1, "This instance should exist")
}

type PromDefaultsValidator struct {
	PrometheusGlobalConfig promConfig.GlobalConfig
}

func (i *PromDefaultsValidator) validate(c *instance.Config) error {
	instanceConfig := instance.GlobalConfig{
		Prometheus: i.PrometheusGlobalConfig,
	}
	return c.ApplyDefaults(instanceConfig)
}

func TestManager_PromConfigChangeReloads(t *testing.T) {
	mock := newMockIntegration()
	icfg := mockConfig{Integration: mock}

	cfg := mockManagerConfig()
	cfg.Integrations = append(cfg.Integrations, makeUnmarshaledConfig(icfg, true))

	im := instance.NewBasicManager(instance.DefaultBasicManagerConfig, log.NewNopLogger(), mockInstanceFactory)

	startingPromConfig := mockPromConfigWithValues(model.Duration(30*time.Second), model.Duration(25*time.Second))
	cfg.PrometheusGlobalConfig = startingPromConfig
	validator := PromDefaultsValidator{startingPromConfig}

	m, err := NewManager(cfg, log.NewNopLogger(), im, validator.validate)
	require.NoError(t, err)
	require.Len(t, m.im.ListConfigs(), 1, "Integration was enabled so should be here")
	//The integration never has the prom config overrides happen so go after the running instance config instead
	for _, c := range m.im.ListConfigs() {
		for _, scrape := range c.ScrapeConfigs {
			require.Equal(t, startingPromConfig.ScrapeInterval, scrape.ScrapeInterval)
			require.Equal(t, startingPromConfig.ScrapeTimeout, scrape.ScrapeTimeout)
		}
	}

	newPromConfig := mockPromConfigWithValues(model.Duration(60*time.Second), model.Duration(55*time.Second))
	cfg.PrometheusGlobalConfig = newPromConfig
	validator.PrometheusGlobalConfig = newPromConfig

	err = m.ApplyConfig(cfg)
	require.NoError(t, err)

	require.Len(t, m.im.ListConfigs(), 1, "Integration was enabled so should be here")
	//The integration never has the prom config overrides happen so go after the running instance config instead
	for _, c := range m.im.ListConfigs() {
		for _, scrape := range c.ScrapeConfigs {
			require.Equal(t, newPromConfig.ScrapeInterval, scrape.ScrapeInterval)
			require.Equal(t, newPromConfig.ScrapeTimeout, scrape.ScrapeTimeout)
		}
	}
}

func generateMockConfigWithEnabledFlag(enabled bool) ManagerConfig {
	enabledMock := newMockIntegration()
	enabledConfig := mockConfig{Integration: enabledMock}
	enabledManagerConfig := mockManagerConfig()
	enabledManagerConfig.Integrations = append(
		enabledManagerConfig.Integrations,
		makeUnmarshaledConfig(enabledConfig, enabled),
	)
	return enabledManagerConfig
}

type mockConfig struct {
	Integration *mockIntegration `yaml:"mock"`
}

// Equal is used for cmp.Equal, since otherwise mockConfig can't be compared to itself.
func (c mockConfig) Equal(other mockConfig) bool { return c.Integration == other.Integration }

func (c mockConfig) Name() string                                { return "mock" }
func (c mockConfig) InstanceKey(agentKey string) (string, error) { return agentKey, nil }

func (c mockConfig) NewIntegration(_ log.Logger) (Integration, error) {
	return c.Integration, nil
}

type mockIntegration struct {
	startedCount *atomic.Uint32
	running      *atomic.Bool
	err          chan error
}

func newMockIntegration() *mockIntegration {
	return &mockIntegration{
		running:      atomic.NewBool(true),
		startedCount: atomic.NewUint32(0),
		err:          make(chan error),
	}
}

func (i *mockIntegration) MetricsHandler() (http.Handler, error) {
	return promhttp.Handler(), nil
}

func (i *mockIntegration) ScrapeConfigs() []config.ScrapeConfig {
	return []config.ScrapeConfig{{
		JobName:     "mock",
		MetricsPath: "/metrics",
	}}
}

func (i *mockIntegration) Run(ctx context.Context) error {
	i.startedCount.Inc()
	i.running.Store(true)
	defer i.running.Store(false)

	select {
	case <-ctx.Done():
		return ctx.Err()
	case err := <-i.err:
		return err
	}
}

func mockInstanceFactory(_ instance.Config) (instance.ManagedInstance, error) {
	return instance.NoOpInstance{}, nil
}

func mockManagerConfig() ManagerConfig {
	listenPort := 0
	listenHost := "127.0.0.1"
	return ManagerConfig{
		ScrapeIntegrations:        true,
		IntegrationRestartBackoff: 0,
		ListenPort:                listenPort,
		ListenHost:                listenHost,
	}
}

func mockPromConfigWithValues(scrapeInterval model.Duration, scrapeTimeout model.Duration) promConfig.GlobalConfig {
	return promConfig.GlobalConfig{
		ScrapeInterval: scrapeInterval,
		ScrapeTimeout:  scrapeTimeout,
	}
}

'''
'''--- pkg/integrations/memcached_exporter/memcached_exporter.go ---
// Package memcached_exporter embeds https://github.com/google/memcached_exporter
package memcached_exporter //nolint:golint

import (
	"time"

	"github.com/go-kit/log"
	"github.com/grafana/agent/pkg/integrations"
	integrations_v2 "github.com/grafana/agent/pkg/integrations/v2"
	"github.com/grafana/agent/pkg/integrations/v2/metricsutils"
	"github.com/prometheus/memcached_exporter/pkg/exporter"
)

// DefaultConfig is the default config for memcached_exporter.
var DefaultConfig = Config{
	MemcachedAddress: "localhost:11211",
	Timeout:          time.Second,
}

// Config controls the memcached_exporter integration.
type Config struct {
	// MemcachedAddress is the address of the memcached server (host:port).
	MemcachedAddress string `yaml:"memcached_address,omitempty"`

	// Timeout is the connection timeout for memcached.
	Timeout time.Duration `yaml:"timeout,omitempty"`
}

// UnmarshalYAML implements yaml.Unmarshaler for Config.
func (c *Config) UnmarshalYAML(unmarshal func(interface{}) error) error {
	*c = DefaultConfig

	type plain Config
	return unmarshal((*plain)(c))
}

// Name returns the name of the integration that this config represents.
func (c *Config) Name() string {
	return "memcached_exporter"
}

// InstanceKey returns the address:port of the memcached server.
func (c *Config) InstanceKey(agentKey string) (string, error) {
	return c.MemcachedAddress, nil
}

// NewIntegration converts this config into an instance of an integration.
func (c *Config) NewIntegration(l log.Logger) (integrations.Integration, error) {
	return New(l, c)
}

func init() {
	integrations.RegisterIntegration(&Config{})
	integrations_v2.RegisterLegacy(&Config{}, integrations_v2.TypeMultiplex, metricsutils.NewNamedShim("memcached"))
}

// New creates a new memcached_exporter integration. The integration scrapes metrics
// from a memcached server.
func New(log log.Logger, c *Config) (integrations.Integration, error) {
	return integrations.NewCollectorIntegration(
		c.Name(),
		integrations.WithCollectors(
			exporter.New(c.MemcachedAddress, c.Timeout, log),
		),
	), nil
}

'''
'''--- pkg/integrations/mongodb_exporter/logruskit.go ---
package mongodb_exporter //nolint:golint

import (
	"encoding/json"
	"fmt"
	"sort"
	"time"

	"github.com/go-kit/log/level"

	"github.com/go-kit/log"
	"github.com/sirupsen/logrus"
)

// NewLogger transalates log.Logger to logrus.Logger
func NewLogger(logger log.Logger, opts ...Option) *logrus.Logger {
	o := output{}
	for _, apply := range opts {
		apply(&o)
	}

	l := logrus.New()
	l.SetFormatter(formatter{})
	l.SetOutput(output{l: logger})
	return l
}

// Option Exposes logging options
type Option func(*output)

// WithTimestampFromLogrus sets tsFromLogrus logging option
func WithTimestampFromLogrus() Option {
	return func(o *output) {
		o.tsFromLogrus = true
	}
}

type output struct {
	l            log.Logger
	tsFromLogrus bool
}

func (o output) Write(data []byte) (n int, err error) {
	var ll line
	if err := json.Unmarshal(data, &ll); err != nil {
		return 0, fmt.Errorf("can't unmarshal line: %w", err)
	}
	keys := make([]string, 0, len(ll.Data))
	for k := range ll.Data {
		keys = append(keys, k)
	}
	sort.Strings(keys)

	vals := make([]interface{}, 0, 2*len(ll.Data)+2)
	for _, k := range keys {
		vals = append(vals, k, ll.Data[k])
	}
	vals = append(vals, "msg", ll.Message)

	logger := o.l
	if o.tsFromLogrus {
		logger = log.WithPrefix(o.l, "ts", ll.Time)
	}

	lvl := level.InfoValue()
	if mappedLvl, ok := levelMap[ll.Level]; ok {
		lvl = mappedLvl
	}
	logger = log.WithPrefix(logger, level.Key(), lvl)

	return 0, logger.Log(vals...)
}

type formatter struct{}

func (f formatter) Format(e *logrus.Entry) ([]byte, error) {
	ll := line{
		Time:    e.Time,
		Level:   e.Level,
		Data:    e.Data,
		Message: e.Message,
	}

	// FIXME: this can be much better in performance, but we can change it anytime since it's an internal contract
	return json.Marshal(ll)
}

type line struct {
	Time    time.Time
	Level   logrus.Level
	Data    logrus.Fields
	Message string
}

var levelMap = map[logrus.Level]level.Value{
	logrus.PanicLevel: level.ErrorValue(),
	logrus.FatalLevel: level.ErrorValue(),
	logrus.ErrorLevel: level.ErrorValue(),
	logrus.WarnLevel:  level.WarnValue(),
	logrus.InfoLevel:  level.InfoValue(),
	logrus.DebugLevel: level.DebugValue(),
	logrus.TraceLevel: level.DebugValue(),
}

'''
'''--- pkg/integrations/mongodb_exporter/mongodb_exporter.go ---
package mongodb_exporter //nolint:golint

import (
	"fmt"
	"net/url"

	"github.com/go-kit/log"
	"github.com/grafana/agent/pkg/integrations"
	integrations_v2 "github.com/grafana/agent/pkg/integrations/v2"
	"github.com/grafana/agent/pkg/integrations/v2/metricsutils"
	"github.com/percona/mongodb_exporter/exporter"
	config_util "github.com/prometheus/common/config"
)

// Config controls mongodb_exporter
type Config struct {
	// MongoDB connection URI. example:mongodb://user:pass@127.0.0.1:27017/admin?ssl=true"
	URI config_util.Secret `yaml:"mongodb_uri"`
}

// UnmarshalYAML implements yaml.Unmarshaler for Config
func (c *Config) UnmarshalYAML(unmarshal func(interface{}) error) error {
	type plain Config
	return unmarshal((*plain)(c))
}

// Name returns the name of the integration that this config represents.
func (c *Config) Name() string {
	return "mongodb_exporter"
}

// InstanceKey returns the address:port of the mongodb server being queried.
func (c *Config) InstanceKey(_ string) (string, error) {
	u, err := url.Parse(string(c.URI))
	if err != nil {
		return "", fmt.Errorf("could not parse url: %w", err)
	}
	return u.Host, nil
}

// NewIntegration creates a new mongodb_exporter
func (c *Config) NewIntegration(logger log.Logger) (integrations.Integration, error) {
	return New(logger, c)
}

func init() {
	integrations.RegisterIntegration(&Config{})
	integrations_v2.RegisterLegacy(&Config{}, integrations_v2.TypeMultiplex, metricsutils.NewNamedShim("mongodb"))
}

// New creates a new mongodb_exporter integration.
func New(logger log.Logger, c *Config) (integrations.Integration, error) {
	logrusLogger := NewLogger(logger)

	exp := exporter.New(&exporter.Opts{
		URI:                    string(c.URI),
		Logger:                 logrusLogger,
		DisableDefaultRegistry: true,

		// NOTE(rfratto): CompatibleMode configures the exporter to use old metric
		// names from mongodb_exporter <v0.20.0. Many existing dashboards rely on
		// the old names, so we hard-code it to true now. We may wish to make this
		// configurable in the future.
		CompatibleMode: true,
		CollectAll:     true,
	})

	return integrations.NewHandlerIntegration(c.Name(), exp.Handler()), nil
}

'''
'''--- pkg/integrations/mongodb_exporter/mongodb_test.go ---
package mongodb_exporter //nolint:golint

import (
	"testing"

	"github.com/grafana/agent/pkg/config"
)

func TestConfig_SecretMongoDB(t *testing.T) {
	stringCfg := `
prometheus:
  wal_directory: /tmp/agent
integrations:
  mongodb_exporter:
    enabled: true
    mongodb_uri: secret_password_in_uri
`
	config.CheckSecret(t, stringCfg, "secret_password_in_uri")
}

'''
'''--- pkg/integrations/mysqld_exporter/mysqld-exporter.go ---
// Package mysqld_exporter embeds https://github.com/prometheus/mysqld_exporter
package mysqld_exporter //nolint:golint

import (
	"context"
	"fmt"
	"os"

	config_util "github.com/prometheus/common/config"

	"github.com/go-kit/log"
	"github.com/go-kit/log/level"
	"github.com/go-sql-driver/mysql"
	"github.com/grafana/agent/pkg/integrations"
	integrations_v2 "github.com/grafana/agent/pkg/integrations/v2"
	"github.com/grafana/agent/pkg/integrations/v2/metricsutils"
	"github.com/prometheus/mysqld_exporter/collector"
)

// DefaultConfig holds the default settings for the mysqld_exporter integration.
var DefaultConfig = Config{
	LockWaitTimeout: 2,

	InfoSchemaProcessListProcessesByUser: true,
	InfoSchemaProcessListProcessesByHost: true,
	InfoSchemaTablesDatabases:            "*",

	PerfSchemaEventsStatementsLimit:     250,
	PerfSchemaEventsStatementsTimeLimit: 86400,
	PerfSchemaEventsStatementsTextLimit: 120,
	PerfSchemaFileInstancesFilter:       ".*",
	PerfSchemaFileInstancesRemovePrefix: "/var/lib/mysql",

	HeartbeatDatabase: "heartbeat",
	HeartbeatTable:    "heartbeat",
}

// Config controls the mysqld_exporter integration.
type Config struct {
	// DataSourceName to use to connect to MySQL.
	DataSourceName config_util.Secret `yaml:"data_source_name,omitempty"`

	// Collectors to mark as enabled in addition to the default.
	EnableCollectors []string `yaml:"enable_collectors,omitempty"`
	// Collectors to explicitly mark as disabled.
	DisableCollectors []string `yaml:"disable_collectors,omitempty"`

	// Overrides the default set of enabled collectors with the given list.
	SetCollectors []string `yaml:"set_collectors,omitempty"`

	// Collector-wide options
	LockWaitTimeout int  `yaml:"lock_wait_timeout,omitempty"`
	LogSlowFilter   bool `yaml:"log_slow_filter,omitempty"`

	// Collector-specific config options
	InfoSchemaProcessListMinTime         int    `yaml:"info_schema_processlist_min_time,omitempty"`
	InfoSchemaProcessListProcessesByUser bool   `yaml:"info_schema_processlist_processes_by_user,omitempty"`
	InfoSchemaProcessListProcessesByHost bool   `yaml:"info_schema_processlist_processes_by_host,omitempty"`
	InfoSchemaTablesDatabases            string `yaml:"info_schema_tables_databases,omitempty"`
	PerfSchemaEventsStatementsLimit      int    `yaml:"perf_schema_eventsstatements_limit,omitempty"`
	PerfSchemaEventsStatementsTimeLimit  int    `yaml:"perf_schema_eventsstatements_time_limit,omitempty"`
	PerfSchemaEventsStatementsTextLimit  int    `yaml:"perf_schema_eventsstatements_digtext_text_limit,omitempty"`
	PerfSchemaFileInstancesFilter        string `yaml:"perf_schema_file_instances_filter,omitempty"`
	PerfSchemaFileInstancesRemovePrefix  string `yaml:"perf_schema_file_instances_remove_prefix,omitempty"`
	HeartbeatDatabase                    string `yaml:"heartbeat_database,omitempty"`
	HeartbeatTable                       string `yaml:"heartbeat_table,omitempty"`
	HeartbeatUTC                         bool   `yaml:"heartbeat_utc,omitempty"`
	MySQLUserPrivileges                  bool   `yaml:"mysql_user_privileges,omitempty"`
}

// UnmarshalYAML implements yaml.Unmarshaler for Config.
func (c *Config) UnmarshalYAML(unmarshal func(interface{}) error) error {
	*c = DefaultConfig

	type plain Config
	return unmarshal((*plain)(c))
}

// Name returns the name of the integration that this config represents.
func (c *Config) Name() string {
	return "mysqld_exporter"
}

// InstanceKey returns network(hostname:port)/dbname of the MySQL server.
func (c *Config) InstanceKey(_ string) (string, error) {
	m, err := mysql.ParseDSN(string(c.DataSourceName))
	if err != nil {
		return "", fmt.Errorf("failed to parse DSN: %w", err)
	}

	if m.Addr == "" {
		m.Addr = "localhost:3306"
	}
	if m.Net == "" {
		m.Net = "tcp"
	}

	return fmt.Sprintf("%s(%s)/%s", m.Net, m.Addr, m.DBName), nil
}

// NewIntegration converts this config into an instance of an integration.
func (c *Config) NewIntegration(l log.Logger) (integrations.Integration, error) {
	return New(l, c)
}

func init() {
	integrations.RegisterIntegration(&Config{})
	integrations_v2.RegisterLegacy(&Config{}, integrations_v2.TypeMultiplex, metricsutils.NewNamedShim("mysql"))
}

// New creates a new mysqld_exporter integration. The integration scrapes
// metrics from a mysqld process.
func New(log log.Logger, c *Config) (integrations.Integration, error) {
	dsn := c.DataSourceName
	if len(dsn) == 0 {
		dsn = config_util.Secret(os.Getenv("MYSQLD_EXPORTER_DATA_SOURCE_NAME"))
	}
	if len(dsn) == 0 {
		return nil, fmt.Errorf("cannot create mysqld_exporter; neither mysqld_exporter.data_source_name or $MYSQLD_EXPORTER_DATA_SOURCE_NAME is set")
	}

	scrapers := GetScrapers(c)
	exporter := collector.New(context.Background(), string(dsn), collector.NewMetrics(), scrapers, log, collector.Config{
		LockTimeout:   c.LockWaitTimeout,
		SlowLogFilter: c.LogSlowFilter,
	})

	level.Debug(log).Log("msg", "enabled mysqld_exporter scrapers")
	for _, scraper := range scrapers {
		level.Debug(log).Log("scraper", scraper.Name())
	}

	return integrations.NewCollectorIntegration(
		c.Name(),
		integrations.WithCollectors(exporter),
	), nil
}

// GetScrapers returns the set of *enabled* scrapers from the config.
// Configurable scrapers will have their configuration filled out matching the
// Config's settings.
func GetScrapers(c *Config) []collector.Scraper {
	scrapers := map[collector.Scraper]bool{
		&collector.ScrapeAutoIncrementColumns{}:                false,
		&collector.ScrapeBinlogSize{}:                          false,
		&collector.ScrapeClientStat{}:                          false,
		&collector.ScrapeEngineInnodbStatus{}:                  false,
		&collector.ScrapeEngineTokudbStatus{}:                  false,
		&collector.ScrapeGlobalStatus{}:                        true,
		&collector.ScrapeGlobalVariables{}:                     true,
		&collector.ScrapeInfoSchemaInnodbTablespaces{}:         false,
		&collector.ScrapeInnodbCmpMem{}:                        true,
		&collector.ScrapeInnodbCmp{}:                           true,
		&collector.ScrapeInnodbMetrics{}:                       false,
		&collector.ScrapePerfEventsStatementsSum{}:             false,
		&collector.ScrapePerfEventsWaits{}:                     false,
		&collector.ScrapePerfFileEvents{}:                      false,
		&collector.ScrapePerfIndexIOWaits{}:                    false,
		&collector.ScrapePerfReplicationApplierStatsByWorker{}: false,
		&collector.ScrapePerfReplicationGroupMemberStats{}:     false,
		&collector.ScrapePerfReplicationGroupMembers{}:         false,
		&collector.ScrapePerfTableIOWaits{}:                    false,
		&collector.ScrapePerfTableLockWaits{}:                  false,
		&collector.ScrapeQueryResponseTime{}:                   true,
		&collector.ScrapeReplicaHost{}:                         false,
		&collector.ScrapeSchemaStat{}:                          false,
		&collector.ScrapeSlaveHosts{}:                          false,
		&collector.ScrapeSlaveStatus{}:                         true,
		&collector.ScrapeTableStat{}:                           false,
		&collector.ScrapeUserStat{}:                            false,

		// Collectors that have configuration
		&collector.ScrapeHeartbeat{
			Database: c.HeartbeatDatabase,
			Table:    c.HeartbeatTable,
			UTC:      c.HeartbeatUTC,
		}: false,

		&collector.ScrapePerfEventsStatements{
			Limit:           c.PerfSchemaEventsStatementsLimit,
			TimeLimit:       c.PerfSchemaEventsStatementsTimeLimit,
			DigestTextLimit: c.PerfSchemaEventsStatementsTextLimit,
		}: false,

		&collector.ScrapePerfFileInstances{
			Filter:       c.PerfSchemaFileInstancesFilter,
			RemovePrefix: c.PerfSchemaFileInstancesRemovePrefix,
		}: false,

		&collector.ScrapeProcesslist{
			ProcessListMinTime:  c.InfoSchemaProcessListMinTime,
			ProcessesByHostFlag: c.InfoSchemaProcessListProcessesByHost,
			ProcessesByUserFlag: c.InfoSchemaProcessListProcessesByUser,
		}: false,

		&collector.ScrapeTableSchema{
			Databases: c.InfoSchemaTablesDatabases,
		}: false,

		&collector.ScrapeUser{
			Privileges: c.MySQLUserPrivileges,
		}: false,
	}

	// Override the defaults with the provided set of collectors if
	// set_collectors has at least one element in it.
	if len(c.SetCollectors) != 0 {
		customDefaults := map[string]struct{}{}
		for _, c := range c.SetCollectors {
			customDefaults[c] = struct{}{}
		}
		for scraper := range scrapers {
			_, enable := customDefaults[scraper.Name()]
			scrapers[scraper] = enable
		}
	}

	// Explicitly disable/enable specific collectors.
	for _, c := range c.DisableCollectors {
		for scraper := range scrapers {
			if scraper.Name() == c {
				scrapers[scraper] = false
				break
			}
		}
	}
	for _, c := range c.EnableCollectors {
		for scraper := range scrapers {
			if scraper.Name() == c {
				scrapers[scraper] = true
				break
			}
		}
	}

	enabledScrapers := []collector.Scraper{}
	for scraper, enabled := range scrapers {
		if enabled {
			enabledScrapers = append(enabledScrapers, scraper)
		}
	}
	return enabledScrapers
}

'''
'''--- pkg/integrations/mysqld_exporter/mysqld_test.go ---
package mysqld_exporter //nolint:golint

import (
	"testing"

	"github.com/grafana/agent/pkg/config"
)

func TestConfig_SecretMysqlD(t *testing.T) {
	stringCfg := `
prometheus:
  wal_directory: /tmp/agent
integrations:
  mysqld_exporter:
    enabled: true
    data_source_name: root:secret_password@myserver:3306`
	config.CheckSecret(t, stringCfg, "secret_password")
}

'''
'''--- pkg/integrations/node_exporter/collectors.go ---
package node_exporter // nolint:golint

import (
	"fmt"
	"sort"

	"gopkg.in/alecthomas/kingpin.v2"
)

// CollectorState represents the default state of the collector, where it can
// either be enabled or disabled
type CollectorState bool

const (
	// CollectorStateDisabled represents a disabled collector that will not run
	// and collect metrics.
	CollectorStateDisabled CollectorState = false

	// CollectorStateEnabled represents an enabled collector that _will_ run
	// and collect metrics.
	CollectorStateEnabled CollectorState = true
)

// Collector is a specific collector that node_exporter runs.
type Collector string

// Collection of collectors defined by node_exporter
const (
	CollectorARP          = "arp"
	CollectorBCache       = "bcache"
	CollectorBTRFS        = "btrfs"
	CollectorBonding      = "bonding"
	CollectorBootTime     = "boottime"
	CollectorBuddyInfo    = "buddyinfo"
	CollectorCPU          = "cpu"
	CollectorCPUFreq      = "cpufreq"
	CollectorConntrack    = "conntrack"
	CollectorDMI          = "dmi"
	CollectorDRBD         = "drbd"
	CollectorDRM          = "drm"
	CollectorDevstat      = "devstat"
	CollectorDiskstats    = "diskstats"
	CollectorEDAC         = "edac"
	CollectorEntropy      = "entropy"
	CollectorEthtool      = "ethtool"
	CollectorExec         = "exec"
	CollectorFibrechannel = "fibrechannel"
	CollectorFileFD       = "filefd"
	CollectorFilesystem   = "filesystem"
	CollectorHWMon        = "hwmon"
	CollectorIPVS         = "ipvs"
	CollectorInfiniband   = "infiniband"
	CollectorInterrupts   = "interrupts"
	CollectorKSMD         = "ksmd"
	CollectorLnstat       = "lnstat"
	CollectorLoadAvg      = "loadavg"
	CollectorLogind       = "logind"
	CollectorMDADM        = "mdadm"
	CollectorMeminfo      = "meminfo"
	CollectorMeminfoNuma  = "meminfo_numa"
	CollectorMountstats   = "mountstats"
	CollectorNFS          = "nfs"
	CollectorNFSD         = "nfsd"
	CollectorNTP          = "ntp"
	CollectorNVME         = "nvme"
	CollectorNetclass     = "netclass"
	CollectorNetdev       = "netdev"
	CollectorNetstat      = "netstat"
	CollectorNetworkRoute = "network_route"
	CollectorOS           = "os"
	CollectorPerf         = "perf"
	CollectorPowersuppply = "powersupplyclass"
	CollectorPressure     = "pressure"
	CollectorProcesses    = "processes"
	CollectorQDisc        = "qdisc"
	CollectorRAPL         = "rapl"
	CollectorRunit        = "runit"
	CollectorSchedstat    = "schedstat"
	CollectorSockstat     = "sockstat"
	CollectorSoftnet      = "softnet"
	CollectorStat         = "stat"
	CollectorSupervisord  = "supervisord"
	CollectorSystemd      = "systemd"
	CollectorTCPStat      = "tcpstat"
	CollectorTapestats    = "tapestats"
	CollectorTextfile     = "textfile"
	CollectorThermal      = "thermal"
	CollectorThermalzone  = "thermal_zone"
	CollectorTime         = "time"
	CollectorTimex        = "timex"
	CollectorUDPQueues    = "udp_queues"
	CollectorUname        = "uname"
	CollectorVMStat       = "vmstat"
	CollectorWiFi         = "wifi"
	CollectorXFS          = "xfs"
	CollectorZFS          = "zfs"
	CollectorZoneinfo     = "zoneinfo"
)

// Collectors holds a map of known collector names to their default
// state.
var Collectors = map[string]CollectorState{
	CollectorARP:          CollectorStateEnabled,
	CollectorBCache:       CollectorStateEnabled,
	CollectorBTRFS:        CollectorStateEnabled,
	CollectorBonding:      CollectorStateEnabled,
	CollectorBootTime:     CollectorStateEnabled,
	CollectorBuddyInfo:    CollectorStateDisabled,
	CollectorCPU:          CollectorStateEnabled,
	CollectorCPUFreq:      CollectorStateEnabled,
	CollectorConntrack:    CollectorStateEnabled,
	CollectorDMI:          CollectorStateEnabled,
	CollectorDRBD:         CollectorStateDisabled,
	CollectorDRM:          CollectorStateDisabled,
	CollectorDevstat:      CollectorStateDisabled,
	CollectorDiskstats:    CollectorStateEnabled,
	CollectorEDAC:         CollectorStateEnabled,
	CollectorEntropy:      CollectorStateEnabled,
	CollectorEthtool:      CollectorStateDisabled,
	CollectorExec:         CollectorStateEnabled,
	CollectorFibrechannel: CollectorStateEnabled,
	CollectorFileFD:       CollectorStateEnabled,
	CollectorFilesystem:   CollectorStateEnabled,
	CollectorHWMon:        CollectorStateEnabled,
	CollectorIPVS:         CollectorStateEnabled,
	CollectorInfiniband:   CollectorStateEnabled,
	CollectorInterrupts:   CollectorStateDisabled,
	CollectorKSMD:         CollectorStateDisabled,
	CollectorLnstat:       CollectorStateDisabled,
	CollectorLoadAvg:      CollectorStateEnabled,
	CollectorLogind:       CollectorStateDisabled,
	CollectorMDADM:        CollectorStateEnabled,
	CollectorMeminfo:      CollectorStateEnabled,
	CollectorMeminfoNuma:  CollectorStateDisabled,
	CollectorMountstats:   CollectorStateDisabled,
	CollectorNFS:          CollectorStateEnabled,
	CollectorNFSD:         CollectorStateEnabled,
	CollectorNTP:          CollectorStateDisabled,
	CollectorNVME:         CollectorStateEnabled,
	CollectorNetclass:     CollectorStateEnabled,
	CollectorNetdev:       CollectorStateEnabled,
	CollectorNetstat:      CollectorStateEnabled,
	CollectorNetworkRoute: CollectorStateDisabled,
	CollectorOS:           CollectorStateEnabled,
	CollectorPerf:         CollectorStateDisabled,
	CollectorPowersuppply: CollectorStateEnabled,
	CollectorPressure:     CollectorStateEnabled,
	CollectorProcesses:    CollectorStateDisabled,
	CollectorQDisc:        CollectorStateDisabled,
	CollectorRAPL:         CollectorStateEnabled,
	CollectorRunit:        CollectorStateDisabled,
	CollectorSchedstat:    CollectorStateEnabled,
	CollectorSockstat:     CollectorStateEnabled,
	CollectorSoftnet:      CollectorStateEnabled,
	CollectorStat:         CollectorStateEnabled,
	CollectorSupervisord:  CollectorStateDisabled,
	CollectorSystemd:      CollectorStateDisabled,
	CollectorTCPStat:      CollectorStateDisabled,
	CollectorTapestats:    CollectorStateEnabled,
	CollectorTextfile:     CollectorStateEnabled,
	CollectorThermal:      CollectorStateEnabled,
	CollectorThermalzone:  CollectorStateEnabled,
	CollectorTime:         CollectorStateEnabled,
	CollectorTimex:        CollectorStateEnabled,
	CollectorUDPQueues:    CollectorStateEnabled,
	CollectorUname:        CollectorStateEnabled,
	CollectorVMStat:       CollectorStateEnabled,
	CollectorWiFi:         CollectorStateDisabled,
	CollectorXFS:          CollectorStateEnabled,
	CollectorZFS:          CollectorStateEnabled,
	CollectorZoneinfo:     CollectorStateDisabled,
}

// MapCollectorsToFlags takes in a map of collector keys and their states and
// converts them into flags that node_exporter expects. Collectors that are not
// defined will be ignored, which will be the case for collectors that are not
// supported on the host system.
func MapCollectorsToFlags(cs map[string]CollectorState) (flags []string) {
	for collector, state := range cs {
		flag := fmt.Sprintf("collector.%s", collector)

		// Skip the flag if it's not defined in kingpin
		if kingpin.CommandLine.GetFlag(flag) == nil {
			continue
		}

		switch state {
		case CollectorStateEnabled:
			flags = append(flags, "--"+flag)
		case CollectorStateDisabled:
			flags = append(flags, "--no-"+flag)
		}
	}

	sort.Strings(flags)
	return
}

// DisableUnavailableCollectors disables collectors that are not available on
// the host machine.
func DisableUnavailableCollectors(cs map[string]CollectorState) {
	for collector := range cs {
		flag := fmt.Sprintf("collector.%s", collector)

		// If kingpin doesn't have the flag, the collector is unavailable.
		if kingpin.CommandLine.GetFlag(flag) == nil {
			cs[collector] = CollectorStateDisabled
		}
	}
}

'''
'''--- pkg/integrations/node_exporter/config.go ---
package node_exporter //nolint:golint

import (
	"fmt"
	"os"
	"runtime"
	"strings"
	"time"

	"github.com/go-kit/log"
	"github.com/grafana/agent/pkg/integrations"
	integrations_v2 "github.com/grafana/agent/pkg/integrations/v2"
	"github.com/grafana/agent/pkg/integrations/v2/metricsutils"
	"github.com/grafana/dskit/flagext"
	"github.com/prometheus/procfs"
	"gopkg.in/alecthomas/kingpin.v2"
)

var (
	// DefaultConfig holds non-zero default options for the Config when it is
	// unmarshaled from YAML.
	//
	// DefaultConfig's defaults are populated from init functions in this package.
	// See the init function here and in node_exporter_linux.go.
	DefaultConfig = Config{
		ProcFSPath: procfs.DefaultMountPoint,
		RootFSPath: "/",

		DiskStatsIgnoredDevices: "^(ram|loop|fd|(h|s|v|xv)d[a-z]|nvme\\d+n\\d+p)\\d+$",

		EthtoolMetricsInclude: ".*",

		FilesystemMountTimeout: 5 * time.Second,

		NTPIPTTL:                1,
		NTPLocalOffsetTolerance: time.Millisecond,
		NTPMaxDistance:          time.Microsecond * 3466080,
		NTPProtocolVersion:      4,
		NTPServer:               "127.0.0.1",

		NetclassIgnoredDevices: "^$",
		NetstatFields:          "^(.*_(InErrors|InErrs)|Ip_Forwarding|Ip(6|Ext)_(InOctets|OutOctets)|Icmp6?_(InMsgs|OutMsgs)|TcpExt_(Listen.*|Syncookies.*|TCPSynRetrans|TCPTimeouts)|Tcp_(ActiveOpens|InSegs|OutSegs|OutRsts|PassiveOpens|RetransSegs|CurrEstab)|Udp6?_(InDatagrams|OutDatagrams|NoPorts|RcvbufErrors|SndbufErrors))$",

		PowersupplyIgnoredSupplies: "^$",

		RunitServiceDir: "/etc/service",

		SupervisordURL: "http://localhost:9001/RPC2",

		SystemdUnitExclude: ".+\\.(automount|device|mount|scope|slice)",
		SystemdUnitInclude: ".+",

		TapestatsIgnoredDevices: "^$",

		VMStatFields: "^(oom_kill|pgpg|pswp|pg.*fault).*",
	}
)

func init() {
	// The default values for the filesystem collector are to ignore everything,
	// but some platforms have specific defaults. We'll fill these in below at
	// initialization time, but the values can still be overridden via the config
	// file.
	switch runtime.GOOS {
	case "linux":
		DefaultConfig.FilesystemMountPointsExclude = "^/(dev|proc|run/credentials/.+|sys|var/lib/docker/.+)($|/)"
		DefaultConfig.FilesystemFSTypesExclude = "^(autofs|binfmt_misc|bpf|cgroup2?|configfs|debugfs|devpts|devtmpfs|fusectl|hugetlbfs|iso9660|mqueue|nsfs|overlay|proc|procfs|pstore|rpc_pipefs|securityfs|selinuxfs|squashfs|sysfs|tracefs)$"
	case "darwin":
		DefaultConfig.FilesystemMountPointsExclude = "^/(dev)($|/)"
		DefaultConfig.FilesystemFSTypesExclude = "^(autofs|devfs)$"
	case "freebsd", "netbsd", "openbsd":
		DefaultConfig.FilesystemMountPointsExclude = "^/(dev)($|/)"
		DefaultConfig.FilesystemFSTypesExclude = "^devfs$"
	}

	if url := os.Getenv("SUPERVISORD_URL"); url != "" {
		DefaultConfig.SupervisordURL = url
	}
}

// Config controls the node_exporter integration.
type Config struct {
	IncludeExporterMetrics bool `yaml:"include_exporter_metrics,omitempty"`

	ProcFSPath string `yaml:"procfs_path,omitempty"`
	SysFSPath  string `yaml:"sysfs_path,omitempty"`
	RootFSPath string `yaml:"rootfs_path,omitempty"`

	// Collectors to mark as enabled
	EnableCollectors flagext.StringSlice `yaml:"enable_collectors,omitempty"`

	// Collectors to mark as disabled
	DisableCollectors flagext.StringSlice `yaml:"disable_collectors,omitempty"`

	// Overrides the default set of enabled collectors with the collectors
	// listed.
	SetCollectors flagext.StringSlice `yaml:"set_collectors,omitempty"`

	// Collector-specific config options
	BcachePriorityStats              bool                `yaml:"enable_bcache_priority_stats,omitempty"`
	CPUBugsInclude                   string              `yaml:"cpu_bugs_include,omitempty"`
	CPUEnableCPUGuest                bool                `yaml:"enable_cpu_guest_seconds_metric,omitempty"`
	CPUEnableCPUInfo                 bool                `yaml:"enable_cpu_info_metric,omitempty"`
	CPUFlagsInclude                  string              `yaml:"cpu_flags_include,omitempty"`
	DiskStatsIgnoredDevices          string              `yaml:"diskstats_ignored_devices,omitempty"`
	EthtoolDeviceExclude             string              `yaml:"ethtool_device_exclude,omitempty"`
	EthtoolDeviceInclude             string              `yaml:"ethtool_device_include,omitempty"`
	EthtoolMetricsInclude            string              `yaml:"ethtool_metrics_include,omitempty"`
	FilesystemFSTypesExclude         string              `yaml:"filesystem_fs_types_exclude,omitempty"`
	FilesystemMountPointsExclude     string              `yaml:"filesystem_mount_points_exclude,omitempty"`
	FilesystemMountTimeout           time.Duration       `yaml:"filesystem_mount_timeout,omitempty"`
	IPVSBackendLabels                []string            `yaml:"ipvs_backend_labels,omitempty"`
	NTPIPTTL                         int                 `yaml:"ntp_ip_ttl,omitempty"`
	NTPLocalOffsetTolerance          time.Duration       `yaml:"ntp_local_offset_tolerance,omitempty"`
	NTPMaxDistance                   time.Duration       `yaml:"ntp_max_distance,omitempty"`
	NTPProtocolVersion               int                 `yaml:"ntp_protocol_version,omitempty"`
	NTPServer                        string              `yaml:"ntp_server,omitempty"`
	NTPServerIsLocal                 bool                `yaml:"ntp_server_is_local,omitempty"`
	NetclassIgnoreInvalidSpeedDevice bool                `yaml:"netclass_ignore_invalid_speed_device,omitempty"`
	NetclassIgnoredDevices           string              `yaml:"netclass_ignored_devices,omitempty"`
	NetdevAddressInfo                bool                `yaml:"netdev_address_info,omitempty"`
	NetdevDeviceExclude              string              `yaml:"netdev_device_exclude,omitempty"`
	NetdevDeviceInclude              string              `yaml:"netdev_device_include,omitempty"`
	NetstatFields                    string              `yaml:"netstat_fields,omitempty"`
	PerfCPUS                         string              `yaml:"perf_cpus,omitempty"`
	PerfTracepoint                   flagext.StringSlice `yaml:"perf_tracepoint,omitempty"`
	PowersupplyIgnoredSupplies       string              `yaml:"powersupply_ignored_supplies,omitempty"`
	RunitServiceDir                  string              `yaml:"runit_service_dir,omitempty"`
	SupervisordURL                   string              `yaml:"supervisord_url,omitempty"`
	SystemdEnableRestartsMetrics     bool                `yaml:"systemd_enable_restarts_metrics,omitempty"`
	SystemdEnableStartTimeMetrics    bool                `yaml:"systemd_enable_start_time_metrics,omitempty"`
	SystemdEnableTaskMetrics         bool                `yaml:"systemd_enable_task_metrics,omitempty"`
	SystemdUnitExclude               string              `yaml:"systemd_unit_exclude,omitempty"`
	SystemdUnitInclude               string              `yaml:"systemd_unit_include,omitempty"`
	TapestatsIgnoredDevices          string              `yaml:"tapestats_ignored_devices,omitempty"`
	TextfileDirectory                string              `yaml:"textfile_directory,omitempty"`
	VMStatFields                     string              `yaml:"vmstat_fields,omitempty"`

	UnmarshalWarnings []string `yaml:"-"`
}

// UnmarshalYAML implements yaml.Unmarshaler for Config.
func (c *Config) UnmarshalYAML(unmarshal func(interface{}) error) error {
	*c = DefaultConfig

	type baseConfig Config
	type config struct {
		baseConfig `yaml:",inline"`

		// Deprecated field names:
		NetdevDeviceWhitelist        string `yaml:"netdev_device_whitelist,omitempty"`
		NetdevDeviceBlacklist        string `yaml:"netdev_device_blacklist,omitempty"`
		SystemdUnitWhitelist         string `yaml:"systemd_unit_whitelist,omitempty"`
		SystemdUnitBlacklist         string `yaml:"systemd_unit_blacklist,omitempty"`
		FilesystemIgnoredMountPoints string `yaml:"filesystem_ignored_mount_points,omitempty"`
		FilesystemIgnoredFSTypes     string `yaml:"filesystem_ignored_fs_types,omitempty"`
	}

	var fc config // our full config (schema + deprecated names)
	fc.baseConfig = baseConfig(*c)

	type migratedField struct {
		OldName, NewName   string
		OldValue, NewValue *string

		defaultValue string
	}
	migratedFields := []*migratedField{
		{
			OldName: "netdev_device_whitelist", NewName: "netdev_device_include",
			OldValue: &fc.NetdevDeviceWhitelist, NewValue: &fc.NetdevDeviceInclude,
		},
		{
			OldName: "netdev_device_blacklist", NewName: "netdev_device_exclude",
			OldValue: &fc.NetdevDeviceBlacklist, NewValue: &fc.NetdevDeviceExclude,
		},
		{
			OldName: "systemd_unit_whitelist", NewName: "systemd_unit_include",
			OldValue: &fc.SystemdUnitWhitelist, NewValue: &fc.SystemdUnitInclude,
		},
		{
			OldName: "systemd_unit_blacklist", NewName: "systemd_unit_exclude",
			OldValue: &fc.SystemdUnitBlacklist, NewValue: &fc.SystemdUnitExclude,
		},
		{
			OldName: "filesystem_ignored_mount_points", NewName: "filesystem_mount_points_exclude",
			OldValue: &fc.FilesystemIgnoredMountPoints, NewValue: &fc.FilesystemMountPointsExclude,
		},
		{
			OldName: "filesystem_ignored_fs_types", NewName: "filesystem_fs_types_exclude",
			OldValue: &fc.FilesystemIgnoredFSTypes, NewValue: &fc.FilesystemFSTypesExclude,
		},
	}

	// We don't know when fields are unmarshaled unless they have non-zero
	// values. Defaults stop us from being able to check, so we'll temporarily
	// cache the default and make sure both the old and new migrated fields are
	// zero.
	for _, mf := range migratedFields {
		mf.defaultValue = *mf.NewValue
		*mf.NewValue = ""
	}

	if err := unmarshal(&fc); err != nil {
		return err
	}

	for _, mf := range migratedFields {
		switch {
		case *mf.OldValue != "" && *mf.NewValue != "": // New set, old set
			return fmt.Errorf("only one of %q and %q may be specified", mf.OldName, mf.NewName)

		case *mf.NewValue == "" && *mf.OldValue != "": // New unset, old set
			*mf.NewValue = *mf.OldValue

			warning := fmt.Sprintf("%q is deprecated by %q and will be removed in a future version", mf.OldName, mf.NewName)
			fc.UnmarshalWarnings = append(fc.UnmarshalWarnings, warning)

		case *mf.NewValue == "" && *mf.OldValue == "": // Neither set.
			// Copy the default back to mf.NewValue.
			*mf.NewValue = mf.defaultValue

		case *mf.NewValue != "" && *mf.OldValue == "": // New set, old unset
			// Nothing to do
		}
	}

	*c = (Config)(fc.baseConfig)
	return nil
}

// Name returns the name of the integration that this config represents.
func (c *Config) Name() string {
	return "node_exporter"
}

// InstanceKey returns the hostname:port of the agent process.
func (c *Config) InstanceKey(agentKey string) (string, error) {
	return agentKey, nil
}

// NewIntegration converts this config into an instance of an integration.
func (c *Config) NewIntegration(l log.Logger) (integrations.Integration, error) {
	return New(l, c)
}

func init() {
	integrations.RegisterIntegration(&Config{})
	integrations_v2.RegisterLegacy(&Config{}, integrations_v2.TypeSingleton, metricsutils.Shim)
}

// MapConfigToNodeExporterFlags takes in a node_exporter Config and converts
// it to the set of flags that node_exporter usually expects when running as a
// separate binary.
func MapConfigToNodeExporterFlags(c *Config) (accepted []string, ignored []string) {
	collectors := make(map[string]CollectorState, len(Collectors))
	for k, v := range Collectors {
		collectors[k] = v
	}

	// Override the set of defaults with the provided set of collectors if
	// set_collectors has at least one element in it.
	if len(c.SetCollectors) != 0 {
		customDefaults := map[string]struct{}{}
		for _, c := range c.SetCollectors {
			customDefaults[c] = struct{}{}
		}

		for k := range collectors {
			_, shouldEnable := customDefaults[k]
			if shouldEnable {
				collectors[k] = CollectorStateEnabled
			} else {
				collectors[k] = CollectorStateDisabled
			}
		}
	}

	// Explicitly disable/enable specific collectors
	for _, c := range c.DisableCollectors {
		collectors[c] = CollectorStateDisabled
	}
	for _, c := range c.EnableCollectors {
		collectors[c] = CollectorStateEnabled
	}

	DisableUnavailableCollectors(collectors)

	var flags flags
	flags.accepted = append(flags.accepted, MapCollectorsToFlags(collectors)...)

	flags.add(
		"--path.procfs", c.ProcFSPath,
		"--path.sysfs", c.SysFSPath,
		"--path.rootfs", c.RootFSPath,
	)

	if collectors[CollectorBCache] {
		flags.addBools(map[*bool]string{
			&c.BcachePriorityStats: "collector.bcache.priorityStats",
		})
	}

	if collectors[CollectorCPU] {
		flags.addBools(map[*bool]string{
			&c.CPUEnableCPUGuest: "collector.cpu.guest",
			&c.CPUEnableCPUInfo:  "collector.cpu.info",
		})
		flags.add("--collector.cpu.info.flags-include", c.CPUFlagsInclude)
		flags.add("--collector.cpu.info.bugs-include", c.CPUBugsInclude)
	}

	if collectors[CollectorDiskstats] {
		flags.add("--collector.diskstats.ignored-devices", c.DiskStatsIgnoredDevices)
	}

	if collectors[CollectorEthtool] {
		flags.add("--collector.ethtool.device-include", c.EthtoolDeviceInclude)
		flags.add("--collector.ethtool.device-exclude", c.EthtoolDeviceExclude)
		flags.add("--collector.ethtool.metrics-include", c.EthtoolMetricsInclude)
	}

	if collectors[CollectorFilesystem] {
		flags.add(
			"--collector.filesystem.mount-timeout", c.FilesystemMountTimeout.String(),
			"--collector.filesystem.mount-points-exclude", c.FilesystemMountPointsExclude,
			"--collector.filesystem.fs-types-exclude", c.FilesystemFSTypesExclude,
		)
	}

	if collectors[CollectorIPVS] {
		flags.add("--collector.ipvs.backend-labels", strings.Join(c.IPVSBackendLabels, ","))
	}

	if collectors[CollectorNetclass] {
		flags.addBools(map[*bool]string{
			&c.NetclassIgnoreInvalidSpeedDevice: "collector.netclass.ignore-invalid-speed",
		})

		flags.add("--collector.netclass.ignored-devices", c.NetclassIgnoredDevices)
	}

	if collectors[CollectorNetdev] {
		flags.addBools(map[*bool]string{
			&c.NetdevAddressInfo: "collector.netdev.address-info",
		})

		flags.add(
			"--collector.netdev.device-include", c.NetdevDeviceInclude,
			"--collector.netdev.device-exclude", c.NetdevDeviceExclude,
		)
	}

	if collectors[CollectorNetstat] {
		flags.add("--collector.netstat.fields", c.NetstatFields)
	}

	if collectors[CollectorNTP] {
		flags.add(
			"--collector.ntp.server", c.NTPServer,
			"--collector.ntp.protocol-version", fmt.Sprintf("%d", c.NTPProtocolVersion),
			"--collector.ntp.ip-ttl", fmt.Sprintf("%d", c.NTPIPTTL),
			"--collector.ntp.max-distance", c.NTPMaxDistance.String(),
			"--collector.ntp.local-offset-tolerance", c.NTPLocalOffsetTolerance.String(),
		)

		flags.addBools(map[*bool]string{
			&c.NTPServerIsLocal: "collector.ntp.server-is-local",
		})
	}

	if collectors[CollectorPerf] {
		flags.add("--collector.perf.cpus", c.PerfCPUS)

		for _, tp := range c.PerfTracepoint {
			flags.add("--collector.perf.tracepoint", tp)
		}
	}

	if collectors[CollectorPowersuppply] {
		flags.add("--collector.powersupply.ignored-supplies", c.PowersupplyIgnoredSupplies)
	}

	if collectors[CollectorRunit] {
		flags.add("--collector.runit.servicedir", c.RunitServiceDir)
	}

	if collectors[CollectorSupervisord] {
		flags.add("--collector.supervisord.url", c.SupervisordURL)
	}

	if collectors[CollectorSystemd] {
		flags.add(
			"--collector.systemd.unit-include", c.SystemdUnitInclude,
			"--collector.systemd.unit-exclude", c.SystemdUnitExclude,
		)

		flags.addBools(map[*bool]string{
			&c.SystemdEnableTaskMetrics:      "collector.systemd.enable-task-metrics",
			&c.SystemdEnableRestartsMetrics:  "collector.systemd.enable-restarts-metrics",
			&c.SystemdEnableStartTimeMetrics: "collector.systemd.enable-start-time-metrics",
		})
	}

	if collectors[CollectorTapestats] {
		flags.add("--collector.tapestats.ignored-devices", c.TapestatsIgnoredDevices)
	}

	if collectors[CollectorTextfile] {
		flags.add("--collector.textfile.directory", c.TextfileDirectory)
	}

	if collectors[CollectorVMStat] {
		flags.add("--collector.vmstat.fields", c.VMStatFields)
	}

	return flags.accepted, flags.ignored
}

type flags struct {
	accepted []string
	ignored  []string
}

// add pushes new flags as key value pairs. If the flag isn't registered with kingpin,
// it will be ignored.
func (f *flags) add(kvp ...string) {
	if (len(kvp) % 2) != 0 {
		panic("missing value for added flag")
	}

	for i := 0; i < len(kvp); i += 2 {
		key := kvp[i+0]
		value := kvp[i+1]

		rawFlag := strings.TrimPrefix(key, "--")
		if kingpin.CommandLine.GetFlag(rawFlag) == nil {
			f.ignored = append(f.ignored, rawFlag)
			continue
		}

		f.accepted = append(f.accepted, key, value)
	}
}

func (f *flags) addBools(m map[*bool]string) {
	for setting, key := range m {
		// The flag might not exist on this platform, so skip it if it's not
		// defined.
		if kingpin.CommandLine.GetFlag(key) == nil {
			f.ignored = append(f.ignored, key)
			continue
		}

		if *setting {
			f.accepted = append(f.accepted, "--"+key)
		} else {
			f.accepted = append(f.accepted, "--no-"+key)
		}
	}
}

'''
'''--- pkg/integrations/node_exporter/config_test.go ---
package node_exporter //nolint:golint

import (
	"fmt"
	"testing"

	"github.com/stretchr/testify/require"
	"gopkg.in/yaml.v2"
)

func TestNodeExporter_Config(t *testing.T) {
	var c Config

	err := yaml.Unmarshal([]byte("{}"), &c)
	require.NoError(t, err)
	require.Equal(t, DefaultConfig, c)
}

func TestNodeExporter_ConfigMigrate(t *testing.T) {
	tt := []struct {
		name           string
		in             string
		expectError    string
		expectWarnings []string
		check          func(t *testing.T, c *Config)
	}{
		{
			name: "old fields migrate",
			in: `
      netdev_device_whitelist: netdev_wl
      netdev_device_blacklist: netdev_bl
      systemd_unit_whitelist: systemd_wl
      systemd_unit_blacklist: systemd_bl
      filesystem_ignored_mount_points: fs_mp
      filesystem_ignored_fs_types: fs_types
      `,
			expectWarnings: []string{
				`"netdev_device_whitelist" is deprecated by "netdev_device_include" and will be removed in a future version`,
				`"netdev_device_blacklist" is deprecated by "netdev_device_exclude" and will be removed in a future version`,
				`"systemd_unit_whitelist" is deprecated by "systemd_unit_include" and will be removed in a future version`,
				`"systemd_unit_blacklist" is deprecated by "systemd_unit_exclude" and will be removed in a future version`,
				`"filesystem_ignored_mount_points" is deprecated by "filesystem_mount_points_exclude" and will be removed in a future version`,
				`"filesystem_ignored_fs_types" is deprecated by "filesystem_fs_types_exclude" and will be removed in a future version`,
			},
			check: func(t *testing.T, c *Config) {
				t.Helper()

				require.Equal(t, c.NetdevDeviceInclude, "netdev_wl")
				require.Equal(t, c.NetdevDeviceExclude, "netdev_bl")
				require.Equal(t, c.SystemdUnitInclude, "systemd_wl")
				require.Equal(t, c.SystemdUnitExclude, "systemd_bl")
				require.Equal(t, c.FilesystemMountPointsExclude, "fs_mp")
				require.Equal(t, c.FilesystemFSTypesExclude, "fs_types")
			},
		},
		{
			name: "new fields valid",
			in: `
      netdev_device_include: netdev_wl
      netdev_device_exclude: netdev_bl
      systemd_unit_include: systemd_wl
      systemd_unit_exclude: systemd_bl
      filesystem_mount_points_exclude: fs_mp
      filesystem_fs_types_exclude: fs_types
      `,
			check: func(t *testing.T, c *Config) {
				t.Helper()

				require.Equal(t, c.NetdevDeviceInclude, "netdev_wl")
				require.Equal(t, c.NetdevDeviceExclude, "netdev_bl")
				require.Equal(t, c.SystemdUnitInclude, "systemd_wl")
				require.Equal(t, c.SystemdUnitExclude, "systemd_bl")
				require.Equal(t, c.FilesystemMountPointsExclude, "fs_mp")
				require.Equal(t, c.FilesystemFSTypesExclude, "fs_types")
			},
		},
		{
			name:        `netdev_device_whitelist and netdev_device_include`,
			in:          illegalConfig("netdev_device_whitelist", "netdev_device_include"),
			expectError: `only one of "netdev_device_whitelist" and "netdev_device_include" may be specified`,
		},
		{
			name:        `netdev_device_blacklist and netdev_device_exclude`,
			in:          illegalConfig("netdev_device_blacklist", "netdev_device_exclude"),
			expectError: `only one of "netdev_device_blacklist" and "netdev_device_exclude" may be specified`,
		},
		{
			name:        `systemd_unit_whitelist and systemd_unit_include`,
			in:          illegalConfig("systemd_unit_whitelist", "systemd_unit_include"),
			expectError: `only one of "systemd_unit_whitelist" and "systemd_unit_include" may be specified`,
		},
		{
			name:        `systemd_unit_blacklist and systemd_unit_exclude`,
			in:          illegalConfig("systemd_unit_blacklist", "systemd_unit_exclude"),
			expectError: `only one of "systemd_unit_blacklist" and "systemd_unit_exclude" may be specified`,
		},
		{
			name:        `filesystem_ignored_mount_points and filesystem_mount_points_exclude`,
			in:          illegalConfig("filesystem_ignored_mount_points", "filesystem_mount_points_exclude"),
			expectError: `only one of "filesystem_ignored_mount_points" and "filesystem_mount_points_exclude" may be specified`,
		},
		{
			name:        `filesystem_ignored_fs_types and filesystem_fs_types_exclude`,
			in:          illegalConfig("filesystem_ignored_fs_types", "filesystem_fs_types_exclude"),
			expectError: `only one of "filesystem_ignored_fs_types" and "filesystem_fs_types_exclude" may be specified`,
		},
	}

	for _, tc := range tt {
		t.Run(tc.name, func(t *testing.T) {
			var c Config

			err := yaml.Unmarshal([]byte(tc.in), &c)
			if tc.expectError != "" {
				require.EqualError(t, err, tc.expectError)
				return
			}
			require.NoError(t, err)

			require.ElementsMatch(t, tc.expectWarnings, c.UnmarshalWarnings)
			if tc.check != nil {
				tc.check(t, &c)
			}
		})
	}
}

func illegalConfig(oldName, newName string) string {
	return fmt.Sprintf(`
  %s: illegal
  %s: illegal
  `, oldName, newName)
}

'''
'''--- pkg/integrations/node_exporter/node_exporter.go ---
package node_exporter //nolint:golint

import (
	"context"
	"fmt"
	"net/http"
	"sort"
	"strings"

	"github.com/go-kit/log"
	"github.com/go-kit/log/level"
	"github.com/grafana/agent/pkg/integrations/config"
	"github.com/prometheus/client_golang/prometheus"
	"github.com/prometheus/client_golang/prometheus/promhttp"
	"github.com/prometheus/common/version"
	"github.com/prometheus/node_exporter/collector"
	"gopkg.in/alecthomas/kingpin.v2"
)

// Integration is the node_exporter integration. The integration scrapes metrics
// from the host Linux-based system.
type Integration struct {
	c      *Config
	logger log.Logger
	nc     *collector.NodeCollector

	exporterMetricsRegistry *prometheus.Registry
}

// New creates a new node_exporter integration.
func New(log log.Logger, c *Config) (*Integration, error) {
	// NOTE(rfratto): this works as long as node_exporter is the only thing using
	// kingpin across the codebase. node_exporter may need a PR eventually to pass
	// in a custom kingpin application or expose methods to explicitly enable/disable
	// collectors that we can use instead of this command line hack.
	flags, _ := MapConfigToNodeExporterFlags(c)
	level.Debug(log).Log("msg", "initializing node_exporter with flags converted from agent config", "flags", strings.Join(flags, " "))

	for _, warn := range c.UnmarshalWarnings {
		level.Warn(log).Log("msg", warn)
	}

	_, err := kingpin.CommandLine.Parse(flags)
	if err != nil {
		return nil, fmt.Errorf("failed to parse flags for generating node_exporter configuration: %w", err)
	}

	nc, err := collector.NewNodeCollector(log)
	if err != nil {
		return nil, fmt.Errorf("failed to create node_exporter: %w", err)
	}

	level.Info(log).Log("msg", "Enabled node_exporter collectors")
	collectors := []string{}
	for n := range nc.Collectors {
		collectors = append(collectors, n)
	}
	sort.Strings(collectors)
	for _, c := range collectors {
		level.Info(log).Log("collector", c)
	}

	return &Integration{
		c:      c,
		logger: log,
		nc:     nc,

		exporterMetricsRegistry: prometheus.NewRegistry(),
	}, nil
}

// MetricsHandler implements Integration.
func (i *Integration) MetricsHandler() (http.Handler, error) {
	r := prometheus.NewRegistry()
	if err := r.Register(i.nc); err != nil {
		return nil, fmt.Errorf("couldn't register node_exporter node collector: %w", err)
	}
	handler := promhttp.HandlerFor(
		prometheus.Gatherers{i.exporterMetricsRegistry, r},
		promhttp.HandlerOpts{
			ErrorHandling:       promhttp.ContinueOnError,
			MaxRequestsInFlight: 0,
			Registry:            i.exporterMetricsRegistry,
		},
	)

	// Register node_exporter_build_info metrics, generally useful for
	// dashboards that depend on them for discovering targets.
	if err := r.Register(version.NewCollector(i.c.Name())); err != nil {
		return nil, fmt.Errorf("couldn't register %s: %w", i.c.Name(), err)
	}

	if i.c.IncludeExporterMetrics {
		// Note that we have to use reg here to use the same promhttp metrics for
		// all expositions.
		handler = promhttp.InstrumentMetricHandler(i.exporterMetricsRegistry, handler)
	}

	return handler, nil
}

// ScrapeConfigs satisfies Integration.ScrapeConfigs.
func (i *Integration) ScrapeConfigs() []config.ScrapeConfig {
	return []config.ScrapeConfig{{
		JobName:     i.c.Name(),
		MetricsPath: "/metrics",
	}}
}

// Run satisfies Integration.Run.
func (i *Integration) Run(ctx context.Context) error {
	// We don't need to do anything here, so we can just wait for the context to
	// finish.
	<-ctx.Done()
	return ctx.Err()
}

'''
'''--- pkg/integrations/node_exporter/node_exporter_linux.go ---
package node_exporter //nolint:golint

import (
	"github.com/prometheus/procfs/sysfs"
)

func init() {
	DefaultConfig.SysFSPath = sysfs.DefaultMountPoint
}

'''
'''--- pkg/integrations/node_exporter/node_exporter_test.go ---
//go:build !race
// +build !race

package node_exporter //nolint:golint

import (
	"io"
	"io/ioutil"
	"net/http"
	"net/http/httptest"
	"runtime"
	"testing"

	"github.com/go-kit/log"
	"github.com/go-kit/log/level"
	"github.com/gorilla/mux"
	"github.com/grafana/agent/pkg/util"
	"github.com/prometheus/prometheus/model/textparse"
	"github.com/stretchr/testify/assert"
	"github.com/stretchr/testify/require"
	"gopkg.in/alecthomas/kingpin.v2"
)

// TestNodeExporter runs an integration test for node_exporter, doing the
// following:
//
// 1. Enabling all collectors (minus some that cause issues in cross-platform testing)
// 2. Creating the integration
// 3. Scrape the integration once
// 4. Parse the result of the scrape
//
// This ensures that the flag parsing is correct and that the handler is
// set up properly. We do not test the contents of the scrape, just that it
// was parsable by Prometheus.
func TestNodeExporter(t *testing.T) {
	cfg := DefaultConfig

	// Enable all collectors except perf
	cfg.SetCollectors = make([]string, 0, len(Collectors))
	for c := range Collectors {
		cfg.SetCollectors = append(cfg.SetCollectors, c)
	}
	cfg.DisableCollectors = []string{CollectorPerf, CollectorBuddyInfo}

	// Check that the flags convert and the integration initiailizes
	logger := log.NewNopLogger()
	integration, err := New(logger, &cfg)
	require.NoError(t, err, "failed to setup node_exporter")

	r := mux.NewRouter()
	handler, err := integration.MetricsHandler()
	require.NoError(t, err)
	r.Handle("/metrics", handler)

	// Invoke /metrics and parse the response
	srv := httptest.NewServer(r)
	defer srv.Close()

	res, err := http.Get(srv.URL + "/metrics")
	require.NoError(t, err)

	body, err := ioutil.ReadAll(res.Body)
	require.NoError(t, err)

	p := textparse.NewPromParser(body)
	for {
		_, err := p.Next()
		if err == io.EOF {
			break
		}
		require.NoError(t, err)
	}
}

// TestFTestNodeExporter_IgnoredFlags ensures that flags don't get ignored for
// misspellings.
func TestNodeExporter_IgnoredFlags(t *testing.T) {
	l := util.TestLogger(t)
	cfg := DefaultConfig

	// Enable all collectors except perf
	cfg.SetCollectors = make([]string, 0, len(Collectors))
	for c := range Collectors {
		cfg.SetCollectors = append(cfg.SetCollectors, c)
	}
	cfg.DisableCollectors = []string{CollectorPerf}

	_, ignored := MapConfigToNodeExporterFlags(&cfg)
	var expect []string

	switch runtime.GOOS {
	case "darwin":
		expect = []string{
			"collector.cpu.info",
			"collector.cpu.guest",
			"collector.cpu.info.flags-include",
			"collector.cpu.info.bugs-include",
			"collector.diskstats.ignored-devices",
			"collector.filesystem.mount-timeout",
		}
	}

	if !assert.ElementsMatch(t, expect, ignored) {
		level.Debug(l).Log("msg", "printing available flags")
		for _, flag := range kingpin.CommandLine.Model().Flags {
			level.Debug(l).Log("flag", flag.Name, "hidden", flag.Hidden)
		}
	}
}

// TestFlags makes sure that boolean flags and some known non-boolean flags
// work as expected
func TestFlags(t *testing.T) {
	var f flags
	f.add("--path.rootfs", "/")
	require.Equal(t, []string{"--path.rootfs", "/"}, f.accepted)

	// Set up booleans to use as pointers
	var (
		truth = true

		// You know, the opposite of truth?
		falth = false
	)

	f = flags{}
	f.addBools(map[*bool]string{&truth: "collector.textfile"})
	require.Equal(t, []string{"--collector.textfile"}, f.accepted)

	f = flags{}
	f.addBools(map[*bool]string{&falth: "collector.textfile"})
	require.Equal(t, []string{"--no-collector.textfile"}, f.accepted)
}

'''
'''--- pkg/integrations/postgres_exporter/postgres_exporter.go ---
// Package postgres_exporter embeds https://github.com/prometheus/postgres_exporter
package postgres_exporter //nolint:golint

import (
	"fmt"
	"os"
	"strings"

	config_util "github.com/prometheus/common/config"

	"github.com/go-kit/log"
	"github.com/grafana/agent/pkg/integrations"
	integrations_v2 "github.com/grafana/agent/pkg/integrations/v2"
	"github.com/grafana/agent/pkg/integrations/v2/metricsutils"
	"github.com/lib/pq"
	"github.com/prometheus-community/postgres_exporter/exporter"
)

// Config controls the postgres_exporter integration.
type Config struct {
	// DataSourceNames to use to connect to Postgres.
	DataSourceNames []config_util.Secret `yaml:"data_source_names,omitempty"`

	DisableSettingsMetrics bool     `yaml:"disable_settings_metrics,omitempty"`
	AutodiscoverDatabases  bool     `yaml:"autodiscover_databases,omitempty"`
	ExcludeDatabases       []string `yaml:"exclude_databases,omitempty"`
	IncludeDatabases       []string `yaml:"include_databases,omitempty"`
	DisableDefaultMetrics  bool     `yaml:"disable_default_metrics,omitempty"`
	QueryPath              string   `yaml:"query_path,omitempty"`
}

// Name returns the name of the integration this config is for.
func (c *Config) Name() string {
	return "postgres_exporter"
}

// NewIntegration converts this config into an instance of a configuration.
func (c *Config) NewIntegration(l log.Logger) (integrations.Integration, error) {
	return New(l, c)
}

// InstanceKey returns a simplified DSN of the first postgresql DSN, or an error if
// not exactly one DSN is provided.
func (c *Config) InstanceKey(_ string) (string, error) {
	dsn, err := c.getDataSourceNames()
	if err != nil {
		return "", err
	}
	if len(dsn) != 1 {
		return "", fmt.Errorf("can't automatically determine a value for `instance` with %d DSN. either use 1 DSN or manually assign a value for `instance` in the integration config", len(dsn))
	}

	s, err := parsePostgresURL(dsn[0])
	if err != nil {
		return "", fmt.Errorf("cannot parse DSN: %w", err)
	}

	// Assign default values to s.
	//
	// PostgreSQL hostspecs can contain multiple host pairs. We'll assign a host
	// and port by default, but otherwise just use the hostname.
	if _, ok := s["host"]; !ok {
		s["host"] = "localhost"
		s["port"] = "5432"
	}

	hostport := s["host"]
	if p, ok := s["port"]; ok {
		hostport += fmt.Sprintf(":%s", p)
	}
	return fmt.Sprintf("postgresql://%s/%s", hostport, s["dbname"]), nil
}

func parsePostgresURL(url string) (map[string]string, error) {
	raw, err := pq.ParseURL(url)
	if err != nil {
		return nil, err
	}

	res := map[string]string{}

	unescaper := strings.NewReplacer(`\'`, `'`, `\\`, `\`)

	for _, keypair := range strings.Split(raw, " ") {
		parts := strings.SplitN(keypair, "=", 2)
		if len(parts) != 2 {
			panic(fmt.Sprintf("unexpected keypair %s from pq", keypair))
		}

		key := parts[0]
		value := parts[1]

		// Undo all the transformations ParseURL did: remove wrapping
		// quotes and then unescape the escaped characters.
		value = strings.TrimPrefix(value, "'")
		value = strings.TrimSuffix(value, "'")
		value = unescaper.Replace(value)

		res[key] = value
	}

	return res, nil
}

// getDataSourceNames loads data source names from the config or from the
// environment, if set.
func (c *Config) getDataSourceNames() ([]string, error) {
	dsn := c.DataSourceNames
	var stringDsn []string
	if len(dsn) == 0 {
		stringDsn = append(stringDsn, strings.Split(os.Getenv("POSTGRES_EXPORTER_DATA_SOURCE_NAME"), ",")...)
	} else {
		for _, d := range dsn {
			stringDsn = append(stringDsn, string(d))
		}
	}
	if len(stringDsn) == 0 {
		return nil, fmt.Errorf("cannot create postgres_exporter; neither postgres_exporter.data_source_name or $POSTGRES_EXPORTER_DATA_SOURCE_NAME is set")
	}
	return stringDsn, nil
}

func init() {
	integrations.RegisterIntegration(&Config{})
	integrations_v2.RegisterLegacy(&Config{}, integrations_v2.TypeMultiplex, metricsutils.NewNamedShim("postgres"))
}

// New creates a new postgres_exporter integration. The integration scrapes
// metrics from a postgres process.
func New(log log.Logger, c *Config) (integrations.Integration, error) {
	dsn, err := c.getDataSourceNames()
	if err != nil {
		return nil, err
	}

	e := exporter.NewExporter(
		dsn,
		log,
		exporter.DisableDefaultMetrics(c.DisableDefaultMetrics),
		exporter.WithUserQueriesPath(c.QueryPath),
		exporter.DisableSettingsMetrics(c.DisableSettingsMetrics),
		exporter.AutoDiscoverDatabases(c.AutodiscoverDatabases),
		exporter.ExcludeDatabases(strings.Join(c.ExcludeDatabases, ",")),
		exporter.IncludeDatabases(strings.Join(c.IncludeDatabases, ",")),
		exporter.MetricPrefix("pg"),
	)

	return integrations.NewCollectorIntegration(c.Name(), integrations.WithCollectors(e)), nil
}

'''
'''--- pkg/integrations/postgres_exporter/postgres_exporter_test.go ---
package postgres_exporter //nolint:golint

import (
	"os"
	"testing"

	"github.com/stretchr/testify/require"
	"gopkg.in/yaml.v2"
)

func Test_ParsePostgresURL(t *testing.T) {
	dsn := "postgresql://linus:42secret@localhost:5432/postgres?sslmode=disable"
	expected := map[string]string{
		"dbname":   "postgres",
		"host":     "localhost",
		"password": "42secret",
		"port":     "5432",
		"sslmode":  "disable",
		"user":     "linus",
	}

	actual, err := parsePostgresURL(dsn)
	require.NoError(t, err)
	require.Equal(t, actual, expected)
}

func Test_getDataSourceNames(t *testing.T) {
	tt := []struct {
		name   string
		config string
		env    string
		expect []string
	}{
		{
			name:   "env",
			config: "{}",
			env:    "foo",
			expect: []string{"foo"},
		},
		{
			name:   "multi-env",
			config: "{}",
			env:    "foo,bar",
			expect: []string{"foo", "bar"},
		},
		{
			name: "config",
			config: `{
        "data_source_names": [
          "foo"
        ]
      }`,
			env:    "",
			expect: []string{"foo"},
		},
		{
			name: "config and env",
			config: `{
        "data_source_names": [
          "foo"
        ]
      }`,
			env:    "bar",
			expect: []string{"foo"},
		},
	}

	for _, tc := range tt {
		t.Run(tc.name, func(t *testing.T) {
			orig := os.Getenv("POSTGRES_EXPORTER_DATA_SOURCE_NAME")
			t.Cleanup(func() {
				os.Setenv("POSTGRES_EXPORTER_DATA_SOURCE_NAME", orig)
			})
			os.Setenv("POSTGRES_EXPORTER_DATA_SOURCE_NAME", tc.env)

			var cfg Config
			err := yaml.Unmarshal([]byte(tc.config), &cfg)
			require.NoError(t, err)

			res, err := cfg.getDataSourceNames()
			require.NoError(t, err)
			require.Equal(t, tc.expect, res)
		})
	}
}

'''
'''--- pkg/integrations/postgres_exporter/postgres_test.go ---
package postgres_exporter //nolint:golint

import (
	"testing"

	"github.com/grafana/agent/pkg/config"
)

func TestConfig_SecretPostgres(t *testing.T) {
	stringCfg := `
prometheus:
  wal_directory: /tmp/agent
integrations:
  postgres_exporter:
    enabled: true
    data_source_names: ["secret_password_in_uri","secret_password_in_uri_2"]
`
	config.CheckSecret(t, stringCfg, "secret_password_in_uri")
	config.CheckSecret(t, stringCfg, "secret_password_in_uri_2")
}

'''
'''--- pkg/integrations/process_exporter/config.go ---
// Package process_exporter embeds https://github.com/ncabatoff/process-exporter
package process_exporter //nolint:golint

import (
	"github.com/go-kit/log"
	"github.com/grafana/agent/pkg/integrations"
	integrations_v2 "github.com/grafana/agent/pkg/integrations/v2"
	"github.com/grafana/agent/pkg/integrations/v2/metricsutils"

	exporter_config "github.com/ncabatoff/process-exporter/config"
)

// DefaultConfig holds the default settings for the process_exporter integration.
var DefaultConfig = Config{
	ProcFSPath: "/proc",
	Children:   true,
	Threads:    true,
	SMaps:      true,
	Recheck:    false,
}

// Config controls the process_exporter integration.
type Config struct {
	ProcessExporter exporter_config.MatcherRules `yaml:"process_names,omitempty"`

	ProcFSPath string `yaml:"procfs_path,omitempty"`
	Children   bool   `yaml:"track_children,omitempty"`
	Threads    bool   `yaml:"track_threads,omitempty"`
	SMaps      bool   `yaml:"gather_smaps,omitempty"`
	Recheck    bool   `yaml:"recheck_on_scrape,omitempty"`
}

// UnmarshalYAML implements yaml.Unmarshaler.
func (c *Config) UnmarshalYAML(unmarshal func(v interface{}) error) error {
	*c = DefaultConfig

	type plain Config
	return unmarshal((*plain)(c))
}

// Name returns the name of the integration that this config represents.
func (c *Config) Name() string {
	return "process_exporter"
}

// InstanceKey returns the hostname of the machine.
func (c *Config) InstanceKey(agentKey string) (string, error) {
	return agentKey, nil
}

// NewIntegration converts this config into an instance of an integration.
func (c *Config) NewIntegration(l log.Logger) (integrations.Integration, error) {
	return New(l, c)
}

func init() {
	integrations.RegisterIntegration(&Config{})
	integrations_v2.RegisterLegacy(&Config{}, integrations_v2.TypeSingleton, metricsutils.NewNamedShim("process"))
}

'''
'''--- pkg/integrations/process_exporter/process-exporter.go ---
//go:build !linux
// +build !linux

// Package process_exporter embeds https://github.com/ncabatoff/process-exporter
package process_exporter //nolint:golint

import (
	"context"
	"net/http"

	"github.com/go-kit/log"
	"github.com/go-kit/log/level"
	"github.com/grafana/agent/pkg/integrations/config"
)

// Integration is the process_exporter integration. On non-Linux platforms,
// this integration does nothing and will print a warning if enabled.
type Integration struct {
	c *Config
}

// New creates a process_exporter integration for non-Linux platforms, which is always a
// no-op.
func New(logger log.Logger, c *Config) (*Integration, error) {
	level.Warn(logger).Log("msg", "the process_exporter only works on Linux; enabling it otherwise will do nothing")
	return &Integration{c: c}, nil
}

// MetricsHandler satisfies Integration.RegisterRoutes.
func (i *Integration) MetricsHandler() (http.Handler, error) {
	return http.NotFoundHandler(), nil
}

// ScrapeConfigs satisfies Integration.ScrapeConfigs.
func (i *Integration) ScrapeConfigs() []config.ScrapeConfig {
	// No-op: nothing to scrape.
	return []config.ScrapeConfig{}
}

// Run satisfies Integration.Run.
func (i *Integration) Run(ctx context.Context) error {
	// We don't need to do anything here, so we can just wait for the context to
	// finish.
	<-ctx.Done()
	return ctx.Err()
}

'''
'''--- pkg/integrations/process_exporter/process-exporter_linux.go ---
// Package process_exporter embeds https://github.com/ncabatoff/process-exporter
package process_exporter //nolint:golint

import (
	"context"
	"fmt"
	"net/http"

	"github.com/go-kit/log"
	"github.com/grafana/agent/pkg/integrations/config"
	"github.com/prometheus/client_golang/prometheus"
	"github.com/prometheus/client_golang/prometheus/promhttp"
	"github.com/prometheus/common/version"

	"github.com/ncabatoff/process-exporter/collector"
)

// Integration is the process_exporter integration. The integration scrapes
// metrics based on information in the /proc filesystem for Linux.
// Agent's own metrics.
type Integration struct {
	c         *Config
	collector *collector.NamedProcessCollector
}

// New creaets a new instance of the process_exporter integration.
func New(logger log.Logger, c *Config) (*Integration, error) {
	cfg, err := c.ProcessExporter.ToConfig()
	if err != nil {
		return nil, fmt.Errorf("process_names is invalid: %w", err)
	}

	pc, err := collector.NewProcessCollector(collector.ProcessCollectorOption{
		ProcFSPath:  c.ProcFSPath,
		Children:    c.Children,
		Threads:     c.Threads,
		GatherSMaps: c.SMaps,
		Namer:       cfg.MatchNamers,
		Recheck:     c.Recheck,
		Debug:       false,
	})
	if err != nil {
		return nil, err
	}

	return &Integration{c: c, collector: pc}, nil
}

// MetricsHandler satisfies Integration.RegisterRoutes.
func (i *Integration) MetricsHandler() (http.Handler, error) {
	r := prometheus.NewRegistry()
	if err := r.Register(i.collector); err != nil {
		return nil, fmt.Errorf("couldn't register process_exporter collector: %w", err)
	}

	// Register process_exporter_build_info metrics, generally useful for
	// dashboards that depend on them for discovering targets.
	if err := r.Register(version.NewCollector("process_exporter")); err != nil {
		return nil, fmt.Errorf("couldn't register process_exporter: %w", err)
	}

	return promhttp.HandlerFor(
		prometheus.Gatherers{r},
		promhttp.HandlerOpts{
			ErrorHandling:       promhttp.ContinueOnError,
			MaxRequestsInFlight: 0,
		},
	), nil
}

// ScrapeConfigs satisfies Integration.ScrapeConfigs.
func (i *Integration) ScrapeConfigs() []config.ScrapeConfig {
	return []config.ScrapeConfig{{
		JobName:     i.c.Name(),
		MetricsPath: "/metrics",
	}}
}

// Run satisfies Integration.Run.
func (i *Integration) Run(ctx context.Context) error {
	// We don't need to do anything here, so we can just wait for the context to
	// finish.
	<-ctx.Done()
	return ctx.Err()
}

'''
'''--- pkg/integrations/redis_exporter/redis_exporter.go ---
// Package redis_exporter embeds https://github.com/oliver006/redis_exporter
package redis_exporter //nolint:golint

import (
	"errors"
	"fmt"
	"io/ioutil"
	"time"

	"github.com/grafana/agent/pkg/integrations"
	integrations_v2 "github.com/grafana/agent/pkg/integrations/v2"
	"github.com/grafana/agent/pkg/integrations/v2/metricsutils"

	"github.com/go-kit/log"
	"github.com/go-kit/log/level"
	re "github.com/oliver006/redis_exporter/exporter"
	config_util "github.com/prometheus/common/config"
)

// DefaultConfig holds non-zero default options for the Config when it is
// unmarshaled from YAML.
var DefaultConfig = Config{
	Namespace:               "redis",
	ConfigCommand:           "CONFIG",
	ConnectionTimeout:       15 * time.Second,
	SetClientName:           true,
	CheckKeyGroupsBatchSize: 10000,
	MaxDistinctKeyGroups:    100,
}

// Config controls the redis_exporter integration.
type Config struct {
	IncludeExporterMetrics bool `yaml:"include_exporter_metrics"`

	// exporter-specific config.
	//
	// The exporter binary config differs to this, but these
	// are the only fields that are relevant to the exporter struct.
	RedisAddr               string             `yaml:"redis_addr,omitempty"`
	RedisUser               string             `yaml:"redis_user,omitempty"`
	RedisPassword           config_util.Secret `yaml:"redis_password,omitempty"`
	RedisPasswordFile       string             `yaml:"redis_password_file,omitempty"`
	Namespace               string             `yaml:"namespace,omitempty"`
	ConfigCommand           string             `yaml:"config_command,omitempty"`
	CheckKeys               string             `yaml:"check_keys,omitempty"`
	CheckKeyGroups          string             `yaml:"check_key_groups,omitempty"`
	CheckKeyGroupsBatchSize int64              `yaml:"check_key_groups_batch_size,omitempty"`
	MaxDistinctKeyGroups    int64              `yaml:"max_distinct_key_groups,omitempty"`
	CheckSingleKeys         string             `yaml:"check_single_keys,omitempty"`
	CheckStreams            string             `yaml:"check_streams,omitempty"`
	CheckSingleStreams      string             `yaml:"check_single_streams,omitempty"`
	CountKeys               string             `yaml:"count_keys,omitempty"`
	ScriptPath              string             `yaml:"script_path,omitempty"`
	ConnectionTimeout       time.Duration      `yaml:"connection_timeout,omitempty"`
	TLSClientKeyFile        string             `yaml:"tls_client_key_file,omitempty"`
	TLSClientCertFile       string             `yaml:"tls_client_cert_file,omitempty"`
	TLSCaCertFile           string             `yaml:"tls_ca_cert_file,omitempty"`
	SetClientName           bool               `yaml:"set_client_name,omitempty"`
	IsTile38                bool               `yaml:"is_tile38,omitempty"`
	ExportClientList        bool               `yaml:"export_client_list,omitempty"`
	ExportClientPort        bool               `yaml:"export_client_port,omitempty"`
	RedisMetricsOnly        bool               `yaml:"redis_metrics_only,omitempty"`
	PingOnConnect           bool               `yaml:"ping_on_connect,omitempty"`
	InclSystemMetrics       bool               `yaml:"incl_system_metrics,omitempty"`
	SkipTLSVerification     bool               `yaml:"skip_tls_verification,omitempty"`
}

// GetExporterOptions returns relevant Config properties as a redis_exporter
// Options struct. The redis_exporter Options struct has no yaml tags, so
// we marshal the yaml into Config and then create the re.Options from that.
func (c Config) GetExporterOptions() re.Options {
	return re.Options{
		User:                  c.RedisUser,
		Password:              string(c.RedisPassword),
		Namespace:             c.Namespace,
		ConfigCommandName:     c.ConfigCommand,
		CheckKeys:             c.CheckKeys,
		CheckKeysBatchSize:    c.CheckKeyGroupsBatchSize,
		CheckKeyGroups:        c.CheckKeyGroups,
		CheckSingleKeys:       c.CheckSingleKeys,
		CheckStreams:          c.CheckStreams,
		CheckSingleStreams:    c.CheckSingleStreams,
		CountKeys:             c.CountKeys,
		InclSystemMetrics:     c.InclSystemMetrics,
		SkipTLSVerification:   c.SkipTLSVerification,
		SetClientName:         c.SetClientName,
		IsTile38:              c.IsTile38,
		ExportClientList:      c.ExportClientList,
		ExportClientsInclPort: c.ExportClientPort,
		ConnectionTimeouts:    c.ConnectionTimeout,
		RedisMetricsOnly:      c.RedisMetricsOnly,
		PingOnConnect:         c.PingOnConnect,
	}
}

// UnmarshalYAML implements yaml.Unmarshaler for Config
func (c *Config) UnmarshalYAML(unmarshal func(interface{}) error) error {
	*c = DefaultConfig

	type plain Config
	return unmarshal((*plain)(c))
}

// Name returns the name of the integration this config is for.
func (c *Config) Name() string {
	return "redis_exporter"
}

// InstanceKey returns the addr of the redis server.
func (c *Config) InstanceKey(agentKey string) (string, error) {
	return c.RedisAddr, nil
}

// NewIntegration converts the config into an integration instance.
func (c *Config) NewIntegration(l log.Logger) (integrations.Integration, error) {
	return New(l, c)
}

func init() {
	integrations.RegisterIntegration(&Config{})
	integrations_v2.RegisterLegacy(&Config{}, integrations_v2.TypeMultiplex, metricsutils.NewNamedShim("redis"))
}

// New creates a new redis_exporter integration. The integration queries
// a redis instance's INFO and exposes the results as metrics.
func New(log log.Logger, c *Config) (integrations.Integration, error) {
	level.Debug(log).Log("msg", "initializing redis_exporter", "config", c)

	exporterConfig := c.GetExporterOptions()

	if c.RedisAddr == "" {
		return nil, errors.New("cannot create redis_exporter; redis_exporter.redis_addr is not defined")
	}

	if c.ScriptPath != "" {
		ls, err := ioutil.ReadFile(c.ScriptPath)
		if err != nil {
			return nil, fmt.Errorf("Error loading script file %s: %w", c.ScriptPath, err)
		}
		exporterConfig.LuaScript = ls
	}

	//new version of the exporter takes the file paths directly, for hot-reloading support (https://github.com/oliver006/redis_exporter/pull/526)

	if (c.TLSClientKeyFile != "") != (c.TLSClientCertFile != "") {
		return nil, errors.New("TLS client key file and cert file should both be present")
	} else if c.TLSClientKeyFile != "" && c.TLSClientCertFile != "" {
		exporterConfig.ClientKeyFile = c.TLSClientKeyFile
		exporterConfig.ClientCertFile = c.TLSClientCertFile
	}

	if c.TLSCaCertFile != "" {
		exporterConfig.CaCertFile = c.TLSCaCertFile
	}

	// optional password file to take precedence over password property
	if c.RedisPasswordFile != "" {
		password, err := ioutil.ReadFile(c.RedisPasswordFile)
		if err != nil {
			return nil, fmt.Errorf("Error loading password file %s: %w", c.RedisPasswordFile, err)
		}
		exporterConfig.Password = string(password)
	}

	exporter, err := re.NewRedisExporter(
		c.RedisAddr,
		exporterConfig,
	)
	if err != nil {
		return nil, fmt.Errorf("failed to create redis exporter: %w", err)
	}

	return integrations.NewCollectorIntegration(
		c.Name(),
		integrations.WithCollectors(exporter),
		integrations.WithExporterMetricsIncluded(c.IncludeExporterMetrics),
	), nil
}

'''
'''--- pkg/integrations/redis_exporter/redis_exporter_test.go ---
package redis_exporter //nolint:golint

import (
	"bytes"
	"io"
	"io/ioutil"
	"net/http"
	"net/http/httptest"
	"testing"

	"github.com/grafana/agent/pkg/config"

	"github.com/go-kit/log"
	"github.com/gorilla/mux"
	"github.com/prometheus/prometheus/model/textparse"
	"github.com/stretchr/testify/require"
)

const addr string = "localhost:6379"

func TestRedisCases(t *testing.T) {
	tt := []struct {
		name                   string
		cfg                    Config
		expectedMetrics        []string
		expectConstructorError bool
	}{
		// Test that default config results in some metrics that can be parsed by
		// prometheus.
		{
			name: "Default config",
			cfg: (func() Config {
				c := DefaultConfig
				c.RedisAddr = addr
				return c
			})(),
			expectedMetrics: []string{},
		},
		// Test that exporter metrics are included when configured to do so.
		{
			name: "Include exporter metrics",
			cfg: (func() Config {
				c := DefaultConfig
				c.RedisAddr = addr
				c.IncludeExporterMetrics = true
				return c
			})(),
			expectedMetrics: []string{
				"promhttp_metric_handler_requests_total",
				"promhttp_metric_handler_requests_in_flight",
			},
		},
		// Test that some valid pre-constructor config logic doesn't cause errors.
		{
			name: "Lua script read OK",
			cfg: (func() Config {
				c := DefaultConfig
				c.RedisAddr = addr
				c.ScriptPath = "./redis_exporter.go" // file content is irrelevant
				return c
			})(),
		},
		// Test that some invalid pre-constructor config logic causes an error.
		{
			name: "Lua script read fail",
			cfg: (func() Config {
				c := DefaultConfig
				c.RedisAddr = addr
				c.ScriptPath = "/does/not/exist"
				return c
			})(),
			expectConstructorError: true,
		},
		// Test exporter complains when no address given via env or config.
		{
			name:                   "no address given",
			cfg:                    Config{}, // no address in here
			expectConstructorError: true,
		},
		// Test exporter constructs ok when password file is defined and exists
		{
			name: "valid password file",
			cfg: (func() Config {
				c := DefaultConfig
				c.RedisAddr = addr
				c.RedisPasswordFile = "./redis_exporter.go" // contents not important
				return c
			})(),
		},
		// Test exporter construction fails when password file is defined and doesnt
		// exist
		{
			name: "invalid password file",
			cfg: (func() Config {
				c := DefaultConfig
				c.RedisAddr = addr
				c.RedisPasswordFile = "/does/not/exist"
				return c
			})(),
			expectConstructorError: true,
		},
	}

	logger := log.NewNopLogger()

	for _, test := range tt {
		t.Run(test.name, func(t *testing.T) {
			integration, err := New(logger, &test.cfg)

			if test.expectConstructorError {
				require.Error(t, err, "expected failure when setting up redis_exporter")
				return
			}
			require.NoError(t, err, "failed to setup redis_exporter")

			r := mux.NewRouter()
			handler, err := integration.MetricsHandler()
			require.NoError(t, err)
			r.Handle("/metrics", handler)
			require.NoError(t, err)

			srv := httptest.NewServer(r)
			defer srv.Close()

			res, err := http.Get(srv.URL + "/metrics")
			require.NoError(t, err)

			body, err := ioutil.ReadAll(res.Body)
			require.NoError(t, err)

			foundMetricNames := map[string]bool{}
			for _, name := range test.expectedMetrics {
				foundMetricNames[name] = false
			}

			p := textparse.NewPromParser(body)
			for {
				entry, err := p.Next()
				if err == io.EOF {
					break
				}
				require.NoError(t, err)

				if entry == textparse.EntryHelp {
					matchMetricNames(foundMetricNames, p)
				}
			}

			for metric, exists := range foundMetricNames {
				require.True(t, exists, "could not find metric %s", metric)
			}
		})
	}
}

func TestConfig_SecretRedisPassword(t *testing.T) {
	stringCfg := `
prometheus:
  wal_directory: /tmp/agent
integrations:
  redis_exporter:
    enabled: true
    redis_password: secret_password
`
	config.CheckSecret(t, stringCfg, "secret_password")
}

func matchMetricNames(names map[string]bool, p textparse.Parser) {
	for name := range names {
		metricName, _ := p.Help()
		if bytes.Equal([]byte(name), metricName) {
			names[name] = true
		}
	}
}

'''
'''--- pkg/integrations/register.go ---
package integrations

import (
	"fmt"
	"reflect"
	"strings"

	"github.com/grafana/agent/pkg/integrations/config"
	"github.com/grafana/agent/pkg/util"
	"gopkg.in/yaml.v2"
)

var (
	registeredIntegrations = []Config{}
	configFieldNames       = make(map[reflect.Type]string)

	emptyStructType = reflect.TypeOf(struct{}{})
	configsType     = reflect.TypeOf(Configs{})
)

// RegisterIntegration dynamically registers a new integration. The Config
// will represent the configuration that controls the specific integration.
// Registered Configs may be loaded using UnmarshalYAML or manually
// constructed.
//
// RegisterIntegration panics if cfg is not a pointer.
func RegisterIntegration(cfg Config) {
	if reflect.TypeOf(cfg).Kind() != reflect.Ptr {
		panic(fmt.Sprintf("RegisterIntegration must be given a pointer, got %T", cfg))
	}
	registeredIntegrations = append(registeredIntegrations, cfg)
	configFieldNames[reflect.TypeOf(cfg)] = cfg.Name()
}

// RegisteredIntegrations all Configs that were passed to RegisterIntegration.
// Each call will generate a new set of pointers.
func RegisteredIntegrations() []Config {
	res := make([]Config, 0, len(registeredIntegrations))
	for _, in := range registeredIntegrations {
		res = append(res, cloneIntegration(in))
	}
	return res
}

func cloneIntegration(c Config) Config {
	return reflect.New(reflect.TypeOf(c).Elem()).Interface().(Config)
}

// Configs is a list of UnmarshaledConfig. Configs for integrations which are
// unmarshaled from YAML are combined with common settings.
type Configs []UnmarshaledConfig

// UnmarshaledConfig combines an integration's config with common settings.
type UnmarshaledConfig struct {
	Config
	Common config.Common
}

// MarshalYAML helps implement yaml.Marshaller for structs that have a Configs
// field that should be inlined in the YAML string.
func MarshalYAML(v interface{}) (interface{}, error) {
	inVal := reflect.ValueOf(v)
	for inVal.Kind() == reflect.Ptr {
		inVal = inVal.Elem()
	}
	if inVal.Kind() != reflect.Struct {
		return nil, fmt.Errorf("integrations: can only marshal a struct, got %T", v)
	}
	inType := inVal.Type()

	var (
		cfgType    = getConfigTypeForIntegrations(registeredIntegrations, inType)
		cfgPointer = reflect.New(cfgType)
		cfgVal     = cfgPointer.Elem()
	)

	// Copy over any existing value from inVal to cfgVal.
	//
	// The ordering of fields in inVal and cfgVal match identically up until the
	// extra fields appended to the end of cfgVal.
	var configs Configs
	for i, n := 0, inType.NumField(); i < n; i++ {
		if inType.Field(i).Type == configsType {
			configs = inVal.Field(i).Interface().(Configs)
			if configs == nil {
				configs = Configs{}
			}
		}
		if cfgType.Field(i).PkgPath != "" {
			continue // Field is unexported: ignore.
		}
		cfgVal.Field(i).Set(inVal.Field(i))
	}
	if configs == nil {
		return nil, fmt.Errorf("integrations: Configs field not found in type: %T", v)
	}

	for _, c := range configs {
		fieldName, ok := configFieldNames[reflect.TypeOf(c.Config)]
		if !ok {
			return nil, fmt.Errorf("integrations: cannot marshal unregistered Config type: %T", c)
		}
		field := cfgVal.FieldByName("XXX_Config_" + fieldName)
		rawConfig, err := getRawIntegrationConfig(c)
		if err != nil {
			return nil, fmt.Errorf("integrations: cannot marshal integration %q: %w", c.Name(), err)
		}
		field.Set(rawConfig)
	}

	return cfgPointer.Interface(), nil
}

// getRawIntegrationConfig turns an UnmarshaledConfig into the *util.RawYAML
// used to represent it in configs.
func getRawIntegrationConfig(uc UnmarshaledConfig) (v reflect.Value, err error) {
	bb, err := util.MarshalYAMLMerged(uc.Common, uc.Config)
	if err != nil {
		return v, err
	}
	raw := util.RawYAML(bb)
	return reflect.ValueOf(&raw), nil
}

// UnmarshalYAML helps implement yaml.Unmarshaller for structs that have a
// Configs field that should be inlined in the YAML string.
func UnmarshalYAML(out interface{}, unmarshal func(interface{}) error) error {
	return unmarshalIntegrationsWithList(registeredIntegrations, out, unmarshal)
}

// unmarshalIntegrationsWithList unmarshals to a subtype of out that has a
// field added for every integration in integrations. Code adapted from
// Prometheus:
//
//   https://github.com/prometheus/prometheus/blob/511511324adfc4f4178f064cc104c2deac3335de/discovery/registry.go#L111
func unmarshalIntegrationsWithList(integrations []Config, out interface{}, unmarshal func(interface{}) error) error {
	outVal := reflect.ValueOf(out)
	if outVal.Kind() != reflect.Ptr {
		return fmt.Errorf("integrations: can only unmarshal into a struct pointer, got %T", out)
	}
	outVal = outVal.Elem()
	if outVal.Kind() != reflect.Struct {
		return fmt.Errorf("integrations: can only unmarshal into a struct pointer, got %T", out)
	}
	outType := outVal.Type()

	var (
		cfgType    = getConfigTypeForIntegrations(integrations, outType)
		cfgPointer = reflect.New(cfgType)
		cfgVal     = cfgPointer.Elem()
	)

	// Copy over any existing value from outVal to cfgVal.
	//
	// The ordering of fields in outVal and cfgVal match identically up until the
	// extra fields appended to the end of cfgVal.
	var configs *Configs
	for i := 0; i < outVal.NumField(); i++ {
		if outType.Field(i).Type == configsType {
			if configs != nil {
				return fmt.Errorf("integrations: Multiple Configs fields found in %T", out)
			}
			configs = outVal.Field(i).Addr().Interface().(*Configs)
			continue
		}
		if cfgType.Field(i).PkgPath != "" {
			// Ignore unexported fields
			continue
		}
		cfgVal.Field(i).Set(outVal.Field(i))
	}
	if configs == nil {
		return fmt.Errorf("integrations: No Configs field found in %T", out)
	}

	// Unmarshal into our dynamic type.
	if err := unmarshal(cfgPointer.Interface()); err != nil {
		return replaceYAMLTypeError(err, cfgType, outType)
	}

	// Copy back unmarshaled fields that were originally in outVal.
	for i := 0; i < outVal.NumField(); i++ {
		if cfgType.Field(i).PkgPath != "" {
			// Ignore unexported fields
			continue
		}
		outVal.Field(i).Set(cfgVal.Field(i))
	}

	// Iterate through the remainder of our fields, which should all be dynamic
	// structs where the first field is a config.Common and the second field is
	// a Config.
	integrationLookup := buildIntegrationsMap(integrations)
	for i := outVal.NumField(); i < cfgVal.NumField(); i++ {
		// Our integrations are unmarshaled as *util.RawYAML. If it's nil, we treat
		// it as not defined.
		fieldType := cfgVal.Type().Field(i)
		field := cfgVal.Field(i)
		if field.IsNil() {
			continue
		}

		configName := strings.TrimPrefix(fieldType.Name, "XXX_Config_")
		configReference, ok := integrationLookup[configName]
		if !ok {
			return fmt.Errorf("integration %q not registered", configName)
		}
		uc, err := buildUnmarshaledConfig(field.Interface().(*util.RawYAML), configReference)
		if err != nil {
			return fmt.Errorf("failed to unmarshal integration %q: %w", configName, err)
		}
		*configs = append(*configs, uc)
	}

	return nil
}

// getConfigTypeForIntegrations returns a dynamic struct type that has all of
// the same fields as out including the fields for the provided integrations.
//
// integrations are unmarshaled to *util.RawYAML for deferred unmarshaling.
func getConfigTypeForIntegrations(integrations []Config, out reflect.Type) reflect.Type {
	// Initial exported fields map one-to-one.
	var fields []reflect.StructField
	for i, n := 0, out.NumField(); i < n; i++ {
		switch field := out.Field(i); {
		case field.PkgPath == "" && field.Type != configsType:
			fields = append(fields, field)
		default:
			fields = append(fields, reflect.StructField{
				Name:    "_" + field.Name, // Field must be unexported.
				PkgPath: out.PkgPath(),
				Type:    emptyStructType,
			})
		}
	}
	for _, cfg := range integrations {
		// Use a prefix that's unlikely to collide with anything else.
		fieldName := "XXX_Config_" + cfg.Name()
		fields = append(fields, reflect.StructField{
			Name: fieldName,
			Tag:  reflect.StructTag(fmt.Sprintf(`yaml:"%s,omitempty"`, cfg.Name())),
			Type: reflect.PtrTo(reflect.TypeOf(util.RawYAML{})),
		})
	}
	return reflect.StructOf(fields)
}

func buildIntegrationsMap(in []Config) map[string]Config {
	m := make(map[string]Config, len(in))
	for _, i := range in {
		m[i.Name()] = i
	}
	return m
}

// buildUnmarshaledConfig converts raw YAML into an UnmarshaledConfig where the
// config type is the same as ref.
func buildUnmarshaledConfig(raw *util.RawYAML, ref Config) (uc UnmarshaledConfig, err error) {
	// Initialize uc.Config so it can be unmarshaled properly as an interface.
	uc = UnmarshaledConfig{
		Config: cloneIntegration(ref),
	}
	err = util.UnmarshalYAMLMerged(*raw, &uc.Common, uc.Config)
	return
}

func replaceYAMLTypeError(err error, oldTyp, newTyp reflect.Type) error {
	if e, ok := err.(*yaml.TypeError); ok {
		oldStr := oldTyp.String()
		newStr := newTyp.String()
		for i, s := range e.Errors {
			e.Errors[i] = strings.ReplaceAll(s, oldStr, newStr)
		}
	}
	return err
}

'''
'''--- pkg/integrations/register_test.go ---
package integrations

import (
	"fmt"
	"testing"
	"time"

	"github.com/go-kit/log"
	"github.com/stretchr/testify/require"
	"gopkg.in/yaml.v2"
)

func TestIntegrationRegistration(t *testing.T) {
	// This test checks for a few things:
	//
	// 1. Registered integrations will be parseable
	// 2. Registered integrations that are not present will not be unmarshaled to
	//    the list of configs
	// 3. Registered integrations that have defaults may still be parsed
	// 4. Strict parsing should still work as expected.

	var cfgToParse = `
name: John Doe
duration: 500ms
test:
  text: Hello, world!
`

	var fullCfg testFullConfig
	err := yaml.UnmarshalStrict([]byte(cfgToParse), &fullCfg)
	require.NoError(t, err)

	expect := testFullConfig{
		Name:     "John Doe",
		Duration: 500 * time.Millisecond,
		Default:  12345,
		Configs: []UnmarshaledConfig{{
			Config: &testIntegrationA{Text: "Hello, world!", Truth: true},
		}},
	}
	require.Equal(t, expect, fullCfg)
}

type testIntegrationA struct {
	Text  string `yaml:"text"`
	Truth bool   `yaml:"truth"`
}

func (i *testIntegrationA) Name() string                         { return "test" }
func (i *testIntegrationA) InstanceKey(_ string) (string, error) { return "integrationA", nil }

func (i *testIntegrationA) NewIntegration(l log.Logger) (Integration, error) {
	return nil, fmt.Errorf("not implemented")
}

func (i *testIntegrationA) UnmarshalYAML(unmarshal func(interface{}) error) error {
	i.Truth = true
	type plain testIntegrationA
	return unmarshal((*plain)(i))
}

type testIntegrationB struct {
	Text string `yaml:"text"`
}

func (*testIntegrationB) Name() string                         { return "shouldnotbefound" }
func (*testIntegrationB) InstanceKey(_ string) (string, error) { return "integrationB", nil }

func (*testIntegrationB) NewIntegration(l log.Logger) (Integration, error) {
	return nil, fmt.Errorf("not implemented")
}

type testFullConfig struct {
	// Some random fields that will also be exposed
	Name     string        `yaml:"name"`
	Duration time.Duration `yaml:"duration"`
	Default  int           `yaml:"default"`

	Configs Configs `yaml:"-"`
}

func (c *testFullConfig) UnmarshalYAML(unmarshal func(interface{}) error) error {
	// This default value should not change.
	c.Default = 12345

	// Mock out registered integrations.
	registered := []Config{
		&testIntegrationA{},
		&testIntegrationB{},
	}
	return unmarshalIntegrationsWithList(registered, c, unmarshal)
}

'''
'''--- pkg/integrations/snmp_exporter/common/common.go ---
package common

import (
	"bytes"
	"compress/gzip"
	_ "embed" // enables the go:embed directive
	"io/ioutil"

	snmp_config "github.com/prometheus/snmp_exporter/config"
	"gopkg.in/yaml.v2"
)

//go:generate curl https://raw.githubusercontent.com/prometheus/snmp_exporter/v0.20.0/snmp.yml --output snmp.yml
//go:generate gzip -9 snmp.yml
//go:embed snmp.yml.gz
var content []byte

// LoadEmbeddedConfig loads the SNMP config via a file using the go:embed directive.
func LoadEmbeddedConfig() (*snmp_config.Config, error) {
	gzipReader, err := gzip.NewReader(bytes.NewReader(content))
	if err != nil {
		return nil, err
	}

	b, err := ioutil.ReadAll(gzipReader)
	if err != nil {
		return nil, err
	}

	cfg := &snmp_config.Config{}
	err = yaml.UnmarshalStrict(b, cfg)
	if err != nil {
		return nil, err
	}
	return cfg, nil
}

'''
'''--- pkg/integrations/snmp_exporter/snmp.go ---
package snmp_exporter

import (
	"fmt"
	"net/http"
	"time"

	"github.com/go-kit/log"
	"github.com/go-kit/log/level"
	"github.com/prometheus/client_golang/prometheus"
	"github.com/prometheus/client_golang/prometheus/promhttp"
	"github.com/prometheus/snmp_exporter/collector"
	snmp_config "github.com/prometheus/snmp_exporter/config"
)

type snmpHandler struct {
	cfg     *Config
	modules *snmp_config.Config
	log     log.Logger
}

func (sh *snmpHandler) handler(w http.ResponseWriter, r *http.Request) {
	logger := sh.log

	query := r.URL.Query()

	snmpTargets := make(map[string]SNMPTarget)
	for _, target := range sh.cfg.SnmpTargets {
		snmpTargets[target.Name] = target
	}

	var target string
	targetName := query.Get("target")
	if len(query["target"]) != 1 || targetName == "" {
		http.Error(w, "'target' parameter must be specified once", 400)
		return
	}

	t, ok := snmpTargets[targetName]
	if ok {
		target = t.Target
	} else {
		target = targetName
	}

	moduleName := query.Get("module")
	if len(query["module"]) > 1 {
		http.Error(w, "'module' parameter must only be specified once", 400)
		return
	}
	if moduleName == "" {
		moduleName = "if_mib"
	}

	module, ok := (*sh.modules)[moduleName]
	if !ok {
		http.Error(w, fmt.Sprintf("Unknown module '%s'", moduleName), 400)
		return
	}

	// override module connection details with custom walk params if provided
	walkParams := query.Get("walk_params")
	if len(query["walk_params"]) > 1 {
		http.Error(w, "'walk_params' parameter must only be specified once", 400)
		return
	}

	if walkParams != "" {
		if wp, ok := sh.cfg.WalkParams[walkParams]; ok {
			// module.WalkParams = wp
			if wp.Version != 0 {
				module.WalkParams.Version = wp.Version
			}
			if wp.MaxRepetitions != 0 {
				module.WalkParams.MaxRepetitions = wp.MaxRepetitions
			}
			if wp.Retries != 0 {
				module.WalkParams.Retries = wp.Retries
			}
			if wp.Timeout != 0 {
				module.WalkParams.Timeout = wp.Timeout
			}
			module.WalkParams.Auth = wp.Auth
		} else {
			http.Error(w, fmt.Sprintf("Unknown walk_params '%s'", walkParams), 400)
			return
		}
		logger = log.With(logger, "module", moduleName, "target", target, "walk_params", walkParams)
	} else {
		logger = log.With(logger, "module", moduleName, "target", target)
	}
	level.Debug(logger).Log("msg", "Starting scrape")

	start := time.Now()
	registry := prometheus.NewRegistry()
	c := collector.New(r.Context(), target, module, logger)
	registry.MustRegister(c)
	// Delegate http serving to Prometheus client library, which will call collector.Collect.
	h := promhttp.HandlerFor(registry, promhttp.HandlerOpts{})
	h.ServeHTTP(w, r)
	duration := time.Since(start).Seconds()
	level.Debug(logger).Log("msg", "Finished scrape", "duration_seconds", duration)
}

func (sh snmpHandler) ServeHTTP(w http.ResponseWriter, r *http.Request) {
	sh.handler(w, r)
}

'''
'''--- pkg/integrations/snmp_exporter/snmp_exporter.go ---
// Package snmp_exporter embeds https://github.com/prometheus/snmp_exporter
package snmp_exporter

import (
	"context"
	"fmt"
	"net/http"
	"net/url"

	"github.com/go-kit/log"
	"github.com/grafana/agent/pkg/integrations"
	"github.com/grafana/agent/pkg/integrations/config"
	snmp_common "github.com/grafana/agent/pkg/integrations/snmp_exporter/common"
	snmp_config "github.com/prometheus/snmp_exporter/config"
)

// DefaultConfig holds the default settings for the snmp_exporter integration.
var DefaultConfig = Config{
	WalkParams:     make(map[string]snmp_config.WalkParams),
	SnmpConfigFile: "",
	SnmpTargets:    make([]SNMPTarget, 0),
}

// SNMPTarget defines a target device to be used by the integration.
type SNMPTarget struct {
	Name       string `yaml:"name"`
	Target     string `yaml:"address"`
	Module     string `yaml:"module"`
	WalkParams string `yaml:"walk_params,omitempty"`
}

// Config configures the SNMP integration.
type Config struct {
	WalkParams     map[string]snmp_config.WalkParams `yaml:"walk_params,omitempty"`
	SnmpConfigFile string                            `yaml:"config_file,omitempty"`
	SnmpTargets    []SNMPTarget                      `yaml:"snmp_targets"`
}

// UnmarshalYAML implements yaml.Unmarshaler for Config.
func (c *Config) UnmarshalYAML(unmarshal func(interface{}) error) error {
	*c = DefaultConfig

	type plain Config
	return unmarshal((*plain)(c))
}

// Name returns the name of the integration.
func (c *Config) Name() string {
	return "snmp"
}

// InstanceKey returns the hostname:port of the agent.
func (c *Config) InstanceKey(agentKey string) (string, error) {
	return agentKey, nil
}

// NewIntegration creates a new SNMP integration.
func (c *Config) NewIntegration(l log.Logger) (integrations.Integration, error) {
	return New(l, c)
}

func init() {
	integrations.RegisterIntegration(&Config{})
}

// New creates a new snmp_exporter integration
func New(log log.Logger, c *Config) (integrations.Integration, error) {
	var modules *snmp_config.Config
	var err error
	if c.SnmpConfigFile != "" {
		modules, err = snmp_config.LoadFile(c.SnmpConfigFile)
		if err != nil {
			return nil, fmt.Errorf("failed to load snmp config from file %v: %w", c.SnmpConfigFile, err)
		}
	} else {
		modules, err = snmp_common.LoadEmbeddedConfig()
		if err != nil {
			return nil, fmt.Errorf("failed to load embedded snmp config: %w", err)
		}
	}

	// The `name` and `address` fields are mandatory for the SNMP targets are mandatory.
	// Enforce this check and fail the creation of the integration if they're missing.
	for _, target := range c.SnmpTargets {
		if target.Name == "" || target.Target == "" {
			return nil, fmt.Errorf("failed to load snmp_targets; the `name` and `address` fields are mandatory")
		}
	}

	sh := &snmpHandler{
		cfg:     c,
		modules: modules,
		log:     log,
	}
	integration := &Integration{
		sh: sh,
	}

	return integration, nil
}

// Integration is the node_exporter integration. The integration scrapes metrics
// from the host Linux-based system.
type Integration struct {
	sh *snmpHandler
}

// MetricsHandler implements Integration.
func (i *Integration) MetricsHandler() (http.Handler, error) {
	return i.sh, nil
}

// Run satisfies Integration.Run.
func (i *Integration) Run(ctx context.Context) error {
	// We don't need to do anything here, so we can just wait for the context to
	// finish.
	<-ctx.Done()
	return ctx.Err()
}

// ScrapeConfigs satisfies Integration.ScrapeConfigs.
func (i *Integration) ScrapeConfigs() []config.ScrapeConfig {
	var res []config.ScrapeConfig
	for _, target := range i.sh.cfg.SnmpTargets {
		queryParams := url.Values{}
		queryParams.Add("target", target.Target)
		res = append(res, config.ScrapeConfig{
			JobName:     i.sh.cfg.Name() + "/" + target.Name,
			MetricsPath: "/metrics",
			QueryParams: queryParams,
		})
	}
	return res
}

'''
'''--- pkg/integrations/statsd_exporter/metrics.go ---
package statsd_exporter //nolint:golint

import "github.com/prometheus/client_golang/prometheus"

// Metrics holds metrics used by the statsd_exporter integration. These metrics
// are distinct from the set of metrics used by the exporter itself, and are just
// used to monitor the stats of the listeners that forward data to the exporter.
type Metrics struct {
	EventStats            *prometheus.CounterVec
	EventsFlushed         prometheus.Counter
	EventsUnmapped        prometheus.Counter
	UDPPackets            prometheus.Counter
	TCPConnections        prometheus.Counter
	TCPErrors             prometheus.Counter
	TCPLineTooLong        prometheus.Counter
	UnixgramPackets       prometheus.Counter
	LinesReceived         prometheus.Counter
	SamplesReceived       prometheus.Counter
	SampleErrors          *prometheus.CounterVec
	TagsReceived          prometheus.Counter
	TagErrors             prometheus.Counter
	MappingsCount         prometheus.Gauge
	ConflictingEventStats *prometheus.CounterVec
	ErrorEventStats       *prometheus.CounterVec
	EventsActions         *prometheus.CounterVec
	MetricsCount          *prometheus.GaugeVec
}

// NewMetrics initializes Metrics and registers them to the given Registerer.
func NewMetrics(r prometheus.Registerer) (*Metrics, error) {
	var m Metrics

	m.EventStats = prometheus.NewCounterVec(prometheus.CounterOpts{
		Name: "statsd_exporter_events_total",
		Help: "The total number of StatsD events seen.",
	}, []string{"type"})
	m.EventsFlushed = prometheus.NewCounter(prometheus.CounterOpts{
		Name: "statsd_exporter_event_queue_flushed_total",
		Help: "Number of times events were flushed to exporter",
	})
	m.EventsUnmapped = prometheus.NewCounter(prometheus.CounterOpts{
		Name: "statsd_exporter_events_unmapped_total",
		Help: "The total number of StatsD events no mapping was found for.",
	})
	m.UDPPackets = prometheus.NewCounter(prometheus.CounterOpts{
		Name: "statsd_exporter_udp_packets_total",
		Help: "The total number of StatsD packets received over UDP.",
	})
	m.TCPConnections = prometheus.NewCounter(prometheus.CounterOpts{
		Name: "statsd_exporter_tcp_connections_total",
		Help: "The total number of TCP connections handled.",
	})
	m.TCPErrors = prometheus.NewCounter(prometheus.CounterOpts{
		Name: "statsd_exporter_tcp_connection_errors_total",
		Help: "The number of errors encountered reading from TCP.",
	})
	m.TCPLineTooLong = prometheus.NewCounter(prometheus.CounterOpts{
		Name: "statsd_exporter_tcp_too_long_lines_total",
		Help: "The number of lines discarded due to being too long.",
	})
	m.UnixgramPackets = prometheus.NewCounter(prometheus.CounterOpts{
		Name: "statsd_exporter_unixgram_packets_total",
		Help: "The total number of StatsD packets received over Unixgram.",
	})
	m.LinesReceived = prometheus.NewCounter(prometheus.CounterOpts{
		Name: "statsd_exporter_lines_total",
		Help: "The total number of StatsD lines received.",
	})
	m.SamplesReceived = prometheus.NewCounter(prometheus.CounterOpts{
		Name: "statsd_exporter_samples_total",
		Help: "The total number of StatsD samples received.",
	})
	m.SampleErrors = prometheus.NewCounterVec(prometheus.CounterOpts{
		Name: "statsd_exporter_sample_errors_total",
		Help: "The total number of errors parsing StatsD samples.",
	}, []string{"reason"})
	m.TagsReceived = prometheus.NewCounter(prometheus.CounterOpts{
		Name: "statsd_exporter_tags_total",
		Help: "The total number of DogStatsD tags processed.",
	})
	m.TagErrors = prometheus.NewCounter(prometheus.CounterOpts{
		Name: "statsd_exporter_tag_errors_total",
		Help: "The number of errors parsing DogStatsD tags.",
	})
	m.MappingsCount = prometheus.NewGauge(prometheus.GaugeOpts{
		Name: "statsd_exporter_loaded_mappings",
		Help: "The current number of configured metric mappings.",
	})
	m.ConflictingEventStats = prometheus.NewCounterVec(prometheus.CounterOpts{
		Name: "statsd_exporter_events_conflict_total",
		Help: "The total number of StatsD events with conflicting names.",
	}, []string{"type"})
	m.ErrorEventStats = prometheus.NewCounterVec(prometheus.CounterOpts{
		Name: "statsd_exporter_events_error_total",
		Help: "The total number of StatsD events discarded due to errors.",
	}, []string{"reason"})
	m.EventsActions = prometheus.NewCounterVec(prometheus.CounterOpts{
		Name: "statsd_exporter_events_actions_total",
		Help: "The total number of StatsD events by action.",
	}, []string{"action"})
	m.MetricsCount = prometheus.NewGaugeVec(prometheus.GaugeOpts{
		Name: "statsd_exporter_metrics_total",
		Help: "The total number of metrics.",
	}, []string{"type"})

	cs := []prometheus.Collector{
		m.EventStats,
		m.EventsFlushed,
		m.EventsUnmapped,
		m.UDPPackets,
		m.TCPConnections,
		m.TCPErrors,
		m.TCPLineTooLong,
		m.UnixgramPackets,
		m.LinesReceived,
		m.SamplesReceived,
		m.SampleErrors,
		m.TagsReceived,
		m.TagErrors,
		m.MappingsCount,
		m.ConflictingEventStats,
		m.ErrorEventStats,
		m.EventsActions,
		m.MetricsCount,
	}
	if r != nil {
		for _, c := range cs {
			if err := r.Register(c); err != nil {
				return nil, err
			}
		}
	}

	return &m, nil
}

'''
'''--- pkg/integrations/statsd_exporter/statsd_exporter.go ---
// Package statsd_exporter embeds https://github.com/prometheus/statsd_exporter
package statsd_exporter //nolint:golint

import (
	"context"
	"fmt"
	"net"
	"net/http"
	"os"
	"strconv"
	"time"

	"github.com/go-kit/log"
	"github.com/go-kit/log/level"
	"github.com/grafana/agent/pkg/integrations"
	"github.com/grafana/agent/pkg/integrations/config"
	integrations_v2 "github.com/grafana/agent/pkg/integrations/v2"
	"github.com/grafana/agent/pkg/integrations/v2/metricsutils"
	"github.com/prometheus/client_golang/prometheus"
	"github.com/prometheus/client_golang/prometheus/promhttp"
	"github.com/prometheus/common/version"
	"github.com/prometheus/statsd_exporter/pkg/address"
	"github.com/prometheus/statsd_exporter/pkg/event"
	"github.com/prometheus/statsd_exporter/pkg/exporter"
	"github.com/prometheus/statsd_exporter/pkg/line"
	"github.com/prometheus/statsd_exporter/pkg/listener"
	"github.com/prometheus/statsd_exporter/pkg/mapper"
	"github.com/prometheus/statsd_exporter/pkg/mappercache/lru"
	"github.com/prometheus/statsd_exporter/pkg/mappercache/randomreplacement"
	"gopkg.in/yaml.v2"
)

// DefaultConfig holds the default settings for the statsd_exporter integration.
var DefaultConfig = Config{
	ListenUDP:      ":9125",
	ListenTCP:      ":9125",
	UnixSocketMode: "755",

	CacheSize:           1000,
	CacheType:           "lru",
	EventQueueSize:      10000,
	EventFlushThreshold: 1000,
	EventFlushInterval:  200 * time.Millisecond,

	ParseDogStatsd: true,
	ParseInfluxDB:  true,
	ParseLibrato:   true,
	ParseSignalFX:  true,
}

// Config controls the statsd_exporter integration.
type Config struct {
	ListenUDP      string               `yaml:"listen_udp,omitempty"`
	ListenTCP      string               `yaml:"listen_tcp,omitempty"`
	ListenUnixgram string               `yaml:"listen_unixgram,omitempty"`
	UnixSocketMode string               `yaml:"unix_socket_mode,omitempty"`
	MappingConfig  *mapper.MetricMapper `yaml:"mapping_config,omitempty"`

	ReadBuffer          int           `yaml:"read_buffer,omitempty"`
	CacheSize           int           `yaml:"cache_size,omitempty"`
	CacheType           string        `yaml:"cache_type,omitempty"`
	EventQueueSize      int           `yaml:"event_queue_size,omitempty"`
	EventFlushThreshold int           `yaml:"event_flush_threshold,omitempty"`
	EventFlushInterval  time.Duration `yaml:"event_flush_interval,omitempty"`

	ParseDogStatsd bool `yaml:"parse_dogstatsd_tags,omitempty"`
	ParseInfluxDB  bool `yaml:"parse_influxdb_tags,omitempty"`
	ParseLibrato   bool `yaml:"parse_librato_tags,omitempty"`
	ParseSignalFX  bool `yaml:"parse_signalfx_tags,omitempty"`
}

// UnmarshalYAML implements yaml.Unmarshaler for Config.
func (c *Config) UnmarshalYAML(unmarshal func(interface{}) error) error {
	*c = DefaultConfig

	type plain Config
	return unmarshal((*plain)(c))
}

// Name returns the name of the integration that this config represents.
func (c *Config) Name() string {
	return "statsd_exporter"
}

// InstanceKey returns the hostname:port of the agent.
func (c *Config) InstanceKey(agentKey string) (string, error) {
	return agentKey, nil
}

// NewIntegration converts this config into an instance of an integration.
func (c *Config) NewIntegration(l log.Logger) (integrations.Integration, error) {
	return New(l, c)
}

func init() {
	integrations.RegisterIntegration(&Config{})
	integrations_v2.RegisterLegacy(&Config{}, integrations_v2.TypeSingleton, metricsutils.NewNamedShim("statsd"))
}

// Exporter defines the statsd_exporter integration.
type Exporter struct {
	cfg      *Config
	reg      *prometheus.Registry
	metrics  *Metrics
	exporter *exporter.Exporter
	log      log.Logger
}

// New creates a new statsd_exporter integration. The integration scrapes
// metrics from a statsd process.
func New(log log.Logger, c *Config) (integrations.Integration, error) {
	reg := prometheus.NewRegistry()

	m, err := NewMetrics(reg)
	if err != nil {
		return nil, fmt.Errorf("failed to create metrics for network listeners: %w", err)
	}

	if c.ListenUDP == "" && c.ListenTCP == "" && c.ListenUnixgram == "" {
		return nil, fmt.Errorf("at least one of UDP/TCP/Unixgram listeners must be used")
	}
	statsdMapper := &mapper.MetricMapper{
		Registerer:    reg,
		MappingsCount: m.MappingsCount,
		Logger:        log,
	}

	if c.MappingConfig != nil {
		cfgBytes, err := yaml.Marshal(c.MappingConfig)
		if err != nil {
			return nil, fmt.Errorf("failed to serialize mapping config: %w", err)
		}

		err = statsdMapper.InitFromYAMLString(string(cfgBytes))
		if err != nil {
			return nil, fmt.Errorf("failed to load mapping config: %w", err)
		}
	}

	var cache mapper.MetricMapperCache
	if c.CacheSize != 0 {
		switch c.CacheType {
		case "lru":
			cache, err = lru.NewMetricMapperLRUCache(statsdMapper.Registerer, c.CacheSize)
		case "random":
			cache, err = randomreplacement.NewMetricMapperRRCache(statsdMapper.Registerer, c.CacheSize)
		default:
			err = fmt.Errorf("unsupported cache type %q", c.CacheType)
		}
		if err != nil {
			return nil, err
		}
	}
	if cache != nil {
		statsdMapper.UseCache(cache)
	}

	e := exporter.NewExporter(reg, statsdMapper, log, m.EventsActions, m.EventsUnmapped, m.ErrorEventStats, m.EventStats, m.ConflictingEventStats, m.MetricsCount)

	if err := reg.Register(version.NewCollector("statsd_exporter")); err != nil {
		return nil, fmt.Errorf("couldn't register version metrics: %w", err)
	}

	return &Exporter{
		cfg:      c,
		metrics:  m,
		exporter: e,
		reg:      reg,
		log:      log,
	}, nil
}

// MetricsHandler returns the HTTP handler for the integration.
func (e *Exporter) MetricsHandler() (http.Handler, error) {
	return promhttp.HandlerFor(e.reg, promhttp.HandlerOpts{
		ErrorHandling: promhttp.ContinueOnError,
	}), nil
}

// ScrapeConfigs satisfies Integration.ScrapeConfigs.
func (e *Exporter) ScrapeConfigs() []config.ScrapeConfig {
	return []config.ScrapeConfig{{JobName: e.cfg.Name(), MetricsPath: "/metrics"}}
}

// Run satisfies Run.
func (e *Exporter) Run(ctx context.Context) error {
	parser := line.NewParser()
	if e.cfg.ParseDogStatsd {
		parser.EnableDogstatsdParsing()
	}
	if e.cfg.ParseInfluxDB {
		parser.EnableInfluxdbParsing()
	}
	if e.cfg.ParseLibrato {
		parser.EnableLibratoParsing()
	}
	if e.cfg.ParseSignalFX {
		parser.EnableSignalFXParsing()
	}

	events := make(chan event.Events, e.cfg.EventQueueSize)
	defer close(events)
	eventQueue := event.NewEventQueue(events, e.cfg.EventFlushThreshold, e.cfg.EventFlushInterval, e.metrics.EventsFlushed)

	if e.cfg.ListenUDP != "" {
		addr, err := address.UDPAddrFromString(e.cfg.ListenUDP)
		if err != nil {
			return fmt.Errorf("invalid UDP listen address %s: %w", e.cfg.ListenUDP, err)
		}
		uconn, err := net.ListenUDP("udp", addr)
		if err != nil {
			return fmt.Errorf("failed to start UDP listener: %w", err)
		}
		defer func() {
			err := uconn.Close()
			if err != nil {
				level.Warn(e.log).Log("msg", "failed to close UDP listener", "err", err)
			}
		}()

		if e.cfg.ReadBuffer != 0 {
			err = uconn.SetReadBuffer(e.cfg.ReadBuffer)
			if err != nil {
				return fmt.Errorf("failed to set UDP read buffer: %w", err)
			}
		}

		ul := &listener.StatsDUDPListener{
			Conn:            uconn,
			EventHandler:    eventQueue,
			Logger:          e.log,
			LineParser:      parser,
			UDPPackets:      e.metrics.UDPPackets,
			LinesReceived:   e.metrics.LinesReceived,
			EventsFlushed:   e.metrics.EventsFlushed,
			SampleErrors:    *e.metrics.SampleErrors,
			SamplesReceived: e.metrics.SamplesReceived,
			TagErrors:       e.metrics.TagErrors,
			TagsReceived:    e.metrics.TagsReceived,
		}

		go ul.Listen()
	}

	if e.cfg.ListenTCP != "" {
		addr, err := address.TCPAddrFromString(e.cfg.ListenTCP)
		if err != nil {
			return fmt.Errorf("invalid TCP listen address %s: %w", e.cfg.ListenTCP, err)
		}
		tconn, err := net.ListenTCP("tcp", addr)
		if err != nil {
			return fmt.Errorf("failed to start TCP listener: %w", err)
		}
		defer func() {
			err := tconn.Close()
			if err != nil {
				level.Warn(e.log).Log("msg", "failed to close TCP listener", "err", err)
			}
		}()

		tl := &listener.StatsDTCPListener{
			Conn:            tconn,
			EventHandler:    eventQueue,
			Logger:          e.log,
			LineParser:      parser,
			LinesReceived:   e.metrics.LinesReceived,
			EventsFlushed:   e.metrics.EventsFlushed,
			SampleErrors:    *e.metrics.SampleErrors,
			SamplesReceived: e.metrics.SamplesReceived,
			TagErrors:       e.metrics.TagErrors,
			TagsReceived:    e.metrics.TagsReceived,
			TCPConnections:  e.metrics.TCPConnections,
			TCPErrors:       e.metrics.TCPErrors,
			TCPLineTooLong:  e.metrics.TCPLineTooLong,
		}

		go tl.Listen()
	}

	if e.cfg.ListenUnixgram != "" {
		var err error
		if _, err = os.Stat(e.cfg.ListenUnixgram); !os.IsNotExist(err) {
			return fmt.Errorf("unixgram socket %s already exists: %w", e.cfg.ListenUnixgram, err)
		}
		uxgconn, err := net.ListenUnixgram("unixgram", &net.UnixAddr{
			Net:  "unixgram",
			Name: e.cfg.ListenUnixgram,
		})
		if err != nil {
			return fmt.Errorf("failed to listen on unixgram socket: %w", err)
		}
		defer func() {
			err := uxgconn.Close()
			if err != nil {
				level.Warn(e.log).Log("msg", "failed to close unixgram listener", "err", err)
			}
		}()

		if e.cfg.ReadBuffer != 0 {
			err = uxgconn.SetReadBuffer(e.cfg.ReadBuffer)
			if err != nil {
				return fmt.Errorf("error setting unixgram read buffer: %w", err)
			}
		}

		ul := &listener.StatsDUnixgramListener{
			Conn:            uxgconn,
			EventHandler:    eventQueue,
			Logger:          e.log,
			LineParser:      parser,
			UnixgramPackets: e.metrics.UnixgramPackets,
			LinesReceived:   e.metrics.LinesReceived,
			EventsFlushed:   e.metrics.EventsFlushed,
			SampleErrors:    *e.metrics.SampleErrors,
			SamplesReceived: e.metrics.SamplesReceived,
			TagErrors:       e.metrics.TagErrors,
			TagsReceived:    e.metrics.TagsReceived,
		}

		go ul.Listen()

		// If it's an abstract unix domain socket, it won't exist on fs so we can't
		// chmod it either.
		if _, err := os.Stat(e.cfg.ListenUnixgram); !os.IsNotExist(err) {
			defer os.Remove(e.cfg.ListenUnixgram)

			// Convert the string to octet
			perm, err := strconv.ParseInt("0"+e.cfg.UnixSocketMode, 8, 32)
			if err != nil {
				level.Warn(e.log).Log("msg", "bad permission on unixgram socket, ignoring", "permission", e.cfg.UnixSocketMode, "socket", e.cfg.ListenUnixgram, "err", err)
			} else {
				err = os.Chmod(e.cfg.ListenUnixgram, os.FileMode(perm))
				if err != nil {
					level.Warn(e.log).Log("msg", "failed to change unixgram socket permission", "socket", e.cfg.ListenUnixgram, "err", err)
				}
			}
		}
	}

	go e.exporter.Listen(events)

	<-ctx.Done()
	return nil
}

'''
'''--- pkg/integrations/stub_integration.go ---
package integrations

import (
	"context"
	"net/http"

	"github.com/grafana/agent/pkg/integrations/config"
)

// StubIntegration implements a no-op integration for use on platforms not supported by an integration
type StubIntegration struct{}

// MetricsHandler returns an http.NotFoundHandler to satisfy the Integration interface
func (i *StubIntegration) MetricsHandler() (http.Handler, error) {
	return http.NotFoundHandler(), nil
}

// ScrapeConfigs returns an empty list of scrape configs, since there is nothing to scrape
func (i *StubIntegration) ScrapeConfigs() []config.ScrapeConfig {
	return []config.ScrapeConfig{}
}

// Run just waits for the context to finish
func (i *StubIntegration) Run(ctx context.Context) error {
	<-ctx.Done()
	return ctx.Err()
}

'''
'''--- pkg/integrations/v2/agent/agent.go ---
// Package agent is an "example" integration that has very little functionality,
// but is still useful in practice. The Agent integration re-exposes the Agent's
// own metrics endpoint and allows the Agent to scrape itself.
package agent

import (
	"github.com/go-kit/log"
	"github.com/grafana/agent/pkg/integrations/v2"
	"github.com/grafana/agent/pkg/integrations/v2/common"
	"github.com/grafana/agent/pkg/integrations/v2/metricsutils"
	"github.com/prometheus/client_golang/prometheus/promhttp"
)

// Config controls the Agent integration.
type Config struct {
	Common common.MetricsConfig `yaml:",inline"`
}

// Name returns the name of the integration that this config represents.
func (c *Config) Name() string { return "agent" }

// ApplyDefaults applies runtime-specific defaults to c.
func (c *Config) ApplyDefaults(globals integrations.Globals) error {
	c.Common.ApplyDefaults(globals.SubsystemOpts.Metrics.Autoscrape)
	if id, err := c.Identifier(globals); err == nil {
		c.Common.InstanceKey = &id
	}
	return nil
}

// Identifier uniquely identifies this instance of Config.
func (c *Config) Identifier(globals integrations.Globals) (string, error) {
	if c.Common.InstanceKey != nil {
		return *c.Common.InstanceKey, nil
	}
	return globals.AgentIdentifier, nil
}

// NewIntegration converts this config into an instance of an integration.
func (c *Config) NewIntegration(l log.Logger, globals integrations.Globals) (integrations.Integration, error) {
	return metricsutils.NewMetricsHandlerIntegration(l, c, c.Common, globals, promhttp.Handler())
}

func init() {
	integrations.Register(&Config{}, integrations.TypeSingleton)
}

'''
'''--- pkg/integrations/v2/apache_http/apache_http.go ---
// Package apache_http embeds https://github.com/Lusitaniae/apache_exporter
package apache_http //nolint:golint

import (
	"fmt"
	"net/http"
	"net/url"

	ae "github.com/Lusitaniae/apache_exporter/collector"
	"github.com/go-kit/log"
	"github.com/go-kit/log/level"
	integrations_v2 "github.com/grafana/agent/pkg/integrations/v2"
	"github.com/grafana/agent/pkg/integrations/v2/common"
	"github.com/grafana/agent/pkg/integrations/v2/metricsutils"
	"github.com/prometheus/client_golang/prometheus"
	"github.com/prometheus/client_golang/prometheus/promhttp"
)

// DefaultConfig holds the default settings for the apache_http integration
var DefaultConfig = Config{
	ApacheAddr:         "http://localhost/server-status?auto",
	ApacheHostOverride: "",
	ApacheInsecure:     false,
}

// Config controls the apache_http integration.
type Config struct {
	ApacheAddr         string               `yaml:"scrape_uri,omitempty"`
	ApacheHostOverride string               `yaml:"host_override,omitempty"`
	ApacheInsecure     bool                 `yaml:"insecure,omitempty"`
	Common             common.MetricsConfig `yaml:",inline"`
}

// ApplyDefaults applies the integration's default configuration.
func (c *Config) ApplyDefaults(globals integrations_v2.Globals) error {
	c.Common.ApplyDefaults(globals.SubsystemOpts.Metrics.Autoscrape)
	return nil
}

// Identifier returns a string that identifies the integration.
func (c *Config) Identifier(globals integrations_v2.Globals) (string, error) {
	if c.Common.InstanceKey != nil {
		return *c.Common.InstanceKey, nil
	}
	u, err := url.Parse(c.ApacheAddr)
	if err != nil {
		return "", err
	}
	return fmt.Sprintf("%s:%s", u.Hostname(), u.Port()), nil
}

// UnmarshalYAML implements yaml.Unmarshaler for Config
func (c *Config) UnmarshalYAML(unmarshal func(interface{}) error) error {
	*c = DefaultConfig

	type plain Config
	return unmarshal((*plain)(c))
}

// Name returns the name of the integration this config is for.
func (c *Config) Name() string {
	return "apache_http"
}

type apacheHandler struct {
	cfg *Config
	log log.Logger
}

// NewIntegration instantiates a new integrations.MetricsIntegration
// which will handle requests to the apache http integration.
func (c *Config) NewIntegration(logger log.Logger, globals integrations_v2.Globals) (integrations_v2.Integration, error) {
	ah := &apacheHandler{cfg: c, log: logger}
	h, err := ah.createHandler()
	if err != nil {
		return nil, err
	}

	return metricsutils.NewMetricsHandlerIntegration(logger, c, c.Common, globals, h)
}

func (ah *apacheHandler) createHandler() (http.HandlerFunc, error) {
	_, err := url.ParseRequestURI(ah.cfg.ApacheAddr)
	if err != nil {
		level.Error(ah.log).Log("msg", "scrape_uri is invalid", "err", err)
		return nil, err
	}

	aeExporter := ae.NewExporter(ah.log, &ae.Config{
		ScrapeURI:    ah.cfg.ApacheAddr,
		HostOverride: ah.cfg.ApacheHostOverride,
		Insecure:     ah.cfg.ApacheInsecure,
	})

	return func(w http.ResponseWriter, r *http.Request) {
		registry := prometheus.NewRegistry()
		registry.MustRegister(aeExporter)
		h := promhttp.HandlerFor(registry, promhttp.HandlerOpts{})
		h.ServeHTTP(w, r)
	}, nil
}

func init() {
	integrations_v2.Register(&Config{}, integrations_v2.TypeMultiplex)
}

'''
'''--- pkg/integrations/v2/app_agent_receiver/app_agent_receiver.go ---
package app_agent_receiver //nolint:golint

import (
	"context"
	"fmt"
	"net/http"

	"github.com/go-kit/log"
	"github.com/go-kit/log/level"
	"github.com/gorilla/mux"
	"github.com/grafana/agent/pkg/integrations/v2"
	"github.com/grafana/agent/pkg/integrations/v2/metricsutils"
	"github.com/grafana/agent/pkg/traces/pushreceiver"
	"github.com/prometheus/client_golang/prometheus"
	"github.com/prometheus/client_golang/prometheus/promhttp"
	"github.com/weaveworks/common/instrument"
	"github.com/weaveworks/common/middleware"
	"go.opentelemetry.io/collector/component"
	"go.opentelemetry.io/collector/consumer"
)

type appAgentReceiverIntegration struct {
	integrations.MetricsIntegration
	appAgentReceiverHandler AppAgentReceiverHandler
	logger                  log.Logger
	conf                    *Config
	reg                     prometheus.Registerer

	requestDurationCollector     *prometheus.HistogramVec
	receivedMessageSizeCollector *prometheus.HistogramVec
	sentMessageSizeCollector     *prometheus.HistogramVec
	inflightRequestsCollector    *prometheus.GaugeVec
}

// Static typecheck tests
var (
	_ integrations.Integration        = (*appAgentReceiverIntegration)(nil)
	_ integrations.HTTPIntegration    = (*appAgentReceiverIntegration)(nil)
	_ integrations.MetricsIntegration = (*appAgentReceiverIntegration)(nil)
)

// NewIntegration converts this config into an instance of an integration
func (c *Config) NewIntegration(l log.Logger, globals integrations.Globals) (integrations.Integration, error) {
	reg := prometheus.NewRegistry()
	sourcemapLogger := log.With(l, "subcomponent", "sourcemaps")
	sourcemapStore := NewSourceMapStore(sourcemapLogger, c.SourceMaps, reg, nil, nil)

	receiverMetricsExporter := NewReceiverMetricsExporter(reg)

	var exp = []appAgentReceiverExporter{
		receiverMetricsExporter,
	}

	if len(c.LogsInstance) > 0 {
		getLogsInstance := func() (logsInstance, error) {
			instance := globals.Logs.Instance(c.LogsInstance)
			if instance == nil {
				return nil, fmt.Errorf("logs instance \"%s\" not found", c.LogsInstance)
			}
			return instance, nil
		}

		if _, err := getLogsInstance(); err != nil {
			return nil, err
		}

		lokiExporter := NewLogsExporter(
			l,
			LogsExporterConfig{
				GetLogsInstance:  getLogsInstance,
				Labels:           c.LogsLabels,
				SendEntryTimeout: c.LogsSendTimeout,
			},
			sourcemapStore,
		)
		exp = append(exp, lokiExporter)
	}

	if len(c.TracesInstance) > 0 {
		getTracesConsumer := func() (consumer.Traces, error) {
			tracesInstance := globals.Tracing.Instance(c.TracesInstance)
			if tracesInstance == nil {
				return nil, fmt.Errorf("traces instance \"%s\" not found", c.TracesInstance)
			}
			factory := tracesInstance.GetFactory(component.KindReceiver, pushreceiver.TypeStr)
			if factory == nil {
				return nil, fmt.Errorf("push receiver factory not found for traces instance \"%s\"", c.TracesInstance)
			}
			consumer := factory.(*pushreceiver.Factory).Consumer
			if consumer == nil {
				return nil, fmt.Errorf("consumer not set for push receiver factory on traces instance \"%s\"", c.TracesInstance)
			}
			return consumer, nil
		}
		if _, err := getTracesConsumer(); err != nil {
			return nil, err
		}
		tracesExporter := NewTracesExporter(getTracesConsumer)
		exp = append(exp, tracesExporter)
	}

	handler := NewAppAgentReceiverHandler(c, exp, reg)

	metricsIntegration, err := metricsutils.NewMetricsHandlerIntegration(l, c, c.Common, globals, promhttp.HandlerFor(reg, promhttp.HandlerOpts{}))
	if err != nil {
		return nil, err
	}

	requestDurationCollector := prometheus.NewHistogramVec(prometheus.HistogramOpts{
		Name:    "app_agent_receiver_request_duration_seconds",
		Help:    "Time (in seconds) spent serving HTTP requests.",
		Buckets: instrument.DefBuckets,
	}, []string{"method", "route", "status_code", "ws"})
	reg.MustRegister(requestDurationCollector)

	receivedMessageSizeCollector := prometheus.NewHistogramVec(prometheus.HistogramOpts{
		Name:    "app_agent_receiver_request_message_bytes",
		Help:    "Size (in bytes) of messages received in the request.",
		Buckets: middleware.BodySizeBuckets,
	}, []string{"method", "route"})
	reg.MustRegister(receivedMessageSizeCollector)

	sentMessageSizeCollector := prometheus.NewHistogramVec(prometheus.HistogramOpts{
		Name:    "app_agent_receiver_response_message_bytes",
		Help:    "Size (in bytes) of messages sent in response.",
		Buckets: middleware.BodySizeBuckets,
	}, []string{"method", "route"})
	reg.MustRegister(sentMessageSizeCollector)

	inflightRequestsCollector := prometheus.NewGaugeVec(prometheus.GaugeOpts{
		Name: "app_agent_receiver_inflight_requests",
		Help: "Current number of inflight requests.",
	}, []string{"method", "route"})
	reg.MustRegister(inflightRequestsCollector)

	return &appAgentReceiverIntegration{
		MetricsIntegration:      metricsIntegration,
		appAgentReceiverHandler: handler,
		logger:                  l,
		conf:                    c,
		reg:                     reg,

		requestDurationCollector:     requestDurationCollector,
		receivedMessageSizeCollector: receivedMessageSizeCollector,
		sentMessageSizeCollector:     sentMessageSizeCollector,
		inflightRequestsCollector:    inflightRequestsCollector,
	}, nil
}

// RunIntegration implements Integration
func (i *appAgentReceiverIntegration) RunIntegration(ctx context.Context) error {
	r := mux.NewRouter()
	r.Handle("/collect", i.appAgentReceiverHandler.HTTPHandler(i.logger)).Methods("POST", "OPTIONS")

	mw := middleware.Instrument{
		RouteMatcher:     r,
		Duration:         i.requestDurationCollector,
		RequestBodySize:  i.receivedMessageSizeCollector,
		ResponseBodySize: i.sentMessageSizeCollector,
		InflightRequests: i.inflightRequestsCollector,
	}

	srv := &http.Server{
		Addr:    fmt.Sprintf("%s:%d", i.conf.Server.Host, i.conf.Server.Port),
		Handler: mw.Wrap(r),
	}
	errChan := make(chan error, 1)

	go func() {
		level.Info(i.logger).Log("msg", "starting app agent receiver", "host", i.conf.Server.Host, "port", i.conf.Server.Port)
		if err := srv.ListenAndServe(); err != http.ErrServerClosed {
			errChan <- err
		}
	}()

	select {
	case <-ctx.Done():
		if err := srv.Shutdown(ctx); err != nil {
			return err
		}
	case err := <-errChan:
		close(errChan)
		return err
	}

	return nil
}

func init() {
	integrations.Register(&Config{}, integrations.TypeMultiplex)
}

'''
'''--- pkg/integrations/v2/app_agent_receiver/config.go ---
package app_agent_receiver

import (
	"time"

	"github.com/grafana/agent/pkg/integrations/v2"
	"github.com/grafana/agent/pkg/integrations/v2/common"
)

const (
	// DefaultRateLimitingRPS is the default value of Requests Per Second
	// for ratelimiting
	DefaultRateLimitingRPS = 100
	// DefaultRateLimitingBurstiness is the default burstiness factor of the
	// token bucket algorigthm
	DefaultRateLimitingBurstiness = 50
	// DefaultMaxPayloadSize is the max paylad size in bytes
	DefaultMaxPayloadSize = 5e6
)

// DefaultConfig holds the default configuration of the receiver
var DefaultConfig = Config{
	// Default JS agent port

	Server: ServerConfig{
		Host: "127.0.0.1",
		Port: 12347,
		RateLimiting: RateLimitingConfig{
			Enabled:    true,
			RPS:        DefaultRateLimitingRPS,
			Burstiness: DefaultRateLimitingBurstiness,
		},
		MaxAllowedPayloadSize: DefaultMaxPayloadSize,
	},
	LogsLabels:      map[string]string{},
	LogsSendTimeout: time.Second * 2,
	SourceMaps: SourceMapConfig{
		DownloadFromOrigins: []string{"*"},
		DownloadTimeout:     time.Second,
	},
}

// ServerConfig holds the receiver http server configuration
type ServerConfig struct {
	Host                  string             `yaml:"host,omitempty"`
	Port                  int                `yaml:"port,omitempty"`
	CORSAllowedOrigins    []string           `yaml:"cors_allowed_origins,omitempty"`
	RateLimiting          RateLimitingConfig `yaml:"rate_limiting,omitempty"`
	APIKey                string             `yaml:"api_key,omitempty"`
	MaxAllowedPayloadSize int64              `yaml:"max_allowed_payload_size,omitempty"`
}

// RateLimitingConfig holds the configuration of the rate limiter
type RateLimitingConfig struct {
	Enabled    bool    `yaml:"enabled,omitempty"`
	RPS        float64 `yaml:"rps,omitempty"`
	Burstiness int     `yaml:"burstiness,omitempty"`
}

// SourceMapFileLocation holds sourcemap location on file system
type SourceMapFileLocation struct {
	Path               string `yaml:"path"`
	MinifiedPathPrefix string `yaml:"minified_path_prefix,omitempty"`
}

// SourceMapConfig configure source map locations
type SourceMapConfig struct {
	Download            bool                    `yaml:"download"`
	DownloadFromOrigins []string                `yaml:"download_origins,omitempty"`
	DownloadTimeout     time.Duration           `yaml:"download_timeout,omitempty"`
	FileSystem          []SourceMapFileLocation `yaml:"filesystem,omitempty"`
}

// Config is the configuration struct of the
// integration
type Config struct {
	Common          common.MetricsConfig `yaml:",inline"`
	Server          ServerConfig         `yaml:"server,omitempty"`
	TracesInstance  string               `yaml:"traces_instance,omitempty"`
	LogsInstance    string               `yaml:"logs_instance,omitempty"`
	LogsLabels      map[string]string    `yaml:"logs_labels,omitempty"`
	LogsSendTimeout time.Duration        `yaml:"logs_send_timeout,omitempty"`
	SourceMaps      SourceMapConfig      `yaml:"sourcemaps,omitempty"`
}

// UnmarshalYAML implements the Unmarshaler interface
func (c *Config) UnmarshalYAML(unmarshal func(interface{}) error) error {
	*c = DefaultConfig
	c.LogsLabels = make(map[string]string)
	type plain Config
	return unmarshal((*plain)(c))
}

// IntegrationName is the name of this integration
var IntegrationName = "app_agent_receiver"

// ApplyDefaults applies runtime-specific defaults to c.
func (c *Config) ApplyDefaults(globals integrations.Globals) error {
	c.Common.ApplyDefaults(globals.SubsystemOpts.Metrics.Autoscrape)
	if id, err := c.Identifier(globals); err == nil {
		c.Common.InstanceKey = &id
	}
	return nil
}

// Name returns the name of the integration that this config represents
func (c *Config) Name() string { return IntegrationName }

// Identifier uniquely identifies the app agent receiver integration
func (c *Config) Identifier(globals integrations.Globals) (string, error) {
	if c.Common.InstanceKey != nil {
		return *c.Common.InstanceKey, nil
	}
	return globals.AgentIdentifier, nil
}

'''
'''--- pkg/integrations/v2/app_agent_receiver/config_test.go ---
package app_agent_receiver

import (
	"testing"

	"github.com/stretchr/testify/require"
	"gopkg.in/yaml.v2"
)

func TestConfig_DefaultConfig(t *testing.T) {
	var cfg Config
	cb := `
test-conf: test-val`
	err := yaml.Unmarshal([]byte(cb), &cfg)
	require.NoError(t, err)
	require.Equal(t, []string(nil), cfg.Server.CORSAllowedOrigins)
	require.Equal(t, "127.0.0.1", cfg.Server.Host)
	require.Equal(t, 12347, cfg.Server.Port)
	require.Equal(t, true, cfg.Server.RateLimiting.Enabled)
}

func TestConfig_EnableRateLimitNoRPS(t *testing.T) {
	var cfg Config
	cb := `
server:
  rate_limiting:
    enabled: true`
	err := yaml.Unmarshal([]byte(cb), &cfg)
	require.NoError(t, err)
	require.Equal(t, true, cfg.Server.RateLimiting.Enabled)
	require.Equal(t, 100.0, cfg.Server.RateLimiting.RPS)
	require.Equal(t, 50, cfg.Server.RateLimiting.Burstiness)
}

func TestConfig_EnableRateLimitRPS(t *testing.T) {
	var cfg Config
	cb := `
server:
  rate_limiting:
    enabled: true
    rps: 142`
	err := yaml.Unmarshal([]byte(cb), &cfg)
	require.NoError(t, err)
	require.Equal(t, true, cfg.Server.RateLimiting.Enabled)
	require.Equal(t, 142.0, cfg.Server.RateLimiting.RPS)
	require.Equal(t, 50, cfg.Server.RateLimiting.Burstiness)
}

func TestConfig_MultipleUnmarshals(t *testing.T) {
	var cfg1 Config
	cb1 := `
sourcemaps:
  download_origins: ["one"]
logs_labels:
  app: frontend
  one: two`
	var cfg2 Config
	cb2 := `
logs_labels:
  app: backend
  bar: baz`

	err := yaml.UnmarshalStrict([]byte(cb1), &cfg1)
	require.NoError(t, err)
	err = yaml.UnmarshalStrict([]byte(cb2), &cfg2)
	require.NoError(t, err)

	require.Equal(t, map[string]string{
		"app": "frontend",
		"one": "two",
	}, cfg1.LogsLabels)
	require.Equal(t, []string{"one"}, cfg1.SourceMaps.DownloadFromOrigins)

	require.Equal(t, map[string]string{
		"app": "backend",
		"bar": "baz",
	}, cfg2.LogsLabels)
	require.Equal(t, []string{"*"}, cfg2.SourceMaps.DownloadFromOrigins)
}

'''
'''--- pkg/integrations/v2/app_agent_receiver/handler.go ---
package app_agent_receiver

import (
	"context"
	"sync"

	"crypto/subtle"
	"encoding/json"
	"net/http"

	"github.com/go-kit/log"
	"github.com/go-kit/log/level"
	"github.com/prometheus/client_golang/prometheus"
	"github.com/rs/cors"
	"golang.org/x/time/rate"
)

const apiKeyHeader = "x-api-key"

type appAgentReceiverExporter interface {
	Name() string
	Export(ctx context.Context, payload Payload) error
}

// AppAgentReceiverHandler struct controls the data ingestion http handler of the receiver
type AppAgentReceiverHandler struct {
	exporters               []appAgentReceiverExporter
	config                  *Config
	rateLimiter             *rate.Limiter
	exporterErrorsCollector *prometheus.CounterVec
}

// NewAppAgentReceiverHandler creates a new AppReceiver instance based on the given configuration
func NewAppAgentReceiverHandler(conf *Config, exporters []appAgentReceiverExporter, reg prometheus.Registerer) AppAgentReceiverHandler {
	var rateLimiter *rate.Limiter
	if conf.Server.RateLimiting.Enabled {
		var rps float64
		if conf.Server.RateLimiting.RPS > 0 {
			rps = conf.Server.RateLimiting.RPS
		}

		var b int
		if conf.Server.RateLimiting.Burstiness > 0 {
			b = conf.Server.RateLimiting.Burstiness
		}
		rateLimiter = rate.NewLimiter(rate.Limit(rps), b)
	}

	exporterErrorsCollector := prometheus.NewCounterVec(prometheus.CounterOpts{
		Name: "app_agent_receiver_exporter_errors_total",
		Help: "Total number of errors produced by a receiver exporter",
	}, []string{"exporter"})

	reg.MustRegister(exporterErrorsCollector)

	return AppAgentReceiverHandler{
		exporters:               exporters,
		config:                  conf,
		rateLimiter:             rateLimiter,
		exporterErrorsCollector: exporterErrorsCollector,
	}
}

// HTTPHandler is the http.Handler for the receiver. It will do the following
// 0. Enable CORS for the configured hosts
// 1. Check if the request should be rate limited
// 2. Verify that the payload size is within limits
// 3. Start two go routines for exporters processing and exporting data respectively
// 4. Respond with 202 once all the work is done
func (ar *AppAgentReceiverHandler) HTTPHandler(logger log.Logger) http.Handler {
	var handler http.Handler = http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
		// Check rate limiting state
		if ar.config.Server.RateLimiting.Enabled {
			if ok := ar.rateLimiter.Allow(); !ok {
				http.Error(w, http.StatusText(http.StatusTooManyRequests), http.StatusTooManyRequests)
				return
			}
		}

		// check API key if one is provided
		if len(ar.config.Server.APIKey) > 0 && subtle.ConstantTimeCompare([]byte(r.Header.Get(apiKeyHeader)), []byte(ar.config.Server.APIKey)) == 0 {
			http.Error(w, "api key not provided or incorrect", http.StatusUnauthorized)
			return
		}

		// Verify content length. We trust net/http to give us the correct number
		if ar.config.Server.MaxAllowedPayloadSize > 0 && r.ContentLength > ar.config.Server.MaxAllowedPayloadSize {
			http.Error(w, http.StatusText(http.StatusRequestEntityTooLarge), http.StatusRequestEntityTooLarge)
			return
		}

		var p Payload
		err := json.NewDecoder(r.Body).Decode(&p)
		if err != nil {
			http.Error(w, err.Error(), http.StatusBadRequest)
			return
		}

		var wg sync.WaitGroup

		for _, exporter := range ar.exporters {
			wg.Add(1)
			go func(exp appAgentReceiverExporter) {
				defer wg.Done()
				if err := exp.Export(r.Context(), p); err != nil {
					level.Error(logger).Log("msg", "exporter error", "exporter", exp.Name(), "error", err)
					ar.exporterErrorsCollector.WithLabelValues(exp.Name()).Inc()
				}
			}(exporter)
		}

		wg.Wait()
		w.WriteHeader(http.StatusAccepted)
		_, _ = w.Write([]byte("ok"))
	})

	if len(ar.config.Server.CORSAllowedOrigins) > 0 {
		c := cors.New(cors.Options{
			AllowedOrigins: ar.config.Server.CORSAllowedOrigins,
			AllowedHeaders: []string{apiKeyHeader, "content-type"},
		})
		handler = c.Handler(handler)
	}

	return handler
}

'''
'''--- pkg/integrations/v2/app_agent_receiver/handler_test.go ---
package app_agent_receiver

import (
	"bytes"
	"context"
	"errors"
	"net/http"
	"net/http/httptest"
	"testing"

	"github.com/go-kit/log"
	"github.com/stretchr/testify/require"

	"github.com/prometheus/client_golang/prometheus"
)

const PAYLOAD = `
{
  "traces": {
    "resourceSpans": []
  },
  "logs": [],
  "exceptions": [],
  "measurements": [],
  "meta": {}
}
`

type TestExporter struct {
	name     string
	broken   bool
	payloads []Payload
}

func (te *TestExporter) Name() string {
	return te.name
}

func (te *TestExporter) Export(ctx context.Context, payload Payload) error {
	if te.broken {
		return errors.New("this exporter is broken")
	}
	te.payloads = append(te.payloads, payload)
	return nil
}

func TestMultipleExportersAllSucceed(t *testing.T) {
	req, err := http.NewRequest("POST", "/collect", bytes.NewBuffer([]byte(PAYLOAD)))

	reg := prometheus.NewRegistry()

	require.NoError(t, err)

	exporter1 := TestExporter{
		name:     "exporter1",
		broken:   false,
		payloads: []Payload{},
	}
	exporter2 := TestExporter{
		name:     "exporter2",
		broken:   false,
		payloads: []Payload{},
	}

	conf := &Config{}

	fr := NewAppAgentReceiverHandler(conf, []appAgentReceiverExporter{&exporter1, &exporter2}, reg)
	handler := fr.HTTPHandler(log.NewNopLogger())

	rr := httptest.NewRecorder()

	handler.ServeHTTP(rr, req)

	require.Equal(t, http.StatusAccepted, rr.Result().StatusCode)

	require.Len(t, exporter1.payloads, 1)
	require.Len(t, exporter2.payloads, 1)
}

func TestMultipleExportersOneFails(t *testing.T) {
	req, err := http.NewRequest("POST", "/collect", bytes.NewBuffer([]byte(PAYLOAD)))

	require.NoError(t, err)

	reg := prometheus.NewRegistry()

	exporter1 := TestExporter{
		name:     "exporter1",
		broken:   true,
		payloads: []Payload{},
	}
	exporter2 := TestExporter{
		name:     "exporter2",
		broken:   false,
		payloads: []Payload{},
	}

	conf := &Config{}

	fr := NewAppAgentReceiverHandler(conf, []appAgentReceiverExporter{&exporter1, &exporter2}, reg)
	handler := fr.HTTPHandler(log.NewNopLogger())

	rr := httptest.NewRecorder()

	handler.ServeHTTP(rr, req)

	metrics, err := reg.Gather()
	require.NoError(t, err)

	metric := metrics[0]
	require.Equal(t, "app_agent_receiver_exporter_errors_total", *metric.Name)
	require.Len(t, metric.Metric, 1)
	require.Equal(t, 1.0, *metric.Metric[0].Counter.Value)
	require.Len(t, metric.Metric[0].Label, 1)
	require.Equal(t, *metric.Metric[0].Label[0].Value, "exporter1")
	require.Len(t, metrics, 1)
	require.Equal(t, http.StatusAccepted, rr.Result().StatusCode)
	require.Len(t, exporter1.payloads, 0)
	require.Len(t, exporter2.payloads, 1)
}

func TestMultipleExportersAllFail(t *testing.T) {
	req, err := http.NewRequest("POST", "/collect", bytes.NewBuffer([]byte(PAYLOAD)))

	reg := prometheus.NewRegistry()

	require.NoError(t, err)

	exporter1 := TestExporter{
		name:     "exporter1",
		broken:   true,
		payloads: []Payload{},
	}
	exporter2 := TestExporter{
		name:     "exporter2",
		broken:   true,
		payloads: []Payload{},
	}

	conf := &Config{}

	fr := NewAppAgentReceiverHandler(conf, []appAgentReceiverExporter{&exporter1, &exporter2}, reg)
	handler := fr.HTTPHandler(log.NewNopLogger())

	rr := httptest.NewRecorder()

	handler.ServeHTTP(rr, req)

	metrics, err := reg.Gather()
	require.NoError(t, err)

	require.Len(t, metrics, 1)
	metric := metrics[0]

	require.Equal(t, "app_agent_receiver_exporter_errors_total", *metric.Name)
	require.Len(t, metric.Metric, 2)
	require.Equal(t, 1.0, *metric.Metric[0].Counter.Value)
	require.Equal(t, 1.0, *metric.Metric[1].Counter.Value)
	require.Len(t, metric.Metric[0].Label, 1)
	require.Len(t, metric.Metric[1].Label, 1)
	require.Equal(t, *metric.Metric[0].Label[0].Value, "exporter1")
	require.Equal(t, *metric.Metric[1].Label[0].Value, "exporter2")
	require.Equal(t, http.StatusAccepted, rr.Result().StatusCode)
	require.Len(t, exporter1.payloads, 0)
	require.Len(t, exporter2.payloads, 0)
}

func TestNoContentLengthLimitSet(t *testing.T) {
	req, err := http.NewRequest("POST", "/collect", bytes.NewBuffer([]byte(PAYLOAD)))
	require.NoError(t, err)
	reg := prometheus.NewRegistry()

	conf := &Config{}

	req.ContentLength = 89348593894

	fr := NewAppAgentReceiverHandler(conf, []appAgentReceiverExporter{}, reg)
	handler := fr.HTTPHandler(nil)

	rr := httptest.NewRecorder()

	handler.ServeHTTP(rr, req)

	require.Equal(t, http.StatusAccepted, rr.Result().StatusCode)
}

func TestLargePayload(t *testing.T) {
	req, err := http.NewRequest("POST", "/collect", bytes.NewBuffer([]byte(PAYLOAD)))
	require.NoError(t, err)
	reg := prometheus.NewRegistry()

	conf := &Config{
		Server: ServerConfig{
			MaxAllowedPayloadSize: 10,
		},
	}

	fr := NewAppAgentReceiverHandler(conf, []appAgentReceiverExporter{}, reg)
	handler := fr.HTTPHandler(nil)

	rr := httptest.NewRecorder()

	handler.ServeHTTP(rr, req)
	require.Equal(t, http.StatusRequestEntityTooLarge, rr.Result().StatusCode)
}

func TestAPIKeyRequiredButNotProvided(t *testing.T) {
	req, err := http.NewRequest("POST", "/collect", bytes.NewBuffer([]byte(PAYLOAD)))

	if err != nil {
		t.Fatal(err)
	}

	conf := &Config{
		Server: ServerConfig{
			APIKey: "foo",
		},
	}

	fr := NewAppAgentReceiverHandler(conf, nil, prometheus.NewRegistry())
	handler := fr.HTTPHandler(nil)

	rr := httptest.NewRecorder()

	handler.ServeHTTP(rr, req)
	require.Equal(t, http.StatusUnauthorized, rr.Result().StatusCode)
}

func TestAPIKeyWrong(t *testing.T) {
	req, err := http.NewRequest("POST", "/collect", bytes.NewBuffer([]byte(PAYLOAD)))
	req.Header.Set("x-api-key", "bar")

	if err != nil {
		t.Fatal(err)
	}

	conf := &Config{
		Server: ServerConfig{
			APIKey: "foo",
		},
	}

	fr := NewAppAgentReceiverHandler(conf, nil, prometheus.NewRegistry())
	handler := fr.HTTPHandler(nil)

	rr := httptest.NewRecorder()

	handler.ServeHTTP(rr, req)
	require.Equal(t, http.StatusUnauthorized, rr.Result().StatusCode)
}

func TestAPIKeyCorrect(t *testing.T) {
	req, err := http.NewRequest("POST", "/collect", bytes.NewBuffer([]byte(PAYLOAD)))
	req.Header.Set("x-api-key", "foo")

	if err != nil {
		t.Fatal(err)
	}

	conf := &Config{
		Server: ServerConfig{
			APIKey: "foo",
		},
	}

	fr := NewAppAgentReceiverHandler(conf, nil, prometheus.NewRegistry())
	handler := fr.HTTPHandler(nil)

	rr := httptest.NewRecorder()

	handler.ServeHTTP(rr, req)
	require.Equal(t, http.StatusAccepted, rr.Result().StatusCode)
}

func TestRateLimiterNoReject(t *testing.T) {
	req, err := http.NewRequest("POST", "/collect", bytes.NewBuffer([]byte(PAYLOAD)))

	if err != nil {
		t.Fatal(err)
	}

	conf := &Config{
		Server: ServerConfig{
			RateLimiting: RateLimitingConfig{
				Burstiness: 10,
				RPS:        10,
				Enabled:    true,
			},
		},
	}

	fr := NewAppAgentReceiverHandler(conf, nil, prometheus.NewRegistry())
	handler := fr.HTTPHandler(nil)

	rr := httptest.NewRecorder()

	handler.ServeHTTP(rr, req)
	require.Equal(t, http.StatusAccepted, rr.Result().StatusCode)
}

func TestRateLimiterReject(t *testing.T) {
	conf := &Config{
		Server: ServerConfig{
			RateLimiting: RateLimitingConfig{
				Burstiness: 2,
				RPS:        1,
				Enabled:    true,
			},
		},
	}

	fr := NewAppAgentReceiverHandler(conf, nil, prometheus.NewRegistry())
	handler := fr.HTTPHandler(nil)

	makeRequest := func() *httptest.ResponseRecorder {
		req, err := http.NewRequest("POST", "/collect", bytes.NewBuffer([]byte(PAYLOAD)))
		require.NoError(t, err)
		rr := httptest.NewRecorder()
		handler.ServeHTTP(rr, req)
		return rr
	}

	r1 := makeRequest()
	r2 := makeRequest()
	r3 := makeRequest()

	require.Equal(t, http.StatusAccepted, r1.Result().StatusCode)
	require.Equal(t, http.StatusAccepted, r2.Result().StatusCode)
	require.Equal(t, http.StatusTooManyRequests, r3.Result().StatusCode)
}

func TestRateLimiterDisabled(t *testing.T) {
	req, err := http.NewRequest("POST", "/collect", bytes.NewBuffer([]byte(PAYLOAD)))

	if err != nil {
		t.Fatal(err)
	}

	conf := &Config{
		Server: ServerConfig{
			RateLimiting: RateLimitingConfig{
				Burstiness: 0,
				RPS:        0,
				Enabled:    false,
			},
		},
	}

	fr := NewAppAgentReceiverHandler(conf, nil, prometheus.NewRegistry())
	handler := fr.HTTPHandler(nil)

	rr := httptest.NewRecorder()

	handler.ServeHTTP(rr, req)
	require.Equal(t, http.StatusAccepted, rr.Result().StatusCode)
}

'''
'''--- pkg/integrations/v2/app_agent_receiver/logs_exporter.go ---
package app_agent_receiver

import (
	"context"
	"fmt"
	"time"

	kitlog "github.com/go-kit/log"
	"github.com/go-kit/log/level"
	"github.com/go-logfmt/logfmt"
	"github.com/grafana/agent/pkg/logs"
	"github.com/grafana/loki/clients/pkg/promtail/api"
	"github.com/grafana/loki/pkg/logproto"
	prommodel "github.com/prometheus/common/model"
)

// logsInstance is an interface with capability to send log entries
type logsInstance interface {
	SendEntry(entry api.Entry, dur time.Duration) bool
}

// logsInstanceGetter is a function that returns a LogsInstance to send log entries to
type logsInstanceGetter func() (logsInstance, error)

// LogsExporterConfig holds the configuration of the logs exporter
type LogsExporterConfig struct {
	SendEntryTimeout time.Duration
	GetLogsInstance  logsInstanceGetter
	Labels           map[string]string
}

// LogsExporter will send logs & errors to loki
type LogsExporter struct {
	getLogsInstance  logsInstanceGetter
	sendEntryTimeout time.Duration
	logger           kitlog.Logger
	labels           map[string]string
	sourceMapStore   SourceMapStore
}

// NewLogsExporter creates a new logs exporter with the given
// configuration
func NewLogsExporter(logger kitlog.Logger, conf LogsExporterConfig, sourceMapStore SourceMapStore) appAgentReceiverExporter {
	return &LogsExporter{
		logger:           logger,
		getLogsInstance:  conf.GetLogsInstance,
		sendEntryTimeout: conf.SendEntryTimeout,
		labels:           conf.Labels,
		sourceMapStore:   sourceMapStore,
	}
}

// Name of the exporter, for logging purposes
func (le *LogsExporter) Name() string {
	return "logs exporter"
}

// Export implements the AppDataExporter interface
func (le *LogsExporter) Export(ctx context.Context, payload Payload) error {
	meta := payload.Meta.KeyVal()

	var err error

	// log events
	for _, logItem := range payload.Logs {
		kv := logItem.KeyVal()
		MergeKeyVal(kv, meta)
		err = le.sendKeyValsToLogsPipeline(kv)
	}

	// exceptions
	for _, exception := range payload.Exceptions {
		transformedException := TransformException(le.sourceMapStore, le.logger, &exception, payload.Meta.App.Release)
		kv := transformedException.KeyVal()
		MergeKeyVal(kv, meta)
		err = le.sendKeyValsToLogsPipeline(kv)
	}

	// measurements
	for _, measurement := range payload.Measurements {
		kv := measurement.KeyVal()
		MergeKeyVal(kv, meta)
		err = le.sendKeyValsToLogsPipeline(kv)
	}

	return err
}

func (le *LogsExporter) sendKeyValsToLogsPipeline(kv *KeyVal) error {
	line, err := logfmt.MarshalKeyvals(KeyValToInterfaceSlice(kv)...)
	if err != nil {
		level.Error(le.logger).Log("msg", "failed to logfmt a frontend log event", "err", err)
		return err
	}
	instance, err := le.getLogsInstance()
	if err != nil {
		return err
	}
	sent := instance.SendEntry(api.Entry{
		Labels: le.labelSet(kv),
		Entry: logproto.Entry{
			Timestamp: time.Now(),
			Line:      string(line),
		},
	}, le.sendEntryTimeout)
	if !sent {
		level.Warn(le.logger).Log("msg", "failed to log frontend log event to logs pipeline")
		return fmt.Errorf("failed to send app event to logs pipeline")
	}
	return nil
}

func (le *LogsExporter) labelSet(kv *KeyVal) prommodel.LabelSet {
	set := make(prommodel.LabelSet, len(le.labels))

	for k, v := range le.labels {
		if len(v) > 0 {
			set[prommodel.LabelName(k)] = prommodel.LabelValue(v)
		} else {
			if val, ok := kv.Get(k); ok {
				set[prommodel.LabelName(k)] = prommodel.LabelValue(fmt.Sprint(val))
			}
		}
	}

	return set
}

// Static typecheck tests
var (
	_ appAgentReceiverExporter = (*LogsExporter)(nil)
	_ logsInstance             = (*logs.Instance)(nil)
)

'''
'''--- pkg/integrations/v2/app_agent_receiver/logs_exporter_test.go ---
package app_agent_receiver

import (
	"context"
	"encoding/json"
	"io/ioutil"
	"testing"
	"time"

	kitlog "github.com/go-kit/log"
	"github.com/grafana/loki/clients/pkg/promtail/api"
	prommodel "github.com/prometheus/common/model"

	"github.com/stretchr/testify/require"
)

func loadTestPayload(t *testing.T) Payload {
	t.Helper()
	// Safe to disable, this is a test.
	// nolint:gosec
	content, err := ioutil.ReadFile("./testdata/payload.json")
	require.NoError(t, err, "expected to be able to read file")
	require.True(t, len(content) > 0)
	var payload Payload
	err = json.Unmarshal(content, &payload)
	require.NoError(t, err)
	return payload
}

type testLogsInstance struct {
	Entries []api.Entry
}

func (i *testLogsInstance) SendEntry(entry api.Entry, dur time.Duration) bool {
	i.Entries = append(i.Entries, entry)
	return true
}

type MockSourceMapStore struct{}

func (store *MockSourceMapStore) GetSourceMap(sourceURL string, release string) (*SourceMap, error) {
	return nil, nil
}

func TestExportLogs(t *testing.T) {
	ctx := context.Background()
	inst := &testLogsInstance{
		Entries: []api.Entry{},
	}

	logger := kitlog.NewNopLogger()

	logsExporter := NewLogsExporter(
		logger,
		LogsExporterConfig{
			GetLogsInstance: func() (logsInstance, error) { return inst, nil },
			Labels: map[string]string{
				"app":  "frontend",
				"kind": "",
			},
			SendEntryTimeout: 100,
		},
		&MockSourceMapStore{},
	)

	payload := loadTestPayload(t)

	err := logsExporter.Export(ctx, payload)
	require.NoError(t, err)

	require.Len(t, inst.Entries, 4)

	// log1
	require.Equal(t, prommodel.LabelSet{
		prommodel.LabelName("app"):  prommodel.LabelValue("frontend"),
		prommodel.LabelName("kind"): prommodel.LabelValue("log"),
	}, inst.Entries[0].Labels)
	expectedLine := "timestamp=\"2021-09-30 10:46:17.68 +0000 UTC\" kind=log message=\"opened pricing page\" level=info context_component=AppRoot context_page=Pricing traceID=abcd spanID=def sdk_name=grafana-frontend-agent sdk_version=1.0.0 app_name=testapp app_release=0.8.2 app_version=abcdefg app_environment=production user_email=geralt@kaermorhen.org user_id=123 user_username=domasx2 user_attr_foo=bar session_id=abcd session_attr_time_elapsed=100s page_url=https://example.com/page browser_name=chrome browser_version=88.12.1 browser_os=linux browser_mobile=false"
	require.Equal(t, expectedLine, inst.Entries[0].Line)

	// log2
	require.Equal(t, prommodel.LabelSet{
		prommodel.LabelName("app"):  prommodel.LabelValue("frontend"),
		prommodel.LabelName("kind"): prommodel.LabelValue("log"),
	}, inst.Entries[1].Labels)
	expectedLine = "timestamp=\"2021-09-30 10:46:17.68 +0000 UTC\" kind=log message=\"loading price list\" level=trace context_component=AppRoot context_page=Pricing traceID=abcd spanID=ghj sdk_name=grafana-frontend-agent sdk_version=1.0.0 app_name=testapp app_release=0.8.2 app_version=abcdefg app_environment=production user_email=geralt@kaermorhen.org user_id=123 user_username=domasx2 user_attr_foo=bar session_id=abcd session_attr_time_elapsed=100s page_url=https://example.com/page browser_name=chrome browser_version=88.12.1 browser_os=linux browser_mobile=false"
	require.Equal(t, expectedLine, inst.Entries[1].Line)

	// exception
	require.Equal(t, prommodel.LabelSet{
		prommodel.LabelName("app"):  prommodel.LabelValue("frontend"),
		prommodel.LabelName("kind"): prommodel.LabelValue("exception"),
	}, inst.Entries[2].Labels)
	expectedLine = "timestamp=\"2021-09-30 10:46:17.68 +0000 UTC\" kind=exception type=Error value=\"Cannot read property 'find' of undefined\" stacktrace=\"Error: Cannot read property 'find' of undefined\\n  at ? (http://fe:3002/static/js/vendors~main.chunk.js:8639:42)\\n  at dispatchAction (http://fe:3002/static/js/vendors~main.chunk.js:268095:9)\\n  at scheduleUpdateOnFiber (http://fe:3002/static/js/vendors~main.chunk.js:273726:13)\\n  at flushSyncCallbackQueue (http://fe:3002/static/js/vendors~main.chunk.js:263362:7)\\n  at flushSyncCallbackQueueImpl (http://fe:3002/static/js/vendors~main.chunk.js:263374:13)\\n  at runWithPriority$1 (http://fe:3002/static/js/vendors~main.chunk.js:263325:14)\\n  at unstable_runWithPriority (http://fe:3002/static/js/vendors~main.chunk.js:291265:16)\\n  at ? (http://fe:3002/static/js/vendors~main.chunk.js:263379:30)\\n  at performSyncWorkOnRoot (http://fe:3002/static/js/vendors~main.chunk.js:274126:22)\\n  at renderRootSync (http://fe:3002/static/js/vendors~main.chunk.js:274509:11)\\n  at workLoopSync (http://fe:3002/static/js/vendors~main.chunk.js:274543:9)\\n  at performUnitOfWork (http://fe:3002/static/js/vendors~main.chunk.js:274606:16)\\n  at beginWork$1 (http://fe:3002/static/js/vendors~main.chunk.js:275746:18)\\n  at beginWork (http://fe:3002/static/js/vendors~main.chunk.js:270944:20)\\n  at updateFunctionComponent (http://fe:3002/static/js/vendors~main.chunk.js:269291:24)\\n  at renderWithHooks (http://fe:3002/static/js/vendors~main.chunk.js:266969:22)\\n  at ? (http://fe:3002/static/js/main.chunk.js:2600:74)\\n  at useGetBooksQuery (http://fe:3002/static/js/main.chunk.js:1299:65)\\n  at Module.useQuery (http://fe:3002/static/js/vendors~main.chunk.js:8495:85)\\n  at useBaseQuery (http://fe:3002/static/js/vendors~main.chunk.js:8656:83)\\n  at useDeepMemo (http://fe:3002/static/js/vendors~main.chunk.js:8696:14)\\n  at ? (http://fe:3002/static/js/vendors~main.chunk.js:8657:55)\\n  at QueryData.execute (http://fe:3002/static/js/vendors~main.chunk.js:7883:47)\\n  at QueryData.getExecuteResult (http://fe:3002/static/js/vendors~main.chunk.js:7944:23)\\n  at QueryData._this.getQueryResult (http://fe:3002/static/js/vendors~main.chunk.js:7790:19)\\n  at new ApolloError (http://fe:3002/static/js/vendors~main.chunk.js:5164:24)\" sdk_name=grafana-frontend-agent sdk_version=1.0.0 app_name=testapp app_release=0.8.2 app_version=abcdefg app_environment=production user_email=geralt@kaermorhen.org user_id=123 user_username=domasx2 user_attr_foo=bar session_id=abcd session_attr_time_elapsed=100s page_url=https://example.com/page browser_name=chrome browser_version=88.12.1 browser_os=linux browser_mobile=false"
	require.Equal(t, expectedLine, inst.Entries[2].Line)

	// measurement
	require.Equal(t, prommodel.LabelSet{
		prommodel.LabelName("app"):  prommodel.LabelValue("frontend"),
		prommodel.LabelName("kind"): prommodel.LabelValue("measurement"),
	}, inst.Entries[3].Labels)
	expectedLine = "timestamp=\"2021-09-30 10:46:17.68 +0000 UTC\" kind=measurement ttfb=14.000000 ttfcp=22.120000 ttfp=20.120000 traceID=abcd spanID=def sdk_name=grafana-frontend-agent sdk_version=1.0.0 app_name=testapp app_release=0.8.2 app_version=abcdefg app_environment=production user_email=geralt@kaermorhen.org user_id=123 user_username=domasx2 user_attr_foo=bar session_id=abcd session_attr_time_elapsed=100s page_url=https://example.com/page browser_name=chrome browser_version=88.12.1 browser_os=linux browser_mobile=false"
	require.Equal(t, expectedLine, inst.Entries[3].Line)
}

'''
'''--- pkg/integrations/v2/app_agent_receiver/payload.go ---
package app_agent_receiver

import (
	"fmt"
	"sort"
	"strings"
	"time"

	"go.opentelemetry.io/collector/pdata/pcommon"
	"go.opentelemetry.io/collector/pdata/ptrace"
)

// Payload is the body of the receiver request
type Payload struct {
	Exceptions   []Exception   `json:"exceptions,omitempty"`
	Logs         []Log         `json:"logs,omitempty"`
	Measurements []Measurement `json:"measurements,omitempty"`
	Meta         Meta          `json:"meta,omitempty"`
	Traces       *Traces       `json:"traces,omitempty"`
}

// Frame struct represents a single stacktrace frame
type Frame struct {
	Function string `json:"function,omitempty"`
	Module   string `json:"module,omitempty"`
	Filename string `json:"filename,omitempty"`
	Lineno   int    `json:"lineno,omitempty"`
	Colno    int    `json:"colno,omitempty"`
}

// String function converts a Frame into a human readable string
func (frame Frame) String() string {
	module := ""
	if len(frame.Module) > 0 {
		module = frame.Module + "|"
	}
	return fmt.Sprintf("\n  at %s (%s%s:%v:%v)", frame.Function, module, frame.Filename, frame.Lineno, frame.Colno)
}

// Stacktrace is a collection of Frames
type Stacktrace struct {
	Frames []Frame `json:"frames,omitempty"`
}

// Exception struct controls all the data regarding an exception
type Exception struct {
	Type       string       `json:"type,omitempty"`
	Value      string       `json:"value,omitempty"`
	Stacktrace *Stacktrace  `json:"stacktrace,omitempty"`
	Timestamp  time.Time    `json:"timestamp"`
	Trace      TraceContext `json:"trace,omitempty"`
}

// Message string is concatenating of the Exception.Type and Exception.Value
func (e Exception) Message() string {
	return fmt.Sprintf("%s: %s", e.Type, e.Value)
}

// String is the string representation of an Exception
func (e Exception) String() string {
	var stacktrace = e.Message()
	if e.Stacktrace != nil {
		for _, frame := range e.Stacktrace.Frames {
			stacktrace += frame.String()
		}
	}
	return stacktrace
}

// KeyVal representation of the exception object
func (e Exception) KeyVal() *KeyVal {
	kv := NewKeyVal()
	KeyValAdd(kv, "timestamp", e.Timestamp.String())
	KeyValAdd(kv, "kind", "exception")
	KeyValAdd(kv, "type", e.Type)
	KeyValAdd(kv, "value", e.Value)
	KeyValAdd(kv, "stacktrace", e.String())
	MergeKeyVal(kv, e.Trace.KeyVal())
	return kv
}

// TraceContext holds trace id and span id associated to an entity (log, exception, measurement...).
type TraceContext struct {
	TraceID string `json:"trace_id"`
	SpanID  string `json:"span_id"`
}

// KeyVal representation of the trace context object.
func (tc TraceContext) KeyVal() *KeyVal {
	retv := NewKeyVal()
	KeyValAdd(retv, "traceID", tc.TraceID)
	KeyValAdd(retv, "spanID", tc.SpanID)
	return retv
}

// Traces wraps the otel traces model.
type Traces struct {
	ptrace.Traces
}

// UnmarshalJSON unmarshals Traces model.
func (t *Traces) UnmarshalJSON(b []byte) error {
	unmarshaler := ptrace.NewJSONUnmarshaler()
	td, err := unmarshaler.UnmarshalTraces(b)
	if err != nil {
		return err
	}
	*t = Traces{td}
	return nil
}

// MarshalJSON marshals Traces model to json.
func (t Traces) MarshalJSON() ([]byte, error) {
	marshaler := ptrace.NewJSONMarshaler()
	return marshaler.MarshalTraces(t.Traces)
}

// SpanSlice unpacks Traces entity into a slice of Spans.
func (t Traces) SpanSlice() []ptrace.Span {
	spans := make([]ptrace.Span, 0)
	rss := t.ResourceSpans()
	for i := 0; i < rss.Len(); i++ {
		rs := rss.At(i)
		ilss := rs.ScopeSpans()
		for j := 0; j < ilss.Len(); j++ {
			s := ilss.At(j).Spans()
			for si := 0; si < s.Len(); si++ {
				spans = append(spans, s.At(si))
			}
		}
	}
	return spans
}

// SpanToKeyVal returns KeyVal representation of a Span.
func SpanToKeyVal(s ptrace.Span) *KeyVal {
	kv := NewKeyVal()
	if s.StartTimestamp() > 0 {
		KeyValAdd(kv, "timestamp", s.StartTimestamp().AsTime().String())
	}
	if s.EndTimestamp() > 0 {
		KeyValAdd(kv, "end_timestamp", s.StartTimestamp().AsTime().String())
	}
	KeyValAdd(kv, "kind", "span")
	KeyValAdd(kv, "traceID", s.TraceID().HexString())
	KeyValAdd(kv, "spanID", s.SpanID().HexString())
	KeyValAdd(kv, "span_kind", s.Kind().String())
	KeyValAdd(kv, "name", s.Name())
	KeyValAdd(kv, "parent_spanID", s.ParentSpanID().HexString())
	s.Attributes().Range(func(k string, v pcommon.Value) bool {
		KeyValAdd(kv, "attr_"+k, fmt.Sprintf("%v", v))
		return true
	})

	return kv
}

// LogLevel is log level enum for incoming app logs
type LogLevel string

const (
	// LogLevelTrace is "trace"
	LogLevelTrace LogLevel = "trace"
	// LogLevelDebug is "debug"
	LogLevelDebug LogLevel = "debug"
	// LogLevelInfo is "info"
	LogLevelInfo LogLevel = "info"
	// LogLevelWarning is "warning"
	LogLevelWarning LogLevel = "warning"
	// LogLevelError is "error"
	LogLevelError LogLevel = "error"
)

// LogContext is a string to string map structure that
// represents the context of a log message
type LogContext map[string]string

// Log struct controls the data that come into a Log message
type Log struct {
	Message   string       `json:"message,omitempty"`
	LogLevel  LogLevel     `json:"level,omitempty"`
	Context   LogContext   `json:"context,omitempty"`
	Timestamp time.Time    `json:"timestamp"`
	Trace     TraceContext `json:"trace,omitempty"`
}

// KeyVal representation of a Log object
func (l Log) KeyVal() *KeyVal {
	kv := NewKeyVal()
	KeyValAdd(kv, "timestamp", l.Timestamp.String())
	KeyValAdd(kv, "kind", "log")
	KeyValAdd(kv, "message", l.Message)
	KeyValAdd(kv, "level", string(l.LogLevel))
	MergeKeyValWithPrefix(kv, KeyValFromMap(l.Context), "context_")
	MergeKeyVal(kv, l.Trace.KeyVal())
	return kv
}

// Measurement holds the data for user provided measurements
type Measurement struct {
	Values    map[string]float64 `json:"values,omitempty"`
	Timestamp time.Time          `json:"timestamp,omitempty"`
	Trace     TraceContext       `json:"trace,omitempty"`
}

// KeyVal representation of the exception object
func (m Measurement) KeyVal() *KeyVal {
	kv := NewKeyVal()

	KeyValAdd(kv, "timestamp", m.Timestamp.String())
	KeyValAdd(kv, "kind", "measurement")

	keys := make([]string, 0, len(m.Values))
	for k := range m.Values {
		keys = append(keys, k)
	}
	sort.Strings(keys)
	for _, k := range keys {
		KeyValAdd(kv, k, fmt.Sprintf("%f", m.Values[k]))
	}
	MergeKeyVal(kv, m.Trace.KeyVal())
	return kv
}

// SDK holds metadata about the app agent that produced the event
type SDK struct {
	Name         string           `json:"name,omitempty"`
	Version      string           `json:"version,omitempty"`
	Integrations []SDKIntegration `json:"integrations,omitempty"`
}

// KeyVal produces key->value representation of Sdk metadata
func (sdk SDK) KeyVal() *KeyVal {
	kv := NewKeyVal()
	KeyValAdd(kv, "name", sdk.Name)
	KeyValAdd(kv, "version", sdk.Version)

	if len(sdk.Integrations) > 0 {
		integrations := make([]string, len(sdk.Integrations))

		for i, integration := range sdk.Integrations {
			integrations[i] = integration.String()
		}

		KeyValAdd(kv, "integrations", strings.Join(integrations, ","))
	}

	return kv
}

// SDKIntegration holds metadata about a plugin/integration on the app agent that collected and sent the event
type SDKIntegration struct {
	Name    string `json:"name,omitempty"`
	Version string `json:"version,omitempty"`
}

func (i SDKIntegration) String() string {
	return fmt.Sprintf("%s:%s", i.Name, i.Version)
}

// User holds metadata about the user related to an app event
type User struct {
	Email      string            `json:"email,omitempty"`
	ID         string            `json:"id,omitempty"`
	Username   string            `json:"username,omitempty"`
	Attributes map[string]string `json:"attributes,omitempty"`
}

// KeyVal produces a key->value representation User metadata
func (u User) KeyVal() *KeyVal {
	kv := NewKeyVal()
	KeyValAdd(kv, "email", u.Email)
	KeyValAdd(kv, "id", u.ID)
	KeyValAdd(kv, "username", u.Username)
	MergeKeyValWithPrefix(kv, KeyValFromMap(u.Attributes), "attr_")
	return kv
}

// Meta holds metadata about an app event
type Meta struct {
	SDK     SDK     `json:"sdk,omitempty"`
	App     App     `json:"app,omitempty"`
	User    User    `json:"user,omitempty"`
	Session Session `json:"session,omitempty"`
	Page    Page    `json:"page,omitempty"`
	Browser Browser `json:"browser,omitempty"`
}

// KeyVal produces key->value representation of the app event metadatga
func (m Meta) KeyVal() *KeyVal {
	kv := NewKeyVal()
	MergeKeyValWithPrefix(kv, m.SDK.KeyVal(), "sdk_")
	MergeKeyValWithPrefix(kv, m.App.KeyVal(), "app_")
	MergeKeyValWithPrefix(kv, m.User.KeyVal(), "user_")
	MergeKeyValWithPrefix(kv, m.Session.KeyVal(), "session_")
	MergeKeyValWithPrefix(kv, m.Page.KeyVal(), "page_")
	MergeKeyValWithPrefix(kv, m.Browser.KeyVal(), "browser_")
	return kv
}

// Session holds metadata about the browser session the event originates from
type Session struct {
	ID         string            `json:"id,omitempty"`
	Attributes map[string]string `json:"attributes,omitempty"`
}

// KeyVal produces key->value representation of the Session metadata
func (s Session) KeyVal() *KeyVal {
	kv := NewKeyVal()
	KeyValAdd(kv, "id", s.ID)
	MergeKeyValWithPrefix(kv, KeyValFromMap(s.Attributes), "attr_")
	return kv
}

// Page holds metadata about the web page event originates from
type Page struct {
	ID         string            `json:"id,omitempty"`
	URL        string            `json:"url,omitempty"`
	Attributes map[string]string `json:"attributes,omitempty"`
}

// KeyVal produces key->val representation of Page metadata
func (p Page) KeyVal() *KeyVal {
	kv := NewKeyVal()
	KeyValAdd(kv, "id", p.ID)
	KeyValAdd(kv, "url", p.URL)
	MergeKeyValWithPrefix(kv, KeyValFromMap(p.Attributes), "attr_")
	return kv
}

// App holds metadata about the application event originates from
type App struct {
	Name        string `json:"name,omitempty"`
	Release     string `json:"release,omitempty"`
	Version     string `json:"version,omitempty"`
	Environment string `json:"environment,omitempty"`
}

// KeyVal produces key-> value representation of App metadata
func (a App) KeyVal() *KeyVal {
	kv := NewKeyVal()
	KeyValAdd(kv, "name", a.Name)
	KeyValAdd(kv, "release", a.Release)
	KeyValAdd(kv, "version", a.Version)
	KeyValAdd(kv, "environment", a.Environment)
	return kv
}

// Browser holds metadata about a client's browser
type Browser struct {
	Name    string `json:"name,omitempty"`
	Version string `json:"version,omitempty"`
	OS      string `json:"os,omitempty"`
	Mobile  bool   `json:"mobile,omitempty"`
}

// KeyVal produces key->value representation of the Browser metadata
func (b Browser) KeyVal() *KeyVal {
	kv := NewKeyVal()
	KeyValAdd(kv, "name", b.Name)
	KeyValAdd(kv, "version", b.Version)
	KeyValAdd(kv, "os", b.OS)
	KeyValAdd(kv, "mobile", fmt.Sprintf("%v", b.Mobile))
	return kv
}

'''
'''--- pkg/integrations/v2/app_agent_receiver/payload_test.go ---
package app_agent_receiver

import (
	"encoding/json"
	"io/ioutil"
	"path/filepath"
	"testing"
	"time"

	"github.com/stretchr/testify/require"
)

func loadTestData(t *testing.T, file string) []byte {
	t.Helper()
	// Safe to disable, this is a test.
	// nolint:gosec
	content, err := ioutil.ReadFile(filepath.Join("testdata", file))
	require.NoError(t, err, "expected to be able to read file")
	require.True(t, len(content) > 0)
	return content
}

func TestUnmarshalPayloadJSON(t *testing.T) {
	content := loadTestData(t, "payload.json")
	var payload Payload
	err := json.Unmarshal(content, &payload)
	require.NoError(t, err)

	now, err := time.Parse("2006-01-02T15:04:05Z0700", "2021-09-30T10:46:17.680Z")
	require.NoError(t, err)

	require.Equal(t, Meta{
		SDK: SDK{
			Name:    "grafana-frontend-agent",
			Version: "1.0.0",
		},
		App: App{
			Name:        "testapp",
			Release:     "0.8.2",
			Version:     "abcdefg",
			Environment: "production",
		},
		User: User{
			Username:   "domasx2",
			ID:         "123",
			Email:      "geralt@kaermorhen.org",
			Attributes: map[string]string{"foo": "bar"},
		},
		Session: Session{
			ID:         "abcd",
			Attributes: map[string]string{"time_elapsed": "100s"},
		},
		Page: Page{
			URL: "https://example.com/page",
		},
		Browser: Browser{
			Name:    "chrome",
			Version: "88.12.1",
			OS:      "linux",
			Mobile:  false,
		},
	}, payload.Meta)

	require.Len(t, payload.Exceptions, 1)
	require.Len(t, payload.Exceptions[0].Stacktrace.Frames, 26)
	require.Equal(t, "Error", payload.Exceptions[0].Type)
	require.Equal(t, "Cannot read property 'find' of undefined", payload.Exceptions[0].Value)

	require.Equal(t, []Log{
		{
			Message:  "opened pricing page",
			LogLevel: LogLevelInfo,
			Context: map[string]string{
				"component": "AppRoot",
				"page":      "Pricing",
			},
			Timestamp: now,
			Trace: TraceContext{
				TraceID: "abcd",
				SpanID:  "def",
			},
		},
		{
			Message:  "loading price list",
			LogLevel: LogLevelTrace,
			Context: map[string]string{
				"component": "AppRoot",
				"page":      "Pricing",
			},
			Timestamp: now,
			Trace: TraceContext{
				TraceID: "abcd",
				SpanID:  "ghj",
			},
		},
	}, payload.Logs)
}

'''
'''--- pkg/integrations/v2/app_agent_receiver/receiver_metrics_exporter.go ---
package app_agent_receiver

import (
	"context"

	"github.com/prometheus/client_golang/prometheus"
)

// ReceiverMetricsExporter is a app agent receiver exporter that will capture metrics
// about counts of logs, exceptions, measurements, traces being ingested
type ReceiverMetricsExporter struct {
	totalLogs         prometheus.Counter
	totalMeasurements prometheus.Counter
	totalExceptions   prometheus.Counter
}

// NewReceiverMetricsExporter creates a new ReceiverMetricsExporter
func NewReceiverMetricsExporter(reg prometheus.Registerer) appAgentReceiverExporter {
	exp := &ReceiverMetricsExporter{
		totalLogs: prometheus.NewCounter(prometheus.CounterOpts{
			Name: "app_agent_receiver_logs_total",
			Help: "Total number of ingested logs",
		}),
		totalMeasurements: prometheus.NewCounter(prometheus.CounterOpts{
			Name: "app_agent_receiver_measurements_total",
			Help: "Total number of ingested measurements",
		}),
		totalExceptions: prometheus.NewCounter(prometheus.CounterOpts{
			Name: "app_agent_receiver_exceptions_total",
			Help: "Total number of ingested exceptions",
		}),
	}

	reg.MustRegister(exp.totalLogs, exp.totalExceptions, exp.totalMeasurements)

	return exp
}

// Name of the exporter, for logging purposes
func (re *ReceiverMetricsExporter) Name() string {
	return "receiver metrics exporter"
}

// Export implements the AppDataExporter interface
func (re *ReceiverMetricsExporter) Export(ctx context.Context, payload Payload) error {
	re.totalExceptions.Add(float64(len(payload.Exceptions)))
	re.totalLogs.Add(float64(len(payload.Logs)))
	re.totalMeasurements.Add(float64(len(payload.Measurements)))
	return nil
}

'''
'''--- pkg/integrations/v2/app_agent_receiver/receiver_metrics_test.go ---
package app_agent_receiver

import (
	"context"
	"fmt"
	"testing"

	"github.com/prometheus/client_golang/prometheus"

	"github.com/stretchr/testify/require"
)

type metricAssertion struct {
	name  string
	value float64
}

func testcase(t *testing.T, payload Payload, assertions []metricAssertion) {
	ctx := context.Background()

	reg := prometheus.NewRegistry()

	exporter := NewReceiverMetricsExporter(reg)

	err := exporter.Export(ctx, payload)
	require.NoError(t, err)

	metrics, err := reg.Gather()
	require.NoError(t, err)

	for _, assertion := range assertions {
		found := false
		for _, metric := range metrics {
			if *metric.Name == assertion.name {
				found = true
				require.Len(t, metric.Metric, 1)
				val := metric.Metric[0].Counter.Value
				require.Equal(t, assertion.value, *val)
				break
			}
		}
		if !found {
			require.Fail(t, fmt.Sprintf("metric [%s] not found", assertion.name))
		}
	}
}

func TestReceiverMetricsExport(t *testing.T) {
	var payload Payload
	payload.Logs = make([]Log, 2)
	payload.Measurements = make([]Measurement, 3)
	payload.Exceptions = make([]Exception, 4)
	testcase(t, payload, []metricAssertion{
		{
			name:  "app_agent_receiver_logs_total",
			value: 2,
		},
		{
			name:  "app_agent_receiver_measurements_total",
			value: 3,
		},
		{
			name:  "app_agent_receiver_exceptions_total",
			value: 4,
		},
	})
}

func TestReceiverMetricsExportLogsOnly(t *testing.T) {
	var payload Payload
	payload.Logs = []Log{
		{},
		{},
	}
	testcase(t, payload, []metricAssertion{
		{
			name:  "app_agent_receiver_logs_total",
			value: 2,
		},
		{
			name:  "app_agent_receiver_measurements_total",
			value: 0,
		},
		{
			name:  "app_agent_receiver_exceptions_total",
			value: 0,
		},
	})
}

func TestReceiverMetricsExportExceptionsOnly(t *testing.T) {
	var payload Payload
	payload.Exceptions = []Exception{
		{},
		{},
		{},
		{},
	}
	testcase(t, payload, []metricAssertion{
		{
			name:  "app_agent_receiver_logs_total",
			value: 0,
		},
		{
			name:  "app_agent_receiver_measurements_total",
			value: 0,
		},
		{
			name:  "app_agent_receiver_exceptions_total",
			value: 4,
		},
	})
}

func TestReceiverMetricsExportMeasurementsOnly(t *testing.T) {
	var payload Payload
	payload.Measurements = []Measurement{
		{},
		{},
		{},
	}
	testcase(t, payload, []metricAssertion{
		{
			name:  "app_agent_receiver_logs_total",
			value: 0,
		},
		{
			name:  "app_agent_receiver_measurements_total",
			value: 3,
		},
		{
			name:  "app_agent_receiver_exceptions_total",
			value: 0,
		},
	})
}

'''
'''--- pkg/integrations/v2/app_agent_receiver/sourcemaps.go ---
package app_agent_receiver

import (
	"bytes"
	"fmt"
	"io"
	"io/fs"
	"net/http"
	"net/url"
	"os"
	"path/filepath"
	"regexp"
	"strings"
	"sync"
	"text/template"

	"github.com/go-kit/log"
	"github.com/go-kit/log/level"
	"github.com/go-sourcemap/sourcemap"
	"github.com/prometheus/client_golang/prometheus"
	"github.com/vincent-petithory/dataurl"
)

// SourceMapStore is interface for a sourcemap service capable of transforming
// minified source locations to original source location
type SourceMapStore interface {
	GetSourceMap(sourceURL string, release string) (*SourceMap, error)
}

type httpClient interface {
	Get(url string) (resp *http.Response, err error)
}

// FileService is interface for a service that can be used to load source maps
// from file system
type fileService interface {
	Stat(name string) (fs.FileInfo, error)
	ReadFile(name string) ([]byte, error)
}

type osFileService struct{}

func (s *osFileService) Stat(name string) (fs.FileInfo, error) {
	return os.Stat(name)
}

func (s *osFileService) ReadFile(name string) ([]byte, error) {
	return os.ReadFile(name)
}

var reSourceMap = "//[#@]\\s(source(?:Mapping)?URL)=\\s*(?P<url>\\S+)\r?\n?$"

// SourceMap is a wrapper for go-sourcemap consumer
type SourceMap struct {
	consumer *sourcemap.Consumer
}

type sourceMapMetrics struct {
	cacheSize *prometheus.CounterVec
	downloads *prometheus.CounterVec
	fileReads *prometheus.CounterVec
}

type sourcemapFileLocation struct {
	SourceMapFileLocation
	pathTemplate *template.Template
}

// RealSourceMapStore is an implementation of SourceMapStore
// that can download source maps or read them from file system
type RealSourceMapStore struct {
	sync.Mutex
	l             log.Logger
	httpClient    httpClient
	fileService   fileService
	config        SourceMapConfig
	cache         map[string]*SourceMap
	fileLocations []*sourcemapFileLocation
	metrics       *sourceMapMetrics
}

// NewSourceMapStore creates an instance of SourceMapStore.
// httpClient and fileService will be instantiated to defaults if nil is provided
func NewSourceMapStore(l log.Logger, config SourceMapConfig, reg prometheus.Registerer, httpClient httpClient, fileService fileService) SourceMapStore {
	if httpClient == nil {
		httpClient = &http.Client{
			Timeout: config.DownloadTimeout,
		}
	}

	if fileService == nil {
		fileService = &osFileService{}
	}

	metrics := &sourceMapMetrics{
		cacheSize: prometheus.NewCounterVec(prometheus.CounterOpts{
			Name: "app_agent_receiver_sourcemap_cache_size",
			Help: "number of items in sourcemap cache, per origin",
		}, []string{"origin"}),
		downloads: prometheus.NewCounterVec(prometheus.CounterOpts{
			Name: "app_agent_receiver_sourcemap_downloads_total",
			Help: "downloads by the sourcemap service",
		}, []string{"origin", "http_status"}),
		fileReads: prometheus.NewCounterVec(prometheus.CounterOpts{
			Name: "app_agent_receiver_sourcemap_file_reads_total",
			Help: "sourcemap file reads from file system, by origin and status",
		}, []string{"origin", "status"}),
	}
	reg.MustRegister(metrics.cacheSize, metrics.downloads, metrics.fileReads)

	fileLocations := []*sourcemapFileLocation{}

	for _, configLocation := range config.FileSystem {
		tpl, err := template.New(configLocation.Path).Parse(configLocation.Path)
		if err != nil {
			panic(err)
		}

		fileLocations = append(fileLocations, &sourcemapFileLocation{
			SourceMapFileLocation: configLocation,
			pathTemplate:          tpl,
		})
	}

	return &RealSourceMapStore{
		l:             l,
		httpClient:    httpClient,
		fileService:   fileService,
		config:        config,
		cache:         make(map[string]*SourceMap),
		metrics:       metrics,
		fileLocations: fileLocations,
	}
}

func (store *RealSourceMapStore) downloadFileContents(url string) ([]byte, error) {
	resp, err := store.httpClient.Get(url)
	if err != nil {
		store.metrics.downloads.WithLabelValues(getOrigin(url), "?").Inc()
		return nil, err
	}
	defer resp.Body.Close()
	store.metrics.downloads.WithLabelValues(getOrigin(url), fmt.Sprint(resp.StatusCode)).Inc()
	if resp.StatusCode != 200 {
		return nil, fmt.Errorf("unexpected status %v", resp.StatusCode)
	}
	body, err := io.ReadAll(resp.Body)
	if err != nil {
		return nil, err
	}
	return body, nil
}

func (store *RealSourceMapStore) downloadSourceMapContent(sourceURL string) (content []byte, resolvedSourceMapURL string, err error) {
	level.Debug(store.l).Log("msg", "attempting to download source file", "url", sourceURL)

	result, err := store.downloadFileContents(sourceURL)
	if err != nil {
		level.Debug(store.l).Log("msg", "failed to download source file", "url", sourceURL, "err", err)
		return nil, "", err
	}
	r := regexp.MustCompile(reSourceMap)
	match := r.FindAllStringSubmatch(string(result), -1)
	if len(match) == 0 {
		level.Debug(store.l).Log("msg", "no sourcemap url found in source", "url", sourceURL)
		return nil, "", nil
	}
	sourceMapURL := match[len(match)-1][2]

	// inline sourcemap
	if strings.HasPrefix(sourceMapURL, "data:") {
		dataURL, err := dataurl.DecodeString(sourceMapURL)
		if err != nil {
			level.Debug(store.l).Log("msg", "failed to parse inline sourcemap data url", "url", sourceURL, "err", err)
			return nil, "", err
		}

		level.Info(store.l).Log("msg", "successfully parsed inline sourcemap data url", "url", sourceURL)
		return dataURL.Data, sourceURL + ".map", nil
	}
	// remote sourcemap
	resolvedSourceMapURL = sourceMapURL

	// if url is relative, attempt to resolve absolute
	if !strings.HasPrefix(resolvedSourceMapURL, "http") {
		base, err := url.Parse(sourceURL)
		if err != nil {
			level.Debug(store.l).Log("msg", "failed to parse source url", "url", sourceURL, "err", err)
			return nil, "", err
		}
		relative, err := url.Parse(sourceMapURL)
		if err != nil {
			level.Debug(store.l).Log("msg", "failed to parse source map url", "url", sourceURL, "sourceMapURL", sourceMapURL, "err", err)
			return nil, "", err
		}
		resolvedSourceMapURL = base.ResolveReference(relative).String()
		level.Debug(store.l).Log("msg", "resolved absolute soure map url", "url", sourceURL, "sourceMapURL", resolvedSourceMapURL)
	}
	level.Debug(store.l).Log("msg", "attempting to download sourcemap file", "url", resolvedSourceMapURL)
	result, err = store.downloadFileContents(resolvedSourceMapURL)
	if err != nil {
		level.Debug(store.l).Log("failed to download source map file", "url", resolvedSourceMapURL, "err", err)
		return nil, "", err
	}
	return result, resolvedSourceMapURL, nil
}

func (store *RealSourceMapStore) getSourceMapFromFileSystem(sourceURL string, release string, fileconf *sourcemapFileLocation) (content []byte, sourceMapURL string, err error) {
	if len(sourceURL) == 0 || !strings.HasPrefix(sourceURL, fileconf.MinifiedPathPrefix) || strings.HasSuffix(sourceURL, "/") {
		return nil, "", nil
	}

	var rootPath bytes.Buffer

	err = fileconf.pathTemplate.Execute(&rootPath, struct{ Release string }{Release: cleanFilePathPart(release)})
	if err != nil {
		return nil, "", err
	}

	pathParts := []string{rootPath.String()}
	for _, part := range strings.Split(strings.TrimPrefix(strings.Split(sourceURL, "?")[0], fileconf.MinifiedPathPrefix), "/") {
		if len(part) > 0 && part != "." && part != ".." {
			pathParts = append(pathParts, part)
		}
	}
	mapFilePath := filepath.Join(pathParts...) + ".map"

	if _, err := store.fileService.Stat(mapFilePath); err != nil {
		store.metrics.fileReads.WithLabelValues(getOrigin(sourceURL), "not_found").Inc()
		level.Debug(store.l).Log("msg", "sourcemap not found on filesystem", "url", sourceURL, "file_path", mapFilePath)
		return nil, "", nil
	}
	level.Debug(store.l).Log("msg", "sourcemap found on filesystem", "url", mapFilePath, "file_path", mapFilePath)

	content, err = store.fileService.ReadFile(mapFilePath)
	if err != nil {
		store.metrics.fileReads.WithLabelValues(getOrigin(sourceURL), "error").Inc()
	} else {
		store.metrics.fileReads.WithLabelValues(getOrigin(sourceURL), "ok").Inc()
	}
	return content, sourceURL, err
}

func (store *RealSourceMapStore) getSourceMapContent(sourceURL string, release string) (content []byte, sourceMapURL string, err error) {
	//attempt to find in fs
	for _, fileconf := range store.fileLocations {
		content, sourceMapURL, err = store.getSourceMapFromFileSystem(sourceURL, release, fileconf)
		if content != nil || err != nil {
			return content, sourceMapURL, err
		}
	}

	//attempt to download
	if strings.HasPrefix(sourceURL, "http") && urlMatchesOrigins(sourceURL, store.config.DownloadFromOrigins) {
		return store.downloadSourceMapContent(sourceURL)
	}
	return nil, "", nil
}

// GetSourceMap returns sourcemap for a given source url
func (store *RealSourceMapStore) GetSourceMap(sourceURL string, release string) (*SourceMap, error) {
	store.Lock()
	defer store.Unlock()

	cacheKey := fmt.Sprintf("%s__%s", sourceURL, release)

	if smap, ok := store.cache[cacheKey]; ok {
		return smap, nil
	}
	content, sourceMapURL, err := store.getSourceMapContent(sourceURL, release)
	if err != nil || content == nil {
		store.cache[cacheKey] = nil
		return nil, err
	}
	if content != nil {
		consumer, err := sourcemap.Parse(sourceMapURL, content)
		if err != nil {
			store.cache[cacheKey] = nil
			level.Debug(store.l).Log("msg", "failed to parse sourcemap", "url", sourceMapURL, "release", release, "err", err)
			return nil, err
		}
		level.Info(store.l).Log("msg", "successfully parsed sourcemap", "url", sourceMapURL, "release", release)
		smap := &SourceMap{
			consumer: consumer,
		}
		store.cache[cacheKey] = smap
		store.metrics.cacheSize.WithLabelValues(getOrigin(sourceURL)).Inc()
		return smap, nil
	}
	return nil, nil
}

// ResolveSourceLocation resolves minified source location to original source location
func ResolveSourceLocation(store SourceMapStore, frame *Frame, release string) (*Frame, error) {
	smap, err := store.GetSourceMap(frame.Filename, release)
	if err != nil {
		return nil, err
	}
	if smap == nil {
		return nil, nil
	}

	file, function, line, col, ok := smap.consumer.Source(frame.Lineno, frame.Colno)
	if !ok {
		return nil, nil
	}
	// unfortunately in many cases go-sourcemap fails to determine the original function name.
	// not a big issue as long as file, line and column are correct
	if len(function) == 0 {
		function = "?"
	}
	return &Frame{
		Filename: file,
		Lineno:   line,
		Colno:    col,
		Function: function,
	}, nil
}

// TransformException will attempt to resolved all monified source locations in the stacktrace with original source locations
func TransformException(store SourceMapStore, log log.Logger, ex *Exception, release string) *Exception {
	if ex.Stacktrace == nil {
		return ex
	}
	frames := []Frame{}

	for _, frame := range ex.Stacktrace.Frames {
		mappedFrame, err := ResolveSourceLocation(store, &frame, release)
		if err != nil {
			level.Error(log).Log("msg", "Error resolving stack trace frame source location", "err", err)
			frames = append(frames, frame)
		} else if mappedFrame != nil {
			frames = append(frames, *mappedFrame)
		} else {
			frames = append(frames, frame)
		}
	}

	return &Exception{
		Type:       ex.Type,
		Value:      ex.Value,
		Stacktrace: &Stacktrace{Frames: frames},
		Timestamp:  ex.Timestamp,
	}
}

func cleanFilePathPart(x string) string {
	return strings.TrimLeft(strings.ReplaceAll(strings.ReplaceAll(x, "\\", ""), "/", ""), ".")
}

func getOrigin(URL string) string {
	parsed, err := url.Parse(URL)
	if err != nil {
		return "?"
	}
	return fmt.Sprintf("%s://%s", parsed.Scheme, parsed.Host)
}

'''
'''--- pkg/integrations/v2/app_agent_receiver/sourcemaps_test.go ---
package app_agent_receiver

import (
	"bytes"
	"errors"
	"io"
	"io/fs"
	"io/ioutil"
	"net/http"
	"path/filepath"
	"testing"

	"github.com/go-kit/log"
	"github.com/prometheus/client_golang/prometheus"
	"github.com/stretchr/testify/require"
)

type mockHTTPClient struct {
	responses []struct {
		*http.Response
		error
	}
	requests []string
}

func (cl *mockHTTPClient) Get(url string) (resp *http.Response, err error) {
	if len(cl.responses) > len(cl.requests) {
		r := cl.responses[len(cl.requests)]
		cl.requests = append(cl.requests, url)
		return r.Response, r.error
	}
	return nil, errors.New("mockHTTPClient got more requests than expected")
}

type mockFileService struct {
	files map[string][]byte
	stats []string
	reads []string
}

func (s *mockFileService) Stat(name string) (fs.FileInfo, error) {
	s.stats = append(s.stats, name)
	_, ok := s.files[name]
	if !ok {
		return nil, errors.New("file not found")
	}
	return nil, nil
}

func (s *mockFileService) ReadFile(name string) ([]byte, error) {
	s.reads = append(s.reads, name)
	content, ok := s.files[name]
	if ok {
		return content, nil
	}
	return nil, errors.New("file not found")
}

func newResponseFromTestData(t *testing.T, file string) *http.Response {
	return &http.Response{
		Body:       io.NopCloser(bytes.NewReader(loadTestData(t, file))),
		StatusCode: 200,
	}
}

func mockException() *Exception {
	return &Exception{
		Stacktrace: &Stacktrace{
			Frames: []Frame{
				{
					Colno:    6,
					Filename: "http://localhost:1234/foo.js",
					Function: "eval",
					Lineno:   5,
				},
				{
					Colno:    5,
					Filename: "http://localhost:1234/foo.js",
					Function: "callUndefined",
					Lineno:   6,
				},
			},
		},
	}
}

func Test_RealSourceMapStore_DownloadSuccess(t *testing.T) {
	conf := SourceMapConfig{
		Download:            true,
		DownloadFromOrigins: []string{"*"},
	}

	httpClient := &mockHTTPClient{
		responses: []struct {
			*http.Response
			error
		}{
			{newResponseFromTestData(t, "foo.js"), nil},
			{newResponseFromTestData(t, "foo.js.map"), nil},
		},
	}

	logger := log.NewNopLogger()

	sourceMapStore := NewSourceMapStore(logger, conf, prometheus.NewRegistry(), httpClient, &mockFileService{})

	exception := mockException()

	transformed := TransformException(sourceMapStore, logger, exception, "123")

	require.Equal(t, []string{"http://localhost:1234/foo.js", "http://localhost:1234/foo.js.map"}, httpClient.requests)

	expected := &Exception{
		Stacktrace: &Stacktrace{
			Frames: []Frame{
				{
					Colno:    37,
					Filename: "/__parcel_source_root/demo/src/actions.ts",
					Function: "?",
					Lineno:   6,
				},
				{
					Colno:    2,
					Filename: "/__parcel_source_root/demo/src/actions.ts",
					Function: "?",
					Lineno:   7,
				},
			},
		},
	}

	require.Equal(t, *expected, *transformed)
}

func Test_RealSourceMapStore_DownloadError(t *testing.T) {
	conf := SourceMapConfig{
		Download:            true,
		DownloadFromOrigins: []string{"*"},
	}

	resp := &http.Response{
		StatusCode: 500,
		Body:       ioutil.NopCloser(bytes.NewReader([]byte{})),
	}

	httpClient := &mockHTTPClient{
		responses: []struct {
			*http.Response
			error
		}{
			{resp, nil},
		},
	}

	logger := log.NewNopLogger()

	sourceMapStore := NewSourceMapStore(logger, conf, prometheus.NewRegistry(), httpClient, &mockFileService{})

	exception := mockException()

	transformed := TransformException(sourceMapStore, logger, exception, "123")

	require.Equal(t, []string{"http://localhost:1234/foo.js"}, httpClient.requests)
	require.Equal(t, exception, transformed)
}

func Test_RealSourceMapStore_DownloadHTTPOriginFiltering(t *testing.T) {
	conf := SourceMapConfig{
		Download:            true,
		DownloadFromOrigins: []string{"http://bar.com/"},
	}

	httpClient := &mockHTTPClient{
		responses: []struct {
			*http.Response
			error
		}{
			{newResponseFromTestData(t, "foo.js"), nil},
			{newResponseFromTestData(t, "foo.js.map"), nil},
		},
	}

	logger := log.NewNopLogger()

	sourceMapStore := NewSourceMapStore(logger, conf, prometheus.NewRegistry(), httpClient, &mockFileService{})

	exception := &Exception{
		Stacktrace: &Stacktrace{
			Frames: []Frame{
				{
					Colno:    6,
					Filename: "http://foo.com/foo.js",
					Function: "eval",
					Lineno:   5,
				},
				{
					Colno:    5,
					Filename: "http://bar.com/foo.js",
					Function: "callUndefined",
					Lineno:   6,
				},
			},
		},
	}

	transformed := TransformException(sourceMapStore, logger, exception, "123")

	require.Equal(t, []string{"http://bar.com/foo.js", "http://bar.com/foo.js.map"}, httpClient.requests)

	expected := &Exception{
		Stacktrace: &Stacktrace{
			Frames: []Frame{
				{
					Colno:    6,
					Filename: "http://foo.com/foo.js",
					Function: "eval",
					Lineno:   5,
				},
				{
					Colno:    2,
					Filename: "/__parcel_source_root/demo/src/actions.ts",
					Function: "?",
					Lineno:   7,
				},
			},
		},
	}

	require.Equal(t, *expected, *transformed)
}

func Test_RealSourceMapStore_ReadFromFileSystem(t *testing.T) {
	conf := SourceMapConfig{
		Download: false,
		FileSystem: []SourceMapFileLocation{
			{
				MinifiedPathPrefix: "http://foo.com/",
				Path:               filepath.FromSlash("/var/build/latest/"),
			},
			{
				MinifiedPathPrefix: "http://bar.com/",
				Path:               filepath.FromSlash("/var/build/{{ .Release }}/"),
			},
		},
	}

	mapFile := loadTestData(t, "foo.js.map")

	fileService := &mockFileService{
		files: map[string][]byte{
			filepath.FromSlash("/var/build/latest/foo.js.map"): mapFile,
			filepath.FromSlash("/var/build/123/foo.js.map"):    mapFile,
		},
	}

	logger := log.NewNopLogger()

	sourceMapStore := NewSourceMapStore(logger, conf, prometheus.NewRegistry(), &mockHTTPClient{}, fileService)

	exception := &Exception{
		Stacktrace: &Stacktrace{
			Frames: []Frame{
				{
					Colno:    6,
					Filename: "http://foo.com/foo.js",
					Function: "eval",
					Lineno:   5,
				},
				{
					Colno:    6,
					Filename: "http://foo.com/bar.js",
					Function: "eval",
					Lineno:   5,
				},
				{
					Colno:    5,
					Filename: "http://bar.com/foo.js",
					Function: "callUndefined",
					Lineno:   6,
				},
				{
					Colno:    5,
					Filename: "http://baz.com/foo.js",
					Function: "callUndefined",
					Lineno:   6,
				},
			},
		},
	}

	transformed := TransformException(sourceMapStore, logger, exception, "123")

	require.Equal(t, []string{
		filepath.FromSlash("/var/build/latest/foo.js.map"),
		filepath.FromSlash("/var/build/latest/bar.js.map"),
		filepath.FromSlash("/var/build/123/foo.js.map"),
	}, fileService.stats)
	require.Equal(t, []string{
		filepath.FromSlash("/var/build/latest/foo.js.map"),
		filepath.FromSlash("/var/build/123/foo.js.map"),
	}, fileService.reads)

	expected := &Exception{
		Stacktrace: &Stacktrace{
			Frames: []Frame{
				{
					Colno:    37,
					Filename: "/__parcel_source_root/demo/src/actions.ts",
					Function: "?",
					Lineno:   6,
				},
				{
					Colno:    6,
					Filename: "http://foo.com/bar.js",
					Function: "eval",
					Lineno:   5,
				},
				{
					Colno:    2,
					Filename: "/__parcel_source_root/demo/src/actions.ts",
					Function: "?",
					Lineno:   7,
				},
				{
					Colno:    5,
					Filename: "http://baz.com/foo.js",
					Function: "callUndefined",
					Lineno:   6,
				},
			},
		},
	}

	require.Equal(t, *expected, *transformed)
}

func Test_RealSourceMapStore_ReadFromFileSystemAndDownload(t *testing.T) {
	conf := SourceMapConfig{
		Download:            true,
		DownloadFromOrigins: []string{"*"},
		FileSystem: []SourceMapFileLocation{
			{
				MinifiedPathPrefix: "http://foo.com/",
				Path:               filepath.FromSlash("/var/build/latest/"),
			},
		},
	}

	mapFile := loadTestData(t, "foo.js.map")

	fileService := &mockFileService{
		files: map[string][]byte{
			filepath.FromSlash("/var/build/latest/foo.js.map"): mapFile,
		},
	}

	httpClient := &mockHTTPClient{
		responses: []struct {
			*http.Response
			error
		}{
			{newResponseFromTestData(t, "foo.js"), nil},
			{newResponseFromTestData(t, "foo.js.map"), nil},
		},
	}

	logger := log.NewNopLogger()

	sourceMapStore := NewSourceMapStore(logger, conf, prometheus.NewRegistry(), httpClient, fileService)

	exception := &Exception{
		Stacktrace: &Stacktrace{
			Frames: []Frame{
				{
					Colno:    6,
					Filename: "http://foo.com/foo.js",
					Function: "eval",
					Lineno:   5,
				},
				{
					Colno:    5,
					Filename: "http://bar.com/foo.js",
					Function: "callUndefined",
					Lineno:   6,
				},
			},
		},
	}

	transformed := TransformException(sourceMapStore, logger, exception, "123")

	require.Equal(t, []string{filepath.FromSlash("/var/build/latest/foo.js.map")}, fileService.stats)
	require.Equal(t, []string{filepath.FromSlash("/var/build/latest/foo.js.map")}, fileService.reads)
	require.Equal(t, []string{"http://bar.com/foo.js", "http://bar.com/foo.js.map"}, httpClient.requests)

	expected := &Exception{
		Stacktrace: &Stacktrace{
			Frames: []Frame{
				{
					Colno:    37,
					Filename: "/__parcel_source_root/demo/src/actions.ts",
					Function: "?",
					Lineno:   6,
				},
				{
					Colno:    2,
					Filename: "/__parcel_source_root/demo/src/actions.ts",
					Function: "?",
					Lineno:   7,
				},
			},
		},
	}

	require.Equal(t, *expected, *transformed)
}

func Test_RealSourceMapStore_FilepathSanitized(t *testing.T) {
	conf := SourceMapConfig{
		Download: false,
		FileSystem: []SourceMapFileLocation{
			{
				MinifiedPathPrefix: "http://foo.com/",
				Path:               filepath.FromSlash("/var/build/latest/"),
			},
		},
	}

	fileService := &mockFileService{}

	logger := log.NewNopLogger()

	sourceMapStore := NewSourceMapStore(logger, conf, prometheus.NewRegistry(), &mockHTTPClient{}, fileService)

	exception := &Exception{
		Stacktrace: &Stacktrace{
			Frames: []Frame{
				{
					Colno:    6,
					Filename: "http://foo.com/../../../etc/passwd",
					Function: "eval",
					Lineno:   5,
				},
			},
		},
	}

	transformed := TransformException(sourceMapStore, logger, exception, "123")

	require.Equal(t, []string{
		filepath.FromSlash("/var/build/latest/etc/passwd.map"),
	}, fileService.stats)
	require.Len(t, fileService.reads, 0)

	require.Equal(t, *exception, *transformed)
}

func Test_RealSourceMapStore_FilepathQueryParamsOmitted(t *testing.T) {
	conf := SourceMapConfig{
		Download: false,
		FileSystem: []SourceMapFileLocation{
			{
				MinifiedPathPrefix: "http://foo.com/",
				Path:               filepath.FromSlash("/var/build/latest/"),
			},
		},
	}

	fileService := &mockFileService{}

	logger := log.NewNopLogger()

	sourceMapStore := NewSourceMapStore(logger, conf, prometheus.NewRegistry(), &mockHTTPClient{}, fileService)

	exception := &Exception{
		Stacktrace: &Stacktrace{
			Frames: []Frame{
				{
					Colno:    6,
					Filename: "http://foo.com/static/foo.js?v=1233",
					Function: "eval",
					Lineno:   5,
				},
			},
		},
	}

	transformed := TransformException(sourceMapStore, logger, exception, "123")

	require.Equal(t, []string{
		filepath.FromSlash("/var/build/latest/static/foo.js.map"),
	}, fileService.stats)
	require.Len(t, fileService.reads, 0)

	require.Equal(t, *exception, *transformed)
}

'''
'''--- pkg/integrations/v2/app_agent_receiver/testdata/foo.js ---
function throwError() {
  throw new Error('This is a thrown error');
}
function callUndefined() {
  // eslint-disable-next-line no-eval
  eval('test();');
}
function callConsole(method) {
  // eslint-disable-next-line no-console
  console[method](`This is a console ${method} message`);
}
function fetchError() {
  fetch('http://localhost:12345', {
      method: 'POST'
  });
}
function promiseReject() {
  new Promise((_accept, reject)=>{
      reject('This is a rejected promise');
  });
}
function fetchSuccess() {
  fetch('http://localhost:1234');
}
function sendCustomMetric() {
  window.grafanaJavaScriptAgent.api.pushMeasurement({
      type: 'custom',
      values: {
          my_custom_metric: Math.random()
      }
  });
}
window.addEventListener('load', ()=>{
  window.grafanaJavaScriptAgent.api.pushLog([
      'Manual event from Home'
  ]);
});

//# sourceMappingURL=foo.js.map

'''
'''--- pkg/integrations/v2/app_agent_receiver/testdata/payload.json ---
{
  "logs": [
      {
          "message": "opened pricing page",
          "level": "info",
          "context": {
              "component": "AppRoot",
              "page": "Pricing"
          },
          "timestamp": "2021-09-30T10:46:17.680Z",
          "trace": {
              "trace_id": "abcd",
              "span_id": "def"
          }
      },
      {
          "message": "loading price list",
          "level": "trace",
          "context": {
              "component": "AppRoot",
              "page": "Pricing"
          },
          "timestamp": "2021-09-30T10:46:17.680Z",
          "trace": {
              "trace_id": "abcd",
              "span_id": "ghj"
          }
      }
  ],
  "exceptions": [
      {
          "type": "Error",
          "value": "Cannot read property 'find' of undefined",
          "stacktrace": {
              "frames": [
                  {
                      "colno": 42,
                      "filename": "http://fe:3002/static/js/vendors~main.chunk.js",
                      "function": "?",
                      "in_app": true,
                      "lineno": 8639
                  },
                  {
                      "colno": 9,
                      "filename": "http://fe:3002/static/js/vendors~main.chunk.js",
                      "function": "dispatchAction",
                      "in_app": true,
                      "lineno": 268095
                  },
                  {
                      "colno": 13,
                      "filename": "http://fe:3002/static/js/vendors~main.chunk.js",
                      "function": "scheduleUpdateOnFiber",
                      "in_app": true,
                      "lineno": 273726
                  },
                  {
                      "colno": 7,
                      "filename": "http://fe:3002/static/js/vendors~main.chunk.js",
                      "function": "flushSyncCallbackQueue",
                      "in_app": true,
                      "lineno": 263362
                  },
                  {
                      "colno": 13,
                      "filename": "http://fe:3002/static/js/vendors~main.chunk.js",
                      "function": "flushSyncCallbackQueueImpl",
                      "in_app": true,
                      "lineno": 263374
                  },
                  {
                      "colno": 14,
                      "filename": "http://fe:3002/static/js/vendors~main.chunk.js",
                      "function": "runWithPriority$1",
                      "lineno": 263325
                  },
                  {
                      "colno": 16,
                      "filename": "http://fe:3002/static/js/vendors~main.chunk.js",
                      "function": "unstable_runWithPriority",
                      "lineno": 291265
                  },
                  {
                      "colno": 30,
                      "filename": "http://fe:3002/static/js/vendors~main.chunk.js",
                      "function": "?",
                      "lineno": 263379
                  },
                  {
                      "colno": 22,
                      "filename": "http://fe:3002/static/js/vendors~main.chunk.js",
                      "function": "performSyncWorkOnRoot",
                      "lineno": 274126
                  },
                  {
                      "colno": 11,
                      "filename": "http://fe:3002/static/js/vendors~main.chunk.js",
                      "function": "renderRootSync",
                      "lineno": 274509
                  },
                  {
                      "colno": 9,
                      "filename": "http://fe:3002/static/js/vendors~main.chunk.js",
                      "function": "workLoopSync",
                      "lineno": 274543
                  },
                  {
                      "colno": 16,
                      "filename": "http://fe:3002/static/js/vendors~main.chunk.js",
                      "function": "performUnitOfWork",
                      "lineno": 274606
                  },
                  {
                      "colno": 18,
                      "filename": "http://fe:3002/static/js/vendors~main.chunk.js",
                      "function": "beginWork$1",
                      "in_app": true,
                      "lineno": 275746
                  },
                  {
                      "colno": 20,
                      "filename": "http://fe:3002/static/js/vendors~main.chunk.js",
                      "function": "beginWork",
                      "lineno": 270944
                  },
                  {
                      "colno": 24,
                      "filename": "http://fe:3002/static/js/vendors~main.chunk.js",
                      "function": "updateFunctionComponent",
                      "lineno": 269291
                  },
                  {
                      "colno": 22,
                      "filename": "http://fe:3002/static/js/vendors~main.chunk.js",
                      "function": "renderWithHooks",
                      "lineno": 266969
                  },
                  {
                      "colno": 74,
                      "filename": "http://fe:3002/static/js/main.chunk.js",
                      "function": "?",
                      "in_app": true,
                      "lineno": 2600
                  },
                  {
                      "colno": 65,
                      "filename": "http://fe:3002/static/js/main.chunk.js",
                      "function": "useGetBooksQuery",
                      "lineno": 1299
                  },
                  {
                      "colno": 85,
                      "filename": "http://fe:3002/static/js/vendors~main.chunk.js",
                      "function": "Module.useQuery",
                      "lineno": 8495
                  },
                  {
                      "colno": 83,
                      "filename": "http://fe:3002/static/js/vendors~main.chunk.js",
                      "function": "useBaseQuery",
                      "in_app": true,
                      "lineno": 8656
                  },
                  {
                      "colno": 14,
                      "filename": "http://fe:3002/static/js/vendors~main.chunk.js",
                      "function": "useDeepMemo",
                      "lineno": 8696
                  },
                  {
                      "colno": 55,
                      "filename": "http://fe:3002/static/js/vendors~main.chunk.js",
                      "function": "?",
                      "lineno": 8657
                  },
                  {
                      "colno": 47,
                      "filename": "http://fe:3002/static/js/vendors~main.chunk.js",
                      "function": "QueryData.execute",
                      "in_app": true,
                      "lineno": 7883
                  },
                  {
                      "colno": 23,
                      "filename": "http://fe:3002/static/js/vendors~main.chunk.js",
                      "function": "QueryData.getExecuteResult",
                      "lineno": 7944
                  },
                  {
                      "colno": 19,
                      "filename": "http://fe:3002/static/js/vendors~main.chunk.js",
                      "function": "QueryData._this.getQueryResult",
                      "lineno": 7790
                  },
                  {
                      "colno": 24,
                      "filename": "http://fe:3002/static/js/vendors~main.chunk.js",
                      "function": "new ApolloError",
                      "in_app": true,
                      "lineno": 5164
                  }
              ]
          },
          "timestamp": "2021-09-30T10:46:17.680Z",
          "trace": {
              "trace_id": "abcd",
              "span_id": "def"
          }
      }
  ],
  "measurements": [
      {
          "values": {
              "ttfp": 20.12,
              "ttfcp": 22.12,
              "ttfb": 14
          },
          "type": "page load",
          "timestamp": "2021-09-30T10:46:17.680Z",
          "trace": {
              "trace_id": "abcd",
              "span_id": "def"
          }
      }
  ],
  "meta": {
      "sdk": {
          "name": "grafana-frontend-agent",
          "version": "1.0.0"
      },
      "app": {
          "name": "testapp",
          "release": "0.8.2",
          "version": "abcdefg",
          "environment": "production"
      },
      "user": {
          "username": "domasx2",
          "id": "123",
          "email": "geralt@kaermorhen.org",
          "attributes": {
              "foo": "bar"
          }
      },
      "session": {
          "id": "abcd",
          "attributes": {
              "time_elapsed": "100s"
          }
      },
      "page": {
          "url": "https://example.com/page"
      },
      "browser": {
          "name": "chrome",
          "version": "88.12.1",
          "os": "linux",
          "mobile": false
      }
  },
  "traces": {
    "resourceSpans": [
        {
            "resource": {
                "attributes": [
                    {
                        "key": "host.name",
                        "value": {
                            "stringValue": "testHost"
                        }
                    }
                ]
            },
            "instrumentationLibrarySpans": [
                {
                    "instrumentationLibrary": {
                        "name": "name",
                        "version": "version"
                    },
                    "spans": [
                        {
                            "traceId": "",
                            "spanId": "",
                            "parentSpanId": "",
                            "name": "testSpan",
                            "status": {}
                        },
                        {
                            "traceId": "",
                            "spanId": "",
                            "parentSpanId": "",
                            "name": "testSpan2",
                            "status": {}
                        }
                    ]
                }
            ]
        }
    ]
  }
}
'''
'''--- pkg/integrations/v2/app_agent_receiver/testdata/payload_2.json ---
{
  "logs": [
      {
          "message": "opened pricing page",
          "level": "info",
          "context": {
              "component": "AppRoot",
              "page": "Pricing"
          },
          "timestamp": "2021-09-30T10:46:17.680Z",
          "trace": {
              "trace_id": "abcd",
              "span_id": "def"
          }
      },
      {
          "message": "loading price list",
          "level": "trace",
          "context": {
              "component": "AppRoot",
              "page": "Pricing"
          },
          "timestamp": "2021-09-30T10:46:17.680Z",
          "trace": {
              "trace_id": "abcd",
              "span_id": "ghj"
          }
      }
  ],
  "exceptions": [
      {
          "type": "Error",
          "value": "Cannot read property 'find' of undefined",
          "stacktrace": {
              "frames": [
                  {
                      "colno": 42,
                      "filename": "http://fe:3002/static/js/vendors~main.chunk.js",
                      "function": "?",
                      "in_app": true,
                      "lineno": 8639
                  },
                  {
                      "colno": 9,
                      "filename": "http://fe:3002/static/js/vendors~main.chunk.js",
                      "function": "dispatchAction",
                      "in_app": true,
                      "lineno": 268095
                  },
                  {
                      "colno": 13,
                      "filename": "http://fe:3002/static/js/vendors~main.chunk.js",
                      "function": "scheduleUpdateOnFiber",
                      "in_app": true,
                      "lineno": 273726
                  },
                  {
                      "colno": 7,
                      "filename": "http://fe:3002/static/js/vendors~main.chunk.js",
                      "function": "flushSyncCallbackQueue",
                      "in_app": true,
                      "lineno": 263362
                  },
                  {
                      "colno": 13,
                      "filename": "http://fe:3002/static/js/vendors~main.chunk.js",
                      "function": "flushSyncCallbackQueueImpl",
                      "in_app": true,
                      "lineno": 263374
                  },
                  {
                      "colno": 14,
                      "filename": "http://fe:3002/static/js/vendors~main.chunk.js",
                      "function": "runWithPriority$1",
                      "lineno": 263325
                  },
                  {
                      "colno": 16,
                      "filename": "http://fe:3002/static/js/vendors~main.chunk.js",
                      "function": "unstable_runWithPriority",
                      "lineno": 291265
                  },
                  {
                      "colno": 30,
                      "filename": "http://fe:3002/static/js/vendors~main.chunk.js",
                      "function": "?",
                      "lineno": 263379
                  },
                  {
                      "colno": 22,
                      "filename": "http://fe:3002/static/js/vendors~main.chunk.js",
                      "function": "performSyncWorkOnRoot",
                      "lineno": 274126
                  },
                  {
                      "colno": 11,
                      "filename": "http://fe:3002/static/js/vendors~main.chunk.js",
                      "function": "renderRootSync",
                      "lineno": 274509
                  },
                  {
                      "colno": 9,
                      "filename": "http://fe:3002/static/js/vendors~main.chunk.js",
                      "function": "workLoopSync",
                      "lineno": 274543
                  },
                  {
                      "colno": 16,
                      "filename": "http://fe:3002/static/js/vendors~main.chunk.js",
                      "function": "performUnitOfWork",
                      "lineno": 274606
                  },
                  {
                      "colno": 18,
                      "filename": "http://fe:3002/static/js/vendors~main.chunk.js",
                      "function": "beginWork$1",
                      "in_app": true,
                      "lineno": 275746
                  },
                  {
                      "colno": 20,
                      "filename": "http://fe:3002/static/js/vendors~main.chunk.js",
                      "function": "beginWork",
                      "lineno": 270944
                  },
                  {
                      "colno": 24,
                      "filename": "http://fe:3002/static/js/vendors~main.chunk.js",
                      "function": "updateFunctionComponent",
                      "lineno": 269291
                  },
                  {
                      "colno": 22,
                      "filename": "http://fe:3002/static/js/vendors~main.chunk.js",
                      "function": "renderWithHooks",
                      "lineno": 266969
                  },
                  {
                      "colno": 74,
                      "filename": "http://fe:3002/static/js/main.chunk.js",
                      "function": "?",
                      "in_app": true,
                      "lineno": 2600
                  },
                  {
                      "colno": 65,
                      "filename": "http://fe:3002/static/js/main.chunk.js",
                      "function": "useGetBooksQuery",
                      "lineno": 1299
                  },
                  {
                      "colno": 85,
                      "filename": "http://fe:3002/static/js/vendors~main.chunk.js",
                      "function": "Module.useQuery",
                      "lineno": 8495
                  },
                  {
                      "colno": 83,
                      "filename": "http://fe:3002/static/js/vendors~main.chunk.js",
                      "function": "useBaseQuery",
                      "in_app": true,
                      "lineno": 8656
                  },
                  {
                      "colno": 14,
                      "filename": "http://fe:3002/static/js/vendors~main.chunk.js",
                      "function": "useDeepMemo",
                      "lineno": 8696
                  },
                  {
                      "colno": 55,
                      "filename": "http://fe:3002/static/js/vendors~main.chunk.js",
                      "function": "?",
                      "lineno": 8657
                  },
                  {
                      "colno": 47,
                      "filename": "http://fe:3002/static/js/vendors~main.chunk.js",
                      "function": "QueryData.execute",
                      "in_app": true,
                      "lineno": 7883
                  },
                  {
                      "colno": 23,
                      "filename": "http://fe:3002/static/js/vendors~main.chunk.js",
                      "function": "QueryData.getExecuteResult",
                      "lineno": 7944
                  },
                  {
                      "colno": 19,
                      "filename": "http://fe:3002/static/js/vendors~main.chunk.js",
                      "function": "QueryData._this.getQueryResult",
                      "lineno": 7790
                  },
                  {
                      "colno": 24,
                      "filename": "http://fe:3002/static/js/vendors~main.chunk.js",
                      "function": "new ApolloError",
                      "in_app": true,
                      "lineno": 5164
                  }
              ]
          },
          "timestamp": "2021-09-30T10:46:17.680Z",
          "trace": {
              "trace_id": "abcd",
              "span_id": "def"
          }
      }
  ],
  "measurements": [
      {
          "values": {
              "ttfp": 20.12,
              "ttfcp": 22.12,
              "ttfb": 14
          },
          "type": "page load",
          "timestamp": "2021-09-30T10:46:17.680Z",
          "trace": {
              "trace_id": "abcd",
              "span_id": "def"
          }
      }
  ],
  "meta": {
      "sdk": {
          "name": "grafana-frontend-agent",
          "version": "1.0.0"
      },
      "app": {
          "name": "testapp",
          "release": "0.8.2",
          "version": "abcdefg",
          "environment": "production"
      },
      "user": {
          "username": "domasx2",
          "attributes": {
              "foo": "bar"
          }
      },
      "session": {
          "id": "abcd",
          "attributes": {
              "time_elapsed": "100s"
          }
      },
      "page": {
          "url": "https://example.com/page"
      },
      "browser": {
          "name": "chrome",
          "version": "88.12.1",
          "os": "linux",
          "mobile": false
      }
  },
  "traces": {
    "resourceSpans": [
      {
        "resource": {
          "attributes": [
            {
              "key": "service.name",
              "value": {
                "stringValue": "unknown_service"
              }
            },
            {
              "key": "telemetry.sdk.language",
              "value": {
                "stringValue": "webjs"
              }
            },
            {
              "key": "telemetry.sdk.name",
              "value": {
                "stringValue": "opentelemetry"
              }
            },
            {
              "key": "telemetry.sdk.version",
              "value": {
                "stringValue": "1.0.1"
              }
            }
          ],
          "droppedAttributesCount": 0
        },
        "instrumentationLibrarySpans": [
          {
            "spans": [
              {
                "traceId": "2d6f18da2663c7e477df23d8a8ad95b7",
                "spanId": "50e64e3fac969cbb",
                "parentSpanId": "9d9da6529d56706c",
                "name": "documentFetch",
                "kind": 1,
                "startTimeUnixNano": 1646228314336100000,
                "endTimeUnixNano": 1646228314351000000,
                "attributes": [
                  {
                    "key": "component",
                    "value": {
                      "stringValue": "document-load"
                    }
                  },
                  {
                    "key": "http.response_content_length",
                    "value": {
                      "intValue": 1326
                    }
                  }
                ],
                "droppedAttributesCount": 0,
                "events": [
                  {
                    "timeUnixNano": 1646228314336100000,
                    "name": "fetchStart",
                    "attributes": [],
                    "droppedAttributesCount": 0
                  },
                  {
                    "timeUnixNano": 1646228314342000000,
                    "name": "domainLookupStart",
                    "attributes": [],
                    "droppedAttributesCount": 0
                  },
                  {
                    "timeUnixNano": 1646228314342000000,
                    "name": "domainLookupEnd",
                    "attributes": [],
                    "droppedAttributesCount": 0
                  },
                  {
                    "timeUnixNano": 1646228314342000000,
                    "name": "connectStart",
                    "attributes": [],
                    "droppedAttributesCount": 0
                  },
                  {
                    "timeUnixNano": 1646228314330100000,
                    "name": "secureConnectionStart",
                    "attributes": [],
                    "droppedAttributesCount": 0
                  },
                  {
                    "timeUnixNano": 1646228314342500000,
                    "name": "connectEnd",
                    "attributes": [],
                    "droppedAttributesCount": 0
                  },
                  {
                    "timeUnixNano": 1646228314342700000,
                    "name": "requestStart",
                    "attributes": [],
                    "droppedAttributesCount": 0
                  },
                  {
                    "timeUnixNano": 1646228314347000000,
                    "name": "responseStart",
                    "attributes": [],
                    "droppedAttributesCount": 0
                  },
                  {
                    "timeUnixNano": 1646228314351000000,
                    "name": "responseEnd",
                    "attributes": [],
                    "droppedAttributesCount": 0
                  }
                ],
                "droppedEventsCount": 0,
                "status": {
                  "code": 0
                },
                "links": [],
                "droppedLinksCount": 0
              }
            ],
            "instrumentationLibrary": {
              "name": "@opentelemetry/instrumentation-document-load",
              "version": "0.27.1"
            }
          }
        ]
      }
    ]
  }
}

'''
'''--- pkg/integrations/v2/app_agent_receiver/traces_exporter.go ---
package app_agent_receiver

import (
	"context"

	"go.opentelemetry.io/collector/consumer"
)

type tracesConsumerGetter func() (consumer.Traces, error)

// TracesExporter will send traces to a traces instance
type TracesExporter struct {
	getTracesConsumer tracesConsumerGetter
}

// NewTracesExporter creates a trace exporter for the app agent receiver.
func NewTracesExporter(getTracesConsumer tracesConsumerGetter) appAgentReceiverExporter {
	return &TracesExporter{getTracesConsumer}
}

// Name of the exporter, for logging purposes
func (te *TracesExporter) Name() string {
	return "traces exporter"
}

// Export implements the AppDataExporter interface
func (te *TracesExporter) Export(ctx context.Context, payload Payload) error {
	if payload.Traces == nil {
		return nil
	}
	consumer, err := te.getTracesConsumer()
	if err != nil {
		return err
	}
	return consumer.ConsumeTraces(ctx, payload.Traces.Traces)
}

'''
'''--- pkg/integrations/v2/app_agent_receiver/traces_test.go ---
package app_agent_receiver

import (
	"context"
	"errors"
	"testing"

	"github.com/stretchr/testify/require"
	"go.opentelemetry.io/collector/consumer"
	"go.opentelemetry.io/collector/pdata/ptrace"
)

type mockTracesConsumer struct {
	consumed []ptrace.Traces
}

func (c *mockTracesConsumer) Capabilities() consumer.Capabilities {
	return consumer.Capabilities{MutatesData: false}
}

func (c *mockTracesConsumer) ConsumeTraces(ctx context.Context, td ptrace.Traces) error {
	c.consumed = append(c.consumed, td)
	return nil
}

func Test_exportTraces_success(t *testing.T) {
	ctx := context.Background()
	tracesConsumer := &mockTracesConsumer{}
	exporter := NewTracesExporter(func() (consumer.Traces, error) { return tracesConsumer, nil })
	payload := loadTestPayload(t)
	err := exporter.Export(ctx, payload)
	require.NoError(t, err)
	require.Len(t, tracesConsumer.consumed, 1)
}

func Test_exportTraces_noTracesInpayload(t *testing.T) {
	ctx := context.Background()
	tracesConsumer := &mockTracesConsumer{consumed: nil}
	exporter := NewTracesExporter(func() (consumer.Traces, error) { return tracesConsumer, nil })
	payload := loadTestPayload(t)
	payload.Traces = nil
	err := exporter.Export(ctx, payload)
	require.NoError(t, err)
	require.Len(t, tracesConsumer.consumed, 0)
}

func Test_exportTraces_noConsumer(t *testing.T) {
	ctx := context.Background()
	exporter := NewTracesExporter(func() (consumer.Traces, error) { return nil, errors.New("it dont work") })
	payload := loadTestPayload(t)
	err := exporter.Export(ctx, payload)
	require.Error(t, err, "it don't work")
}

'''
'''--- pkg/integrations/v2/app_agent_receiver/utils.go ---
package app_agent_receiver

import (
	"fmt"
	"sort"

	"github.com/minio/pkg/wildcard"
	om "github.com/wk8/go-ordered-map"
)

// KeyVal is an ordered map of string to interface
type KeyVal = om.OrderedMap

// NewKeyVal creates new empty KeyVal
func NewKeyVal() *KeyVal {
	return om.New()
}

// KeyValFromMap will instantiate KeyVal from a map[string]string
func KeyValFromMap(m map[string]string) *KeyVal {
	kv := NewKeyVal()
	keys := make([]string, 0, len(m))
	for k := range m {
		keys = append(keys, k)
	}
	sort.Strings(keys)
	for _, k := range keys {
		KeyValAdd(kv, k, m[k])
	}
	return kv
}

// MergeKeyVal will merge source in target
func MergeKeyVal(target *KeyVal, source *KeyVal) {
	for el := source.Oldest(); el != nil; el = el.Next() {
		target.Set(el.Key, el.Value)
	}
}

// MergeKeyValWithPrefix will merge source in target, adding a prefix to each key being merged in
func MergeKeyValWithPrefix(target *KeyVal, source *KeyVal, prefix string) {
	for el := source.Oldest(); el != nil; el = el.Next() {
		target.Set(fmt.Sprintf("%s%s", prefix, el.Key), el.Value)
	}
}

// KeyValAdd adds a key + value string pair to kv
func KeyValAdd(kv *KeyVal, key string, value string) {
	if len(value) > 0 {
		kv.Set(key, value)
	}
}

// KeyValToInterfaceSlice converts KeyVal to []interface{}, typically used for logging
func KeyValToInterfaceSlice(kv *KeyVal) []interface{} {
	slice := make([]interface{}, kv.Len()*2)
	idx := 0
	for el := kv.Oldest(); el != nil; el = el.Next() {
		slice[idx] = el.Key
		idx++
		slice[idx] = el.Value
		idx++
	}
	return slice
}

// KeyValToInterfaceMap converts KeyVal to map[string]interface
func KeyValToInterfaceMap(kv *KeyVal) map[string]interface{} {
	retv := make(map[string]interface{})
	for el := kv.Oldest(); el != nil; el = el.Next() {
		retv[fmt.Sprint(el.Key)] = el.Value
	}
	return retv
}

// URLMatchesOrigins returns true if URL matches at least one of origin prefix. Wildcard '*' and '?' supported
func urlMatchesOrigins(URL string, origins []string) bool {
	for _, origin := range origins {
		if origin == "*" || wildcard.Match(origin+"*", URL) {
			return true
		}
	}
	return false
}

'''
'''--- pkg/integrations/v2/app_agent_receiver/utils_test.go ---
package app_agent_receiver

import (
	"testing"

	"github.com/stretchr/testify/require"
)

func testCase(t *testing.T, URL string, origins []string, expected bool) {
	result := urlMatchesOrigins(URL, origins)
	require.Equal(t, expected, result)
}

func Test_Origin_WildcardAlwaysMatches(t *testing.T) {
	testCase(t, "http://example.com/static/foo.js", []string{"https://foo.com/", "*"}, true)
}

func Test_Origin_Matches(t *testing.T) {
	testCase(t, "http://example.com/static/foo.js", []string{"https://foo.com/", "http://example.com/"}, true)
}

func Test_Origin_MatchesWithWildcard(t *testing.T) {
	testCase(t, "http://foo.bar.com/static/foo.js", []string{"https://foo.com/", "http://*.bar.com/"}, true)
}

func Test_Origin_DoesNotMatch(t *testing.T) {
	testCase(t, "http://example.com/static/foo.js", []string{"https://foo.com/", "http://test.com/"}, false)
}

func Test_Origin_DoesNotMatchWithWildcard(t *testing.T) {
	testCase(t, "http://foo.bar.com/static/foo.js", []string{"https://foo.com/", "http://*.baz.com/"}, false)
}

func Test_Origin_MatchesWithWildcardNoProtocol(t *testing.T) {
	testCase(t, "http://foo.bar.com/static/foo.js", []string{"https://foo.com/", "*.bar.com/"}, true)
}

'''
'''--- pkg/integrations/v2/autoscrape/appender.go ---
package autoscrape

import (
	"fmt"

	"github.com/prometheus/prometheus/model/exemplar"
	"github.com/prometheus/prometheus/model/labels"
	"github.com/prometheus/prometheus/storage"
)

// failedAppender is used as the appender when an instance couldn't be found.
type failedAppender struct {
	instanceName string
}

var _ storage.Appender = (*failedAppender)(nil)

func (fa *failedAppender) Append(ref storage.SeriesRef, l labels.Labels, t int64, v float64) (storage.SeriesRef, error) {
	return 0, fmt.Errorf("no such instance %s", fa.instanceName)
}

func (fa *failedAppender) Commit() error {
	return fmt.Errorf("no such instance %s", fa.instanceName)
}

func (fa *failedAppender) Rollback() error {
	return fmt.Errorf("no such instance %s", fa.instanceName)
}

func (fa *failedAppender) AppendExemplar(ref storage.SeriesRef, l labels.Labels, e exemplar.Exemplar) (storage.SeriesRef, error) {
	return 0, fmt.Errorf("no such instance %s", fa.instanceName)
}

'''
'''--- pkg/integrations/v2/autoscrape/autoscrape.go ---
// Package autoscrape implements a scraper for integrations.
package autoscrape

import (
	"context"
	"sync"

	"github.com/go-kit/log"
	"github.com/go-kit/log/level"
	"github.com/grafana/agent/pkg/metrics"
	"github.com/grafana/agent/pkg/metrics/instance"
	"github.com/grafana/agent/pkg/server"
	"github.com/oklog/run"
	config_util "github.com/prometheus/common/config"
	"github.com/prometheus/common/model"
	prom_config "github.com/prometheus/prometheus/config"
	"github.com/prometheus/prometheus/discovery"
	"github.com/prometheus/prometheus/model/relabel"
	"github.com/prometheus/prometheus/scrape"
	"github.com/prometheus/prometheus/storage"
)

// DefaultGlobal holds default values for Global.
var DefaultGlobal = Global{
	Enable:          true,
	MetricsInstance: "default",
}

// Global holds default settings for metrics integrations that support
// autoscraping. Integrations may override their settings.
type Global struct {
	Enable          bool           `yaml:"enable,omitempty"`           // Whether self-scraping should be enabled.
	MetricsInstance string         `yaml:"metrics_instance,omitempty"` // Metrics instance name to send metrics to.
	ScrapeInterval  model.Duration `yaml:"scrape_interval,omitempty"`  // Self-scraping frequency.
	ScrapeTimeout   model.Duration `yaml:"scrape_timeout,omitempty"`   // Self-scraping timeout.
}

// UnmarshalYAML implements yaml.Unmarshaler.
func (g *Global) UnmarshalYAML(f func(interface{}) error) error {
	*g = DefaultGlobal
	type global Global
	return f((*global)(g))
}

// Config configure autoscrape for an individual integration. Override defaults.
type Config struct {
	Enable          *bool          `yaml:"enable,omitempty"`           // Whether self-scraping should be enabled.
	MetricsInstance string         `yaml:"metrics_instance,omitempty"` // Metrics instance name to send metrics to.
	ScrapeInterval  model.Duration `yaml:"scrape_interval,omitempty"`  // Self-scraping frequency.
	ScrapeTimeout   model.Duration `yaml:"scrape_timeout,omitempty"`   // Self-scraping timeout.

	RelabelConfigs       []*relabel.Config `yaml:"relabel_configs,omitempty"`        // Relabel the autoscrape job
	MetricRelabelConfigs []*relabel.Config `yaml:"metric_relabel_configs,omitempty"` // Relabel individual autoscrape metrics
}

// InstanceStore is used to find instances to send metrics to. It is a subset
// of the pkg/metrics/instance.Manager interface.
type InstanceStore interface {
	// GetInstance retrieves a ManagedInstance by name.
	GetInstance(name string) (instance.ManagedInstance, error)
}

// ScrapeConfig bind a Prometheus scrape config with an instance to send
// scraped metrics to.
type ScrapeConfig struct {
	Instance string
	Config   prom_config.ScrapeConfig
}

// Scraper is a metrics autoscraper.
type Scraper struct {
	ctx    context.Context
	cancel context.CancelFunc

	log log.Logger
	is  InstanceStore

	// Prometheus doesn't pass contextual information at scrape time that could
	// be used to change the behavior of generating an appender. This means that
	// it's not yet possible for us to just run a single SD + scrape manager for
	// all of our integrations, and we instead need to launch a pair of each for
	// every instance we're writing to.

	iscrapersMut sync.RWMutex
	iscrapers    map[string]*instanceScraper
	dialerFunc   server.DialContextFunc
}

// NewScraper creates a new autoscraper. Scraper will run until Stop is called.
// Instances to send scraped metrics to will be looked up via im. Scraping will
// use the provided dialerFunc to make connections if non-nil.
func NewScraper(l log.Logger, is InstanceStore, dialerFunc server.DialContextFunc) *Scraper {
	l = log.With(l, "component", "autoscraper")

	ctx, cancel := context.WithCancel(context.Background())

	s := &Scraper{
		ctx:    ctx,
		cancel: cancel,

		log:        l,
		is:         is,
		iscrapers:  map[string]*instanceScraper{},
		dialerFunc: dialerFunc,
	}
	return s
}

// ApplyConfig will apply the given jobs. An error will be returned for any
// jobs that failed to be applied.
func (s *Scraper) ApplyConfig(jobs []*ScrapeConfig) error {
	s.iscrapersMut.Lock()
	defer s.iscrapersMut.Unlock()

	var firstError error
	saveError := func(e error) {
		if firstError == nil {
			firstError = e
		}
	}

	// Shard our jobs by target instance.
	shardedJobs := map[string][]*prom_config.ScrapeConfig{}
	for _, j := range jobs {
		_, err := s.is.GetInstance(j.Instance)
		if err != nil {
			level.Error(s.log).Log("msg", "cannot autoscrape integration", "name", j.Config.JobName, "err", err)
			saveError(err)
			continue
		}

		shardedJobs[j.Instance] = append(shardedJobs[j.Instance], &j.Config)
	}

	// Then pass the jobs to instanceScraper, creating them if we need to.
	for instance, jobs := range shardedJobs {
		is, ok := s.iscrapers[instance]
		if !ok {
			is = newInstanceScraper(s.ctx, s.log, s.is, instance, config_util.DialContextFunc(s.dialerFunc))
			s.iscrapers[instance] = is
		}
		if err := is.ApplyConfig(jobs); err != nil {
			// Not logging here; is.ApplyConfig already logged the errors.
			saveError(err)
		}
	}

	// Garbage collect: if if there's a key in s.scrapers that wasn't in
	// shardedJobs, stop that unused scraper.
	for instance, is := range s.iscrapers {
		_, current := shardedJobs[instance]
		if !current {
			is.Stop()
			delete(s.iscrapers, instance)
		}
	}

	return firstError
}

// TargetsActive returns the set of active scrape targets for all target
// instances.
func (s *Scraper) TargetsActive() map[string]metrics.TargetSet {
	s.iscrapersMut.RLock()
	defer s.iscrapersMut.RUnlock()

	allTargets := make(map[string]metrics.TargetSet, len(s.iscrapers))
	for instance, is := range s.iscrapers {
		allTargets[instance] = is.sm.TargetsActive()
	}
	return allTargets
}

// Stop stops the Scraper.
func (s *Scraper) Stop() {
	s.iscrapersMut.Lock()
	defer s.iscrapersMut.Unlock()

	for instance, is := range s.iscrapers {
		is.Stop()
		delete(s.iscrapers, instance)
	}

	s.cancel()
}

// instanceScraper is a Scraper which always sends to the same instance.
type instanceScraper struct {
	log log.Logger

	sd     *discovery.Manager
	sm     *scrape.Manager
	cancel context.CancelFunc
	exited chan struct{}
}

// newInstanceScraper runs a new instanceScraper. Must be stopped by calling
// Stop.
func newInstanceScraper(
	ctx context.Context,
	l log.Logger,
	s InstanceStore,
	instanceName string,
	dialerFunc config_util.DialContextFunc,
) *instanceScraper {

	ctx, cancel := context.WithCancel(ctx)
	l = log.With(l, "target_instance", instanceName)

	sdOpts := []func(*discovery.Manager){
		discovery.Name("autoscraper/" + instanceName),
		discovery.DialContextFunc(dialerFunc),
	}
	sd := discovery.NewManager(ctx, l, sdOpts...)
	sm := scrape.NewManager(&scrape.Options{
		HTTPClientOptions: []config_util.HTTPClientOption{
			// If dialerFunc is nil, scrape.NewManager will use Go's default dialer.
			config_util.WithDialContextFunc(dialerFunc),
		},
	}, l, &agentAppender{
		inst: instanceName,
		is:   s,
	})

	is := &instanceScraper{
		log: l,

		sd:     sd,
		sm:     sm,
		cancel: cancel,
		exited: make(chan struct{}),
	}

	go is.run()
	return is
}

type agentAppender struct {
	inst string
	is   InstanceStore
}

func (aa *agentAppender) Appender(ctx context.Context) storage.Appender {
	mi, err := aa.is.GetInstance(aa.inst)
	if err != nil {
		return &failedAppender{instanceName: aa.inst}
	}
	return mi.Appender(ctx)
}

func (is *instanceScraper) run() {
	defer close(is.exited)
	var rg run.Group

	rg.Add(func() error {
		// Service discovery will stop whenever our parent context is canceled or
		// if is.cancel is called.
		err := is.sd.Run()
		if err != nil {
			level.Error(is.log).Log("msg", "autoscrape service discovery exited with error", "err", err)
		}
		return err
	}, func(_ error) {
		is.cancel()
	})

	rg.Add(func() error {
		err := is.sm.Run(is.sd.SyncCh())
		if err != nil {
			level.Error(is.log).Log("msg", "autoscrape scrape manager exited with error", "err", err)
		}
		return err
	}, func(_ error) {
		is.sm.Stop()
	})

	_ = rg.Run()
}

func (is *instanceScraper) ApplyConfig(jobs []*prom_config.ScrapeConfig) error {
	var firstError error
	saveError := func(e error) {
		if firstError == nil && e != nil {
			firstError = e
		}
	}

	var (
		scrapeConfigs = make([]*prom_config.ScrapeConfig, 0, len(jobs))
		sdConfigs     = make(map[string]discovery.Configs, len(jobs))
	)
	for _, job := range jobs {
		sdConfigs[job.JobName] = job.ServiceDiscoveryConfigs
		scrapeConfigs = append(scrapeConfigs, job)
	}
	if err := is.sd.ApplyConfig(sdConfigs); err != nil {
		level.Error(is.log).Log("msg", "error when applying SD to autoscraper", "err", err)
		saveError(err)
	}
	if err := is.sm.ApplyConfig(&prom_config.Config{ScrapeConfigs: scrapeConfigs}); err != nil {
		level.Error(is.log).Log("msg", "error when applying jobs to scraper", "err", err)
		saveError(err)
	}

	return firstError
}

func (is *instanceScraper) Stop() {
	is.cancel()
	<-is.exited
}

'''
'''--- pkg/integrations/v2/autoscrape/autoscrape_test.go ---
package autoscrape

import (
	"context"
	"net/http/httptest"
	"testing"
	"time"

	"github.com/grafana/agent/pkg/metrics/instance"
	"github.com/grafana/agent/pkg/util"
	"github.com/prometheus/client_golang/prometheus/promhttp"
	"github.com/prometheus/common/model"
	prom_config "github.com/prometheus/prometheus/config"
	"github.com/prometheus/prometheus/discovery"
	"github.com/prometheus/prometheus/model/exemplar"
	"github.com/prometheus/prometheus/model/labels"
	"github.com/prometheus/prometheus/storage"
	"github.com/stretchr/testify/assert"
	"github.com/stretchr/testify/require"
	"go.uber.org/atomic"
)

// TestAutoscrape is a basic end-to-end test of the autoscraper.
func TestAutoscrape(t *testing.T) {
	srv := httptest.NewServer(promhttp.Handler())
	defer srv.Close()

	wt := util.NewWaitTrigger()

	noop := noOpAppender
	noop.AppendFunc = func(ref storage.SeriesRef, l labels.Labels, t int64, v float64) (storage.SeriesRef, error) {
		wt.Trigger()
		return noOpAppender.AppendFunc(ref, l, t, v)
	}

	im := instance.MockManager{
		GetInstanceFunc: func(name string) (instance.ManagedInstance, error) {
			assert.Equal(t, t.Name(), name)
			return &mockInstance{app: &noop}, nil
		},
	}
	as := NewScraper(util.TestLogger(t), im, nil)
	defer as.Stop()

	err := as.ApplyConfig([]*ScrapeConfig{{
		Instance: t.Name(),
		Config: func() prom_config.ScrapeConfig {
			cfg := prom_config.DefaultScrapeConfig
			cfg.JobName = t.Name()
			cfg.ScrapeInterval = model.Duration(time.Second)
			cfg.ScrapeTimeout = model.Duration(time.Second / 2)
			cfg.ServiceDiscoveryConfigs = discovery.Configs{
				discovery.StaticConfig{{
					Targets: []model.LabelSet{{
						model.AddressLabel: model.LabelValue(srv.Listener.Addr().String()),
					}},
					Source: t.Name(),
				}},
			}
			return cfg
		}(),
	}})
	require.NoError(t, err, "failed to apply configs")

	// NOTE(rfratto): SD won't start sending targets until after 5 seconds. We'll
	// need to at least wait that long.
	time.Sleep(5 * time.Second)

	require.NoError(t, wt.Wait(5*time.Second), "timed out waiting for scrape")
}

var globalRef atomic.Uint64
var noOpAppender = mockAppender{
	AppendFunc: func(ref storage.SeriesRef, l labels.Labels, t int64, v float64) (storage.SeriesRef, error) {
		return storage.SeriesRef(globalRef.Inc()), nil
	},
	CommitFunc:   func() error { return nil },
	RollbackFunc: func() error { return nil },
	AppendExemplarFunc: func(ref storage.SeriesRef, l labels.Labels, e exemplar.Exemplar) (storage.SeriesRef, error) {
		return storage.SeriesRef(globalRef.Inc()), nil
	},
}

type mockAppender struct {
	AppendFunc         func(ref storage.SeriesRef, l labels.Labels, t int64, v float64) (storage.SeriesRef, error)
	CommitFunc         func() error
	RollbackFunc       func() error
	AppendExemplarFunc func(ref storage.SeriesRef, l labels.Labels, e exemplar.Exemplar) (storage.SeriesRef, error)
}

func (ma *mockAppender) Append(ref storage.SeriesRef, l labels.Labels, t int64, v float64) (storage.SeriesRef, error) {
	return ma.AppendFunc(ref, l, t, v)
}
func (ma *mockAppender) Commit() error   { return ma.CommitFunc() }
func (ma *mockAppender) Rollback() error { return ma.RollbackFunc() }
func (ma *mockAppender) AppendExemplar(ref storage.SeriesRef, l labels.Labels, e exemplar.Exemplar) (storage.SeriesRef, error) {
	return ma.AppendExemplarFunc(ref, l, e)
}

type mockInstance struct {
	instance.NoOpInstance
	app storage.Appender
}

func (mi *mockInstance) Appender(ctx context.Context) storage.Appender { return mi.app }

'''
'''--- pkg/integrations/v2/common/metrics.go ---
package common

import (
	"github.com/grafana/agent/pkg/integrations/v2/autoscrape"
	"github.com/prometheus/prometheus/model/labels"
)

// MetricsConfig is a set of common options shared by metrics integrations. It
// should be utilised by an integration's config by inlining the common
// options:
//
//   type IntegrationConfig struct {
//     Common common.MetricsConfig `yaml:",inline"`
//   }
type MetricsConfig struct {
	Autoscrape  autoscrape.Config `yaml:"autoscrape,omitempty"`
	InstanceKey *string           `yaml:"instance,omitempty"`
	ExtraLabels labels.Labels     `yaml:"extra_labels,omitempty"`
}

// ApplyDefaults applies defaults to mc.
func (mc *MetricsConfig) ApplyDefaults(g autoscrape.Global) {
	if mc.Autoscrape.Enable == nil {
		val := g.Enable
		mc.Autoscrape.Enable = &val
	}
	if mc.Autoscrape.MetricsInstance == "" {
		mc.Autoscrape.MetricsInstance = g.MetricsInstance
	}
	if mc.Autoscrape.ScrapeInterval == 0 {
		mc.Autoscrape.ScrapeInterval = g.ScrapeInterval
	}
	if mc.Autoscrape.ScrapeTimeout == 0 {
		mc.Autoscrape.ScrapeTimeout = g.ScrapeTimeout
	}
}

'''
'''--- pkg/integrations/v2/controller.go ---
package integrations

import (
	"context"
	"errors"
	"fmt"
	"net/http"
	"net/url"
	"path"
	"sort"
	"strings"
	"sync"

	"github.com/go-kit/log"
	"github.com/go-kit/log/level"
	"github.com/gorilla/mux"
	"github.com/grafana/agent/pkg/integrations/v2/autoscrape"
	"github.com/prometheus/prometheus/discovery"
	http_sd "github.com/prometheus/prometheus/discovery/http"
	"go.uber.org/atomic"
)

// controllerConfig holds a set of integration configs.
type controllerConfig []Config

// controller manages a set of integrations.
type controller struct {
	logger log.Logger

	mut          sync.Mutex
	cfg          controllerConfig
	globals      Globals
	integrations []*controlledIntegration // Running integrations

	runIntegrations chan []*controlledIntegration // Schedule integrations to run
}

// newController creates a new Controller. Controller is intended to be
// embedded inside of integrations that may want to multiplex other
// integrations.
func newController(l log.Logger, cfg controllerConfig, globals Globals) (*controller, error) {
	c := &controller{
		logger:          l,
		runIntegrations: make(chan []*controlledIntegration, 1),
	}
	if err := c.UpdateController(cfg, globals); err != nil {
		return nil, err
	}
	return c, nil
}

// run starts the controller and blocks until ctx is canceled.
func (c *controller) run(ctx context.Context) {
	pool := newWorkerPool(ctx, c.logger)
	defer pool.Close()

	for {
		select {
		case <-ctx.Done():
			level.Debug(c.logger).Log("msg", "controller exiting")
			return
		case newIntegrations := <-c.runIntegrations:
			pool.Reload(newIntegrations)
		}
	}
}

// controlledIntegration is a running Integration. A running integration is
// identified uniquely by its id.
type controlledIntegration struct {
	id      integrationID
	i       Integration
	c       Config // Config that generated i. Used for changing to see if a config changed.
	running atomic.Bool
}

func (ci *controlledIntegration) Running() bool {
	return ci.running.Load()
}

// integrationID uses a tuple of Name and Identifier to uniquely identify an
// integration.
type integrationID struct{ Name, Identifier string }

func (id integrationID) String() string {
	return fmt.Sprintf("%s/%s", id.Name, id.Identifier)
}

// UpdateController updates the Controller with new Controller and
// IntegrationOptions.
//
// UpdateController updates running integrations. Extensions can be
// recalculated by calling relevant methods like Handler or Targets.
func (c *controller) UpdateController(cfg controllerConfig, globals Globals) error {
	c.mut.Lock()
	defer c.mut.Unlock()

	// Ensure that no singleton integration is defined twice
	var (
		duplicatedSingletons []string
		singletonSet         = make(map[string]struct{})
	)
	for _, cfg := range cfg {
		t, _ := RegisteredType(cfg)
		if t != TypeSingleton {
			continue
		}

		if _, exists := singletonSet[cfg.Name()]; exists {
			duplicatedSingletons = append(duplicatedSingletons, cfg.Name())
			continue
		}
		singletonSet[cfg.Name()] = struct{}{}
	}
	if len(duplicatedSingletons) == 1 {
		return fmt.Errorf("integration %q may only be defined once", duplicatedSingletons[0])
	} else if len(duplicatedSingletons) > 1 {
		list := strings.Join(duplicatedSingletons, ", ")
		return fmt.Errorf("the following integrations may only be defined once each: %s", list)
	}

	integrationIDMap := map[integrationID]struct{}{}

	integrations := make([]*controlledIntegration, 0, len(cfg))

NextConfig:
	for _, ic := range cfg {
		name := ic.Name()

		identifier, err := ic.Identifier(globals)
		if err != nil {
			return fmt.Errorf("could not build identifier for integration %q: %w", name, err)
		}

		if err := ic.ApplyDefaults(globals); err != nil {
			return fmt.Errorf("failed to apply defaults for %s/%s: %w", name, identifier, err)
		}

		id := integrationID{Name: name, Identifier: identifier}
		if _, exist := integrationIDMap[id]; exist {
			return fmt.Errorf("multiple instance names %q in integration %q", identifier, name)
		}
		integrationIDMap[id] = struct{}{}

		// Now that we know the ID for an integration, we can check to see if it's
		// running and can be dynamically updated.
		for _, ci := range c.integrations {
			if ci.id != id {
				continue
			}

			// If the configs haven't changed, then we don't need to do anything.
			if CompareConfigs(ci.c, ic) {
				integrations = append(integrations, ci)
				continue NextConfig
			}

			if ui, ok := ci.i.(UpdateIntegration); ok {
				if err := ui.ApplyConfig(ic, globals); errors.Is(err, ErrInvalidUpdate) {
					level.Warn(c.logger).Log("msg", "failed to dynamically update integration; will recreate", "integration", name, "instance", identifier, "err', err")
					break
				} else if err != nil {
					return fmt.Errorf("failed to update %s integration %q: %w", name, identifier, err)
				} else {
					// Update succeeded; re-use the running one and go to the next
					// integration to process.
					integrations = append(integrations, ci)
					continue NextConfig
				}
			}

			// We found the integration to update: we can stop this loop now.
			break
		}

		logger := log.With(c.logger, "integration", name, "instance", identifier)
		integration, err := ic.NewIntegration(logger, globals)
		if err != nil {
			return fmt.Errorf("failed to construct %s integration %q: %w", name, identifier, err)
		}

		// Create a new controlled integration.
		integrations = append(integrations, &controlledIntegration{
			id: id,
			i:  integration,
			c:  ic,
		})
	}

	// Schedule integrations to run
	c.runIntegrations <- integrations

	c.cfg = cfg
	c.globals = globals
	c.integrations = integrations
	return nil
}

// Handler returns an HTTP handler for the controller and its integrations.
// Handler will pass through requests to other running integrations. Handler
// always returns an http.Handler regardless of error.
//
// Handler is expensive to compute and should only be done after reloading the
// config.
func (c *controller) Handler(prefix string) (http.Handler, error) {
	var firstErr error
	saveFirstErr := func(err error) {
		if firstErr == nil {
			firstErr = err
		}
	}

	r := mux.NewRouter()

	err := c.forEachIntegration(prefix, func(ci *controlledIntegration, iprefix string) {
		id := ci.id

		i, ok := ci.i.(HTTPIntegration)
		if !ok {
			return
		}

		handler, err := i.Handler(iprefix + "/")
		if err != nil {
			saveFirstErr(fmt.Errorf("could not generate HTTP handler for %s integration %q: %w", id.Name, id.Identifier, err))
			return
		} else if handler == nil {
			return
		}

		// Anything that matches the integrationPrefix should be passed to the handler.
		// The reason these two are separated is if you have two instance names and one is a prefix of another
		// ie localhost and localhost2, localhost2 will never get called because localhost will always get precedence
		// add / fixes this, but to keep old behavior we need to ensure /localhost and localhost2 also work, hence
		// the second handlefunc below this one. https://github.com/grafana/agent/issues/1718
		hfunc := func(rw http.ResponseWriter, r *http.Request) {
			if !ci.Running() {
				http.Error(rw, fmt.Sprintf("%s integration intance %q not running", id.Name, id.Identifier), http.StatusServiceUnavailable)
				return
			}
			handler.ServeHTTP(rw, r)
		}
		r.PathPrefix(iprefix + "/").HandlerFunc(hfunc)
		// Handle calling the iprefix itself
		r.HandleFunc(iprefix, hfunc)
	})
	if err != nil {
		level.Warn(c.logger).Log("msg", "error when iterating over integrations to build HTTP handlers", "err", err)
	}

	// TODO(rfratto): navigation page for exact prefix match

	return r, firstErr
}

// forEachIntegration calculates the prefix for each integration and calls f.
// prefix will not end in /.
func (c *controller) forEachIntegration(basePrefix string, f func(ci *controlledIntegration, iprefix string)) error {
	c.mut.Lock()
	defer c.mut.Unlock()

	// Pre-populate a mapping of integration name -> identifier. If there are
	// two instances of the same integration, we want to ensure unique routing.
	//
	// This special logic is done for backwards compatibility with the original
	// design of integrations.
	identifiersMap := map[string][]string{}
	for _, i := range c.integrations {
		identifiersMap[i.id.Name] = append(identifiersMap[i.id.Name], i.id.Identifier)
	}

	usedPrefixes := map[string]struct{}{}

	for _, ci := range c.integrations {
		id := ci.id
		multipleInstances := len(identifiersMap[id.Name]) > 1

		var integrationPrefix string
		if multipleInstances {
			// i.e., /integrations/mysqld_exporter/server-a
			integrationPrefix = path.Join(basePrefix, id.Name, id.Identifier)
		} else {
			// i.e., /integrations/node_exporter
			integrationPrefix = path.Join(basePrefix, id.Name)
		}

		f(ci, integrationPrefix)

		if _, exist := usedPrefixes[integrationPrefix]; exist {
			return fmt.Errorf("BUG: duplicate integration prefix %q", integrationPrefix)
		}
		usedPrefixes[integrationPrefix] = struct{}{}
	}
	return nil
}

// Targets returns the current set of targets across all integrations. Use opts
// to customize which targets are returned.
func (c *controller) Targets(ep Endpoint, opts TargetOptions) []*targetGroup {
	// Grab the integrations as fast as possible. We don't want to spend too much
	// time holding the mutex.
	type prefixedMetricsIntegration struct {
		id integrationID
		i  MetricsIntegration
		ep Endpoint
	}
	var mm []prefixedMetricsIntegration

	err := c.forEachIntegration(ep.Prefix, func(ci *controlledIntegration, iprefix string) {
		// Best effort liveness check. They might stop running when we request
		// their targets, which is fine, but we should save as much work as we
		// can.
		if !ci.Running() {
			return
		}
		if mi, ok := ci.i.(MetricsIntegration); ok {
			ep := Endpoint{Host: ep.Host, Prefix: iprefix}
			mm = append(mm, prefixedMetricsIntegration{id: ci.id, i: mi, ep: ep})
		}
	})
	if err != nil {
		level.Warn(c.logger).Log("msg", "error when iterating over integrations to get targets", "err", err)
	}

	var tgs []*targetGroup
	for _, mi := range mm {
		// If we're looking for a subset of integrations, filter out anything that doesn't match.
		if len(opts.Integrations) > 0 && !stringSliceContains(opts.Integrations, mi.id.Name) {
			continue
		}
		// If we're looking for a specific instance, filter out anything that doesn't match.
		if opts.Instance != "" && mi.id.Identifier != opts.Instance {
			continue
		}

		for _, tgt := range mi.i.Targets(mi.ep) {
			tgs = append(tgs, (*targetGroup)(tgt))
		}
	}
	sort.Slice(tgs, func(i, j int) bool {
		return tgs[i].Source < tgs[j].Source
	})
	return tgs
}

func stringSliceContains(ss []string, s string) bool {
	for _, check := range ss {
		if check == s {
			return true
		}
	}
	return false
}

// TargetOptions controls which targets should be returned by the subsystem.
type TargetOptions struct {
	// Integrations is the set of integrations to return. An empty slice will
	// default to returning all integrations.
	Integrations []string
	// Instance matches a specific instance from all integrations. An empty
	// string will match any instance.
	Instance string
}

// TargetOptionsFromParams creates TargetOptions from parsed URL query parameters.
func TargetOptionsFromParams(u url.Values) (TargetOptions, error) {
	var to TargetOptions

	rawIntegrations := u.Get("integrations")
	if rawIntegrations != "" {
		rawIntegrations, err := url.QueryUnescape(rawIntegrations)
		if err != nil {
			return to, fmt.Errorf("invalid value for integrations: %w", err)
		}
		to.Integrations = strings.Split(rawIntegrations, ",")
	}

	rawInstance := u.Get("instance")
	if rawInstance != "" {
		rawInstance, err := url.QueryUnescape(rawInstance)
		if err != nil {
			return to, fmt.Errorf("invalid value for instance: %w", err)
		}
		to.Instance = rawInstance
	}

	return to, nil
}

// ToParams will convert to into URL query parameters.
func (to TargetOptions) ToParams() url.Values {
	p := make(url.Values)
	if len(to.Integrations) != 0 {
		p.Set("integrations", url.QueryEscape(strings.Join(to.Integrations, ",")))
	}
	if to.Instance != "" {
		p.Set("instance", url.QueryEscape(to.Instance))
	}
	return p
}

// ScrapeConfigs returns a set of scrape configs to use for self-scraping.
// sdConfig should contain the full URL where the integrations SD API is
// exposed. ScrapeConfigs will inject unique query parameters per integration
// to limit what will be discovered.
func (c *controller) ScrapeConfigs(prefix string, sdConfig *http_sd.SDConfig) []*autoscrape.ScrapeConfig {
	// Grab the integrations as fast as possible. We don't want to spend too much
	// time holding the mutex.
	type prefixedMetricsIntegration struct {
		id     integrationID
		i      MetricsIntegration
		prefix string
	}
	var mm []prefixedMetricsIntegration

	err := c.forEachIntegration(prefix, func(ci *controlledIntegration, iprefix string) {
		if mi, ok := ci.i.(MetricsIntegration); ok {
			mm = append(mm, prefixedMetricsIntegration{id: ci.id, i: mi, prefix: iprefix})
		}
	})
	if err != nil {
		level.Warn(c.logger).Log("msg", "error when iterating over integrations to get scrape configs", "err", err)
	}

	var cfgs []*autoscrape.ScrapeConfig
	for _, mi := range mm {
		// sdConfig will be pointing to the targets API. By default, this returns absolutely everything.
		// We want to use the query parmaeters to inform the API to only return
		// specific targets.
		opts := TargetOptions{
			Integrations: []string{mi.id.Name},
			Instance:     mi.id.Identifier,
		}

		integrationSDConfig := *sdConfig
		integrationSDConfig.URL = sdConfig.URL + "?" + opts.ToParams().Encode()
		sds := discovery.Configs{&integrationSDConfig}
		cfgs = append(cfgs, mi.i.ScrapeConfigs(sds)...)
	}
	sort.Slice(cfgs, func(i, j int) bool {
		return cfgs[i].Config.JobName < cfgs[j].Config.JobName
	})
	return cfgs
}

'''
'''--- pkg/integrations/v2/controller_httpintegration_test.go ---
package integrations

import (
	"fmt"
	"io"
	"net/http"
	"net/http/httptest"
	"strings"
	"testing"

	"github.com/go-kit/log"
	"github.com/gorilla/mux"
	"github.com/grafana/agent/pkg/util"
	"github.com/stretchr/testify/require"
)

//
// Tests for controller's utilization of the HTTPIntegration interface.
//

func Test_controller_Handler_Sync(t *testing.T) {
	httpConfigFromID := func(t *testing.T, name, identifier string) Config {
		t.Helper()

		cfg := mockConfigNameTuple(t, name, identifier)
		cfg.NewIntegrationFunc = func(log.Logger, Globals) (Integration, error) {
			i := mockHTTPIntegration{
				Integration: NoOpIntegration,
				HandlerFunc: func(prefix string) (http.Handler, error) {
					return http.HandlerFunc(func(rw http.ResponseWriter, _ *http.Request) {
						// We should never reach here since we don't run the integrations.
						rw.WriteHeader(http.StatusBadRequest)
					}), nil
				},
			}
			return i, nil
		}

		return cfg
	}

	cfg := controllerConfig{httpConfigFromID(t, "foo", "bar")}
	ctrl, err := newController(util.TestLogger(t), cfg, Globals{})
	require.NoError(t, err)

	handler, err := ctrl.Handler("/integrations/")
	require.NoError(t, err)

	srv := httptest.NewServer(handler)

	resp, err := srv.Client().Get(srv.URL + "/integrations/foo/bar")
	require.NoError(t, err)
	require.Equal(t, http.StatusServiceUnavailable, resp.StatusCode)
}

// Test_controller_HTTPIntegration_Prefixes ensures that the controller will assign
// appropriate prefixes to HTTPIntegrations.
func Test_controller_HTTPIntegration_Prefixes(t *testing.T) {
	httpConfigFromID := func(t *testing.T, prefixes *[]string, name, identifier string) Config {
		t.Helper()

		cfg := mockConfigNameTuple(t, name, identifier)
		cfg.NewIntegrationFunc = func(log.Logger, Globals) (Integration, error) {
			i := mockHTTPIntegration{
				Integration: NoOpIntegration,
				HandlerFunc: func(prefix string) (http.Handler, error) {
					*prefixes = append(*prefixes, prefix)
					return http.NotFoundHandler(), nil
				},
			}
			return i, nil
		}

		return cfg
	}

	t.Run("fully unique", func(t *testing.T) {
		var prefixes []string

		ctrl, err := newController(
			util.TestLogger(t),
			controllerConfig{
				httpConfigFromID(t, &prefixes, "foo", "bar"),
				httpConfigFromID(t, &prefixes, "fizz", "buzz"),
				httpConfigFromID(t, &prefixes, "hello", "world"),
			},
			Globals{},
		)
		require.NoError(t, err)
		_ = newSyncController(t, ctrl)

		_, err = ctrl.Handler("/integrations/")
		require.NoError(t, err)

		expect := []string{
			"/integrations/foo/",
			"/integrations/fizz/",
			"/integrations/hello/",
		}
		require.ElementsMatch(t, prefixes, expect)
	})

	t.Run("multiple instances", func(t *testing.T) {
		var prefixes []string

		ctrl, err := newController(
			util.TestLogger(t),
			controllerConfig{
				httpConfigFromID(t, &prefixes, "foo", "bar"),
				httpConfigFromID(t, &prefixes, "foo", "buzz"),
				httpConfigFromID(t, &prefixes, "hello", "world"),
			},
			Globals{},
		)
		require.NoError(t, err)
		_ = newSyncController(t, ctrl)

		_, err = ctrl.Handler("/integrations/")
		require.NoError(t, err)

		expect := []string{
			"/integrations/foo/bar/",
			"/integrations/foo/buzz/",
			"/integrations/hello/",
		}
		require.ElementsMatch(t, prefixes, expect)
	})
}

// Test_controller_HTTPIntegration_Routing ensures that the controller will route
// requests to the appropriate integration.
func Test_controller_HTTPIntegration_Routing(t *testing.T) {
	httpConfigFromID := func(t *testing.T, name, identifier string) Config {
		t.Helper()

		cfg := mockConfigNameTuple(t, name, identifier)
		cfg.NewIntegrationFunc = func(log.Logger, Globals) (Integration, error) {
			i := mockHTTPIntegration{
				Integration: NoOpIntegration,
				HandlerFunc: func(prefix string) (http.Handler, error) {
					return http.HandlerFunc(func(rw http.ResponseWriter, r *http.Request) {
						fmt.Fprintf(rw, "prefix=%s, path=%s", prefix, r.URL.Path)
					}), nil
				},
			}
			return i, nil
		}

		return cfg
	}

	ctrl, err := newController(
		util.TestLogger(t),
		controllerConfig{
			httpConfigFromID(t, "foo", "bar"),
			httpConfigFromID(t, "foo", "buzz"),
			httpConfigFromID(t, "hello", "world"),
		},
		Globals{},
	)
	require.NoError(t, err)
	_ = newSyncController(t, ctrl)

	handler, err := ctrl.Handler("/integrations/")
	require.NoError(t, err)

	srv := httptest.NewServer(handler)

	getResponse := func(t *testing.T, path string) string {
		t.Helper()
		resp, err := srv.Client().Get(srv.URL + path)
		require.NoError(t, err)
		defer resp.Body.Close()

		var sb strings.Builder
		_, err = io.Copy(&sb, resp.Body)
		require.NoError(t, err)
		return sb.String()
	}

	tt := []struct {
		path, expect string
	}{
		{"/integrations/foo/bar", "prefix=/integrations/foo/bar/, path=/integrations/foo/bar"},
		{"/integrations/foo/bar/", "prefix=/integrations/foo/bar/, path=/integrations/foo/bar/"},
		{"/integrations/foo/bar/extra", "prefix=/integrations/foo/bar/, path=/integrations/foo/bar/extra"},
	}

	for _, tc := range tt {
		require.Equal(t, tc.expect, getResponse(t, tc.path))
	}
}

// Test_controller_HTTPIntegration_NestedRouting ensures that the controller
// will work with nested routers.
func Test_controller_HTTPIntegration_NestedRouting(t *testing.T) {
	cfg := mockConfigNameTuple(t, "test", "test")
	cfg.NewIntegrationFunc = func(log.Logger, Globals) (Integration, error) {
		i := mockHTTPIntegration{
			Integration: NoOpIntegration,
			HandlerFunc: func(prefix string) (http.Handler, error) {
				r := mux.NewRouter()
				r.StrictSlash(true)

				r.HandleFunc(prefix, func(rw http.ResponseWriter, r *http.Request) {
					fmt.Fprintf(rw, "prefix=%s, path=%s", prefix, r.URL.Path)
				})

				r.HandleFunc(prefix+"greet", func(rw http.ResponseWriter, _ *http.Request) {
					fmt.Fprintf(rw, "Hello, world!")
				})
				return r, nil
			},
		}
		return i, nil
	}

	ctrl, err := newController(util.TestLogger(t), controllerConfig{cfg}, Globals{})
	require.NoError(t, err)
	_ = newSyncController(t, ctrl)

	handler, err := ctrl.Handler("/integrations/")
	require.NoError(t, err)

	srv := httptest.NewServer(handler)

	getResponse := func(t *testing.T, path string) string {
		t.Helper()
		resp, err := srv.Client().Get(srv.URL + path)
		require.NoError(t, err)
		defer resp.Body.Close()

		var sb strings.Builder
		_, err = io.Copy(&sb, resp.Body)
		require.NoError(t, err)
		return sb.String()
	}

	tt := []struct {
		path, expect string
	}{
		{"/integrations/test", "prefix=/integrations/test/, path=/integrations/test/"},
		{"/integrations/test/", "prefix=/integrations/test/, path=/integrations/test/"},
		{"/integrations/test/greet", "Hello, world!"},
	}

	for _, tc := range tt {
		require.Equal(t, tc.expect, getResponse(t, tc.path))
	}
}

type mockHTTPIntegration struct {
	Integration
	HandlerFunc func(prefix string) (http.Handler, error)
}

func (m mockHTTPIntegration) Handler(prefix string) (http.Handler, error) {
	return m.HandlerFunc(prefix)
}

'''
'''--- pkg/integrations/v2/controller_metricsintegration_test.go ---
package integrations

import (
	"context"
	nethttp "net/http"
	"testing"

	"github.com/go-kit/log"
	"github.com/grafana/agent/pkg/integrations/v2/autoscrape"
	"github.com/grafana/agent/pkg/util"
	"github.com/prometheus/common/model"
	prom_config "github.com/prometheus/prometheus/config"
	"github.com/prometheus/prometheus/discovery"
	"github.com/prometheus/prometheus/discovery/http"
	"github.com/prometheus/prometheus/discovery/targetgroup"
	"github.com/stretchr/testify/require"
)

//
// Tests for controller's utilization of the MetricsIntegration interface.
//

func Test_controller_MetricsIntegration_Targets(t *testing.T) {
	integrationWithTarget := func(targetName string) Integration {
		return mockMetricsIntegration{
			HTTPIntegration: newWaitStartedIntegration(),
			TargetsFunc: func(Endpoint) []*targetgroup.Group {
				return []*targetgroup.Group{{
					Targets: []model.LabelSet{{model.AddressLabel: model.LabelValue(targetName)}},
				}}
			},
			ScrapeConfigsFunc: func(c discovery.Configs) []*autoscrape.ScrapeConfig { return nil },
		}
	}

	integrations := []Config{
		mockConfigNameTuple(t, "a", "instanceA").WithNewIntegrationFunc(func(l log.Logger, g Globals) (Integration, error) {
			return integrationWithTarget("a"), nil
		}),
		mockConfigNameTuple(t, "b", "instanceB").WithNewIntegrationFunc(func(l log.Logger, g Globals) (Integration, error) {
			return integrationWithTarget("b"), nil
		}),
	}

	// waitIntegrations starts a controller and waits for all of its integrations
	// to run.
	waitIntegrations := func(t *testing.T, ctrl *controller) {
		t.Helper()
		_ = newSyncController(t, ctrl)
		err := ctrl.forEachIntegration("/", func(ci *controlledIntegration, _ string) {
			wsi := ci.i.(mockMetricsIntegration).HTTPIntegration.(*waitStartedIntegration)
			_ = wsi.trigger.WaitContext(context.Background())
		})
		require.NoError(t, err)
	}

	t.Run("All", func(t *testing.T) {
		ctrl, err := newController(
			util.TestLogger(t),
			controllerConfig(integrations),
			Globals{},
		)
		require.NoError(t, err)
		waitIntegrations(t, ctrl)

		result := ctrl.Targets(Endpoint{Prefix: "/"}, TargetOptions{})
		expect := []*targetGroup{
			{Targets: []model.LabelSet{{model.AddressLabel: "a"}}},
			{Targets: []model.LabelSet{{model.AddressLabel: "b"}}},
		}
		require.Equal(t, expect, result)
	})

	t.Run("All by Integration", func(t *testing.T) {
		ctrl, err := newController(
			util.TestLogger(t),
			controllerConfig(integrations),
			Globals{},
		)
		require.NoError(t, err)
		waitIntegrations(t, ctrl)

		result := ctrl.Targets(Endpoint{Prefix: "/"}, TargetOptions{
			Integrations: []string{"a", "b"},
		})
		expect := []*targetGroup{
			{Targets: []model.LabelSet{{model.AddressLabel: "a"}}},
			{Targets: []model.LabelSet{{model.AddressLabel: "b"}}},
		}
		require.Equal(t, expect, result)
	})

	t.Run("Specific Integration", func(t *testing.T) {
		ctrl, err := newController(
			util.TestLogger(t),
			controllerConfig(integrations),
			Globals{},
		)
		require.NoError(t, err)
		waitIntegrations(t, ctrl)

		result := ctrl.Targets(Endpoint{Prefix: "/"}, TargetOptions{
			Integrations: []string{"a"},
		})
		expect := []*targetGroup{
			{Targets: []model.LabelSet{{model.AddressLabel: "a"}}},
		}
		require.Equal(t, expect, result)
	})
}

func Test_controller_MetricsIntegration_ScrapeConfig(t *testing.T) {
	integrationWithTarget := func(targetName string) Integration {
		return mockMetricsIntegration{
			HTTPIntegration: NoOpIntegration,
			ScrapeConfigsFunc: func(c discovery.Configs) []*autoscrape.ScrapeConfig {
				return []*autoscrape.ScrapeConfig{{
					Instance: "default",
					Config:   prom_config.ScrapeConfig{JobName: targetName},
				}}
			},
		}
	}

	integrations := []Config{
		mockConfigNameTuple(t, "a", "instanceA").WithNewIntegrationFunc(func(l log.Logger, g Globals) (Integration, error) {
			return integrationWithTarget("a"), nil
		}),
		mockConfigNameTuple(t, "b", "instanceB").WithNewIntegrationFunc(func(l log.Logger, g Globals) (Integration, error) {
			return integrationWithTarget("b"), nil
		}),
	}

	ctrl, err := newController(
		util.TestLogger(t),
		controllerConfig(integrations),
		Globals{},
	)
	require.NoError(t, err)
	_ = newSyncController(t, ctrl)

	result := ctrl.ScrapeConfigs("/", &http.DefaultSDConfig)
	expect := []*autoscrape.ScrapeConfig{
		{Instance: "default", Config: prom_config.ScrapeConfig{JobName: "a"}},
		{Instance: "default", Config: prom_config.ScrapeConfig{JobName: "b"}},
	}
	require.Equal(t, expect, result)
}

//
// Tests for controller's utilization of the MetricsIntegration interface.
//

type waitStartedIntegration struct {
	trigger *util.WaitTrigger
}

func newWaitStartedIntegration() *waitStartedIntegration {
	return &waitStartedIntegration{trigger: util.NewWaitTrigger()}
}

func (i *waitStartedIntegration) RunIntegration(ctx context.Context) error {
	i.trigger.Trigger()
	<-ctx.Done()
	return nil
}

func (i *waitStartedIntegration) Handler(prefix string) (nethttp.Handler, error) {
	return nil, nil
}

type mockMetricsIntegration struct {
	HTTPIntegration
	TargetsFunc       func(ep Endpoint) []*targetgroup.Group
	ScrapeConfigsFunc func(discovery.Configs) []*autoscrape.ScrapeConfig
}

func (m mockMetricsIntegration) Targets(ep Endpoint) []*targetgroup.Group {
	return m.TargetsFunc(ep)
}

func (m mockMetricsIntegration) ScrapeConfigs(cfgs discovery.Configs) []*autoscrape.ScrapeConfig {
	return m.ScrapeConfigsFunc(cfgs)
}

'''
'''--- pkg/integrations/v2/controller_test.go ---
package integrations

import (
	"context"
	"strings"
	"sync"
	"testing"

	"github.com/go-kit/log"
	"github.com/grafana/agent/pkg/util"
	"github.com/stretchr/testify/require"
	"go.uber.org/atomic"
)

//
// Tests for Controller's utilization of the core Integration interface.
//

// Test_controller_UniqueIdentifer ensures that integrations must not share a (name, id) tuple.
func Test_controller_UniqueIdentifier(t *testing.T) {
	controllerFromConfigs := func(t *testing.T, cc []Config) (*controller, error) {
		t.Helper()
		return newController(util.TestLogger(t), controllerConfig(cc), Globals{})
	}

	t.Run("different name, identifier", func(t *testing.T) {
		_, err := controllerFromConfigs(t, []Config{
			mockConfigNameTuple(t, "foo", "bar"),
			mockConfigNameTuple(t, "fizz", "buzz"),
		})
		require.NoError(t, err)
	})

	t.Run("same name, different identifier", func(t *testing.T) {
		_, err := controllerFromConfigs(t, []Config{
			mockConfigNameTuple(t, "foo", "bar"),
			mockConfigNameTuple(t, "foo", "buzz"),
		})
		require.NoError(t, err)
	})

	t.Run("same name, same identifier", func(t *testing.T) {
		_, err := controllerFromConfigs(t, []Config{
			mockConfigNameTuple(t, "foo", "bar"),
			mockConfigNameTuple(t, "foo", "bar"),
		})
		require.Error(t, err, `multiple instance names "bar" in integration "foo"`)
	})
}

// Test_controller_RunsIntegration ensures that integrations
// run.
func Test_controller_RunsIntegration(t *testing.T) {
	var wg sync.WaitGroup
	wg.Add(1)

	ctx, cancel := context.WithCancel(context.Background())

	ctrl, err := newController(
		util.TestLogger(t),
		controllerConfig{
			mockConfigForIntegration(t, FuncIntegration(func(ctx context.Context) error {
				defer wg.Done()
				cancel()
				<-ctx.Done()
				return nil
			})),
		},
		Globals{},
	)
	require.NoError(t, err, "failed to create controller")

	// Run the controller. The controller should immediately run our fake integration
	// which will cancel ctx and cause ctrl to exit.
	ctrl.run(ctx)

	// Make sure that our integration exited too.
	wg.Wait()
}

// Test_controller_ConfigChanges ensures that integrations only get restarted
// when configs are no longer equal.
func Test_controller_ConfigChanges(t *testing.T) {
	tc := func(t *testing.T, changed bool) (timesRan uint64) {
		t.Helper()

		var integrationsWg sync.WaitGroup
		var starts atomic.Uint64

		mockIntegration := FuncIntegration(func(ctx context.Context) error {
			integrationsWg.Done()
			starts.Inc()
			<-ctx.Done()
			return nil
		})

		cfg := controllerConfig{
			mockConfig{
				NameFunc:          func() string { return mockIntegrationName },
				ConfigEqualsFunc:  func(Config) bool { return !changed },
				ApplyDefaultsFunc: func(g Globals) error { return nil },
				IdentifierFunc: func(Globals) (string, error) {
					return mockIntegrationName, nil
				},
				NewIntegrationFunc: func(log.Logger, Globals) (Integration, error) {
					integrationsWg.Add(1)
					return mockIntegration, nil
				},
			},
		}

		globals := Globals{}
		ctrl, err := newController(util.TestLogger(t), cfg, globals)
		require.NoError(t, err, "failed to create controller")

		sc := newSyncController(t, ctrl)
		require.NoError(t, sc.UpdateController(cfg, globals), "failed to re-apply config")

		// Wait for our integrations to have been started
		integrationsWg.Wait()

		sc.Stop()
		return starts.Load()
	}

	t.Run("Unchanged", func(t *testing.T) {
		starts := tc(t, false)
		require.Equal(t, uint64(1), starts, "integration should only have started exactly once")
	})

	t.Run("Changed", func(t *testing.T) {
		starts := tc(t, true)
		require.Equal(t, uint64(2), starts, "integration should have started exactly twice")
	})
}

func Test_controller_SingletonCheck(t *testing.T) {
	var integrationsWg sync.WaitGroup
	var starts atomic.Uint64

	mockIntegration := FuncIntegration(func(ctx context.Context) error {
		integrationsWg.Done()
		starts.Inc()
		<-ctx.Done()
		return nil
	})
	c1 := mockConfig{
		NameFunc:          func() string { return mockIntegrationName },
		ConfigEqualsFunc:  func(Config) bool { return true },
		ApplyDefaultsFunc: func(g Globals) error { return nil },
		IdentifierFunc: func(Globals) (string, error) {
			return mockIntegrationName, nil
		},
		NewIntegrationFunc: func(log.Logger, Globals) (Integration, error) {
			integrationsWg.Add(1)
			return mockIntegration, nil
		},
	}
	configMap := make(map[Config]Type)
	configMap[&c1] = TypeSingleton
	setRegistered(t, configMap)
	cfg := controllerConfig{
		c1,
		c1,
	}

	globals := Globals{}
	_, err := newController(util.TestLogger(t), cfg, globals)
	require.Error(t, err)
	require.True(t, strings.Contains(err.Error(), `integration "mock" may only be defined once`))
}

type syncController struct {
	inner *controller
	pool  *workerPool
}

// newSyncController pairs an unstarted controller with a manually managed
// worker pool to synchronously apply integrations.
func newSyncController(t *testing.T, inner *controller) *syncController {
	t.Helper()

	sc := &syncController{
		inner: inner,
		pool:  newWorkerPool(context.Background(), inner.logger),
	}

	// There's always immediately one queued integration set from any
	// successfully created controller.
	sc.refresh()
	return sc
}

func (sc *syncController) refresh() {
	sc.inner.mut.Lock()
	defer sc.inner.mut.Unlock()

	newIntegrations := <-sc.inner.runIntegrations
	sc.pool.Reload(newIntegrations)
	sc.inner.integrations = newIntegrations
}

func (sc *syncController) UpdateController(c controllerConfig, g Globals) error {
	err := sc.inner.UpdateController(c, g)
	if err != nil {
		return err
	}
	sc.refresh()
	return nil
}

func (sc *syncController) Stop() {
	sc.pool.Close()
}

const mockIntegrationName = "mock"

type mockConfig struct {
	NameFunc           func() string
	ApplyDefaultsFunc  func(Globals) error
	ConfigEqualsFunc   func(Config) bool
	IdentifierFunc     func(Globals) (string, error)
	NewIntegrationFunc func(log.Logger, Globals) (Integration, error)
}

func (mc mockConfig) Name() string {
	return mc.NameFunc()
}

func (mc mockConfig) ConfigEquals(c Config) bool {
	if mc.ConfigEqualsFunc != nil {
		return mc.ConfigEqualsFunc(c)
	}
	return false
}

func (mc mockConfig) ApplyDefaults(g Globals) error {
	return mc.ApplyDefaultsFunc(g)
}

func (mc mockConfig) Identifier(g Globals) (string, error) {
	return mc.IdentifierFunc(g)
}

func (mc mockConfig) NewIntegration(l log.Logger, g Globals) (Integration, error) {
	return mc.NewIntegrationFunc(l, g)
}

func (mc mockConfig) WithNewIntegrationFunc(f func(log.Logger, Globals) (Integration, error)) mockConfig {
	return mockConfig{
		NameFunc:           mc.NameFunc,
		ApplyDefaultsFunc:  mc.ApplyDefaultsFunc,
		ConfigEqualsFunc:   mc.ConfigEqualsFunc,
		IdentifierFunc:     mc.IdentifierFunc,
		NewIntegrationFunc: f,
	}
}

func mockConfigNameTuple(t *testing.T, name, id string) mockConfig {
	t.Helper()

	return mockConfig{
		NameFunc:          func() string { return name },
		IdentifierFunc:    func(_ Globals) (string, error) { return id, nil },
		ApplyDefaultsFunc: func(g Globals) error { return nil },
		NewIntegrationFunc: func(log.Logger, Globals) (Integration, error) {
			return NoOpIntegration, nil
		},
	}
}

// mockConfigForIntegration returns a Config that will always return i.
func mockConfigForIntegration(t *testing.T, i Integration) mockConfig {
	t.Helper()

	return mockConfig{
		NameFunc:          func() string { return mockIntegrationName },
		ApplyDefaultsFunc: func(g Globals) error { return nil },
		IdentifierFunc: func(Globals) (string, error) {
			return mockIntegrationName, nil
		},
		NewIntegrationFunc: func(log.Logger, Globals) (Integration, error) {
			return i, nil
		},
	}
}

'''
'''--- pkg/integrations/v2/controller_updateintegration_test.go ---
package integrations

import (
	"context"
	"sync"
	"testing"

	"github.com/go-kit/log"
	"github.com/grafana/agent/pkg/util"
	"github.com/stretchr/testify/require"
	"go.uber.org/atomic"
)

//
// Tests for controller's utilization of the UpdateIntegration interface.
//

// Test_controller_UpdateIntegration ensures that the controller will call
// UpdateIntegration for integrations that support it.
func Test_controller_UpdateIntegration(t *testing.T) {
	var (
		integrationStartWg sync.WaitGroup
		applies, starts    atomic.Uint64
	)

	mockIntegration := mockUpdateIntegration{
		Integration: FuncIntegration(func(ctx context.Context) error {
			starts.Inc()
			integrationStartWg.Done()
			<-ctx.Done()
			return nil
		}),
		ApplyConfigFunc: func(Config, Globals) error {
			applies.Inc()
			return nil
		},
	}

	cfg := controllerConfig{
		mockConfig{
			NameFunc:          func() string { return mockIntegrationName },
			ConfigEqualsFunc:  func(Config) bool { return false },
			ApplyDefaultsFunc: func(g Globals) error { return nil },
			IdentifierFunc: func(Globals) (string, error) {
				return mockIntegrationName, nil
			},
			NewIntegrationFunc: func(log.Logger, Globals) (Integration, error) {
				integrationStartWg.Add(1)
				return mockIntegration, nil
			},
		},
	}

	ctrl, err := newController(util.TestLogger(t), cfg, Globals{})
	require.NoError(t, err, "failed to create controller")

	sc := newSyncController(t, ctrl)

	// Wait for our integration to start.
	integrationStartWg.Wait()

	// Try to apply again.
	require.NoError(t, sc.UpdateController(cfg, ctrl.globals), "failed to re-apply config")
	integrationStartWg.Wait()

	sc.Stop()

	require.Equal(t, uint64(1), applies.Load(), "dynamic reload should have occurred")
	require.Equal(t, uint64(1), starts.Load(), "restart should not have occurred")
}

type mockUpdateIntegration struct {
	Integration
	ApplyConfigFunc func(Config, Globals) error
}

func (m mockUpdateIntegration) ApplyConfig(c Config, g Globals) error {
	return m.ApplyConfigFunc(c, g)
}

'''
'''--- pkg/integrations/v2/eventhandler/eventhandler.go ---
// Package eventhandler watches for Kubernetes Event objects and hands them off to
// Agent's Logs subsystem (embedded promtail)
package eventhandler

import (
	"context"
	"encoding/json"
	"fmt"
	"io/ioutil"
	"os"
	"path/filepath"
	"strings"
	"sync"
	"time"

	v1 "k8s.io/api/core/v1"
	"k8s.io/client-go/informers"
	"k8s.io/client-go/kubernetes"
	"k8s.io/client-go/rest"
	"k8s.io/client-go/tools/cache"
	"k8s.io/client-go/tools/clientcmd"
	"k8s.io/client-go/util/homedir"

	"github.com/go-kit/log"
	"github.com/go-kit/log/level"
	"github.com/grafana/agent/pkg/integrations/v2"
	"github.com/grafana/agent/pkg/logs"
	"github.com/grafana/loki/clients/pkg/promtail/api"
	"github.com/grafana/loki/pkg/logproto"
	"github.com/prometheus/common/model"
	"github.com/prometheus/prometheus/model/labels"
)

const (
	cacheFileMode = 0600
)

// EventHandler watches for Kubernetes Event objects and hands them off to
// Agent's logs subsystem (embedded promtail).
type EventHandler struct {
	LogsClient    *logs.Logs
	LogsInstance  string
	Log           log.Logger
	CachePath     string
	LastEvent     *ShippedEvents
	InitEvent     *ShippedEvents
	EventInformer cache.SharedIndexInformer
	SendTimeout   time.Duration
	ticker        *time.Ticker
	instance      string
	extraLabels   labels.Labels
	sync.Mutex
}

// ShippedEvents stores a timestamp and map of event ResourceVersions shipped for that timestamp.
// Used to avoid double-shipping events upon restart.
type ShippedEvents struct {
	// shipped event's timestamp
	Timestamp time.Time `json:"ts"`
	// map of event RVs (resource versions) already "shipped" (handed off) for this timestamp.
	// this is to handle the case of a timestamp having multiple events,
	// which happens quite frequently.
	RvMap map[string]struct{} `json:"resourceVersion"`
}

func newEventHandler(l log.Logger, globals integrations.Globals, c *Config) (integrations.Integration, error) {
	var (
		config  *rest.Config
		err     error
		factory informers.SharedInformerFactory
		id      string
	)

	// Try using KubeconfigPath or inClusterConfig
	config, err = clientcmd.BuildConfigFromFlags("", c.KubeconfigPath)
	if err != nil {
		level.Error(l).Log("msg", "Loading from KubeconfigPath or inClusterConfig failed", "err", err)
		// Trying default home location
		if home := homedir.HomeDir(); home != "" {
			kubeconfigPath := filepath.Join(home, ".kube", "config")
			config, err = clientcmd.BuildConfigFromFlags("", kubeconfigPath)
			if err != nil {
				level.Error(l).Log("msg", "Could not load a kubeconfig", "err", err)
				return nil, err
			}
		} else {
			err = fmt.Errorf("could not load a kubeconfig")
			return nil, err
		}
	}

	clientset, err := kubernetes.NewForConfig(config)
	if err != nil {
		return nil, err
	}

	// get an informer
	if c.Namespace == "" {
		factory = informers.NewSharedInformerFactory(clientset, time.Duration(c.InformerResync)*time.Second)
	} else {
		factory = informers.NewSharedInformerFactoryWithOptions(clientset, time.Duration(c.InformerResync)*time.Second, informers.WithNamespace(c.Namespace))
	}

	eventInformer := factory.Core().V1().Events().Informer()
	id, _ = c.Identifier(globals)

	eh := &EventHandler{
		LogsClient:    globals.Logs,
		LogsInstance:  c.LogsInstance,
		Log:           l,
		CachePath:     c.CachePath,
		EventInformer: eventInformer,
		SendTimeout:   time.Duration(c.SendTimeout) * time.Second,
		instance:      id,
		extraLabels:   c.ExtraLabels,
	}
	// set the resource handler fns
	eh.initInformer(eventInformer)
	eh.ticker = time.NewTicker(time.Duration(c.FlushInterval) * time.Second)
	return eh, nil
}

// Initialize informer by setting event handler fns
func (eh *EventHandler) initInformer(eventsInformer cache.SharedIndexInformer) {
	eventsInformer.AddEventHandler(cache.ResourceEventHandlerFuncs{
		AddFunc:    eh.addEvent,
		UpdateFunc: eh.updateEvent,
		DeleteFunc: eh.deleteEvent,
	})
}

// Handles new event objects
func (eh *EventHandler) addEvent(obj interface{}) {
	event, _ := obj.(*v1.Event)

	err := eh.handleEvent(event)
	if err != nil {
		level.Error(eh.Log).Log("msg", "Error handling event", "err", err, "event", event)
	}
}

// Handles event object updates. Note that this get triggered on informer resyncs and also
// events occurring more than once (in which case .count is incremented)
func (eh *EventHandler) updateEvent(objOld interface{}, objNew interface{}) {
	eOld, _ := objOld.(*v1.Event)
	eNew, _ := objNew.(*v1.Event)

	if eOld.GetResourceVersion() == eNew.GetResourceVersion() {
		// ignore resync updates
		level.Debug(eh.Log).Log("msg", "Event RV didn't change, ignoring", "eRV", eNew.ResourceVersion)
		return
	}

	err := eh.handleEvent(eNew)
	if err != nil {
		level.Error(eh.Log).Log("msg", "Error handling event", "err", err, "event", eNew)
	}
}

func (eh *EventHandler) handleEvent(event *v1.Event) error {
	eventTs := getTimestamp(event)

	// if event is older than the one stored in cache on startup, we've shipped it
	if eventTs.Before(eh.InitEvent.Timestamp) {
		return nil
	}
	// if event is equal and is in map, we've shipped it
	if eventTs.Equal(eh.InitEvent.Timestamp) {
		if _, ok := eh.InitEvent.RvMap[event.ResourceVersion]; ok {
			return nil
		}
	}

	labels, msg, err := eh.extractEvent(event)
	if err != nil {
		return err
	}

	entry := newEntry(msg, eventTs, labels)
	ok := eh.LogsClient.Instance(eh.LogsInstance).SendEntry(entry, eh.SendTimeout)
	if !ok {
		err = fmt.Errorf("msg=%s entry=%s", "error handing entry off to promtail", entry)
		return err
	}
	level.Info(eh.Log).Log("msg", "Shipped entry", "eventRV", event.ResourceVersion, "eventMsg", event.Message)

	// update cache with new "last" event
	err = eh.updateLastEvent(event, eventTs)
	if err != nil {
		return err
	}
	return nil
}

// Called when event objects are removed from etcd, can safely ignore this
func (eh *EventHandler) deleteEvent(obj interface{}) {
}

// extract data from event fields and create labels, etc.
// TODO: ship JSON blobs and allow users to configure using pipelines etc.
// instead of hardcoding labels here
func (eh *EventHandler) extractEvent(event *v1.Event) (model.LabelSet, string, error) {
	var (
		msg    strings.Builder
		labels = make(model.LabelSet)
	)

	obj := event.InvolvedObject
	if obj.Name == "" {
		return nil, "", fmt.Errorf("no involved object for event")
	}
	msg.WriteString(fmt.Sprintf("name=%s ", obj.Name))

	labels[model.LabelName("namespace")] = model.LabelValue(obj.Namespace)
	// TODO(hjet) omit "kubernetes"
	labels[model.LabelName("job")] = model.LabelValue("integrations/kubernetes/eventhandler")
	labels[model.LabelName("instance")] = model.LabelValue(eh.instance)
	labels[model.LabelName("agent_hostname")] = model.LabelValue(eh.instance)
	for _, lbl := range eh.extraLabels {
		labels[model.LabelName(lbl.Name)] = model.LabelValue(lbl.Value)
	}

	// we add these fields to the log line to reduce label bloat and cardinality
	if obj.Kind != "" {
		msg.WriteString(fmt.Sprintf("kind=%s ", obj.Kind))
	}
	if event.Action != "" {
		msg.WriteString(fmt.Sprintf("action=%s ", event.Action))
	}
	if obj.APIVersion != "" {
		msg.WriteString(fmt.Sprintf("objectAPIversion=%s ", obj.APIVersion))
	}
	if obj.ResourceVersion != "" {
		msg.WriteString(fmt.Sprintf("objectRV=%s ", obj.ResourceVersion))
	}
	if event.ResourceVersion != "" {
		msg.WriteString(fmt.Sprintf("eventRV=%s ", event.ResourceVersion))
	}
	if event.ReportingInstance != "" {
		msg.WriteString(fmt.Sprintf("reportinginstance=%s ", event.ReportingInstance))
	}
	if event.ReportingController != "" {
		msg.WriteString(fmt.Sprintf("reportingcontroller=%s ", event.ReportingController))
	}
	if event.Source.Component != "" {
		msg.WriteString(fmt.Sprintf("sourcecomponent=%s ", event.Source.Component))
	}
	if event.Source.Host != "" {
		msg.WriteString(fmt.Sprintf("sourcehost=%s ", event.Source.Host))
	}
	if event.Reason != "" {
		msg.WriteString(fmt.Sprintf("reason=%s ", event.Reason))
	}
	if event.Type != "" {
		msg.WriteString(fmt.Sprintf("type=%s ", event.Type))
	}
	if event.Count != 0 {
		msg.WriteString(fmt.Sprintf("count=%d ", event.Count))
	}

	msg.WriteString(fmt.Sprintf("msg=%q", event.Message))

	return labels, msg.String(), nil
}

func getTimestamp(event *v1.Event) time.Time {
	if !event.LastTimestamp.IsZero() {
		return event.LastTimestamp.Time
	}
	return event.EventTime.Time
}

func newEntry(msg string, ts time.Time, labels model.LabelSet) api.Entry {
	entry := logproto.Entry{Timestamp: ts, Line: msg}
	return api.Entry{Labels: labels, Entry: entry}
}

// maintain "last event" state
func (eh *EventHandler) updateLastEvent(e *v1.Event, eventTs time.Time) error {
	eh.Lock()
	defer eh.Unlock()

	eventRv := e.ResourceVersion

	if eh.LastEvent == nil {
		// startup
		eh.LastEvent = &ShippedEvents{Timestamp: eventTs, RvMap: make(map[string]struct{})}
		eh.LastEvent.RvMap[eventRv] = struct{}{}
		return nil
	}

	// if timestamp is the same, add to map
	if eh.LastEvent != nil && eventTs.Equal(eh.LastEvent.Timestamp) {
		eh.LastEvent.RvMap[eventRv] = struct{}{}
		return nil
	}

	// if timestamp is different, create a new ShippedEvents struct
	eh.LastEvent = &ShippedEvents{Timestamp: eventTs, RvMap: make(map[string]struct{})}
	eh.LastEvent.RvMap[eventRv] = struct{}{}
	return nil
}

func (eh *EventHandler) writeOutLastEvent() error {
	level.Info(eh.Log).Log("msg", "Flushing last event to disk")

	eh.Lock()
	defer eh.Unlock()

	if eh.LastEvent == nil {
		level.Info(eh.Log).Log("msg", "No last event to flush, returning")
		return nil
	}

	temp := eh.CachePath + "-new"
	buf, err := json.Marshal(&eh.LastEvent)
	if err != nil {
		return err
	}

	err = ioutil.WriteFile(temp, buf, os.FileMode(cacheFileMode))
	if err != nil {
		return err
	}

	if err = os.Rename(temp, eh.CachePath); err != nil {
		return err
	}
	level.Info(eh.Log).Log("msg", "Flushed last event to disk")
	return nil
}

// RunIntegration runs the eventhandler integration
func (eh *EventHandler) RunIntegration(ctx context.Context) error {
	var wg sync.WaitGroup

	ctx, cancel := context.WithCancel(ctx)
	defer cancel()

	// Quick check to make sure logs instance exists
	if i := eh.LogsClient.Instance(eh.LogsInstance); i == nil {
		level.Error(eh.Log).Log("msg", "Logs instance not configured", "instance", eh.LogsInstance)
		cancel()
	}

	cacheDir := filepath.Dir(eh.CachePath)
	if err := os.MkdirAll(cacheDir, 0755); err != nil {
		level.Error(eh.Log).Log("msg", "Failed to create cache dir", "err", err)
		cancel()
	}

	// cache file to store events shipped (prevents double shipping on restart)
	cacheFile, err := os.OpenFile(eh.CachePath, os.O_RDWR|os.O_CREATE, cacheFileMode)
	if err != nil {
		level.Error(eh.Log).Log("msg", "Failed to open or create cache file", "err", err)
		cancel()
	}

	// attempt to read last timestamp from cache file into a ShippedEvents struct
	initEvent, err := readInitEvent(cacheFile, eh.Log)
	if err != nil {
		level.Error(eh.Log).Log("msg", "Failed to read last event from cache file", "err", err)
		cancel()
	}
	eh.InitEvent = initEvent

	if err = cacheFile.Close(); err != nil {
		level.Error(eh.Log).Log("msg", "Failed to close cache file", "err", err)
		cancel()
	}

	go func() {
		level.Info(eh.Log).Log("msg", "Waiting for cache to sync (initial List of events)")
		isSynced := cache.WaitForCacheSync(ctx.Done(), eh.EventInformer.HasSynced)
		if !isSynced {
			level.Error(eh.Log).Log("msg", "Failed to sync informer cache")
			// maybe want to bail here
			return
		}
		level.Info(eh.Log).Log("msg", "Informer cache synced")
	}()

	// start the informer
	// technically we should prob use the factory here, but since we
	// only have one informer atm, this likely doesn't matter
	go eh.EventInformer.Run(ctx.Done())

	// wait for last event to flush before returning
	wg.Add(1)
	go func() {
		defer wg.Done()
		eh.runTicker(ctx.Done())
	}()
	wg.Wait()

	return nil
}

// write out last event every FlushInterval
func (eh *EventHandler) runTicker(stopCh <-chan struct{}) {
	for {
		select {
		case <-stopCh:
			if err := eh.writeOutLastEvent(); err != nil {
				level.Error(eh.Log).Log("msg", "Failed to flush last event", "err", err)
			}
			return
		case <-eh.ticker.C:
			if err := eh.writeOutLastEvent(); err != nil {
				level.Error(eh.Log).Log("msg", "Failed to flush last event", "err", err)
			}
		}
	}
}

func readInitEvent(file *os.File, logger log.Logger) (*ShippedEvents, error) {
	var (
		initEvent = new(ShippedEvents)
	)

	stat, err := file.Stat()
	if err != nil {
		return nil, err
	}
	if stat.Size() == 0 {
		level.Info(logger).Log("msg", "Cache file empty, setting zero-valued initEvent")
		return initEvent, nil
	}

	dec := json.NewDecoder(file)
	err = dec.Decode(&initEvent)
	if err != nil {
		err = fmt.Errorf("could not read init event from cache: %s. Please delete the cache file", err)
		return nil, err
	}
	level.Info(logger).Log("msg", "Loaded init event from cache file", "initEventTime", initEvent.Timestamp)
	return initEvent, nil
}

'''
'''--- pkg/integrations/v2/eventhandler/eventhandler_test.go ---
package eventhandler

import (
	"os"
	"testing"
	"time"

	"github.com/go-kit/log"
	"github.com/stretchr/testify/require"
)

func TestCacheLoad(t *testing.T) {
	l := log.NewNopLogger()
	testTime, _ := time.Parse(time.RFC3339, "2022-01-26T13:39:40-05:00")
	expectedEvents := &ShippedEvents{
		Timestamp: testTime,
		RvMap:     map[string]struct{}{"58588": {}},
	}
	cacheFile, err := os.OpenFile("testdata/eventhandler.cache", os.O_RDWR|os.O_CREATE, cacheFileMode)
	require.NoError(t, err, "Failed to open test eventhandler cache file")
	actualEvents, err := readInitEvent(cacheFile, l)
	require.NoError(t, err, "Failed to parse last event from eventhandler cache file")
	require.Equal(t, expectedEvents, actualEvents)
}

'''
'''--- pkg/integrations/v2/eventhandler/integration.go ---
package eventhandler

import (
	"github.com/go-kit/log"
	"github.com/grafana/agent/pkg/integrations/v2"
	"github.com/prometheus/prometheus/model/labels"
)

// DefaultConfig sets defaults for Config
var DefaultConfig = Config{
	SendTimeout:    60,
	CachePath:      "./.eventcache/eventhandler.cache",
	LogsInstance:   "default",
	InformerResync: 120,
	FlushInterval:  10,
}

// Config configures the eventhandler integration
type Config struct {
	// Eventhandler hands watched events off to promtail using a promtail
	// client channel. This parameter configures how long to wait (in seconds) on the channel
	// before abandoning and moving on.
	SendTimeout int `yaml:"send_timeout,omitempty"`
	// Configures the path to a kubeconfig file. If not set, will fall back to using
	// an in-cluster config. If this fails, will fall back to checking the user's home
	// directory for a kubeconfig.
	KubeconfigPath string `yaml:"kubeconfig_path,omitempty"`
	// Path to a cache file that will store the last timestamp for a shipped event and events
	// shipped for that timestamp. Used to prevent double-shipping on integration restart.
	CachePath string `yaml:"cache_path,omitempty"`
	// Name of logs subsystem instance to hand log entries off to.
	LogsInstance string `yaml:"logs_instance,omitempty"`
	// K8s informer resync interval (seconds). You should use defaults here unless you are
	// familiar with K8s informers.
	InformerResync int `yaml:"informer_resync,omitempty"`
	// The integration will flush the last event shipped out to disk every flush_interval seconds.
	FlushInterval int `yaml:"flush_interval,omitempty"`
	// If you would like to limit events to a given namespace, use this parameter.
	Namespace string `yaml:"namespace,omitempty"`
	// Extra labels to append to log lines
	ExtraLabels labels.Labels `yaml:"extra_labels,omitempty"`
}

// UnmarshalYAML implements yaml.Unmarshaler for Config
func (c *Config) UnmarshalYAML(unmarshal func(interface{}) error) error {
	*c = DefaultConfig

	type plain Config
	return unmarshal((*plain)(c))
}

// Name returns the name of the integration that this config represents
func (c *Config) Name() string { return "eventhandler" }

// ApplyDefaults applies runtime-specific defaults to c
func (c *Config) ApplyDefaults(globals integrations.Globals) error {
	return nil
}

// Identifier uniquely identifies this instance of Config
func (c *Config) Identifier(globals integrations.Globals) (string, error) {
	return globals.AgentIdentifier, nil
}

// NewIntegration converts this config into an instance of an integration.
func (c *Config) NewIntegration(l log.Logger, globals integrations.Globals) (integrations.Integration, error) {
	return newEventHandler(l, globals, c)
}

func init() {
	integrations.Register(&Config{}, integrations.TypeSingleton)
}

'''
'''--- pkg/integrations/v2/integrations.go ---
// Package integrations provides a way to run and manage Grafana Agent
// "integrations," which integrate some external system (such as MySQL) to
// Grafana Agent's existing metrics, logging, and tracing subsystems.
//
// Integrations are implemented in sub-packages. Every integration must
// have an implementation of Config that configures the integration. The Config
// interface is then used to instantiate an instance of the Integration
// interface.
//
// Implementations of integrations implement extra functionality by
// implementing interface extensions. The Integration interface is the most
// basic interface that all integrations must implement. Extensions like
// the MetricsIntegration interface define an integration that supports
// metrics.
//
// Extension interfaces are used by the integrations subsystem to enable
// common use cases. New behaviors can be implemented by manually using
// the other subsystems of the agent provided in IntegrationOptions.
package integrations

import (
	"context"
	"fmt"
	"net/http"
	"net/url"

	"github.com/go-kit/log"
	"github.com/grafana/agent/pkg/integrations/v2/autoscrape"
	"github.com/grafana/agent/pkg/logs"
	"github.com/grafana/agent/pkg/metrics"
	"github.com/grafana/agent/pkg/server"
	"github.com/grafana/agent/pkg/traces"
	"github.com/prometheus/prometheus/discovery"
	"github.com/prometheus/prometheus/discovery/targetgroup"
)

var (
	// ErrInvalidUpdate is returned by ApplyConfig when the config cannot
	// be dynamically applied.
	ErrInvalidUpdate = fmt.Errorf("invalid dynamic update")
)

// Config provides a configuration and constructor for an integration.
type Config interface {
	// Name returns the YAML field name of the integration. Name is used
	// when unmarshaling the Config from YAML.
	Name() string

	// ApplyDefaults should apply default settings to Config.
	ApplyDefaults(Globals) error

	// Identifier returns a string to uniquely identify the integration created
	// by this Config. Identifier must be unique for each integration that shares
	// the same Name.
	//
	// If there is no reasonable identifier to use for an integration,
	// Globals.AgentIdentifier may be used by default.
	Identifier(Globals) (string, error)

	// NewIntegration should return a new Integration using the provided
	// Globals to help initialize the Integration.
	//
	// NewIntegration must be idempotent for a Config. Use
	// Integration.RunIntegration to do anything with side effects, such as
	// opening a port.
	NewIntegration(log.Logger, Globals) (Integration, error)
}

// ComparableConfig extends Config with an ConfigEquals method.
type ComparableConfig interface {
	Config

	// ConfigEquals should return true if c is equal to the ComparableConfig.
	ConfigEquals(c Config) bool
}

// Globals are used to pass around subsystem-wide settings that integrations
// can take advantage of.
type Globals struct {
	// AgentIdentifier provides an identifier for the running agent. This can
	// be used for labelling whenever appropriate.
	//
	// AgentIdentifier will be set to the hostname:port of the running agent.
	// TODO(rfratto): flag to override identifier at agent level?
	AgentIdentifier string

	// Some integrations may wish to interact with various subsystems for their
	// implementation if the desired behavior is not supported natively by the
	// integration manager.

	Metrics *metrics.Agent // Metrics subsystem
	Logs    *logs.Logs     // Logs subsystem
	Tracing *traces.Traces // Traces subsystem

	// Options the integations subsystem is using.
	SubsystemOpts SubsystemOptions
	// BaseURL to use to invoke methods against the embedded HTTP server.
	AgentBaseURL *url.URL
	// Dialer to use for making connections. May be nil.
	DialContextFunc server.DialContextFunc
}

// CloneAgentBaseURL returns a copy of AgentBaseURL that can be modified.
func (g Globals) CloneAgentBaseURL() *url.URL {
	if g.AgentBaseURL == nil {
		return nil
	}
	rawURL := g.AgentBaseURL.String()
	u, err := url.Parse(rawURL)
	if err != nil {
		// The URL shouldn't be invalid at this point
		panic(err)
	}
	return u
}

// An Integration integrates some external system with Grafana Agent's existing
// subsystems.
//
// All integrations must at least implement this interface. More behaviors
// can be added by implementing additional *Integration interfaces, such
// as HTTPIntegration.
type Integration interface {
	// RunIntegration starts the integration and performs background tasks. It
	// must not return until ctx is canceled, even if there is no work to do.
	//
	// An error will be returned if the integration failed. Integrations will
	// never return the ctx error.
	RunIntegration(ctx context.Context) error
}

// UpdateIntegration is an Integration whose config can be updated
// dynamically. Integrations that do not implement this interface will be shut
// down and re-instantiated with the new Config.
type UpdateIntegration interface {
	Integration

	// ApplyConfig should apply the config c to the integration. An error can be
	// returned if the Config is invalid. When this happens, the old config will
	// continue to run.
	//
	// If ApplyConfig returns ErrInvalidUpdate, the integration will be
	// recreated.
	ApplyConfig(c Config, g Globals) error
}

// HTTPIntegration is an integration that exposes an HTTP handler.
//
// Integrations are given a unique base path prefix where HTTP requests will be
// routed. The prefix chosen for an integration is not guaranteed to be
// predictable.
type HTTPIntegration interface {
	Integration

	// Handler returns an http.Handler. Handler will be invoked for any endpoint
	// under prefix. If Handler returns nil, nothing will be called. Handler
	// may be called multiple times.
	//
	// prefix will not be removed from the HTTP request by default.
	Handler(prefix string) (http.Handler, error)
}

// MetricsIntegration is an integration that exposes Prometheus scrape targets.
//
// It is assumed, but not required, that HTTPIntegration is also implemented
// to expose metrics. See HTTPIntegration for more information about how
// HTTP works with integrations.
type MetricsIntegration interface {
	HTTPIntegration

	// Targets should return the current set of active targets exposed by this
	// integration. Targets may be called multiple times throughout the lifecycle
	// of the integration. Targets will not be called when the integration is not
	// running.
	//
	// prefix will be the same prefixed passed to HTTPIntegration.Handler and
	// can be used to update __metrics_path__ for targets.
	Targets(ep Endpoint) []*targetgroup.Group

	// ScrapeConfigs configures automatic scraping of targets. ScrapeConfigs
	// is optional if an integration should not scrape itself.
	//
	// Unlike Targets, ScrapeConfigs is only called once per config load, and may be
	// called before the integration runs. Use the provided discovery.Configs to
	// discover the targets exposed by this integration.
	ScrapeConfigs(discovery.Configs) []*autoscrape.ScrapeConfig
}

// Endpoint is a location where something is exposed.
type Endpoint struct {
	// Hostname (and optional port) where endpoint is exposed.
	Host string
	// Base prefix of the endpoint.
	Prefix string
}

'''
'''--- pkg/integrations/v2/metricsutils/metricshandler_integration.go ---
package metricsutils

import (
	"context"
	"fmt"
	"net/http"
	"path"

	"github.com/go-kit/log"
	"github.com/gorilla/mux"
	"github.com/grafana/agent/pkg/integrations/v2"
	"github.com/grafana/agent/pkg/integrations/v2/autoscrape"
	"github.com/grafana/agent/pkg/integrations/v2/common"
	"github.com/prometheus/common/model"
	"github.com/prometheus/prometheus/config"
	"github.com/prometheus/prometheus/discovery"
	"github.com/prometheus/prometheus/discovery/targetgroup"
)

// NewMetricsHandlerIntegration returns a integrations.MetricsIntegration which
// will expose a /metrics endpoint for h.
func NewMetricsHandlerIntegration(
	_ log.Logger,
	c integrations.Config,
	mc common.MetricsConfig,
	globals integrations.Globals,
	h http.Handler,
) (integrations.MetricsIntegration, error) {

	id, err := c.Identifier(globals)
	if err != nil {
		return nil, err
	}
	return &metricsHandlerIntegration{
		integrationName: c.Name(),
		instanceID:      id,

		common:  mc,
		globals: globals,
		handler: h,

		targets: []handlerTarget{{MetricsPath: "metrics"}},
	}, nil
}

type metricsHandlerIntegration struct {
	integrationName, instanceID string

	common  common.MetricsConfig
	globals integrations.Globals
	handler http.Handler
	targets []handlerTarget

	runFunc func(ctx context.Context) error
}

type handlerTarget struct {
	// Path relative to Handler prefix where metrics are available.
	MetricsPath string
	// Extra labels to inject into the target. Labels here that take precedence
	// over labels with the same name from the generated target group.
	Labels model.LabelSet
}

// Static typecheck tests
var (
	_ integrations.Integration        = (*metricsHandlerIntegration)(nil)
	_ integrations.HTTPIntegration    = (*metricsHandlerIntegration)(nil)
	_ integrations.MetricsIntegration = (*metricsHandlerIntegration)(nil)
)

// RunIntegration implements Integration.
func (i *metricsHandlerIntegration) RunIntegration(ctx context.Context) error {
	// Call our runFunc if defined (used from integrationShim), otherwise
	// fallback to no-op.
	if i.runFunc != nil {
		return i.runFunc(ctx)
	}

	<-ctx.Done()
	return nil
}

// Handler implements HTTPIntegration.
func (i *metricsHandlerIntegration) Handler(prefix string) (http.Handler, error) {
	r := mux.NewRouter()
	r.Handle(path.Join(prefix, "metrics"), i.handler)
	return r, nil
}

// Targets implements MetricsIntegration.
func (i *metricsHandlerIntegration) Targets(ep integrations.Endpoint) []*targetgroup.Group {
	integrationNameValue := model.LabelValue("integrations/" + i.integrationName)

	group := &targetgroup.Group{
		Labels: model.LabelSet{
			model.InstanceLabel: model.LabelValue(i.instanceID),
			model.JobLabel:      integrationNameValue,
			"agent_hostname":    model.LabelValue(i.globals.AgentIdentifier),

			// Meta labels that can be used during SD.
			"__meta_agent_integration_name":       model.LabelValue(i.integrationName),
			"__meta_agent_integration_instance":   model.LabelValue(i.instanceID),
			"__meta_agent_integration_autoscrape": model.LabelValue(BoolToString(*i.common.Autoscrape.Enable)),
		},
		Source: fmt.Sprintf("%s/%s", i.integrationName, i.instanceID),
	}

	for _, lbl := range i.common.ExtraLabels {
		group.Labels[model.LabelName(lbl.Name)] = model.LabelValue(lbl.Value)
	}

	for _, t := range i.targets {
		group.Targets = append(group.Targets, model.LabelSet{
			model.AddressLabel:     model.LabelValue(ep.Host),
			model.MetricsPathLabel: model.LabelValue(path.Join(ep.Prefix, t.MetricsPath)),
		}.Merge(t.Labels))
	}

	return []*targetgroup.Group{group}
}

// BoolToString is a helper for converting boolean values to a Prometheus labels-compatible string.
func BoolToString(b bool) string {
	switch b {
	case true:
		return "1"
	default:
		return "0"
	}
}

// ScrapeConfigs implements MetricsIntegration.
func (i *metricsHandlerIntegration) ScrapeConfigs(sd discovery.Configs) []*autoscrape.ScrapeConfig {
	if !*i.common.Autoscrape.Enable {
		return nil
	}

	cfg := config.DefaultScrapeConfig
	cfg.JobName = fmt.Sprintf("%s/%s", i.integrationName, i.instanceID)
	cfg.Scheme = i.globals.AgentBaseURL.Scheme
	cfg.ServiceDiscoveryConfigs = sd
	cfg.ScrapeInterval = i.common.Autoscrape.ScrapeInterval
	cfg.ScrapeTimeout = i.common.Autoscrape.ScrapeTimeout
	cfg.RelabelConfigs = i.common.Autoscrape.RelabelConfigs
	cfg.MetricRelabelConfigs = i.common.Autoscrape.MetricRelabelConfigs

	return []*autoscrape.ScrapeConfig{{
		Instance: i.common.Autoscrape.MetricsInstance,
		Config:   cfg,
	}}
}

'''
'''--- pkg/integrations/v2/metricsutils/metricshandler_integration_test.go ---
package metricsutils

import (
	"fmt"
	"net/http"
	"net/url"
	"testing"

	"github.com/go-kit/log"
	"github.com/grafana/agent/pkg/integrations/v2"
	"github.com/grafana/agent/pkg/integrations/v2/common"
	"github.com/prometheus/common/model"
	"github.com/prometheus/prometheus/discovery/targetgroup"
	"github.com/prometheus/prometheus/model/labels"
	"github.com/stretchr/testify/require"
)

func TestMetricsHandlerIntegration_Targets(t *testing.T) {
	globals := integrations.Globals{
		AgentIdentifier: "testagent",
		AgentBaseURL: func() *url.URL {
			u, err := url.Parse("http://testagent/")
			require.NoError(t, err)
			return u
		}(),
		SubsystemOpts: integrations.DefaultSubsystemOptions,
	}

	t.Run("Targets", func(t *testing.T) {
		var cfg common.MetricsConfig
		cfg.ApplyDefaults(globals.SubsystemOpts.Metrics.Autoscrape)

		i, err := NewMetricsHandlerIntegration(nil, fakeConfig{}, cfg, globals, http.NotFoundHandler())
		require.NoError(t, err)

		actual := i.Targets(integrations.Endpoint{Host: "test", Prefix: "/test/"})
		expect := []*targetgroup.Group{{
			Source: "fake/testagent",
			Labels: model.LabelSet{
				"instance":       "testagent",
				"job":            "integrations/fake",
				"agent_hostname": "testagent",

				"__meta_agent_integration_name":       "fake",
				"__meta_agent_integration_instance":   "testagent",
				"__meta_agent_integration_autoscrape": "1",
			},
			Targets: []model.LabelSet{{
				"__address__":      "test",
				"__metrics_path__": "/test/metrics",
			}},
		}}
		require.Equal(t, expect, actual)

		t.Run("Extra labels", func(t *testing.T) {
			cfg := common.MetricsConfig{
				ExtraLabels: labels.FromMap(map[string]string{"foo": "bar", "fizz": "buzz"}),
			}
			cfg.ApplyDefaults(globals.SubsystemOpts.Metrics.Autoscrape)

			i, err := NewMetricsHandlerIntegration(nil, fakeConfig{}, cfg, globals, http.NotFoundHandler())
			require.NoError(t, err)
			actual := i.Targets(integrations.Endpoint{Host: "test", Prefix: "/test/"})
			require.Len(t, actual, 1)

			for _, lbl := range cfg.ExtraLabels {
				val, ok := actual[0].Labels[model.LabelName(lbl.Name)]
				require.True(t, ok, "target does not have extra label %s", lbl.Name)
				require.Equal(t, lbl.Value, string(val), "extra label %s does not match expectation", lbl.Name)
			}
		})
	})
}

type fakeConfig struct{}

func (fakeConfig) Name() string                                      { return "fake" }
func (fakeConfig) ApplyDefaults(_ integrations.Globals) error        { return nil }
func (fakeConfig) Identifier(g integrations.Globals) (string, error) { return g.AgentIdentifier, nil }
func (fakeConfig) NewIntegration(_ log.Logger, _ integrations.Globals) (integrations.Integration, error) {
	return nil, fmt.Errorf("not implemented")
}

'''
'''--- pkg/integrations/v2/metricsutils/versionshim.go ---
package metricsutils

import (
	"context"
	"errors"
	"fmt"
	"net/http"

	"github.com/go-kit/log"
	"github.com/prometheus/common/model"

	v1 "github.com/grafana/agent/pkg/integrations"
	v2 "github.com/grafana/agent/pkg/integrations/v2"
	"github.com/grafana/agent/pkg/integrations/v2/common"
	"github.com/grafana/agent/pkg/util"
)

// NewNamedShim returns a v2.UpgradeFunc which will upgrade a v1.Config to a
// v2.Config with a new name.
func NewNamedShim(newName string) v2.UpgradeFunc {
	return func(before v1.Config, common common.MetricsConfig) v2.UpgradedConfig {
		return &configShim{
			orig:         before,
			common:       common,
			nameOverride: newName,
		}
	}
}

// Shim upgrades a v1.Config to a v2.Config. The resulting config is NOT
// registered. Shim matches the v2.UpgradeFunc type.
func Shim(before v1.Config, common common.MetricsConfig) (after v2.UpgradedConfig) {
	return &configShim{orig: before, common: common}
}

type configShim struct {
	orig         v1.Config
	common       common.MetricsConfig
	nameOverride string
}

var (
	_ v2.Config           = (*configShim)(nil)
	_ v2.UpgradedConfig   = (*configShim)(nil)
	_ v2.ComparableConfig = (*configShim)(nil)
)

func (s *configShim) LegacyConfig() (v1.Config, common.MetricsConfig) { return s.orig, s.common }

func (s *configShim) Name() string {
	if s.nameOverride != "" {
		return s.nameOverride
	}
	return s.orig.Name()
}

func (s *configShim) ApplyDefaults(g v2.Globals) error {
	s.common.ApplyDefaults(g.SubsystemOpts.Metrics.Autoscrape)
	if id, err := s.Identifier(g); err == nil {
		s.common.InstanceKey = &id
	}
	return nil
}

func (s *configShim) ConfigEquals(c v2.Config) bool {
	o, ok := c.(*configShim)
	if !ok {
		return false
	}
	return util.CompareYAML(s.orig, o.orig) && util.CompareYAML(s.common, o.common)
}

func (s *configShim) Identifier(g v2.Globals) (string, error) {
	if s.common.InstanceKey != nil {
		return *s.common.InstanceKey, nil
	}
	return s.orig.InstanceKey(g.AgentIdentifier)
}

func (s *configShim) NewIntegration(l log.Logger, g v2.Globals) (v2.Integration, error) {
	v1Integration, err := s.orig.NewIntegration(l)
	if err != nil {
		return nil, err
	}

	id, err := s.Identifier(g)
	if err != nil {
		return nil, err
	}

	// Generate our handler. Original integrations didn't accept a prefix, and
	// just assumed that they would be wired to /metrics somewhere.
	handler, err := v1Integration.MetricsHandler()
	if err != nil {
		return nil, fmt.Errorf("generating http handler: %w", err)
	} else if handler == nil {
		handler = http.NotFoundHandler()
	}

	// Generate targets. Original integrations used a static set of targets,
	// so this mapping can always be generated just once.
	//
	// Targets are generated from the result of ScrapeConfigs(), which returns a
	// tuple of job name and relative metrics path.
	//
	// Job names were prefixed at the subsystem level with integrations/, so we
	// will retain that behavior here.
	v1ScrapeConfigs := v1Integration.ScrapeConfigs()
	targets := make([]handlerTarget, 0, len(v1ScrapeConfigs))
	for _, sc := range v1ScrapeConfigs {
		targets = append(targets, handlerTarget{
			MetricsPath: sc.MetricsPath,
			Labels: model.LabelSet{
				model.JobLabel: model.LabelValue("integrations/" + sc.JobName),
			},
		})
	}

	// Convert he run function. Original integrations sometimes returned
	// ctx.Err() on exit. This isn't recommended anymore, but we need to hide the
	// error if it happens, since the error was previously ignored.
	runFunc := func(ctx context.Context) error {
		err := v1Integration.Run(ctx)
		switch {
		case err == nil:
			return nil
		case errors.Is(err, context.Canceled) && ctx.Err() != nil:
			// Hide error that no longer happens in newer integrations.
			return nil
		default:
			return err
		}
	}

	// Aggregate our converted settings into a v2 integration.
	return &metricsHandlerIntegration{
		integrationName: s.Name(),
		instanceID:      id,

		common:  s.common,
		globals: g,
		handler: handler,
		targets: targets,

		runFunc: runFunc,
	}, nil
}

'''
'''--- pkg/integrations/v2/register.go ---
package integrations

import (
	"fmt"
	"reflect"
	"strings"
	"testing"

	"gopkg.in/yaml.v2"

	v1 "github.com/grafana/agent/pkg/integrations"
	"github.com/grafana/agent/pkg/integrations/v2/common"
	"github.com/grafana/agent/pkg/util"
)

var (
	integrationByName = make(map[string]interface{})  // Cache of field names for uniqueness checking.
	integrationTypes  = make(map[reflect.Type]Type)   // Map of registered type to Type
	nameByType        = make(map[reflect.Type]string) // Map of Type to registered name

	// Registered integrations. Registered integrations may be either a Config or
	// a v1.Config. v1.Configs must have a corresponding upgrader for their type.
	registered = []interface{}{}
	upgraders  = make(map[reflect.Type]UpgradeFunc)

	emptyStructType = reflect.TypeOf(struct{}{})
	configsType     = reflect.TypeOf(Configs{})
)

// Register dynamically registers a new integration. The Config
// will represent the configuration that controls the specific integration.
// Registered Configs may be loaded using UnmarshalYAML or manually
// constructed.
//
// ty controls how the integration can be unmarshaled from YAML.
//
// Register panics if cfg is not a pointer.
func Register(cfg Config, ty Type) {
	registerIntegration(cfg, cfg.Name(), ty, nil)
}

func registerIntegration(v interface{}, name string, ty Type, upgrader UpgradeFunc) {
	if reflect.TypeOf(v).Kind() != reflect.Ptr {
		panic(fmt.Sprintf("Register must be given a pointer, got %T", v))
	}
	if _, exist := integrationByName[name]; exist {
		panic(fmt.Sprintf("Integration %q registered twice", name))
	}
	integrationByName[name] = v

	registered = append(registered, v)

	configTy := reflect.TypeOf(v)
	integrationTypes[configTy] = ty
	upgraders[configTy] = upgrader
	nameByType[configTy] = name
}

// RegisterLegacy registers a v1.Config. upgrader will be used to upgrade it.
// upgrader will only be invoked after unmarshaling cfg from YAML, and the
// upgraded Config will be unwrapped again when marshaling back to YAML.
//
// RegisterLegacy only exists for the transition period where the v2
// integrations subsystem is an experiment. RegisterLegacy will be removed at a
// later date.
func RegisterLegacy(cfg v1.Config, ty Type, upgrader UpgradeFunc) {
	realConfig := upgrader(cfg, common.MetricsConfig{})
	registerIntegration(cfg, realConfig.Name(), ty, upgrader)
}

// UpgradeFunc upgrades cfg to a UpgradedConfig.
type UpgradeFunc func(cfg v1.Config, common common.MetricsConfig) UpgradedConfig

// UpgradedConfig is a v2 Config that was constructed through a legacy
// v1.Config. It allows unwrapping to retrieve the original config for
// the purposes of marshaling or unmarshaling.
type UpgradedConfig interface {
	Config

	// LegacyConfig returns the old v1.Config.
	LegacyConfig() (v1.Config, common.MetricsConfig)
}

// Type determines a specific type of integration.
type Type int

const (
	// TypeInvalid is an invalid type.
	TypeInvalid Type = iota

	// TypeSingleton is an integration that can only be defined exactly once in
	// the config, unmarshaled through "<integration name>"
	TypeSingleton

	// TypeMultiplex is an integration that can only be defined through an array,
	// unmarshaled through "<integration name>_configs"
	TypeMultiplex

	// TypeEither is an integration that can be unmarshaled either as a singleton
	// or as an array, but not both.
	//
	// Deprecated. Use either TypeSingleton or TypeMultiplex for new integrations.
	TypeEither
)

// setRegistered is used by tests to temporarily set integrations. Registered
// integrations will be unregistered after the test completes.
//
// setRegistered must not be used with parallelized tests.
func setRegistered(t *testing.T, cc map[Config]Type) {
	clear := func() {
		integrationByName = make(map[string]interface{})
		integrationTypes = make(map[reflect.Type]Type)
		registered = registered[:0]
		upgraders = make(map[reflect.Type]UpgradeFunc)
		nameByType = make(map[reflect.Type]string)
	}

	t.Cleanup(clear)
	clear()

	for c, t := range cc {
		Register(c, t)
	}
}

// Registered all Configs that were passed to Register or RegisterLegacy. Each
// call will generate a new set of configs.
func Registered() []Config {
	res := make([]Config, 0, len(registered))
	for _, r := range registered {
		res = append(res, cloneConfig(r))
	}
	return res
}

// RegisteredType returns the registered integrations.Type for c.
func RegisteredType(c Config) (Type, bool) {
	// We want to look up the registered type. Integrations are always registered
	// as pointers, so we need to add indirection here if a non-pointer is loaded
	// into the subsystem.
	cType := reflect.TypeOf(c)
	if cType.Kind() != reflect.Ptr {
		cType = reflect.PtrTo(cType)
	}

	t, ok := integrationTypes[cType]
	return t, ok
}

func cloneConfig(r interface{}) Config {
	switch v := r.(type) {
	case Config:
		return cloneValue(v).(Config)
	case v1.Config:
		mut, ok := upgraders[reflect.TypeOf(v)]
		if !ok || mut == nil {
			panic(fmt.Sprintf("Could not find transformer for legacy integration %T", r))
		}
		return mut(cloneValue(r).(v1.Config), common.MetricsConfig{})
	default:
		panic(fmt.Sprintf("unexpected type %T", r))
	}
}

func cloneValue(in interface{}) interface{} {
	return reflect.New(reflect.TypeOf(in).Elem()).Interface()
}

// Configs is a list of integrations. Note that Configs does not implement
// yaml.Unmarshaler or yaml.Marshaler. Use the UnmarshalYAML or MarshalYAML
// methods to deal with integrations defined from YAML.
type Configs []Config

// MarshalYAML helps implement yaml.Marshaler for structs that have a Configs
// field that should be inlined in the YAML string.
func MarshalYAML(v interface{}) (interface{}, error) {
	inVal := reflect.ValueOf(v)
	for inVal.Kind() == reflect.Ptr {
		inVal = inVal.Elem()
	}
	if inVal.Kind() != reflect.Struct {
		return nil, fmt.Errorf("integrations: can only marshal a struct, got %T", v)
	}
	inType := inVal.Type()

	var (
		outType    = getConfigTypeForIntegrations(inType)
		outPointer = reflect.New(outType)
		outVal     = outPointer.Elem()
	)

	// Copy over any existing value from inVal to cfgVal.
	//
	// The ordering of fields in inVal and cfgVal match identically up until the
	// extra fields appended to the end of cfgVal.
	var configs Configs
	for i, n := 0, inType.NumField(); i < n; i++ {
		if inType.Field(i).Type == configsType {
			configs = inVal.Field(i).Interface().(Configs)
			if configs == nil {
				configs = Configs{}
			}
		}
		if outType.Field(i).PkgPath != "" {
			continue // Field is unexported: ignore.
		}
		outVal.Field(i).Set(inVal.Field(i))
	}
	if configs == nil {
		return nil, fmt.Errorf("integrations: Configs field not found in type: %T", v)
	}

	// Map of discovered singleton integration names. A singleton integration may
	// not be defined in Configs more than once.
	uniqueSingletons := make(map[string]struct{})

	for _, c := range configs {
		fieldName := c.Name()

		var data interface{} = c
		if wc, ok := c.(UpgradedConfig); ok {
			data, _ = wc.LegacyConfig()
		}

		integrationType, ok := integrationTypes[reflect.TypeOf(data)]
		if !ok {
			panic(fmt.Sprintf("config not registered: %T", data))
		}

		if _, exists := uniqueSingletons[fieldName]; exists {
			return nil, fmt.Errorf("integration %q may not be defined more than once", fieldName)
		}
		uniqueSingletons[fieldName] = struct{}{}

		// TODO(rfratto): make sure that TypeSingleton integrations are unique on
		// marshaling out

		// Generate the *util.RawYAML to marshal out with.
		var (
			bb  []byte
			err error
		)
		switch v := c.(type) {
		case UpgradedConfig:
			inner, common := v.LegacyConfig()
			bb, err = util.MarshalYAMLMerged(common, inner)
		default:
			bb, err = yaml.Marshal(v)
		}
		if err != nil {
			return nil, fmt.Errorf("failed to marshal integration %q: %w", fieldName, err)
		}
		raw := util.RawYAML(bb)

		switch integrationType {
		case TypeSingleton:
			field := outVal.FieldByName("XXX_Config_" + fieldName)
			field.Set(reflect.ValueOf(&raw))
		case TypeMultiplex, TypeEither:
			field := outVal.FieldByName("XXX_Configs_" + fieldName)
			field.Set(reflect.Append(field, reflect.ValueOf(&raw)))
		}
	}

	return outPointer.Interface(), nil
}

// UnmarshalYAML helps implement yaml.Unmarshaller for structs that have a
// Configs field that should be inlined in the YAML string. Code adapted from
// Prometheus:
//
//   https://github.com/prometheus/prometheus/blob/511511324adfc4f4178f064cc104c2deac3335de/discovery/registry.go#L111
func UnmarshalYAML(out interface{}, unmarshal func(interface{}) error) error {
	outVal := reflect.ValueOf(out)
	if outVal.Kind() != reflect.Ptr {
		return fmt.Errorf("integrations: can only unmarshal into a struct pointer, got %T", out)
	}
	outVal = outVal.Elem()
	if outVal.Kind() != reflect.Struct {
		return fmt.Errorf("integrations: can only unmarshal into a struct pointer, got %T", out)
	}
	outType := outVal.Type()

	var (
		cfgType    = getConfigTypeForIntegrations(outType)
		cfgPointer = reflect.New(cfgType)
		cfgVal     = cfgPointer.Elem()
	)

	// Copy over any existing value from outVal to cfgVal.
	//
	// The ordering of fields in outVal and cfgVal match identically up until the
	// extra fields appended to the end of cfgVal.
	var configs *Configs
	for i := 0; i < outVal.NumField(); i++ {
		if outType.Field(i).Type == configsType {
			if configs != nil {
				return fmt.Errorf("integrations: Multiple Configs fields found in %T", out)
			}
			configs = outVal.Field(i).Addr().Interface().(*Configs)
			continue
		}
		if cfgType.Field(i).PkgPath != "" {
			// Ignore unexported fields
			continue
		}
		cfgVal.Field(i).Set(outVal.Field(i))
	}
	if configs == nil {
		return fmt.Errorf("integrations: No Configs field found in %T", out)
	}

	// Unmarshal into our dynamic type.
	if err := unmarshal(cfgPointer.Interface()); err != nil {
		return replaceYAMLTypeError(err, cfgType, outType)
	}

	// Copy back unmarshaled fields that were originally in outVal.
	for i := 0; i < outVal.NumField(); i++ {
		if cfgType.Field(i).PkgPath != "" {
			// Ignore unexported fields
			continue
		}
		outVal.Field(i).Set(cfgVal.Field(i))
	}

	// Iterate through the remainder of our fields, which should all be
	// either a Config or a slice of types that implement Config.
	for i := outVal.NumField(); i < cfgVal.NumField(); i++ {
		// Our integrations are unmarshaled as *util.RawYAML or []*util.RawYAML. If
		// it's nil, we treat it as not defined.
		fieldType := cfgVal.Type().Field(i)
		field := cfgVal.Field(i)
		if field.IsNil() {
			continue
		}

		switch field.Kind() {
		case reflect.Slice:
			configName := strings.TrimPrefix(fieldType.Name, "XXX_Configs_")
			configReference, ok := integrationByName[configName]
			if !ok {
				return fmt.Errorf("integration %q not registered", configName)
			}

			for i := 0; i < field.Len(); i++ {
				if field.Index(i).IsNil() {
					continue
				}
				raw := field.Index(i).Interface().(*util.RawYAML)
				c, err := deferredConfigUnmarshal(*raw, configReference)
				if err != nil {
					return err
				}
				*configs = append(*configs, c)
			}
		default:
			configName := strings.TrimPrefix(fieldType.Name, "XXX_Config_")
			configReference, ok := integrationByName[configName]
			if !ok {
				return fmt.Errorf("integration %q not registered", configName)
			}
			raw := field.Interface().(*util.RawYAML)
			c, err := deferredConfigUnmarshal(*raw, configReference)
			if err != nil {
				return err
			}
			*configs = append(*configs, c)
		}
	}

	return nil
}

// deferredConfigUnmarshal performs a deferred unmarshal of raw into a Config.
// ref must be either Config or v1.Config.
func deferredConfigUnmarshal(raw util.RawYAML, ref interface{}) (Config, error) {
	switch ref := ref.(type) {
	case Config:
		out := cloneValue(ref).(Config)
		err := yaml.UnmarshalStrict(raw, out)
		return out, err
	case v1.Config:
		var (
			common common.MetricsConfig
			out    = cloneValue(ref).(v1.Config)
		)
		mut, ok := upgraders[reflect.TypeOf(out)]
		if !ok {
			panic(fmt.Sprintf("unexpected type %T", ref))
		}
		err := util.UnmarshalYAMLMerged(raw, &common, out)
		return mut(out, common), err
	default:
		panic(fmt.Sprintf("unexpected type %T", ref))
	}
}

// getConfigTypeForIntegrations returns a dynamic struct type that has all of
// the same fields as out including the fields for the provided integrations.
//
// integrations are unmarshaled to *util.RawYAML for deferred unmarshaling.
func getConfigTypeForIntegrations(out reflect.Type) reflect.Type {
	// Initial exported fields map one-to-one.
	var fields []reflect.StructField
	for i, n := 0, out.NumField(); i < n; i++ {
		switch field := out.Field(i); {
		case field.PkgPath == "" && field.Type != configsType:
			fields = append(fields, field)
		default:
			fields = append(fields, reflect.StructField{
				Name:    "_" + field.Name, // Field must be unexported.
				PkgPath: out.PkgPath(),
				Type:    emptyStructType,
			})
		}
	}

	for _, reg := range registered {
		// Fields use a prefix that's unlikely to collide with anything else.
		configTy := reflect.TypeOf(reg)
		fieldName := nameByType[configTy]

		singletonType := reflect.PtrTo(reflect.TypeOf(util.RawYAML{}))

		fields = append(fields, reflect.StructField{
			Name: "XXX_Config_" + fieldName,
			Tag:  reflect.StructTag(fmt.Sprintf(`yaml:"%s,omitempty"`, fieldName)),
			Type: singletonType,
		})
		fields = append(fields, reflect.StructField{
			Name: "XXX_Configs_" + fieldName,
			Tag:  reflect.StructTag(fmt.Sprintf(`yaml:"%s_configs,omitempty"`, fieldName)),
			Type: reflect.SliceOf(singletonType),
		})
	}
	return reflect.StructOf(fields)
}

func replaceYAMLTypeError(err error, oldTyp, newTyp reflect.Type) error {
	if e, ok := err.(*yaml.TypeError); ok {
		oldStr := oldTyp.String()
		newStr := newTyp.String()
		for i, s := range e.Errors {
			e.Errors[i] = strings.ReplaceAll(s, oldStr, newStr)
		}
	}
	return err
}

'''
'''--- pkg/integrations/v2/register_test.go ---
package integrations

import (
	"testing"
	"time"

	"github.com/go-kit/log"
	v1 "github.com/grafana/agent/pkg/integrations"
	"github.com/grafana/agent/pkg/integrations/v2/common"
	"github.com/stretchr/testify/require"
	"gopkg.in/yaml.v2"
)

func TestIntegrationRegistration(t *testing.T) {
	setRegistered(t, map[Config]Type{
		&testIntegrationA{}: TypeEither,
		&testIntegrationB{}: TypeEither,
	})

	// This test checks for a few things:
	//
	// 1. Registered integrations will be parseable
	// 2. Registered integrations that are not present will not be unmarshaled to
	//    the list of configs
	// 3. Registered integrations that have defaults may still be parsed
	// 4. Strict parsing should still work as expected.

	var cfgToParse = `
name: John Doe
duration: 500ms
test:
  text: Hello, world!
`

	var fullCfg testFullConfig
	err := yaml.UnmarshalStrict([]byte(cfgToParse), &fullCfg)
	require.NoError(t, err)

	expect := testFullConfig{
		Name:     "John Doe",
		Duration: 500 * time.Millisecond,
		Default:  12345,
		Configs: []Config{
			&testIntegrationA{Text: "Hello, world!", Truth: true},
		},
	}
	require.Equal(t, expect, fullCfg)
}

func TestIntegrationRegistration_Multiple(t *testing.T) {
	setRegistered(t, map[Config]Type{
		&testIntegrationA{}: TypeEither,
		&testIntegrationB{}: TypeEither,
	})

	var cfgToParse = `
name: John Doe
duration: 500ms
test_configs:
  - text: Hello, world!
  - text: Hello again!`

	var fullCfg testFullConfig
	err := yaml.UnmarshalStrict([]byte(cfgToParse), &fullCfg)
	require.NoError(t, err)

	expect := testFullConfig{
		Name:     "John Doe",
		Duration: 500 * time.Millisecond,
		Default:  12345,
		Configs: []Config{
			&testIntegrationA{Text: "Hello, world!", Truth: true},
			&testIntegrationA{Text: "Hello again!", Truth: true},
		},
	}
	require.Equal(t, expect, fullCfg)
}

func TestIntegrationRegistration_Mixed(t *testing.T) {
	setRegistered(t, map[Config]Type{
		&testIntegrationA{}: TypeEither,
		&testIntegrationB{}: TypeEither,
	})

	var cfgToParse = `
name: John Doe
duration: 500ms
test:
  text: Hello, world!
test_configs:
  - text: Hello again!`

	var fullCfg testFullConfig
	err := yaml.UnmarshalStrict([]byte(cfgToParse), &fullCfg)
	require.NoError(t, err)

	expect := testFullConfig{
		Name:     "John Doe",
		Duration: 500 * time.Millisecond,
		Default:  12345,
		Configs: []Config{
			&testIntegrationA{Text: "Hello, world!", Truth: true},
			&testIntegrationA{Text: "Hello again!", Truth: true},
		},
	}
	require.Equal(t, expect, fullCfg)
}

func TestIntegrationRegistration_Legacy(t *testing.T) {
	setRegistered(t, nil)

	RegisterLegacy(&legacyConfig{}, TypeSingleton, func(in v1.Config, mc common.MetricsConfig) UpgradedConfig {
		return &legacyShim{Data: in, Common: mc}
	})

	var cfgToParse = `
name: John Doe
duration: 500ms
legacy:
  text: hello`

	var fullCfg testFullConfig
	err := yaml.UnmarshalStrict([]byte(cfgToParse), &fullCfg)
	require.NoError(t, err)

	require.Len(t, fullCfg.Configs, 1)
	require.IsType(t, &legacyShim{}, fullCfg.Configs[0])

	shim := fullCfg.Configs[0].(*legacyShim)
	require.IsType(t, &legacyConfig{}, shim.Data)

	v1Config := shim.Data.(*legacyConfig)
	require.Equal(t, "hello", v1Config.Text)
}

func TestIntegrationRegistration_Legacy_Multiplex(t *testing.T) {
	setRegistered(t, nil)

	RegisterLegacy(&legacyConfig{}, TypeMultiplex, func(in v1.Config, mc common.MetricsConfig) UpgradedConfig {
		return &legacyShim{Data: in, Common: mc}
	})

	var cfgToParse = `
name: John Doe
duration: 500ms
legacy_configs:
  - text: hello
  - text: world`

	var fullCfg testFullConfig
	err := yaml.UnmarshalStrict([]byte(cfgToParse), &fullCfg)
	require.NoError(t, err)

	require.Len(t, fullCfg.Configs, 2)
	require.IsType(t, &legacyShim{}, fullCfg.Configs[0])
	require.IsType(t, &legacyShim{}, fullCfg.Configs[1])

	shim := fullCfg.Configs[0].(*legacyShim)
	require.IsType(t, &legacyConfig{}, shim.Data)
	require.Equal(t, "hello", shim.Data.(*legacyConfig).Text)

	shim = fullCfg.Configs[1].(*legacyShim)
	require.IsType(t, &legacyConfig{}, shim.Data)
	require.Equal(t, "world", shim.Data.(*legacyConfig).Text)
}

func TestIntegrationRegistration_Marshal_MultipleSingleton(t *testing.T) {
	setRegistered(t, map[Config]Type{
		&testIntegrationA{}: TypeSingleton,
		&testIntegrationB{}: TypeSingleton,
	})

	// Generate an invalid config, which has two instances of a Singleton
	// integration.
	input := testFullConfig{
		Name:     "John Doe",
		Duration: 500 * time.Millisecond,
		Default:  12345,
		Configs: []Config{
			&testIntegrationA{Text: "Hello, world!", Truth: true},
			&testIntegrationA{Text: "Hello again!", Truth: true},
		},
	}

	_, err := yaml.Marshal(&input)
	require.EqualError(t, err, `integration "test" may not be defined more than once`)
}

type legacyConfig struct {
	Text string `yaml:"text"`
}

func (lc *legacyConfig) Name() string                                        { return "legacy" }
func (lc *legacyConfig) InstanceKey(agentKey string) (string, error)         { return agentKey, nil }
func (lc *legacyConfig) NewIntegration(l log.Logger) (v1.Integration, error) { return nil, nil }

type legacyShim struct {
	Data   v1.Config
	Common common.MetricsConfig
}

func (s *legacyShim) LegacyConfig() (v1.Config, common.MetricsConfig) { return s.Data, s.Common }
func (s *legacyShim) Name() string                                    { return s.Data.Name() }
func (s *legacyShim) ApplyDefaults(g Globals) error {
	s.Common.ApplyDefaults(g.SubsystemOpts.Metrics.Autoscrape)
	return nil
}
func (s *legacyShim) Identifier(g Globals) (string, error) { return g.AgentIdentifier, nil }
func (s *legacyShim) NewIntegration(log.Logger, Globals) (Integration, error) {
	return NoOpIntegration, nil
}

type testIntegrationA struct {
	Text  string `yaml:"text"`
	Truth bool   `yaml:"truth"`
}

func (i *testIntegrationA) Name() string                       { return "test" }
func (i *testIntegrationA) ApplyDefaults(Globals) error        { return nil }
func (i *testIntegrationA) Identifier(Globals) (string, error) { return "integrationA", nil }
func (i *testIntegrationA) NewIntegration(log.Logger, Globals) (Integration, error) {
	return NoOpIntegration, nil
}

func (i *testIntegrationA) UnmarshalYAML(unmarshal func(interface{}) error) error {
	i.Truth = true
	type plain testIntegrationA
	return unmarshal((*plain)(i))
}

type testIntegrationB struct {
	Text string `yaml:"text"`
}

func (*testIntegrationB) Name() string                       { return "shouldnotbefound" }
func (*testIntegrationB) ApplyDefaults(Globals) error        { return nil }
func (*testIntegrationB) Identifier(Globals) (string, error) { return "integrationB", nil }
func (*testIntegrationB) NewIntegration(log.Logger, Globals) (Integration, error) {
	return NoOpIntegration, nil
}

type testFullConfig struct {
	// Some random fields that will also be exposed
	Name     string        `yaml:"name"`
	Duration time.Duration `yaml:"duration"`
	Default  int           `yaml:"default"`

	Configs Configs `yaml:"-"`
}

func (c *testFullConfig) UnmarshalYAML(unmarshal func(interface{}) error) error {
	// This default value should not change.
	c.Default = 12345
	return UnmarshalYAML(c, unmarshal)
}

func (c testFullConfig) MarshalYAML() (interface{}, error) {
	return MarshalYAML(c)
}

'''
'''--- pkg/integrations/v2/snmp_exporter/snmp.go ---
package snmp_exporter

import (
	"context"
	"fmt"
	"net/http"
	"path"
	"time"

	"github.com/gorilla/mux"
	"github.com/grafana/agent/pkg/integrations/v2"
	"github.com/grafana/agent/pkg/integrations/v2/autoscrape"
	"github.com/grafana/agent/pkg/integrations/v2/metricsutils"
	"github.com/prometheus/common/model"
	"github.com/prometheus/prometheus/config"
	"github.com/prometheus/prometheus/discovery"
	"github.com/prometheus/prometheus/discovery/targetgroup"

	"github.com/go-kit/log"
	"github.com/go-kit/log/level"
	"github.com/prometheus/client_golang/prometheus"
	"github.com/prometheus/client_golang/prometheus/promhttp"
	"github.com/prometheus/snmp_exporter/collector"
	snmp_config "github.com/prometheus/snmp_exporter/config"
)

type snmpHandler struct {
	cfg     *Config
	modules *snmp_config.Config
	log     log.Logger
}

func (sh *snmpHandler) Targets(ep integrations.Endpoint) []*targetgroup.Group {
	integrationNameValue := model.LabelValue("integrations/" + sh.cfg.Name())
	key, _ := sh.cfg.InstanceKey("")

	group := &targetgroup.Group{
		Labels: model.LabelSet{
			model.InstanceLabel: model.LabelValue(key),
			model.JobLabel:      integrationNameValue,
			"agent_hostname":    model.LabelValue(sh.cfg.globals.AgentIdentifier),

			// Meta labels that can be used during SD.
			"__meta_agent_integration_name":       model.LabelValue(sh.cfg.Name()),
			"__meta_agent_integration_instance":   model.LabelValue(sh.cfg.Name()),
			"__meta_agent_integration_autoscrape": model.LabelValue(metricsutils.BoolToString(*sh.cfg.Common.Autoscrape.Enable)),
		},
		Source: fmt.Sprintf("%s/%s", sh.cfg.Name(), sh.cfg.Name()),
	}

	for _, lbl := range sh.cfg.Common.ExtraLabels {
		group.Labels[model.LabelName(lbl.Name)] = model.LabelValue(lbl.Value)
	}

	for _, t := range sh.cfg.SnmpTargets {
		group.Targets = append(group.Targets, model.LabelSet{
			model.AddressLabel:     model.LabelValue(ep.Host),
			model.MetricsPathLabel: model.LabelValue(path.Join(ep.Prefix, "metrics")),
			"snmp_target":          model.LabelValue(t.Target),
			"__param_target":       model.LabelValue(t.Target),
		})
	}

	return []*targetgroup.Group{group}
}

func (sh *snmpHandler) ScrapeConfigs(sd discovery.Configs) []*autoscrape.ScrapeConfig {
	if !*sh.cfg.Common.Autoscrape.Enable {
		return nil
	}
	name := sh.cfg.Name()
	cfg := config.DefaultScrapeConfig
	cfg.JobName = fmt.Sprintf("%s/%s", name, name)
	cfg.Scheme = sh.cfg.globals.AgentBaseURL.Scheme
	cfg.ServiceDiscoveryConfigs = sd
	cfg.ScrapeInterval = sh.cfg.Common.Autoscrape.ScrapeInterval
	cfg.ScrapeTimeout = sh.cfg.Common.Autoscrape.ScrapeTimeout
	cfg.RelabelConfigs = sh.cfg.Common.Autoscrape.RelabelConfigs
	cfg.MetricRelabelConfigs = sh.cfg.Common.Autoscrape.MetricRelabelConfigs

	return []*autoscrape.ScrapeConfig{{
		Instance: sh.cfg.Common.Autoscrape.MetricsInstance,
		Config:   cfg,
	}}
}

func (sh *snmpHandler) Handler(prefix string) (http.Handler, error) {
	r := mux.NewRouter()
	r.Handle(path.Join(prefix, "metrics"), sh.createHandler(sh.cfg.SnmpTargets))

	return r, nil
}

// Static typecheck tests
var (
	_ integrations.Integration        = (*snmpHandler)(nil)
	_ integrations.HTTPIntegration    = (*snmpHandler)(nil)
	_ integrations.MetricsIntegration = (*snmpHandler)(nil)
)

func (sh *snmpHandler) RunIntegration(ctx context.Context) error {
	<-ctx.Done()
	return nil
}

func (sh *snmpHandler) createHandler(targets []SNMPTarget) http.HandlerFunc {
	snmpTargets := make(map[string]SNMPTarget)
	for _, target := range targets {
		snmpTargets[target.Name] = target
	}

	return func(w http.ResponseWriter, r *http.Request) {
		logger := sh.log
		query := r.URL.Query()
		targetName := query.Get("target")

		var target string
		if len(query["target"]) != 1 || targetName == "" {
			http.Error(w, "'target' parameter must be specified once", 400)
			return
		}

		t, ok := snmpTargets[targetName]
		if ok {
			target = t.Target
		} else {
			target = targetName
		}

		var moduleName string
		if query.Has("module") {
			if len(query["module"]) > 1 {
				http.Error(w, "'module' parameter must only be specified once", 400)
				return
			}
			moduleName = query.Get("module")
		} else {
			moduleName = t.Module
		}

		if moduleName == "" {
			moduleName = "if_mib"
		}

		module, ok := (*sh.modules)[moduleName]
		if !ok {
			http.Error(w, fmt.Sprintf("Unknown module '%s'", moduleName), 400)
			return
		}

		// override module connection details with custom walk params if provided
		var walkParams string
		if query.Has("walk_params") {
			if len(query["walk_params"]) > 1 {
				http.Error(w, "'walk_params' parameter must only be specified once", 400)
				return
			}
			walkParams = query.Get("walk_params")
		} else {
			walkParams = t.WalkParams
		}

		if walkParams != "" {
			if wp, ok := sh.cfg.WalkParams[walkParams]; ok {
				// module.WalkParams = wp
				if wp.Version != 0 {
					module.WalkParams.Version = wp.Version
				}
				if wp.MaxRepetitions != 0 {
					module.WalkParams.MaxRepetitions = wp.MaxRepetitions
				}
				if wp.Retries != 0 {
					module.WalkParams.Retries = wp.Retries
				}
				if wp.Timeout != 0 {
					module.WalkParams.Timeout = wp.Timeout
				}
				module.WalkParams.Auth = wp.Auth
			} else {
				http.Error(w, fmt.Sprintf("Unknown walk_params '%s'", walkParams), 400)
				return
			}
			logger = log.With(logger, "module", moduleName, "target", target, "walk_params", walkParams)
		} else {
			logger = log.With(logger, "module", moduleName, "target", target)
		}
		level.Debug(logger).Log("msg", "Starting scrape")

		start := time.Now()
		registry := prometheus.NewRegistry()
		c := collector.New(r.Context(), target, module, logger)
		registry.MustRegister(c)
		// Delegate http serving to Prometheus client library, which will call collector.Collect.
		h := promhttp.HandlerFor(registry, promhttp.HandlerOpts{})
		h.ServeHTTP(w, r)

		duration := time.Since(start).Seconds()
		level.Debug(logger).Log("msg", "Finished scrape", "duration_seconds", duration)
	}
}

func (sh *snmpHandler) handler(w http.ResponseWriter, r *http.Request) {
	logger := sh.log

	query := r.URL.Query()

	target := query.Get("target")
	if len(query["target"]) != 1 || target == "" {
		http.Error(w, "'target' parameter must be specified once", 400)
		return
	}

	moduleName := query.Get("module")
	if len(query["module"]) > 1 {
		http.Error(w, "'module' parameter must only be specified once", 400)
		return
	}
	if moduleName == "" {
		moduleName = "if_mib"
	}

	module, ok := (*sh.modules)[moduleName]
	if !ok {
		http.Error(w, fmt.Sprintf("Unknown module '%s'", moduleName), 400)
		return
	}

	// override module connection details with custom walk params if provided
	walkParams := query.Get("walk_params")
	if len(query["walk_params"]) > 1 {
		http.Error(w, "'walk_params' parameter must only be specified once", 400)
		return
	}

	if walkParams != "" {
		if wp, ok := sh.cfg.WalkParams[walkParams]; ok {
			// module.WalkParams = wp
			if wp.Version != 0 {
				module.WalkParams.Version = wp.Version
			}
			if wp.MaxRepetitions != 0 {
				module.WalkParams.MaxRepetitions = wp.MaxRepetitions
			}
			if wp.Retries != 0 {
				module.WalkParams.Retries = wp.Retries
			}
			if wp.Timeout != 0 {
				module.WalkParams.Timeout = wp.Timeout
			}
			module.WalkParams.Auth = wp.Auth
		} else {
			http.Error(w, fmt.Sprintf("Unknown walk_params '%s'", walkParams), 400)
			return
		}
		logger = log.With(logger, "module", moduleName, "target", target, "walk_params", walkParams)
	} else {
		logger = log.With(logger, "module", moduleName, "target", target)
	}
	level.Debug(logger).Log("msg", "Starting scrape")

	start := time.Now()
	registry := prometheus.NewRegistry()
	c := collector.New(r.Context(), target, module, logger)
	registry.MustRegister(c)
	// Delegate http serving to Prometheus client library, which will call collector.Collect.
	h := promhttp.HandlerFor(registry, promhttp.HandlerOpts{})
	h.ServeHTTP(w, r)
	duration := time.Since(start).Seconds()
	level.Debug(logger).Log("msg", "Finished scrape", "duration_seconds", duration)
}

func (sh snmpHandler) ServeHTTP(w http.ResponseWriter, r *http.Request) {
	sh.handler(w, r)
}

'''
'''--- pkg/integrations/v2/snmp_exporter/snmp_exporter.go ---
// Package snmp_exporter embeds https://github.com/prometheus/snmp_exporter
package snmp_exporter

import (
	"fmt"

	"github.com/go-kit/log"
	snmp_common "github.com/grafana/agent/pkg/integrations/snmp_exporter/common"
	integrations_v2 "github.com/grafana/agent/pkg/integrations/v2"
	"github.com/grafana/agent/pkg/integrations/v2/common"
	snmp_config "github.com/prometheus/snmp_exporter/config"
)

// DefaultConfig holds the default settings for the snmp_exporter integration.
var DefaultConfig = Config{
	WalkParams:     make(map[string]snmp_config.WalkParams),
	SnmpConfigFile: "",
}

// Config configures the SNMP integration.
type Config struct {
	WalkParams     map[string]snmp_config.WalkParams `yaml:"walk_params,omitempty"`
	SnmpConfigFile string                            `yaml:"config_file,omitempty"`
	SnmpTargets    []SNMPTarget                      `yaml:"snmp_targets"`
	Common         common.MetricsConfig              `yaml:",inline"`

	globals integrations_v2.Globals
}

// SNMPTarget defines a target device to be used by the integration.
type SNMPTarget struct {
	Name       string `yaml:"name"`
	Target     string `yaml:"address"`
	Module     string `yaml:"module"`
	WalkParams string `yaml:"walk_params,omitempty"`
}

// ApplyDefaults applies the integration's default configuration.
func (c *Config) ApplyDefaults(globals integrations_v2.Globals) error {
	c.Common.ApplyDefaults(globals.SubsystemOpts.Metrics.Autoscrape)
	return nil
}

// Identifier returns a string that identifies the integration.
func (c *Config) Identifier(globals integrations_v2.Globals) (string, error) {
	return c.Name(), nil
}

// NewIntegration creates a new SNMP integration.
func (c *Config) NewIntegration(log log.Logger, globals integrations_v2.Globals) (integrations_v2.Integration, error) {
	var modules *snmp_config.Config
	var err error
	if c.SnmpConfigFile != "" {
		modules, err = snmp_config.LoadFile(c.SnmpConfigFile)
		if err != nil {
			return nil, fmt.Errorf("failed to load snmp config from file %v: %w", c.SnmpConfigFile, err)
		}
	} else {
		modules, err = snmp_common.LoadEmbeddedConfig()
		if err != nil {
			return nil, fmt.Errorf("failed to load embedded snmp config: %w", err)
		}
	}
	c.globals = globals
	sh := &snmpHandler{
		cfg:     c,
		modules: modules,
		log:     log,
	}
	return sh, nil
}

// UnmarshalYAML implements yaml.Unmarshaler for Config.
func (c *Config) UnmarshalYAML(unmarshal func(interface{}) error) error {
	*c = DefaultConfig

	type plain Config
	return unmarshal((*plain)(c))
}

// Name returns the name of the integration.
func (c *Config) Name() string {
	return "snmp"
}

// InstanceKey returns the hostname:port of the agent.
func (c *Config) InstanceKey(agentKey string) (string, error) {
	return agentKey, nil
}

func init() {
	integrations_v2.Register(&Config{}, integrations_v2.TypeSingleton)
}

'''
'''--- pkg/integrations/v2/subsystem.go ---
package integrations

import (
	"context"
	"encoding/json"
	"fmt"
	"net/http"
	"sync"
	"time"

	"github.com/go-kit/log"
	"github.com/gorilla/mux"
	"github.com/grafana/agent/pkg/integrations/v2/autoscrape"
	"github.com/grafana/agent/pkg/metrics"
	"github.com/prometheus/common/model"
	http_sd "github.com/prometheus/prometheus/discovery/http"
)

const (
	// IntegrationsSDEndpoint is the API endpoint where the integration HTTP SD
	// API is exposed. The API uses query parameters to customize what gets
	// returned by discovery.
	IntegrationsSDEndpoint = "/agent/api/v1/metrics/integrations/sd"

	// IntegrationsAutoscrapeTargetsEndpoint is the API endpoint where autoscrape
	// integrations targets are exposed.
	IntegrationsAutoscrapeTargetsEndpoint = "/agent/api/v1/metrics/integrations/targets"
)

// DefaultSubsystemOptions holds the default settings for a Controller.
var (
	DefaultSubsystemOptions = SubsystemOptions{
		Metrics: DefaultMetricsSubsystemOptions,
	}

	DefaultMetricsSubsystemOptions = MetricsSubsystemOptions{
		Autoscrape: autoscrape.DefaultGlobal,
	}
)

// SubsystemOptions controls how the integrations subsystem behaves.
type SubsystemOptions struct {
	Metrics MetricsSubsystemOptions `yaml:"metrics,omitempty"`

	// Configs are configurations of integration to create. Unmarshaled through
	// the custom UnmarshalYAML method of Controller.
	Configs Configs `yaml:"-"`
}

// MetricsSubsystemOptions controls how metrics integrations behave.
type MetricsSubsystemOptions struct {
	Autoscrape autoscrape.Global `yaml:"autoscrape,omitempty"`
}

// ApplyDefaults will apply defaults to o.
func (o *SubsystemOptions) ApplyDefaults(mcfg *metrics.Config) error {
	if o.Metrics.Autoscrape.ScrapeInterval == 0 {
		o.Metrics.Autoscrape.ScrapeInterval = mcfg.Global.Prometheus.ScrapeInterval
	}
	if o.Metrics.Autoscrape.ScrapeTimeout == 0 {
		o.Metrics.Autoscrape.ScrapeTimeout = mcfg.Global.Prometheus.ScrapeTimeout
	}

	return nil
}

// MarshalYAML implements yaml.Marshaler for SubsystemOptions. Integrations
// will be marshaled inline.
func (o SubsystemOptions) MarshalYAML() (interface{}, error) {
	return MarshalYAML(o)
}

// UnmarshalYAML implements yaml.Unmarshaler for SubsystemOptions. Inline
// integrations will be unmarshaled into o.Configs.
func (o *SubsystemOptions) UnmarshalYAML(unmarshal func(interface{}) error) error {
	*o = DefaultSubsystemOptions
	return UnmarshalYAML(o, unmarshal)
}

// Subsystem runs the integrations subsystem, managing a set of integrations.
type Subsystem struct {
	logger log.Logger

	mut         sync.RWMutex
	globals     Globals
	apiHandler  http.Handler // generated from controller
	autoscraper *autoscrape.Scraper

	ctrl             *controller
	stopController   context.CancelFunc
	controllerExited chan struct{}
}

// NewSubsystem creates and starts a new integrations Subsystem. Every field in
// IntegrationOptions must be filled out.
func NewSubsystem(l log.Logger, globals Globals) (*Subsystem, error) {
	autoscraper := autoscrape.NewScraper(l, globals.Metrics.InstanceManager(), globals.DialContextFunc)

	l = log.With(l, "component", "integrations")

	ctrl, err := newController(l, controllerConfig(globals.SubsystemOpts.Configs), globals)
	if err != nil {
		autoscraper.Stop()
		return nil, err
	}

	ctx, cancel := context.WithCancel(context.Background())

	ctrlExited := make(chan struct{})
	go func() {
		ctrl.run(ctx)
		close(ctrlExited)
	}()

	s := &Subsystem{
		logger: l,

		globals:     globals,
		autoscraper: autoscraper,

		ctrl:             ctrl,
		stopController:   cancel,
		controllerExited: ctrlExited,
	}
	if err := s.ApplyConfig(globals); err != nil {
		cancel()
		autoscraper.Stop()
		return nil, err
	}
	return s, nil
}

// ApplyConfig updates the configuration of the integrations subsystem.
func (s *Subsystem) ApplyConfig(globals Globals) error {
	const prefix = "/integrations/"

	s.mut.Lock()
	defer s.mut.Unlock()

	if err := s.ctrl.UpdateController(controllerConfig(globals.SubsystemOpts.Configs), globals); err != nil {
		return fmt.Errorf("error applying integrations: %w", err)
	}

	var firstErr error
	saveFirstErr := func(err error) {
		if firstErr == nil {
			firstErr = err
		}
	}

	// Set up HTTP wiring
	{
		handler, err := s.ctrl.Handler(prefix)
		if err != nil {
			saveFirstErr(fmt.Errorf("HTTP handler update failed: %w", err))
		}
		s.apiHandler = handler
	}

	// Set up self-scraping
	{
		httpSDConfig := http_sd.DefaultSDConfig
		httpSDConfig.RefreshInterval = model.Duration(time.Second * 5) // TODO(rfratto): make configurable?

		apiURL := globals.CloneAgentBaseURL()
		apiURL.Path = IntegrationsSDEndpoint
		httpSDConfig.URL = apiURL.String()

		scrapeConfigs := s.ctrl.ScrapeConfigs(prefix, &httpSDConfig)
		if err := s.autoscraper.ApplyConfig(scrapeConfigs); err != nil {
			saveFirstErr(fmt.Errorf("configuring autoscraper failed: %w", err))
		}
	}

	s.globals = globals
	return firstErr
}

// WireAPI hooks up integration endpoints to r.
func (s *Subsystem) WireAPI(r *mux.Router) {
	const prefix = "/integrations"
	r.PathPrefix(prefix).HandlerFunc(func(rw http.ResponseWriter, r *http.Request) {
		s.mut.RLock()
		handler := s.apiHandler
		s.mut.RUnlock()

		if handler == nil {
			rw.WriteHeader(http.StatusServiceUnavailable)
			fmt.Fprintf(rw, "Integrations HTTP endpoints not yet available")
			return
		}
		handler.ServeHTTP(rw, r)
	})

	r.HandleFunc(IntegrationsSDEndpoint, func(rw http.ResponseWriter, r *http.Request) {
		targetOptions, err := TargetOptionsFromParams(r.URL.Query())
		if err != nil {
			http.Error(rw, fmt.Sprintf("invalid query parameters: %s", err), http.StatusBadRequest)
			return
		}

		rw.Header().Set("Content-Type", "application/json")
		rw.WriteHeader(http.StatusOK)

		tgs := s.ctrl.Targets(Endpoint{
			Host:   r.Host,
			Prefix: prefix,
		}, targetOptions)

		// Normalize targets. We may have targets in the group with non-address
		// labels. These need to be retained, so we'll just split everything up
		// into multiple groups.
		//
		// TODO(rfratto): optimize to remove redundant groups
		finalTgs := []*targetGroup{}
		for _, group := range tgs {
			for _, target := range group.Targets {
				// Create the final labels for the group. This will be everything from
				// the group and the target (except for model.AddressLabel). Labels
				// from target take precedence labels from over group.
				groupLabels := group.Labels.Merge(target)
				delete(groupLabels, model.AddressLabel)

				finalTgs = append(finalTgs, &targetGroup{
					Targets: []model.LabelSet{{model.AddressLabel: target[model.AddressLabel]}},
					Labels:  groupLabels,
				})
			}
		}

		enc := json.NewEncoder(rw)
		_ = enc.Encode(finalTgs)
	})

	r.HandleFunc(IntegrationsAutoscrapeTargetsEndpoint, func(rw http.ResponseWriter, r *http.Request) {
		allTargets := s.autoscraper.TargetsActive()
		metrics.ListTargetsHandler(allTargets).ServeHTTP(rw, r)
	})
}

// Stop stops the manager and all running integrations. Blocks until all
// running integrations exit.
func (s *Subsystem) Stop() {
	s.autoscraper.Stop()
	s.stopController()
	<-s.controllerExited
}

'''
'''--- pkg/integrations/v2/subsystem_test.go ---
package integrations

import (
	"testing"

	v1 "github.com/grafana/agent/pkg/integrations"
	"github.com/grafana/agent/pkg/integrations/v2/common"
	"github.com/stretchr/testify/require"
	"gopkg.in/yaml.v2"
)

func TestSubsystemOptions_Unmarshal(t *testing.T) {
	setRegistered(t, map[Config]Type{
		&testIntegrationA{}: TypeSingleton,
	})

	RegisterLegacy(&legacyConfig{}, TypeSingleton, func(in v1.Config, mc common.MetricsConfig) UpgradedConfig {
		return &legacyShim{Data: in, Common: mc}
	})

	tt := []struct {
		name        string
		in          string
		expectError string
	}{
		{
			name: "invalid integration",
			in: `
        invalidintegration: 
          autoscrape:
            enabled: true
      `,
			expectError: "line 2: field invalidintegration not found in type integrations.SubsystemOptions",
		},
		{
			name: "invalid field",
			in: `
        test:
          invalidfield: true
      `,
			expectError: "line 1: field invalidfield not found in type integrations.plain",
		},
		{
			name: "invalid v1 field",
			in: `
        legacy:
          invalidfield: true
      `,
			expectError: "line 1: field invalidfield not found",
		},
	}

	for _, tc := range tt {
		t.Run(tc.name, func(t *testing.T) {
			var so SubsystemOptions
			err := yaml.UnmarshalStrict([]byte(tc.in), &so)

			var te *yaml.TypeError
			require.ErrorAs(t, err, &te)
			require.Len(t, te.Errors, 1)
			require.Equal(t, tc.expectError, te.Errors[0])
		})
	}
}

'''
'''--- pkg/integrations/v2/targetgroup.go ---
package integrations

import (
	"encoding/json"

	"github.com/prometheus/common/model"
	"github.com/prometheus/prometheus/discovery/targetgroup"
)

// targetGroup implements json.Marshaler for targetgroup.Group. This is
// required do to an issue with Prometheus: HTTP SD expects to be unmarshaled
// as JSON, but the form it expects to unmarshal the target groups in is not the form
// it marshals out to JSON as.
type targetGroup targetgroup.Group

func (tg *targetGroup) MarshalJSON() ([]byte, error) {
	g := &struct {
		Targets []string       `json:"targets"`
		Labels  model.LabelSet `json:"labels,omitempty"`
	}{
		Targets: make([]string, 0, len(tg.Targets)),
		Labels:  tg.Labels,
	}
	for _, t := range tg.Targets {
		g.Targets = append(g.Targets, string(t[model.AddressLabel]))
	}
	return json.Marshal(g)
}

'''
'''--- pkg/integrations/v2/utils.go ---
package integrations

import (
	"context"
	"net/http"

	"github.com/grafana/agent/pkg/util"
)

// FuncIntegration is a function that implements Integration.
type FuncIntegration func(ctx context.Context) error

// RunIntegration implements Integration.
func (fi FuncIntegration) RunIntegration(ctx context.Context) error { return fi(ctx) }

// Handler implements HTTPIntegration
func (fi FuncIntegration) Handler(prefix string) (http.Handler, error) {
	return nil, nil
}

// NoOpIntegration is an Integration that does nothing.
var NoOpIntegration = FuncIntegration(func(ctx context.Context) error {
	<-ctx.Done()
	return nil
})

// CompareConfigs will return true if a and b are equal. If neither a or b
// implement ComparableConfig, then configs are compared by marshaling to YAML
// and comparing the results.
func CompareConfigs(a, b Config) bool {
	if a, ok := a.(ComparableConfig); ok {
		return a.ConfigEquals(b)
	}
	if b, ok := b.(ComparableConfig); ok {
		return b.ConfigEquals(a)
	}
	return util.CompareYAML(a, b)
}

'''
'''--- pkg/integrations/v2/vmware_exporter/vmware_exporter.go ---
package vmware_exporter

import (
	"fmt"
	"net/url"
	"time"

	"github.com/go-kit/log"
	"github.com/grafana/agent/pkg/integrations/v2"
	"github.com/grafana/agent/pkg/integrations/v2/common"
	"github.com/grafana/agent/pkg/integrations/v2/metricsutils"
	"github.com/grafana/vmware_exporter/vsphere"
	config_util "github.com/prometheus/common/config"
)

func init() {
	integrations.Register(&Config{}, integrations.TypeMultiplex)
}

// DefaultConfig holds non-zero default options for hte Config when it is
// unmarshaled from YAML.
var DefaultConfig = Config{
	ChunkSize:               256,
	CollectConcurrency:      8,
	ObjectDiscoveryInterval: 0,
	EnableExporterMetrics:   true,
}

// Config configures the vmware_exporter integration.
type Config struct {
	ChunkSize               int                  `yaml:"request_chunk_size,omitempty"`
	CollectConcurrency      int                  `yaml:"collect_concurrency,omitempty"`
	VSphereURL              string               `yaml:"vsphere_url,omitempty"`
	VSphereUser             string               `yaml:"vsphere_user,omitempty"`
	VSpherePass             config_util.Secret   `yaml:"vsphere_password,omitempty"`
	ObjectDiscoveryInterval time.Duration        `yaml:"discovery_interval,omitempty"`
	EnableExporterMetrics   bool                 `yaml:"enable_exporter_metrics,omitempty"`
	Common                  common.MetricsConfig `yaml:",inline"`
}

var _ integrations.Config = (*Config)(nil)

// UnmarshalYAML implements the Unmarshaler interface.
func (c *Config) UnmarshalYAML(unmarshal func(interface{}) error) error {
	*c = DefaultConfig
	type plain Config
	return unmarshal((*plain)(c))
}

// Name returns the name of this integration.
func (c *Config) Name() string {
	return "vsphere"
}

// ApplyDefaults applies the integration's default configuration.
func (c *Config) ApplyDefaults(g integrations.Globals) error {
	c.Common.ApplyDefaults(g.SubsystemOpts.Metrics.Autoscrape)
	return nil
}

// Identifier returns a string that identifies the instance of the integration.
func (c *Config) Identifier(g integrations.Globals) (string, error) {
	if c.Common.InstanceKey != nil {
		return *c.Common.InstanceKey, nil
	}

	u, err := url.Parse(c.VSphereURL)
	if err != nil {
		return "", err
	}
	return fmt.Sprintf("%s:%s", u.Hostname(), u.Port()), nil
}

// NewIntegration constructs a new instance of this integration.
func (c *Config) NewIntegration(log log.Logger, g integrations.Globals) (integrations.Integration, error) {
	vsphereURL, err := url.Parse(c.VSphereURL)
	if err != nil {
		return nil, err
	}
	vsphereURL.User = url.UserPassword(c.VSphereUser, string(c.VSpherePass))

	exporterConfig := vsphere.Config{
		ChunkSize:               c.ChunkSize,
		CollectConcurrency:      c.CollectConcurrency,
		VSphereURL:              vsphereURL,
		ObjectDiscoveryInterval: c.ObjectDiscoveryInterval,
		EnableExporterMetrics:   c.EnableExporterMetrics,
	}
	exporter, err := vsphere.NewExporter(log, &exporterConfig)
	if err != nil {
		return nil, err
	}

	return metricsutils.NewMetricsHandlerIntegration(
		log, c, c.Common, g, exporter,
	)
}

'''
'''--- pkg/integrations/v2/workers.go ---
package integrations

import (
	"context"
	"sync"

	"github.com/go-kit/log"
	"github.com/go-kit/log/level"
)

type workerPool struct {
	log       log.Logger
	parentCtx context.Context

	mut     sync.Mutex
	workers map[*controlledIntegration]worker

	runningWorkers sync.WaitGroup
}

type worker struct {
	ci     *controlledIntegration
	stop   context.CancelFunc
	exited chan struct{}
}

func newWorkerPool(ctx context.Context, l log.Logger) *workerPool {
	return &workerPool{
		log:       l,
		parentCtx: ctx,

		workers: make(map[*controlledIntegration]worker),
	}
}

func (p *workerPool) Reload(newIntegrations []*controlledIntegration) {
	p.mut.Lock()
	defer p.mut.Unlock()

	level.Debug(p.log).Log("msg", "updating running integrations", "prev_count", len(p.workers), "new_count", len(newIntegrations))

	// Shut down workers whose integrations have gone away.
	var stopped []worker
	for ci, w := range p.workers {
		var found bool
		for _, current := range newIntegrations {
			if ci == current {
				found = true
				break
			}
		}
		if !found {
			w.stop()
			stopped = append(stopped, w)
		}
	}
	for _, w := range stopped {
		// Wait for stopped integrations to fully exit. We do this in a separate
		// loop so context cancellations can be handled simultaneously, allowing
		// the wait to complete faster.
		<-w.exited
	}

	// Spawn new workers for integrations that don't have them.
	for _, current := range newIntegrations {
		if _, workerExists := p.workers[current]; workerExists {
			continue
		}
		// This integration doesn't have an existing worker; schedule a new one.
		p.scheduleWorker(current)
	}
}

func (p *workerPool) Close() {
	p.mut.Lock()
	defer p.mut.Unlock()

	level.Debug(p.log).Log("msg", "stopping all integrations")

	defer p.runningWorkers.Wait()
	for _, w := range p.workers {
		w.stop()
	}
}

func (p *workerPool) scheduleWorker(ci *controlledIntegration) {
	p.runningWorkers.Add(1)

	ctx, cancel := context.WithCancel(p.parentCtx)

	w := worker{
		ci:     ci,
		stop:   cancel,
		exited: make(chan struct{}),
	}
	p.workers[ci] = w

	go func() {
		ci.running.Store(true)

		// When the integration stops running, we want to free any of our
		// resources that will notify watchers waiting for the worker to stop.
		//
		// Afterwards, we'll block until we remove ourselves from the map; having
		// an worker remove itself on shutdown allows exited integrations to
		// re-start when the config is reloaded.
		defer func() {
			ci.running.Store(false)
			close(w.exited)
			p.runningWorkers.Done()

			p.mut.Lock()
			defer p.mut.Unlock()
			delete(p.workers, ci)
		}()

		err := ci.i.RunIntegration(ctx)
		if err != nil {
			level.Error(p.log).Log("msg", "integration exited with error", "id", ci.id, "err", err)
		}
	}()
}

'''
'''--- pkg/integrations/windows_exporter/config.go ---
package windows_exporter //nolint:golint

import (
	"github.com/go-kit/log"
	"github.com/grafana/agent/pkg/integrations"
	integrations_v2 "github.com/grafana/agent/pkg/integrations/v2"
	"github.com/grafana/agent/pkg/integrations/v2/metricsutils"
)

// DefaultConfig holds the default settings for the windows_exporter integration.
var DefaultConfig = Config{
	EnabledCollectors: "cpu,cs,logical_disk,net,os,service,system",

	// NOTE(rfratto): there is an init function in config_windows.go that
	// populates defaults for collectors based on the exporter defaults.
}

func init() {
	integrations.RegisterIntegration(&Config{})
	integrations_v2.RegisterLegacy(&Config{}, integrations_v2.TypeSingleton, metricsutils.NewNamedShim("windows"))
}

// Config controls the windows_exporter integration.
// All of these and their child fields are pointers so we can determine if the value was set or not.
type Config struct {
	EnabledCollectors string `yaml:"enabled_collectors"`

	Exchange    ExchangeConfig    `yaml:"exchange,omitempty"`
	IIS         IISConfig         `yaml:"iis,omitempty"`
	TextFile    TextFileConfig    `yaml:"text_file,omitempty"`
	SMTP        SMTPConfig        `yaml:"smtp,omitempty"`
	Service     ServiceConfig     `yaml:"service,omitempty"`
	Process     ProcessConfig     `yaml:"process,omitempty"`
	Network     NetworkConfig     `yaml:"network,omitempty"`
	MSSQL       MSSQLConfig       `yaml:"mssql,omitempty"`
	MSMQ        MSMQConfig        `yaml:"msmq,omitempty"`
	LogicalDisk LogicalDiskConfig `yaml:"logical_disk,omitempty"`
}

// UnmarshalYAML implements yaml.Unmarshaler for Config.
func (c *Config) UnmarshalYAML(unmarshal func(interface{}) error) error {
	*c = DefaultConfig

	type plain Config
	return unmarshal((*plain)(c))
}

// Name returns the name used, "windows_explorer"
func (c *Config) Name() string {
	return "windows_exporter"
}

// InstanceKey returns the hostname:port of the agent.
func (c *Config) InstanceKey(agentKey string) (string, error) {
	return agentKey, nil
}

// NewIntegration creates an integration based on the given configuration
func (c *Config) NewIntegration(l log.Logger) (integrations.Integration, error) {
	return New(l, c)
}

// ExchangeConfig handles settings for the windows_exporter Exchange collector
type ExchangeConfig struct {
	EnabledList string `yaml:"enabled_list,omitempty"`
}

// IISConfig handles settings for the windows_exporter IIS collector
type IISConfig struct {
	SiteWhiteList string `yaml:"site_whitelist,omitempty"`
	SiteBlackList string `yaml:"site_blacklist,omitempty"`
	AppWhiteList  string `yaml:"app_whitelist,omitempty"`
	AppBlackList  string `yaml:"app_blacklist,omitempty"`
}

// TextFileConfig handles settings for the windows_exporter Text File collector
type TextFileConfig struct {
	TextFileDirectory string `yaml:"text_file_directory,omitempty"`
}

// SMTPConfig handles settings for the windows_exporter SMTP collector
type SMTPConfig struct {
	WhiteList string `yaml:"whitelist,omitempty"`
	BlackList string `yaml:"blacklist,omitempty"`
}

// ServiceConfig handles settings for the windows_exporter service collector
type ServiceConfig struct {
	Where string `yaml:"where_clause,omitempty"`
}

// ProcessConfig handles settings for the windows_exporter process collector
type ProcessConfig struct {
	WhiteList string `yaml:"whitelist,omitempty"`
	BlackList string `yaml:"blacklist,omitempty"`
}

// NetworkConfig handles settings for the windows_exporter network collector
type NetworkConfig struct {
	WhiteList string `yaml:"whitelist,omitempty"`
	BlackList string `yaml:"blacklist,omitempty"`
}

// MSSQLConfig handles settings for the windows_exporter SQL server collector
type MSSQLConfig struct {
	EnabledClasses string `yaml:"enabled_classes,omitempty"`
}

// MSMQConfig handles settings for the windows_exporter MSMQ collector
type MSMQConfig struct {
	Where string `yaml:"where_clause,omitempty"`
}

// LogicalDiskConfig handles settings for the windows_exporter logical disk collector
type LogicalDiskConfig struct {
	WhiteList string `yaml:"whitelist,omitempty"`
	BlackList string `yaml:"blacklist,omitempty"`
}

'''
'''--- pkg/integrations/windows_exporter/config_windows.go ---
package windows_exporter //nolint:golint

import (
	"github.com/prometheus-community/windows_exporter/collector"
	"gopkg.in/alecthomas/kingpin.v2"
)

// Populate defaults for all collector configs.
func init() {
	// Register flags from all collector configs to a fake integration and then
	// parse an empty command line to force defaults to be populated.
	ka := kingpin.New("init", "")

	configs := collector.AllConfigs()
	for _, cfg := range configs {
		cfg.RegisterFlags(ka)
	}
	_, err := ka.Parse(nil)
	if err != nil {
		panic(err)
	}

	// Map the configs with defaults applied to our default config.
	DefaultConfig.fromExporterConfig(configs)
}

// fromExporterConfig converts windows_exporter configs into the integration Config.
func (c *Config) fromExporterConfig(configs []collector.Config) {
	for _, ec := range configs {
		switch other := ec.(type) {
		case *collector.ExchangeConfig:
			c.Exchange.EnabledList = other.Enabled

		case *collector.IISConfig:
			c.IIS.SiteWhiteList = other.SiteWhitelist
			c.IIS.SiteBlackList = other.SiteBlacklist
			c.IIS.AppWhiteList = other.AppWhitelist
			c.IIS.AppBlackList = other.AppBlacklist

		case *collector.TextFileConfig:
			c.TextFile.TextFileDirectory = other.Directory

		case *collector.SMTPConfig:
			c.SMTP.WhiteList = other.ServerWhitelist
			c.SMTP.BlackList = other.ServerBlacklist

		case *collector.ServiceConfig:
			c.Service.Where = other.WhereClause

		case *collector.ProcessConfig:
			c.Process.WhiteList = other.ProcessWhitelist
			c.Process.BlackList = other.ProcessBlacklist

		case *collector.NetworkConfig:
			c.Network.WhiteList = other.NICWhitelist
			c.Network.BlackList = other.NICBlacklist

		case *collector.MSSQLConfig:
			c.MSSQL.EnabledClasses = other.EnabledCollectors

		case *collector.MSMQConfig:
			c.MSMQ.Where = other.WhereClause

		case *collector.LogicalDiskConfig:
			c.LogicalDisk.WhiteList = other.VolumeWhitelist
			c.LogicalDisk.BlackList = other.VolumeBlacklist
		}
	}
}

// toExporterConfig converts integration Configs into windows_exporter configs.
func (c *Config) toExporterConfig(configs []collector.Config) {
	for _, ec := range configs {
		switch other := ec.(type) {
		case *collector.ExchangeConfig:
			other.Enabled = c.Exchange.EnabledList

		case *collector.IISConfig:
			other.SiteWhitelist = c.IIS.SiteWhiteList
			other.SiteBlacklist = c.IIS.SiteBlackList
			other.AppWhitelist = c.IIS.AppWhiteList
			other.AppBlacklist = c.IIS.AppBlackList

		case *collector.TextFileConfig:
			other.Directory = c.TextFile.TextFileDirectory

		case *collector.SMTPConfig:
			other.ServerWhitelist = c.SMTP.WhiteList
			other.ServerBlacklist = c.SMTP.BlackList

		case *collector.ServiceConfig:
			other.WhereClause = c.Service.Where

		case *collector.ProcessConfig:
			other.ProcessWhitelist = c.Process.WhiteList
			other.ProcessBlacklist = c.Process.BlackList

		case *collector.NetworkConfig:
			other.NICWhitelist = c.Network.WhiteList
			other.NICBlacklist = c.Network.BlackList

		case *collector.MSSQLConfig:
			other.EnabledCollectors = c.MSSQL.EnabledClasses

		case *collector.MSMQConfig:
			other.WhereClause = c.MSMQ.Where

		case *collector.LogicalDiskConfig:
			other.VolumeWhitelist = c.LogicalDisk.WhiteList
			other.VolumeBlacklist = c.LogicalDisk.BlackList
		}
	}
}

'''
'''--- pkg/integrations/windows_exporter/windows_exporter.go ---
//go:build !windows
// +build !windows

package windows_exporter //nolint:golint

import (
	"context"
	"net/http"

	"github.com/go-kit/log"
	"github.com/go-kit/log/level"
	"github.com/grafana/agent/pkg/integrations/config"
)

// Integration is the windows_exporter integration. On non-Windows platforms,
// this integration does nothing and will print a warning if enabled.
type Integration struct {
}

// New creates a fake windows_exporter integration.
func New(logger log.Logger, _ *Config) (*Integration, error) {
	level.Warn(logger).Log("msg", "the windows_exporter only works on Windows; enabling it otherwise will do nothing")
	return &Integration{}, nil
}

// MetricsHandler satisfies Integration.RegisterRoutes.
func (i *Integration) MetricsHandler() (http.Handler, error) {
	return http.NotFoundHandler(), nil
}

// ScrapeConfigs satisfies Integration.ScrapeConfigs.
func (i *Integration) ScrapeConfigs() []config.ScrapeConfig {
	// No-op: nothing to scrape.
	return []config.ScrapeConfig{}
}

// Run satisfies Integration.Run.
func (i *Integration) Run(ctx context.Context) error {
	// We don't need to do anything here, so we can just wait for the context to
	// finish.
	<-ctx.Done()
	return ctx.Err()
}

'''
'''--- pkg/integrations/windows_exporter/windows_exporter_windows.go ---
package windows_exporter //nolint:golint

import (
	"fmt"
	"sort"
	"strings"
	"time"

	"github.com/go-kit/log"
	"github.com/grafana/agent/pkg/integrations"
	"github.com/prometheus-community/windows_exporter/collector"
	"github.com/prometheus/statsd_exporter/pkg/level"
)

// New creates a new windows_exporter integration.
func New(log log.Logger, c *Config) (integrations.Integration, error) {
	// Get a list of collector configs and map our local config to it.
	availableConfigs := collector.AllConfigs()
	c.toExporterConfig(availableConfigs)

	enabledCollectorNames := enabledCollectors(c.EnabledCollectors)
	collectors, err := buildCollectors(enabledCollectorNames, availableConfigs)
	if err != nil {
		return nil, err
	}

	collectorNames := make([]string, 0, len(collectors))
	for key := range collectors {
		collectorNames = append(collectorNames, key)
	}
	sort.Strings(collectorNames)
	level.Info(log).Log("msg", "enabled windows_exporter collectors", "collectors", strings.Join(collectorNames, ","))

	return integrations.NewCollectorIntegration(c.Name(), integrations.WithCollectors(
		// Hard-coded 4m timeout to represent the time a series goes stale.
		// TODO: Make configurable if useful.
		collector.NewPrometheus(4*time.Minute, collectors),
	)), nil
}

func enabledCollectors(input string) []string {
	separated := strings.Split(input, ",")
	unique := map[string]struct{}{}
	for _, s := range separated {
		s = strings.TrimSpace(s)
		if s != "" {
			unique[s] = struct{}{}
		}
	}
	result := make([]string, 0, len(unique))
	for s := range unique {
		result = append(result, s)
	}
	return result
}

func buildCollectors(enabled []string, available []collector.Config) (map[string]collector.Collector, error) {
	collectors := map[string]collector.Collector{}

	for _, name := range enabled {
		var found collector.Config
		for _, c := range available {
			if c.Name() == name {
				found = c
				break
			}
		}
		if found == nil {
			return nil, fmt.Errorf("unknown collector %q", name)
		}

		c, err := found.Build()
		if err != nil {
			return nil, err
		}
		collectors[name] = c
	}

	return collectors, nil
}

'''
'''--- pkg/logs/config.go ---
package logs

import (
	"flag"
	"fmt"
	"path/filepath"

	"github.com/grafana/loki/clients/pkg/promtail/client"
	"github.com/grafana/loki/clients/pkg/promtail/positions"
	"github.com/grafana/loki/clients/pkg/promtail/scrapeconfig"
	"github.com/grafana/loki/clients/pkg/promtail/targets/file"
)

// Config controls the configuration of the Loki log scraper.
type Config struct {
	PositionsDirectory string            `yaml:"positions_directory,omitempty"`
	Configs            []*InstanceConfig `yaml:"configs,omitempty"`
}

// UnmarshalYAML implements yaml.Unmarshaler.
func (c *Config) UnmarshalYAML(unmarshal func(interface{}) error) error {
	type config Config
	err := unmarshal((*config)(c))
	if err != nil {
		return err
	}

	return c.ApplyDefaults()
}

// ApplyDefaults applies defaults to the Config and ensures that it is valid.
//
// Validations:
//
//   1. No two InstanceConfigs may have the same name.
//   2. No two InstanceConfigs may have the same positions path.
//   3. No InstanceConfig may have an empty name.
//   4. If InstanceConfig positions path is empty, shared PositionsDirectory
//      must not be empty.
//
// Defaults:
//
//   1. If a positions config is empty, it will be generated based on
//      the InstanceConfig name and Config.PositionsDirectory.
func (c *Config) ApplyDefaults() error {
	var (
		names     = map[string]struct{}{}
		positions = map[string]string{} // positions file name -> config using it
	)

	for idx, ic := range c.Configs {
		if ic.Name == "" {
			return fmt.Errorf("Loki config index %d must have a name", idx)
		}
		if _, ok := names[ic.Name]; ok {
			return fmt.Errorf("found two Loki configs with name %s", ic.Name)
		}
		names[ic.Name] = struct{}{}

		if ic.PositionsConfig.PositionsFile == "" {
			if c.PositionsDirectory == "" {
				return fmt.Errorf("cannot generate Loki positions file path for %s because positions_directory is not configured", ic.Name)
			}
			ic.PositionsConfig.PositionsFile = filepath.Join(c.PositionsDirectory, ic.Name+".yml")
		}
		if orig, ok := positions[ic.PositionsConfig.PositionsFile]; ok {
			return fmt.Errorf("Loki configs %s and %s must have different positions file paths", orig, ic.Name)
		}
		positions[ic.PositionsConfig.PositionsFile] = ic.Name
	}

	return nil
}

// InstanceConfig is an individual Promtail config.
type InstanceConfig struct {
	Name string `yaml:"name,omitempty"`

	ClientConfigs   []client.Config       `yaml:"clients,omitempty"`
	PositionsConfig positions.Config      `yaml:"positions,omitempty"`
	ScrapeConfig    []scrapeconfig.Config `yaml:"scrape_configs,omitempty"`
	TargetConfig    file.Config           `yaml:"target_config,omitempty"`
}

// UnmarshalYAML implements yaml.Unmarshaler.
func (c *InstanceConfig) UnmarshalYAML(unmarshal func(interface{}) error) error {
	// Defaults for Promtail are hidden behind flags. Register flags to a fake flagset
	// just to set the defaults in the configs.
	fs := flag.NewFlagSet("temp", flag.PanicOnError)
	c.PositionsConfig.RegisterFlags(fs)
	c.TargetConfig.RegisterFlags(fs)

	// Blank out the positions file since we set our own default for that.
	c.PositionsConfig.PositionsFile = ""

	type instanceConfig InstanceConfig
	return unmarshal((*instanceConfig)(c))
}

'''
'''--- pkg/logs/config_test.go ---
package logs

import (
	"fmt"
	"path/filepath"
	"strings"
	"testing"

	"github.com/stretchr/testify/require"
	"gopkg.in/yaml.v2"
)

func TestConfig_ApplyDefaults_Validations(t *testing.T) {
	tt := []struct {
		name string
		cfg  string
		err  error
	}{
		{
			name: "two configs with different names",
			err:  nil,
			cfg: untab(`
				positions_directory: /tmp
				configs:
				- name: config-a
				- name: config-b
		  `),
		},
		{
			name: "two configs with same name",
			err:  fmt.Errorf("found two Loki configs with name config-a"),
			cfg: untab(`
				positions_directory: /tmp
				configs:
				- name: config-a
				- name: config-b
				- name: config-a
		  `),
		},
		{
			name: "two configs, different positions path",
			err:  nil,
			cfg: untab(`
				configs:
				- name: config-a
				  positions:
					  filename: /tmp/file-a.yml
				- name: config-b
				  positions:
					  filename: /tmp/file-b.yml
		  `),
		},
		{
			name: "re-used positions path",
			err:  fmt.Errorf("Loki configs config-a and config-c must have different positions file paths"),
			cfg: untab(`
				configs:
				- name: config-a
				  positions:
					  filename: /tmp/file-a.yml
				- name: config-b
				  positions:
					  filename: /tmp/file-b.yml
				- name: config-c
				  positions:
					  filename: /tmp/file-a.yml
		  `),
		},
		{
			name: "empty name",
			err:  fmt.Errorf("Loki config index 1 must have a name"),
			cfg: untab(`
				positions_directory: /tmp
				configs:
				- name: config-a
				- name:
				- name: config-a
		  `),
		},
		{
			name: "generated positions file path without positions_directory",
			err:  fmt.Errorf("cannot generate Loki positions file path for config-b because positions_directory is not configured"),
			cfg: untab(`
				configs:
				- name: config-a
				  positions:
					  filename: /tmp/config-a.yaml
				- name: config-b
		  `),
		},
	}

	for _, tc := range tt {
		t.Run(tc.name, func(t *testing.T) {
			var cfg Config
			err := yaml.UnmarshalStrict([]byte(tc.cfg), &cfg)
			if tc.err == nil {
				require.NoError(t, err)
			} else {
				require.EqualError(t, err, tc.err.Error())
			}
		})
	}
}

func TestConfig_ApplyDefaults_Defaults(t *testing.T) {
	cfgText := untab(`
		positions_directory: /tmp
		configs:
		- name: config-a
			positions:
				filename: /config-a.yml
		- name: config-b
	`)
	var cfg Config
	err := yaml.UnmarshalStrict([]byte(cfgText), &cfg)
	require.NoError(t, err)

	var (
		pathA = cfg.Configs[0].PositionsConfig.PositionsFile
		pathB = cfg.Configs[1].PositionsConfig.PositionsFile
	)

	require.Equal(t, "/config-a.yml", pathA)
	require.Equal(t, filepath.Join("/tmp", "config-b.yml"), pathB)
}

// untab is a utility function to make it easier to write YAML tests, where some editors
// will insert tabs into strings by default.
func untab(s string) string {
	return strings.ReplaceAll(s, "\t", "  ")
}

'''
'''--- pkg/logs/http.go ---
package logs

import (
	"net/http"
	"sort"

	"github.com/go-kit/log/level"
	"github.com/gorilla/mux"
	"github.com/grafana/agent/pkg/metrics/cluster/configapi"
	"github.com/grafana/loki/clients/pkg/promtail/targets/target"
	"github.com/prometheus/common/model"
)

// WireAPI adds API routes to the provided mux router.
func (l *Logs) WireAPI(r *mux.Router) {
	r.HandleFunc("/agent/api/v1/logs/instances", l.ListInstancesHandler).Methods("GET")
	r.HandleFunc("/agent/api/v1/logs/targets", l.ListTargetsHandler).Methods("GET")
}

// ListInstancesHandler writes the set of currently running instances to the http.ResponseWriter.
func (l *Logs) ListInstancesHandler(w http.ResponseWriter, _ *http.Request) {
	instances := l.instances
	instanceNames := make([]string, 0, len(instances))
	for instance := range instances {
		instanceNames = append(instanceNames, instance)
	}
	sort.Strings(instanceNames)

	err := configapi.WriteResponse(w, http.StatusOK, instanceNames)
	if err != nil {
		level.Error(l.l).Log("msg", "failed to write response", "err", err)
	}
}

// ListTargetsHandler retrieves the full set of targets across all instances and shows
// information on them.
func (l *Logs) ListTargetsHandler(w http.ResponseWriter, r *http.Request) {
	instances := l.instances
	allTagets := make(map[string]TargetSet, len(instances))
	for instName, inst := range instances {
		allTagets[instName] = inst.promtail.ActiveTargets()
	}
	listTargetsHandler(allTagets).ServeHTTP(w, r)
}

func listTargetsHandler(targets map[string]TargetSet) http.Handler {
	return http.HandlerFunc(func(rw http.ResponseWriter, _ *http.Request) {
		resp := ListTargetsResponse{}
		for instance, tset := range targets {
			for key, targets := range tset {
				for _, tgt := range targets {
					resp = append(resp, TargetInfo{
						InstanceName:     instance,
						TargetGroup:      key,
						Type:             tgt.Type(),
						DiscoveredLabels: tgt.DiscoveredLabels(),
						Labels:           tgt.Labels(),
						Ready:            tgt.Ready(),
						Details:          tgt.Details(),
					})
				}
			}
		}
		_ = configapi.WriteResponse(rw, http.StatusOK, resp)
	})
}

// TargetSet is a set of targets for an individual scraper.
type TargetSet map[string][]target.Target

// ListTargetsResponse is returned by the ListTargetsHandler.
type ListTargetsResponse []TargetInfo

// TargetInfo describes a specific target.
type TargetInfo struct {
	InstanceName string `json:"instance"`
	TargetGroup  string `json:"target_group"`

	Type             target.TargetType `json:"type"`
	Labels           model.LabelSet    `json:"labels"`
	DiscoveredLabels model.LabelSet    `json:"discovered_labels"`
	Ready            bool              `json:"ready"`
	Details          interface{}       `json:"details"`
}

'''
'''--- pkg/logs/http_test.go ---
package logs

import (
	"net/http"
	"net/http/httptest"
	"strings"
	"testing"
	"time"

	"github.com/cortexproject/cortex/pkg/util/test"
	"github.com/grafana/agent/pkg/util"
	"github.com/grafana/loki/clients/pkg/promtail/targets/target"
	"github.com/prometheus/client_golang/prometheus"
	"github.com/prometheus/common/model"
	"github.com/stretchr/testify/require"
	"gopkg.in/yaml.v2"
)

func TestAgent_ListInstancesHandler(t *testing.T) {
	cfgText := util.Untab(`
configs:
- name: instance-a
  positions:
    filename: /tmp/positions.yaml
  clients:
	- url: http://127.0.0.1:80/loki/api/v1/push
	`)

	var cfg Config

	logger := util.TestLogger(t)
	l, err := New(prometheus.NewRegistry(), &cfg, logger)
	require.NoError(t, err)
	defer l.Stop()

	r := httptest.NewRequest("GET", "/agent/api/v1/logs/instances", nil)

	t.Run("no instances", func(t *testing.T) {
		rr := httptest.NewRecorder()
		l.ListInstancesHandler(rr, r)
		expect := `{"status":"success","data":[]}`
		require.Equal(t, expect, rr.Body.String())
	})

	dec := yaml.NewDecoder(strings.NewReader(cfgText))
	dec.SetStrict(true)
	require.NoError(t, dec.Decode(&cfg))
	t.Run("non-empty", func(t *testing.T) {
		require.NoError(t, l.ApplyConfig(&cfg))

		expect := `{"status":"success","data":["instance-a"]}`
		test.Poll(t, time.Second, true, func() interface{} {
			rr := httptest.NewRecorder()
			l.ListInstancesHandler(rr, r)
			return expect == rr.Body.String()
		})
	})
}

func TestAgent_ListTargetsHandler(t *testing.T) {
	cfgText := util.Untab(`
configs:
- name: instance-a
  positions:
    filename: /tmp/positions.yaml
  clients:
	- url: http://127.0.0.1:80/loki/api/v1/push
	`)

	var cfg Config
	dec := yaml.NewDecoder(strings.NewReader(cfgText))
	dec.SetStrict(true)
	require.NoError(t, dec.Decode(&cfg))

	logger := util.TestLogger(t)
	l, err := New(prometheus.NewRegistry(), &cfg, logger)
	require.NoError(t, err)
	defer l.Stop()

	r := httptest.NewRequest("GET", "/agent/api/v1/logs/targets", nil)

	t.Run("scrape manager not ready", func(t *testing.T) {
		rr := httptest.NewRecorder()
		l.ListTargetsHandler(rr, r)
		expect := `{"status": "success", "data": []}`
		require.JSONEq(t, expect, rr.Body.String())
		require.Equal(t, http.StatusOK, rr.Result().StatusCode)
	})

	t.Run("scrape manager targets", func(t *testing.T) {
		rr := httptest.NewRecorder()
		targets := map[string]TargetSet{
			"instance-a": mockActiveTargets(),
		}
		listTargetsHandler(targets).ServeHTTP(rr, r)
		expect := `{
			"status": "success",
			"data": [
				{
				  "instance": "instance-a",
				  "target_group": "varlogs",
				  "type": "File",
				  "labels": {
					"job": "varlogs"
				  },
				  "discovered_labels": {
					"__address__": "localhost",
					"__path__": "/var/log/*log",
					"job": "varlogs"
				  },
				  "ready": true,
				  "details": {
					"/var/log/alternatives.log": 13386,
					"/var/log/apport.log": 0,
					"/var/log/auth.log": 37009,
					"/var/log/bootstrap.log": 107347,
					"/var/log/dpkg.log": 374420,
					"/var/log/faillog": 0,
					"/var/log/fontconfig.log": 11629,
					"/var/log/gpu-manager.log": 1541,
					"/var/log/kern.log": 782582,
					"/var/log/lastlog": 0,
					"/var/log/syslog": 788450
				  }
				}
			]  
		}`
		require.JSONEq(t, expect, rr.Body.String())
		require.Equal(t, http.StatusOK, rr.Result().StatusCode)
	})
}

func mockActiveTargets() map[string][]target.Target {
	return map[string][]target.Target{
		"varlogs": {&mockTarget{}},
	}
}

type mockTarget struct {
}

func (mt *mockTarget) Type() target.TargetType {
	return target.TargetType("File")
}

func (mt *mockTarget) DiscoveredLabels() model.LabelSet {
	return map[model.LabelName]model.LabelValue{
		"__address__": "localhost",
		"__path__":    "/var/log/*log",
		"job":         "varlogs",
	}
}

func (mt *mockTarget) Labels() model.LabelSet {
	return map[model.LabelName]model.LabelValue{
		"job": "varlogs",
	}
}

func (mt *mockTarget) Ready() bool {
	return true
}

func (mt *mockTarget) Details() interface{} {
	return map[string]int{
		"/var/log/alternatives.log": 13386,
		"/var/log/apport.log":       0,
		"/var/log/auth.log":         37009,
		"/var/log/bootstrap.log":    107347,
		"/var/log/dpkg.log":         374420,
		"/var/log/faillog":          0,
		"/var/log/fontconfig.log":   11629,
		"/var/log/gpu-manager.log":  1541,
		"/var/log/kern.log":         782582,
		"/var/log/lastlog":          0,
		"/var/log/syslog":           788450,
	}
}

'''
'''--- pkg/logs/logs.go ---
// Package logs implements logs support for the Grafana Agent.
package logs

import (
	"fmt"
	"os"
	"path/filepath"
	"sync"
	"time"
	_ "time/tzdata" // embed timezone data

	"github.com/go-kit/log"
	"github.com/go-kit/log/level"
	"github.com/grafana/agent/pkg/util"
	"github.com/grafana/loki/clients/pkg/promtail"
	"github.com/grafana/loki/clients/pkg/promtail/api"
	"github.com/grafana/loki/clients/pkg/promtail/client"
	"github.com/grafana/loki/clients/pkg/promtail/config"
	"github.com/grafana/loki/clients/pkg/promtail/server"
	"github.com/prometheus/client_golang/prometheus"
	"github.com/prometheus/common/version"
)

func init() {
	client.UserAgent = fmt.Sprintf("GrafanaAgent/%s", version.Version)
}

// Logs is a Logs log collection. It uses multiple distinct sets of Logs
// Promtail agents to collect logs and send them to a Logs server.
type Logs struct {
	mut sync.Mutex

	reg       prometheus.Registerer
	l         log.Logger
	instances map[string]*Instance
}

// New creates and starts Loki log collection.
func New(reg prometheus.Registerer, c *Config, l log.Logger) (*Logs, error) {
	logs := &Logs{
		instances: make(map[string]*Instance),
		reg:       reg,
		l:         log.With(l, "component", "logs"),
	}
	if err := logs.ApplyConfig(c); err != nil {
		return nil, err
	}
	return logs, nil
}

// ApplyConfig updates Logs with a new Config.
func (l *Logs) ApplyConfig(c *Config) error {
	l.mut.Lock()
	defer l.mut.Unlock()

	if c == nil {
		c = &Config{}
	}

	newInstances := make(map[string]*Instance, len(c.Configs))

	for _, ic := range c.Configs {
		// If an old instance existed, update it and move it to the new map.
		if old, ok := l.instances[ic.Name]; ok {
			err := old.ApplyConfig(ic)
			if err != nil {
				return err
			}

			newInstances[ic.Name] = old
			continue
		}

		inst, err := NewInstance(l.reg, ic, l.l)
		if err != nil {
			return fmt.Errorf("unable to apply config for %s: %w", ic.Name, err)
		}
		newInstances[ic.Name] = inst
	}

	// Any promtail in l.instances that isn't in newInstances has been removed
	// from the config. Stop them before replacing the map.
	for key, i := range l.instances {
		if _, exist := newInstances[key]; exist {
			continue
		}
		i.Stop()
	}
	l.instances = newInstances

	return nil
}

// Stop stops the log collector.
func (l *Logs) Stop() {
	l.mut.Lock()
	defer l.mut.Unlock()

	for _, i := range l.instances {
		i.Stop()
	}
}

// Instance is used to retrieve a named Logs instance
func (l *Logs) Instance(name string) *Instance {
	l.mut.Lock()
	defer l.mut.Unlock()

	return l.instances[name]
}

// Instance is an individual Logs instance.
type Instance struct {
	mut sync.Mutex

	cfg *InstanceConfig
	log log.Logger
	reg *util.Unregisterer

	promtail *promtail.Promtail
}

// NewInstance creates and starts a Logs instance.
func NewInstance(reg prometheus.Registerer, c *InstanceConfig, l log.Logger) (*Instance, error) {
	instReg := prometheus.WrapRegistererWith(prometheus.Labels{"logs_config": c.Name}, reg)

	inst := Instance{
		reg: util.WrapWithUnregisterer(instReg),
		log: log.With(l, "logs_config", c.Name),
	}
	if err := inst.ApplyConfig(c); err != nil {
		return nil, err
	}
	return &inst, nil
}

// ApplyConfig will apply a new InstanceConfig. If the config hasn't changed,
// then nothing will happen, otherwise the old Promtail will be stopped and
// then replaced with a new one.
func (i *Instance) ApplyConfig(c *InstanceConfig) error {
	i.mut.Lock()
	defer i.mut.Unlock()

	// No-op if the configs haven't changed.
	if util.CompareYAML(c, i.cfg) {
		level.Debug(i.log).Log("msg", "instance config hasn't changed, not recreating Promtail")
		return nil
	}
	i.cfg = c

	positionsDir := filepath.Dir(c.PositionsConfig.PositionsFile)
	err := os.MkdirAll(positionsDir, 0775)
	if err != nil {
		level.Warn(i.log).Log("msg", "failed to create the positions directory. logs may be unable to save their position", "path", positionsDir, "err", err)
	}

	if i.promtail != nil {
		i.promtail.Shutdown()
		i.promtail = nil
	}

	// Unregister all existing metrics before trying to create a new instance.
	if !i.reg.UnregisterAll() {
		// If UnregisterAll fails, we need to abort, otherwise the new promtail
		// would try to re-register an existing metric and might panic.
		return fmt.Errorf("failed to unregister all metrics from previous promtail. THIS IS A BUG")
	}

	if len(c.ClientConfigs) == 0 {
		level.Debug(i.log).Log("msg", "skipping creation of a promtail because no client_configs are present")
		return nil
	}

	clientMetrics := client.NewMetrics(i.reg, nil)
	p, err := promtail.New(config.Config{
		ServerConfig:    server.Config{Disable: true},
		ClientConfigs:   c.ClientConfigs,
		PositionsConfig: c.PositionsConfig,
		ScrapeConfig:    c.ScrapeConfig,
		TargetConfig:    c.TargetConfig,
	}, clientMetrics, false, promtail.WithLogger(i.log), promtail.WithRegisterer(i.reg))
	if err != nil {
		return fmt.Errorf("unable to create logs instance: %w", err)
	}

	i.promtail = p
	return nil
}

// SendEntry passes an entry to the internal promtail client and returns true if successfully sent. It is
// best effort and not guaranteed to succeed.
func (i *Instance) SendEntry(entry api.Entry, dur time.Duration) bool {
	i.mut.Lock()
	defer i.mut.Unlock()

	// promtail is nil it has been stopped
	if i.promtail != nil {
		// send non blocking so we don't block the mutex. this is best effort
		select {
		case i.promtail.Client().Chan() <- entry:
			return true
		case <-time.After(dur):
		}
	}

	return false
}

// Stop stops the Promtail instance.
func (i *Instance) Stop() {
	i.mut.Lock()
	defer i.mut.Unlock()

	if i.promtail != nil {
		i.promtail.Shutdown()
		i.promtail = nil
	}
}

'''
'''--- pkg/logs/logs_test.go ---
//go:build !race
// +build !race

package logs

import (
	"fmt"
	"io/ioutil"
	"net"
	"net/http"
	"os"
	"path/filepath"
	"strings"
	"testing"
	"time"

	"github.com/grafana/loki/pkg/loghttp/push"

	"github.com/go-kit/log"
	"github.com/grafana/agent/pkg/util"
	"github.com/grafana/loki/pkg/logproto"
	"github.com/prometheus/client_golang/prometheus"
	"github.com/stretchr/testify/require"
	"gopkg.in/yaml.v2"
)

func TestLogs_NilConfig(t *testing.T) {
	l, err := New(prometheus.NewRegistry(), nil, util.TestLogger(t))
	require.NoError(t, err)
	require.NoError(t, l.ApplyConfig(nil))

	defer l.Stop()
}

func TestLogs(t *testing.T) {
	//
	// Create a temporary file to tail
	//
	positionsDir, err := ioutil.TempDir(os.TempDir(), "positions-*")
	require.NoError(t, err)
	t.Cleanup(func() {
		_ = os.RemoveAll(positionsDir)
	})

	tmpFile, err := ioutil.TempFile(os.TempDir(), "*.log")
	require.NoError(t, err)
	t.Cleanup(func() {
		_ = os.RemoveAll(tmpFile.Name())
	})

	//
	// Listen for push requests and pass them through to a channel
	//
	pushes := make(chan *logproto.PushRequest)

	lis, err := net.Listen("tcp", "127.0.0.1:0")
	require.NoError(t, err)
	t.Cleanup(func() {
		require.NoError(t, lis.Close())
	})
	go func() {
		_ = http.Serve(lis, http.HandlerFunc(func(rw http.ResponseWriter, r *http.Request) {
			req, err := push.ParseRequest(log.NewNopLogger(), "user_id", r, nil)
			require.NoError(t, err)

			pushes <- req
			_, _ = rw.Write(nil)
		}))
	}()

	//
	// Launch Loki so it starts tailing the file and writes to our server.
	//
	cfgText := util.Untab(fmt.Sprintf(`
positions_directory: %s
configs:
- name: default
  clients:
  - url: http://%s/loki/api/v1/push
		batchwait: 50ms
		batchsize: 1
  scrape_configs:
  - job_name: system
    static_configs:
    - targets: [localhost]
      labels:
        job: test
        __path__: %s
	`, positionsDir, lis.Addr().String(), tmpFile.Name()))

	var cfg Config
	dec := yaml.NewDecoder(strings.NewReader(cfgText))
	dec.SetStrict(true)
	require.NoError(t, dec.Decode(&cfg))

	logger := log.NewSyncLogger(log.NewNopLogger())
	l, err := New(prometheus.NewRegistry(), &cfg, logger)
	require.NoError(t, err)
	defer l.Stop()

	//
	// Write a log line and wait for it to come through.
	//
	fmt.Fprintf(tmpFile, "Hello, world!\n")
	select {
	case <-time.After(time.Second * 30):
		require.FailNow(t, "timed out waiting for data to be pushed")
	case req := <-pushes:
		require.Equal(t, "Hello, world!", req.Streams[0].Entries[0].Line)
	}

	//
	// Apply a new config and write a new line.
	//
	cfgText = util.Untab(fmt.Sprintf(`
positions_directory: %s
configs:
- name: default
  clients:
  - url: http://%s/loki/api/v1/push
		batchwait: 50ms
		batchsize: 5
  scrape_configs:
  - job_name: system
    static_configs:
    - targets: [localhost]
      labels:
        job: test-2
        __path__: %s
	`, positionsDir, lis.Addr().String(), tmpFile.Name()))

	var newCfg Config
	dec = yaml.NewDecoder(strings.NewReader(cfgText))
	dec.SetStrict(true)
	require.NoError(t, dec.Decode(&newCfg))

	require.NoError(t, l.ApplyConfig(&newCfg))

	fmt.Fprintf(tmpFile, "Hello again!\n")
	select {
	case <-time.After(time.Second * 30):
		require.FailNow(t, "timed out waiting for data to be pushed")
	case req := <-pushes:
		require.Equal(t, "Hello again!", req.Streams[0].Entries[0].Line)
	}

	t.Run("update to nil", func(t *testing.T) {
		// Applying a nil config should remove all instances.
		err := l.ApplyConfig(nil)
		require.NoError(t, err)
		require.Len(t, l.instances, 0)
	})
}

func TestLogs_PositionsDirectory(t *testing.T) {
	//
	// Create a temporary file to tail
	//
	positionsDir, err := ioutil.TempDir(os.TempDir(), "positions-*")
	require.NoError(t, err)
	t.Cleanup(func() {
		_ = os.RemoveAll(positionsDir)
	})

	//
	// Launch Loki so it starts tailing the file and writes to our server.
	//
	cfgText := util.Untab(fmt.Sprintf(`
positions_directory: %[1]s/positions
configs:
- name: instance-a
  clients:
	- url: http://127.0.0.1:80/loki/api/v1/push
- name: instance-b
  positions:
	  filename: %[1]s/other-positions/instance.yml
  clients:
	- url: http://127.0.0.1:80/loki/api/v1/push
	`, positionsDir))

	var cfg Config
	dec := yaml.NewDecoder(strings.NewReader(cfgText))
	dec.SetStrict(true)
	require.NoError(t, dec.Decode(&cfg))

	logger := util.TestLogger(t)
	l, err := New(prometheus.NewRegistry(), &cfg, logger)
	require.NoError(t, err)
	defer l.Stop()

	_, err = os.Stat(filepath.Join(positionsDir, "positions"))
	require.NoError(t, err, "default shared positions directory did not get created")
	_, err = os.Stat(filepath.Join(positionsDir, "other-positions"))
	require.NoError(t, err, "instance-specific positions directory did not get creatd")
}

'''
'''--- pkg/metrics/agent.go ---
// Package metrics implements a Prometheus-lite client for service discovery,
// scraping metrics into a WAL, and remote_write. Clients are broken into a
// set of instances, each of which contain their own set of configs.
package metrics

import (
	"errors"
	"flag"
	"fmt"
	"sync"
	"time"

	"github.com/go-kit/log"
	"github.com/go-kit/log/level"
	"github.com/prometheus/client_golang/prometheus"
	"go.uber.org/atomic"
	"google.golang.org/grpc"

	"github.com/grafana/agent/pkg/metrics/cluster"
	"github.com/grafana/agent/pkg/metrics/cluster/client"
	"github.com/grafana/agent/pkg/metrics/instance"
	"github.com/grafana/agent/pkg/util"
	"github.com/prometheus/prometheus/discovery"
)

// DefaultConfig is the default settings for the Prometheus-lite client.
var DefaultConfig = Config{
	Global:                 instance.DefaultGlobalConfig,
	InstanceRestartBackoff: instance.DefaultBasicManagerConfig.InstanceRestartBackoff,
	WALDir:                 "data-agent/",
	WALCleanupAge:          DefaultCleanupAge,
	WALCleanupPeriod:       DefaultCleanupPeriod,
	ServiceConfig:          cluster.DefaultConfig,
	ServiceClientConfig:    client.DefaultConfig,
	InstanceMode:           instance.DefaultMode,
}

// Config defines the configuration for the entire set of Prometheus client
// instances, along with a global configuration.
type Config struct {
	Global                 instance.GlobalConfig `yaml:"global,omitempty"`
	WALDir                 string                `yaml:"wal_directory,omitempty"`
	WALCleanupAge          time.Duration         `yaml:"wal_cleanup_age,omitempty"`
	WALCleanupPeriod       time.Duration         `yaml:"wal_cleanup_period,omitempty"`
	ServiceConfig          cluster.Config        `yaml:"scraping_service,omitempty"`
	ServiceClientConfig    client.Config         `yaml:"scraping_service_client,omitempty"`
	Configs                []instance.Config     `yaml:"configs,omitempty,omitempty"`
	InstanceRestartBackoff time.Duration         `yaml:"instance_restart_backoff,omitempty"`
	InstanceMode           instance.Mode         `yaml:"instance_mode,omitempty"`
	DisableKeepAlives      bool                  `yaml:"http_disable_keepalives,omitempty"`
	IdleConnTimeout        time.Duration         `yaml:"http_idle_conn_timeout,omitempty"`

	// Unmarshaled is true when the Config was unmarshaled from YAML.
	Unmarshaled bool `yaml:"-"`
}

// UnmarshalYAML implements yaml.Unmarshaler.
func (c *Config) UnmarshalYAML(unmarshal func(interface{}) error) error {
	*c = DefaultConfig
	util.DefaultConfigFromFlags(c)
	c.Unmarshaled = true

	type plain Config
	err := unmarshal((*plain)(c))
	if err != nil {
		return err
	}

	c.ServiceConfig.Client = c.ServiceClientConfig
	return nil
}

// ApplyDefaults applies default values to the Config and validates it.
func (c *Config) ApplyDefaults() error {
	needWAL := len(c.Configs) > 0 || c.ServiceConfig.Enabled
	if needWAL && c.WALDir == "" {
		return errors.New("no wal_directory configured")
	}

	if c.ServiceConfig.Enabled && len(c.Configs) > 0 {
		return errors.New("cannot use configs when scraping_service mode is enabled")
	}

	c.Global.DisableKeepAlives = c.DisableKeepAlives
	c.Global.IdleConnTimeout = c.IdleConnTimeout
	usedNames := map[string]struct{}{}

	for i := range c.Configs {
		name := c.Configs[i].Name
		if err := c.Configs[i].ApplyDefaults(c.Global); err != nil {
			// Try to show a helpful name in the error
			if name == "" {
				name = fmt.Sprintf("at index %d", i)
			}

			return fmt.Errorf("error validating instance %s: %w", name, err)
		}

		if _, ok := usedNames[name]; ok {
			return fmt.Errorf(
				"prometheus instance names must be unique. found multiple instances with name %s",
				name,
			)
		}
		usedNames[name] = struct{}{}
	}

	return nil
}

// RegisterFlags defines flags corresponding to the Config.
func (c *Config) RegisterFlags(f *flag.FlagSet) {
	c.RegisterFlagsWithPrefix("metrics.", f)
}

// RegisterFlagsWithPrefix defines flags with the provided prefix.
func (c *Config) RegisterFlagsWithPrefix(prefix string, f *flag.FlagSet) {
	f.StringVar(&c.WALDir, prefix+"wal-directory", DefaultConfig.WALDir, "base directory to store the WAL in")
	f.DurationVar(&c.WALCleanupAge, prefix+"wal-cleanup-age", DefaultConfig.WALCleanupAge, "remove abandoned (unused) WALs older than this")
	f.DurationVar(&c.WALCleanupPeriod, prefix+"wal-cleanup-period", DefaultConfig.WALCleanupPeriod, "how often to check for abandoned WALs")
	f.DurationVar(&c.InstanceRestartBackoff, prefix+"instance-restart-backoff", DefaultConfig.InstanceRestartBackoff, "how long to wait before restarting a failed Prometheus instance")

	c.ServiceConfig.RegisterFlagsWithPrefix(prefix+"service.", f)
	c.ServiceClientConfig.RegisterFlagsWithPrefix(prefix, f)
}

// Agent is an agent for collecting Prometheus metrics. It acts as a
// Prometheus-lite; only running the service discovery, remote_write, and WAL
// components of Prometheus. It is broken down into a series of Instances, each
// of which perform metric collection.
type Agent struct {
	mut    sync.RWMutex
	cfg    Config
	logger log.Logger
	reg    prometheus.Registerer

	// Store both the basic manager and the modal manager so we can update their
	// settings indepedently. Only the ModalManager should be used for mutating
	// configs.
	bm      *instance.BasicManager
	mm      *instance.ModalManager
	cleaner *WALCleaner

	instanceFactory instanceFactory

	cluster *cluster.Cluster

	stopped  bool
	stopOnce sync.Once
	actor    chan func()

	initialBootDone atomic.Bool
}

// New creates and starts a new Agent.
func New(reg prometheus.Registerer, cfg Config, logger log.Logger) (*Agent, error) {
	// This registers discovery metrics with the default registry which should be the reg specified above.
	discovery.RegisterMetrics()
	return newAgent(reg, cfg, logger, defaultInstanceFactory)
}

func newAgent(reg prometheus.Registerer, cfg Config, logger log.Logger, fact instanceFactory) (*Agent, error) {
	a := &Agent{
		logger:          log.With(logger, "agent", "prometheus"),
		instanceFactory: fact,
		reg:             reg,
		actor:           make(chan func(), 1),
	}

	a.bm = instance.NewBasicManager(instance.BasicManagerConfig{
		InstanceRestartBackoff: cfg.InstanceRestartBackoff,
	}, a.logger, a.newInstance)

	var err error
	a.mm, err = instance.NewModalManager(a.reg, a.logger, a.bm, cfg.InstanceMode)
	if err != nil {
		return nil, fmt.Errorf("failed to create modal instance manager: %w", err)
	}

	a.cluster, err = cluster.New(a.logger, reg, cfg.ServiceConfig, a.mm, a.Validate)
	if err != nil {
		return nil, err
	}

	if err := a.ApplyConfig(cfg); err != nil {
		return nil, err
	}
	go a.run()
	return a, nil
}

// newInstance creates a new Instance given a config.
func (a *Agent) newInstance(c instance.Config) (instance.ManagedInstance, error) {
	a.mut.RLock()
	defer a.mut.RUnlock()

	// Controls the label
	instanceLabel := "instance_name"
	if a.cfg.InstanceMode == instance.ModeShared {
		instanceLabel = "instance_group_name"
	}

	reg := prometheus.WrapRegistererWith(prometheus.Labels{
		instanceLabel: c.Name,
	}, a.reg)

	return a.instanceFactory(reg, c, a.cfg.WALDir, a.logger)
}

// Validate will validate the incoming Config and mutate it to apply defaults.
func (a *Agent) Validate(c *instance.Config) error {
	a.mut.RLock()
	defer a.mut.RUnlock()

	if a.cfg.WALDir == "" {
		return fmt.Errorf("no wal_directory configured")
	}

	if err := c.ApplyDefaults(a.cfg.Global); err != nil {
		return fmt.Errorf("failed to apply defaults to %q: %w", c.Name, err)
	}
	return nil
}

// ApplyConfig applies config changes to the Agent.
func (a *Agent) ApplyConfig(cfg Config) error {
	a.mut.Lock()
	defer a.mut.Unlock()

	if util.CompareYAML(a.cfg, cfg) {
		return nil
	}

	if a.stopped {
		return fmt.Errorf("agent stopped")
	}

	// The ordering here is done to minimze the number of instances that need to
	// be restarted. We update components from lowest to highest level:
	//
	// 1. WAL Cleaner
	// 2. Basic manager
	// 3. Modal Manager
	// 4. Cluster
	// 5. Local configs

	if a.cleaner != nil {
		a.cleaner.Stop()
		a.cleaner = nil
	}
	if cfg.WALDir != "" {
		a.cleaner = NewWALCleaner(
			a.logger,
			a.mm,
			cfg.WALDir,
			cfg.WALCleanupAge,
			cfg.WALCleanupPeriod,
		)
	}

	a.bm.UpdateManagerConfig(instance.BasicManagerConfig{
		InstanceRestartBackoff: cfg.InstanceRestartBackoff,
	})

	if err := a.mm.SetMode(cfg.InstanceMode); err != nil {
		return err
	}

	if err := a.cluster.ApplyConfig(cfg.ServiceConfig); err != nil {
		return fmt.Errorf("failed to apply cluster config: %w", err)
	}

	// Queue an actor in the background to sync the instances. This is required
	// because creating both this function and newInstance grab the mutex.
	oldConfig := a.cfg

	a.actor <- func() {
		a.syncInstances(oldConfig, cfg)
		a.initialBootDone.Store(true)
	}

	a.cfg = cfg
	return nil
}

// syncInstances syncs the state of the instance manager to newConfig by
// applying all configs from newConfig and deleting any configs from oldConfig
// that are not in newConfig.
func (a *Agent) syncInstances(oldConfig, newConfig Config) {
	// Apply the new configs
	for _, c := range newConfig.Configs {
		if err := a.mm.ApplyConfig(c); err != nil {
			level.Error(a.logger).Log("msg", "failed to apply config", "name", c.Name, "err", err)
		}
	}

	// Remove any configs from oldConfig that aren't in newConfig.
	for _, oc := range oldConfig.Configs {
		foundConfig := false
		for _, nc := range newConfig.Configs {
			if nc.Name == oc.Name {
				foundConfig = true
				break
			}
		}
		if foundConfig {
			continue
		}

		if err := a.mm.DeleteConfig(oc.Name); err != nil {
			level.Error(a.logger).Log("msg", "failed to delete old config", "name", oc.Name, "err", err)
		}
	}
}

// run calls received actor functions in the background.
func (a *Agent) run() {
	for f := range a.actor {
		f()
	}
}

// Ready returns true if both the agent and all instances
// spawned by a Manager have completed startup.
func (a *Agent) Ready() bool {
	// Wait for the initial load to complete so the instance manager has at least
	// the base set of expected instances.
	if !a.initialBootDone.Load() {
		return false
	}

	for _, inst := range a.mm.ListInstances() {
		if !inst.Ready() {
			return false
		}
	}

	return true
}

// WireGRPC wires gRPC services into the provided server.
func (a *Agent) WireGRPC(s *grpc.Server) {
	a.cluster.WireGRPC(s)
}

// Config returns the configuration of this Agent.
func (a *Agent) Config() Config { return a.cfg }

// InstanceManager returns the instance manager used by this Agent.
func (a *Agent) InstanceManager() instance.Manager { return a.mm }

// Stop stops the agent and all its instances.
func (a *Agent) Stop() {
	a.mut.Lock()
	defer a.mut.Unlock()

	// Close the actor channel to stop run.
	a.stopOnce.Do(func() {
		close(a.actor)
	})

	a.cluster.Stop()

	if a.cleaner != nil {
		a.cleaner.Stop()
	}

	// Only need to stop the ModalManager, which will passthrough everything to the
	// BasicManager.
	a.mm.Stop()

	a.stopped = true
}

type instanceFactory = func(reg prometheus.Registerer, cfg instance.Config, walDir string, logger log.Logger) (instance.ManagedInstance, error)

func defaultInstanceFactory(reg prometheus.Registerer, cfg instance.Config, walDir string, logger log.Logger) (instance.ManagedInstance, error) {
	return instance.New(reg, cfg, walDir, logger)
}

'''
'''--- pkg/metrics/agent_test.go ---
package metrics

import (
	"context"
	"errors"
	"fmt"
	"sync"
	"testing"
	"time"

	"github.com/cortexproject/cortex/pkg/util/test"
	"github.com/go-kit/log"
	"github.com/grafana/agent/pkg/metrics/instance"
	"github.com/prometheus/client_golang/prometheus"
	"github.com/prometheus/prometheus/scrape"
	"github.com/prometheus/prometheus/storage"
	"github.com/stretchr/testify/require"
	"go.uber.org/atomic"
	"gopkg.in/yaml.v2"
)

func TestConfig_Validate(t *testing.T) {
	valid := Config{
		WALDir: "/tmp/data",
		Configs: []instance.Config{
			makeInstanceConfig("instance"),
		},
		InstanceMode: instance.DefaultMode,
	}

	tt := []struct {
		name    string
		mutator func(c *Config)
		expect  error
	}{
		{
			name:    "complete config should be valid",
			mutator: func(c *Config) {},
			expect:  nil,
		},
		{
			name:    "no wal dir",
			mutator: func(c *Config) { c.WALDir = "" },
			expect:  errors.New("no wal_directory configured"),
		},
		{
			name:    "missing instance name",
			mutator: func(c *Config) { c.Configs[0].Name = "" },
			expect:  errors.New("error validating instance at index 0: missing instance name"),
		},
		{
			name: "duplicate config name",
			mutator: func(c *Config) {
				c.Configs = append(c.Configs,
					makeInstanceConfig("newinstance"),
					makeInstanceConfig("instance"),
				)
			},
			expect: errors.New("prometheus instance names must be unique. found multiple instances with name instance"),
		},
	}

	for _, tc := range tt {
		t.Run(tc.name, func(t *testing.T) {
			cfg := copyConfig(t, valid)
			tc.mutator(&cfg)

			err := cfg.ApplyDefaults()
			if tc.expect == nil {
				require.NoError(t, err)
			} else {
				require.EqualError(t, err, tc.expect.Error())
			}
		})
	}
}

func copyConfig(t *testing.T, c Config) Config {
	t.Helper()

	bb, err := yaml.Marshal(c)
	require.NoError(t, err)

	var cp Config
	err = yaml.Unmarshal(bb, &cp)
	require.NoError(t, err)
	return cp
}

func TestConfigNonzeroDefaultScrapeInterval(t *testing.T) {
	cfgText := `
wal_directory: ./wal
configs:
  - name: testconfig
    scrape_configs:
      - job_name: 'node'
        static_configs:
          - targets: ['localhost:9100']
`

	var cfg Config

	err := yaml.Unmarshal([]byte(cfgText), &cfg)
	require.NoError(t, err)
	err = cfg.ApplyDefaults()
	require.NoError(t, err)

	require.Equal(t, len(cfg.Configs), 1)
	instanceConfig := cfg.Configs[0]
	require.Equal(t, len(instanceConfig.ScrapeConfigs), 1)
	scrapeConfig := instanceConfig.ScrapeConfigs[0]
	require.Greater(t, int64(scrapeConfig.ScrapeInterval), int64(0))
}

func TestAgent(t *testing.T) {
	// Launch two instances
	cfg := Config{
		WALDir: "/tmp/wal",
		Configs: []instance.Config{
			makeInstanceConfig("instance_a"),
			makeInstanceConfig("instance_b"),
		},
		InstanceRestartBackoff: time.Duration(0),
		InstanceMode:           instance.ModeDistinct,
	}

	fact := newFakeInstanceFactory()

	a, err := newAgent(prometheus.NewRegistry(), cfg, log.NewNopLogger(), fact.factory)
	require.NoError(t, err)

	test.Poll(t, time.Second*30, true, func() interface{} {
		if fact.created == nil {
			return false
		}
		return fact.created.Load() == 2 && len(a.mm.ListInstances()) == 2
	})

	t.Run("instances should be running", func(t *testing.T) {
		for _, mi := range fact.Mocks() {
			// Each instance should have wait called on it
			test.Poll(t, time.Millisecond*500, true, func() interface{} {
				return mi.running.Load()
			})
		}
	})

	t.Run("instances should be restarted when stopped", func(t *testing.T) {
		for _, mi := range fact.Mocks() {
			test.Poll(t, time.Millisecond*500, int64(1), func() interface{} {
				return mi.startedCount.Load()
			})
		}

		for _, mi := range fact.Mocks() {
			mi.err <- fmt.Errorf("really bad error")
		}

		for _, mi := range fact.Mocks() {
			test.Poll(t, time.Millisecond*500, int64(2), func() interface{} {
				return mi.startedCount.Load()
			})
		}
	})
}

func TestAgent_NormalInstanceExits(t *testing.T) {
	tt := []struct {
		name          string
		simulateError error
	}{
		{"no error", nil},
		{"context cancelled", context.Canceled},
	}

	cfg := Config{
		WALDir: "/tmp/wal",
		Configs: []instance.Config{
			makeInstanceConfig("instance_a"),
			makeInstanceConfig("instance_b"),
		},
		InstanceRestartBackoff: time.Duration(0),
		InstanceMode:           instance.ModeDistinct,
	}

	for _, tc := range tt {
		t.Run(tc.name, func(t *testing.T) {
			fact := newFakeInstanceFactory()

			a, err := newAgent(prometheus.NewRegistry(), cfg, log.NewNopLogger(), fact.factory)
			require.NoError(t, err)

			test.Poll(t, time.Second*30, true, func() interface{} {
				if fact.created == nil {
					return false
				}
				return fact.created.Load() == 2 && len(a.mm.ListInstances()) == 2
			})

			for _, mi := range fact.Mocks() {
				mi.err <- tc.simulateError
			}

			time.Sleep(time.Millisecond * 100)

			// Get the new total amount of instances starts; value should
			// be unchanged.
			var startedCount int64
			for _, i := range fact.Mocks() {
				startedCount += i.startedCount.Load()
			}

			// There should only be two instances that started. If there's more, something
			// restarted despite our error.
			require.Equal(t, int64(2), startedCount, "instances should not have restarted")
		})
	}
}

func TestAgent_Stop(t *testing.T) {
	// Launch two instances
	cfg := Config{
		WALDir: "/tmp/wal",
		Configs: []instance.Config{
			makeInstanceConfig("instance_a"),
			makeInstanceConfig("instance_b"),
		},
		InstanceRestartBackoff: time.Duration(0),
		InstanceMode:           instance.ModeDistinct,
	}

	fact := newFakeInstanceFactory()

	a, err := newAgent(prometheus.NewRegistry(), cfg, log.NewNopLogger(), fact.factory)
	require.NoError(t, err)

	test.Poll(t, time.Second*30, true, func() interface{} {
		if fact.created == nil {
			return false
		}
		return fact.created.Load() == 2 && len(a.mm.ListInstances()) == 2
	})

	a.Stop()

	time.Sleep(time.Millisecond * 100)

	for _, mi := range fact.Mocks() {
		require.False(t, mi.running.Load(), "instance should not have been restarted")
	}
}

type fakeInstance struct {
	cfg instance.Config

	err          chan error
	startedCount *atomic.Int64
	running      *atomic.Bool
}

func (i *fakeInstance) Run(ctx context.Context) error {
	i.startedCount.Inc()
	i.running.Store(true)
	defer i.running.Store(false)

	select {
	case <-ctx.Done():
		return ctx.Err()
	case err := <-i.err:
		return err
	}
}

func (i *fakeInstance) Ready() bool {
	return true
}

func (i *fakeInstance) Update(_ instance.Config) error {
	return instance.ErrInvalidUpdate{
		Inner: fmt.Errorf("can't dynamically update fakeInstance"),
	}
}

func (i *fakeInstance) TargetsActive() map[string][]*scrape.Target {
	return nil
}

func (i *fakeInstance) StorageDirectory() string {
	return ""
}

func (i *fakeInstance) Appender(ctx context.Context) storage.Appender {
	return nil
}

type fakeInstanceFactory struct {
	mut   sync.Mutex
	mocks []*fakeInstance

	created *atomic.Int64
}

func newFakeInstanceFactory() *fakeInstanceFactory {
	return &fakeInstanceFactory{created: atomic.NewInt64(0)}
}

func (f *fakeInstanceFactory) Mocks() []*fakeInstance {
	f.mut.Lock()
	defer f.mut.Unlock()
	return f.mocks
}

func (f *fakeInstanceFactory) factory(_ prometheus.Registerer, cfg instance.Config, _ string, _ log.Logger) (instance.ManagedInstance, error) {
	f.created.Add(1)

	f.mut.Lock()
	defer f.mut.Unlock()

	inst := &fakeInstance{
		cfg:          cfg,
		running:      atomic.NewBool(false),
		startedCount: atomic.NewInt64(0),
		err:          make(chan error),
	}

	f.mocks = append(f.mocks, inst)
	return inst, nil
}

func makeInstanceConfig(name string) instance.Config {
	cfg := instance.DefaultConfig
	cfg.Name = name
	return cfg
}

'''
'''--- pkg/metrics/cleaner.go ---
package metrics

import (
	"fmt"
	"os"
	"path/filepath"
	"time"

	"github.com/go-kit/log"
	"github.com/go-kit/log/level"
	"github.com/grafana/agent/pkg/metrics/instance"
	"github.com/grafana/agent/pkg/metrics/wal"
	"github.com/prometheus/client_golang/prometheus"
	"github.com/prometheus/client_golang/prometheus/promauto"
	promwal "github.com/prometheus/prometheus/tsdb/wal"
)

// Default settings for the WAL cleaner.
const (
	DefaultCleanupAge    = 12 * time.Hour
	DefaultCleanupPeriod = 30 * time.Minute
)

var (
	discoveryError = promauto.NewCounterVec(
		prometheus.CounterOpts{
			Name: "agent_metrics_cleaner_storage_error_total",
			Help: "Errors encountered discovering local storage paths",
		},
		[]string{"storage"},
	)

	segmentError = promauto.NewCounterVec(
		prometheus.CounterOpts{
			Name: "agent_metrics_cleaner_segment_error_total",
			Help: "Errors encountered finding most recent WAL segments",
		},
		[]string{"storage"},
	)

	managedStorage = promauto.NewGauge(
		prometheus.GaugeOpts{
			Name: "agent_metrics_cleaner_managed_storage",
			Help: "Number of storage directories associated with managed instances",
		},
	)

	abandonedStorage = promauto.NewGauge(
		prometheus.GaugeOpts{
			Name: "agent_metrics_cleaner_abandoned_storage",
			Help: "Number of storage directories not associated with any managed instance",
		},
	)

	cleanupRunsSuccess = promauto.NewCounter(
		prometheus.CounterOpts{
			Name: "agent_metrics_cleaner_success_total",
			Help: "Number of successfully removed abandoned WALs",
		},
	)

	cleanupRunsErrors = promauto.NewCounter(
		prometheus.CounterOpts{
			Name: "agent_metrics_cleaner_errors_total",
			Help: "Number of errors removing abandoned WALs",
		},
	)

	cleanupTimes = promauto.NewHistogram(
		prometheus.HistogramOpts{
			Name: "agent_metrics_cleaner_cleanup_seconds",
			Help: "Time spent performing each periodic WAL cleanup",
		},
	)
)

// lastModifiedFunc gets the last modified time of the most recent segment of a WAL
type lastModifiedFunc func(path string) (time.Time, error)

func lastModified(path string) (time.Time, error) {
	existing, err := promwal.Open(nil, path)
	if err != nil {
		return time.Time{}, err
	}

	// We don't care if there are errors closing the abandoned WAL
	defer func() { _ = existing.Close() }()

	_, last, err := promwal.Segments(existing.Dir())
	if err != nil {
		return time.Time{}, fmt.Errorf("unable to open WAL: %w", err)
	}

	if last == -1 {
		return time.Time{}, fmt.Errorf("unable to determine most recent segment for %s", path)
	}

	// full path to the most recent segment in this WAL
	lastSegment := promwal.SegmentName(path, last)
	segmentFile, err := os.Stat(lastSegment)
	if err != nil {
		return time.Time{}, fmt.Errorf("unable to determine mtime for %s segment: %w", lastSegment, err)
	}

	return segmentFile.ModTime(), nil
}

// WALCleaner periodically checks for Write Ahead Logs (WALs) that are not associated
// with any active instance.ManagedInstance and have not been written to in some configured
// amount of time and deletes them.
type WALCleaner struct {
	logger          log.Logger
	instanceManager instance.Manager
	walDirectory    string
	walLastModified lastModifiedFunc
	minAge          time.Duration
	period          time.Duration
	done            chan bool
}

// NewWALCleaner creates a new cleaner that looks for abandoned WALs in the given
// directory and removes them if they haven't been modified in over minAge. Starts
// a goroutine to periodically run the cleanup method in a loop
func NewWALCleaner(logger log.Logger, manager instance.Manager, walDirectory string, minAge time.Duration, period time.Duration) *WALCleaner {
	c := &WALCleaner{
		logger:          log.With(logger, "component", "cleaner"),
		instanceManager: manager,
		walDirectory:    filepath.Clean(walDirectory),
		walLastModified: lastModified,
		minAge:          DefaultCleanupAge,
		period:          DefaultCleanupPeriod,
		done:            make(chan bool),
	}

	if minAge > 0 {
		c.minAge = minAge
	}

	// We allow a period of 0 here because '0' means "don't run the task". This
	// is handled by not running a ticker at all in the run method.
	if period >= 0 {
		c.period = period
	}

	go c.run()
	return c
}

// getManagedStorage gets storage directories used for each ManagedInstance
func (c *WALCleaner) getManagedStorage(instances map[string]instance.ManagedInstance) map[string]bool {
	out := make(map[string]bool)

	for _, inst := range instances {
		out[inst.StorageDirectory()] = true
	}

	return out
}

// getAllStorage gets all storage directories under walDirectory
func (c *WALCleaner) getAllStorage() []string {
	var out []string

	_ = filepath.Walk(c.walDirectory, func(p string, info os.FileInfo, err error) error {
		if os.IsNotExist(err) {
			// The root WAL directory doesn't exist. Maybe this Agent isn't responsible for any
			// instances yet. Log at debug since this isn't a big deal. We'll just try to crawl
			// the direction again on the next periodic run.
			level.Debug(c.logger).Log("msg", "WAL storage path does not exist", "path", p, "err", err)
		} else if err != nil {
			// Just log any errors traversing the WAL directory. This will potentially result
			// in a WAL (that has incorrect permissions or some similar problem) not being cleaned
			// up. This is  better than preventing *all* other WALs from being cleaned up.
			discoveryError.WithLabelValues(p).Inc()
			level.Warn(c.logger).Log("msg", "unable to traverse WAL storage path", "path", p, "err", err)
		} else if info.IsDir() && filepath.Dir(p) == c.walDirectory {
			// Single level below the root are instance storage directories (including WALs)
			out = append(out, p)
		}

		return nil
	})

	return out
}

// getAbandonedStorage gets the full path of storage directories that aren't associated with
// an active instance  and haven't been written to within a configured duration (usually several
// hours or more).
func (c *WALCleaner) getAbandonedStorage(all []string, managed map[string]bool, now time.Time) []string {
	var out []string

	for _, dir := range all {
		if managed[dir] {
			level.Debug(c.logger).Log("msg", "active WAL", "name", dir)
			continue
		}

		walDir := wal.SubDirectory(dir)
		mtime, err := c.walLastModified(walDir)
		if err != nil {
			segmentError.WithLabelValues(dir).Inc()
			level.Warn(c.logger).Log("msg", "unable to find segment mtime of WAL", "name", dir, "err", err)
			continue
		}

		diff := now.Sub(mtime)
		if diff > c.minAge {
			// The last segment for this WAL was modified more then $minAge (positive number of hours)
			// in the past. This makes it a candidate for deletion since it's also not associated with
			// any Instances this agent knows about.
			out = append(out, dir)
		}

		level.Debug(c.logger).Log("msg", "abandoned WAL", "name", dir, "mtime", mtime, "diff", diff)
	}

	return out
}

// run cleans up abandoned WALs (if period != 0) in a loop periodically until stopped
func (c *WALCleaner) run() {
	// A period of 0 means don't run a cleanup task
	if c.period == 0 {
		return
	}

	ticker := time.NewTicker(c.period)
	defer ticker.Stop()

	for {
		select {
		case <-c.done:
			level.Debug(c.logger).Log("msg", "stopping cleaner...")
			return
		case <-ticker.C:
			c.cleanup()
		}
	}
}

// cleanup removes any abandoned and unused WAL directories. Note that it shouldn't be
// necessary to call this method explicitly in most cases since it will be run periodically
// in a goroutine (started when WALCleaner is created).
func (c *WALCleaner) cleanup() {
	start := time.Now()
	all := c.getAllStorage()
	managed := c.getManagedStorage(c.instanceManager.ListInstances())
	abandoned := c.getAbandonedStorage(all, managed, time.Now())

	managedStorage.Set(float64(len(managed)))
	abandonedStorage.Set(float64(len(abandoned)))

	for _, a := range abandoned {
		level.Info(c.logger).Log("msg", "deleting abandoned WAL", "name", a)
		err := os.RemoveAll(a)
		if err != nil {
			level.Error(c.logger).Log("msg", "failed to delete abandoned WAL", "name", a, "err", err)
			cleanupRunsErrors.Inc()
		} else {
			cleanupRunsSuccess.Inc()
		}
	}

	cleanupTimes.Observe(time.Since(start).Seconds())
}

// Stop the cleaner and any background tasks running
func (c *WALCleaner) Stop() {
	close(c.done)
}

'''
'''--- pkg/metrics/cleaner_test.go ---
package metrics

import (
	"io/ioutil"
	"os"
	"path/filepath"
	"testing"
	"time"

	"github.com/go-kit/log"
	"github.com/grafana/agent/pkg/metrics/instance"
	"github.com/stretchr/testify/require"
)

func TestWALCleaner_getAllStorageNoRoot(t *testing.T) {
	walRoot := filepath.Join(os.TempDir(), "getAllStorageNoRoot")
	logger := log.NewLogfmtLogger(os.Stderr)
	cleaner := NewWALCleaner(
		logger,
		&instance.MockManager{},
		walRoot,
		DefaultCleanupAge,
		DefaultCleanupPeriod,
	)

	// Bogus WAL root that doesn't exist. Method should return no results
	wals := cleaner.getAllStorage()

	require.Empty(t, wals)
}

func TestWALCleaner_getAllStorageSuccess(t *testing.T) {
	walRoot, err := ioutil.TempDir(os.TempDir(), "getAllStorageSuccess")
	require.NoError(t, err)
	defer os.RemoveAll(walRoot)

	walDir := filepath.Join(walRoot, "instance-1")
	err = os.MkdirAll(walDir, 0755)
	require.NoError(t, err)

	logger := log.NewLogfmtLogger(os.Stderr)
	cleaner := NewWALCleaner(
		logger,
		&instance.MockManager{},
		walRoot,
		DefaultCleanupAge,
		DefaultCleanupPeriod,
	)
	wals := cleaner.getAllStorage()

	require.Equal(t, []string{walDir}, wals)
}

func TestWALCleaner_getAbandonedStorageBeforeCutoff(t *testing.T) {
	walRoot, err := ioutil.TempDir(os.TempDir(), "getAbandonedStorageBeforeCutoff")
	require.NoError(t, err)
	defer os.RemoveAll(walRoot)

	walDir := filepath.Join(walRoot, "instance-1")
	err = os.MkdirAll(walDir, 0755)
	require.NoError(t, err)

	all := []string{walDir}
	managed := make(map[string]bool)
	now := time.Now()

	logger := log.NewLogfmtLogger(os.Stderr)
	cleaner := NewWALCleaner(
		logger,
		&instance.MockManager{},
		walRoot,
		5*time.Minute,
		DefaultCleanupPeriod,
	)

	cleaner.walLastModified = func(path string) (time.Time, error) {
		return now, nil
	}

	// Last modification time on our WAL directory is the same as "now"
	// so there shouldn't be any results even though it's not part of the
	// set of "managed" directories.
	abandoned := cleaner.getAbandonedStorage(all, managed, now)
	require.Empty(t, abandoned)
}

func TestWALCleaner_getAbandonedStorageAfterCutoff(t *testing.T) {
	walRoot, err := ioutil.TempDir(os.TempDir(), "getAbandonedStorageAfterCutoff")
	require.NoError(t, err)
	defer os.RemoveAll(walRoot)

	walDir := filepath.Join(walRoot, "instance-1")
	err = os.MkdirAll(walDir, 0755)
	require.NoError(t, err)

	all := []string{walDir}
	managed := make(map[string]bool)
	now := time.Now()

	logger := log.NewLogfmtLogger(os.Stderr)
	cleaner := NewWALCleaner(
		logger,
		&instance.MockManager{},
		walRoot,
		5*time.Minute,
		DefaultCleanupPeriod,
	)

	cleaner.walLastModified = func(path string) (time.Time, error) {
		return now.Add(-30 * time.Minute), nil
	}

	// Last modification time on our WAL directory is 30 minutes in the past
	// compared to "now" and we've set the cutoff for our cleaner to be 5
	// minutes: our WAL directory should show up as abandoned
	abandoned := cleaner.getAbandonedStorage(all, managed, now)
	require.Equal(t, []string{walDir}, abandoned)
}

func TestWALCleaner_cleanup(t *testing.T) {
	walRoot, err := ioutil.TempDir(os.TempDir(), "cleanup")
	require.NoError(t, err)
	defer os.RemoveAll(walRoot)

	walDir := filepath.Join(walRoot, "instance-1")
	err = os.MkdirAll(walDir, 0755)
	require.NoError(t, err)

	now := time.Now()
	logger := log.NewLogfmtLogger(os.Stderr)
	manager := &instance.MockManager{}
	manager.ListInstancesFunc = func() map[string]instance.ManagedInstance {
		return make(map[string]instance.ManagedInstance)
	}

	cleaner := NewWALCleaner(
		logger,
		manager,
		walRoot,
		5*time.Minute,
		DefaultCleanupPeriod,
	)

	cleaner.walLastModified = func(path string) (time.Time, error) {
		return now.Add(-30 * time.Minute), nil
	}

	// Last modification time on our WAL directory is 30 minutes in the past
	// compared to "now" and we've set the cutoff for our cleaner to be 5
	// minutes: our WAL directory should be removed since it's abandoned
	cleaner.cleanup()
	_, err = os.Stat(walDir)
	require.Error(t, err)
	require.True(t, os.IsNotExist(err))
}

'''
'''--- pkg/metrics/cluster/client/client.go ---
package client

import (
	"flag"
	"io"

	"github.com/grafana/agent/pkg/agentproto"
	"github.com/grafana/agent/pkg/util"
	"github.com/grafana/dskit/grpcclient"
	otgrpc "github.com/opentracing-contrib/go-grpc"
	"github.com/opentracing/opentracing-go"
	"github.com/weaveworks/common/middleware"
	"google.golang.org/grpc"
	"google.golang.org/grpc/credentials/insecure"
)

// ScrapingServiceClient wraps agentproto.ScrapingServiceClient with a Close method.
type ScrapingServiceClient interface {
	agentproto.ScrapingServiceClient
	io.Closer
}

var (
	// DefaultConfig provides default Config values.
	DefaultConfig = *util.DefaultConfigFromFlags(&Config{}).(*Config)
)

// Config controls how scraping service clients are created.
type Config struct {
	GRPCClientConfig grpcclient.Config `yaml:"grpc_client_config,omitempty"`
}

// UnmarshalYAML implements yaml.Unmarshaler.
func (c *Config) UnmarshalYAML(unmarshal func(interface{}) error) error {
	*c = DefaultConfig

	type plain Config
	return unmarshal((*plain)(c))
}

// RegisterFlags registers flags to the provided flag set.
func (c *Config) RegisterFlags(f *flag.FlagSet) {
	c.RegisterFlagsWithPrefix("prometheus.", f)
	c.RegisterFlagsWithPrefix("metrics.", f)
}

// RegisterFlagsWithPrefix registers flags to the provided flag set with the
// specified prefix.
func (c *Config) RegisterFlagsWithPrefix(prefix string, f *flag.FlagSet) {
	c.GRPCClientConfig.RegisterFlagsWithPrefix(prefix+"service-client", f)
}

// New returns a new scraping service client.
func New(cfg Config, addr string) (ScrapingServiceClient, error) {
	opts := []grpc.DialOption{
		grpc.WithTransportCredentials(insecure.NewCredentials()),
		grpc.WithDefaultCallOptions(cfg.GRPCClientConfig.CallOptions()...),
	}
	grpcDialOpts, err := cfg.GRPCClientConfig.DialOption(instrumentation())
	if err != nil {
		return nil, err
	}
	opts = append(opts, grpcDialOpts...)
	conn, err := grpc.Dial(addr, opts...)
	if err != nil {
		return nil, err
	}

	return struct {
		agentproto.ScrapingServiceClient
		io.Closer
	}{
		ScrapingServiceClient: agentproto.NewScrapingServiceClient(conn),
		Closer:                conn,
	}, nil
}

func instrumentation() ([]grpc.UnaryClientInterceptor, []grpc.StreamClientInterceptor) {
	unary := []grpc.UnaryClientInterceptor{
		otgrpc.OpenTracingClientInterceptor(opentracing.GlobalTracer()),
		middleware.ClientUserHeaderInterceptor,
	}
	stream := []grpc.StreamClientInterceptor{
		otgrpc.OpenTracingStreamClientInterceptor(opentracing.GlobalTracer()),
		middleware.StreamClientUserHeaderInterceptor,
	}
	return unary, stream
}

'''
'''--- pkg/metrics/cluster/cluster.go ---
package cluster

import (
	"context"
	"fmt"
	"sync"

	"github.com/go-kit/log"
	"github.com/go-kit/log/level"
	"github.com/golang/protobuf/ptypes/empty"
	"github.com/gorilla/mux"
	"github.com/grafana/agent/pkg/agentproto"
	"github.com/grafana/agent/pkg/metrics/instance"
	"github.com/grafana/agent/pkg/metrics/instance/configstore"
	"github.com/grafana/agent/pkg/util"
	"github.com/prometheus/client_golang/prometheus"
	"google.golang.org/grpc"
)

// Cluster connects an Agent to other Agents and allows them to distribute
// workload.
type Cluster struct {
	mut sync.RWMutex

	log            log.Logger
	cfg            Config
	baseValidation ValidationFunc

	//
	// Internally, Cluster glues together four separate pieces of logic.
	// See comments below to get an understanding of what is going on.
	//

	// node manages membership in the cluster and performs cluster-wide reshards.
	node *node

	// store connects to a configstore for changes. storeAPI is an HTTP API for it.
	store    *configstore.Remote
	storeAPI *configstore.API

	// watcher watches the store and applies changes to an instance.Manager,
	// triggering metrics to be collected and sent. configWatcher also does a
	// complete refresh of its state on an interval.
	watcher *configWatcher
}

// New creates a new Cluster.
func New(
	l log.Logger,
	reg prometheus.Registerer,
	cfg Config,
	im instance.Manager,
	validate ValidationFunc,
) (*Cluster, error) {

	l = log.With(l, "component", "cluster")

	var (
		c   = &Cluster{log: l, cfg: cfg, baseValidation: validate}
		err error
	)

	// Hold the lock for the initialization. This is necessary since newNode will
	// eventually call Reshard, and we want c.watcher to be initialized when that
	// happens.
	c.mut.Lock()
	defer c.mut.Unlock()

	c.node, err = newNode(reg, l, cfg, c)
	if err != nil {
		return nil, fmt.Errorf("failed to initialize node membership: %w", err)
	}

	c.store, err = configstore.NewRemote(l, reg, cfg.KVStore, cfg.Enabled)
	if err != nil {
		return nil, fmt.Errorf("failed to initialize configstore: %w", err)
	}
	c.storeAPI = configstore.NewAPI(l, c.store, c.storeValidate, cfg.APIEnableGetConfiguration)
	reg.MustRegister(c.storeAPI)

	c.watcher, err = newConfigWatcher(l, cfg, c.store, im, c.node.Owns, validate)
	if err != nil {
		return nil, fmt.Errorf("failed to initialize configwatcher: %w", err)
	}

	// NOTE(rfratto): ApplyConfig isn't necessary for the initialization but must
	// be called for any changes to the configuration.
	return c, nil
}

func (c *Cluster) storeValidate(cfg *instance.Config) error {
	c.mut.RLock()
	defer c.mut.RUnlock()

	if err := c.baseValidation(cfg); err != nil {
		return err
	}

	if c.cfg.DangerousAllowReadingFiles {
		return nil
	}

	// If configs aren't allowed to read from the store, we need to make sure no
	// configs coming in from the API set files for passwords.
	return validateNofiles(cfg)
}

// Reshard implements agentproto.ScrapingServiceServer, and syncs the state of
// configs with the configstore.
func (c *Cluster) Reshard(ctx context.Context, _ *agentproto.ReshardRequest) (*empty.Empty, error) {
	c.mut.RLock()
	defer c.mut.RUnlock()

	level.Info(c.log).Log("msg", "received reshard notification, requesting refresh")
	c.watcher.RequestRefresh()
	return &empty.Empty{}, nil
}

// ApplyConfig applies configuration changes to Cluster.
func (c *Cluster) ApplyConfig(cfg Config) error {
	c.mut.Lock()
	defer c.mut.Unlock()

	if util.CompareYAML(c.cfg, cfg) {
		return nil
	}

	if err := c.node.ApplyConfig(cfg); err != nil {
		return fmt.Errorf("failed to apply config to node membership: %w", err)
	}

	if err := c.store.ApplyConfig(cfg.Lifecycler.RingConfig.KVStore, cfg.Enabled); err != nil {
		return fmt.Errorf("failed to apply config to config store: %w", err)
	}

	if err := c.watcher.ApplyConfig(cfg); err != nil {
		return fmt.Errorf("failed to apply config to watcher: %w", err)
	}

	c.cfg = cfg

	// Force a refresh so all the configs get updated with new defaults.
	level.Info(c.log).Log("msg", "cluster config changed, queueing refresh")
	c.watcher.RequestRefresh()
	return nil
}

// WireAPI injects routes into the provided mux router for the config
// management API.
func (c *Cluster) WireAPI(r *mux.Router) {
	c.storeAPI.WireAPI(r)
	c.node.WireAPI(r)
}

// WireGRPC injects gRPC server handlers into the provided gRPC server.
func (c *Cluster) WireGRPC(srv *grpc.Server) {
	agentproto.RegisterScrapingServiceServer(srv, c)
}

// Stop stops the cluster and all of its dependencies.
func (c *Cluster) Stop() {
	c.mut.Lock()
	defer c.mut.Unlock()

	deps := []struct {
		name   string
		closer func() error
	}{
		{"node", c.node.Stop},
		{"config store", c.store.Close},
		{"config watcher", c.watcher.Stop},
	}
	for _, dep := range deps {
		err := dep.closer()
		if err != nil {
			level.Error(c.log).Log("msg", "failed to stop dependency", "dependency", dep.name, "err", err)
		}
	}
}

'''
'''--- pkg/metrics/cluster/config.go ---
package cluster

import (
	"flag"
	"strings"
	"time"

	util_log "github.com/cortexproject/cortex/pkg/util/log"
	"github.com/grafana/agent/pkg/metrics/cluster/client"
	flagutil "github.com/grafana/agent/pkg/util"
	"github.com/grafana/dskit/kv"
	"github.com/grafana/dskit/ring"
)

// DefaultConfig provides default values for the config
var DefaultConfig = *flagutil.DefaultConfigFromFlags(&Config{}).(*Config)

// Config describes how to instantiate a scraping service Server instance.
type Config struct {
	Enabled                    bool                  `yaml:"enabled"`
	ReshardInterval            time.Duration         `yaml:"reshard_interval"`
	ReshardTimeout             time.Duration         `yaml:"reshard_timeout"`
	ClusterReshardEventTimeout time.Duration         `yaml:"cluster_reshard_event_timeout"`
	KVStore                    kv.Config             `yaml:"kvstore"`
	Lifecycler                 ring.LifecyclerConfig `yaml:"lifecycler"`

	DangerousAllowReadingFiles bool `yaml:"dangerous_allow_reading_files"`

	// TODO(rfratto): deprecate scraping_service_client in Agent and replace with this.
	Client                    client.Config `yaml:"-"`
	APIEnableGetConfiguration bool          `yaml:"-"`
}

// UnmarshalYAML implements yaml.Unmarshaler.
func (c *Config) UnmarshalYAML(unmarshal func(interface{}) error) error {
	*c = DefaultConfig

	type plain Config
	err := unmarshal((*plain)(c))
	if err != nil {
		return err
	}
	c.Lifecycler.RingConfig.ReplicationFactor = 1
	return nil
}

// RegisterFlags adds the flags required to config the Server to the given
// FlagSet.
func (c *Config) RegisterFlags(f *flag.FlagSet) {
	c.RegisterFlagsWithPrefix("", f)
}

// RegisterFlagsWithPrefix adds the flags required to config this to the given
// FlagSet with a specified prefix.
func (c *Config) RegisterFlagsWithPrefix(prefix string, f *flag.FlagSet) {
	f.BoolVar(&c.Enabled, prefix+"enabled", false, "enables the scraping service mode")
	f.DurationVar(&c.ReshardInterval, prefix+"reshard-interval", time.Minute*1, "how often to manually refresh configuration")
	f.DurationVar(&c.ReshardTimeout, prefix+"reshard-timeout", time.Second*30, "timeout for refreshing the configuration. Timeout of 0s disables timeout.")
	f.DurationVar(&c.ClusterReshardEventTimeout, prefix+"cluster-reshard-event-timeout", time.Second*30, "timeout for the cluster reshard. Timeout of 0s disables timeout.")
	c.KVStore.RegisterFlagsWithPrefix(prefix+"config-store.", "configurations/", f)
	c.Lifecycler.RegisterFlagsWithPrefix(prefix, f, util_log.Logger)

	// GRPCClientConfig.RegisterFlags expects that prefix does not end in a ".",
	// unlike all other flags.
	noDotPrefix := strings.TrimSuffix(prefix, ".")
	c.Client.GRPCClientConfig.RegisterFlagsWithPrefix(noDotPrefix, f)
}

'''
'''--- pkg/metrics/cluster/config_watcher.go ---
package cluster

import (
	"context"
	"fmt"
	"sync"
	"time"

	"github.com/go-kit/log"
	"github.com/go-kit/log/level"
	"github.com/grafana/agent/pkg/metrics/instance"
	"github.com/grafana/agent/pkg/metrics/instance/configstore"
	"github.com/grafana/agent/pkg/util"
	"github.com/prometheus/client_golang/prometheus"
	"github.com/prometheus/client_golang/prometheus/promauto"
)

var (
	reshardDuration = promauto.NewHistogramVec(prometheus.HistogramOpts{
		Name: "agent_metrics_scraping_service_reshard_duration",
		Help: "How long it took for resharding to run.",
	}, []string{"success"})
)

// configWatcher connects to a configstore and will apply configs to an
// instance.Manager.
type configWatcher struct {
	log log.Logger

	mut     sync.Mutex
	cfg     Config
	stopped bool
	stop    context.CancelFunc

	store    configstore.Store
	im       instance.Manager
	owns     OwnershipFunc
	validate ValidationFunc

	refreshCh   chan struct{}
	instanceMut sync.Mutex
	instances   map[string]struct{}
}

// OwnershipFunc should determine if a given keep is owned by the caller.
type OwnershipFunc = func(key string) (bool, error)

// ValidationFunc should validate a config.
type ValidationFunc = func(*instance.Config) error

// newConfigWatcher watches store for changes and checks for each config against
// owns. It will also poll the configstore at a configurable interval.
func newConfigWatcher(log log.Logger, cfg Config, store configstore.Store, im instance.Manager, owns OwnershipFunc, validate ValidationFunc) (*configWatcher, error) {
	ctx, cancel := context.WithCancel(context.Background())

	w := &configWatcher{
		log: log,

		stop: cancel,

		store:    store,
		im:       im,
		owns:     owns,
		validate: validate,

		refreshCh: make(chan struct{}, 1),
		instances: make(map[string]struct{}),
	}
	if err := w.ApplyConfig(cfg); err != nil {
		return nil, err
	}
	// Delay duration, this is to prevent a race condition, see method for details
	delay := cfg.Lifecycler.HeartbeatPeriod * 3
	go w.run(ctx, delay)
	return w, nil
}

func (w *configWatcher) ApplyConfig(cfg Config) error {
	w.mut.Lock()
	defer w.mut.Unlock()

	if util.CompareYAML(w.cfg, cfg) {
		return nil
	}

	if w.stopped {
		return fmt.Errorf("configWatcher already stopped")
	}

	w.cfg = cfg
	return nil
}

func (w *configWatcher) run(ctx context.Context, delay time.Duration) {
	defer level.Info(w.log).Log("msg", "config watcher run loop exiting")
	// This is due to a race condition between the heartbeat and config ring in a  very narrow set of circumstances
	// https://gist.github.com/mattdurham/c15f27de17a6da97bf2e6a870991c7f2
	time.Sleep(delay)
	lastReshard := time.Now()

	for {
		select {
		case <-ctx.Done():
			return
		case <-w.nextReshard(lastReshard):
			level.Debug(w.log).Log("msg", "reshard timer ticked, scheduling refresh")
			w.RequestRefresh()
			lastReshard = time.Now()
		case <-w.refreshCh:
			err := w.refresh(ctx)
			if err != nil {
				level.Error(w.log).Log("msg", "refresh failed", "err", err)
			}
		case ev := <-w.store.Watch():
			level.Debug(w.log).Log("msg", "handling event from config store")
			if err := w.handleEvent(ev); err != nil {
				level.Error(w.log).Log("msg", "failed to handle changed or deleted config", "key", ev.Key, "err", err)
			}
		}
	}
}

// nextReshard returns a channel to that will fill a value when the reshard
// interval has elapsed.
func (w *configWatcher) nextReshard(lastReshard time.Time) <-chan time.Time {
	w.mut.Lock()
	nextReshard := lastReshard.Add(w.cfg.ReshardInterval)
	w.mut.Unlock()

	remaining := time.Until(nextReshard)

	// NOTE(rfratto): clamping to 0 isn't necessary for time.After,
	// but it makes the log message clearer to always use "0s" as
	// "next reshard will be scheduled immediately."
	if remaining < 0 {
		remaining = 0
	}

	level.Debug(w.log).Log("msg", "waiting for next reshard interval", "last_reshard", lastReshard, "next_reshard", nextReshard, "remaining", remaining)
	return time.After(remaining)
}

// RequestRefresh will queue a refresh. No more than one refresh can be queued at a time.
func (w *configWatcher) RequestRefresh() {
	select {
	case w.refreshCh <- struct{}{}:
		level.Debug(w.log).Log("msg", "successfully scheduled a refresh")
	default:
		level.Debug(w.log).Log("msg", "ignoring request refresh: refresh already scheduled")
	}
}

// refresh reloads all configs from the configstore. Deleted configs will be
// removed. refresh may not be called concurrently and must only be invoked from run.
// Call RequestRefresh to queue a call to refresh.
func (w *configWatcher) refresh(ctx context.Context) (err error) {
	w.mut.Lock()
	enabled := w.cfg.Enabled
	refreshTimeout := w.cfg.ReshardTimeout
	w.mut.Unlock()

	if !enabled {
		level.Debug(w.log).Log("msg", "refresh skipped because clustering is disabled")
		return nil
	}
	level.Info(w.log).Log("msg", "starting refresh")

	if refreshTimeout > 0 {
		var cancel context.CancelFunc
		ctx, cancel = context.WithTimeout(ctx, refreshTimeout)
		defer cancel()
	}

	start := time.Now()
	defer func() {
		success := "1"
		if err != nil {
			success = "0"
		}
		duration := time.Since(start)
		level.Info(w.log).Log("msg", "refresh finished", "duration", duration, "success", success, "err", err)
		reshardDuration.WithLabelValues(success).Observe(duration.Seconds())
	}()

	// This is used to determine if the context was already exceeded before calling the kv provider
	if err = ctx.Err(); err != nil {
		level.Error(w.log).Log("msg", "context deadline exceeded before calling store.all", "err", err)
		return err
	}
	deadline, _ := ctx.Deadline()
	level.Debug(w.log).Log("msg", "deadline before store.all", "deadline", deadline)
	configs, err := w.store.All(ctx, func(key string) bool {
		owns, err := w.owns(key)
		if err != nil {
			level.Error(w.log).Log("msg", "failed to check for ownership, instance will be deleted if it is running", "key", key, "err", err)
			return false
		}
		return owns
	})
	level.Debug(w.log).Log("msg", "count of configs from store.all", "count", len(configs))

	if err != nil {
		return fmt.Errorf("failed to get configs from store: %w", err)
	}

	var (
		keys       = make(map[string]struct{})
		firstError error
	)

Outer:
	for {
		select {
		case <-ctx.Done():
			return ctx.Err()
		case cfg, ok := <-configs:
			// w.store.All will close configs when all of them have been read.
			if !ok {
				break Outer
			}

			if err := w.handleEvent(configstore.WatchEvent{Key: cfg.Name, Config: &cfg}); err != nil {
				level.Error(w.log).Log("msg", "failed to process changed config", "key", cfg.Name, "err", err)
				if firstError == nil {
					firstError = err
				}
			}

			keys[cfg.Name] = struct{}{}
		}
	}

	// Any config we used to be running that disappeared from this most recent
	// iteration should be deleted. We hold the lock just for the duration of
	// populating deleted because handleEvent also grabs a hold on the lock.
	var deleted []string
	w.instanceMut.Lock()
	for key := range w.instances {
		if _, exist := keys[key]; exist {
			continue
		}
		deleted = append(deleted, key)
	}
	w.instanceMut.Unlock()

	// Send a deleted event for any key that has gone away.
	for _, key := range deleted {
		if err := w.handleEvent(configstore.WatchEvent{Key: key, Config: nil}); err != nil {
			level.Error(w.log).Log("msg", "failed to process changed config", "key", key, "err", err)
		}
	}

	return firstError
}

func (w *configWatcher) handleEvent(ev configstore.WatchEvent) error {
	w.mut.Lock()
	defer w.mut.Unlock()

	if w.stopped {
		return fmt.Errorf("configWatcher stopped")
	}

	w.instanceMut.Lock()
	defer w.instanceMut.Unlock()

	owned, err := w.owns(ev.Key)
	if err != nil {
		level.Error(w.log).Log("msg", "failed to see if config is owned. instance will be deleted if it is running", "err", err)
	}

	var (
		_, isRunning = w.instances[ev.Key]
		isDeleted    = ev.Config == nil
	)

	switch {
	// Two deletion scenarios:
	// 1. A config we're running got moved to a new owner.
	// 2. A config we're running got deleted
	case (isRunning && !owned) || (isDeleted && isRunning):
		if isDeleted {
			level.Info(w.log).Log("msg", "untracking deleted config", "key", ev.Key)
		} else {
			level.Info(w.log).Log("msg", "untracking config that changed owners", "key", ev.Key)
		}

		err := w.im.DeleteConfig(ev.Key)
		delete(w.instances, ev.Key)
		if err != nil {
			return fmt.Errorf("failed to delete: %w", err)
		}

	case !isDeleted && owned:
		if err := w.validate(ev.Config); err != nil {
			return fmt.Errorf(
				"failed to validate config. %[1]s cannot run until the global settings are adjusted or the config is adjusted to operate within the global constraints. error: %[2]w",
				ev.Key, err,
			)
		}

		if _, exist := w.instances[ev.Key]; !exist {
			level.Info(w.log).Log("msg", "tracking new config", "key", ev.Key)
		}

		if err := w.im.ApplyConfig(*ev.Config); err != nil {
			return fmt.Errorf("failed to apply config: %w", err)
		}
		w.instances[ev.Key] = struct{}{}
	}

	return nil
}

// Stop stops the configWatcher. Cannot be called more than once.
func (w *configWatcher) Stop() error {
	w.mut.Lock()
	defer w.mut.Unlock()

	if w.stopped {
		return fmt.Errorf("already stopped")
	}
	w.stop()
	w.stopped = true

	// Shut down all the instances that this configWatcher managed. It *MUST*
	// happen after w.stop() is called to prevent the run loop from applying any
	// new configs.
	w.instanceMut.Lock()
	defer w.instanceMut.Unlock()

	for key := range w.instances {
		if err := w.im.DeleteConfig(key); err != nil {
			level.Warn(w.log).Log("msg", "failed deleting config on shutdown", "key", key, "err", err)
		}
	}
	w.instances = make(map[string]struct{})

	return nil
}

'''
'''--- pkg/metrics/cluster/config_watcher_test.go ---
package cluster

import (
	"context"
	"testing"
	"time"

	"github.com/grafana/agent/pkg/metrics/instance"
	"github.com/grafana/agent/pkg/metrics/instance/configstore"
	"github.com/grafana/agent/pkg/util"
	"github.com/stretchr/testify/mock"
	"github.com/stretchr/testify/require"
)

func Test_configWatcher_Refresh(t *testing.T) {
	var (
		log = util.TestLogger(t)

		cfg   = DefaultConfig
		store = configstore.Mock{
			WatchFunc: func() <-chan configstore.WatchEvent {
				return make(chan configstore.WatchEvent)
			},
		}

		im mockConfigManager

		validate = func(*instance.Config) error { return nil }
		owned    = func(key string) (bool, error) { return true, nil }
	)
	cfg.Enabled = true
	cfg.ReshardInterval = time.Hour

	w, err := newConfigWatcher(log, cfg, &store, &im, owned, validate)
	require.NoError(t, err)
	t.Cleanup(func() { _ = w.Stop() })

	im.On("ApplyConfig", mock.Anything).Return(nil)
	im.On("DeleteConfig", mock.Anything).Return(nil)

	// First: return a "hello" config.
	store.AllFunc = func(ctx context.Context, keep func(key string) bool) (<-chan instance.Config, error) {
		ch := make(chan instance.Config)
		go func() {
			ch <- instance.Config{Name: "hello"}
			close(ch)
		}()
		return ch, nil
	}

	err = w.refresh(context.Background())
	require.NoError(t, err)

	// Then: return a "new" config.
	store.AllFunc = func(ctx context.Context, keep func(key string) bool) (<-chan instance.Config, error) {
		ch := make(chan instance.Config, 1)
		go func() {
			ch <- instance.Config{Name: "new"}
			close(ch)
		}()
		return ch, nil
	}

	err = w.refresh(context.Background())
	require.NoError(t, err)

	// "hello" and "new" should've been applied, and "hello" should've been deleted
	// from the second refresh.
	im.AssertCalled(t, "ApplyConfig", instance.Config{Name: "hello"})
	im.AssertCalled(t, "ApplyConfig", instance.Config{Name: "new"})
	im.AssertCalled(t, "DeleteConfig", "hello")
}

func Test_configWatcher_handleEvent(t *testing.T) {
	var (
		cfg   = DefaultConfig
		store = configstore.Mock{
			WatchFunc: func() <-chan configstore.WatchEvent {
				return make(chan configstore.WatchEvent)
			},
		}

		validate = func(*instance.Config) error { return nil }

		owned   = func(key string) (bool, error) { return true, nil }
		unowned = func(key string) (bool, error) { return false, nil }
	)
	cfg.Enabled = true

	t.Run("new owned config", func(t *testing.T) {
		var (
			log = util.TestLogger(t)
			im  mockConfigManager
		)

		w, err := newConfigWatcher(log, cfg, &store, &im, owned, validate)
		require.NoError(t, err)
		t.Cleanup(func() { _ = w.Stop() })

		im.On("ApplyConfig", mock.Anything).Return(nil)
		im.On("DeleteConfig", mock.Anything).Return(nil)

		err = w.handleEvent(configstore.WatchEvent{Key: "new", Config: &instance.Config{}})
		require.NoError(t, err)

		im.AssertNumberOfCalls(t, "ApplyConfig", 1)
	})

	t.Run("updated owned config", func(t *testing.T) {
		var (
			log = util.TestLogger(t)
			im  mockConfigManager
		)

		w, err := newConfigWatcher(log, cfg, &store, &im, owned, validate)
		require.NoError(t, err)
		t.Cleanup(func() { _ = w.Stop() })

		im.On("ApplyConfig", mock.Anything).Return(nil)
		im.On("DeleteConfig", mock.Anything).Return(nil)

		// One for create, one for update
		err = w.handleEvent(configstore.WatchEvent{Key: "update", Config: &instance.Config{}})
		require.NoError(t, err)

		err = w.handleEvent(configstore.WatchEvent{Key: "update", Config: &instance.Config{}})
		require.NoError(t, err)

		im.AssertNumberOfCalls(t, "ApplyConfig", 2)
	})

	t.Run("new unowned config", func(t *testing.T) {
		var (
			log = util.TestLogger(t)
			im  mockConfigManager
		)

		w, err := newConfigWatcher(log, cfg, &store, &im, unowned, validate)
		require.NoError(t, err)
		t.Cleanup(func() { _ = w.Stop() })

		im.On("ApplyConfig", mock.Anything).Return(nil)
		im.On("DeleteConfig", mock.Anything).Return(nil)

		// One for create, one for update
		err = w.handleEvent(configstore.WatchEvent{Key: "unowned", Config: &instance.Config{}})
		require.NoError(t, err)

		im.AssertNumberOfCalls(t, "ApplyConfig", 0)
	})

	t.Run("lost ownership", func(t *testing.T) {
		var (
			log = util.TestLogger(t)

			im mockConfigManager

			isOwned = true
			owns    = func(key string) (bool, error) { return isOwned, nil }
		)

		w, err := newConfigWatcher(log, cfg, &store, &im, owns, validate)
		require.NoError(t, err)
		t.Cleanup(func() { _ = w.Stop() })

		im.On("ApplyConfig", mock.Anything).Return(nil)
		im.On("DeleteConfig", mock.Anything).Return(nil)

		// One for create, then one for ownership change
		err = w.handleEvent(configstore.WatchEvent{Key: "disappear", Config: &instance.Config{}})
		require.NoError(t, err)

		// Mark the config as unowned. The re-apply should then delete it.
		isOwned = false

		err = w.handleEvent(configstore.WatchEvent{Key: "disappear", Config: &instance.Config{}})
		require.NoError(t, err)

		im.AssertNumberOfCalls(t, "ApplyConfig", 1)
		im.AssertNumberOfCalls(t, "DeleteConfig", 1)
	})

	t.Run("deleted running config", func(t *testing.T) {
		var (
			log = util.TestLogger(t)

			im mockConfigManager
		)

		w, err := newConfigWatcher(log, cfg, &store, &im, owned, validate)
		require.NoError(t, err)
		t.Cleanup(func() { _ = w.Stop() })

		im.On("ApplyConfig", mock.Anything).Return(nil)
		im.On("DeleteConfig", mock.Anything).Return(nil)

		// One for create, then one for deleted.
		err = w.handleEvent(configstore.WatchEvent{Key: "new-key", Config: &instance.Config{}})
		require.NoError(t, err)

		err = w.handleEvent(configstore.WatchEvent{Key: "new-key", Config: nil})
		require.NoError(t, err)

		im.AssertNumberOfCalls(t, "ApplyConfig", 1)
		im.AssertNumberOfCalls(t, "DeleteConfig", 1)
	})
}

func Test_configWatcher_nextReshard(t *testing.T) {
	watcher := &configWatcher{
		log: util.TestLogger(t),
		cfg: Config{ReshardInterval: time.Second},
	}

	t.Run("past time", func(t *testing.T) {
		select {
		case <-watcher.nextReshard(time.Time{}):
		case <-time.After(250 * time.Millisecond):
			require.FailNow(t, "nextReshard did not return an already ready channel")
		}
	})

	t.Run("future time", func(t *testing.T) {
		select {
		case <-watcher.nextReshard(time.Now()):
		case <-time.After(1500 * time.Millisecond):
			require.FailNow(t, "nextReshard took too long to return")
		}
	})
}

type mockConfigManager struct {
	mock.Mock
}

func (m *mockConfigManager) GetInstance(name string) (instance.ManagedInstance, error) {
	args := m.Mock.Called()
	return args.Get(0).(instance.ManagedInstance), args.Error(1)
}

func (m *mockConfigManager) ListInstances() map[string]instance.ManagedInstance {
	args := m.Mock.Called()
	return args.Get(0).(map[string]instance.ManagedInstance)
}

// ListConfigs implements Manager.
func (m *mockConfigManager) ListConfigs() map[string]instance.Config {
	args := m.Mock.Called()
	return args.Get(0).(map[string]instance.Config)
}

// ApplyConfig implements Manager.
func (m *mockConfigManager) ApplyConfig(c instance.Config) error {
	args := m.Mock.Called(c)
	return args.Error(0)
}

// DeleteConfig implements Manager.
func (m *mockConfigManager) DeleteConfig(name string) error {
	args := m.Mock.Called(name)
	return args.Error(0)
}

// Stop implements Manager.
func (m *mockConfigManager) Stop() {
	m.Mock.Called()
}

'''
'''--- pkg/metrics/cluster/configapi/types.go ---
package configapi

import (
	"encoding/json"
	"fmt"
	"net/http"
)

// APIResponse is the base object returned for any API call.
// The Data field will be set to either nil or a value of
// another *Response type value from this package.
type APIResponse struct {
	Status string      `json:"status"`
	Data   interface{} `json:"data,omitempty"`
}

// WriteTo writes the response to the given ResponseWriter with the provided
// statusCode.
func (r *APIResponse) WriteTo(w http.ResponseWriter, statusCode int) error {
	bb, err := json.Marshal(r)
	if err != nil {
		// If we fail here, we should at least write a 500 back.
		w.WriteHeader(http.StatusInternalServerError)
		return err
	}

	w.WriteHeader(statusCode)
	n, err := w.Write(bb)
	if err != nil {
		return err
	} else if n != len(bb) {
		return fmt.Errorf("could not write full response. expected %d, wrote %d", len(bb), n)
	}

	return nil
}

// ErrorResponse is contained inside an APIResponse and returns
// an error string. Returned by any API call that can fail.
type ErrorResponse struct {
	Error string `json:"error"`
}

// ListConfigurationsResponse is contained inside an APIResponse
// and provides the list of configurations known to the KV store.
// Returned by ListConfigurations.
type ListConfigurationsResponse struct {
	// Configs is the list of configuration names.
	Configs []string `json:"configs"`
}

// GetConfigurationResponse is contained inside an APIResponse
// and provides a single configuration known to the KV store.
// Returned by GetConfiguration.
type GetConfigurationResponse struct {
	// Value is the stringified YAML configuration.
	Value string `json:"value"`
}

// WriteResponse writes a response object to the provided ResponseWriter w and with a
// status code of statusCode. resp is marshaled to JSON.
func WriteResponse(w http.ResponseWriter, statusCode int, resp interface{}) error {
	apiResp := &APIResponse{Status: "success", Data: resp}
	w.Header().Set("Content-Type", "application/json")
	return apiResp.WriteTo(w, statusCode)
}

// WriteError writes an error response back to the ResponseWriter.
func WriteError(w http.ResponseWriter, statusCode int, err error) error {
	resp := &APIResponse{Status: "error", Data: &ErrorResponse{Error: err.Error()}}
	w.Header().Set("Content-Type", "application/json")
	return resp.WriteTo(w, statusCode)
}

'''
'''--- pkg/metrics/cluster/node.go ---
package cluster

import (
	"context"
	"fmt"
	"hash/fnv"
	"net/http"
	"sync"
	"time"

	"github.com/go-kit/log"
	"github.com/go-kit/log/level"
	"github.com/gorilla/mux"
	pb "github.com/grafana/agent/pkg/agentproto"
	"github.com/grafana/agent/pkg/metrics/cluster/client"
	"github.com/grafana/agent/pkg/util"
	"github.com/grafana/dskit/backoff"
	"github.com/grafana/dskit/kv"
	"github.com/grafana/dskit/ring"
	"github.com/grafana/dskit/services"
	"github.com/prometheus/client_golang/prometheus"
	"github.com/weaveworks/common/user"
)

const (
	// agentKey is the key used for storing the hash ring.
	agentKey = "agent"
)

var backoffConfig = backoff.Config{
	MinBackoff: time.Second,
	MaxBackoff: 2 * time.Minute,
	MaxRetries: 10,
}

// node manages membership within a ring. when a node joins or leaves the ring,
// it will inform other nodes to reshard their workloads. After a node joins
// the ring, it will inform the local service to reshard.
type node struct {
	log log.Logger
	reg *util.Unregisterer
	srv pb.ScrapingServiceServer

	mut  sync.RWMutex
	cfg  Config
	ring *ring.Ring
	lc   *ring.Lifecycler

	exited bool
	reload chan struct{}
}

// newNode creates a new node and registers it to the ring.
func newNode(reg prometheus.Registerer, log log.Logger, cfg Config, s pb.ScrapingServiceServer) (*node, error) {
	n := &node{
		reg: util.WrapWithUnregisterer(reg),
		srv: s,
		log: log,

		reload: make(chan struct{}, 1),
	}
	if err := n.ApplyConfig(cfg); err != nil {
		return nil, err
	}
	go n.run()
	return n, nil
}

func (n *node) ApplyConfig(cfg Config) error {
	n.mut.Lock()
	defer n.mut.Unlock()

	ctx, cancel := context.WithTimeout(context.Background(), 5*time.Minute)
	defer cancel()

	// Detect if the config changed.
	if util.CompareYAML(n.cfg, cfg) {
		return nil
	}

	if n.exited {
		return fmt.Errorf("node already exited")
	}

	level.Info(n.log).Log("msg", "applying config")

	// Shut down old components before re-creating the updated ones.
	n.reg.UnregisterAll()

	if n.lc != nil {
		// Note that this will call performClusterReshard and will block until it
		// completes.
		err := services.StopAndAwaitTerminated(ctx, n.lc)
		if err != nil {
			return fmt.Errorf("failed to stop lifecycler: %w", err)
		}
		n.lc = nil
	}

	if n.ring != nil {
		err := services.StopAndAwaitTerminated(ctx, n.ring)
		if err != nil {
			return fmt.Errorf("failed to stop ring: %w", err)
		}
		n.ring = nil
	}

	if !cfg.Enabled {
		n.cfg = cfg
		return nil
	}

	r, err := newRing(cfg.Lifecycler.RingConfig, "agent_viewer", agentKey, n.reg, n.log)
	if err != nil {
		return fmt.Errorf("failed to create ring: %w", err)
	}

	if err := services.StartAndAwaitRunning(context.Background(), r); err != nil {
		return fmt.Errorf("failed to start ring: %w", err)
	}
	n.ring = r

	lc, err := ring.NewLifecycler(cfg.Lifecycler, n, "agent", agentKey, false, n.log, prometheus.WrapRegistererWithPrefix("agent_dskit_", n.reg))
	if err != nil {
		return fmt.Errorf("failed to create lifecycler: %w", err)
	}
	if err := services.StartAndAwaitRunning(context.Background(), lc); err != nil {
		if err := services.StopAndAwaitTerminated(ctx, r); err != nil {
			level.Error(n.log).Log("msg", "failed to stop ring when returning error. next config reload will fail", "err", err)
		}
		return fmt.Errorf("failed to start lifecycler: %w", err)
	}
	n.lc = lc

	n.cfg = cfg

	// Reload and reshard the cluster.
	n.reload <- struct{}{}
	return nil
}

// newRing creates a new Cortex Ring that ignores unhealthy nodes.
func newRing(cfg ring.Config, name, key string, reg prometheus.Registerer, log log.Logger) (*ring.Ring, error) {
	codec := ring.GetCodec()
	store, err := kv.NewClient(
		cfg.KVStore,
		codec,
		kv.RegistererWithKVName(reg, name+"-ring"),
		log,
	)
	if err != nil {
		return nil, err
	}
	return ring.NewWithStoreClientAndStrategy(cfg, name, key, store, ring.NewIgnoreUnhealthyInstancesReplicationStrategy(), prometheus.WrapRegistererWithPrefix("agent_dskit_", reg), log)
}

// run waits for connection to the ring and kickstarts the join process.
func (n *node) run() {
	for range n.reload {
		n.mut.RLock()

		if err := n.performClusterReshard(context.Background(), true); err != nil {
			level.Warn(n.log).Log("msg", "dynamic cluster reshard did not succeed", "err", err)
		}

		n.mut.RUnlock()
	}

	level.Info(n.log).Log("msg", "node run loop exiting")
}

// performClusterReshard informs the cluster to immediately trigger a reshard
// of their workloads. if joining is true, the server provided to newNode will
// also be informed.
func (n *node) performClusterReshard(ctx context.Context, joining bool) error {
	if n.ring == nil || n.lc == nil {
		level.Info(n.log).Log("msg", "node disabled, not resharding")
		return nil
	}

	if n.cfg.ClusterReshardEventTimeout > 0 {
		var cancel context.CancelFunc
		ctx, cancel = context.WithTimeout(ctx, n.cfg.ClusterReshardEventTimeout)
		defer cancel()
	}

	var (
		rs  ring.ReplicationSet
		err error
	)

	backoff := backoff.New(ctx, backoffConfig)
	for backoff.Ongoing() {
		if ctx.Err() != nil {
			return ctx.Err()
		}
		rs, err = n.ring.GetAllHealthy(ring.Read)
		if err == nil {
			break
		}
		backoff.Wait()
	}

	if len(rs.Instances) > 0 {
		level.Info(n.log).Log("msg", "informing remote nodes to reshard")
	}

	// These are not in the go routine below due to potential race condition with n.lc.addr
	_, err = rs.Do(ctx, 500*time.Millisecond, func(c context.Context, id *ring.InstanceDesc) (interface{}, error) {
		// Skip over ourselves.
		if id.Addr == n.lc.Addr {
			return nil, nil
		}

		notifyCtx := user.InjectOrgID(c, "fake")
		return nil, n.notifyReshard(notifyCtx, id)
	})

	if err != nil {
		level.Error(n.log).Log("msg", "notifying other nodes failed", "err", err)
	}

	if joining {
		level.Info(n.log).Log("msg", "running local reshard")
		if _, err := n.srv.Reshard(ctx, &pb.ReshardRequest{}); err != nil {
			level.Warn(n.log).Log("msg", "dynamic local reshard did not succeed", "err", err)
		}
	}
	return err
}

// notifyReshard informs an individual node to reshard.
func (n *node) notifyReshard(ctx context.Context, id *ring.InstanceDesc) error {
	cli, err := client.New(n.cfg.Client, id.Addr)
	if err != nil {
		return err
	}
	defer cli.Close()

	level.Info(n.log).Log("msg", "attempting to notify remote agent to reshard", "addr", id.Addr)

	backoff := backoff.New(ctx, backoffConfig)
	for backoff.Ongoing() {
		if ctx.Err() != nil {
			return ctx.Err()
		}
		_, err := cli.Reshard(ctx, &pb.ReshardRequest{})
		if err == nil {
			break
		}

		level.Warn(n.log).Log("msg", "reshard notification attempt failed", "addr", id.Addr, "err", err, "attempt", backoff.NumRetries())
		backoff.Wait()
	}

	return backoff.Err()
}

// WaitJoined waits for the node the join the cluster and enter the
// ACTIVE state.
func (n *node) WaitJoined(ctx context.Context) error {
	n.mut.RLock()
	defer n.mut.RUnlock()

	level.Info(n.log).Log("msg", "waiting for the node to join the cluster")
	defer level.Info(n.log).Log("msg", "node has joined the cluster")

	if n.ring == nil || n.lc == nil {
		return fmt.Errorf("node disabled")
	}

	return waitJoined(ctx, agentKey, n.ring.KVClient, n.lc.ID)
}

func waitJoined(ctx context.Context, key string, kvClient kv.Client, id string) error {
	kvClient.WatchKey(ctx, key, func(value interface{}) bool {
		if value == nil {
			return true
		}

		desc := value.(*ring.Desc)
		for ingID, ing := range desc.Ingesters {
			if ingID == id && ing.State == ring.ACTIVE {
				return false
			}
		}

		return true
	})

	return ctx.Err()
}

func (n *node) WireAPI(r *mux.Router) {
	r.HandleFunc("/debug/ring", func(rw http.ResponseWriter, r *http.Request) {
		n.mut.RLock()
		defer n.mut.RUnlock()

		if n.ring == nil {
			http.NotFoundHandler().ServeHTTP(rw, r)
			return
		}

		n.ring.ServeHTTP(rw, r)
	})
}

// Stop stops the node and cancels it from running. The node cannot be used
// again once Stop is called.
func (n *node) Stop() error {
	n.mut.Lock()
	defer n.mut.Unlock()

	if n.exited {
		return fmt.Errorf("node already exited")
	}
	n.exited = true

	level.Info(n.log).Log("msg", "shutting down node")

	// Shut down dependencies. The lifecycler *MUST* be shut down first since n.ring is
	// used during the shutdown process to inform other nodes to reshard.
	//
	// Note that stopping the lifecycler will call performClusterReshard and will block
	// until it completes.
	var (
		firstError error
		deps       []services.Service
	)

	if n.lc != nil {
		deps = append(deps, n.lc)
	}
	if n.ring != nil {
		deps = append(deps, n.ring)
	}
	for _, dep := range deps {
		err := services.StopAndAwaitTerminated(context.Background(), dep)
		if err != nil && firstError == nil {
			firstError = err
		}
	}

	close(n.reload)
	level.Info(n.log).Log("msg", "node shut down")
	return firstError
}

// Flush implements ring.FlushTransferer. It's a no-op.
func (n *node) Flush() {}

// TransferOut implements ring.FlushTransferer. It connects to all other healthy agents and
// tells them to reshard. TransferOut should NOT be called manually unless the mutex is
// held.
func (n *node) TransferOut(ctx context.Context) error {
	return n.performClusterReshard(ctx, false)
}

// Owns checks to see if a key is owned by this node. owns will return
// an error if the ring is empty or if there aren't enough healthy nodes.
func (n *node) Owns(key string) (bool, error) {
	n.mut.RLock()
	defer n.mut.RUnlock()

	rs, err := n.ring.Get(keyHash(key), ring.Write, nil, nil, nil)
	if err != nil {
		return false, err
	}
	for _, r := range rs.Instances {
		if r.Addr == n.lc.Addr {
			return true, nil
		}
	}
	return false, nil
}

func keyHash(key string) uint32 {
	h := fnv.New32()
	_, _ = h.Write([]byte(key))
	return h.Sum32()
}

'''
'''--- pkg/metrics/cluster/node_test.go ---
package cluster

import (
	"context"
	"flag"
	"fmt"
	"math/rand"
	"net"
	"testing"
	"time"

	"github.com/go-kit/log"
	"github.com/go-kit/log/level"
	"github.com/golang/protobuf/ptypes/empty"
	"github.com/grafana/agent/pkg/agentproto"
	"github.com/grafana/agent/pkg/util"
	"github.com/grafana/dskit/ring"
	"github.com/grafana/dskit/services"
	"github.com/prometheus/client_golang/prometheus"
	"github.com/stretchr/testify/require"
	"go.uber.org/atomic"
	"google.golang.org/grpc"
	"gopkg.in/yaml.v2"
)

func Test_node_Join(t *testing.T) {
	var (
		reg    = prometheus.NewRegistry()
		logger = util.TestLogger(t)

		localReshard  = make(chan struct{}, 2)
		remoteReshard = make(chan struct{}, 2)
	)

	local := &agentproto.FuncScrapingServiceServer{
		ReshardFunc: func(c context.Context, rr *agentproto.ReshardRequest) (*empty.Empty, error) {
			localReshard <- struct{}{}
			return &empty.Empty{}, nil
		},
	}

	remote := &agentproto.FuncScrapingServiceServer{
		ReshardFunc: func(c context.Context, rr *agentproto.ReshardRequest) (*empty.Empty, error) {
			remoteReshard <- struct{}{}
			return &empty.Empty{}, nil
		},
	}
	startNode(t, remote, logger)

	nodeConfig := DefaultConfig
	nodeConfig.Enabled = true
	nodeConfig.Lifecycler = testLifecyclerConfig(t)

	n, err := newNode(reg, logger, nodeConfig, local)
	require.NoError(t, err)
	t.Cleanup(func() { _ = n.Stop() })

	require.NoError(t, n.WaitJoined(context.Background()))

	waitAll(t, remoteReshard, localReshard)
}

// waitAll waits for a message on all channels.
func waitAll(t *testing.T, chs ...chan struct{}) {
	timeoutCh := time.After(5 * time.Second)
	for _, ch := range chs {
		select {
		case <-timeoutCh:
			require.FailNow(t, "timeout exceeded")
		case <-ch:
		}
	}
}

func Test_node_Leave(t *testing.T) {
	var (
		reg    = prometheus.NewRegistry()
		logger = util.TestLogger(t)

		sendReshard   = atomic.NewBool(false)
		remoteReshard = make(chan struct{}, 2)
	)

	local := &agentproto.FuncScrapingServiceServer{
		ReshardFunc: func(c context.Context, rr *agentproto.ReshardRequest) (*empty.Empty, error) {
			return &empty.Empty{}, nil
		},
	}

	remote := &agentproto.FuncScrapingServiceServer{
		ReshardFunc: func(c context.Context, rr *agentproto.ReshardRequest) (*empty.Empty, error) {
			if sendReshard.Load() {
				remoteReshard <- struct{}{}
			}
			return &empty.Empty{}, nil
		},
	}
	startNode(t, remote, logger)

	nodeConfig := DefaultConfig
	nodeConfig.Enabled = true
	nodeConfig.Lifecycler = testLifecyclerConfig(t)

	n, err := newNode(reg, logger, nodeConfig, local)
	require.NoError(t, err)
	require.NoError(t, n.WaitJoined(context.Background()))

	// Update the reshard function to write to remoteReshard on shutdown.
	sendReshard.Store(true)

	// Stop the node so it transfers data outward.
	require.NoError(t, n.Stop(), "failed to stop the node")

	level.Info(logger).Log("msg", "waiting for remote reshard to occur")
	waitAll(t, remoteReshard)
}

func Test_node_ApplyConfig(t *testing.T) {
	var (
		reg    = prometheus.NewRegistry()
		logger = util.TestLogger(t)

		localReshard = make(chan struct{}, 10)
	)

	local := &agentproto.FuncScrapingServiceServer{
		ReshardFunc: func(c context.Context, rr *agentproto.ReshardRequest) (*empty.Empty, error) {
			localReshard <- struct{}{}
			return &empty.Empty{}, nil
		},
	}

	nodeConfig := DefaultConfig
	nodeConfig.Enabled = true
	nodeConfig.Lifecycler = testLifecyclerConfig(t)

	n, err := newNode(reg, logger, nodeConfig, local)
	require.NoError(t, err)
	t.Cleanup(func() { _ = n.Stop() })
	require.NoError(t, n.WaitJoined(context.Background()))

	// Wait for the initial join to trigger.
	waitAll(t, localReshard)

	// An ApplyConfig working correctly should re-join the cluster, which can be
	// detected by local resharding applying twice.
	nodeConfig.Lifecycler.NumTokens = 1
	require.NoError(t, n.ApplyConfig(nodeConfig), "failed to apply new config")
	require.NoError(t, n.WaitJoined(context.Background()))

	waitAll(t, localReshard)
}

// startNode launches srv as a gRPC server and registers it to the ring.
func startNode(t *testing.T, srv agentproto.ScrapingServiceServer, logger log.Logger) {
	t.Helper()

	l, err := net.Listen("tcp", "127.0.0.1:0")
	require.NoError(t, err)

	grpcServer := grpc.NewServer()
	agentproto.RegisterScrapingServiceServer(grpcServer, srv)

	go func() {
		_ = grpcServer.Serve(l)
	}()
	t.Cleanup(func() { grpcServer.Stop() })

	lcConfig := testLifecyclerConfig(t)
	lcConfig.Addr = l.Addr().(*net.TCPAddr).IP.String()
	lcConfig.Port = l.Addr().(*net.TCPAddr).Port

	lc, err := ring.NewLifecycler(lcConfig, ring.NewNoopFlushTransferer(), "agent", "agent", false, logger, nil)
	require.NoError(t, err)

	err = services.StartAndAwaitRunning(context.Background(), lc)
	require.NoError(t, err)

	// Wait for the new node to be in the ring.
	joinWaitCtx, joinWaitCancel := context.WithTimeout(context.Background(), 5*time.Second)
	defer joinWaitCancel()
	err = waitJoined(joinWaitCtx, agentKey, lc.KVStore, lc.ID)
	require.NoError(t, err)

	t.Cleanup(func() {
		_ = services.StopAndAwaitTerminated(context.Background(), lc)
	})
}

func testLifecyclerConfig(t *testing.T) ring.LifecyclerConfig {
	t.Helper()

	cfgText := util.Untab(fmt.Sprintf(`
ring:
	kvstore:
		store: inmemory
		prefix: tests/%s
final_sleep: 0s
min_ready_duration: 0s
	`, t.Name()))

	// Apply default values by registering to a fake flag set.
	var lc ring.LifecyclerConfig
	lc.RegisterFlagsWithPrefix("", flag.NewFlagSet("", flag.ContinueOnError), log.NewNopLogger())

	err := yaml.Unmarshal([]byte(cfgText), &lc)
	require.NoError(t, err)

	// Assign a random default ID.
	var letters = []rune("abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ")
	name := make([]rune, 10)
	for i := range name {
		name[i] = letters[rand.Intn(len(letters))]
	}
	lc.ID = string(name)

	// Add an invalid default address/port. Tests can override if they expect
	// incoming traffic.
	lc.Addr = "x.x.x.x"
	lc.Port = -1

	return lc
}

'''
'''--- pkg/metrics/cluster/validation.go ---
package cluster

import (
	"fmt"

	"github.com/grafana/agent/pkg/metrics/instance"
	"github.com/grafana/loki/clients/pkg/promtail/discovery/consulagent"
	"github.com/prometheus/common/config"
	"github.com/prometheus/prometheus/discovery"
	"github.com/prometheus/prometheus/discovery/aws"
	"github.com/prometheus/prometheus/discovery/azure"
	"github.com/prometheus/prometheus/discovery/consul"
	"github.com/prometheus/prometheus/discovery/digitalocean"
	"github.com/prometheus/prometheus/discovery/dns"
	"github.com/prometheus/prometheus/discovery/eureka"
	"github.com/prometheus/prometheus/discovery/file"
	"github.com/prometheus/prometheus/discovery/gce"
	"github.com/prometheus/prometheus/discovery/hetzner"
	"github.com/prometheus/prometheus/discovery/kubernetes"
	"github.com/prometheus/prometheus/discovery/marathon"
	"github.com/prometheus/prometheus/discovery/moby"
	"github.com/prometheus/prometheus/discovery/openstack"
	"github.com/prometheus/prometheus/discovery/scaleway"
	"github.com/prometheus/prometheus/discovery/triton"
	"github.com/prometheus/prometheus/discovery/zookeeper"
)

func validateNofiles(c *instance.Config) error {
	for i, rw := range c.RemoteWrite {
		if err := validateHTTPNoFiles(&rw.HTTPClientConfig); err != nil {
			return fmt.Errorf("failed to validate remote_write at index %d: %w", i, err)
		}
	}

	for i, sc := range c.ScrapeConfigs {
		if err := validateHTTPNoFiles(&sc.HTTPClientConfig); err != nil {
			return fmt.Errorf("failed to validate scrape_config at index %d: %w", i, err)
		}

		for j, disc := range sc.ServiceDiscoveryConfigs {
			if err := validateDiscoveryNoFiles(disc); err != nil {
				return fmt.Errorf("failed to validate service discovery at index %d within scrape_config at index %d: %w", j, i, err)
			}
		}
	}

	return nil
}

func validateHTTPNoFiles(cfg *config.HTTPClientConfig) error {
	checks := []struct {
		name  string
		check func() bool
	}{
		{"bearer_token_file", func() bool { return cfg.BearerTokenFile != "" }},
		{"password_file", func() bool { return cfg.BasicAuth != nil && cfg.BasicAuth.PasswordFile != "" }},
		{"credentials_file", func() bool { return cfg.Authorization != nil && cfg.Authorization.CredentialsFile != "" }},
		{"ca_file", func() bool { return cfg.TLSConfig.CAFile != "" }},
		{"cert_file", func() bool { return cfg.TLSConfig.CertFile != "" }},
		{"key_file", func() bool { return cfg.TLSConfig.KeyFile != "" }},
	}
	for _, check := range checks {
		if check.check() {
			return fmt.Errorf("%s must be empty unless dangerous_allow_reading_files is set", check.name)
		}
	}
	return nil
}

func validateDiscoveryNoFiles(disc discovery.Config) error {
	switch d := disc.(type) {
	case discovery.StaticConfig:
		// no-op
	case *azure.SDConfig:
		// no-op
	case *consul.SDConfig:
		if err := validateHTTPNoFiles(&config.HTTPClientConfig{TLSConfig: d.HTTPClientConfig.TLSConfig}); err != nil {
			return err
		}
	case *consulagent.SDConfig:
		if err := validateHTTPNoFiles(&config.HTTPClientConfig{TLSConfig: d.TLSConfig}); err != nil {
			return err
		}
	case *digitalocean.SDConfig:
		if err := validateHTTPNoFiles(&d.HTTPClientConfig); err != nil {
			return err
		}
	case *dns.SDConfig:
		// no-op
	case *moby.DockerSwarmSDConfig:
		if err := validateHTTPNoFiles(&d.HTTPClientConfig); err != nil {
			return err
		}
	case *aws.EC2SDConfig:
		// no-op
	case *eureka.SDConfig:
		if err := validateHTTPNoFiles(&d.HTTPClientConfig); err != nil {
			return err
		}
	case *file.SDConfig:
		// no-op
	case *gce.SDConfig:
		// no-op
	case *hetzner.SDConfig:
		if err := validateHTTPNoFiles(&d.HTTPClientConfig); err != nil {
			return err
		}
	case *kubernetes.SDConfig:
		if err := validateHTTPNoFiles(&d.HTTPClientConfig); err != nil {
			return err
		}
	case *marathon.SDConfig:
		if err := validateHTTPNoFiles(&d.HTTPClientConfig); err != nil {
			return err
		}
		if d.AuthTokenFile != "" {
			return fmt.Errorf("auth_token_file must be empty unless dangerous_allow_reading_files is set")
		}
	case *openstack.SDConfig:
		if err := validateHTTPNoFiles(&config.HTTPClientConfig{TLSConfig: d.TLSConfig}); err != nil {
			return err
		}
	case *scaleway.SDConfig:
		if err := validateHTTPNoFiles(&d.HTTPClientConfig); err != nil {
			return err
		}
	case *triton.SDConfig:
		if err := validateHTTPNoFiles(&config.HTTPClientConfig{TLSConfig: d.TLSConfig}); err != nil {
			return err
		}
	case *zookeeper.NerveSDConfig:
		// no-op
	case *zookeeper.ServersetSDConfig:
		// no-op
	default:
		return fmt.Errorf("unknown service discovery %s; rejecting config for safety. set dangerous_allow_reading_files to ignore", d.Name())
	}

	return nil
}

'''
'''--- pkg/metrics/cluster/validation_test.go ---
package cluster

import (
	"fmt"
	"strings"
	"testing"

	"github.com/grafana/agent/pkg/metrics/instance"
	"github.com/grafana/agent/pkg/util"
	"github.com/stretchr/testify/require"
)

func Test_validateNoFiles(t *testing.T) {
	tt := []struct {
		name   string
		input  string
		expect error
	}{
		{
			name: "valid config",
			input: util.Untab(`
			scrape_configs:
			- job_name: innocent_scrape
				static_configs:
					- targets: ['127.0.0.1:12345']
			remote_write:
			- url: http://localhost:9009/api/prom/push
			`),
			expect: nil,
		},
		{
			name: "all SDs",
			input: util.Untab(`
      scrape_configs:
			- job_name: basic_sds
				static_configs:
				- targets: ['localhost']
				azure_sd_configs:
				- subscription_id: fake
					tenant_id: fake
					client_id: fake
					client_secret: fake
				consul_sd_configs:
				- {}
				dns_sd_configs:
				- names: ['fake']
				ec2_sd_configs:
				- region: fake
				eureka_sd_configs:
				- server: http://localhost:80/eureka
				file_sd_configs:
				- files: ['fake.json']
				digitalocean_sd_configs:
				- {}
				dockerswarm_sd_configs:
				- host: localhost
					role: nodes
				gce_sd_configs:
				- project: fake
					zone: fake
				hetzner_sd_configs:
				- role: hcloud
				kubernetes_sd_configs:
				- role: pod
				marathon_sd_configs:
				- servers: ['localhost']
				nerve_sd_configs:
				- servers: ['localhost']
					paths: ['/']
				openstack_sd_configs:
				- role: instance
					region: fake
				scaleway_sd_configs:
				- role: instance
					project_id: ffffffff-ffff-ffff-ffff-ffffffffffff
					secret_key: ffffffff-ffff-ffff-ffff-ffffffffffff
					access_key: SCWXXXXXXXXXXXXXXXXX
				serverset_sd_configs:
				- servers: ['localhost']
					paths: ['/']
				triton_sd_configs:
				- account: fake
					dns_suffix: fake
					endpoint: fake
			`),
			expect: nil,
		},
		{
			name: "invalid http client config",
			input: util.Untab(`
			scrape_configs:
			- job_name: malicious_scrape
				static_configs:
					- targets: ['badsite.com']
				basic_auth:
					username: file_leak
					password_file: /etc/password
			remote_write:
			- url: http://localhost:9009/api/prom/push
			`),
			expect: fmt.Errorf("failed to validate scrape_config at index 0: password_file must be empty unless dangerous_allow_reading_files is set"),
		},
	}

	for _, tc := range tt {
		t.Run(tc.name, func(t *testing.T) {
			cfg, err := instance.UnmarshalConfig(strings.NewReader(tc.input))
			require.NoError(t, err)

			actual := validateNofiles(cfg)
			if tc.expect == nil {
				require.NoError(t, actual)
			} else {
				require.EqualError(t, actual, tc.expect.Error())
			}
		})
	}
}

'''
'''--- pkg/metrics/http.go ---
package metrics

import (
	"fmt"
	"net/http"
	"net/url"
	"sort"
	"time"

	"github.com/go-kit/log/level"
	"github.com/gorilla/mux"
	"github.com/grafana/agent/pkg/metrics/cluster/configapi"
	"github.com/prometheus/common/model"
	"github.com/prometheus/prometheus/model/labels"
	"github.com/prometheus/prometheus/scrape"
	"github.com/prometheus/prometheus/storage/remote"
)

// WireAPI adds API routes to the provided mux router.
func (a *Agent) WireAPI(r *mux.Router) {
	a.cluster.WireAPI(r)

	// Backwards compatible endpoints. Use endpoints with `metrics` prefix instead
	r.HandleFunc("/agent/api/v1/instances", a.ListInstancesHandler).Methods("GET")
	r.HandleFunc("/agent/api/v1/targets", a.ListTargetsHandler).Methods("GET")

	r.HandleFunc("/agent/api/v1/metrics/instances", a.ListInstancesHandler).Methods("GET")
	r.HandleFunc("/agent/api/v1/metrics/targets", a.ListTargetsHandler).Methods("GET")
	r.HandleFunc("/agent/api/v1/metrics/instance/{instance}/write", a.PushMetricsHandler).Methods("POST")
}

// ListInstancesHandler writes the set of currently running instances to the http.ResponseWriter.
func (a *Agent) ListInstancesHandler(w http.ResponseWriter, _ *http.Request) {
	cfgs := a.mm.ListConfigs()
	instanceNames := make([]string, 0, len(cfgs))
	for k := range cfgs {
		instanceNames = append(instanceNames, k)
	}
	sort.Strings(instanceNames)

	err := configapi.WriteResponse(w, http.StatusOK, instanceNames)
	if err != nil {
		level.Error(a.logger).Log("msg", "failed to write response", "err", err)
	}
}

// ListTargetsHandler retrieves the full set of targets across all instances and shows
// information on them.
func (a *Agent) ListTargetsHandler(w http.ResponseWriter, r *http.Request) {
	instances := a.mm.ListInstances()
	allTagets := make(map[string]TargetSet, len(instances))
	for instName, inst := range instances {
		allTagets[instName] = inst.TargetsActive()
	}
	ListTargetsHandler(allTagets).ServeHTTP(w, r)
}

// ListTargetsHandler renders a mapping of instance to target set.
func ListTargetsHandler(targets map[string]TargetSet) http.Handler {
	return http.HandlerFunc(func(rw http.ResponseWriter, _ *http.Request) {
		resp := ListTargetsResponse{}

		for instance, tset := range targets {
			for key, targets := range tset {
				for _, tgt := range targets {
					var lastError string
					if scrapeError := tgt.LastError(); scrapeError != nil {
						lastError = scrapeError.Error()
					}

					resp = append(resp, TargetInfo{
						InstanceName: instance,
						TargetGroup:  key,

						Endpoint:         tgt.URL().String(),
						State:            string(tgt.Health()),
						DiscoveredLabels: tgt.DiscoveredLabels(),
						Labels:           tgt.Labels(),
						LastScrape:       tgt.LastScrape(),
						ScrapeDuration:   tgt.LastScrapeDuration().Milliseconds(),
						ScrapeError:      lastError,
					})
				}
			}
		}

		sort.Slice(resp, func(i, j int) bool {
			// sort by instance, then target group, then job label, then instance label
			var (
				iInstance      = resp[i].InstanceName
				iTargetGroup   = resp[i].TargetGroup
				iJobLabel      = resp[i].Labels.Get(model.JobLabel)
				iInstanceLabel = resp[i].Labels.Get(model.InstanceLabel)

				jInstance      = resp[j].InstanceName
				jTargetGroup   = resp[j].TargetGroup
				jJobLabel      = resp[j].Labels.Get(model.JobLabel)
				jInstanceLabel = resp[j].Labels.Get(model.InstanceLabel)
			)

			switch {
			case iInstance != jInstance:
				return iInstance < jInstance
			case iTargetGroup != jTargetGroup:
				return iTargetGroup < jTargetGroup
			case iJobLabel != jJobLabel:
				return iJobLabel < jJobLabel
			default:
				return iInstanceLabel < jInstanceLabel
			}
		})

		_ = configapi.WriteResponse(rw, http.StatusOK, resp)
	})
}

// TargetSet is a set of targets for an individual scraper.
type TargetSet map[string][]*scrape.Target

// ListTargetsResponse is returned by the ListTargetsHandler.
type ListTargetsResponse []TargetInfo

// TargetInfo describes a specific target.
type TargetInfo struct {
	InstanceName string `json:"instance"`
	TargetGroup  string `json:"target_group"`

	Endpoint         string        `json:"endpoint"`
	State            string        `json:"state"`
	Labels           labels.Labels `json:"labels"`
	DiscoveredLabels labels.Labels `json:"discovered_labels"`
	LastScrape       time.Time     `json:"last_scrape"`
	ScrapeDuration   int64         `json:"scrape_duration_ms"`
	ScrapeError      string        `json:"scrape_error"`
}

// PushMetricsHandler provides a way to POST data directly into
// an instance's WAL.
func (a *Agent) PushMetricsHandler(w http.ResponseWriter, r *http.Request) {
	// Get instance name.
	instanceName, err := getInstanceName(r)
	if err != nil {
		http.Error(w, err.Error(), http.StatusBadRequest)
		return
	}

	// Get the metrics instance and serve the request.
	managedInstance, err := a.InstanceManager().GetInstance(instanceName)
	if err != nil || managedInstance == nil {
		http.Error(w, err.Error(), http.StatusBadRequest)
		return
	}

	handler := remote.NewWriteHandler(a.logger, managedInstance)
	handler.ServeHTTP(w, r)
}

// getInstanceName uses gorilla/mux's route variables to extract the
// "instance" variable. If not found, getInstanceName will return an error.
func getInstanceName(r *http.Request) (string, error) {
	vars := mux.Vars(r)
	name := vars["instance"]
	name, err := url.PathUnescape(name)
	if err != nil {
		return "", fmt.Errorf("could not decode instance name: %w", err)
	}
	return name, nil
}

'''
'''--- pkg/metrics/http_test.go ---
package metrics

import (
	"fmt"
	"net/http"
	"net/http/httptest"
	"testing"
	"time"

	"github.com/cortexproject/cortex/pkg/util/test"
	"github.com/go-kit/log"
	"github.com/grafana/agent/pkg/metrics/instance"
	"github.com/prometheus/client_golang/prometheus"
	"github.com/prometheus/common/model"
	"github.com/prometheus/prometheus/model/labels"
	"github.com/prometheus/prometheus/scrape"
	"github.com/stretchr/testify/require"
)

func TestAgent_ListInstancesHandler(t *testing.T) {
	fact := newFakeInstanceFactory()
	a, err := newAgent(prometheus.NewRegistry(), Config{
		WALDir: "/tmp/agent",
	}, log.NewNopLogger(), fact.factory)
	require.NoError(t, err)
	defer a.Stop()

	r := httptest.NewRequest("GET", "/agent/api/v1/metrics/instances", nil)

	t.Run("no instances", func(t *testing.T) {
		rr := httptest.NewRecorder()
		a.ListInstancesHandler(rr, r)
		expect := `{"status":"success","data":[]}`
		require.Equal(t, expect, rr.Body.String())
	})

	t.Run("non-empty", func(t *testing.T) {
		require.NoError(t, a.mm.ApplyConfig(makeInstanceConfig("foo")))
		require.NoError(t, a.mm.ApplyConfig(makeInstanceConfig("bar")))

		expect := `{"status":"success","data":["bar","foo"]}`
		test.Poll(t, time.Second, true, func() interface{} {
			rr := httptest.NewRecorder()
			a.ListInstancesHandler(rr, r)
			return expect == rr.Body.String()
		})
	})
}

func TestAgent_ListTargetsHandler(t *testing.T) {
	fact := newFakeInstanceFactory()
	a, err := newAgent(prometheus.NewRegistry(), Config{
		WALDir: "/tmp/agent",
	}, log.NewNopLogger(), fact.factory)
	require.NoError(t, err)

	mockManager := &instance.MockManager{
		ListInstancesFunc: func() map[string]instance.ManagedInstance { return nil },
		ListConfigsFunc:   func() map[string]instance.Config { return nil },
		ApplyConfigFunc:   func(_ instance.Config) error { return nil },
		DeleteConfigFunc:  func(name string) error { return nil },
		StopFunc:          func() {},
	}
	a.mm, err = instance.NewModalManager(prometheus.NewRegistry(), a.logger, mockManager, instance.ModeDistinct)
	require.NoError(t, err)

	r := httptest.NewRequest("GET", "/agent/api/v1/metrics/targets", nil)

	t.Run("scrape manager not ready", func(t *testing.T) {
		mockManager.ListInstancesFunc = func() map[string]instance.ManagedInstance {
			return map[string]instance.ManagedInstance{
				"test_instance": &mockInstanceScrape{},
			}
		}

		rr := httptest.NewRecorder()
		a.ListTargetsHandler(rr, r)
		expect := `{"status": "success", "data": []}`
		require.JSONEq(t, expect, rr.Body.String())
		require.Equal(t, http.StatusOK, rr.Result().StatusCode)
	})

	t.Run("scrape manager targets", func(t *testing.T) {
		tgt := scrape.NewTarget(labels.FromMap(map[string]string{
			model.JobLabel:         "job",
			model.InstanceLabel:    "instance",
			"foo":                  "bar",
			model.SchemeLabel:      "http",
			model.AddressLabel:     "localhost:12345",
			model.MetricsPathLabel: "/metrics",
		}), labels.FromMap(map[string]string{
			"__discovered__": "yes",
		}), nil)

		startTime := time.Date(1994, time.January, 12, 0, 0, 0, 0, time.UTC)
		tgt.Report(startTime, time.Minute, fmt.Errorf("something went wrong"))

		mockManager.ListInstancesFunc = func() map[string]instance.ManagedInstance {
			return map[string]instance.ManagedInstance{
				"test_instance": &mockInstanceScrape{
					tgts: map[string][]*scrape.Target{
						"group_a": {tgt},
					},
				},
			}
		}

		rr := httptest.NewRecorder()
		a.ListTargetsHandler(rr, r)
		expect := `{
			"status": "success",
			"data": [{
				"instance": "test_instance",
				"target_group": "group_a",
				"endpoint": "http://localhost:12345/metrics",
				"state": "down",
				"labels": {
					"foo": "bar",
					"instance": "instance",
					"job": "job"
				},
				"discovered_labels": {
					"__discovered__": "yes"
				},
				"last_scrape": "1994-01-12T00:00:00Z",
				"scrape_duration_ms": 60000,
				"scrape_error":"something went wrong"
			}]
		}`
		require.JSONEq(t, expect, rr.Body.String())
		require.Equal(t, http.StatusOK, rr.Result().StatusCode)
	})
}

type mockInstanceScrape struct {
	instance.NoOpInstance
	tgts map[string][]*scrape.Target
}

func (i *mockInstanceScrape) TargetsActive() map[string][]*scrape.Target {
	return i.tgts
}

'''
'''--- pkg/metrics/instance/configstore/api.go ---
package configstore

import (
	"errors"
	"fmt"
	"io"
	"net/http"
	"net/url"
	"strings"
	"sync"

	"github.com/go-kit/log"
	"github.com/go-kit/log/level"
	"github.com/gorilla/mux"
	"github.com/grafana/agent/pkg/metrics/cluster/configapi"
	"github.com/grafana/agent/pkg/metrics/instance"
	"github.com/prometheus/client_golang/prometheus"
)

// API is an HTTP API to interact with a configstore.
type API struct {
	log       log.Logger
	storeMut  sync.Mutex
	store     Store
	validator Validator

	totalCreatedConfigs prometheus.Counter
	totalUpdatedConfigs prometheus.Counter
	totalDeletedConfigs prometheus.Counter

	enableGet bool
}

// Validator valides a config before putting it into the store.
// Validator is allowed to mutate the config and will only be given a copy.
type Validator = func(c *instance.Config) error

// NewAPI creates a new API. Store can be applied later with SetStore.
func NewAPI(l log.Logger, store Store, v Validator, enableGet bool) *API {
	return &API{
		log:       l,
		store:     store,
		validator: v,

		totalCreatedConfigs: prometheus.NewCounter(prometheus.CounterOpts{
			Name: "agent_metrics_ha_configs_created_total",
			Help: "Total number of created scraping service configs",
		}),
		totalUpdatedConfigs: prometheus.NewCounter(prometheus.CounterOpts{
			Name: "agent_metrics_ha_configs_updated_total",
			Help: "Total number of updated scraping service configs",
		}),
		totalDeletedConfigs: prometheus.NewCounter(prometheus.CounterOpts{
			Name: "agent_metrics_ha_configs_deleted_total",
			Help: "Total number of deleted scraping service configs",
		}),
		enableGet: enableGet,
	}
}

// WireAPI injects routes into the provided mux router for the config
// store API.
func (api *API) WireAPI(r *mux.Router) {
	// Support URL-encoded config names. The handlers will need to decode the
	// name when reading the path variable.
	r = r.UseEncodedPath()

	r.HandleFunc("/agent/api/v1/configs", api.ListConfigurations).Methods("GET")
	getConfigHandler := messageHandlerFunc(http.StatusNotFound, "404 - config endpoint is disabled")
	if api.enableGet {
		getConfigHandler = api.GetConfiguration
	}
	r.HandleFunc("/agent/api/v1/configs/{name}", getConfigHandler).Methods("GET")
	r.HandleFunc("/agent/api/v1/config/{name}", api.PutConfiguration).Methods("PUT", "POST")
	r.HandleFunc("/agent/api/v1/config/{name}", api.DeleteConfiguration).Methods("DELETE")
}

// Describe implements prometheus.Collector.
func (api *API) Describe(ch chan<- *prometheus.Desc) {
	ch <- api.totalCreatedConfigs.Desc()
	ch <- api.totalUpdatedConfigs.Desc()
	ch <- api.totalDeletedConfigs.Desc()
}

// Collect implements prometheus.Collector.
func (api *API) Collect(mm chan<- prometheus.Metric) {
	mm <- api.totalCreatedConfigs
	mm <- api.totalUpdatedConfigs
	mm <- api.totalDeletedConfigs
}

// ListConfigurations returns a list of configurations.
func (api *API) ListConfigurations(rw http.ResponseWriter, r *http.Request) {
	api.storeMut.Lock()
	defer api.storeMut.Unlock()
	if api.store == nil {
		api.writeError(rw, http.StatusNotFound, fmt.Errorf("no config store running"))
		return
	}

	keys, err := api.store.List(r.Context())
	if errors.Is(err, ErrNotConnected) {
		api.writeError(rw, http.StatusNotFound, fmt.Errorf("no config store running"))
		return
	} else if err != nil {
		api.writeError(rw, http.StatusInternalServerError, fmt.Errorf("failed to write config: %w", err))
		return
	}
	api.writeResponse(rw, http.StatusOK, configapi.ListConfigurationsResponse{Configs: keys})
}

// GetConfiguration gets an individual configuration.
func (api *API) GetConfiguration(rw http.ResponseWriter, r *http.Request) {
	api.storeMut.Lock()
	defer api.storeMut.Unlock()
	if api.store == nil {
		api.writeError(rw, http.StatusNotFound, fmt.Errorf("no config store running"))
		return
	}

	configKey, err := getConfigName(r)
	if err != nil {
		api.writeError(rw, http.StatusBadRequest, err)
		return
	}

	cfg, err := api.store.Get(r.Context(), configKey)
	switch {
	case errors.Is(err, ErrNotConnected):
		api.writeError(rw, http.StatusNotFound, err)
	case errors.As(err, &NotExistError{}):
		api.writeError(rw, http.StatusNotFound, err)
	case err != nil:
		api.writeError(rw, http.StatusInternalServerError, err)
	case err == nil:
		bb, err := instance.MarshalConfig(&cfg, true)
		if err != nil {
			api.writeError(rw, http.StatusInternalServerError, fmt.Errorf("could not marshal config for response: %w", err))
			return
		}
		api.writeResponse(rw, http.StatusOK, &configapi.GetConfigurationResponse{
			Value: string(bb),
		})
	}
}

// PutConfiguration creates or updates a configuration.
func (api *API) PutConfiguration(rw http.ResponseWriter, r *http.Request) {
	api.storeMut.Lock()
	defer api.storeMut.Unlock()
	if api.store == nil {
		api.writeError(rw, http.StatusNotFound, fmt.Errorf("no config store running"))
		return
	}

	configName, err := getConfigName(r)
	if err != nil {
		api.writeError(rw, http.StatusBadRequest, err)
		return
	}

	var config strings.Builder
	if _, err := io.Copy(&config, r.Body); err != nil {
		api.writeError(rw, http.StatusInternalServerError, err)
		return
	}

	cfg, err := instance.UnmarshalConfig(strings.NewReader(config.String()))
	if err != nil {
		api.writeError(rw, http.StatusBadRequest, fmt.Errorf("could not unmarshal config: %w", err))
		return
	}
	cfg.Name = configName

	if api.validator != nil {
		validateCfg, err := instance.UnmarshalConfig(strings.NewReader(config.String()))
		if err != nil {
			api.writeError(rw, http.StatusBadRequest, fmt.Errorf("could not unmarshal config: %w", err))
			return
		}
		validateCfg.Name = configName

		if err := api.validator(validateCfg); err != nil {
			api.writeError(rw, http.StatusBadRequest, fmt.Errorf("failed to validate config: %w", err))
			return
		}
	}

	created, err := api.store.Put(r.Context(), *cfg)
	switch {
	case errors.Is(err, ErrNotConnected):
		api.writeError(rw, http.StatusNotFound, err)
	case errors.As(err, &NotUniqueError{}):
		api.writeError(rw, http.StatusBadRequest, err)
	case err != nil:
		api.writeError(rw, http.StatusInternalServerError, err)
	default:
		if created {
			api.totalCreatedConfigs.Inc()
			api.writeResponse(rw, http.StatusCreated, nil)
		} else {
			api.totalUpdatedConfigs.Inc()
			api.writeResponse(rw, http.StatusOK, nil)
		}
	}
}

// DeleteConfiguration deletes a configuration.
func (api *API) DeleteConfiguration(rw http.ResponseWriter, r *http.Request) {
	api.storeMut.Lock()
	defer api.storeMut.Unlock()
	if api.store == nil {
		api.writeError(rw, http.StatusNotFound, fmt.Errorf("no config store running"))
		return
	}

	configKey, err := getConfigName(r)
	if err != nil {
		api.writeError(rw, http.StatusBadRequest, err)
		return
	}

	err = api.store.Delete(r.Context(), configKey)
	switch {
	case errors.Is(err, ErrNotConnected):
		api.writeError(rw, http.StatusNotFound, err)
	case errors.As(err, &NotExistError{}):
		api.writeError(rw, http.StatusNotFound, err)
	case err != nil:
		api.writeError(rw, http.StatusInternalServerError, err)
	default:
		api.totalDeletedConfigs.Inc()
		api.writeResponse(rw, http.StatusOK, nil)
	}
}

func (api *API) writeError(rw http.ResponseWriter, statusCode int, writeErr error) {
	err := configapi.WriteError(rw, statusCode, writeErr)
	if err != nil {
		level.Error(api.log).Log("msg", "failed to write response", "err", err)
	}
}

func (api *API) writeResponse(rw http.ResponseWriter, statusCode int, v interface{}) {
	err := configapi.WriteResponse(rw, statusCode, v)
	if err != nil {
		level.Error(api.log).Log("msg", "failed to write response", "err", err)
	}
}

// getConfigName uses gorilla/mux's route variables to extract the
// "name" variable. If not found, getConfigName will return an error.
func getConfigName(r *http.Request) (string, error) {
	vars := mux.Vars(r)
	name := vars["name"]
	name, err := url.PathUnescape(name)
	if err != nil {
		return "", fmt.Errorf("could not decode config name: %w", err)
	}
	return name, nil
}

func messageHandlerFunc(statusCode int, msg string) http.HandlerFunc {
	return func(rw http.ResponseWriter, r *http.Request) {
		rw.WriteHeader(statusCode)
		_, _ = rw.Write([]byte(msg))
	}
}

'''
'''--- pkg/metrics/instance/configstore/api_test.go ---
package configstore

import (
	"bytes"
	"context"
	"encoding/json"
	"fmt"
	"io"
	"io/ioutil"
	"net/http"
	"net/http/httptest"
	"strings"
	"testing"
	"time"

	"github.com/go-kit/log"
	"github.com/gorilla/mux"
	"github.com/grafana/agent/pkg/client"
	"github.com/grafana/agent/pkg/metrics/cluster/configapi"
	"github.com/grafana/agent/pkg/metrics/instance"
	"github.com/stretchr/testify/assert"
	"github.com/stretchr/testify/require"
)

func TestAPI_ListConfigurations(t *testing.T) {
	s := &Mock{
		ListFunc: func(ctx context.Context) ([]string, error) {
			return []string{"a", "b", "c"}, nil
		},
	}

	api := NewAPI(log.NewNopLogger(), s, nil, true)
	env := newAPITestEnvironment(t, api)

	resp, err := http.Get(env.srv.URL + "/agent/api/v1/configs")
	require.NoError(t, err)
	require.Equal(t, http.StatusOK, resp.StatusCode)

	expect := `{
		"status": "success",
		"data": {
			"configs": ["a", "b", "c"]
		}
	}`
	body, err := ioutil.ReadAll(resp.Body)
	require.NoError(t, err)
	require.JSONEq(t, expect, string(body))

	t.Run("With Client", func(t *testing.T) {
		cli := client.New(env.srv.URL)
		apiResp, err := cli.ListConfigs(context.Background())
		require.NoError(t, err)

		expect := &configapi.ListConfigurationsResponse{Configs: []string{"a", "b", "c"}}
		require.Equal(t, expect, apiResp)
	})
}

func TestAPI_GetConfiguration_Invalid(t *testing.T) {
	s := &Mock{
		GetFunc: func(ctx context.Context, key string) (instance.Config, error) {
			return instance.Config{}, NotExistError{Key: key}
		},
	}

	api := NewAPI(log.NewNopLogger(), s, nil, true)
	env := newAPITestEnvironment(t, api)

	resp, err := http.Get(env.srv.URL + "/agent/api/v1/configs/does-not-exist")
	require.NoError(t, err)
	require.Equal(t, http.StatusNotFound, resp.StatusCode)

	expect := `{
		"status": "error",
		"data": {
			"error": "configuration does-not-exist does not exist"
		}
	}`
	body, err := ioutil.ReadAll(resp.Body)
	require.NoError(t, err)
	require.JSONEq(t, expect, string(body))

	t.Run("With Client", func(t *testing.T) {
		cli := client.New(env.srv.URL)
		_, err := cli.GetConfiguration(context.Background(), "does-not-exist")
		require.NotNil(t, err)
		require.Equal(t, "configuration does-not-exist does not exist", err.Error())
	})
}

func TestAPI_GetConfiguration(t *testing.T) {
	s := &Mock{
		GetFunc: func(ctx context.Context, key string) (instance.Config, error) {
			return instance.Config{
				Name:                key,
				HostFilter:          true,
				RemoteFlushDeadline: 10 * time.Minute,
			}, nil
		},
	}

	api := NewAPI(log.NewNopLogger(), s, nil, true)
	env := newAPITestEnvironment(t, api)

	resp, err := http.Get(env.srv.URL + "/agent/api/v1/configs/exists")
	require.NoError(t, err)
	require.Equal(t, http.StatusOK, resp.StatusCode)

	expect := `{
		"status": "success",
		"data": {
			"value": "name: exists\nhost_filter: true\nremote_flush_deadline: 10m0s\n"
		}
	}`
	body, err := ioutil.ReadAll(resp.Body)
	require.NoError(t, err)
	require.JSONEq(t, expect, string(body))

	t.Run("With Client", func(t *testing.T) {
		cli := client.New(env.srv.URL)
		actual, err := cli.GetConfiguration(context.Background(), "exists")
		require.NoError(t, err)

		// The client will apply defaults, so we need to start with the DefaultConfig
		// as a base here.
		expect := instance.DefaultConfig
		expect.Name = "exists"
		expect.HostFilter = true
		expect.RemoteFlushDeadline = 10 * time.Minute
		require.Equal(t, &expect, actual)
	})
}

func TestAPI_GetConfiguration_ScrubSecrets(t *testing.T) {
	rawConfig := `name: exists
scrape_configs:
- job_name: local_scrape
  follow_redirects: true
  enable_http2: true
  honor_timestamps: true
  metrics_path: /metrics
  scheme: http
  static_configs:
  - targets:
    - 127.0.0.1:12345
    labels:
      cluster: localhost
  basic_auth:
    username: admin
    password: SCRUBME
remote_write:
- url: http://localhost:9009/api/prom/push
  remote_timeout: 30s
  name: test-d0f32c
  send_exemplars: true
  basic_auth:
    username: admin
    password: SCRUBME
  queue_config:
    capacity: 500
    max_shards: 1000
    min_shards: 1
    max_samples_per_send: 100
    batch_send_deadline: 5s
    min_backoff: 30ms
    max_backoff: 100ms
  follow_redirects: true
  enable_http2: true
  metadata_config:
    send: true
    send_interval: 1m
    max_samples_per_send: 500
wal_truncate_frequency: 1m0s
min_wal_time: 5m0s
max_wal_time: 4h0m0s
remote_flush_deadline: 1m0s
`
	scrubbedConfig := strings.ReplaceAll(rawConfig, "SCRUBME", "<secret>")

	s := &Mock{
		GetFunc: func(ctx context.Context, key string) (instance.Config, error) {
			c, err := instance.UnmarshalConfig(strings.NewReader(rawConfig))
			if err != nil {
				return instance.Config{}, err
			}
			return *c, nil
		},
	}

	api := NewAPI(log.NewNopLogger(), s, nil, true)
	env := newAPITestEnvironment(t, api)

	resp, err := http.Get(env.srv.URL + "/agent/api/v1/configs/exists")
	require.NoError(t, err)
	require.Equal(t, http.StatusOK, resp.StatusCode)
	respBytes, err := io.ReadAll(resp.Body)
	require.NoError(t, err)

	var apiResp struct {
		Status string `json:"status"`
		Data   struct {
			Value string `json:"value"`
		} `json:"data"`
	}
	err = json.Unmarshal(respBytes, &apiResp)
	require.NoError(t, err)
	require.Equal(t, "success", apiResp.Status)
	require.YAMLEq(t, scrubbedConfig, apiResp.Data.Value)

	t.Run("With Client", func(t *testing.T) {
		cli := client.New(env.srv.URL)
		actual, err := cli.GetConfiguration(context.Background(), "exists")
		require.NoError(t, err)

		// Marshal the retrieved config _without_ scrubbing. This means
		// that if the secrets weren't scrubbed from GetConfiguration, something
		// bad happened at the API level.
		actualBytes, err := instance.MarshalConfig(actual, false)
		require.NoError(t, err)
		require.YAMLEq(t, scrubbedConfig, string(actualBytes))
	})
}

func TestServer_GetConfiguration_Disabled(t *testing.T) {
	api := NewAPI(log.NewNopLogger(), nil, nil, false)
	env := newAPITestEnvironment(t, api)
	resp, err := http.Get(env.srv.URL + "/agent/api/v1/configs/exists")
	require.NoError(t, err)
	require.Equal(t, http.StatusNotFound, resp.StatusCode)
	body, err := ioutil.ReadAll(resp.Body)
	require.NoError(t, err)
	require.Equal(t, []byte("404 - config endpoint is disabled"), body)
}

func TestServer_PutConfiguration(t *testing.T) {
	var s Mock

	api := NewAPI(log.NewNopLogger(), &s, nil, true)
	env := newAPITestEnvironment(t, api)

	cfg := instance.Config{Name: "newconfig"}
	bb, err := instance.MarshalConfig(&cfg, false)
	require.NoError(t, err)

	t.Run("Created", func(t *testing.T) {
		// Created configs should return http.StatusCreated
		s.PutFunc = func(ctx context.Context, c instance.Config) (created bool, err error) {
			return true, nil
		}

		resp, err := http.Post(env.srv.URL+"/agent/api/v1/config/newconfig", "", bytes.NewReader(bb))
		require.NoError(t, err)
		require.Equal(t, http.StatusCreated, resp.StatusCode)
	})

	t.Run("Updated", func(t *testing.T) {
		// Updated configs should return http.StatusOK
		s.PutFunc = func(ctx context.Context, c instance.Config) (created bool, err error) {
			return false, nil
		}

		resp, err := http.Post(env.srv.URL+"/agent/api/v1/config/newconfig", "", bytes.NewReader(bb))
		require.NoError(t, err)
		require.Equal(t, http.StatusOK, resp.StatusCode)
	})
}

func TestServer_PutConfiguration_Invalid(t *testing.T) {
	var s Mock

	api := NewAPI(log.NewNopLogger(), &s, func(c *instance.Config) error {
		return fmt.Errorf("custom validation error")
	}, true)
	env := newAPITestEnvironment(t, api)

	cfg := instance.Config{Name: "newconfig"}
	bb, err := instance.MarshalConfig(&cfg, false)
	require.NoError(t, err)

	resp, err := http.Post(env.srv.URL+"/agent/api/v1/config/newconfig", "", bytes.NewReader(bb))
	require.NoError(t, err)
	require.Equal(t, http.StatusBadRequest, resp.StatusCode)

	expect := `{
		"status": "error",
		"data": {
			"error": "failed to validate config: custom validation error"
		}
	}`
	body, err := ioutil.ReadAll(resp.Body)
	require.NoError(t, err)
	require.JSONEq(t, expect, string(body))
}

func TestServer_PutConfiguration_WithClient(t *testing.T) {
	var s Mock
	api := NewAPI(log.NewNopLogger(), &s, nil, true)
	env := newAPITestEnvironment(t, api)

	cfg := instance.DefaultConfig
	cfg.Name = "newconfig-withclient"
	cfg.HostFilter = true
	cfg.RemoteFlushDeadline = 10 * time.Minute

	s.PutFunc = func(ctx context.Context, c instance.Config) (created bool, err error) {
		assert.Equal(t, cfg, c)
		return true, nil
	}

	cli := client.New(env.srv.URL)
	err := cli.PutConfiguration(context.Background(), "newconfig-withclient", &cfg)
	require.NoError(t, err)
}

func TestServer_DeleteConfiguration(t *testing.T) {
	s := &Mock{
		DeleteFunc: func(ctx context.Context, key string) error {
			assert.Equal(t, "deleteme", key)
			return nil
		},
	}

	api := NewAPI(log.NewNopLogger(), s, nil, true)
	env := newAPITestEnvironment(t, api)

	req, err := http.NewRequest(http.MethodDelete, env.srv.URL+"/agent/api/v1/config/deleteme", nil)
	require.NoError(t, err)
	resp, err := http.DefaultClient.Do(req)
	require.NoError(t, err)
	require.Equal(t, http.StatusOK, resp.StatusCode)

	t.Run("With Client", func(t *testing.T) {
		cli := client.New(env.srv.URL)
		err := cli.DeleteConfiguration(context.Background(), "deleteme")
		require.NoError(t, err)
	})
}

func TestServer_DeleteConfiguration_Invalid(t *testing.T) {
	s := &Mock{
		DeleteFunc: func(ctx context.Context, key string) error {
			assert.Equal(t, "deleteme", key)
			return NotExistError{Key: key}
		},
	}

	api := NewAPI(log.NewNopLogger(), s, nil, true)
	env := newAPITestEnvironment(t, api)

	req, err := http.NewRequest(http.MethodDelete, env.srv.URL+"/agent/api/v1/config/deleteme", nil)
	require.NoError(t, err)
	resp, err := http.DefaultClient.Do(req)
	require.NoError(t, err)
	require.Equal(t, http.StatusNotFound, resp.StatusCode)

	t.Run("With Client", func(t *testing.T) {
		cli := client.New(env.srv.URL)
		err := cli.DeleteConfiguration(context.Background(), "deleteme")
		require.Error(t, err)
	})
}

func TestServer_URLEncoded(t *testing.T) {
	var s Mock

	api := NewAPI(log.NewNopLogger(), &s, nil, true)
	env := newAPITestEnvironment(t, api)

	var cfg instance.Config
	bb, err := instance.MarshalConfig(&cfg, false)
	require.NoError(t, err)

	s.PutFunc = func(ctx context.Context, c instance.Config) (created bool, err error) {
		assert.Equal(t, "url/encoded", c.Name)
		return true, nil
	}

	resp, err := http.Post(env.srv.URL+"/agent/api/v1/config/url%2Fencoded", "", bytes.NewReader(bb))
	require.NoError(t, err)
	require.Equal(t, http.StatusCreated, resp.StatusCode)

	s.GetFunc = func(ctx context.Context, key string) (instance.Config, error) {
		assert.Equal(t, "url/encoded", key)
		return instance.Config{Name: "url/encoded"}, nil
	}

	resp, err = http.Get(env.srv.URL + "/agent/api/v1/configs/url%2Fencoded")
	require.NoError(t, err)
	require.Equal(t, http.StatusOK, resp.StatusCode)
}

type apiTestEnvironment struct {
	srv    *httptest.Server
	router *mux.Router
}

func newAPITestEnvironment(t *testing.T, api *API) apiTestEnvironment {
	t.Helper()

	router := mux.NewRouter()
	srv := httptest.NewServer(router)
	t.Cleanup(srv.Close)

	api.WireAPI(router)

	return apiTestEnvironment{srv: srv, router: router}
}

'''
'''--- pkg/metrics/instance/configstore/codec.go ---
package configstore

import (
	"bytes"
	"compress/gzip"
	"fmt"
	"io"
	"strings"

	"github.com/grafana/dskit/kv/codec"
)

// GetCodec returns the codec for encoding and decoding instance.Configs
// in the Remote store.
func GetCodec() codec.Codec {
	return &yamlCodec{}
}

type yamlCodec struct{}

func (*yamlCodec) Decode(bb []byte) (interface{}, error) {
	// Decode is called by kv.Clients with an empty slice when a
	// key is deleted. We should stop early here and don't return
	// an error so the deletion event propagates to watchers.
	if len(bb) == 0 {
		return nil, nil
	}

	r, err := gzip.NewReader(bytes.NewReader(bb))
	if err != nil {
		return nil, err
	}

	var sb strings.Builder
	if _, err := io.Copy(&sb, r); err != nil {
		return nil, err
	}
	return sb.String(), nil
}

func (*yamlCodec) Encode(v interface{}) ([]byte, error) {
	var buf bytes.Buffer

	var cfg string

	switch v := v.(type) {
	case string:
		cfg = v
	default:
		panic(fmt.Sprintf("unexpected type %T passed to yamlCodec.Encode", v))
	}

	w := gzip.NewWriter(&buf)

	if _, err := io.Copy(w, strings.NewReader(cfg)); err != nil {
		return nil, err
	}

	w.Close()
	return buf.Bytes(), nil
}

func (*yamlCodec) CodecID() string {
	return "agentConfig/yaml"
}

'''
'''--- pkg/metrics/instance/configstore/codec_test.go ---
package configstore

import (
	"testing"

	"github.com/stretchr/testify/require"
)

func TestCodec(t *testing.T) {
	exampleConfig := `name: 'test'
host_filter: false
scrape_configs:
  - job_name: process-1
    static_configs:
      - targets: ['process-1:80']
        labels:
          cluster: 'local'
          origin: 'agent'`

	c := &yamlCodec{}
	bb, err := c.Encode(exampleConfig)
	require.NoError(t, err)

	out, err := c.Decode(bb)
	require.NoError(t, err)
	require.Equal(t, exampleConfig, out)
}

// TestCodec_Decode_Nil makes sure that if Decode is called with an empty value,
// which may happen when a key is deleted, that no error occurs and instead an
// nil value is returned.
func TestCodec_Decode_Nil(t *testing.T) {
	c := &yamlCodec{}

	input := [][]byte{nil, make([]byte, 0)}
	for _, bb := range input {
		out, err := c.Decode(bb)
		require.Nil(t, err)
		require.Nil(t, out)
	}
}

'''
'''--- pkg/metrics/instance/configstore/errors.go ---
package configstore

import "fmt"

// ErrNotConnected is used when a store operation was called but no connection
// to the store was active.
var ErrNotConnected = fmt.Errorf("not connected to store")

// NotExistError is used when a config doesn't exist.
type NotExistError struct {
	Key string
}

// Error implements error.
func (e NotExistError) Error() string {
	return fmt.Sprintf("configuration %s does not exist", e.Key)
}

// NotUniqueError is used when two scrape jobs have the same name.
type NotUniqueError struct {
	ScrapeJob string
}

// Error implements error.
func (e NotUniqueError) Error() string {
	return fmt.Sprintf("found multiple scrape configs in config store with job name %q", e.ScrapeJob)
}

'''
'''--- pkg/metrics/instance/configstore/mock.go ---
package configstore

import (
	"context"

	"github.com/grafana/agent/pkg/metrics/instance"
)

// Mock is a Mock Store. Useful primarily for testing.
type Mock struct {
	ListFunc   func(ctx context.Context) ([]string, error)
	GetFunc    func(ctx context.Context, key string) (instance.Config, error)
	PutFunc    func(ctx context.Context, c instance.Config) (created bool, err error)
	DeleteFunc func(ctx context.Context, key string) error
	AllFunc    func(ctx context.Context, keep func(key string) bool) (<-chan instance.Config, error)
	WatchFunc  func() <-chan WatchEvent
	CloseFunc  func() error
}

// List implements Store.
func (s *Mock) List(ctx context.Context) ([]string, error) {
	if s.ListFunc != nil {
		return s.ListFunc(ctx)
	}
	panic("List not implemented")
}

// Get implements Store.
func (s *Mock) Get(ctx context.Context, key string) (instance.Config, error) {
	if s.GetFunc != nil {
		return s.GetFunc(ctx, key)
	}
	panic("Get not implemented")
}

// Put implements Store.
func (s *Mock) Put(ctx context.Context, c instance.Config) (created bool, err error) {
	if s.PutFunc != nil {
		return s.PutFunc(ctx, c)
	}
	panic("Put not implemented")
}

// Delete implements Store.
func (s *Mock) Delete(ctx context.Context, key string) error {
	if s.DeleteFunc != nil {
		return s.DeleteFunc(ctx, key)
	}
	panic("Delete not implemented")
}

// All implements Store.
func (s *Mock) All(ctx context.Context, keep func(key string) bool) (<-chan instance.Config, error) {
	if s.AllFunc != nil {
		return s.AllFunc(ctx, keep)
	}
	panic("All not implemented")
}

// Watch implements Store.
func (s *Mock) Watch() <-chan WatchEvent {
	if s.WatchFunc != nil {
		return s.WatchFunc()
	}
	panic("Watch not implemented")
}

// Close implements Store.
func (s *Mock) Close() error {
	if s.CloseFunc != nil {
		return s.CloseFunc()
	}
	panic("Close not implemented")
}

'''
'''--- pkg/metrics/instance/configstore/remote.go ---
package configstore

import (
	"context"
	"errors"
	"fmt"
	"net/http"
	"strings"
	"sync"

	"github.com/weaveworks/common/instrument"

	"github.com/hashicorp/go-cleanhttp"

	"github.com/hashicorp/consul/api"

	"github.com/go-kit/log"
	"github.com/go-kit/log/level"
	"github.com/grafana/agent/pkg/metrics/instance"
	"github.com/grafana/agent/pkg/util"
	"github.com/grafana/dskit/kv"
	"github.com/prometheus/client_golang/prometheus"
	"github.com/prometheus/client_golang/prometheus/promauto"
)

/***********************************************************************************************************************
The consul code skipping the cortex handler is due to performance issue with a large number of configs and overloading
consul. See issue https://github.com/grafana/agent/issues/789. The long term method will be to refactor and extract
the cortex code so other stores can also benefit from this. @mattdurham
***********************************************************************************************************************/

var consulRequestDuration = instrument.NewHistogramCollector(promauto.NewHistogramVec(prometheus.HistogramOpts{
	Name:    "agent_configstore_consul_request_duration_seconds",
	Help:    "Time spent on consul requests when listing configs.",
	Buckets: prometheus.DefBuckets,
}, []string{"operation", "status_code"}))

// Remote loads instance files from a remote KV store. The KV store
// can be swapped out in real time.
type Remote struct {
	log log.Logger
	reg *util.Unregisterer

	kvMut    sync.RWMutex
	kv       *agentRemoteClient
	reloadKV chan struct{}

	cancelCtx  context.Context
	cancelFunc context.CancelFunc

	configsMut sync.Mutex
	configsCh  chan WatchEvent
}

// agentRemoteClient is a simple wrapper to allow the shortcircuit of consul, while being backwards compatible with non
// consul kv stores
type agentRemoteClient struct {
	kv.Client
	consul *api.Client
	config kv.Config
}

// NewRemote creates a new Remote store that uses a Key-Value client to store
// and retrieve configs. If enable is true, the store will be immediately
// connected to. Otherwise, it can be lazily loaded by enabling later through
// a call to Remote.ApplyConfig.
func NewRemote(l log.Logger, reg prometheus.Registerer, cfg kv.Config, enable bool) (*Remote, error) {
	cancelCtx, cancelFunc := context.WithCancel(context.Background())

	r := &Remote{
		log: l,
		reg: util.WrapWithUnregisterer(reg),

		reloadKV: make(chan struct{}, 1),

		cancelCtx:  cancelCtx,
		cancelFunc: cancelFunc,

		configsCh: make(chan WatchEvent),
	}
	if err := r.ApplyConfig(cfg, enable); err != nil {
		return nil, fmt.Errorf("failed to apply config for config store: %w", err)
	}

	go r.run()
	return r, nil
}

// ApplyConfig applies the config for a kv client.
func (r *Remote) ApplyConfig(cfg kv.Config, enable bool) error {
	r.kvMut.Lock()
	defer r.kvMut.Unlock()

	if r.cancelCtx.Err() != nil {
		return fmt.Errorf("remote store already stopped")
	}

	// Unregister all metrics that the previous kv may have registered.
	r.reg.UnregisterAll()

	if !enable {
		r.setClient(nil, nil, kv.Config{})
		return nil
	}

	cli, err := kv.NewClient(cfg, GetCodec(), kv.RegistererWithKVName(r.reg, "agent_configs"), r.log)
	// This is a hack to get a consul client, the client above has it embedded but its not exposed
	var consulClient *api.Client
	if cfg.Store == "consul" {
		consulClient, err = api.NewClient(&api.Config{
			Address: cfg.Consul.Host,
			Token:   cfg.Consul.ACLToken,
			Scheme:  "http",
			HttpClient: &http.Client{
				Transport: cleanhttp.DefaultPooledTransport(),
				// See https://blog.cloudflare.com/the-complete-guide-to-golang-net-http-timeouts/
				Timeout: cfg.Consul.HTTPClientTimeout,
			},
		})
		if err != nil {
			return err
		}
	}

	if err != nil {
		return fmt.Errorf("failed to create kv client: %w", err)
	}

	r.setClient(cli, consulClient, cfg)
	return nil
}

// setClient sets the active client and notifies run to restart the
// kv watcher.
func (r *Remote) setClient(client kv.Client, consulClient *api.Client, config kv.Config) {
	if client == nil && consulClient == nil {
		r.kv = nil
	} else {
		r.kv = &agentRemoteClient{
			Client: client,
			consul: consulClient,
			config: config,
		}
	}
	r.reloadKV <- struct{}{}
}

func (r *Remote) run() {
	var (
		kvContext context.Context
		kvCancel  context.CancelFunc
	)

Outer:
	for {
		select {
		case <-r.cancelCtx.Done():
			break Outer
		case <-r.reloadKV:
			r.kvMut.RLock()
			kv := r.kv
			r.kvMut.RUnlock()

			if kvCancel != nil {
				kvCancel()
			}
			kvContext, kvCancel = context.WithCancel(r.cancelCtx)
			go r.watchKV(kvContext, kv)
		}
	}

	if kvCancel != nil {
		kvCancel()
	}
}

func (r *Remote) watchKV(ctx context.Context, client *agentRemoteClient) {
	// Edge case: client was unset, nothing to do here.
	if client == nil {
		level.Info(r.log).Log("msg", "not watching the KV, none set")
		return
	}

	client.WatchPrefix(ctx, "", func(key string, v interface{}) bool {
		if ctx.Err() != nil {
			return false
		}

		r.configsMut.Lock()
		defer r.configsMut.Unlock()

		switch {
		case v == nil:
			r.configsCh <- WatchEvent{Key: key, Config: nil}
		default:
			cfg, err := instance.UnmarshalConfig(strings.NewReader(v.(string)))
			if err != nil {
				level.Error(r.log).Log("msg", "could not unmarshal config from store", "name", key, "err", err)
				break
			}

			r.configsCh <- WatchEvent{Key: key, Config: cfg}
		}

		return true
	})
}

// List returns the list of all configs in the KV store.
func (r *Remote) List(ctx context.Context) ([]string, error) {
	r.kvMut.RLock()
	defer r.kvMut.RUnlock()
	if r.kv == nil {
		return nil, ErrNotConnected
	}

	return r.kv.List(ctx, "")
}

// listConsul returns Key Value Pairs instead of []string
func (r *Remote) listConsul(ctx context.Context) (api.KVPairs, error) {
	if r.kv == nil {
		return nil, ErrNotConnected
	}

	var pairs api.KVPairs
	options := &api.QueryOptions{
		AllowStale:        !r.kv.config.Consul.ConsistentReads,
		RequireConsistent: r.kv.config.Consul.ConsistentReads,
	}
	// This is copied from cortex list so that stats stay the same
	err := instrument.CollectedRequest(ctx, "List", consulRequestDuration, instrument.ErrorCode, func(ctx context.Context) error {
		var err error
		pairs, _, err = r.kv.consul.KV().List(r.kv.config.Prefix, options.WithContext(ctx))
		return err
	})

	if err != nil {
		return nil, err
	}
	// This mirrors the previous behavior of returning a blank array as opposed to nil.
	if pairs == nil {
		blankPairs := make(api.KVPairs, 0)
		return blankPairs, nil
	}
	for _, kvp := range pairs {
		kvp.Key = strings.TrimPrefix(kvp.Key, r.kv.config.Prefix)
	}
	return pairs, nil
}

// Get retrieves an individual config from the KV store.
func (r *Remote) Get(ctx context.Context, key string) (instance.Config, error) {
	r.kvMut.RLock()
	defer r.kvMut.RUnlock()
	if r.kv == nil {
		return instance.Config{}, ErrNotConnected
	}

	v, err := r.kv.Get(ctx, key)
	if err != nil {
		return instance.Config{}, fmt.Errorf("failed to get config %s: %w", key, err)
	} else if v == nil {
		return instance.Config{}, NotExistError{Key: key}
	}

	cfg, err := instance.UnmarshalConfig(strings.NewReader(v.(string)))
	if err != nil {
		return instance.Config{}, fmt.Errorf("failed to unmarshal config %s: %w", key, err)
	}
	return *cfg, nil
}

// Put adds or updates a config in the KV store.
func (r *Remote) Put(ctx context.Context, c instance.Config) (bool, error) {
	// We need to use a write lock here since two Applies can't run concurrently
	// (given the current need to perform a store-wide validation.)
	r.kvMut.Lock()
	defer r.kvMut.Unlock()
	if r.kv == nil {
		return false, ErrNotConnected
	}

	bb, err := instance.MarshalConfig(&c, false)
	if err != nil {
		return false, fmt.Errorf("failed to marshal config: %w", err)
	}

	cfgCh, err := r.all(ctx, nil)
	if err != nil {
		return false, fmt.Errorf("failed to check validity of config: %w", err)
	}
	if err := checkUnique(cfgCh, &c); err != nil {
		return false, fmt.Errorf("failed to check uniqueness of config: %w", err)
	}

	var created bool
	err = r.kv.CAS(ctx, c.Name, func(in interface{}) (out interface{}, retry bool, err error) {
		// The configuration is new if there's no previous value from the CAS
		created = (in == nil)
		return string(bb), false, nil
	})
	if err != nil {
		return false, fmt.Errorf("failed to put config: %w", err)
	}
	return created, nil
}

// Delete deletes a config from the KV store. It returns NotExistError if
// the config doesn't exist.
func (r *Remote) Delete(ctx context.Context, key string) error {
	r.kvMut.RLock()
	defer r.kvMut.RUnlock()
	if r.kv == nil {
		return ErrNotConnected
	}

	// Some KV stores don't return an error if something failed to be
	// deleted, so we'll try to get it first. This isn't perfect, and
	// it may fail, so we'll silently ignore any errors here unless
	// we know for sure the config doesn't exist.
	v, err := r.kv.Get(ctx, key)
	if err != nil {
		level.Warn(r.log).Log("msg", "error validating key existence for deletion", "err", err)
	} else if v == nil {
		return NotExistError{Key: key}
	}

	err = r.kv.Delete(ctx, key)
	if err != nil {
		return fmt.Errorf("error deleting configuration: %w", err)
	}

	return nil
}

// All retrieves the set of all configs in the store.
func (r *Remote) All(ctx context.Context, keep func(key string) bool) (<-chan instance.Config, error) {
	r.kvMut.RLock()
	defer r.kvMut.RUnlock()
	return r.all(ctx, keep)
}

// all can only be called if the kvMut lock is already held.
func (r *Remote) all(ctx context.Context, keep func(key string) bool) (<-chan instance.Config, error) {
	if r.kv == nil {
		return nil, ErrNotConnected
	}

	// If we are using a consul client then do the short circuit way, this is done so that we receive all the key value pairs
	//	in one call then, operate on them in memory. Previously we retrieved the list (which stripped the values)
	//	then ran a goroutine to get each individual value from consul. In situations with an extremely large number of
	//	configs this overloaded the consul instances. This reduces that to one call, that was being made anyways.
	if r.kv.consul != nil {
		return r.allConsul(ctx, keep)
	}

	return r.allOther(ctx, keep)
}

// allConsul is ONLY usable when consul is the keystore. This is a performance improvement in using the client directly
//	instead of the cortex multi store kv interface. That interface returns the list then each value must be retrieved
//	individually. This returns all the keys and values in one call and works on them in memory
func (r *Remote) allConsul(ctx context.Context, keep func(key string) bool) (<-chan instance.Config, error) {
	if r.kv.consul == nil {
		level.Error(r.log).Log("err", "allConsul called but consul client nil")
		return nil, errors.New("allConsul called but consul client nil")
	}
	var configs []*instance.Config
	c := GetCodec()

	pairs, err := r.listConsul(ctx)

	if err != nil {
		return nil, err
	}
	for _, kvp := range pairs {
		if keep != nil && !keep(kvp.Key) {
			level.Debug(r.log).Log("msg", "skipping key that was filtered out", "key", kvp.Key)
			continue
		}
		value, err := c.Decode(kvp.Value)
		if err != nil {
			level.Error(r.log).Log("msg", "failed to decode config from store", "key", kvp.Key, "err", err)
			continue
		}
		if value == nil {
			// Config was deleted since we called list, skip it.
			level.Debug(r.log).Log("msg", "skipping key that was deleted after list was called", "key", kvp.Key)
			continue
		}

		cfg, err := instance.UnmarshalConfig(strings.NewReader(value.(string)))
		if err != nil {
			level.Error(r.log).Log("msg", "failed to unmarshal config from store", "key", kvp.Key, "err", err)
			continue
		}
		configs = append(configs, cfg)
	}
	ch := make(chan instance.Config, len(configs))
	for _, cfg := range configs {
		ch <- *cfg
	}
	close(ch)
	return ch, nil
}

func (r *Remote) allOther(ctx context.Context, keep func(key string) bool) (<-chan instance.Config, error) {
	if r.kv == nil {
		return nil, ErrNotConnected
	}

	keys, err := r.kv.List(ctx, "")
	if err != nil {
		return nil, fmt.Errorf("failed to list configs: %w", err)
	}

	ch := make(chan instance.Config)

	var wg sync.WaitGroup
	wg.Add(len(keys))
	go func() {
		wg.Wait()
		close(ch)
	}()

	for _, key := range keys {
		go func(key string) {
			defer wg.Done()

			if keep != nil && !keep(key) {
				level.Debug(r.log).Log("msg", "skipping key that was filtered out", "key", key)
				return
			}

			// TODO(rfratto): retries might be useful here
			v, err := r.kv.Get(ctx, key)
			if err != nil {
				level.Error(r.log).Log("msg", "failed to get config with key", "key", key, "err", err)
				return
			} else if v == nil {
				// Config was deleted since we called list, skip it.
				level.Debug(r.log).Log("msg", "skipping key that was deleted after list was called", "key", key)
				return
			}

			cfg, err := instance.UnmarshalConfig(strings.NewReader(v.(string)))
			if err != nil {
				level.Error(r.log).Log("msg", "failed to unmarshal config from store", "key", key, "err", err)
				return
			}
			ch <- *cfg
		}(key)
	}

	return ch, nil
}

// Watch watches the Store for changes.
func (r *Remote) Watch() <-chan WatchEvent {
	return r.configsCh
}

// Close closes the Remote store.
func (r *Remote) Close() error {
	r.kvMut.Lock()
	defer r.kvMut.Unlock()
	r.cancelFunc()
	return nil
}

'''
'''--- pkg/metrics/instance/configstore/remote_test.go ---
package configstore

import (
	"context"
	"fmt"
	"sort"
	"strings"
	"testing"
	"time"

	"github.com/go-kit/log"
	"github.com/grafana/agent/pkg/metrics/instance"
	"github.com/grafana/agent/pkg/util"
	"github.com/grafana/dskit/kv"
	"github.com/prometheus/client_golang/prometheus"
	"github.com/stretchr/testify/require"
)

func TestRemote_List(t *testing.T) {
	remote, err := NewRemote(log.NewNopLogger(), prometheus.NewRegistry(), kv.Config{
		Store:  "inmemory",
		Prefix: "configs/",
	}, true)
	require.NoError(t, err)
	t.Cleanup(func() {
		err := remote.Close()
		require.NoError(t, err)
	})

	cfgs := []string{"a", "b", "c"}
	for _, cfg := range cfgs {
		err := remote.kv.CAS(context.Background(), cfg, func(in interface{}) (out interface{}, retry bool, err error) {
			return fmt.Sprintf("name: %s", cfg), false, nil
		})
		require.NoError(t, err)
	}

	list, err := remote.List(context.Background())
	require.NoError(t, err)
	sort.Strings(list)
	require.Equal(t, cfgs, list)
}

func TestRemote_Get(t *testing.T) {
	remote, err := NewRemote(log.NewNopLogger(), prometheus.NewRegistry(), kv.Config{
		Store:  "inmemory",
		Prefix: "configs/",
	}, true)
	require.NoError(t, err)
	t.Cleanup(func() {
		err := remote.Close()
		require.NoError(t, err)
	})

	err = remote.kv.CAS(context.Background(), "someconfig", func(in interface{}) (out interface{}, retry bool, err error) {
		return "name: someconfig", false, nil
	})
	require.NoError(t, err)

	cfg, err := remote.Get(context.Background(), "someconfig")
	require.NoError(t, err)

	expect := instance.DefaultConfig
	expect.Name = "someconfig"
	require.Equal(t, expect, cfg)
}

func TestRemote_Put(t *testing.T) {
	remote, err := NewRemote(log.NewNopLogger(), prometheus.NewRegistry(), kv.Config{
		Store:  "inmemory",
		Prefix: "configs/",
	}, true)
	require.NoError(t, err)
	t.Cleanup(func() {
		err := remote.Close()
		require.NoError(t, err)
	})

	cfg := instance.DefaultConfig
	cfg.Name = "newconfig"

	created, err := remote.Put(context.Background(), cfg)
	require.NoError(t, err)
	require.True(t, created)

	actual, err := remote.Get(context.Background(), "newconfig")
	require.NoError(t, err)
	require.Equal(t, cfg, actual)

	t.Run("Updating", func(t *testing.T) {
		cfg := instance.DefaultConfig
		cfg.Name = "newconfig"
		cfg.HostFilter = true

		created, err := remote.Put(context.Background(), cfg)
		require.NoError(t, err)
		require.False(t, created)
	})
}

func TestRemote_Put_NonUnique(t *testing.T) {
	var (
		conflictingA = util.Untab(`
name: conflicting-a
scrape_configs:
- job_name: foobar
		`)
		conflictingB = util.Untab(`
name: conflicting-b
scrape_configs:
- job_name: fizzbuzz
- job_name: foobar
		`)
	)

	conflictingACfg, err := instance.UnmarshalConfig(strings.NewReader(conflictingA))
	require.NoError(t, err)

	conflictingBCfg, err := instance.UnmarshalConfig(strings.NewReader(conflictingB))
	require.NoError(t, err)

	remote, err := NewRemote(log.NewNopLogger(), prometheus.NewRegistry(), kv.Config{
		Store:  "inmemory",
		Prefix: "configs/",
	}, true)
	require.NoError(t, err)
	t.Cleanup(func() {
		err := remote.Close()
		require.NoError(t, err)
	})

	created, err := remote.Put(context.Background(), *conflictingACfg)
	require.NoError(t, err)
	require.True(t, created)

	_, err = remote.Put(context.Background(), *conflictingBCfg)
	require.EqualError(t, err, fmt.Sprintf("failed to check uniqueness of config: found multiple scrape configs in config store with job name %q", "foobar"))
}

func TestRemote_Delete(t *testing.T) {
	remote, err := NewRemote(log.NewNopLogger(), prometheus.NewRegistry(), kv.Config{
		Store:  "inmemory",
		Prefix: "configs/",
	}, true)
	require.NoError(t, err)
	t.Cleanup(func() {
		err := remote.Close()
		require.NoError(t, err)
	})

	var cfg instance.Config
	cfg.Name = "deleteme"

	created, err := remote.Put(context.Background(), cfg)
	require.NoError(t, err)
	require.True(t, created)

	err = remote.Delete(context.Background(), "deleteme")
	require.NoError(t, err)

	_, err = remote.Get(context.Background(), "deleteme")
	require.EqualError(t, err, "configuration deleteme does not exist")

	err = remote.Delete(context.Background(), "deleteme")
	require.EqualError(t, err, "configuration deleteme does not exist")
}

func TestRemote_All(t *testing.T) {
	remote, err := NewRemote(log.NewNopLogger(), prometheus.NewRegistry(), kv.Config{
		Store:  "inmemory",
		Prefix: "all-configs/",
	}, true)
	require.NoError(t, err)
	t.Cleanup(func() {
		err := remote.Close()
		require.NoError(t, err)
	})

	cfgs := []string{"a", "b", "c"}
	for _, cfg := range cfgs {
		err := remote.kv.CAS(context.Background(), cfg, func(in interface{}) (out interface{}, retry bool, err error) {
			return fmt.Sprintf("name: %s", cfg), false, nil
		})
		require.NoError(t, err)
	}

	configCh, err := remote.All(context.Background(), nil)
	require.NoError(t, err)

	var gotConfigs []string
	for gotConfig := range configCh {
		gotConfigs = append(gotConfigs, gotConfig.Name)
	}
	sort.Strings(gotConfigs)

	require.Equal(t, cfgs, gotConfigs)
}

func TestRemote_Watch(t *testing.T) {
	remote, err := NewRemote(log.NewNopLogger(), prometheus.NewRegistry(), kv.Config{
		Store:  "inmemory",
		Prefix: "watch-configs/",
	}, true)
	require.NoError(t, err)
	t.Cleanup(func() {
		err := remote.Close()
		require.NoError(t, err)
	})

	_, err = remote.Put(context.Background(), instance.Config{Name: "watch"})
	require.NoError(t, err)

	select {
	case cfg := <-remote.Watch():
		require.Equal(t, "watch", cfg.Key)
		require.NotNil(t, cfg.Config)
		require.Equal(t, "watch", cfg.Config.Name)
	case <-time.After(3 * time.Second):
		require.FailNow(t, "failed to watch for config")
	}

	// Make sure Watch gets other updates.
	_, err = remote.Put(context.Background(), instance.Config{Name: "watch2"})
	require.NoError(t, err)

	select {
	case cfg := <-remote.Watch():
		require.Equal(t, "watch2", cfg.Key)
		require.NotNil(t, cfg.Config)
		require.Equal(t, "watch2", cfg.Config.Name)
	case <-time.After(3 * time.Second):
		require.FailNow(t, "failed to watch for config")
	}
}

func TestRemote_ApplyConfig(t *testing.T) {
	remote, err := NewRemote(log.NewNopLogger(), prometheus.NewRegistry(), kv.Config{
		Store:  "inmemory",
		Prefix: "test-applyconfig/",
	}, true)
	require.NoError(t, err)
	t.Cleanup(func() {
		err := remote.Close()
		require.NoError(t, err)
	})

	err = remote.ApplyConfig(kv.Config{
		Store:  "inmemory",
		Prefix: "test-applyconfig2/",
	}, true)
	require.NoError(t, err, "failed to apply a new config")

	err = remote.ApplyConfig(kv.Config{
		Store:  "inmemory",
		Prefix: "test-applyconfig2/",
	}, true)
	require.NoError(t, err, "failed to re-apply the current config")

	// Make sure watch still works
	_, err = remote.Put(context.Background(), instance.Config{Name: "watch"})
	require.NoError(t, err)

	select {
	case cfg := <-remote.Watch():
		require.Equal(t, "watch", cfg.Key)
		require.NotNil(t, cfg.Config)
		require.Equal(t, "watch", cfg.Config.Name)
	case <-time.After(3 * time.Second):
		require.FailNow(t, "failed to watch for config")
	}
}

'''
'''--- pkg/metrics/instance/configstore/store.go ---
// Package configstore abstracts the concepts of where instance files get
// retrieved.
package configstore

import (
	"context"

	"github.com/grafana/agent/pkg/metrics/instance"
)

// Store is some interface to retrieving instance configurations.
type Store interface {
	// List gets the list of config names.
	List(ctx context.Context) ([]string, error)

	// Get gets an individual config by name.
	Get(ctx context.Context, key string) (instance.Config, error)

	// Put applies a new instance Config to the store.
	// If the config already exists, created will be false to indicate an
	// update.
	Put(ctx context.Context, c instance.Config) (created bool, err error)

	// Delete deletes a config from the store.
	Delete(ctx context.Context, key string) error

	// All retrieves the entire list of instance configs currently
	// in the store. A filtering "keep" function can be provided to ignore some
	// configs, which can significantly speed up the operation in some cases.
	All(ctx context.Context, keep func(key string) bool) (<-chan instance.Config, error)

	// Watch watches for changed instance Configs.
	// All callers of Watch receive the same Channel.
	//
	// It is not guaranteed that Watch will emit all store events, and Watch
	// should only be used for best-effort quick convergence with the remote
	// store. Watch should always be paired with polling All.
	Watch() <-chan WatchEvent

	// Close closes the store.
	Close() error
}

// WatchEvent is returned by Watch. The Key is the name of the config that was
// added, updated, or deleted. If the Config was deleted, Config will be nil.
type WatchEvent struct {
	Key    string
	Config *instance.Config
}

'''
'''--- pkg/metrics/instance/configstore/unique.go ---
package configstore

import (
	"github.com/grafana/agent/pkg/metrics/instance"
)

// checkUnique validates that cfg is unique from all, ensuring that no two
// configs share a job_name.
func checkUnique(all <-chan instance.Config, cfg *instance.Config) error {
	defer func() {
		// Drain the channel, which is necessary if we're returning an error.
		for range all {
		}
	}()

	newJobNames := make(map[string]struct{}, len(cfg.ScrapeConfigs))
	for _, sc := range cfg.ScrapeConfigs {
		newJobNames[sc.JobName] = struct{}{}
	}

	for otherConfig := range all {
		// If the other config is the one we're validating, skip it.
		if otherConfig.Name == cfg.Name {
			continue
		}

		for _, otherScrape := range otherConfig.ScrapeConfigs {
			if _, exist := newJobNames[otherScrape.JobName]; exist {
				return NotUniqueError{ScrapeJob: otherScrape.JobName}
			}
		}
	}

	return nil
}

'''
'''--- pkg/metrics/instance/errors.go ---
package instance

import "fmt"

// ErrInvalidUpdate is returned whenever Update is called against an instance
// but an invalid field is changed between configs. If ErrInvalidUpdate is
// returned, the instance must be fully stopped and replaced with a new one
// with the new config.
type ErrInvalidUpdate struct {
	Inner error
}

// Error implements the error interface.
func (e ErrInvalidUpdate) Error() string { return e.Inner.Error() }

// Is returns true if err is an ErrInvalidUpdate.
func (e ErrInvalidUpdate) Is(err error) bool {
	switch err.(type) {
	case ErrInvalidUpdate, *ErrInvalidUpdate:
		return true
	default:
		return false
	}
}

// As will set the err object to ErrInvalidUpdate provided err
// is a pointer to ErrInvalidUpdate.
func (e ErrInvalidUpdate) As(err interface{}) bool {
	switch v := err.(type) {
	case *ErrInvalidUpdate:
		*v = e
	default:
		return false
	}
	return true
}

// errImmutableField is the error describing a field that cannot be changed. It
// is wrapped inside of a ErrInvalidUpdate.
type errImmutableField struct{ Field string }

func (e errImmutableField) Error() string {
	return fmt.Sprintf("%s cannot be changed dynamically", e.Field)
}

'''
'''--- pkg/metrics/instance/global.go ---
package instance

import (
	"time"

	"github.com/prometheus/prometheus/config"
)

// DefaultGlobalConfig holds default global settings to be used across all instances.
var DefaultGlobalConfig = GlobalConfig{
	Prometheus: config.DefaultGlobalConfig,
}

// GlobalConfig holds global settings that apply to all instances by default.
type GlobalConfig struct {
	Prometheus  config.GlobalConfig         `yaml:",inline"`
	RemoteWrite []*config.RemoteWriteConfig `yaml:"remote_write,omitempty"`

	ExtraMetrics      bool          `yaml:"-"`
	DisableKeepAlives bool          `yaml:"-"`
	IdleConnTimeout   time.Duration `yaml:"-"`
}

// UnmarshalYAML implements yaml.Unmarshaler.
func (c *GlobalConfig) UnmarshalYAML(unmarshal func(interface{}) error) error {
	*c = DefaultGlobalConfig

	type plain GlobalConfig
	return unmarshal((*plain)(c))
}

'''
'''--- pkg/metrics/instance/group_manager.go ---
package instance

import (
	"crypto/md5"
	"encoding/hex"
	"fmt"
	"sort"
	"sync"

	"github.com/prometheus/prometheus/config"
)

// A GroupManager wraps around another Manager and groups all incoming Configs
// into a smaller set of configs, causing less managed instances to be spawned.
//
// Configs are grouped by all settings for a Config *except* scrape configs.
// Any difference found in any flag will cause a Config to be placed in another
// group. One exception to this rule is that remote_writes are compared
// unordered, but the sets of remote_writes should otherwise be identical.
//
// GroupManagers drastically improve the performance of the Agent when a
// significant number of instances are spawned, as the overhead of each
// instance having its own service discovery, WAL, and remote_write can be
// significant.
//
// The config names of instances within the group will be represented by
// that group's hash of settings.
type GroupManager struct {
	inner Manager

	mtx sync.Mutex

	// groups is a map of group name to the grouped configs.
	groups map[string]groupedConfigs

	// groupLookup is a map of config name to group name.
	groupLookup map[string]string
}

// groupedConfigs holds a set of grouped configs, keyed by the config name.
// They are stored in a map rather than a slice to make overriding an existing
// config within the group less error prone.
type groupedConfigs map[string]Config

// Copy returns a shallow copy of the groupedConfigs.
func (g groupedConfigs) Copy() groupedConfigs {
	res := make(groupedConfigs, len(g))
	for k, v := range g {
		res[k] = v
	}
	return res
}

// NewGroupManager creates a new GroupManager for combining instances of the
// same "group."
func NewGroupManager(inner Manager) *GroupManager {
	return &GroupManager{
		inner:       inner,
		groups:      make(map[string]groupedConfigs),
		groupLookup: make(map[string]string),
	}
}

// GetInstance gets the underlying grouped instance for a given name.
func (m *GroupManager) GetInstance(name string) (ManagedInstance, error) {
	m.mtx.Lock()
	defer m.mtx.Unlock()

	group, ok := m.groupLookup[name]
	if !ok {
		return nil, fmt.Errorf("instance %s does not exist", name)
	}

	inst, err := m.inner.GetInstance(group)
	if err != nil {
		return nil, fmt.Errorf("failed to get instance for %s: %w", name, err)
	}
	return inst, nil
}

// ListInstances returns all currently grouped managed instances. The key
// will be the group's hash of shared settings.
func (m *GroupManager) ListInstances() map[string]ManagedInstance {
	return m.inner.ListInstances()
}

// ListConfigs returns the UNGROUPED instance configs with their original
// settings. To see the grouped instances, call ListInstances instead.
func (m *GroupManager) ListConfigs() map[string]Config {
	m.mtx.Lock()
	defer m.mtx.Unlock()

	cfgs := make(map[string]Config)
	for _, groupedConfigs := range m.groups {
		for _, cfg := range groupedConfigs {
			cfgs[cfg.Name] = cfg
		}
	}
	return cfgs
}

// ApplyConfig will determine the group of the Config before applying it to
// the group. If no group exists, one will be created. If a group already
// exists, the group will have its settings merged with the Config and
// will be updated.
func (m *GroupManager) ApplyConfig(c Config) error {
	m.mtx.Lock()
	defer m.mtx.Unlock()
	return m.applyConfig(c)
}

func (m *GroupManager) applyConfig(c Config) (err error) {
	groupName, err := hashConfig(c)
	if err != nil {
		return fmt.Errorf("failed to get group name for config %s: %w", c.Name, err)
	}

	grouped := m.groups[groupName]
	if grouped == nil {
		grouped = make(groupedConfigs)
	} else {
		grouped = grouped.Copy()
	}

	// Add the config to the group. If the config already exists within this
	// group, it'll be overwritten.
	grouped[c.Name] = c
	mergedConfig, err := groupConfigs(groupName, grouped)
	if err != nil {
		err = fmt.Errorf("failed to group configs for %s: %w", c.Name, err)
		return
	}

	// If this config already exists in another group, we have to delete it.
	// If we can't delete it from the old group, we also can't apply it.
	if oldGroup, ok := m.groupLookup[c.Name]; ok && oldGroup != groupName {
		// There's a few cases here where if something fails, it's safer to crash
		// out and restart the Agent from scratch than it would be to continue as
		// normal. The panics here are for truly exceptional cases, otherwise if
		// something is recoverable, we'll return an error like normal.

		// If we can't find the old config, something got messed up when applying
		// the config. But it also means that we're not going to be able to restore
		// the config if something fails. Preemptively we should panic, since the
		// internal state has gotten messed up and can't be fixed.
		oldConfig, ok := m.groups[oldGroup][c.Name]
		if !ok {
			panic("failed to properly move config to new group. THIS IS A BUG!")
		}

		err = m.deleteConfig(c.Name)
		if err != nil {
			err = fmt.Errorf("cannot apply config %s because deleting it from the old group failed: %w", c.Name, err)
			return
		}

		// Now that the config is deleted, we need to restore it in case applying
		// the new one happens to fail.
		defer func() {
			if err == nil {
				return
			}

			// If restoring a config fails, we've left the Agent in a really bad
			// state: the new config can't be applied and the old config can't be
			// brought back. Just crash and let the Agent start fresh.
			//
			// Restoring the config _shouldn't_ fail here since applies only fail
			// if the config is invalid. Since the config was running before, it
			// should already be valid. If it does happen to fail, though, the
			// internal state is left corrupted since we've completely lost a
			// config.
			restoreError := m.applyConfig(oldConfig)
			if restoreError != nil {
				panic(fmt.Sprintf("failed to properly restore config. THIS IS A BUG! error: %s", restoreError))
			}
		}()
	}

	err = m.inner.ApplyConfig(mergedConfig)
	if err != nil {
		err = fmt.Errorf("failed to apply grouped configs for config %s: %w", c.Name, err)
		return
	}

	// If the inner apply succeeded, we can update our group and the lookup.
	m.groups[groupName] = grouped
	m.groupLookup[c.Name] = groupName
	return
}

// DeleteConfig will remove a Config from its associated group. If there are
// no more Configs within that group after this Config is deleted, the managed
// instance will be stopped. Otherwise, the managed instance will be updated
// with the new grouped Config that doesn't include the removed one.
func (m *GroupManager) DeleteConfig(name string) error {
	m.mtx.Lock()
	defer m.mtx.Unlock()
	return m.deleteConfig(name)
}

func (m *GroupManager) deleteConfig(name string) error {
	groupName, ok := m.groupLookup[name]
	if !ok {
		return fmt.Errorf("config does not exist")
	}

	// Grab a copy of the stored group and delete our entry. We can
	// persist it after we successfully remove the config.
	group := m.groups[groupName].Copy()
	delete(group, name)

	if len(group) == 0 {
		// We deleted the last remaining config in that group; we can delete it in
		// its entirety now.
		if err := m.inner.DeleteConfig(groupName); err != nil {
			return fmt.Errorf("failed to delete empty group %s after removing config %s: %w", groupName, name, err)
		}
	} else {
		// We deleted the config but there's still more in the group; apply the new
		// group that holds the remainder of the configs (minus the one we just
		// deleted).
		mergedConfig, err := groupConfigs(groupName, group)
		if err != nil {
			return fmt.Errorf("failed to regroup configs without %s: %w", name, err)
		}

		err = m.inner.ApplyConfig(mergedConfig)
		if err != nil {
			return fmt.Errorf("failed to apply new group without %s: %w", name, err)
		}
	}

	// Update the stored group and remove the entry from the lookup table.
	if len(group) == 0 {
		delete(m.groups, groupName)
	} else {
		m.groups[groupName] = group
	}

	delete(m.groupLookup, name)
	return nil
}

// Stop stops the Manager and all of its managed instances.
func (m *GroupManager) Stop() {
	m.mtx.Lock()
	defer m.mtx.Unlock()

	m.inner.Stop()
	m.groupLookup = make(map[string]string)
	m.groups = make(map[string]groupedConfigs)
}

// hashConfig determines the hash of a Config used for grouping. It ignores
// the name and scrape_configs and also orders remote_writes by name prior to
// hashing.
func hashConfig(c Config) (string, error) {
	// We need a deep copy since we're going to mutate the remote_write
	// pointers.
	groupable, err := c.Clone()
	if err != nil {
		return "", err
	}

	// Ignore name and scrape configs when hashing
	groupable.Name = ""
	groupable.ScrapeConfigs = nil

	// Assign names to remote_write configs if they're not present already.
	// This is also done in AssignDefaults but is duplicated here for the sake
	// of simplifying responsibility of GroupManager.
	for _, cfg := range groupable.RemoteWrite {
		if cfg != nil {
			// We don't care if the names are different, just that the other settings
			// are the same. Blank out the name here before hashing the remote
			// write config.
			cfg.Name = ""

			hash, err := getHash(cfg)
			if err != nil {
				return "", err
			}
			cfg.Name = hash[:6]
		}
	}

	// Now sort remote_writes by name and nil-ness.
	sort.Slice(groupable.RemoteWrite, func(i, j int) bool {
		switch {
		case groupable.RemoteWrite[i] == nil:
			return true
		case groupable.RemoteWrite[j] == nil:
			return false
		default:
			return groupable.RemoteWrite[i].Name < groupable.RemoteWrite[j].Name
		}
	})

	bb, err := MarshalConfig(&groupable, false)
	if err != nil {
		return "", err
	}
	hash := md5.Sum(bb)
	return hex.EncodeToString(hash[:]), nil
}

// groupConfig creates a grouped Config where all fields are copied from
// the first config except for scrape_configs, which are appended together.
func groupConfigs(groupName string, grouped groupedConfigs) (Config, error) {
	if len(grouped) == 0 {
		return Config{}, fmt.Errorf("no configs")
	}

	// Move the map into a slice and sort it by name so this function
	// consistently does the same thing.
	cfgs := make([]Config, 0, len(grouped))
	for _, cfg := range grouped {
		cfgs = append(cfgs, cfg)
	}
	sort.Slice(cfgs, func(i, j int) bool { return cfgs[i].Name < cfgs[j].Name })

	combined, err := cfgs[0].Clone()
	if err != nil {
		return Config{}, err
	}
	combined.Name = groupName
	combined.ScrapeConfigs = []*config.ScrapeConfig{}

	// Assign all remote_write configs in the group a consistent set of remote_names.
	// If the grouped configs are coming from the scraping service, defaults will have
	// been applied and the remote names will be prefixed with the old instance config name.
	for _, rwc := range combined.RemoteWrite {
		// Blank out the existing name before getting the hash so it is doesn't take into
		// account any existing name.
		rwc.Name = ""

		hash, err := getHash(rwc)
		if err != nil {
			return Config{}, err
		}

		rwc.Name = groupName[:6] + "-" + hash[:6]
	}

	// Combine all the scrape configs. It's possible that two different ungrouped
	// configs had a matching job name, but this will be detected and rejected
	// (as it should be) when the underlying Manager eventually validates the
	// combined config.
	//
	// TODO(rfratto): should we prepend job names with the name of the original
	// config? (e.g., job_name = "config_name/job_name").
	for _, cfg := range cfgs {
		combined.ScrapeConfigs = append(combined.ScrapeConfigs, cfg.ScrapeConfigs...)
	}

	return combined, nil
}

'''
'''--- pkg/metrics/instance/group_manager_test.go ---
package instance

import (
	"fmt"
	"strings"
	"testing"

	"github.com/stretchr/testify/require"
)

func TestGroupManager_ListInstances_Configs(t *testing.T) {
	gm := NewGroupManager(newFakeManager())

	// Create two configs in the same group and one in another
	// group.
	configs := []string{
		`
name: configA
scrape_configs: []
remote_write: []`,
		`
name: configB
scrape_configs: []
remote_write: []`,
		`
name: configC
scrape_configs: []
remote_write:
- url: http://localhost:9090`,
	}

	for _, cfg := range configs {
		c := testUnmarshalConfig(t, cfg)
		err := gm.ApplyConfig(c)
		require.NoError(t, err)
	}

	// ListInstances should return our grouped instances
	insts := gm.ListInstances()
	require.Equal(t, 2, len(insts))

	// ...but ListConfigs should return the ungrouped configs.
	confs := gm.ListConfigs()
	require.Equal(t, 3, len(confs))
	require.Containsf(t, confs, "configA", "configA not in confs")
	require.Containsf(t, confs, "configB", "configB not in confs")
	require.Containsf(t, confs, "configC", "configC not in confs")
}

func testUnmarshalConfig(t *testing.T, cfg string) Config {
	c, err := UnmarshalConfig(strings.NewReader(cfg))
	require.NoError(t, err)
	return *c
}

func TestGroupManager_ApplyConfig(t *testing.T) {
	t.Run("combining configs", func(t *testing.T) {
		inner := newFakeManager()
		gm := NewGroupManager(inner)
		err := gm.ApplyConfig(testUnmarshalConfig(t, `
name: configA
scrape_configs: []
remote_write: []
`))
		require.NoError(t, err)

		err = gm.ApplyConfig(testUnmarshalConfig(t, `
name: configB
scrape_configs:
- job_name: test_job
  static_configs:
    - targets: [127.0.0.1:12345]
remote_write: []
`))
		require.NoError(t, err)

		require.Equal(t, 1, len(gm.groups))
		require.Equal(t, 2, len(gm.groupLookup))

		// Check the underlying grouped config and make sure it was updated.
		expect := testUnmarshalConfig(t, fmt.Sprintf(`
name: %s
scrape_configs:
- job_name: test_job
  static_configs:
    - targets: [127.0.0.1:12345]
remote_write: []
`, gm.groupLookup["configA"]))

		innerConfigs := inner.ListConfigs()
		require.Equal(t, 1, len(innerConfigs))
		require.Equal(t, expect, innerConfigs[gm.groupLookup["configA"]])
	})

	t.Run("updating existing config within group", func(t *testing.T) {
		inner := newFakeManager()
		gm := NewGroupManager(inner)
		err := gm.ApplyConfig(testUnmarshalConfig(t, `
name: configA
scrape_configs: []
remote_write: []
`))
		require.NoError(t, err)
		require.Equal(t, 1, len(gm.groups))
		require.Equal(t, 1, len(gm.groupLookup))

		err = gm.ApplyConfig(testUnmarshalConfig(t, `
name: configA
scrape_configs:
- job_name: test_job
  static_configs:
    - targets: [127.0.0.1:12345]
remote_write: []
`))
		require.NoError(t, err)
		require.Equal(t, 1, len(gm.groups))
		require.Equal(t, 1, len(gm.groupLookup))

		// Check the underlying grouped config and make sure it was updated.
		expect := testUnmarshalConfig(t, fmt.Sprintf(`
name: %s
scrape_configs:
- job_name: test_job
  static_configs:
    - targets: [127.0.0.1:12345]
remote_write: []
`, gm.groupLookup["configA"]))
		actual := inner.ListConfigs()[gm.groupLookup["configA"]]
		require.Equal(t, expect, actual)
	})

	t.Run("updating existing config to new group", func(t *testing.T) {
		inner := newFakeManager()
		gm := NewGroupManager(inner)
		err := gm.ApplyConfig(testUnmarshalConfig(t, `
name: configA
scrape_configs: []
remote_write: []
`))
		require.NoError(t, err)
		require.Equal(t, 1, len(gm.groups))
		require.Equal(t, 1, len(gm.groupLookup))
		oldGroup := gm.groupLookup["configA"]

		// Reapply the config but give it a setting change that would
		// force it into a new group. We should still have only one
		// group and only one entry in the group lookup table.
		err = gm.ApplyConfig(testUnmarshalConfig(t, `
name: configA
host_filter: true
scrape_configs: []
remote_write: []
`))
		require.NoError(t, err)
		require.Equal(t, 1, len(gm.groups))
		require.Equal(t, 1, len(gm.groupLookup))
		newGroup := gm.groupLookup["configA"]

		// Check the underlying grouped config and make sure it was updated.
		expect := testUnmarshalConfig(t, fmt.Sprintf(`
name: %s
host_filter: true
scrape_configs: []
remote_write: []
`, gm.groupLookup["configA"]))
		actual := inner.ListConfigs()[newGroup]
		require.Equal(t, expect, actual)

		// The old underlying ngroup should be gone.
		require.NotContains(t, inner.ListConfigs(), oldGroup)
		require.Equal(t, 1, len(inner.ListConfigs()))
	})
}

func TestGroupManager_ApplyConfig_RemoteWriteName(t *testing.T) {
	inner := newFakeManager()
	gm := NewGroupManager(inner)
	err := gm.ApplyConfig(testUnmarshalConfig(t, `
name: configA
scrape_configs: []
remote_write:
- name: rw-cfg-a
  url: http://localhost:9009/api/prom/push
`))
	require.NoError(t, err)

	require.Equal(t, 1, len(gm.groups))
	require.Equal(t, 1, len(gm.groupLookup))

	// Check the underlying grouped config and make sure the group_name
	// didn't get copied from the remote_name of A.
	innerConfigs := inner.ListConfigs()
	require.Equal(t, 1, len(innerConfigs))

	cfg := innerConfigs[gm.groupLookup["configA"]]
	require.NotEqual(t, "rw-cfg-a", cfg.RemoteWrite[0].Name)
}

func TestGroupManager_DeleteConfig(t *testing.T) {
	t.Run("partial delete", func(t *testing.T) {
		inner := newFakeManager()
		gm := NewGroupManager(inner)

		// Apply two configs in the same group and then delete one. The group
		// should still be active with the one config inside of it.
		err := gm.ApplyConfig(testUnmarshalConfig(t, `
name: configA
scrape_configs:
- job_name: test_job
  static_configs:
    - targets: [127.0.0.1:12345]
remote_write: []
`))
		require.NoError(t, err)

		err = gm.ApplyConfig(testUnmarshalConfig(t, `
name: configB
scrape_configs:
- job_name: test_job2
  static_configs:
    - targets: [127.0.0.1:12345]
remote_write: []
`))
		require.NoError(t, err)

		err = gm.DeleteConfig("configA")
		require.NoError(t, err)

		expect := testUnmarshalConfig(t, fmt.Sprintf(`
name: %s
scrape_configs:
- job_name: test_job2
  static_configs:
    - targets: [127.0.0.1:12345]
remote_write: []`, gm.groupLookup["configB"]))
		actual := inner.ListConfigs()[gm.groupLookup["configB"]]
		require.Equal(t, expect, actual)
		require.Equal(t, 1, len(gm.groups))
		require.Equal(t, 1, len(gm.groupLookup))
	})

	t.Run("full delete", func(t *testing.T) {
		inner := newFakeManager()
		gm := NewGroupManager(inner)

		// Apply a single config but delete the entire group.
		err := gm.ApplyConfig(testUnmarshalConfig(t, `
name: configA
scrape_configs:
- job_name: test_job
  static_configs:
    - targets: [127.0.0.1:12345]
remote_write: []
`))
		require.NoError(t, err)

		err = gm.DeleteConfig("configA")
		require.NoError(t, err)
		require.Equal(t, 0, len(inner.ListConfigs()))
		require.Equal(t, 0, len(inner.ListInstances()))
		require.Equal(t, 0, len(gm.groups))
		require.Equal(t, 0, len(gm.groupLookup))
	})
}

func newFakeManager() Manager {
	instances := make(map[string]ManagedInstance)
	configs := make(map[string]Config)

	return &MockManager{
		ListInstancesFunc: func() map[string]ManagedInstance {
			return instances
		},
		ListConfigsFunc: func() map[string]Config {
			return configs
		},
		ApplyConfigFunc: func(c Config) error {
			instances[c.Name] = &mockInstance{}
			configs[c.Name] = c
			return nil
		},
		DeleteConfigFunc: func(name string) error {
			delete(instances, name)
			delete(configs, name)
			return nil
		},
		StopFunc: func() {},
	}
}

func Test_hashConfig(t *testing.T) {
	t.Run("name and scrape configs are ignored", func(t *testing.T) {
		configAText := `
name: configA
scrape_configs: []
remote_write: []`

		configBText := `
name: configB
scrape_configs:
- job_name: test_job
  static_configs:
    - targets: [127.0.0.1:12345]
remote_write: []`

		hashA, hashB := getHashesFromConfigs(t, configAText, configBText)
		require.Equal(t, hashA, hashB)
	})

	t.Run("remote_writes are unordered", func(t *testing.T) {
		configAText := `
name: configA
scrape_configs: []
remote_write:
- url: http://localhost:9009/api/prom/push1
- url: http://localhost:9009/api/prom/push2`

		configBText := `
name: configB
scrape_configs: []
remote_write:
- url: http://localhost:9009/api/prom/push2
- url: http://localhost:9009/api/prom/push1`

		hashA, hashB := getHashesFromConfigs(t, configAText, configBText)
		require.Equal(t, hashA, hashB)
	})

	t.Run("remote_writes must match", func(t *testing.T) {
		configAText := `
name: configA
scrape_configs: []
remote_write:
- url: http://localhost:9009/api/prom/push1
- url: http://localhost:9009/api/prom/push2`

		configBText := `
name: configB
scrape_configs: []
remote_write:
- url: http://localhost:9009/api/prom/push1
- url: http://localhost:9009/api/prom/push1`

		hashA, hashB := getHashesFromConfigs(t, configAText, configBText)
		require.NotEqual(t, hashA, hashB)
	})

	t.Run("other fields must match", func(t *testing.T) {
		configAText := `
name: configA
host_filter: true
scrape_configs: []
remote_write: []`

		configBText := `
name: configB
host_filter: false
scrape_configs: []
remote_write: []`

		hashA, hashB := getHashesFromConfigs(t, configAText, configBText)
		require.NotEqual(t, hashA, hashB)
	})
}

func getHashesFromConfigs(t *testing.T, configAText, configBText string) (string, string) {
	configA := testUnmarshalConfig(t, configAText)
	configB := testUnmarshalConfig(t, configBText)

	hashA, err := hashConfig(configA)
	require.NoError(t, err)

	hashB, err := hashConfig(configB)
	require.NoError(t, err)

	return hashA, hashB
}

func Test_groupConfigs(t *testing.T) {
	configAText := `
name: configA
scrape_configs:
- job_name: test_job
  static_configs:
    - targets: [127.0.0.1:12345]
remote_write:
- url: http://localhost:9009/api/prom/push1
- url: http://localhost:9009/api/prom/push2`

	configBText := `
name: configB
scrape_configs:
- job_name: test_job2
  static_configs:
    - targets: [127.0.0.1:12345]
remote_write:
- url: http://localhost:9009/api/prom/push2
- url: http://localhost:9009/api/prom/push1`

	configA := testUnmarshalConfig(t, configAText)
	configB := testUnmarshalConfig(t, configBText)

	groupName, err := hashConfig(configA)
	require.NoError(t, err)

	expectText := fmt.Sprintf(`
name: %s
scrape_configs:
- job_name: test_job
  static_configs:
    - targets: [127.0.0.1:12345]
- job_name: test_job2
  static_configs:
    - targets: [127.0.0.1:12345]
remote_write:
- url: http://localhost:9009/api/prom/push1
- url: http://localhost:9009/api/prom/push2`, groupName)

	expect, err := UnmarshalConfig(strings.NewReader(expectText))
	require.NoError(t, err)

	// Generate expected remote_write names
	for _, rwConfig := range expect.RemoteWrite {
		hash, err := getHash(rwConfig)
		require.NoError(t, err)
		rwConfig.Name = groupName[:6] + "-" + hash[:6]
	}

	group := groupedConfigs{
		"configA": configA,
		"configB": configB,
	}
	actual, err := groupConfigs(groupName, group)
	require.NoError(t, err)
	require.Equal(t, *expect, actual)

	// Consistency check: groupedConfigs is a map and we want to always have
	// groupConfigs return the same thing regardless of how the map
	// is iterated over. Run through groupConfigs a bunch of times and
	// make sure it always returns the same thing.
	for i := 0; i < 100; i++ {
		actual, err = groupConfigs(groupName, group)
		require.NoError(t, err)
		require.Equal(t, *expect, actual)
	}
}

'''
'''--- pkg/metrics/instance/host_filter.go ---
package instance

import (
	"context"
	"fmt"
	"net"
	"sync"

	"github.com/prometheus/common/model"
	"github.com/prometheus/prometheus/config"
	"github.com/prometheus/prometheus/discovery/kubernetes"
	"github.com/prometheus/prometheus/discovery/targetgroup"
	"github.com/prometheus/prometheus/model/labels"
	"github.com/prometheus/prometheus/model/relabel"
)

// HostFilterLabelMatchers are the set of labels that will be used to match
// against an incoming target.
var HostFilterLabelMatchers = []string{
	// Consul
	"__meta_consul_node",

	// Dockerswarm
	"__meta_dockerswarm_node_id",
	"__meta_dockerswarm_node_hostname",
	"__meta_dockerswarm_node_address",

	// Kubernetes node labels. Labels for `role: service` are omitted as
	// service targets have labels merged with discovered pods.
	"__meta_kubernetes_pod_node_name",
	"__meta_kubernetes_node_name",

	// Generic (applied by host_filter_relabel_configs)
	"__host__",
}

// DiscoveredGroups is a set of groups found via service discovery.
type DiscoveredGroups = map[string][]*targetgroup.Group

// GroupChannel is a channel that provides discovered target groups.
type GroupChannel = <-chan DiscoveredGroups

// HostFilter acts as a MITM between the discovery manager and the
// scrape manager, filtering out discovered targets that are not
// running on the same node as the agent itself.
type HostFilter struct {
	ctx    context.Context
	cancel context.CancelFunc

	host string

	inputCh  GroupChannel
	outputCh chan map[string][]*targetgroup.Group

	relabelMut sync.Mutex
	relabels   []*relabel.Config
}

// NewHostFilter creates a new HostFilter.
func NewHostFilter(host string, relabels []*relabel.Config) *HostFilter {
	ctx, cancel := context.WithCancel(context.Background())
	f := &HostFilter{
		ctx:    ctx,
		cancel: cancel,

		host:     host,
		relabels: relabels,

		outputCh: make(chan map[string][]*targetgroup.Group),
	}
	return f
}

// PatchSD patches services discoveries to optimize performance for host
// filtering. The discovered targets will be pruned to as close to the set
// that HostFilter will output as possible.
func (f *HostFilter) PatchSD(scrapes []*config.ScrapeConfig) {
	for _, sc := range scrapes {
		for _, d := range sc.ServiceDiscoveryConfigs {
			switch d := d.(type) {
			case *kubernetes.SDConfig:
				if d.Role == kubernetes.RolePod {
					d.Selectors = []kubernetes.SelectorConfig{{
						Role:  kubernetes.RolePod,
						Field: fmt.Sprintf("spec.nodeName=%s", f.host),
					}}
				}
			}
		}
	}
}

// SetRelabels updates the relabeling rules used by the HostFilter.
func (f *HostFilter) SetRelabels(relabels []*relabel.Config) {
	f.relabelMut.Lock()
	defer f.relabelMut.Unlock()
	f.relabels = relabels
}

// Run starts the HostFilter. It only exits when the HostFilter is stopped.
// Run will continually read from syncCh and filter groups discovered down to
// targets that are colocated on the same node as the one the HostFilter is
// running in.
func (f *HostFilter) Run(syncCh GroupChannel) {
	f.inputCh = syncCh

	for {
		select {
		case <-f.ctx.Done():
			return
		case data := <-f.inputCh:
			f.relabelMut.Lock()
			relabels := f.relabels
			f.relabelMut.Unlock()

			f.outputCh <- FilterGroups(data, f.host, relabels)
		}
	}
}

// Stop stops the host filter from processing more target updates.
func (f *HostFilter) Stop() {
	f.cancel()
}

// SyncCh returns a read only channel used by all the clients to receive
// target updates.
func (f *HostFilter) SyncCh() GroupChannel {
	return f.outputCh
}

// FilterGroups takes a set of DiscoveredGroups as input and filters out
// any Target that is not running on the host machine provided by host.
//
// This is done by looking at HostFilterLabelMatchers and __address__.
//
// If the discovered address is localhost or 127.0.0.1, the group is never
// filtered out.
func FilterGroups(in DiscoveredGroups, host string, configs []*relabel.Config) DiscoveredGroups {
	out := make(DiscoveredGroups, len(in))

	for name, groups := range in {
		groupList := make([]*targetgroup.Group, 0, len(groups))

		for _, group := range groups {
			newGroup := &targetgroup.Group{
				Targets: make([]model.LabelSet, 0, len(group.Targets)),
				Labels:  group.Labels,
				Source:  group.Source,
			}

			for _, target := range group.Targets {
				allLabels := mergeSets(target, group.Labels)
				processedLabels := relabel.Process(toLabelSlice(allLabels), configs...)

				if !shouldFilterTarget(processedLabels, host) {
					newGroup.Targets = append(newGroup.Targets, target)
				}
			}

			groupList = append(groupList, newGroup)
		}

		out[name] = groupList
	}

	return out
}

// shouldFilterTarget returns true when the target labels (combined with the set of common
// labels) should be filtered out by FilterGroups.
func shouldFilterTarget(lbls labels.Labels, host string) bool {
	shouldFilterTargetByLabelValue := func(labelValue string) bool {
		if addr, _, err := net.SplitHostPort(labelValue); err == nil {
			labelValue = addr
		}

		// Special case: always allow localhost/127.0.0.1
		if labelValue == "localhost" || labelValue == "127.0.0.1" {
			return false
		}

		return labelValue != host
	}

	lset := labels.New(lbls...)
	addressLabel := lset.Get(model.AddressLabel)
	if addressLabel == "" {
		// No address label. This is invalid and will generate an error by the scrape
		// manager, so we'll pass it on for now.
		return false
	}

	// If the __address__ label matches, we can quit early.
	if !shouldFilterTargetByLabelValue(addressLabel) {
		return false
	}

	// Fall back to checking metalabels as long as their values are nonempty.
	for _, check := range HostFilterLabelMatchers {
		// If any of the checked labels match for not being filtered out, we can
		// return before checking any of the other matchers.
		if addr := lset.Get(check); addr != "" && !shouldFilterTargetByLabelValue(addr) {
			return false
		}
	}

	// Nothing matches, filter it out.
	return true
}

// mergeSets merges the sets of labels together. Earlier sets take priority for label names.
func mergeSets(sets ...model.LabelSet) model.LabelSet {
	sz := 0
	for _, set := range sets {
		sz += len(set)
	}
	result := make(model.LabelSet, sz)

	for _, set := range sets {
		for labelName, labelValue := range set {
			if _, exist := result[labelName]; exist {
				continue
			}
			result[labelName] = labelValue
		}
	}

	return result
}

func toLabelSlice(set model.LabelSet) labels.Labels {
	slice := make(labels.Labels, 0, len(set))
	for name, value := range set {
		slice = append(slice, labels.Label{Name: string(name), Value: string(value)})
	}
	return slice
}

'''
'''--- pkg/metrics/instance/host_filter_test.go ---
package instance

import (
	"testing"

	"github.com/grafana/agent/pkg/util"
	"github.com/prometheus/common/model"
	"github.com/prometheus/prometheus/config"
	"github.com/prometheus/prometheus/discovery/targetgroup"
	"github.com/prometheus/prometheus/model/relabel"
	"github.com/stretchr/testify/require"
	"gopkg.in/yaml.v3"
)

func makeGroup(labels []model.LabelSet) *targetgroup.Group {
	return &targetgroup.Group{
		Targets: labels,
		Labels:  model.LabelSet{},
	}
}

func TestFilterGroups(t *testing.T) {
	tt := []struct {
		name         string
		labelHost    string
		inputHost    string
		shouldRemove bool
	}{
		{
			name:         "complete match",
			labelHost:    "myhost",
			inputHost:    "myhost",
			shouldRemove: false,
		},
		{
			name:         "mismatch",
			labelHost:    "notmyhost",
			inputHost:    "myhost",
			shouldRemove: true,
		},
		{
			name:         "match with port",
			labelHost:    "myhost:12345",
			inputHost:    "myhost",
			shouldRemove: false,
		},
		{
			name:         "mismatch with port",
			labelHost:    "notmyhost:12345",
			inputHost:    "myhost",
			shouldRemove: true,
		},
	}

	// Sets of labels we want to test against.
	labels := []model.LabelName{
		model.AddressLabel,
		model.LabelName("__meta_consul_node"),
		model.LabelName("__meta_dockerswarm_node_id"),
		model.LabelName("__meta_dockerswarm_node_hostname"),
		model.LabelName("__meta_dockerswarm_node_address"),
		model.LabelName("__meta_kubernetes_pod_node_name"),
		model.LabelName("__meta_kubernetes_node_name"),
		model.LabelName("__host__"),
	}

	for _, tc := range tt {
		t.Run(tc.name, func(t *testing.T) {
			for _, label := range labels {
				t.Run(string(label), func(t *testing.T) {
					lset := model.LabelSet{
						label: model.LabelValue(tc.labelHost),
					}

					// Special case: if label is not model.AddressLabel, we need to give
					// it a fake value. model.AddressLabel is always expected to be present and
					// is considered an error if it isn't.
					if label != model.AddressLabel {
						lset[model.AddressLabel] = "fake"
					}

					group := makeGroup([]model.LabelSet{lset})

					groups := DiscoveredGroups{"test": []*targetgroup.Group{group}}
					result := FilterGroups(groups, tc.inputHost, nil)

					require.NotNil(t, result["test"])
					if tc.shouldRemove {
						require.NotEqual(t, len(result["test"][0].Targets), len(groups["test"][0].Targets))
					} else {
						require.Equal(t, len(result["test"][0].Targets), len(groups["test"][0].Targets))
					}
				})
			}
		})
	}
}

func TestFilterGroups_Relabel(t *testing.T) {
	tt := []struct {
		name         string
		labelHost    string
		inputHost    string
		shouldRemove bool
	}{
		{
			name:         "complete match",
			labelHost:    "myhost",
			inputHost:    "myhost",
			shouldRemove: false,
		},
		{
			name:         "mismatch",
			labelHost:    "notmyhost",
			inputHost:    "myhost",
			shouldRemove: true,
		},
		{
			name:         "match with port",
			labelHost:    "myhost:12345",
			inputHost:    "myhost",
			shouldRemove: false,
		},
		{
			name:         "mismatch with port",
			labelHost:    "notmyhost:12345",
			inputHost:    "myhost",
			shouldRemove: true,
		},
	}

	relabelConfig := []*relabel.Config{{
		SourceLabels: model.LabelNames{"__internal_label"},
		Action:       relabel.Replace,
		Separator:    ";",
		Regex:        relabel.MustNewRegexp("(.*)"),
		Replacement:  "$1",
		TargetLabel:  "__host__",
	}}

	for _, tc := range tt {
		t.Run(tc.name, func(t *testing.T) {
			lset := model.LabelSet{
				model.AddressLabel: "fake_target",
				"__internal_label": model.LabelValue(tc.labelHost),
			}

			group := makeGroup([]model.LabelSet{lset})

			groups := DiscoveredGroups{"test": []*targetgroup.Group{group}}
			result := FilterGroups(groups, tc.inputHost, relabelConfig)

			require.NotNil(t, result["test"])
			if tc.shouldRemove {
				require.NotEqual(t, len(result["test"][0].Targets), len(groups["test"][0].Targets))
			} else {
				require.Equal(t, len(result["test"][0].Targets), len(groups["test"][0].Targets))
			}
		})
	}
}

func TestHostFilter_PatchSD(t *testing.T) {
	rawInput := util.Untab(`
- job_name: default
  kubernetes_sd_configs:
	  - role: service
	  - role: pod`)

	expect := util.Untab(`
- job_name: default
	honor_timestamps: true
	metrics_path: /metrics
	scheme: http
	follow_redirects: true
	enable_http2: true
	kubernetes_sd_configs:
		- role: service
		  kubeconfig_file: ""
		  follow_redirects: true
		  enable_http2: true
		- role: pod
			follow_redirects: true
			enable_http2: true
			kubeconfig_file: ""
			selectors:
			- role: pod
			  field: spec.nodeName=myhost
	`)

	var input []*config.ScrapeConfig
	err := yaml.Unmarshal([]byte(rawInput), &input)
	require.NoError(t, err)

	NewHostFilter("myhost", nil).PatchSD(input)

	output, err := yaml.Marshal(input)
	require.NoError(t, err)
	require.YAMLEq(t, expect, string(output))
}

'''
'''--- pkg/metrics/instance/instance.go ---
// Package instance provides a mini Prometheus scraper and remote_writer.
package instance

import (
	"bytes"
	"context"
	"crypto/md5"
	"encoding/hex"
	"encoding/json"
	"errors"
	"fmt"
	"math"
	"os"
	"path/filepath"
	"sync"
	"time"

	"github.com/go-kit/log"
	"github.com/go-kit/log/level"
	"github.com/grafana/agent/pkg/build"
	"github.com/grafana/agent/pkg/metrics/wal"
	"github.com/grafana/agent/pkg/util"
	"github.com/oklog/run"
	"github.com/prometheus/client_golang/prometheus"
	config_util "github.com/prometheus/common/config"
	"github.com/prometheus/prometheus/config"
	"github.com/prometheus/prometheus/discovery"
	"github.com/prometheus/prometheus/model/relabel"
	"github.com/prometheus/prometheus/model/timestamp"
	"github.com/prometheus/prometheus/scrape"
	"github.com/prometheus/prometheus/storage"
	"github.com/prometheus/prometheus/storage/remote"
	"go.uber.org/atomic"
	"gopkg.in/yaml.v2"
)

func init() {
	remote.UserAgent = fmt.Sprintf("GrafanaAgent/%s", build.Version)
	scrape.UserAgent = fmt.Sprintf("GrafanaAgent/%s", build.Version)

	// default remote_write send_exemplars to true
	config.DefaultRemoteWriteConfig.SendExemplars = true
}

// Default configuration values
var (
	DefaultConfig = Config{
		HostFilter:           false,
		WALTruncateFrequency: 60 * time.Minute,
		MinWALTime:           5 * time.Minute,
		MaxWALTime:           4 * time.Hour,
		RemoteFlushDeadline:  1 * time.Minute,
		WriteStaleOnShutdown: false,
		global:               DefaultGlobalConfig,
	}
)

// Config is a specific agent that runs within the overall Prometheus
// agent. It has its own set of scrape_configs and remote_write rules.
type Config struct {
	Name                     string                      `yaml:"name,omitempty"`
	HostFilter               bool                        `yaml:"host_filter,omitempty"`
	HostFilterRelabelConfigs []*relabel.Config           `yaml:"host_filter_relabel_configs,omitempty"`
	ScrapeConfigs            []*config.ScrapeConfig      `yaml:"scrape_configs,omitempty"`
	RemoteWrite              []*config.RemoteWriteConfig `yaml:"remote_write,omitempty"`

	// How frequently the WAL should be truncated.
	WALTruncateFrequency time.Duration `yaml:"wal_truncate_frequency,omitempty"`

	// Minimum and maximum time series should exist in the WAL for.
	MinWALTime time.Duration `yaml:"min_wal_time,omitempty"`
	MaxWALTime time.Duration `yaml:"max_wal_time,omitempty"`

	RemoteFlushDeadline  time.Duration `yaml:"remote_flush_deadline,omitempty"`
	WriteStaleOnShutdown bool          `yaml:"write_stale_on_shutdown,omitempty"`

	global GlobalConfig `yaml:"-"`
}

// UnmarshalYAML implements yaml.Unmarshaler.
func (c *Config) UnmarshalYAML(unmarshal func(interface{}) error) error {
	*c = DefaultConfig

	type plain Config
	return unmarshal((*plain)(c))
}

// MarshalYAML implements yaml.Marshaler.
func (c Config) MarshalYAML() (interface{}, error) {
	// We want users to be able to marshal instance.Configs directly without
	// *needing* to call instance.MarshalConfig, so we call it internally
	// here and return a map.
	bb, err := MarshalConfig(&c, true)
	if err != nil {
		return nil, err
	}

	// Use a yaml.MapSlice rather than a map[string]interface{} so
	// order of keys is retained compared to just calling MarshalConfig.
	var m yaml.MapSlice
	if err := yaml.Unmarshal(bb, &m); err != nil {
		return nil, err
	}
	return m, nil
}

// ApplyDefaults applies default configurations to the configuration to all
// values that have not been changed to their non-zero value. ApplyDefaults
// also validates the config.
//
// The value for global will saved.
func (c *Config) ApplyDefaults(global GlobalConfig) error {
	c.global = global

	switch {
	case c.Name == "":
		return errors.New("missing instance name")
	case c.WALTruncateFrequency <= 0:
		return errors.New("wal_truncate_frequency must be greater than 0s")
	case c.RemoteFlushDeadline <= 0:
		return errors.New("remote_flush_deadline must be greater than 0s")
	case c.MinWALTime > c.MaxWALTime:
		return errors.New("min_wal_time must be less than max_wal_time")
	}

	jobNames := map[string]struct{}{}
	for _, sc := range c.ScrapeConfigs {
		if sc == nil {
			return fmt.Errorf("empty or null scrape config section")
		}

		// First set the correct scrape interval, then check that the timeout
		// (inferred or explicit) is not greater than that.
		if sc.ScrapeInterval == 0 {
			sc.ScrapeInterval = c.global.Prometheus.ScrapeInterval
		}
		if sc.ScrapeTimeout > sc.ScrapeInterval {
			return fmt.Errorf("scrape timeout greater than scrape interval for scrape config with job name %q", sc.JobName)
		}
		if time.Duration(sc.ScrapeInterval) > c.WALTruncateFrequency {
			return fmt.Errorf("scrape interval greater than wal_truncate_frequency for scrape config with job name %q", sc.JobName)
		}
		if sc.ScrapeTimeout == 0 {
			if c.global.Prometheus.ScrapeTimeout > sc.ScrapeInterval {
				sc.ScrapeTimeout = sc.ScrapeInterval
			} else {
				sc.ScrapeTimeout = c.global.Prometheus.ScrapeTimeout
			}
		}

		if _, exists := jobNames[sc.JobName]; exists {
			return fmt.Errorf("found multiple scrape configs with job name %q", sc.JobName)
		}
		jobNames[sc.JobName] = struct{}{}
	}

	rwNames := map[string]struct{}{}

	// If the instance remote write is not filled in, then apply the prometheus write config
	if len(c.RemoteWrite) == 0 {
		c.RemoteWrite = c.global.RemoteWrite
	}
	for _, cfg := range c.RemoteWrite {
		if cfg == nil {
			return fmt.Errorf("empty or null remote write config section")
		}

		// Typically Prometheus ignores empty names here, but we need to assign a
		// unique name to the config so we can pull metrics from it when running
		// an instance.
		var generatedName bool
		if cfg.Name == "" {
			hash, err := getHash(cfg)
			if err != nil {
				return err
			}

			// We have to add the name of the instance to ensure that generated metrics
			// are unique across multiple agent instances. The remote write queues currently
			// globally register their metrics so we can't inject labels here.
			cfg.Name = c.Name + "-" + hash[:6]
			generatedName = true
		}

		if _, exists := rwNames[cfg.Name]; exists {
			if generatedName {
				return fmt.Errorf("found two identical remote_write configs")
			}
			return fmt.Errorf("found duplicate remote write configs with name %q", cfg.Name)
		}
		rwNames[cfg.Name] = struct{}{}
	}

	return nil
}

// Clone makes a deep copy of the config along with global settings.
func (c *Config) Clone() (Config, error) {
	bb, err := MarshalConfig(c, false)
	if err != nil {
		return Config{}, err
	}
	cp, err := UnmarshalConfig(bytes.NewReader(bb))
	if err != nil {
		return Config{}, err
	}
	cp.global = c.global

	// Some tests will trip up on this; the marshal/unmarshal cycle might set
	// an empty slice to nil. Set it back to an empty slice if we detect this
	// happening.
	if cp.ScrapeConfigs == nil && c.ScrapeConfigs != nil {
		cp.ScrapeConfigs = []*config.ScrapeConfig{}
	}
	if cp.RemoteWrite == nil && c.RemoteWrite != nil {
		cp.RemoteWrite = []*config.RemoteWriteConfig{}
	}

	return *cp, nil
}

type walStorageFactory func(reg prometheus.Registerer) (walStorage, error)

// Instance is an individual metrics collector and remote_writer.
type Instance struct {
	// All fields in the following block may be accessed and modified by
	// concurrently running goroutines.
	//
	// Note that all Prometheus components listed here may be nil at any
	// given time; methods reading them should take care to do nil checks.
	mut                sync.Mutex
	cfg                Config
	wal                walStorage
	discovery          *discoveryService
	readyScrapeManager *readyScrapeManager
	remoteStore        *remote.Storage
	storage            storage.Storage

	// ready is set to true after the initialization process finishes
	ready atomic.Bool

	hostFilter *HostFilter

	logger log.Logger

	reg    prometheus.Registerer
	newWal walStorageFactory
}

// New creates a new Instance with a directory for storing the WAL. The instance
// will not start until Run is called on the instance.
func New(reg prometheus.Registerer, cfg Config, walDir string, logger log.Logger) (*Instance, error) {
	logger = log.With(logger, "instance", cfg.Name)

	instWALDir := filepath.Join(walDir, cfg.Name)

	newWal := func(reg prometheus.Registerer) (walStorage, error) {
		return wal.NewStorage(logger, reg, instWALDir)
	}

	return newInstance(cfg, reg, logger, newWal)
}

func newInstance(cfg Config, reg prometheus.Registerer, logger log.Logger, newWal walStorageFactory) (*Instance, error) {
	hostname, err := Hostname()
	if err != nil {
		return nil, fmt.Errorf("failed to get hostname: %w", err)
	}

	i := &Instance{
		cfg:        cfg,
		logger:     logger,
		hostFilter: NewHostFilter(hostname, cfg.HostFilterRelabelConfigs),

		reg:    reg,
		newWal: newWal,

		readyScrapeManager: &readyScrapeManager{},
	}

	return i, nil
}

// Run starts the instance, initializing Prometheus components, and will
// continue to run until an error happens during execution or the provided
// context is cancelled.
//
// Run may be re-called after exiting, as components will be reinitialized each
// time Run is called.
func (i *Instance) Run(ctx context.Context) error {
	// i.cfg may change at any point in the middle of this method but not in a way
	// that affects any of the code below; rather than grabbing a mutex every time
	// we want to read the config, we'll simplify the access and just grab a copy
	// now.
	i.mut.Lock()
	cfg := i.cfg
	i.mut.Unlock()

	level.Debug(i.logger).Log("msg", "initializing instance", "name", cfg.Name)

	// trackingReg wraps the register for the instance to make sure that if Run
	// exits, any metrics Prometheus registers are removed and can be
	// re-registered if Run is called again.
	trackingReg := util.WrapWithUnregisterer(i.reg)
	defer trackingReg.UnregisterAll()

	if err := i.initialize(ctx, trackingReg, &cfg); err != nil {
		level.Error(i.logger).Log("msg", "failed to initialize instance", "err", err)
		return fmt.Errorf("failed to initialize instance: %w", err)
	}

	// The actors defined here are defined in the order we want them to shut down.
	// Primarily, we want to ensure that the following shutdown order is
	// maintained:
	//    1. The scrape manager stops
	//    2. WAL storage is closed
	//    3. Remote write storage is closed
	// This is done to allow the instance to write stale markers for all active
	// series.
	rg := runGroupWithContext(ctx)

	{
		// Target Discovery
		rg.Add(i.discovery.Run, i.discovery.Stop)
	}
	{
		// Truncation loop
		ctx, contextCancel := context.WithCancel(context.Background())
		defer contextCancel()
		rg.Add(
			func() error {
				i.truncateLoop(ctx, i.wal, &cfg)
				level.Info(i.logger).Log("msg", "truncation loop stopped")
				return nil
			},
			func(err error) {
				level.Info(i.logger).Log("msg", "stopping truncation loop...")
				contextCancel()
			},
		)
	}
	{
		sm, err := i.readyScrapeManager.Get()
		if err != nil {
			level.Error(i.logger).Log("msg", "failed to get scrape manager")
			return err
		}

		// Scrape manager
		rg.Add(
			func() error {
				err := sm.Run(i.discovery.SyncCh())
				level.Info(i.logger).Log("msg", "scrape manager stopped")
				return err
			},
			func(err error) {
				// The scrape manager is closed first to allow us to write staleness
				// markers without receiving new samples from scraping in the meantime.
				level.Info(i.logger).Log("msg", "stopping scrape manager...")
				sm.Stop()

				// On a graceful shutdown, write staleness markers. If something went
				// wrong, then the instance will be relaunched.
				if err == nil && cfg.WriteStaleOnShutdown {
					level.Info(i.logger).Log("msg", "writing staleness markers...")
					err := i.wal.WriteStalenessMarkers(i.getRemoteWriteTimestamp)
					if err != nil {
						level.Error(i.logger).Log("msg", "error writing staleness markers", "err", err)
					}
				}

				// Closing the storage closes both the WAL storage and remote wrte
				// storage.
				level.Info(i.logger).Log("msg", "closing storage...")
				if err := i.storage.Close(); err != nil {
					level.Error(i.logger).Log("msg", "error stopping storage", "err", err)
				}
			},
		)
	}

	level.Debug(i.logger).Log("msg", "running instance", "name", cfg.Name)
	i.ready.Store(true)
	err := rg.Run()
	if err != nil {
		level.Error(i.logger).Log("msg", "agent instance stopped with error", "err", err)
	}
	return err
}

// initialize sets up the various Prometheus components with their initial
// settings. initialize will be called each time the Instance is run. Prometheus
// components cannot be reused after they are stopped so we need to recreate them
// each run.
func (i *Instance) initialize(ctx context.Context, reg prometheus.Registerer, cfg *Config) error {
	i.mut.Lock()
	defer i.mut.Unlock()

	if cfg.HostFilter {
		i.hostFilter.PatchSD(cfg.ScrapeConfigs)
	}

	var err error

	i.wal, err = i.newWal(reg)
	if err != nil {
		return fmt.Errorf("error creating WAL: %w", err)
	}

	i.discovery, err = i.newDiscoveryManager(ctx, cfg)
	if err != nil {
		return fmt.Errorf("error creating discovery manager: %w", err)
	}

	i.readyScrapeManager = &readyScrapeManager{}

	// Setup the remote storage
	remoteLogger := log.With(i.logger, "component", "remote")
	i.remoteStore = remote.NewStorage(remoteLogger, reg, i.wal.StartTime, i.wal.Directory(), cfg.RemoteFlushDeadline, i.readyScrapeManager)
	err = i.remoteStore.ApplyConfig(&config.Config{
		GlobalConfig:       cfg.global.Prometheus,
		RemoteWriteConfigs: cfg.RemoteWrite,
	})
	if err != nil {
		return fmt.Errorf("failed applying config to remote storage: %w", err)
	}

	i.storage = storage.NewFanout(i.logger, i.wal, i.remoteStore)

	opts := &scrape.Options{
		ExtraMetrics:      cfg.global.ExtraMetrics,
		HTTPClientOptions: []config_util.HTTPClientOption{},
	}

	if cfg.global.DisableKeepAlives {
		opts.HTTPClientOptions = append(opts.HTTPClientOptions, config_util.WithKeepAlivesDisabled())
	}
	if cfg.global.IdleConnTimeout > 0 {
		opts.HTTPClientOptions = append(opts.HTTPClientOptions, config_util.WithIdleConnTimeout(cfg.global.IdleConnTimeout))
	}
	scrapeManager := newScrapeManager(opts, log.With(i.logger, "component", "scrape manager"), i.storage)
	err = scrapeManager.ApplyConfig(&config.Config{
		GlobalConfig:  cfg.global.Prometheus,
		ScrapeConfigs: cfg.ScrapeConfigs,
	})
	if err != nil {
		return fmt.Errorf("failed applying config to scrape manager: %w", err)
	}

	i.readyScrapeManager.Set(scrapeManager)

	return nil
}

// Ready returns true if the Instance has been initialized and is ready
// to start scraping and delivering metrics.
func (i *Instance) Ready() bool {
	return i.ready.Load()
}

// Update accepts a new Config for the Instance and will dynamically update any
// running Prometheus components with the new values from Config. Update will
// return an ErrInvalidUpdate if the Update could not be applied.
func (i *Instance) Update(c Config) (err error) {
	i.mut.Lock()
	defer i.mut.Unlock()

	// It's only (currently) valid to update scrape_configs and remote_write, so
	// if any other field has changed here, return the error.
	switch {
	// This first case should never happen in practice but it's included here for
	// completions sake.
	case i.cfg.Name != c.Name:
		err = errImmutableField{Field: "name"}
	case i.cfg.HostFilter != c.HostFilter:
		err = errImmutableField{Field: "host_filter"}
	case i.cfg.WALTruncateFrequency != c.WALTruncateFrequency:
		err = errImmutableField{Field: "wal_truncate_frequency"}
	case i.cfg.RemoteFlushDeadline != c.RemoteFlushDeadline:
		err = errImmutableField{Field: "remote_flush_deadline"}
	case i.cfg.WriteStaleOnShutdown != c.WriteStaleOnShutdown:
		err = errImmutableField{Field: "write_stale_on_shutdown"}
	}
	if err != nil {
		return ErrInvalidUpdate{Inner: err}
	}

	// Check to see if the components exist yet.
	if i.discovery == nil || i.remoteStore == nil || i.readyScrapeManager == nil {
		return ErrInvalidUpdate{
			Inner: fmt.Errorf("cannot dynamically update because instance is not running"),
		}
	}

	// NOTE(rfratto): Prometheus applies configs in a specific order to ensure
	// flow from service discovery down to the WAL continues working properly.
	//
	// Keep the following order below:
	//
	// 1. Local config
	// 2. Remote Store
	// 3. Scrape Manager
	// 4. Discovery Manager

	originalConfig := i.cfg
	defer func() {
		if err != nil {
			i.cfg = originalConfig
		}
	}()
	i.cfg = c

	i.hostFilter.SetRelabels(c.HostFilterRelabelConfigs)
	if c.HostFilter {
		// N.B.: only call PatchSD if HostFilter is enabled since it
		// mutates what targets will be discovered.
		i.hostFilter.PatchSD(c.ScrapeConfigs)
	}

	err = i.remoteStore.ApplyConfig(&config.Config{
		GlobalConfig:       c.global.Prometheus,
		RemoteWriteConfigs: c.RemoteWrite,
	})
	if err != nil {
		return fmt.Errorf("error applying new remote_write configs: %w", err)
	}

	sm, err := i.readyScrapeManager.Get()
	if err != nil {
		return fmt.Errorf("couldn't get scrape manager to apply new scrape configs: %w", err)
	}
	err = sm.ApplyConfig(&config.Config{
		GlobalConfig:  c.global.Prometheus,
		ScrapeConfigs: c.ScrapeConfigs,
	})
	if err != nil {
		return fmt.Errorf("error applying updated configs to scrape manager: %w", err)
	}

	sdConfigs := map[string]discovery.Configs{}
	for _, v := range c.ScrapeConfigs {
		sdConfigs[v.JobName] = v.ServiceDiscoveryConfigs
	}
	err = i.discovery.Manager.ApplyConfig(sdConfigs)
	if err != nil {
		return fmt.Errorf("failed applying configs to discovery manager: %w", err)
	}

	return nil
}

// TargetsActive returns the set of active targets from the scrape manager. Returns nil
// if the scrape manager is not ready yet.
func (i *Instance) TargetsActive() map[string][]*scrape.Target {
	i.mut.Lock()
	defer i.mut.Unlock()

	if i.readyScrapeManager == nil {
		return nil
	}

	mgr, err := i.readyScrapeManager.Get()
	if err == ErrNotReady {
		return nil
	} else if err != nil {
		level.Error(i.logger).Log("msg", "failed to get scrape manager when collecting active targets", "err", err)
		return nil
	}
	return mgr.TargetsActive()
}

// StorageDirectory returns the directory where this Instance is writing series
// and samples to for the WAL.
func (i *Instance) StorageDirectory() string {
	return i.wal.Directory()
}

// Appender returns a storage.Appender from the instance's WAL
func (i *Instance) Appender(ctx context.Context) storage.Appender {
	return i.wal.Appender(ctx)
}

type discoveryService struct {
	Manager *discovery.Manager

	RunFunc    func() error
	StopFunc   func(err error)
	SyncChFunc func() GroupChannel
}

func (s *discoveryService) Run() error           { return s.RunFunc() }
func (s *discoveryService) Stop(err error)       { s.StopFunc(err) }
func (s *discoveryService) SyncCh() GroupChannel { return s.SyncChFunc() }

// newDiscoveryManager returns an implementation of a runnable service
// that outputs discovered targets to a channel. The implementation
// uses the Prometheus Discovery Manager. Targets will be filtered
// if the instance is configured to perform host filtering.
func (i *Instance) newDiscoveryManager(ctx context.Context, cfg *Config) (*discoveryService, error) {
	ctx, cancel := context.WithCancel(ctx)

	logger := log.With(i.logger, "component", "discovery manager")
	manager := discovery.NewManager(ctx, logger, discovery.Name("scrape"))

	// TODO(rfratto): refactor this to a function?
	// TODO(rfratto): ensure job name name is unique
	c := map[string]discovery.Configs{}
	for _, v := range cfg.ScrapeConfigs {
		c[v.JobName] = v.ServiceDiscoveryConfigs
	}
	err := manager.ApplyConfig(c)
	if err != nil {
		cancel()
		level.Error(i.logger).Log("msg", "failed applying config to discovery manager", "err", err)
		return nil, fmt.Errorf("failed applying config to discovery manager: %w", err)
	}

	rg := runGroupWithContext(ctx)

	// Run the manager
	rg.Add(func() error {
		err := manager.Run()
		level.Info(i.logger).Log("msg", "discovery manager stopped")
		return err
	}, func(err error) {
		level.Info(i.logger).Log("msg", "stopping discovery manager...")
		cancel()
	})

	syncChFunc := manager.SyncCh

	// If host filtering is enabled, run it and use its channel for discovered
	// targets.
	if cfg.HostFilter {
		rg.Add(func() error {
			i.hostFilter.Run(manager.SyncCh())
			level.Info(i.logger).Log("msg", "host filterer stopped")
			return nil
		}, func(_ error) {
			level.Info(i.logger).Log("msg", "stopping host filterer...")
			i.hostFilter.Stop()
		})

		syncChFunc = i.hostFilter.SyncCh
	}

	return &discoveryService{
		Manager: manager,

		RunFunc:    rg.Run,
		StopFunc:   rg.Stop,
		SyncChFunc: syncChFunc,
	}, nil
}

func (i *Instance) truncateLoop(ctx context.Context, wal walStorage, cfg *Config) {
	// Track the last timestamp we truncated for to prevent segments from getting
	// deleted until at least some new data has been sent.
	var lastTs int64 = math.MinInt64

	for {
		select {
		case <-ctx.Done():
			return
		case <-time.After(cfg.WALTruncateFrequency):
			// The timestamp ts is used to determine which series are not receiving
			// samples and may be deleted from the WAL. Their most recent append
			// timestamp is compared to ts, and if that timestamp is older then ts,
			// they are considered inactive and may be deleted.
			//
			// Subtracting a duration from ts will delay when it will be considered
			// inactive and scheduled for deletion.
			ts := i.getRemoteWriteTimestamp() - i.cfg.MinWALTime.Milliseconds()
			if ts < 0 {
				ts = 0
			}

			// Network issues can prevent the result of getRemoteWriteTimestamp from
			// changing. We don't want data in the WAL to grow forever, so we set a cap
			// on the maximum age data can be. If our ts is older than this cutoff point,
			// we'll shift it forward to start deleting very stale data.
			if maxTS := timestamp.FromTime(time.Now().Add(-i.cfg.MaxWALTime)); ts < maxTS {
				ts = maxTS
			}

			if ts == lastTs {
				level.Debug(i.logger).Log("msg", "not truncating the WAL, remote_write timestamp is unchanged", "ts", ts)
				continue
			}
			lastTs = ts

			level.Debug(i.logger).Log("msg", "truncating the WAL", "ts", ts)
			err := wal.Truncate(ts)
			if err != nil {
				// The only issue here is larger disk usage and a greater replay time,
				// so we'll only log this as a warning.
				level.Warn(i.logger).Log("msg", "could not truncate WAL", "err", err)
			}
		}
	}
}

// getRemoteWriteTimestamp looks up the last successful remote write timestamp.
// This is passed to wal.Storage for its truncation. If no remote write sections
// are configured, getRemoteWriteTimestamp returns the current time.
func (i *Instance) getRemoteWriteTimestamp() int64 {
	i.mut.Lock()
	defer i.mut.Unlock()

	if len(i.cfg.RemoteWrite) == 0 {
		return timestamp.FromTime(time.Now())
	}

	if i.remoteStore == nil {
		// Instance still being initialized; start at 0.
		return 0
	}
	return i.remoteStore.LowestSentTimestamp()
}

// walStorage is an interface satisfied by wal.Storage, and created for testing.
type walStorage interface {
	// walStorage implements Queryable/ChunkQueryable for compatibility, but is unused.
	storage.Queryable
	storage.ChunkQueryable

	Directory() string

	StartTime() (int64, error)
	WriteStalenessMarkers(remoteTsFunc func() int64) error
	Appender(context.Context) storage.Appender
	Truncate(mint int64) error

	Close() error
}

// Hostname retrieves the hostname identifying the machine the process is
// running on. It will return the value of $HOSTNAME, if defined, and fall
// back to Go's os.Hostname.
func Hostname() (string, error) {
	hostname := os.Getenv("HOSTNAME")
	if hostname != "" {
		return hostname, nil
	}

	hostname, err := os.Hostname()
	if err != nil {
		return "", fmt.Errorf("failed to get hostname: %w", err)
	}
	return hostname, nil
}

func getHash(data interface{}) (string, error) {
	bytes, err := json.Marshal(data)
	if err != nil {
		return "", err
	}
	hash := md5.Sum(bytes)
	return hex.EncodeToString(hash[:]), nil
}

var managerMtx sync.Mutex

func newScrapeManager(o *scrape.Options, logger log.Logger, app storage.Appendable) *scrape.Manager {
	// scrape.NewManager modifies a global variable in Prometheus. To avoid a
	// data race of modifying that global, we lock a mutex here briefly.
	managerMtx.Lock()
	defer managerMtx.Unlock()
	return scrape.NewManager(o, logger, app)
}

type runGroupContext struct {
	cancel context.CancelFunc

	g *run.Group
}

// runGroupWithContext creates a new run.Group that will be stopped if the
// context gets canceled in addition to the normal behavior of stopping
// when any of the actors stop.
func runGroupWithContext(ctx context.Context) *runGroupContext {
	ctx, cancel := context.WithCancel(ctx)

	var g run.Group
	g.Add(func() error {
		<-ctx.Done()
		return nil
	}, func(_ error) {
		cancel()
	})

	return &runGroupContext{cancel: cancel, g: &g}
}

func (rg *runGroupContext) Add(execute func() error, interrupt func(error)) {
	rg.g.Add(execute, interrupt)
}

func (rg *runGroupContext) Run() error   { return rg.g.Run() }
func (rg *runGroupContext) Stop(_ error) { rg.cancel() }

// ErrNotReady is returned when the scrape manager is used but has not been
// initialized yet.
var ErrNotReady = errors.New("Scrape manager not ready")

// readyScrapeManager allows a scrape manager to be retrieved. Even if it's set at a later point in time.
type readyScrapeManager struct {
	mtx sync.RWMutex
	m   *scrape.Manager
}

// Set the scrape manager.
func (rm *readyScrapeManager) Set(m *scrape.Manager) {
	rm.mtx.Lock()
	defer rm.mtx.Unlock()

	rm.m = m
}

// Get the scrape manager. If is not ready, return an error.
func (rm *readyScrapeManager) Get() (*scrape.Manager, error) {
	rm.mtx.RLock()
	defer rm.mtx.RUnlock()

	if rm.m != nil {
		return rm.m, nil
	}

	return nil, ErrNotReady
}

'''
'''--- pkg/metrics/instance/instance_integration_test.go ---
package instance

import (
	"context"
	"fmt"
	"io/ioutil"
	"net"
	"net/http"
	"os"
	"strings"
	"testing"
	"time"

	"github.com/cortexproject/cortex/pkg/util/test"
	"github.com/go-kit/log"
	"github.com/gorilla/mux"
	"github.com/prometheus/client_golang/prometheus"
	"github.com/prometheus/client_golang/prometheus/promhttp"
	"github.com/stretchr/testify/require"
	"go.uber.org/atomic"
)

// TestInstance_Update performs a full integration test by doing the following:
//
// 1. Launching an HTTP server which can be scraped and also mocks the remote_write
//    endpoint.
// 2. Creating an instance config with no scrape_configs or remote_write configs.
// 3. Updates the instance with a scrape_config and remote_write.
// 4. Validates that after 15 seconds, the scrape endpoint and remote_write
//    endpoint has been called.
func TestInstance_Update(t *testing.T) {
	logger := log.NewLogfmtLogger(log.NewSyncWriter(os.Stderr))

	walDir, err := ioutil.TempDir(os.TempDir(), "wal")
	require.NoError(t, err)
	t.Cleanup(func() { os.RemoveAll(walDir) })

	var (
		scraped = atomic.NewBool(false)
		pushed  = atomic.NewBool(false)
	)

	r := mux.NewRouter()
	r.HandleFunc("/metrics", func(w http.ResponseWriter, r *http.Request) {
		scraped.Store(true)
		promhttp.Handler().ServeHTTP(w, r)
	})
	r.HandleFunc("/push", func(w http.ResponseWriter, r *http.Request) {
		pushed.Store(true)
		// We don't particularly care what was pushed to us so we'll ignore
		// everything here; we just want to make sure the endpoint was invoked.
	})

	// Start a server for exposing the router.
	l, err := net.Listen("tcp", "127.0.0.1:0")
	require.NoError(t, err)
	defer l.Close()
	go func() {
		_ = http.Serve(l, r)
	}()

	// Create a new instance where it's not scraping or writing anything by default.
	initialConfig := loadConfig(t, `
name: integration_test
scrape_configs: []
remote_write: []
`)
	inst, err := New(prometheus.NewRegistry(), initialConfig, walDir, logger)
	require.NoError(t, err)

	instCtx, cancel := context.WithCancel(context.Background())
	defer cancel()
	go func() {
		err := inst.Run(instCtx)
		require.NoError(t, err)
	}()

	// Update the config with a single scrape_config and remote_write.
	newConfig := loadConfig(t, fmt.Sprintf(`
name: integration_test
scrape_configs:
  - job_name: test_scrape
    scrape_interval: 5s
    static_configs:
      - targets: ['%[1]s']
remote_write:
  - url: http://%[1]s/push
`, l.Addr()))

	// Wait minute for the instance to update (it might not be ready yet and
	// would return an error until everything is initialized), and then wait
	// again for the configs to apply and set the scraped and pushed atomic
	// variables, indicating that the Prometheus components successfully updated.
	test.Poll(t, time.Second*15, nil, func() interface{} {
		err := inst.Update(newConfig)
		if err != nil {
			logger.Log("msg", "failed to update instance", "err", err)
		}
		return err
	})

	test.Poll(t, time.Second*15, true, func() interface{} {
		return scraped.Load() && pushed.Load()
	})
}

func TestInstance_Update_Failed(t *testing.T) {
	logger := log.NewLogfmtLogger(log.NewSyncWriter(os.Stderr))

	walDir, err := ioutil.TempDir(os.TempDir(), "wal")
	require.NoError(t, err)
	t.Cleanup(func() { os.RemoveAll(walDir) })

	r := mux.NewRouter()
	r.HandleFunc("/metrics", func(w http.ResponseWriter, r *http.Request) {
		promhttp.Handler().ServeHTTP(w, r)
	})
	r.HandleFunc("/push", func(w http.ResponseWriter, r *http.Request) {})

	// Start a server for exposing the router.
	l, err := net.Listen("tcp", "127.0.0.1:0")
	require.NoError(t, err)
	defer l.Close()
	go func() {
		_ = http.Serve(l, r)
	}()

	// Create a new instance where it's not scraping or writing anything by default.
	initialConfig := loadConfig(t, `
name: integration_test
scrape_configs: []
remote_write: []
`)
	inst, err := New(prometheus.NewRegistry(), initialConfig, walDir, logger)
	require.NoError(t, err)

	instCtx, cancel := context.WithCancel(context.Background())
	defer cancel()
	go func() {
		err := inst.Run(instCtx)
		require.NoError(t, err)
	}()

	// Create a new config to use for updating
	newConfig := loadConfig(t, fmt.Sprintf(`
name: integration_test
scrape_configs:
  - job_name: test_scrape
    scrape_interval: 5s
    static_configs:
      - targets: ['%[1]s']
remote_write:
  - url: http://%[1]s/push
`, l.Addr()))

	// Make sure the instance can successfully update first
	test.Poll(t, time.Second*15, nil, func() interface{} {
		err := inst.Update(newConfig)
		if err != nil {
			logger.Log("msg", "failed to update instance", "err", err)
		}
		return err
	})

	// Now force an update back to the original config to fail
	inst.readyScrapeManager.Set(nil)
	require.NotNil(t, inst.Update(initialConfig), "update should have failed")
	require.Equal(t, newConfig, inst.cfg, "config did not roll back")
}

// TestInstance_Update_InvalidChanges runs an instance with a blank initial
// config and performs various unacceptable updates that should return an
// error.
func TestInstance_Update_InvalidChanges(t *testing.T) {
	logger := log.NewLogfmtLogger(log.NewSyncWriter(os.Stderr))

	walDir, err := ioutil.TempDir(os.TempDir(), "wal")
	require.NoError(t, err)
	t.Cleanup(func() { os.RemoveAll(walDir) })

	// Create a new instance where it's not scraping or writing anything by default.
	initialConfig := loadConfig(t, `
name: integration_test
scrape_configs: []
remote_write: []
`)
	inst, err := New(prometheus.NewRegistry(), initialConfig, walDir, logger)
	require.NoError(t, err)

	instCtx, cancel := context.WithCancel(context.Background())
	defer cancel()
	go func() {
		err := inst.Run(instCtx)
		require.NoError(t, err)
	}()

	// Do a no-op update that succeeds to ensure that the instance is running.
	test.Poll(t, time.Second*15, nil, func() interface{} {
		err := inst.Update(initialConfig)
		if err != nil {
			logger.Log("msg", "failed to update instance", "err", err)
		}
		return err
	})

	tt := []struct {
		name   string
		mut    func(c *Config)
		expect string
	}{
		{
			name:   "name changed",
			mut:    func(c *Config) { c.Name = "changed name" },
			expect: "name cannot be changed dynamically",
		},
		{
			name:   "host_filter changed",
			mut:    func(c *Config) { c.HostFilter = true },
			expect: "host_filter cannot be changed dynamically",
		},
		{
			name:   "wal_truncate_frequency changed",
			mut:    func(c *Config) { c.WALTruncateFrequency *= 2 },
			expect: "wal_truncate_frequency cannot be changed dynamically",
		},
		{
			name:   "remote_flush_deadline changed",
			mut:    func(c *Config) { c.RemoteFlushDeadline *= 2 },
			expect: "remote_flush_deadline cannot be changed dynamically",
		},
		{
			name:   "write_stale_on_shutdown changed",
			mut:    func(c *Config) { c.WriteStaleOnShutdown = true },
			expect: "write_stale_on_shutdown cannot be changed dynamically",
		},
	}

	for _, tc := range tt {
		t.Run(tc.name, func(t *testing.T) {
			mutatedConfig := initialConfig
			tc.mut(&mutatedConfig)

			err := inst.Update(mutatedConfig)
			require.EqualError(t, err, tc.expect)
		})
	}
}

func loadConfig(t *testing.T, s string) Config {
	cfg, err := UnmarshalConfig(strings.NewReader(s))
	require.NoError(t, err)
	require.NoError(t, cfg.ApplyDefaults(DefaultGlobalConfig))
	return *cfg
}

'''
'''--- pkg/metrics/instance/instance_test.go ---
package instance

import (
	"context"
	"fmt"
	"io/ioutil"
	"net/http/httptest"
	"os"
	"path"
	"strings"
	"sync"
	"testing"
	"time"

	"github.com/cortexproject/cortex/pkg/util/test"
	"github.com/go-kit/log"
	"github.com/prometheus/client_golang/prometheus"
	"github.com/prometheus/client_golang/prometheus/promhttp"
	"github.com/prometheus/common/model"
	"github.com/prometheus/prometheus/config"
	"github.com/prometheus/prometheus/discovery"
	"github.com/prometheus/prometheus/model/exemplar"
	"github.com/prometheus/prometheus/model/labels"
	"github.com/prometheus/prometheus/storage"
	"github.com/stretchr/testify/require"
)

func TestConfig_Unmarshal_Defaults(t *testing.T) {
	global := DefaultGlobalConfig
	cfgText := `name: test
scrape_configs:
  - job_name: local_scrape
    static_configs:
      - targets: ['127.0.0.1:12345']
        labels:
          cluster: 'localhost'
remote_write:
  - url: http://localhost:9009/api/prom/push`

	cfg, err := UnmarshalConfig(strings.NewReader(cfgText))
	require.NoError(t, err)

	err = cfg.ApplyDefaults(global)
	require.NoError(t, err)

	require.Equal(t, DefaultConfig.HostFilter, cfg.HostFilter)
	require.Equal(t, DefaultConfig.WALTruncateFrequency, cfg.WALTruncateFrequency)
	require.Equal(t, DefaultConfig.RemoteFlushDeadline, cfg.RemoteFlushDeadline)
	require.Equal(t, DefaultConfig.WriteStaleOnShutdown, cfg.WriteStaleOnShutdown)

	for _, sc := range cfg.ScrapeConfigs {
		require.Equal(t, sc.ScrapeInterval, global.Prometheus.ScrapeInterval)
		require.Equal(t, sc.ScrapeTimeout, global.Prometheus.ScrapeTimeout)
	}
}

func TestConfig_ApplyDefaults_Validations(t *testing.T) {
	global := DefaultGlobalConfig
	cfg := DefaultConfig
	cfg.Name = "instance"
	cfg.ScrapeConfigs = []*config.ScrapeConfig{{
		JobName: "scrape",
		ServiceDiscoveryConfigs: discovery.Configs{
			discovery.StaticConfig{{
				Targets: []model.LabelSet{{
					model.AddressLabel: model.LabelValue("127.0.0.1:12345"),
				}},
				Labels: model.LabelSet{"cluster": "localhost"},
			}},
		},
	}}
	cfg.RemoteWrite = []*config.RemoteWriteConfig{{Name: "write"}}

	tt := []struct {
		name     string
		mutation func(c *Config)
		err      error
	}{
		{
			"valid config",
			nil,
			nil,
		},
		{
			"requires name",
			func(c *Config) { c.Name = "" },
			fmt.Errorf("missing instance name"),
		},
		{
			"missing scrape",
			func(c *Config) { c.ScrapeConfigs[0] = nil },
			fmt.Errorf("empty or null scrape config section"),
		},
		{
			"missing wal truncate frequency",
			func(c *Config) { c.WALTruncateFrequency = 0 },
			fmt.Errorf("wal_truncate_frequency must be greater than 0s"),
		},
		{
			"missing remote flush deadline",
			func(c *Config) { c.RemoteFlushDeadline = 0 },
			fmt.Errorf("remote_flush_deadline must be greater than 0s"),
		},
		{
			"scrape timeout too high",
			func(c *Config) { c.ScrapeConfigs[0].ScrapeTimeout = global.Prometheus.ScrapeInterval + 1 },
			fmt.Errorf("scrape timeout greater than scrape interval for scrape config with job name \"scrape\""),
		},
		{
			"scrape interval greater than truncate frequency",
			func(c *Config) { c.ScrapeConfigs[0].ScrapeInterval = model.Duration(c.WALTruncateFrequency + 1) },
			fmt.Errorf("scrape interval greater than wal_truncate_frequency for scrape config with job name \"scrape\""),
		},
		{
			"multiple scrape configs with same name",
			func(c *Config) {
				c.ScrapeConfigs = append(c.ScrapeConfigs, &config.ScrapeConfig{
					JobName: "scrape",
				})
			},
			fmt.Errorf("found multiple scrape configs with job name \"scrape\""),
		},
		{
			"empty remote write",
			func(c *Config) { c.RemoteWrite = append(c.RemoteWrite, nil) },
			fmt.Errorf("empty or null remote write config section"),
		},
		{
			"multiple remote writes with same name",
			func(c *Config) {
				c.RemoteWrite = []*config.RemoteWriteConfig{
					{Name: "foo"},
					{Name: "foo"},
				}
			},
			fmt.Errorf("found duplicate remote write configs with name \"foo\""),
		},
	}

	for _, tc := range tt {
		t.Run(tc.name, func(t *testing.T) {
			// Copy the input and all of its slices
			input := cfg

			var scrapeConfigs []*config.ScrapeConfig
			for _, sc := range input.ScrapeConfigs {
				scCopy := *sc
				scrapeConfigs = append(scrapeConfigs, &scCopy)
			}
			input.ScrapeConfigs = scrapeConfigs

			var remoteWrites []*config.RemoteWriteConfig
			for _, rw := range input.RemoteWrite {
				rwCopy := *rw
				remoteWrites = append(remoteWrites, &rwCopy)
			}
			input.RemoteWrite = remoteWrites

			if tc.mutation != nil {
				tc.mutation(&input)
			}

			err := input.ApplyDefaults(global)
			if tc.err == nil {
				require.NoError(t, err)
			} else {
				require.EqualError(t, err, tc.err.Error())
			}
		})
	}
}

func TestConfig_ApplyDefaults_HashedName(t *testing.T) {
	cfgText := `
name: default
host_filter: false
remote_write:
- url: http://localhost:9009/api/prom/push
  sigv4: {}`

	cfg, err := UnmarshalConfig(strings.NewReader(cfgText))
	require.NoError(t, err)
	require.NoError(t, cfg.ApplyDefaults(DefaultGlobalConfig))
	require.NotEmpty(t, cfg.RemoteWrite[0].Name)
}

func TestInstance_Path(t *testing.T) {
	scrapeAddr, closeSrv := getTestServer(t)
	defer closeSrv()

	walDir, err := ioutil.TempDir(os.TempDir(), "wal")
	require.NoError(t, err)
	defer os.RemoveAll(walDir)

	globalConfig := getTestGlobalConfig(t)

	cfg := getTestConfig(t, &globalConfig, scrapeAddr)
	cfg.WALTruncateFrequency = time.Hour
	cfg.RemoteFlushDeadline = time.Hour

	logger := log.NewLogfmtLogger(log.NewSyncWriter(os.Stderr))
	inst, err := New(prometheus.NewRegistry(), cfg, walDir, logger)
	require.NoError(t, err)
	runInstance(t, inst)

	// <walDir>/<inst.name> path should exist for WAL
	test.Poll(t, time.Second*5, true, func() interface{} {
		_, err := os.Stat(path.Join(walDir, "test"))
		return err == nil
	})
}

// TestInstance tests that discovery and scraping are working by using a mock
// instance of the WAL storage and testing that samples get written to it.
// This test touches most of Instance and is enough for a basic integration test.
func TestInstance(t *testing.T) {
	scrapeAddr, closeSrv := getTestServer(t)
	defer closeSrv()

	walDir, err := ioutil.TempDir(os.TempDir(), "wal")
	require.NoError(t, err)
	defer os.RemoveAll(walDir)

	globalConfig := getTestGlobalConfig(t)
	cfg := getTestConfig(t, &globalConfig, scrapeAddr)
	cfg.WALTruncateFrequency = time.Hour
	cfg.RemoteFlushDeadline = time.Hour

	mockStorage := mockWalStorage{
		series:    make(map[storage.SeriesRef]int),
		directory: walDir,
	}
	newWal := func(_ prometheus.Registerer) (walStorage, error) { return &mockStorage, nil }

	logger := log.NewLogfmtLogger(log.NewSyncWriter(os.Stderr))
	inst, err := newInstance(cfg, nil, logger, newWal)
	require.NoError(t, err)
	runInstance(t, inst)

	// Wait until mockWalStorage has had a series added to it.
	test.Poll(t, 30*time.Second, true, func() interface{} {
		mockStorage.mut.Lock()
		defer mockStorage.mut.Unlock()
		return len(mockStorage.series) > 0
	})
}

// TestInstance_Recreate ensures that creating an instance with the same name twice
// does not cause any duplicate metrics registration that leads to a panic.
func TestInstance_Recreate(t *testing.T) {
	scrapeAddr, closeSrv := getTestServer(t)
	defer closeSrv()

	walDir, err := ioutil.TempDir(os.TempDir(), "wal")
	require.NoError(t, err)
	defer os.RemoveAll(walDir)

	globalConfig := getTestGlobalConfig(t)

	cfg := getTestConfig(t, &globalConfig, scrapeAddr)
	cfg.Name = "recreate_test"
	cfg.WALTruncateFrequency = time.Hour
	cfg.RemoteFlushDeadline = time.Hour

	logger := log.NewLogfmtLogger(log.NewSyncWriter(os.Stderr))
	inst, err := New(prometheus.NewRegistry(), cfg, walDir, logger)
	require.NoError(t, err)

	ctx, cancel := context.WithCancel(context.Background())
	exited := make(chan bool)
	go func() {
		err := inst.Run(ctx)
		close(exited)

		if err != nil {
			require.Equal(t, context.Canceled, err)
		}
	}()

	time.Sleep(1 * time.Second)
	cancel()
	<-exited

	// Recreate the instance, no panic should happen.
	require.NotPanics(t, func() {
		inst, err := New(prometheus.NewRegistry(), cfg, walDir, logger)
		require.NoError(t, err)
		runInstance(t, inst)

		time.Sleep(1 * time.Second)
	})
}

func getTestServer(t *testing.T) (addr string, closeFunc func()) {
	t.Helper()

	reg := prometheus.NewRegistry()

	testCounter := prometheus.NewCounter(prometheus.CounterOpts{
		Name: "test_metric_total",
	})
	testCounter.Inc()
	reg.MustRegister(testCounter)

	handler := promhttp.HandlerFor(reg, promhttp.HandlerOpts{})
	httpSrv := httptest.NewServer(handler)
	return httpSrv.Listener.Addr().String(), httpSrv.Close
}

func getTestGlobalConfig(t *testing.T) GlobalConfig {
	t.Helper()

	return GlobalConfig{
		Prometheus: config.GlobalConfig{
			ScrapeInterval:     model.Duration(time.Millisecond * 50),
			ScrapeTimeout:      model.Duration(time.Millisecond * 25),
			EvaluationInterval: model.Duration(time.Hour),
		},
	}
}

func getTestConfig(t *testing.T, global *GlobalConfig, scrapeAddr string) Config {
	t.Helper()

	scrapeCfg := config.DefaultScrapeConfig
	scrapeCfg.JobName = "test"
	scrapeCfg.ScrapeInterval = global.Prometheus.ScrapeInterval
	scrapeCfg.ScrapeTimeout = global.Prometheus.ScrapeTimeout
	scrapeCfg.ServiceDiscoveryConfigs = discovery.Configs{
		discovery.StaticConfig{{
			Targets: []model.LabelSet{{
				model.AddressLabel: model.LabelValue(scrapeAddr),
			}},
			Labels: model.LabelSet{},
		}},
	}

	cfg := DefaultConfig
	cfg.Name = "test"
	cfg.ScrapeConfigs = []*config.ScrapeConfig{&scrapeCfg}
	cfg.global = *global

	return cfg
}

type mockWalStorage struct {
	storage.Queryable
	storage.ChunkQueryable

	directory string
	mut       sync.Mutex
	series    map[storage.SeriesRef]int
}

func (s *mockWalStorage) Directory() string                          { return s.directory }
func (s *mockWalStorage) StartTime() (int64, error)                  { return 0, nil }
func (s *mockWalStorage) WriteStalenessMarkers(f func() int64) error { return nil }
func (s *mockWalStorage) Close() error                               { return nil }
func (s *mockWalStorage) Truncate(mint int64) error                  { return nil }

func (s *mockWalStorage) Appender(context.Context) storage.Appender {
	return &mockAppender{s: s}
}

type mockAppender struct {
	s *mockWalStorage
}

func (a *mockAppender) Append(ref storage.SeriesRef, l labels.Labels, t int64, v float64) (storage.SeriesRef, error) {
	if ref == 0 {
		return a.Add(l, t, v)
	}
	return ref, a.AddFast(ref, t, v)
}

// Add adds a new series and sets its written count to 1.
func (a *mockAppender) Add(l labels.Labels, t int64, v float64) (storage.SeriesRef, error) {
	a.s.mut.Lock()
	defer a.s.mut.Unlock()

	hash := l.Hash()
	a.s.series[storage.SeriesRef(hash)] = 1
	return storage.SeriesRef(hash), nil
}

// AddFast increments the number of writes to an existing series.
func (a *mockAppender) AddFast(ref storage.SeriesRef, t int64, v float64) error {
	a.s.mut.Lock()
	defer a.s.mut.Unlock()
	_, ok := a.s.series[ref]
	if !ok {
		return storage.ErrNotFound
	}

	a.s.series[ref]++
	return nil
}

func (a *mockAppender) AppendExemplar(ref storage.SeriesRef, l labels.Labels, e exemplar.Exemplar) (storage.SeriesRef, error) {
	return 0, nil
}

func (a *mockAppender) Commit() error {
	return nil
}

func (a *mockAppender) Rollback() error {
	return nil
}

func runInstance(t *testing.T, i *Instance) {
	ctx, cancel := context.WithCancel(context.Background())
	t.Cleanup(func() { cancel() })
	go require.NotPanics(t, func() {
		_ = i.Run(ctx)
	})
}

'''
'''--- pkg/metrics/instance/manager.go ---
package instance

import (
	"context"
	"errors"
	"fmt"
	"sync"
	"time"

	"github.com/go-kit/log"
	"github.com/go-kit/log/level"
	"github.com/prometheus/client_golang/prometheus"
	"github.com/prometheus/client_golang/prometheus/promauto"
	"github.com/prometheus/prometheus/scrape"
	"github.com/prometheus/prometheus/storage"
)

var (
	instanceAbnormalExits = promauto.NewCounterVec(prometheus.CounterOpts{
		Name: "agent_metrics_instance_abnormal_exits_total",
		Help: "Total number of times a Prometheus instance exited unexpectedly, causing it to be restarted.",
	}, []string{"instance_name"})

	currentActiveInstances = promauto.NewGauge(prometheus.GaugeOpts{
		Name: "agent_metrics_active_instances",
		Help: "Current number of active instances being used by the agent.",
	})

	// DefaultBasicManagerConfig is the default config for the BasicManager.
	DefaultBasicManagerConfig = BasicManagerConfig{
		InstanceRestartBackoff: 5 * time.Second,
	}
)

// Manager represents a set of methods for manipulating running instances at
// runtime.
type Manager interface {
	// GetInstance retrieves a ManagedInstance by name.
	GetInstance(name string) (ManagedInstance, error)

	// ListInstances returns all currently managed instances running
	// within the Manager. The key will be the instance name from their config.
	ListInstances() map[string]ManagedInstance

	// ListConfigs returns the config objects associated with a managed
	// instance. The key will be the Name field from Config.
	ListConfigs() map[string]Config

	// ApplyConfig creates a new Config or updates an existing Config if
	// one with Config.Name already exists.
	ApplyConfig(Config) error

	// DeleteConfig deletes a given managed instance based on its Config.Name.
	DeleteConfig(name string) error

	// Stop stops the Manager and all managed instances.
	Stop()
}

// ManagedInstance is implemented by Instance. It is defined as an interface
// for the sake of testing from Manager implementations.
type ManagedInstance interface {
	Run(ctx context.Context) error
	Ready() bool
	Update(c Config) error
	TargetsActive() map[string][]*scrape.Target
	StorageDirectory() string
	Appender(ctx context.Context) storage.Appender
}

// BasicManagerConfig controls the operations of a BasicManager.
type BasicManagerConfig struct {
	InstanceRestartBackoff time.Duration
}

// BasicManager creates a new BasicManager, implementing the Manager interface.
// BasicManager will directly launch instances and perform no extra processing.
//
// Other implementations of Manager usually wrap a BasicManager.
type BasicManager struct {
	cfgMut sync.Mutex
	cfg    BasicManagerConfig
	logger log.Logger

	// Take care when locking mut: if you hold onto a lock of mut while calling
	// Stop on a process, you will deadlock.
	mut       sync.Mutex
	processes map[string]*managedProcess

	launch Factory
}

// managedProcess represents a goroutine running a ManagedInstance. cancel
// requests that the goroutine should shutdown. done will be closed after the
// goroutine exists.
type managedProcess struct {
	cfg    Config
	inst   ManagedInstance
	cancel context.CancelFunc
	done   chan bool
}

func (p managedProcess) Stop() {
	p.cancel()
	<-p.done
}

// Factory should return an unstarted instance given some config.
type Factory func(c Config) (ManagedInstance, error)

// NewBasicManager creates a new BasicManager. The launch function will be
// invoked any time a new Config is applied.
//
// The lifecycle of any ManagedInstance returned by the launch function will
// be handled by the BasicManager. Instances will be automatically restarted
// if stopped, updated if the config changes, or removed when the Config is
// deleted.
func NewBasicManager(cfg BasicManagerConfig, logger log.Logger, launch Factory) *BasicManager {
	return &BasicManager{
		cfg:       cfg,
		logger:    logger,
		processes: make(map[string]*managedProcess),
		launch:    launch,
	}
}

// UpdateManagerConfig updates the BasicManagerConfig.
func (m *BasicManager) UpdateManagerConfig(c BasicManagerConfig) {
	m.cfgMut.Lock()
	defer m.cfgMut.Unlock()
	m.cfg = c
}

// GetInstance returns the given instance by name.
func (m *BasicManager) GetInstance(name string) (ManagedInstance, error) {
	m.mut.Lock()
	defer m.mut.Unlock()

	process, ok := m.processes[name]
	if !ok {
		return nil, fmt.Errorf("instance %s does not exist", name)
	}
	return process.inst, nil
}

// ListInstances returns the current active instances managed by BasicManager.
func (m *BasicManager) ListInstances() map[string]ManagedInstance {
	m.mut.Lock()
	defer m.mut.Unlock()

	res := make(map[string]ManagedInstance, len(m.processes))
	for name, process := range m.processes {
		if process == nil {
			continue
		}
		res[name] = process.inst
	}
	return res
}

// ListConfigs lists the current active configs managed by BasicManager.
func (m *BasicManager) ListConfigs() map[string]Config {
	m.mut.Lock()
	defer m.mut.Unlock()

	res := make(map[string]Config, len(m.processes))
	for name, process := range m.processes {
		res[name] = process.cfg
	}
	return res
}

// ApplyConfig takes a Config and either starts a new managed instance or
// updates an existing managed instance. The value for Name in c is used to
// uniquely identify the Config and determine whether the Config has an
// existing associated managed instance.
func (m *BasicManager) ApplyConfig(c Config) error {
	m.mut.Lock()
	defer m.mut.Unlock()

	// If the config already exists, we need to update it.
	proc, ok := m.processes[c.Name]
	if ok {
		err := proc.inst.Update(c)

		// If the instance could not be dynamically updated, we need to force the
		// update by restarting it. If it failed for another reason, something
		// serious went wrong and we'll completely give up without stopping the
		// existing job.
		if errors.Is(err, ErrInvalidUpdate{}) {
			level.Info(m.logger).Log("msg", "could not dynamically update instance, will manually restart", "instance", c.Name, "reason", err)

			// NOTE: we don't return here; we fall through to spawn the new instance.
			proc.Stop()
		} else if err != nil {
			return fmt.Errorf("failed to update instance %s: %w", c.Name, err)
		} else {
			level.Info(m.logger).Log("msg", "dynamically updated instance", "instance", c.Name)

			proc.cfg = c
			return nil
		}
	}

	// Spawn a new process for the new config.
	err := m.spawnProcess(c)
	if err != nil {
		return err
	}

	currentActiveInstances.Inc()
	return nil
}

func (m *BasicManager) spawnProcess(c Config) error {
	inst, err := m.launch(c)
	if err != nil {
		return err
	}

	ctx, cancel := context.WithCancel(context.Background())
	done := make(chan bool)

	proc := &managedProcess{
		cancel: cancel,
		done:   done,
		cfg:    c,
		inst:   inst,
	}
	m.processes[c.Name] = proc

	go func() {
		m.runProcess(ctx, c.Name, inst)
		close(done)

		// Now that the process has stopped, we can remove it from our managed
		// list.
		//
		// However, it's possible that a new Config may have been applied and
		// overwrote the initial value in our map. We only want to delete the
		// process from the map if it hasn't changed from what we initially
		// set it to.
		//
		// We only use the instance for comparing (which will never change) because
		// the instance may have dynamically been given a new config since this
		// goroutine started.
		m.mut.Lock()
		if storedProc, exist := m.processes[c.Name]; exist && storedProc.inst == inst {
			delete(m.processes, c.Name)
		}
		m.mut.Unlock()

		currentActiveInstances.Dec()
	}()

	return nil
}

// runProcess runs and instance and keeps it alive until it is explicitly stopped
// by cancelling the context.
func (m *BasicManager) runProcess(ctx context.Context, name string, inst ManagedInstance) {
	for {
		err := inst.Run(ctx)
		if err != nil && err != context.Canceled {
			backoff := m.instanceRestartBackoff()

			instanceAbnormalExits.WithLabelValues(name).Inc()
			level.Error(m.logger).Log("msg", "instance stopped abnormally, restarting after backoff period", "err", err, "backoff", backoff, "instance", name)
			time.Sleep(backoff)
		} else {
			level.Info(m.logger).Log("msg", "stopped instance", "instance", name)
			break
		}
	}
}

func (m *BasicManager) instanceRestartBackoff() time.Duration {
	m.cfgMut.Lock()
	defer m.cfgMut.Unlock()
	return m.cfg.InstanceRestartBackoff
}

// DeleteConfig removes a managed instance by its config name. Returns an error
// if there is no such managed instance with the given name.
func (m *BasicManager) DeleteConfig(name string) error {
	m.mut.Lock()
	proc, ok := m.processes[name]
	if !ok {
		m.mut.Unlock()
		return errors.New("config does not exist")
	}
	m.mut.Unlock()

	// spawnProcess is responsible for removing the process from the map after it
	// stops so we don't need to delete anything from m.processes here.
	proc.Stop()
	return nil
}

// Stop stops the BasicManager and stops all active processes for configs.
func (m *BasicManager) Stop() {
	var wg sync.WaitGroup

	// We don't need to change m.processes here; processes remove themselves
	// from the map (in spawnProcess).
	m.mut.Lock()
	wg.Add(len(m.processes))
	for _, proc := range m.processes {
		go func(proc *managedProcess) {
			proc.Stop()
			wg.Done()
		}(proc)
	}
	m.mut.Unlock()

	wg.Wait()
}

// MockManager exposes methods of the Manager interface as struct fields.
// Useful for tests.
type MockManager struct {
	GetInstanceFunc   func(name string) (ManagedInstance, error)
	ListInstancesFunc func() map[string]ManagedInstance
	ListConfigsFunc   func() map[string]Config
	ApplyConfigFunc   func(Config) error
	DeleteConfigFunc  func(name string) error
	StopFunc          func()
}

// GetInstance implements Manager.
func (m MockManager) GetInstance(name string) (ManagedInstance, error) {
	if m.GetInstanceFunc != nil {
		return m.GetInstanceFunc(name)
	}
	panic("GetInstanceFunc not implemented")
}

// ListInstances implements Manager.
func (m MockManager) ListInstances() map[string]ManagedInstance {
	if m.ListInstancesFunc != nil {
		return m.ListInstancesFunc()
	}
	panic("ListInstancesFunc not implemented")
}

// ListConfigs implements Manager.
func (m MockManager) ListConfigs() map[string]Config {
	if m.ListConfigsFunc != nil {
		return m.ListConfigsFunc()
	}
	panic("ListConfigsFunc not implemented")
}

// ApplyConfig implements Manager.
func (m MockManager) ApplyConfig(c Config) error {
	if m.ApplyConfigFunc != nil {
		return m.ApplyConfigFunc(c)
	}
	panic("ApplyConfigFunc not implemented")
}

// DeleteConfig implements Manager.
func (m MockManager) DeleteConfig(name string) error {
	if m.DeleteConfigFunc != nil {
		return m.DeleteConfigFunc(name)
	}
	panic("DeleteConfigFunc not implemented")
}

// Stop implements Manager.
func (m MockManager) Stop() {
	if m.StopFunc != nil {
		m.StopFunc()
		return
	}
	panic("StopFunc not implemented")
}

'''
'''--- pkg/metrics/instance/manager_test.go ---
package instance

import (
	"context"
	"fmt"
	"os"
	"testing"

	"github.com/go-kit/log"
	"github.com/prometheus/prometheus/scrape"
	"github.com/prometheus/prometheus/storage"
	"github.com/stretchr/testify/require"
)

func TestBasicManager_ApplyConfig(t *testing.T) {
	logger := log.NewLogfmtLogger(log.NewSyncWriter(os.Stderr))

	baseMock := mockInstance{
		RunFunc: func(ctx context.Context) error {
			logger.Log("msg", "starting an instance")
			<-ctx.Done()
			return nil
		},
		UpdateFunc: func(c Config) error {
			return nil
		},
		TargetsActiveFunc: func() map[string][]*scrape.Target {
			return nil
		},
	}

	t.Run("dynamic update successful", func(t *testing.T) {
		spawnedCount := 0
		spawner := func(c Config) (ManagedInstance, error) {
			spawnedCount++

			newMock := baseMock
			return &newMock, nil
		}

		cm := NewBasicManager(DefaultBasicManagerConfig, logger, spawner)

		for i := 0; i < 10; i++ {
			err := cm.ApplyConfig(Config{Name: "test"})
			require.NoError(t, err)
		}

		require.Equal(t, 1, spawnedCount)
	})

	t.Run("dynamic update unsuccessful", func(t *testing.T) {
		spawnedCount := 0
		spawner := func(c Config) (ManagedInstance, error) {
			spawnedCount++

			newMock := baseMock
			newMock.UpdateFunc = func(c Config) error {
				return ErrInvalidUpdate{
					Inner: fmt.Errorf("cannot dynamically update for testing reasons"),
				}
			}
			return &newMock, nil
		}

		cm := NewBasicManager(DefaultBasicManagerConfig, logger, spawner)

		for i := 0; i < 10; i++ {
			err := cm.ApplyConfig(Config{Name: "test"})
			require.NoError(t, err)
		}

		require.Equal(t, 10, spawnedCount)
	})

	t.Run("dynamic update errored", func(t *testing.T) {
		spawnedCount := 0
		spawner := func(c Config) (ManagedInstance, error) {
			spawnedCount++

			newMock := baseMock
			newMock.UpdateFunc = func(c Config) error {
				return fmt.Errorf("something really bad happened")
			}
			return &newMock, nil
		}

		cm := NewBasicManager(DefaultBasicManagerConfig, logger, spawner)

		// Creation should succeed
		err := cm.ApplyConfig(Config{Name: "test"})
		require.NoError(t, err)

		// ...but the update should fail
		err = cm.ApplyConfig(Config{Name: "test"})
		require.Error(t, err, "something really bad happened")
		require.Equal(t, 1, spawnedCount)
	})
}

type mockInstance struct {
	RunFunc              func(ctx context.Context) error
	ReadyFunc            func() bool
	UpdateFunc           func(c Config) error
	TargetsActiveFunc    func() map[string][]*scrape.Target
	StorageDirectoryFunc func() string
	AppenderFunc         func() storage.Appender
}

func (m mockInstance) Run(ctx context.Context) error {
	if m.RunFunc != nil {
		return m.RunFunc(ctx)
	}
	panic("RunFunc not provided")
}

func (m mockInstance) Ready() bool {
	if m.ReadyFunc != nil {
		return m.ReadyFunc()
	}
	panic("ReadyFunc not provided")
}

func (m mockInstance) Update(c Config) error {
	if m.UpdateFunc != nil {
		return m.UpdateFunc(c)
	}
	panic("UpdateFunc not provided")
}

func (m mockInstance) TargetsActive() map[string][]*scrape.Target {
	if m.TargetsActiveFunc != nil {
		return m.TargetsActiveFunc()
	}
	panic("TargetsActiveFunc not provided")
}

func (m mockInstance) StorageDirectory() string {
	if m.StorageDirectoryFunc != nil {
		return m.StorageDirectoryFunc()
	}
	panic("StorageDirectoryFunc not provided")
}

func (m mockInstance) Appender(_ context.Context) storage.Appender {
	if m.AppenderFunc != nil {
		return m.AppenderFunc()
	}
	panic("AppenderFunc not provided")
}

'''
'''--- pkg/metrics/instance/marshal.go ---
package instance

import (
	"bytes"
	"io"

	config_util "github.com/prometheus/common/config"
	"gopkg.in/yaml.v2"
)

// UnmarshalConfig unmarshals an instance config from a reader based on a
// provided content type.
func UnmarshalConfig(r io.Reader) (*Config, error) {
	var cfg Config
	dec := yaml.NewDecoder(r)
	dec.SetStrict(true)
	err := dec.Decode(&cfg)
	return &cfg, err
}

// MarshalConfig marshals an instance config based on a provided content type.
func MarshalConfig(c *Config, scrubSecrets bool) ([]byte, error) {
	var buf bytes.Buffer
	err := MarshalConfigToWriter(c, &buf, scrubSecrets)
	return buf.Bytes(), err
}

// MarshalConfigToWriter marshals a config to an io.Writer.
func MarshalConfigToWriter(c *Config, w io.Writer, scrubSecrets bool) error {
	enc := yaml.NewEncoder(w)

	// If we're not sanitizing the marshaled config, we want to add in an
	// encoding hook to ignore how Secrets marshal (i.e., scrubbing the value
	// and replacing it with <secret>).
	if !scrubSecrets {
		enc.SetHook(func(in interface{}) (ok bool, out interface{}, err error) {
			switch v := in.(type) {
			case config_util.Secret:
				return true, string(v), nil
			case *config_util.URL:
				return true, v.String(), nil
			default:
				return false, nil, nil
			}
		})
	}

	type plain Config
	return enc.Encode((*plain)(c))
}

'''
'''--- pkg/metrics/instance/marshal_test.go ---
package instance

import (
	"bytes"
	"strings"
	"testing"

	"github.com/stretchr/testify/require"
	"gopkg.in/yaml.v2"
)

func TestUnmarshalConfig_Valid(t *testing.T) {
	validConfig := DefaultConfig
	validConfigContent, err := yaml.Marshal(validConfig)
	require.NoError(t, err)

	_, err = UnmarshalConfig(bytes.NewReader(validConfigContent))
	require.NoError(t, err)
}

func TestUnmarshalConfig_Invalid(t *testing.T) {
	invalidConfigContent := `whyWouldAnyoneThinkThisisAValidConfig: 12345`

	_, err := UnmarshalConfig(strings.NewReader(invalidConfigContent))
	require.Error(t, err)
}

// TestMarshal_UnmarshalConfig_RetainSecrets ensures that secrets can be
// retained.
func TestMarshal_UnmarshalConfig_RetainSecrets(t *testing.T) {
	cfg := `name: test
scrape_configs:
- job_name: local_scrape
  follow_redirects: true
  enable_http2: true
  honor_timestamps: true
  metrics_path: /metrics
  scheme: http
  static_configs:
  - targets:
    - 127.0.0.1:12345
    labels:
      cluster: localhost
  basic_auth:
    username: admin
    password: foobar
remote_write:
- url: http://admin:verysecret@localhost:9009/api/prom/push
  remote_timeout: 30s
  name: test-d0f32c
  send_exemplars: true
  basic_auth:
    username: admin
    password: verysecret
  queue_config:
    capacity: 500
    max_shards: 1000
    min_shards: 1
    max_samples_per_send: 100
    batch_send_deadline: 5s
    min_backoff: 30ms
    max_backoff: 100ms
  follow_redirects: true
  enable_http2: true
  metadata_config:
    max_samples_per_send: 500
    send: true
    send_interval: 1m
wal_truncate_frequency: 1m0s
min_wal_time: 5m0s
max_wal_time: 4h0m0s
remote_flush_deadline: 1m0s
`

	c, err := UnmarshalConfig(strings.NewReader(cfg))
	require.NoError(t, err)

	out, err := MarshalConfig(c, false)
	require.NoError(t, err)
	require.YAMLEq(t, cfg, string(out))
}

// TestMarshal_UnmarshalConfig_ScrubSecrets ensures that secrets can be
// scrubbed.
func TestMarshal_UnmarshalConfig_ScrubSecrets(t *testing.T) {
	cfg := `name: test
scrape_configs:
- job_name: local_scrape
  follow_redirects: true
  enable_http2: true
  honor_timestamps: true
  metrics_path: /metrics
  scheme: http
  static_configs:
  - targets:
    - 127.0.0.1:12345
    labels:
      cluster: localhost
  basic_auth:
    username: admin
    password: SCRUBME
remote_write:
- url: http://username:SCRUBURL@localhost:9009/api/prom/push
  remote_timeout: 30s
  name: test-d0f32c
  send_exemplars: true
  basic_auth:
    username: admin
    password: SCRUBME
  queue_config:
    capacity: 500
    max_shards: 1000
    min_shards: 1
    max_samples_per_send: 100
    batch_send_deadline: 5s
    min_backoff: 30ms
    max_backoff: 100ms
  follow_redirects: true
  enable_http2: true
  metadata_config:
    max_samples_per_send: 500
    send: true
    send_interval: 1m
wal_truncate_frequency: 1m0s
min_wal_time: 5m0s
max_wal_time: 4h0m0s
remote_flush_deadline: 1m0s
`

	scrub := func(in string) string {
		in = strings.ReplaceAll(in, "SCRUBME", "<secret>")
		in = strings.ReplaceAll(in, "SCRUBURL", "xxxxx")
		return in
	}

	t.Run("direct marshal", func(t *testing.T) {
		var c Config
		err := yaml.Unmarshal([]byte(cfg), &c)
		require.NoError(t, err)

		out, err := yaml.Marshal(c)
		require.NoError(t, err)
		require.YAMLEq(t, scrub(cfg), string(out))
	})

	t.Run("direct marshal pointer", func(t *testing.T) {
		var c Config
		err := yaml.Unmarshal([]byte(cfg), &c)
		require.NoError(t, err)

		out, err := yaml.Marshal(&c)
		require.NoError(t, err)
		require.YAMLEq(t, scrub(cfg), string(out))
	})

	t.Run("custom marshal methods", func(t *testing.T) {
		c, err := UnmarshalConfig(strings.NewReader(cfg))
		require.NoError(t, err)

		out, err := MarshalConfig(c, true)
		require.NoError(t, err)
		require.YAMLEq(t, scrub(cfg), string(out))
	})
}

'''
'''--- pkg/metrics/instance/modal_manager.go ---
package instance

import (
	"fmt"
	"sync"

	"github.com/go-kit/log"
	"github.com/go-kit/log/level"
	"github.com/prometheus/client_golang/prometheus"
	"github.com/prometheus/client_golang/prometheus/promauto"
)

// Mode controls how instances are created.
type Mode string

// Types of instance modes
var (
	ModeDistinct Mode = "distinct"
	ModeShared   Mode = "shared"

	DefaultMode = ModeShared
)

// UnmarshalYAML unmarshals a string to a Mode. Fails if the string is
// unrecognized.
func (m *Mode) UnmarshalYAML(unmarshal func(interface{}) error) error {
	*m = DefaultMode

	var plain string
	if err := unmarshal(&plain); err != nil {
		return err
	}

	switch plain {
	case string(ModeDistinct):
		*m = ModeDistinct
		return nil
	case string(ModeShared):
		*m = ModeShared
		return nil
	default:
		return fmt.Errorf("unsupported instance_mode '%s'. supported values 'shared', 'distinct'", plain)
	}
}

// ModalManager runs instances by either grouping them or running them fully
// separately.
type ModalManager struct {
	mut     sync.RWMutex
	mode    Mode
	configs map[string]Config

	changedConfigs       *prometheus.GaugeVec
	currentActiveConfigs prometheus.Gauge

	log log.Logger

	// The ModalManager wraps around a "final" Manager that is intended to
	// launch and manage instances based on Configs. This is specified here by the
	// "wrapped" Manager.
	//
	// However, there may be another manager performing formations on the configs
	// before they are passed through to wrapped. This is specified by the "active"
	// Manager.
	//
	// If no transformations on Configs are needed, active will be identical to
	// wrapped.
	wrapped, active Manager
}

// NewModalManager creates a new ModalManager.
func NewModalManager(reg prometheus.Registerer, l log.Logger, next Manager, mode Mode) (*ModalManager, error) {
	changedConfigs := promauto.With(reg).NewGaugeVec(prometheus.GaugeOpts{
		Name: "agent_metrics_configs_changed_total",
		Help: "Total number of dynamically updated configs",
	}, []string{"event"})
	currentActiveConfigs := promauto.With(reg).NewGauge(prometheus.GaugeOpts{
		Name: "agent_metrics_active_configs",
		Help: "Current number of active configs being used by the agent.",
	})

	mm := ModalManager{
		wrapped:              next,
		log:                  l,
		changedConfigs:       changedConfigs,
		currentActiveConfigs: currentActiveConfigs,
		configs:              make(map[string]Config),
	}
	if err := mm.SetMode(mode); err != nil {
		return nil, err
	}
	return &mm, nil
}

// SetMode updates the mode ModalManager is running in. Changing the mode is
// an expensive operation; all underlying configs must be stopped and then
// reapplied.
func (m *ModalManager) SetMode(newMode Mode) error {
	if newMode == "" {
		newMode = DefaultMode
	}

	m.mut.Lock()
	defer m.mut.Unlock()

	var (
		prevMode   = m.mode
		prevActive = m.active
	)

	if prevMode == newMode {
		return nil
	}

	// Set the active Manager based on the new mode. "distinct" means no transformations
	// need to be applied and we can use the wrapped Manager directly. Otherwise, we need
	// to create a new Manager to apply transformations.
	switch newMode {
	case ModeDistinct:
		m.active = m.wrapped
	case ModeShared:
		m.active = NewGroupManager(m.wrapped)
	default:
		panic("unknown mode " + m.mode)
	}
	m.mode = newMode

	// Remove all configs from the previous active Manager.
	if prevActive != nil {
		prevActive.Stop()
	}

	// Re-apply configs to the new active Manager.
	var firstError error
	for name, cfg := range m.configs {
		err := m.active.ApplyConfig(cfg)
		if err != nil {
			level.Error(m.log).Log("msg", "failed to apply config when changing modes", "name", name, "prev_mode", prevMode, "new_mode", newMode, "err", err)
		}
		if firstError == nil && err != nil {
			firstError = err
		}
	}

	return firstError
}

// GetInstance implements Manager.
func (m *ModalManager) GetInstance(name string) (ManagedInstance, error) {
	m.mut.RLock()
	defer m.mut.RUnlock()
	return m.active.GetInstance(name)
}

// ListInstances implements Manager.
func (m *ModalManager) ListInstances() map[string]ManagedInstance {
	m.mut.RLock()
	defer m.mut.RUnlock()
	return m.active.ListInstances()
}

// ListConfigs implements Manager.
func (m *ModalManager) ListConfigs() map[string]Config {
	m.mut.RLock()
	defer m.mut.RUnlock()
	return m.active.ListConfigs()
}

// ApplyConfig implements Manager.
func (m *ModalManager) ApplyConfig(c Config) error {
	m.mut.Lock()
	defer m.mut.Unlock()

	if err := m.active.ApplyConfig(c); err != nil {
		return err
	}

	if _, existingConfig := m.configs[c.Name]; !existingConfig {
		m.currentActiveConfigs.Inc()
		m.changedConfigs.WithLabelValues("created").Inc()
	} else {
		m.changedConfigs.WithLabelValues("updated").Inc()
	}

	m.configs[c.Name] = c

	return nil
}

// DeleteConfig implements Manager.
func (m *ModalManager) DeleteConfig(name string) error {
	m.mut.Lock()
	defer m.mut.Unlock()

	if err := m.active.DeleteConfig(name); err != nil {
		return err
	}

	if _, existingConfig := m.configs[name]; existingConfig {
		m.currentActiveConfigs.Dec()
		delete(m.configs, name)
	}

	m.changedConfigs.WithLabelValues("deleted").Inc()
	return nil
}

// Stop implements Manager.
func (m *ModalManager) Stop() {
	m.mut.Lock()
	defer m.mut.Unlock()

	m.active.Stop()
	m.currentActiveConfigs.Set(0)
	m.configs = make(map[string]Config)
}

'''
'''--- pkg/metrics/instance/noop.go ---
package instance

import (
	"context"

	"github.com/prometheus/prometheus/scrape"
	"github.com/prometheus/prometheus/storage"
)

// NoOpInstance implements the Instance interface in pkg/prom
// but does not do anything. Useful for tests.
type NoOpInstance struct{}

// Run implements Instance.
func (NoOpInstance) Run(ctx context.Context) error {
	<-ctx.Done()
	return nil
}

// Ready implements Instance.
func (NoOpInstance) Ready() bool {
	return true
}

// Update implements Instance.
func (NoOpInstance) Update(_ Config) error {
	return nil
}

// TargetsActive implements Instance.
func (NoOpInstance) TargetsActive() map[string][]*scrape.Target {
	return nil
}

// StorageDirectory implements Instance.
func (NoOpInstance) StorageDirectory() string {
	return ""
}

// Appender implements Instance
func (NoOpInstance) Appender(_ context.Context) storage.Appender {
	return nil
}

'''
'''--- pkg/metrics/wal/series.go ---
package wal

import (
	"sync"

	"github.com/prometheus/prometheus/model/exemplar"
	"github.com/prometheus/prometheus/model/intern"
	"github.com/prometheus/prometheus/model/labels"
	"github.com/prometheus/prometheus/tsdb/chunks"
)

type memSeries struct {
	sync.Mutex

	ref    chunks.HeadSeriesRef
	lset   labels.Labels
	lastTs int64

	// TODO(rfratto): this solution below isn't perfect, and there's still
	// the possibility for a series to be deleted before it's
	// completely gone from the WAL. Rather, we should have gc return
	// a "should delete" map and be given a "deleted" map.
	// If a series that is going to be marked for deletion is in the
	// "deleted" map, then it should be deleted instead.
	//
	// The "deleted" map will be populated by the Truncate function.
	// It will be cleared with every call to gc.

	// willDelete marks a series as to be deleted on the next garbage
	// collection. If it receives a write, willDelete is disabled.
	willDelete bool

	// Whether this series has samples waiting to be committed to the WAL
	pendingCommit bool
}

func (s *memSeries) updateTs(ts int64) {
	s.lastTs = ts
	s.willDelete = false
	s.pendingCommit = true
}

// seriesHashmap is a simple hashmap for memSeries by their label set. It is
// built on top of a regular hashmap and holds a slice of series to resolve
// hash collisions. Its methods require the hash to be submitted with it to
// avoid re-computations throughout the code.
//
// This code is copied from the Prometheus TSDB.
type seriesHashmap map[uint64][]*memSeries

func (m seriesHashmap) get(hash uint64, lset labels.Labels) *memSeries {
	for _, s := range m[hash] {
		if labels.Equal(s.lset, lset) {
			return s
		}
	}
	return nil
}

func (m seriesHashmap) set(hash uint64, s *memSeries) {
	intern.Intern(intern.Global, s.lset)

	l := m[hash]
	for i, prev := range l {
		if labels.Equal(prev.lset, s.lset) {
			l[i] = s
			return
		}
	}
	m[hash] = append(l, s)
}

func (m seriesHashmap) del(hash uint64, ref chunks.HeadSeriesRef) {
	var rem []*memSeries
	for _, s := range m[hash] {
		if s.ref != ref {
			rem = append(rem, s)
		} else {
			intern.Release(intern.Global, s.lset)
		}
	}
	if len(rem) == 0 {
		delete(m, hash)
	} else {
		m[hash] = rem
	}
}

const (
	// defaultStripeSize is the default number of entries to allocate in the
	// stripeSeries hash map.
	defaultStripeSize = 1 << 14
)

// stripeSeries locks modulo ranges of IDs and hashes to reduce lock contention.
// The locks are padded to not be on the same cache line. Filling the padded space
// with the maps was profiled to be slower  likely due to the additional pointer
// dereferences.
//
// This code is copied from the Prometheus TSDB.
type stripeSeries struct {
	size      int
	series    []map[chunks.HeadSeriesRef]*memSeries
	hashes    []seriesHashmap
	exemplars []map[chunks.HeadSeriesRef]*exemplar.Exemplar
	locks     []stripeLock
}

type stripeLock struct {
	sync.RWMutex
	// Padding to avoid multiple locks being on the same cache line.
	_ [40]byte
}

func newStripeSeries() *stripeSeries {
	stripeSize := defaultStripeSize
	s := &stripeSeries{
		size:      stripeSize,
		series:    make([]map[chunks.HeadSeriesRef]*memSeries, stripeSize),
		hashes:    make([]seriesHashmap, stripeSize),
		exemplars: make([]map[chunks.HeadSeriesRef]*exemplar.Exemplar, stripeSize),
		locks:     make([]stripeLock, stripeSize),
	}

	for i := range s.series {
		s.series[i] = map[chunks.HeadSeriesRef]*memSeries{}
	}
	for i := range s.hashes {
		s.hashes[i] = seriesHashmap{}
	}
	for i := range s.exemplars {
		s.exemplars[i] = map[chunks.HeadSeriesRef]*exemplar.Exemplar{}
	}
	return s
}

// gc garbage collects old chunks that are strictly before mint and removes
// series entirely that have no chunks left.
func (s *stripeSeries) gc(mint int64) map[chunks.HeadSeriesRef]struct{} {
	var (
		deleted = map[chunks.HeadSeriesRef]struct{}{}
	)

	// Run through all series and find series that haven't been written to
	// since mint. Mark those series as deleted and store their ID.
	for i := 0; i < s.size; i++ {
		s.locks[i].Lock()

		for _, series := range s.series[i] {
			series.Lock()
			seriesHash := series.lset.Hash()

			// If the series has received a write after mint, there's still
			// data and it's not completely gone yet.
			if series.lastTs >= mint || series.pendingCommit {
				series.willDelete = false
				series.Unlock()
				continue
			}

			// The series hasn't received any data and *might* be gone, but
			// we want to give it an opportunity to come back before marking
			// it as deleted, so we wait one more GC cycle.
			if !series.willDelete {
				series.willDelete = true
				series.Unlock()
				continue
			}

			// The series is gone entirely. We'll need to delete the label
			// hash (if one exists) so we'll obtain a lock for that too.
			j := int(seriesHash) & (s.size - 1)
			if i != j {
				s.locks[j].Lock()
			}

			deleted[series.ref] = struct{}{}
			delete(s.series[i], series.ref)
			s.hashes[j].del(seriesHash, series.ref)

			// Since the series is gone, we'll also delete
			// the latest stored exemplar.
			delete(s.exemplars[i], series.ref)

			if i != j {
				s.locks[j].Unlock()
			}

			series.Unlock()
		}

		s.locks[i].Unlock()
	}

	return deleted
}

func (s *stripeSeries) getByID(id chunks.HeadSeriesRef) *memSeries {
	i := id & chunks.HeadSeriesRef(s.size-1)

	s.locks[i].RLock()
	series := s.series[i][id]
	s.locks[i].RUnlock()

	return series
}

func (s *stripeSeries) getByHash(hash uint64, lset labels.Labels) *memSeries {
	i := hash & uint64(s.size-1)

	s.locks[i].RLock()
	series := s.hashes[i].get(hash, lset)
	s.locks[i].RUnlock()

	return series
}

func (s *stripeSeries) set(hash uint64, series *memSeries) {
	i := hash & uint64(s.size-1)
	s.locks[i].Lock()
	s.hashes[i].set(hash, series)
	s.locks[i].Unlock()

	i = uint64(series.ref) & uint64(s.size-1)
	s.locks[i].Lock()
	s.series[i][series.ref] = series
	s.locks[i].Unlock()
}

func (s *stripeSeries) getLatestExemplar(id chunks.HeadSeriesRef) *exemplar.Exemplar {
	i := id & chunks.HeadSeriesRef(s.size-1)

	s.locks[i].RLock()
	exemplar := s.exemplars[i][id]
	s.locks[i].RUnlock()

	return exemplar
}

func (s *stripeSeries) setLatestExemplar(id chunks.HeadSeriesRef, exemplar *exemplar.Exemplar) {
	i := id & chunks.HeadSeriesRef(s.size-1)

	// Make sure that's a valid series id and record its latest exemplar
	s.locks[i].Lock()
	if s.series[i][id] != nil {
		s.exemplars[i][id] = exemplar
	}
	s.locks[i].Unlock()
}

func (s *stripeSeries) iterator() *stripeSeriesIterator {
	return &stripeSeriesIterator{s}
}

// stripeSeriesIterator allows to iterate over series through a channel.
// The channel should always be completely consumed to not leak.
type stripeSeriesIterator struct {
	s *stripeSeries
}

func (it *stripeSeriesIterator) Channel() <-chan *memSeries {
	ret := make(chan *memSeries)

	go func() {
		for i := 0; i < it.s.size; i++ {
			it.s.locks[i].RLock()

			for _, series := range it.s.series[i] {
				series.Lock()

				j := int(series.lset.Hash()) & (it.s.size - 1)
				if i != j {
					it.s.locks[j].RLock()
				}

				ret <- series

				if i != j {
					it.s.locks[j].RUnlock()
				}
				series.Unlock()
			}

			it.s.locks[i].RUnlock()
		}

		close(ret)
	}()

	return ret
}

'''
'''--- pkg/metrics/wal/util.go ---
package wal

import (
	"path/filepath"
	"sync"

	"github.com/prometheus/prometheus/tsdb/record"
	"github.com/prometheus/prometheus/tsdb/wal"
)

type walReplayer struct {
	w wal.WriteTo
}

func (r walReplayer) Replay(dir string) error {
	w, err := wal.Open(nil, dir)
	if err != nil {
		return err
	}

	dir, startFrom, err := wal.LastCheckpoint(w.Dir())
	if err != nil && err != record.ErrNotFound {
		return err
	}

	if err == nil {
		sr, err := wal.NewSegmentsReader(dir)
		if err != nil {
			return err
		}

		err = r.replayWAL(wal.NewReader(sr))
		if closeErr := sr.Close(); closeErr != nil && err == nil {
			err = closeErr
		}
		if err != nil {
			return err
		}

		startFrom++
	}

	_, last, err := wal.Segments(w.Dir())
	if err != nil {
		return err
	}

	for i := startFrom; i <= last; i++ {
		s, err := wal.OpenReadSegment(wal.SegmentName(w.Dir(), i))
		if err != nil {
			return err
		}

		sr := wal.NewSegmentBufReader(s)
		err = r.replayWAL(wal.NewReader(sr))
		if closeErr := sr.Close(); closeErr != nil && err == nil {
			err = closeErr
		}
		if err != nil {
			return err
		}
	}

	return nil
}

func (r walReplayer) replayWAL(reader *wal.Reader) error {
	var dec record.Decoder

	for reader.Next() {
		rec := reader.Record()
		switch dec.Type(rec) {
		case record.Series:
			series, err := dec.Series(rec, nil)
			if err != nil {
				return err
			}
			r.w.StoreSeries(series, 0)
		case record.Samples:
			samples, err := dec.Samples(rec, nil)
			if err != nil {
				return err
			}
			r.w.Append(samples)
		case record.Exemplars:
			exemplars, err := dec.Exemplars(rec, nil)
			if err != nil {
				return err
			}
			r.w.AppendExemplars(exemplars)
		}
	}

	return nil
}

type walDataCollector struct {
	mut       sync.Mutex
	samples   []record.RefSample
	series    []record.RefSeries
	exemplars []record.RefExemplar
}

func (c *walDataCollector) AppendExemplars(exemplars []record.RefExemplar) bool {
	c.mut.Lock()
	defer c.mut.Unlock()

	c.exemplars = append(c.exemplars, exemplars...)
	return true
}

func (c *walDataCollector) Append(samples []record.RefSample) bool {
	c.mut.Lock()
	defer c.mut.Unlock()

	c.samples = append(c.samples, samples...)
	return true
}

func (c *walDataCollector) StoreSeries(series []record.RefSeries, _ int) {
	c.mut.Lock()
	defer c.mut.Unlock()

	c.series = append(c.series, series...)
}

func (c *walDataCollector) SeriesReset(_ int) {}

func (*walDataCollector) UpdateSeriesSegment([]record.RefSeries, int) {}

// SubDirectory returns the subdirectory within a Storage directory used for
// the Prometheus WAL.
func SubDirectory(base string) string {
	return filepath.Join(base, "wal")
}

'''
'''--- pkg/metrics/wal/wal.go ---
package wal

import (
	"context"
	"errors"
	"fmt"
	"math"
	"sync"
	"time"
	"unicode/utf8"

	"github.com/go-kit/log"
	"github.com/go-kit/log/level"
	"github.com/prometheus/client_golang/prometheus"
	"github.com/prometheus/prometheus/model/exemplar"
	"github.com/prometheus/prometheus/model/labels"
	"github.com/prometheus/prometheus/model/timestamp"
	"github.com/prometheus/prometheus/model/value"
	"github.com/prometheus/prometheus/storage"
	"github.com/prometheus/prometheus/tsdb"
	"github.com/prometheus/prometheus/tsdb/chunks"
	"github.com/prometheus/prometheus/tsdb/record"
	"github.com/prometheus/prometheus/tsdb/wal"
	"go.uber.org/atomic"
)

// ErrWALClosed is an error returned when a WAL operation can't run because the
// storage has already been closed.
var ErrWALClosed = fmt.Errorf("WAL storage closed")

type storageMetrics struct {
	r prometheus.Registerer

	numActiveSeries        prometheus.Gauge
	numDeletedSeries       prometheus.Gauge
	totalCreatedSeries     prometheus.Counter
	totalRemovedSeries     prometheus.Counter
	totalAppendedSamples   prometheus.Counter
	totalAppendedExemplars prometheus.Counter
}

func newStorageMetrics(r prometheus.Registerer) *storageMetrics {
	m := storageMetrics{r: r}
	m.numActiveSeries = prometheus.NewGauge(prometheus.GaugeOpts{
		Name: "agent_wal_storage_active_series",
		Help: "Current number of active series being tracked by the WAL storage",
	})

	m.numDeletedSeries = prometheus.NewGauge(prometheus.GaugeOpts{
		Name: "agent_wal_storage_deleted_series",
		Help: "Current number of series marked for deletion from memory",
	})

	m.totalCreatedSeries = prometheus.NewCounter(prometheus.CounterOpts{
		Name: "agent_wal_storage_created_series_total",
		Help: "Total number of created series appended to the WAL",
	})

	m.totalRemovedSeries = prometheus.NewCounter(prometheus.CounterOpts{
		Name: "agent_wal_storage_removed_series_total",
		Help: "Total number of created series removed from the WAL",
	})

	m.totalAppendedSamples = prometheus.NewCounter(prometheus.CounterOpts{
		Name: "agent_wal_samples_appended_total",
		Help: "Total number of samples appended to the WAL",
	})

	m.totalAppendedExemplars = prometheus.NewCounter(prometheus.CounterOpts{
		Name: "agent_wal_exemplars_appended_total",
		Help: "Total number of exemplars appended to the WAL",
	})

	if r != nil {
		r.MustRegister(
			m.numActiveSeries,
			m.numDeletedSeries,
			m.totalCreatedSeries,
			m.totalRemovedSeries,
			m.totalAppendedSamples,
			m.totalAppendedExemplars,
		)
	}

	return &m
}

func (m *storageMetrics) Unregister() {
	if m.r == nil {
		return
	}
	cs := []prometheus.Collector{
		m.numActiveSeries,
		m.numDeletedSeries,
		m.totalCreatedSeries,
		m.totalRemovedSeries,
		m.totalAppendedSamples,
		m.totalAppendedExemplars,
	}
	for _, c := range cs {
		m.r.Unregister(c)
	}
}

// Storage implements storage.Storage, and just writes to the WAL.
type Storage struct {
	// Embed Queryable/ChunkQueryable for compatibility, but don't actually implement it.
	storage.Queryable
	storage.ChunkQueryable

	// Operations against the WAL must be protected by a mutex so it doesn't get
	// closed in the middle of an operation. Other operations are concurrency-safe, so we
	// use a RWMutex to allow multiple usages of the WAL at once. If the WAL is closed, all
	// operations that change the WAL must fail.
	walMtx    sync.RWMutex
	walClosed bool

	path   string
	wal    *wal.WAL
	logger log.Logger

	appenderPool sync.Pool
	bufPool      sync.Pool

	ref    *atomic.Uint64
	series *stripeSeries

	deletedMtx sync.Mutex
	deleted    map[chunks.HeadSeriesRef]int // Deleted series, and what WAL segment they must be kept until.

	metrics *storageMetrics
}

// NewStorage makes a new Storage.
func NewStorage(logger log.Logger, registerer prometheus.Registerer, path string) (*Storage, error) {
	w, err := wal.NewSize(logger, registerer, SubDirectory(path), wal.DefaultSegmentSize, true)
	if err != nil {
		return nil, err
	}

	storage := &Storage{
		path:    path,
		wal:     w,
		logger:  logger,
		deleted: map[chunks.HeadSeriesRef]int{},
		series:  newStripeSeries(),
		metrics: newStorageMetrics(registerer),
		ref:     atomic.NewUint64(0),
	}

	storage.bufPool.New = func() interface{} {
		b := make([]byte, 0, 1024)
		return b
	}

	storage.appenderPool.New = func() interface{} {
		return &appender{
			w:         storage,
			series:    make([]record.RefSeries, 0, 100),
			samples:   make([]record.RefSample, 0, 100),
			exemplars: make([]record.RefExemplar, 0, 10),
		}
	}

	if err := storage.replayWAL(); err != nil {
		level.Warn(storage.logger).Log("msg", "encountered WAL read error, attempting repair", "err", err)

		var ce *wal.CorruptionErr
		if ok := errors.As(err, &ce); !ok {
			return nil, err
		}
		if err := w.Repair(ce); err != nil {
			// if repair fails, truncate everything in WAL
			level.Warn(storage.logger).Log("msg", "WAL repair failed, truncating!", "err", err)
			if e := w.Truncate(math.MaxInt); e != nil {
				level.Error(storage.logger).Log("msg", "WAL truncate failure", "err", e)
				return nil, fmt.Errorf("truncate corrupted WAL: %w", e)
			}
			if e := wal.DeleteCheckpoints(w.Dir(), math.MaxInt); e != nil {
				return nil, fmt.Errorf("delete WAL checkpoints: %w", e)
			}
			return nil, fmt.Errorf("repair corrupted WAL: %w", err)
		}
	}

	return storage, nil
}

func (w *Storage) replayWAL() error {
	w.walMtx.RLock()
	defer w.walMtx.RUnlock()

	if w.walClosed {
		return ErrWALClosed
	}

	level.Info(w.logger).Log("msg", "replaying WAL, this may take a while", "dir", w.wal.Dir())
	dir, startFrom, err := wal.LastCheckpoint(w.wal.Dir())
	if err != nil && err != record.ErrNotFound {
		return fmt.Errorf("find last checkpoint: %w", err)
	}

	if err == nil {
		sr, err := wal.NewSegmentsReader(dir)
		if err != nil {
			return fmt.Errorf("open checkpoint: %w", err)
		}
		defer func() {
			if err := sr.Close(); err != nil {
				level.Warn(w.logger).Log("msg", "error while closing the wal segments reader", "err", err)
			}
		}()

		// A corrupted checkpoint is a hard error for now and requires user
		// intervention. There's likely little data that can be recovered anyway.
		if err := w.loadWAL(wal.NewReader(sr)); err != nil {
			return fmt.Errorf("backfill checkpoint: %w", err)
		}
		startFrom++
		level.Info(w.logger).Log("msg", "WAL checkpoint loaded")
	}

	// Find the last segment.
	_, last, err := wal.Segments(w.wal.Dir())
	if err != nil {
		return fmt.Errorf("finding WAL segments: %w", err)
	}

	// Backfill segments from the most recent checkpoint onwards.
	for i := startFrom; i <= last; i++ {
		s, err := wal.OpenReadSegment(wal.SegmentName(w.wal.Dir(), i))
		if err != nil {
			return fmt.Errorf("open WAL segment %d: %w", i, err)
		}

		sr := wal.NewSegmentBufReader(s)
		err = w.loadWAL(wal.NewReader(sr))
		if err := sr.Close(); err != nil {
			level.Warn(w.logger).Log("msg", "error while closing the wal segments reader", "err", err)
		}
		if err != nil {
			return err
		}
		level.Info(w.logger).Log("msg", "WAL segment loaded", "segment", i, "maxSegment", last)
	}

	return nil
}

func (w *Storage) loadWAL(r *wal.Reader) (err error) {
	var (
		dec record.Decoder
	)

	var (
		decoded    = make(chan interface{}, 10)
		errCh      = make(chan error, 1)
		seriesPool = sync.Pool{
			New: func() interface{} {
				return []record.RefSeries{}
			},
		}
		samplesPool = sync.Pool{
			New: func() interface{} {
				return []record.RefSample{}
			},
		}
	)

	go func() {
		defer close(decoded)
		for r.Next() {
			rec := r.Record()
			switch dec.Type(rec) {
			case record.Series:
				series := seriesPool.Get().([]record.RefSeries)[:0]
				series, err = dec.Series(rec, series)
				if err != nil {
					errCh <- &wal.CorruptionErr{
						Err:     fmt.Errorf("decode series: %w", err),
						Segment: r.Segment(),
						Offset:  r.Offset(),
					}
					return
				}
				decoded <- series
			case record.Samples:
				samples := samplesPool.Get().([]record.RefSample)[:0]
				samples, err = dec.Samples(rec, samples)
				if err != nil {
					errCh <- &wal.CorruptionErr{
						Err:     fmt.Errorf("decode samples: %w", err),
						Segment: r.Segment(),
						Offset:  r.Offset(),
					}
				}
				decoded <- samples
			case record.Tombstones, record.Exemplars:
				// We don't care about decoding tombstones or exemplars
				// TODO: If decide to decode exemplars, we should make sure to prepopulate
				// stripeSeries.exemplars in the next block by using setLatestExemplar.
				continue
			default:
				errCh <- &wal.CorruptionErr{
					Err:     fmt.Errorf("invalid record type %v", dec.Type(rec)),
					Segment: r.Segment(),
					Offset:  r.Offset(),
				}
				return
			}
		}
	}()

	var biggestRef uint64 = w.ref.Load()

	for d := range decoded {
		switch v := d.(type) {
		case []record.RefSeries:
			for _, s := range v {
				// If this is a new series, create it in memory without a timestamp.
				// If we read in a sample for it, we'll use the timestamp of the latest
				// sample. Otherwise, the series is stale and will be deleted once
				// the truncation is performed.
				if w.series.getByID(s.Ref) == nil {
					series := &memSeries{ref: s.Ref, lset: s.Labels, lastTs: 0}
					w.series.set(s.Labels.Hash(), series)

					w.metrics.numActiveSeries.Inc()
					w.metrics.totalCreatedSeries.Inc()

					if biggestRef <= uint64(s.Ref) {
						biggestRef = uint64(s.Ref)
					}
				}
			}

			//nolint:staticcheck
			seriesPool.Put(v)
		case []record.RefSample:
			for _, s := range v {
				// Update the lastTs for the series based
				series := w.series.getByID(s.Ref)
				if series == nil {
					level.Warn(w.logger).Log("msg", "found sample referencing non-existing series, skipping")
					continue
				}

				series.Lock()
				if s.T > series.lastTs {
					series.lastTs = s.T
				}
				series.Unlock()
			}

			//nolint:staticcheck
			samplesPool.Put(v)
		default:
			panic(fmt.Errorf("unexpected decoded type: %T", d))
		}
	}

	w.ref.Store(biggestRef)

	select {
	case err := <-errCh:
		return err
	default:
	}

	if r.Err() != nil {
		return fmt.Errorf("read records: %w", r.Err())
	}

	return nil
}

// Directory returns the path where the WAL storage is held.
func (w *Storage) Directory() string {
	return w.path
}

// Appender returns a new appender against the storage.
func (w *Storage) Appender(_ context.Context) storage.Appender {
	return w.appenderPool.Get().(storage.Appender)
}

// StartTime always returns 0, nil. It is implemented for compatibility with
// Prometheus, but is unused in the agent.
func (*Storage) StartTime() (int64, error) {
	return 0, nil
}

// Truncate removes all data from the WAL prior to the timestamp specified by
// mint.
func (w *Storage) Truncate(mint int64) error {
	w.walMtx.RLock()
	defer w.walMtx.RUnlock()

	if w.walClosed {
		return ErrWALClosed
	}

	start := time.Now()

	// Garbage collect series that haven't received an update since mint.
	w.gc(mint)
	level.Info(w.logger).Log("msg", "series GC completed", "duration", time.Since(start))

	first, last, err := wal.Segments(w.wal.Dir())
	if err != nil {
		return fmt.Errorf("get segment range: %w", err)
	}

	// Start a new segment, so low ingestion volume instance don't have more WAL
	// than needed.
	err = w.wal.NextSegment()
	if err != nil {
		return fmt.Errorf("next segment: %w", err)
	}

	last-- // Never consider last segment for checkpoint.
	if last < 0 {
		return nil // no segments yet.
	}

	// The lower two thirds of segments should contain mostly obsolete samples.
	// If we have less than two segments, it's not worth checkpointing yet.
	last = first + (last-first)*2/3
	if last <= first {
		return nil
	}

	keep := func(id chunks.HeadSeriesRef) bool {
		if w.series.getByID(id) != nil {
			return true
		}

		w.deletedMtx.Lock()
		_, ok := w.deleted[id]
		w.deletedMtx.Unlock()
		return ok
	}
	if _, err = wal.Checkpoint(w.logger, w.wal, first, last, keep, mint); err != nil {
		return fmt.Errorf("create checkpoint: %w", err)
	}
	if err := w.wal.Truncate(last + 1); err != nil {
		// If truncating fails, we'll just try again at the next checkpoint.
		// Leftover segments will just be ignored in the future if there's a checkpoint
		// that supersedes them.
		level.Error(w.logger).Log("msg", "truncating segments failed", "err", err)
	}

	// The checkpoint is written and segments before it is truncated, so we no
	// longer need to track deleted series that are before it.
	w.deletedMtx.Lock()
	for ref, segment := range w.deleted {
		if segment < first {
			delete(w.deleted, ref)
			w.metrics.totalRemovedSeries.Inc()
		}
	}
	w.metrics.numDeletedSeries.Set(float64(len(w.deleted)))
	w.deletedMtx.Unlock()

	if err := wal.DeleteCheckpoints(w.wal.Dir(), last); err != nil {
		// Leftover old checkpoints do not cause problems down the line beyond
		// occupying disk space.
		// They will just be ignored since a higher checkpoint exists.
		level.Error(w.logger).Log("msg", "delete old checkpoints", "err", err)
	}

	level.Info(w.logger).Log("msg", "WAL checkpoint complete",
		"first", first, "last", last, "duration", time.Since(start))
	return nil
}

// gc removes data before the minimum timestamp from the head.
func (w *Storage) gc(mint int64) {
	deleted := w.series.gc(mint)
	w.metrics.numActiveSeries.Sub(float64(len(deleted)))

	_, last, _ := wal.Segments(w.wal.Dir())
	w.deletedMtx.Lock()
	defer w.deletedMtx.Unlock()

	// We want to keep series records for any newly deleted series
	// until we've passed the last recorded segment. The WAL will
	// still contain samples records with all of the ref IDs until
	// the segment's samples has been deleted from the checkpoint.
	//
	// If the series weren't kept on startup when the WAL was replied,
	// the samples wouldn't be able to be used since there wouldn't
	// be any labels for that ref ID.
	for ref := range deleted {
		w.deleted[ref] = last
	}

	w.metrics.numDeletedSeries.Set(float64(len(w.deleted)))
}

// WriteStalenessMarkers appends a staleness sample for all active series.
func (w *Storage) WriteStalenessMarkers(remoteTsFunc func() int64) error {
	var lastErr error
	var lastTs int64

	app := w.Appender(context.Background())
	it := w.series.iterator()
	for series := range it.Channel() {
		var (
			ref  = series.ref
			lset = series.lset
		)

		ts := timestamp.FromTime(time.Now())
		_, err := app.Append(storage.SeriesRef(ref), lset, ts, math.Float64frombits(value.StaleNaN))
		if err != nil {
			lastErr = err
		}

		// Remove millisecond precision; the remote write timestamp we get
		// only has second precision.
		lastTs = (ts / 1000) * 1000
	}

	if lastErr == nil {
		if err := app.Commit(); err != nil {
			return fmt.Errorf("failed to commit staleness markers: %w", err)
		}

		// Wait for remote write to write the lastTs, but give up after 1m
		level.Info(w.logger).Log("msg", "waiting for remote write to write staleness markers...")

		stopCh := time.After(1 * time.Minute)
		start := time.Now()

	Outer:
		for {
			select {
			case <-stopCh:
				level.Error(w.logger).Log("msg", "timed out waiting for staleness markers to be written")
				break Outer
			default:
				writtenTs := remoteTsFunc()
				if writtenTs >= lastTs {
					duration := time.Since(start)
					level.Info(w.logger).Log("msg", "remote write wrote staleness markers", "duration", duration)
					break Outer
				}

				level.Info(w.logger).Log("msg", "remote write hasn't written staleness markers yet", "remoteTs", writtenTs, "lastTs", lastTs)

				// Wait a bit before reading again
				time.Sleep(5 * time.Second)
			}
		}
	}

	return lastErr
}

// Close closes the storage and all its underlying resources.
func (w *Storage) Close() error {
	w.walMtx.Lock()
	defer w.walMtx.Unlock()

	if w.walClosed {
		return fmt.Errorf("already closed")
	}
	w.walClosed = true

	if w.metrics != nil {
		w.metrics.Unregister()
	}
	return w.wal.Close()
}

type appender struct {
	w         *Storage
	series    []record.RefSeries
	samples   []record.RefSample
	exemplars []record.RefExemplar
}

func (a *appender) Append(ref storage.SeriesRef, l labels.Labels, t int64, v float64) (storage.SeriesRef, error) {
	series := a.w.series.getByID(chunks.HeadSeriesRef(ref))
	if series == nil {
		// Ensure no empty or duplicate labels have gotten through. This mirrors the
		// equivalent validation code in the TSDB's headAppender.
		l = l.WithoutEmpty()
		if len(l) == 0 {
			return 0, fmt.Errorf("empty labelset: %w", tsdb.ErrInvalidSample)
		}

		if lbl, dup := l.HasDuplicateLabelNames(); dup {
			return 0, fmt.Errorf("label name %q is not unique: %w", lbl, tsdb.ErrInvalidSample)
		}

		var created bool
		series, created = a.getOrCreate(l)
		if created {
			a.series = append(a.series, record.RefSeries{
				Ref:    series.ref,
				Labels: l,
			})

			a.w.metrics.numActiveSeries.Inc()
			a.w.metrics.totalCreatedSeries.Inc()
		}
	}

	series.Lock()
	defer series.Unlock()

	// Update last recorded timestamp. Used by Storage.gc to determine if a
	// series is stale.
	series.updateTs(t)

	a.samples = append(a.samples, record.RefSample{
		Ref: series.ref,
		T:   t,
		V:   v,
	})

	a.w.metrics.totalAppendedSamples.Inc()
	return storage.SeriesRef(series.ref), nil
}

func (a *appender) getOrCreate(l labels.Labels) (series *memSeries, created bool) {
	hash := l.Hash()

	series = a.w.series.getByHash(hash, l)
	if series != nil {
		return series, false
	}

	ref := chunks.HeadSeriesRef(a.w.ref.Inc())
	series = &memSeries{ref: ref, lset: l}
	a.w.series.set(l.Hash(), series)
	return series, true
}

func (a *appender) AppendExemplar(ref storage.SeriesRef, _ labels.Labels, e exemplar.Exemplar) (storage.SeriesRef, error) {
	cref := chunks.HeadSeriesRef(ref)
	s := a.w.series.getByID(cref)
	if s == nil {
		return 0, fmt.Errorf("unknown series ref. when trying to add exemplar: %d", cref)
	}

	// Ensure no empty labels have gotten through.
	e.Labels = e.Labels.WithoutEmpty()

	if lbl, dup := e.Labels.HasDuplicateLabelNames(); dup {
		return 0, fmt.Errorf("label name %q is not unique: %w", lbl, tsdb.ErrInvalidExemplar)
	}

	// Exemplar label length does not include chars involved in text rendering such as quotes
	// equals sign, or commas. See definition of const ExemplarMaxLabelLength.
	labelSetLen := 0
	for _, l := range e.Labels {
		labelSetLen += utf8.RuneCountInString(l.Name)
		labelSetLen += utf8.RuneCountInString(l.Value)

		if labelSetLen > exemplar.ExemplarMaxLabelSetLength {
			return 0, storage.ErrExemplarLabelLength
		}
	}

	// Check for duplicate vs last stored exemplar for this series, and discard those.
	// Otherwise, record the current exemplar as the latest.
	// Prometheus returns 0 when encountering duplicates, so we do the same here.
	prevExemplar := a.w.series.getLatestExemplar(cref)
	if prevExemplar != nil && prevExemplar.Equals(e) {
		// Duplicate, don't return an error but don't accept the exemplar.
		return 0, nil
	}
	a.w.series.setLatestExemplar(cref, &e)

	a.exemplars = append(a.exemplars, record.RefExemplar{
		Ref:    cref,
		T:      e.Ts,
		V:      e.Value,
		Labels: e.Labels,
	})

	a.w.metrics.totalAppendedExemplars.Inc()
	return storage.SeriesRef(s.ref), nil
}

// Commit submits the collected samples and purges the batch.
func (a *appender) Commit() error {
	a.w.walMtx.RLock()
	defer a.w.walMtx.RUnlock()

	if a.w.walClosed {
		return ErrWALClosed
	}

	var encoder record.Encoder
	buf := a.w.bufPool.Get().([]byte)

	if len(a.series) > 0 {
		buf = encoder.Series(a.series, buf)
		if err := a.w.wal.Log(buf); err != nil {
			return err
		}
		buf = buf[:0]
	}

	if len(a.samples) > 0 {
		buf = encoder.Samples(a.samples, buf)
		if err := a.w.wal.Log(buf); err != nil {
			return err
		}
		buf = buf[:0]
	}

	if len(a.exemplars) > 0 {
		buf = encoder.Exemplars(a.exemplars, buf)
		if err := a.w.wal.Log(buf); err != nil {
			return err
		}
		buf = buf[:0]
	}

	//nolint:staticcheck
	a.w.bufPool.Put(buf)

	for _, sample := range a.samples {
		series := a.w.series.getByID(sample.Ref)
		if series != nil {
			series.Lock()
			series.pendingCommit = false
			series.Unlock()
		}
	}

	return a.Rollback()
}

func (a *appender) Rollback() error {
	a.series = a.series[:0]
	a.samples = a.samples[:0]
	a.exemplars = a.exemplars[:0]
	a.w.appenderPool.Put(a)
	return nil
}

'''
'''--- pkg/metrics/wal/wal_test.go ---
package wal

import (
	"context"
	"io/ioutil"
	"math"
	"os"
	"sort"
	"testing"
	"time"

	"github.com/go-kit/log"
	"github.com/grafana/agent/pkg/util"
	"github.com/prometheus/prometheus/model/exemplar"
	"github.com/prometheus/prometheus/model/labels"
	"github.com/prometheus/prometheus/model/value"
	"github.com/prometheus/prometheus/storage"
	"github.com/prometheus/prometheus/tsdb"
	"github.com/prometheus/prometheus/tsdb/chunks"
	"github.com/prometheus/prometheus/tsdb/record"
	"github.com/stretchr/testify/require"
)

func TestStorage_InvalidSeries(t *testing.T) {
	walDir, err := ioutil.TempDir(os.TempDir(), "wal")
	require.NoError(t, err)
	defer os.RemoveAll(walDir)

	s, err := NewStorage(log.NewNopLogger(), nil, walDir)
	require.NoError(t, err)
	defer func() {
		require.NoError(t, s.Close())
	}()

	app := s.Appender(context.Background())

	// Samples
	_, err = app.Append(0, labels.Labels{}, 0, 0)
	require.Error(t, err, "should reject empty labels")

	_, err = app.Append(0, labels.Labels{{Name: "a", Value: "1"}, {Name: "a", Value: "2"}}, 0, 0)
	require.Error(t, err, "should reject duplicate labels")

	// Sanity check: valid series
	sRef, err := app.Append(0, labels.Labels{{Name: "a", Value: "1"}}, 0, 0)
	require.NoError(t, err, "should not reject valid series")

	// Exemplars
	_, err = app.AppendExemplar(0, nil, exemplar.Exemplar{})
	require.Error(t, err, "should reject unknown series ref")

	e := exemplar.Exemplar{Labels: labels.Labels{{Name: "a", Value: "1"}, {Name: "a", Value: "2"}}}
	_, err = app.AppendExemplar(sRef, nil, e)
	require.ErrorIs(t, err, tsdb.ErrInvalidExemplar, "should reject duplicate labels")

	e = exemplar.Exemplar{Labels: labels.Labels{{Name: "a_somewhat_long_trace_id", Value: "nYJSNtFrFTY37VR7mHzEE/LIDt7cdAQcuOzFajgmLDAdBSRHYPDzrxhMA4zz7el8naI/AoXFv9/e/G0vcETcIoNUi3OieeLfaIRQci2oa"}}}
	_, err = app.AppendExemplar(sRef, nil, e)
	require.ErrorIs(t, err, storage.ErrExemplarLabelLength, "should reject too long label length")

	// Sanity check: valid exemplars
	e = exemplar.Exemplar{Labels: labels.Labels{{Name: "a", Value: "1"}}, Value: 20, Ts: 10, HasTs: true}
	_, err = app.AppendExemplar(sRef, nil, e)
	require.NoError(t, err, "should not reject valid exemplars")
}

func TestStorage(t *testing.T) {
	walDir, err := ioutil.TempDir(os.TempDir(), "wal")
	require.NoError(t, err)
	defer os.RemoveAll(walDir)

	s, err := NewStorage(log.NewNopLogger(), nil, walDir)
	require.NoError(t, err)
	defer func() {
		require.NoError(t, s.Close())
	}()

	app := s.Appender(context.Background())

	// Write some samples
	payload := buildSeries([]string{"foo", "bar", "baz"})
	for _, metric := range payload {
		metric.Write(t, app)
	}

	require.NoError(t, app.Commit())

	collector := walDataCollector{}
	replayer := walReplayer{w: &collector}
	require.NoError(t, replayer.Replay(s.wal.Dir()))

	names := []string{}
	for _, series := range collector.series {
		names = append(names, series.Labels.Get("__name__"))
	}
	require.Equal(t, payload.SeriesNames(), names)

	expectedSamples := payload.ExpectedSamples()
	actualSamples := collector.samples
	sort.Sort(byRefSample(actualSamples))
	require.Equal(t, expectedSamples, actualSamples)

	expectedExemplars := payload.ExpectedExemplars()
	actualExemplars := collector.exemplars
	sort.Sort(byRefExemplar(actualExemplars))
	require.Equal(t, expectedExemplars, actualExemplars)
}

func TestStorage_DuplicateExemplarsIgnored(t *testing.T) {
	walDir, err := ioutil.TempDir(os.TempDir(), "wal")
	require.NoError(t, err)
	defer os.RemoveAll(walDir)

	s, err := NewStorage(log.NewNopLogger(), nil, walDir)
	require.NoError(t, err)

	app := s.Appender(context.Background())

	sRef, err := app.Append(0, labels.Labels{{Name: "a", Value: "1"}}, 0, 0)
	require.NoError(t, err, "should not reject valid series")

	// If the Labels, Value or Timestamp are different than the last exemplar,
	// then a new one should be appended; Otherwise, it should be skipped.
	e := exemplar.Exemplar{Labels: labels.Labels{{Name: "a", Value: "1"}}, Value: 20, Ts: 10, HasTs: true}
	_, _ = app.AppendExemplar(sRef, nil, e)
	_, _ = app.AppendExemplar(sRef, nil, e)

	e.Labels = labels.Labels{{Name: "b", Value: "2"}}
	_, _ = app.AppendExemplar(sRef, nil, e)
	_, _ = app.AppendExemplar(sRef, nil, e)
	_, _ = app.AppendExemplar(sRef, nil, e)

	e.Value = 42
	_, _ = app.AppendExemplar(sRef, nil, e)
	_, _ = app.AppendExemplar(sRef, nil, e)

	e.Ts = 25
	_, _ = app.AppendExemplar(sRef, nil, e)
	_, _ = app.AppendExemplar(sRef, nil, e)

	require.NoError(t, app.Commit())
	collector := walDataCollector{}
	replayer := walReplayer{w: &collector}
	require.NoError(t, replayer.Replay(s.wal.Dir()))

	// We had 9 calls to AppendExemplar but only 4 of those should have gotten through
	require.Equal(t, 4, len(collector.exemplars))
}

func TestStorage_ExistingWAL(t *testing.T) {
	walDir, err := ioutil.TempDir(os.TempDir(), "wal")
	require.NoError(t, err)
	defer os.RemoveAll(walDir)

	s, err := NewStorage(log.NewNopLogger(), nil, walDir)
	require.NoError(t, err)

	app := s.Appender(context.Background())
	payload := buildSeries([]string{"foo", "bar", "baz", "blerg"})

	// Write half of the samples.
	for _, metric := range payload[0 : len(payload)/2] {
		metric.Write(t, app)
	}

	require.NoError(t, app.Commit())
	require.NoError(t, s.Close())

	// We need to wait a little bit for the previous store to finish
	// flushing.
	time.Sleep(time.Millisecond * 150)

	// Create a new storage, write the other half of samples.
	s, err = NewStorage(log.NewNopLogger(), nil, walDir)
	require.NoError(t, err)
	defer func() {
		require.NoError(t, s.Close())
	}()

	// Verify that the storage picked up existing series when it
	// replayed the WAL.
	for series := range s.series.iterator().Channel() {
		require.Greater(t, series.lastTs, int64(0), "series timestamp not updated")
	}

	app = s.Appender(context.Background())

	for _, metric := range payload[len(payload)/2:] {
		metric.Write(t, app)
	}

	require.NoError(t, app.Commit())

	collector := walDataCollector{}
	replayer := walReplayer{w: &collector}
	require.NoError(t, replayer.Replay(s.wal.Dir()))

	names := []string{}
	for _, series := range collector.series {
		names = append(names, series.Labels.Get("__name__"))
	}
	require.Equal(t, payload.SeriesNames(), names)

	expectedSamples := payload.ExpectedSamples()
	actualSamples := collector.samples
	sort.Sort(byRefSample(actualSamples))
	require.Equal(t, expectedSamples, actualSamples)

	expectedExemplars := payload.ExpectedExemplars()
	actualExemplars := collector.exemplars
	sort.Sort(byRefExemplar(actualExemplars))
	require.Equal(t, expectedExemplars, actualExemplars)
}

func TestStorage_ExistingWAL_RefID(t *testing.T) {
	l := util.TestLogger(t)

	walDir, err := ioutil.TempDir(os.TempDir(), "wal")
	require.NoError(t, err)
	defer os.RemoveAll(walDir)

	s, err := NewStorage(l, nil, walDir)
	require.NoError(t, err)

	app := s.Appender(context.Background())
	payload := buildSeries([]string{"foo", "bar", "baz", "blerg"})

	// Write all the samples
	for _, metric := range payload {
		metric.Write(t, app)
	}
	require.NoError(t, app.Commit())

	// Truncate the WAL to force creation of a new segment.
	require.NoError(t, s.Truncate(0))
	require.NoError(t, s.Close())

	// Create a new storage and see what the ref ID is initialized to.
	s, err = NewStorage(l, nil, walDir)
	require.NoError(t, err)
	defer require.NoError(t, s.Close())

	require.Equal(t, uint64(len(payload)), s.ref.Load(), "cached ref ID should be equal to the number of series written")
}

func TestStorage_Truncate(t *testing.T) {
	// Same as before but now do the following:
	// after writing all the data, forcefully create 4 more segments,
	// then do a truncate of a timestamp for _some_ of the data.
	// then read data back in. Expect to only get the latter half of data.
	walDir, err := ioutil.TempDir(os.TempDir(), "wal")
	require.NoError(t, err)
	defer os.RemoveAll(walDir)

	s, err := NewStorage(log.NewNopLogger(), nil, walDir)
	require.NoError(t, err)
	defer func() {
		require.NoError(t, s.Close())
	}()

	app := s.Appender(context.Background())

	payload := buildSeries([]string{"foo", "bar", "baz", "blerg"})

	for _, metric := range payload {
		metric.Write(t, app)
	}

	require.NoError(t, app.Commit())

	// Forefully create a bunch of new segments so when we truncate
	// there's enough segments to be considered for truncation.
	for i := 0; i < 5; i++ {
		require.NoError(t, s.wal.NextSegment())
	}

	// Truncate half of the samples, keeping only the second sample
	// per series.
	keepTs := payload[len(payload)-1].samples[0].ts + 1
	err = s.Truncate(keepTs)
	require.NoError(t, err)

	payload = payload.Filter(func(s sample) bool {
		return s.ts >= keepTs
	}, func(e exemplar.Exemplar) bool {
		return e.HasTs && e.Ts >= keepTs
	})
	expectedSamples := payload.ExpectedSamples()
	expectedExemplars := payload.ExpectedExemplars()

	// Read back the WAL, collect series and samples.
	collector := walDataCollector{}
	replayer := walReplayer{w: &collector}
	require.NoError(t, replayer.Replay(s.wal.Dir()))

	names := []string{}
	for _, series := range collector.series {
		names = append(names, series.Labels.Get("__name__"))
	}
	require.Equal(t, payload.SeriesNames(), names)

	actualSamples := collector.samples
	sort.Sort(byRefSample(actualSamples))
	require.Equal(t, expectedSamples, actualSamples)

	actualExemplars := collector.exemplars
	sort.Sort(byRefExemplar(actualExemplars))
	require.Equal(t, expectedExemplars, actualExemplars)
}

func TestStorage_WriteStalenessMarkers(t *testing.T) {
	walDir, err := ioutil.TempDir(os.TempDir(), "wal")
	require.NoError(t, err)
	defer os.RemoveAll(walDir)

	s, err := NewStorage(log.NewNopLogger(), nil, walDir)
	require.NoError(t, err)
	defer func() {
		require.NoError(t, s.Close())
	}()

	app := s.Appender(context.Background())

	// Write some samples
	payload := seriesList{
		{name: "foo", samples: []sample{{1, 10.0}, {10, 100.0}}},
		{name: "bar", samples: []sample{{2, 20.0}, {20, 200.0}}},
		{name: "baz", samples: []sample{{3, 30.0}, {30, 300.0}}},
	}
	for _, metric := range payload {
		metric.Write(t, app)
	}

	require.NoError(t, app.Commit())

	// Write staleness markers for every series
	require.NoError(t, s.WriteStalenessMarkers(func() int64 {
		// Pass math.MaxInt64 so it seems like everything was written already
		return math.MaxInt64
	}))

	// Read back the WAL, collect series and samples.
	collector := walDataCollector{}
	replayer := walReplayer{w: &collector}
	require.NoError(t, replayer.Replay(s.wal.Dir()))

	actual := collector.samples
	sort.Sort(byRefSample(actual))

	staleMap := map[chunks.HeadSeriesRef]bool{}
	for _, sample := range actual {
		if _, ok := staleMap[sample.Ref]; !ok {
			staleMap[sample.Ref] = false
		}
		if value.IsStaleNaN(sample.V) {
			staleMap[sample.Ref] = true
		}
	}

	for ref, v := range staleMap {
		require.True(t, v, "ref %d doesn't have stale marker", ref)
	}
}

func TestStorage_TruncateAfterClose(t *testing.T) {
	walDir, err := ioutil.TempDir(os.TempDir(), "wal")
	require.NoError(t, err)
	defer os.RemoveAll(walDir)

	s, err := NewStorage(log.NewNopLogger(), nil, walDir)
	require.NoError(t, err)

	require.NoError(t, s.Close())
	require.Error(t, ErrWALClosed, s.Truncate(0))
}

func TestGlobalReferenceID_Normal(t *testing.T) {
	walDir, _ := ioutil.TempDir(os.TempDir(), "wal")
	defer os.RemoveAll(walDir)

	s, _ := NewStorage(log.NewNopLogger(), nil, walDir)
	defer s.Close()
	app := s.Appender(context.Background())
	l := labels.New(labels.Label{
		Name:  "__name__",
		Value: "label1",
	})
	ref, err := app.Append(0, l, time.Now().UnixMilli(), 0.1)
	_ = app.Commit()
	require.NoError(t, err)
	require.True(t, ref == 1)
	ref2, err := app.Append(0, l, time.Now().UnixMilli(), 0.1)
	require.NoError(t, err)
	require.True(t, ref2 == 1)

	l2 := labels.New(labels.Label{
		Name:  "__name__",
		Value: "label2",
	})
	ref3, err := app.Append(0, l2, time.Now().UnixMilli(), 0.1)
	require.NoError(t, err)
	require.True(t, ref3 == 2)
}

func BenchmarkAppendExemplar(b *testing.B) {
	walDir, _ := ioutil.TempDir(os.TempDir(), "wal")
	defer os.RemoveAll(walDir)

	s, _ := NewStorage(log.NewNopLogger(), nil, walDir)
	defer s.Close()
	app := s.Appender(context.Background())
	sRef, _ := app.Append(0, labels.Labels{{Name: "a", Value: "1"}}, 0, 0)
	e := exemplar.Exemplar{Labels: labels.Labels{{Name: "a", Value: "1"}}, Value: 20, Ts: 10, HasTs: true}

	b.StartTimer()
	for i := 0; i < b.N; i++ {
		e.Ts = int64(i)
		_, _ = app.AppendExemplar(sRef, nil, e)
	}
	b.StopTimer()

	// Actually use appended exemplars in case they get eliminated
	_ = app.Commit()
}

type sample struct {
	ts  int64
	val float64
}

type series struct {
	name      string
	samples   []sample
	exemplars []exemplar.Exemplar

	ref *storage.SeriesRef
}

func (s *series) Write(t *testing.T, app storage.Appender) {
	t.Helper()

	lbls := labels.FromMap(map[string]string{"__name__": s.name})

	offset := 0
	if s.ref == nil {
		// Write first sample to get ref ID
		ref, err := app.Append(0, lbls, s.samples[0].ts, s.samples[0].val)
		require.NoError(t, err)

		s.ref = &ref
		offset = 1
	}

	// Write other data points with AddFast
	for _, sample := range s.samples[offset:] {
		_, err := app.Append(*s.ref, lbls, sample.ts, sample.val)
		require.NoError(t, err)
	}

	sRef := *s.ref
	for _, exemplar := range s.exemplars {
		var err error
		sRef, err = app.AppendExemplar(sRef, nil, exemplar)
		require.NoError(t, err)
	}
}

type seriesList []*series

// Filter creates a new seriesList with series filtered by a sample
// keep predicate function.
func (s seriesList) Filter(fn func(s sample) bool, fnExemplar func(e exemplar.Exemplar) bool) seriesList {
	var ret seriesList

	for _, entry := range s {
		var (
			samples   []sample
			exemplars []exemplar.Exemplar
		)

		for _, sample := range entry.samples {
			if fn(sample) {
				samples = append(samples, sample)
			}
		}

		for _, e := range entry.exemplars {
			if fnExemplar(e) {
				exemplars = append(exemplars, e)
			}
		}

		if len(samples) > 0 && len(exemplars) > 0 {
			ret = append(ret, &series{
				name:      entry.name,
				ref:       entry.ref,
				samples:   samples,
				exemplars: exemplars,
			})
		}
	}

	return ret
}

func (s seriesList) SeriesNames() []string {
	names := make([]string, 0, len(s))
	for _, series := range s {
		names = append(names, series.name)
	}
	return names
}

// ExpectedSamples returns the list of expected samples, sorted by ref ID and timestamp
func (s seriesList) ExpectedSamples() []record.RefSample {
	expect := []record.RefSample{}
	for _, series := range s {
		for _, sample := range series.samples {
			expect = append(expect, record.RefSample{
				Ref: chunks.HeadSeriesRef(*series.ref),
				T:   sample.ts,
				V:   sample.val,
			})
		}
	}
	sort.Sort(byRefSample(expect))
	return expect
}

// ExpectedExemplars returns the list of expected exemplars, sorted by ref ID and timestamp
func (s seriesList) ExpectedExemplars() []record.RefExemplar {
	expect := []record.RefExemplar{}
	for _, series := range s {
		for _, exemplar := range series.exemplars {
			expect = append(expect, record.RefExemplar{
				Ref:    chunks.HeadSeriesRef(*series.ref),
				T:      exemplar.Ts,
				V:      exemplar.Value,
				Labels: exemplar.Labels,
			})
		}
	}
	sort.Sort(byRefExemplar(expect))
	return expect
}

func buildSeries(nameSlice []string) seriesList {
	s := make(seriesList, 0, len(nameSlice))
	for i, n := range nameSlice {
		i++
		s = append(s, &series{
			name:    n,
			samples: []sample{{int64(i), float64(i * 10.0)}, {int64(i * 10), float64(i * 100.0)}},
			exemplars: []exemplar.Exemplar{
				{Labels: labels.Labels{{Name: "foobar", Value: "barfoo"}}, Value: float64(i * 10.0), Ts: int64(i), HasTs: true},
				{Labels: labels.Labels{{Name: "lorem", Value: "ipsum"}}, Value: float64(i * 100.0), Ts: int64(i * 10), HasTs: true},
			},
		})
	}
	return s
}

type byRefSample []record.RefSample

func (b byRefSample) Len() int      { return len(b) }
func (b byRefSample) Swap(i, j int) { b[i], b[j] = b[j], b[i] }
func (b byRefSample) Less(i, j int) bool {
	if b[i].Ref == b[j].Ref {
		return b[i].T < b[j].T
	}
	return b[i].Ref < b[j].Ref
}

type byRefExemplar []record.RefExemplar

func (b byRefExemplar) Len() int      { return len(b) }
func (b byRefExemplar) Swap(i, j int) { b[i], b[j] = b[j], b[i] }
func (b byRefExemplar) Less(i, j int) bool {
	if b[i].Ref == b[j].Ref {
		return b[i].T < b[j].T
	}
	return b[i].Ref < b[j].Ref
}

'''
'''--- pkg/operator/apis/monitoring/v1alpha1/deployment.go ---
package v1alpha1

import (
	"github.com/grafana/agent/pkg/operator/assets"
	promv1 "github.com/prometheus-operator/prometheus-operator/pkg/apis/monitoring/v1"
)

// Deployment is a set of discovered resources relative to a GrafanaAgent. The
// tree of resources contained in a Deployment form the resource hierarchy used
// for reconciling a GrafanaAgent.
type Deployment struct {
	// Root resource in the deployment.
	Agent *GrafanaAgent
	// Metrics resources discovered by Agent.
	Metrics []MetricsDeployment
	// Logs resources discovered by Agent.
	Logs []LogsDeployment
	// Integrations resources discovered by Agent.
	Integrations []IntegrationsDeployment
	// The full list of Secrets referenced by resources in the Deployment.
	Secrets assets.SecretStore
}

// MetricsDeployment is a set of discovered resources relative to a
// MetricsInstance.
type MetricsDeployment struct {
	Instance        *MetricsInstance
	ServiceMonitors []*promv1.ServiceMonitor
	PodMonitors     []*promv1.PodMonitor
	Probes          []*promv1.Probe
}

// LogsDeployment is a set of discovered resources relative to a LogsInstance.
type LogsDeployment struct {
	Instance *LogsInstance
	PodLogs  []*PodLogs
}

// IntegrationsDeployment is a set of discovered resources relative to an
// IntegrationsDeployment.
type IntegrationsDeployment struct {
	Instance *Integration

	// NOTE(rfratto): Integration doesn't have any children resources, but we
	// define a *Deployment type for consistency with Metrics and Logs.
}

'''
'''--- pkg/operator/apis/monitoring/v1alpha1/group.go ---
// +kubebuilder:object:generate=true
// +groupName=monitoring.grafana.com

package v1alpha1

import (
	"k8s.io/apimachinery/pkg/runtime/schema"
	"sigs.k8s.io/controller-runtime/pkg/scheme"
)

var (
	// SchemeGroupVersion is the group version used to register CRDs for this
	// package.
	SchemeGroupVersion = schema.GroupVersion{Group: "monitoring.grafana.com", Version: "v1alpha1"}

	// SchemeBuilder is used to add Go types to the GroupVersionKind scheme.
	SchemeBuilder = &scheme.Builder{GroupVersion: SchemeGroupVersion}

	// AddToScheme is required by client packages.
	AddToScheme = SchemeBuilder.AddToScheme
)

func init() {
	SchemeBuilder.Register(
		&GrafanaAgent{},
		&GrafanaAgentList{},
		&MetricsInstance{},
		&MetricsInstanceList{},
		&LogsInstance{},
		&LogsInstanceList{},
		&PodLogs{},
		&PodLogsList{},
		&Integration{},
		&IntegrationList{},
	)
}

'''
'''--- pkg/operator/apis/monitoring/v1alpha1/types.go ---
package v1alpha1

import (
	prom_v1 "github.com/prometheus-operator/prometheus-operator/pkg/apis/monitoring/v1"
	v1 "k8s.io/api/core/v1"
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
	"sigs.k8s.io/controller-runtime/pkg/client"
)

// +kubebuilder:object:root=true
// +kubebuilder:resource:path="grafanaagents"
// +kubebuilder:resource:singular="grafanaagent"
// +kubebuilder:resource:categories="agent-operator"

// GrafanaAgent defines a Grafana Agent deployment.
type GrafanaAgent struct {
	metav1.TypeMeta   `json:",inline"`
	metav1.ObjectMeta `json:"metadata,omitempty"`

	// Spec holds the specification of the desired behavior for the Grafana Agent
	// cluster.
	Spec GrafanaAgentSpec `json:"spec,omitempty"`
}

// MetricsInstanceSelector returns a selector to find MetricsInstances.
func (a *GrafanaAgent) MetricsInstanceSelector() ObjectSelector {
	return ObjectSelector{
		ObjectType:        &MetricsInstance{},
		ParentNamespace:   a.Namespace,
		NamespaceSelector: a.Spec.Metrics.InstanceNamespaceSelector,
		Labels:            a.Spec.Metrics.InstanceSelector,
	}
}

// LogsInstanceSelector returns a selector to find LogsInstances.
func (a *GrafanaAgent) LogsInstanceSelector() ObjectSelector {
	return ObjectSelector{
		ObjectType:        &LogsInstance{},
		ParentNamespace:   a.Namespace,
		NamespaceSelector: a.Spec.Logs.InstanceNamespaceSelector,
		Labels:            a.Spec.Logs.InstanceSelector,
	}
}

// IntegrationsSelector returns a selector to find Integrations.
func (a *GrafanaAgent) IntegrationsSelector() ObjectSelector {
	return ObjectSelector{
		ObjectType:        &Integration{},
		ParentNamespace:   a.Namespace,
		NamespaceSelector: a.Spec.Integrations.NamespaceSelector,
		Labels:            a.Spec.Integrations.Selector,
	}
}

// +kubebuilder:object:root=true

// GrafanaAgentList is a list of GrafanaAgents.
type GrafanaAgentList struct {
	metav1.TypeMeta `json:",inline"`
	metav1.ListMeta `json:"metadata,omitempty"`
	// Items is the list of GrafanaAgents.
	Items []*GrafanaAgent `json:"items"`
}

// GrafanaAgentSpec is a specification of the desired behavior of the Grafana
// Agent cluster.
type GrafanaAgentSpec struct {
	// LogLevel controls the log level of the generated pods. Defaults to "info" if not set.
	LogLevel string `json:"logLevel,omitempty"`
	// LogFormat controls the logging format of the generated pods. Defaults to "logfmt" if not set.
	LogFormat string `json:"logFormat,omitempty"`
	// APIServerConfig allows specifying a host and auth methods to access the
	// Kubernetes API server. If left empty, the Agent will assume that it is
	// running inside of the cluster and will discover API servers automatically
	// and use the pod's CA certificate and bearer token file at
	// /var/run/secrets/kubernetes.io/serviceaccount.
	APIServerConfig *prom_v1.APIServerConfig `json:"apiServer,omitempty"`
	// PodMetadata configures Labels and Annotations which are propagated to
	// created Grafana Agent pods.
	PodMetadata *prom_v1.EmbeddedObjectMetadata `json:"podMetadata,omitempty"`
	// Version of Grafana Agent to be deployed.
	Version string `json:"version,omitempty"`
	// Paused prevents actions except for deletion to be performed on the
	// underlying managed objects.
	Paused bool `json:"paused,omitempty"`
	// Image, when specified, overrides the image used to run the Agent. It
	// should be specified along with a tag. Version must still be set to ensure
	// the Grafana Agent Operator knows which version of Grafana Agent is being
	// configured.
	Image *string `json:"image,omitempty"`
	// ImagePullSecrets holds an optional list of references to secrets within
	// the same namespace to use for pulling the Grafana Agent image from
	// registries.
	// More info: https://kubernetes.io/docs/user-guide/images#specifying-imagepullsecrets-on-a-pod
	ImagePullSecrets []v1.LocalObjectReference `json:"imagePullSecrets,omitempty"`
	// Storage spec to specify how storage will be used.
	Storage *prom_v1.StorageSpec `json:"storage,omitempty"`
	// Volumes allows configuration of additional volumes on the output
	// StatefulSet definition. Volumes specified will be appended to other
	// volumes that are generated as a result of StorageSpec objects.
	Volumes []v1.Volume `json:"volumes,omitempty"`
	// VolumeMounts allows configuration of additional VolumeMounts on the output
	// StatefulSet definition. VolumEMounts specified will be appended to other
	// VolumeMounts in the Grafana Agent container that are generated as a result
	// of StorageSpec objects.
	VolumeMounts []v1.VolumeMount `json:"volumeMounts,omitempty"`
	// Resources holds requests and limits for individual pods.
	Resources v1.ResourceRequirements `json:"resources,omitempty"`
	// NodeSelector defines which nodes pods should be scheduling on.
	NodeSelector map[string]string `json:"nodeSelector,omitempty"`
	// ServiceAccountName is the name of the ServiceAccount to use for running Grafana Agent pods.
	ServiceAccountName string `json:"serviceAccountName,omitempty"`
	// Secrets is a list of secrets in the same namespace as the GrafanaAgent
	// object which will be mounted into each running Grafana Agent pod.
	// The secrets are mounted into /etc/grafana-agent/extra-secrets/<secret-name>.
	Secrets []string `json:"secrets,omitempty"`
	// ConfigMaps is a liset of config maps in the same namespace as the
	// GrafanaAgent object which will be mounted into each running Grafana Agent
	// pod.
	// The ConfigMaps are mounted into /etc/grafana-agent/extra-configmaps/<configmap-name>.
	ConfigMaps []string `json:"configMaps,omitempty"`
	// Affinity, if specified, controls pod scheduling constraints.
	Affinity *v1.Affinity `json:"affinity,omitempty"`
	// Tolerations, if specified, controls the pod's tolerations.
	Tolerations []v1.Toleration `json:"tolerations,omitempty"`
	// TopologySpreadConstraints, if specified, controls the pod's topology spread constraints.
	TopologySpreadConstraints []v1.TopologySpreadConstraint `json:"topologySpreadConstraints,omitempty"`
	// SecurityContext holds pod-level security attributes and common container
	// settings. When unspecified, defaults to the default PodSecurityContext.
	SecurityContext *v1.PodSecurityContext `json:"securityContext,omitempty"`
	// Containers allows injecting additional containers or modifying operator
	// generated containers. This can be used to allow adding an authentication
	// proxy to a Grafana Agent pod or to change the behavior of an
	// operator-generated container. Containers described here modify an operator
	// generated container if they share the same name and modifications are done
	// via a strategic merge patch. The current container names are:
	// `grafana-agent` and `config-reloader`. Overriding containers is entirely
	// outside the scope of what the Grafana Agent team will support and by doing
	// so, you accept that this behavior may break at any time without notice.
	Containers []v1.Container `json:"containers,omitempty"`
	// InitContainers allows adding initContainers to the pod definition. These
	// can be used to, for example, fetch secrets for injection into the Grafana
	// Agent configuration from external sources. Any errors during the execution
	// of an initContainer will lead to a restart of the pod.
	// More info: https://kubernetes.io/docs/concepts/workloads/pods/init-containers/
	// Using initContainers for any use case other than secret fetching is
	// entirely outside the scope of what the Grafana Agent maintainers will
	// support and by doing so, you accept that this behavior may break at any
	// time without notice.
	InitContainers []v1.Container `json:"initContainers,omitempty"`
	// PriorityClassName is the priority class assigned to pods.
	PriorityClassName string `json:"priorityClassName,omitempty"`
	// Port name used for the pods and governing service. This defaults to agent-metrics.
	PortName string `json:"portName,omitempty"`

	// Metrics controls the metrics subsystem of the Agent and settings
	// unique to metrics-specific pods that are deployed.
	Metrics MetricsSubsystemSpec `json:"metrics,omitempty"`

	// Logs controls the logging subsystem of the Agent and settings unique to
	// logging-specific pods that are deployed.
	Logs LogsSubsystemSpec `json:"logs,omitempty"`

	// Integrations controls the integration subsystem of the Agent and settings
	// unique to integration-specific pods that are deployed.
	Integrations IntegrationsSubsystemSpec `json:"integrations,omitempty"`

	// enableConfigReadAPI enables the read API for viewing currently running
	// config port 8080 on the agent.
	// +kubebuilder:default=false
	EnableConfigReadAPI bool `json:"enableConfigReadAPI,omitempty"`
}

// +kubebuilder:object:generate=false

// ObjectSelector is a set of selectors to use for finding an object in the
// resource hierarchy. When NamespaceSelector is nil, objects should be
// searched directly in the ParentNamespace.
type ObjectSelector struct {
	ObjectType        client.Object
	ParentNamespace   string
	NamespaceSelector *metav1.LabelSelector
	Labels            *metav1.LabelSelector
}

'''
'''--- pkg/operator/apis/monitoring/v1alpha1/types_integrations.go ---
package v1alpha1

import (
	corev1 "k8s.io/api/core/v1"
	apiextv1 "k8s.io/apiextensions-apiserver/pkg/apis/apiextensions/v1"
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
)

// IntegrationsSubsystemSpec defines global settings to apply across the
// integrations subsystem.
type IntegrationsSubsystemSpec struct {
	// Label selector to find Integration resources to run. When nil, no
	// integration resources will be defined.
	Selector *metav1.LabelSelector `json:"selector,omitempty"`

	// Label selector for namespaces to search when discovering integration
	// resources. If nil, integration resources are only discovered in the
	// namespace of the GrafanaAgent resource.
	//
	// Set to `{}` to search all namespaces.
	NamespaceSelector *metav1.LabelSelector `json:"namespaceSelector,omitempty"`
}

// +kubebuilder:object:root=true
// +kubebuilder:resource:path="integrations"
// +kubebuilder:resource:singular="integration"
// +kubebuilder:resource:categories="agent-operator"

// Integration runs a single Grafana Agent integration. Integrations that
// generate telemetry must be configured to send that telemetry somewhere; such
// as autoscrape for exporter-based integrations.
//
// Integrations have access to the LogsInstances and MetricsInstances in the
// same GrafanaAgent resource set, referenced by the <namespace>/<name> of the
// *Instance resource.
//
// For example, if there is a default/production MetricsInstance, you can
// configure a supported integration's autoscrape block with:
//
//     autoscrape:
//       enable: true
//       metrics_instance: default/production
//
// There is currently no way for telemetry created by an Operator-managed
// integration to be collected from outside of the integration itself.
type Integration struct {
	metav1.TypeMeta   `json:",inline"`
	metav1.ObjectMeta `json:"metadata,omitempty"`

	// Specifies the desired behavior of the Integration.
	Spec IntegrationSpec `json:"spec,omitempty"`
}

// IntegrationSpec specifies the desired behavior of a metrics
// integration.
type IntegrationSpec struct {
	// Name of the integration to run (e.g., "node_exporter", "mysqld_exporter").
	Name string `json:"name"`

	// Type informs Grafana Agent Operator how to manage the integration being
	// configured.
	Type IntegrationType `json:"type"`

	// +kubebuilder:validation:Type=object

	// The configuration for the named integration. Note that integrations are
	// deployed with the integrations-next feature flag, which has different
	// common settings:
	//
	//   https://grafana.com/docs/agent/latest/configuration/integrations/integrations-next/
	Config apiextv1.JSON `json:"config"`

	// An extra list of Volumes to be associated with the Grafana Agent pods
	// running this integration. Volume names will be mutated to be unique across
	// all Integrations. Note that the specified volumes should be able to
	// tolerate existing on multiple pods at once when type is daemonset.
	//
	// Don't use volumes for loading secrets/configMaps from the same namespace
	// as the Integration; use the secrets and configMaps fields instead.
	Volumes []corev1.Volume `json:"volumes,omitempty"`

	// An extra list of VolumeMounts to be associated with the Grafana Agent pods
	// running this integration. VolumeMount names will be mutated to be unique
	// across all used IntegrationSpecs.
	//
	// Mount paths should include the namespace/name of the Integration CR to
	// avoid potentially colliding with other resources.
	VolumeMounts []corev1.VolumeMount `json:"volumeMounts,omitempty"`

	// An extra list of keys from Secrets in the same namespace as the
	// Integration which will be mounted into the Grafana Agent pod running this
	// integration.
	//
	// Secrets will be mounted at
	// /etc/grafana-agent/integrations/secrets/<secret_namespace>/<secret_name>/<key>.
	Secrets []corev1.SecretKeySelector `json:"secrets,omitempty"`

	// An extra list of keys from ConfigMaps in the same namespace as the
	// Integration which will be mounted into the Grafana Agent pod running this
	// integration.
	//
	// ConfigMaps will be mounted at
	// /etc/grafana-agent/integrations/configMaps/<configmap_namespace>/<configmap_name>/<key>.
	ConfigMaps []corev1.ConfigMapKeySelector `json:"configMaps,omitempty"`
}

// IntegrationType determines specific behaviors of a configured integration.
type IntegrationType struct {
	// +kubebuilder:validation:Optional

	// When true, the configured integration should be run on every Node in the
	// cluster. This is required for integrations that generate Node-specific
	// metrics like node_exporter, otherwise it must be false to avoid generating
	// duplicate metrics.
	AllNodes bool `json:"allNodes"`

	// +kubebuilder:validation:Optional

	// Whether this integration can only be defined once for a Grafana Agent
	// process, such as statsd_exporter. It is invalid for a GrafanaAgent to
	// discover multiple unique Integrations with the same integration name
	// (i.e., a single GrafanaAgent cannot deploy two statsd_exporters).
	Unique bool `json:"unique"`
}

// +kubebuilder:object:root=true

// IntegrationList is a list of Integration.
type IntegrationList struct {
	metav1.TypeMeta `json:",inline"`
	metav1.ListMeta `json:"metadata,omitempty"`
	// Items is the list of Integration.
	Items []*Integration `json:"items"`
}

'''
'''--- pkg/operator/apis/monitoring/v1alpha1/types_logs.go ---
package v1alpha1

import (
	prom_v1 "github.com/prometheus-operator/prometheus-operator/pkg/apis/monitoring/v1"
	v1 "k8s.io/api/core/v1"
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
)

// LogsSubsystemSpec defines global settings to apply across the logging
// subsystem.
type LogsSubsystemSpec struct {
	// Global set of clients to use when a discovered LogsInstance does not
	// have any clients defined.
	Clients []LogsClientSpec `json:"clients,omitempty"`
	// LogsExternalLabelName is the name of the external label used to
	// denote Grafana Agent cluster. Defaults to "cluster." External label will
	// _not_ be added when value is set to the empty string.
	LogsExternalLabelName *string `json:"logsExternalLabelName,omitempty"`
	// InstanceSelector determines which LogInstances should be selected
	// for running. Each instance runs its own set of Prometheus components,
	// including service discovery, scraping, and remote_write.
	InstanceSelector *metav1.LabelSelector `json:"instanceSelector,omitempty"`
	// InstanceNamespaceSelector are the set of labels to determine which
	// namespaces to watch for LogInstances. If not provided, only checks own
	// namespace.
	InstanceNamespaceSelector *metav1.LabelSelector `json:"instanceNamespaceSelector,omitempty"`

	// IgnoreNamespaceSelectors, if true, will ignore NamespaceSelector settings
	// from the PodLogs configs, and they will only discover endpoints within
	// their current namespace.
	IgnoreNamespaceSelectors bool `json:"ignoreNamespaceSelectors,omitempty"`
	// EnforcedNamespaceLabel enforces adding a namespace label of origin for
	// each metric that is user-created. The label value will always be the
	// namespace of the object that is being created.
	EnforcedNamespaceLabel string `json:"enforcedNamespaceLabel,omitempty"`
}

// LogsClientSpec defines the client integration for logs, indicating which
// Loki server to send logs to.
type LogsClientSpec struct {
	// URL is the URL where Loki is listening. Must be a full HTTP URL, including
	// protocol. Required.
	// Example: https://logs-prod-us-central1.grafana.net/loki/api/v1/push.
	URL string `json:"url"`
	// Tenant ID used by default to push logs to Loki. If omitted assumes remote
	// Loki is running in single-tenant mode or an authentication layer is used
	// to inject an X-Scope-OrgID header.
	TenantID string `json:"tenantId,omitempty"`
	// Maximum amount of time to wait before sending a batch, even if that batch
	// isn't full.
	BatchWait string `json:"batchWait,omitempty"`
	// Maximum batch size (in bytes) of logs to accumulate before sending the
	// batch to Loki.
	BatchSize int `json:"batchSize,omitempty"`
	// BasicAuth for the Loki server.
	BasicAuth *prom_v1.BasicAuth `json:"basicAuth,omitempty"`
	// BearerToken used for remote_write.
	BearerToken string `json:"bearerToken,omitempty"`
	// BearerTokenFile used to read bearer token.
	BearerTokenFile string `json:"bearerTokenFile,omitempty"`
	// ProxyURL to proxy requests through. Optional.
	ProxyURL string `json:"proxyUrl,omitempty"`
	// TLSConfig to use for the client. Only used when the protocol of the URL
	// is https.
	TLSConfig *prom_v1.TLSConfig `json:"tlsConfig,omitempty"`
	// Configures how to retry requests to Loki when a request fails.
	// Defaults to a minPeriod of 500ms, maxPeriod of 5m, and maxRetries of 10.
	BackoffConfig *LogsBackoffConfigSpec `json:"backoffConfig,omitempty"`
	// ExternalLabels are labels to add to any time series when sending data to
	// Loki.
	ExternalLabels map[string]string `json:"externalLabels,omitempty"`
	// Maximum time to wait for a server to respond to a request.
	Timeout string `json:"timeout,omitempty"`
}

// LogsBackoffConfigSpec configures timing for retrying failed requests.
type LogsBackoffConfigSpec struct {
	// Initial backoff time between retries. Time between retries is
	// increased exponentially.
	MinPeriod string `json:"minPeriod,omitempty"`
	// Maximum backoff time between retries.
	MaxPeriod string `json:"maxPeriod,omitempty"`
	// Maximum number of retries to perform before giving up a request.
	MaxRetries int `json:"maxRetries,omitempty"`
}

// +kubebuilder:object:root=true
// +kubebuilder:resource:path="logsinstances"
// +kubebuilder:resource:singular="logsinstance"
// +kubebuilder:resource:categories="agent-operator"

// LogsInstance controls an individual logs instance within a Grafana Agent
// deployment.
type LogsInstance struct {
	metav1.TypeMeta   `json:",inline"`
	metav1.ObjectMeta `json:"metadata,omitempty"`

	// Spec holds the specification of the desired behavior for the logs
	// instance.
	Spec LogsInstanceSpec `json:"spec,omitempty"`
}

// PodLogsSelector returns the selector to discover PodLogs.
func (i *LogsInstance) PodLogsSelector() ObjectSelector {
	return ObjectSelector{
		ObjectType:        &PodLogs{},
		ParentNamespace:   i.Namespace,
		NamespaceSelector: i.Spec.PodLogsNamespaceSelector,
		Labels:            i.Spec.PodLogsSelector,
	}
}

// LogsInstanceSpec controls how an individual instance will be used to
// discover LogMonitors.
type LogsInstanceSpec struct {
	// Clients controls where logs are written to for this instance.
	Clients []LogsClientSpec `json:"clients,omitempty"`

	// Determines which PodLogs should be selected for including in this
	// instance.
	PodLogsSelector *metav1.LabelSelector `json:"podLogsSelector,omitempty"`
	// Set of labels to determine which namespaces should be watched
	// for PodLogs. If not provided, checks only namespace of the
	// instance.
	PodLogsNamespaceSelector *metav1.LabelSelector `json:"podLogsNamespaceSelector,omitempty"`

	// AdditionalScrapeConfigs allows specifying a key of a Secret containing
	// additional Grafana Agent logging scrape configurations. Scrape
	// configurations specified are appended to the configurations generated by
	// the Grafana Agent Operator.
	//
	// Job configurations specified must have the form as specified in the
	// official Promtail documentation:
	//
	// https://grafana.com/docs/loki/latest/clients/promtail/configuration/#scrape_configs
	//
	// As scrape configs are appended, the user is responsible to make sure it is
	// valid. Note that using this feature may expose the possibility to break
	// upgrades of Grafana Agent. It is advised to review both Grafana Agent and
	// Promtail release notes to ensure that no incompatible scrape configs are
	// going to break Grafana Agent after the upgrade.
	AdditionalScrapeConfigs *v1.SecretKeySelector `json:"additionalScrapeConfigs,omitempty"`

	// Configures how tailed targets will be watched.
	TargetConfig *LogsTargetConfigSpec `json:"targetConfig,omitempty"`
}

// LogsTargetConfigSpec configures how tailed targets are watched.
type LogsTargetConfigSpec struct {
	// Period to resync directories being watched and files being tailed to discover
	// new ones or stop watching removed ones.
	SyncPeriod string `json:"syncPeriod,omitempty"`
}

// +kubebuilder:object:root=true

// LogsInstanceList is a list of LogsInstance.
type LogsInstanceList struct {
	metav1.TypeMeta `json:",inline"`
	metav1.ListMeta `json:"metadata,omitempty"`
	// Items is the list of LogsInstance.
	Items []*LogsInstance `json:"items"`
}

// +kubebuilder:object:root=true
// +kubebuilder:resource:categories="agent-operator"

// PodLogs defines how to collect logs for a pod.
type PodLogs struct {
	metav1.TypeMeta   `json:",inline"`
	metav1.ObjectMeta `json:"metadata,omitempty"`

	// Spec holds the specification of the desired behavior for the PodLogs.
	Spec PodLogsSpec `json:"spec,omitempty"`
}

// PodLogsSpec defines how to collect logs for a pod.
type PodLogsSpec struct {
	// The label to use to retrieve the job name from.
	JobLabel string `json:"jobLabel,omitempty"`
	// PodTargetLabels transfers labels on the Kubernetes Pod onto the target.
	PodTargetLabels []string `json:"podTargetLabels,omitempty"`
	// Selector to select Pod objects. Required.
	Selector metav1.LabelSelector `json:"selector"`
	// Selector to select which namespaces the Pod objects are discovered from.
	NamespaceSelector prom_v1.NamespaceSelector `json:"namespaceSelector,omitempty"`

	// Pipeline stages for this pod. Pipeline stages allow for transforming and
	// filtering log lines.
	PipelineStages []*PipelineStageSpec `json:"pipelineStages,omitempty"`

	// RelabelConfigs to apply to logs before delivering.
	// Grafana Agent Operator automatically adds relabelings for a few standard
	// Kubernetes fields and replaces original scrape job name with
	// __tmp_logs_job_name.
	//
	// More info: https://grafana.com/docs/loki/latest/clients/promtail/configuration/#relabel_configs
	RelabelConfigs []*prom_v1.RelabelConfig `json:"relabelings,omitempty"`
}

// +kubebuilder:object:root=true

// PodLogsList is a list of PodLogs.
type PodLogsList struct {
	metav1.TypeMeta `json:",inline"`
	metav1.ListMeta `json:"metadata,omitempty"`
	// Items is the list of PodLogs.
	Items []*PodLogs `json:"items"`
}

// PipelineStageSpec defines an individual pipeline stage. Each stage type is
// mutually exclusive and no more than one may be set per stage.
//
// More information on pipelines can be found in the Promtail documentation:
// https://grafana.com/docs/loki/latest/clients/promtail/pipelines/
type PipelineStageSpec struct {
	// CRI is a parsing stage that reads log lines using the standard
	// CRI logging format. Supply cri: {} to enable.
	CRI *CRIStageSpec `json:"cri,omitempty"`
	// Docker is a parsing stage that reads log lines using the standard
	// Docker logging format. Supply docker: {} to enable.
	Docker *DockerStageSpec `json:"docker,omitempty"`
	// Drop is a filtering stage that lets you drop certain logs.
	Drop *DropStageSpec `json:"drop,omitempty"`
	// JSON is a parsing stage that reads the log line as JSON and accepts
	// JMESPath expressions to extract data.
	//
	// Information on JMESPath: http://jmespath.org/
	JSON *JSONStageSpec `json:"json,omitempty"`
	// LabelAllow is an action stage that only allows the provided labels to be
	// included in the label set that is sent to Loki with the log entry.
	LabelAllow []string `json:"labelAllow,omitempty"`
	// LabelDrop is an action stage that drops labels from the label set that
	// is sent to Loki with the log entry.
	LabelDrop []string `json:"labelDrop,omitempty"`
	// Labels is an action stage that takes data from the extracted map and
	// modifies the label set that is sent to Loki with the log entry.
	//
	// The key is REQUIRED and represents the name for the label that will
	// be created. Value is optional and will be the name from extracted data
	// to use for the value of the label. If the value is not provided, it
	// defaults to match the key.
	Labels map[string]string `json:"labels,omitempty"`
	// Match is a filtering stage that conditionally applies a set of stages
	// or drop entries when a log entry matches a configurable LogQL stream
	// selector and filter expressions.
	Match *MatchStageSpec `json:"match,omitempty"`
	// Metrics is an action stage that allows for defining and updating metrics
	// based on data from the extracted map. Created metrics are not pushed to
	// Loki or Prometheus and are instead exposed via the /metrics endpoint of
	// the Grafana Agent pod. The Grafana Agent Operator should be configured
	// with a MetricsInstance that discovers the logging DaemonSet to collect
	// metrics created by this stage.
	Metrics map[string]MetricsStageSpec `json:"metrics,omitempty"`
	// Multiline stage merges multiple lines into a multiline block before
	// passing it on to the next stage in the pipeline.
	Multiline *MultilineStageSpec `json:"multiline,omitempty"`
	// Output stage is an action stage that takes data from the extracted map and
	// changes the log line that will be sent to Loki.
	Output *OutputStageSpec `json:"output,omitempty"`
	// Pack is a transform stage that lets you embed extracted values and labels
	// into the log line by packing the log line and labels inside of a JSON
	// object.
	Pack *PackStageSpec `json:"pack,omitempty"`
	// Regex is a parsing stage that parses a log line using a regular
	// expression.  Named capture groups in the regex allows for adding data into
	// the extracted map.
	Regex *RegexStageSpec `json:"regex,omitempty"`
	// Replace is a parsing stage that parses a log line using a regular
	// expression and replaces the log line. Named capture groups in the regex
	// allows for adding data into the extracted map.
	Replace *ReplaceStageSpec `json:"replace,omitempty"`
	// Template is a transform stage that manipulates the values in the extracted
	// map using Go's template syntax.
	Template *TemplateStageSpec `json:"template,omitempty"`
	// Tenant is an action stage that sets the tenant ID for the log entry picking it from a
	// field in the extracted data map. If the field is missing, the default
	// LogsClientSpec.tenantId will be used.
	Tenant *TenantStageSpec `json:"tenant,omitempty"`
	// Timestamp is an action stage that can change the timestamp of a log line
	// before it is sent to Loki. If not present, the timestamp of a log line
	// defaults to the time when the log line was read.
	Timestamp *TimestampStageSpec `json:"timestamp,omitempty"`
}

// CRIStageSpec is a parsing stage that reads log lines using the standard CRI
// logging format. It needs no defined fields.
type CRIStageSpec struct{}

// DockerStageSpec is a parsing stage that reads log lines using the standard
// Docker logging format. It needs no defined fields.
type DockerStageSpec struct{}

// DropStageSpec is a filtering stage that lets you drop certain logs.
type DropStageSpec struct {
	// Name from the extract data to parse. If empty, uses the log message.
	Source string `json:"source,omitempty"`

	// RE2 regular exprssion.
	//
	// If source is provided, the regex will attempt
	// to match the source.
	//
	// If no source is provided, then the regex will attempt
	// to attach the log line.
	//
	// If the provided regex matches the log line or a provided source, the
	// line will be dropped.
	Expression string `json:"expression,omitempty"`

	// Value can only be specified when source is specified. If the value
	// provided is an exact match for the given source then the line will be
	// dropped.
	//
	// Mutually exclusive with expression.
	Value string `json:"value,omitempty"`

	// OlderThan will be parsed as a Go duration. If the log line's timestamp
	// is older than the current time minus the provided duration it will be
	// dropped.
	OlderThan string `json:"olderThan,omitempty"`

	// LongerThan will drop a log line if it its content is longer than this
	// value (in bytes). Can be expressed as an integer (8192) or a number with a
	// suffix (8kb).
	LongerThan string `json:"longerThan,omitempty"`

	// Every time a log line is dropped the metric logentry_dropped_lines_total
	// will be incremented. A "reason" label is added, and can be customized by
	// providing a custom value here. Defaults to "drop_stage."
	DropCounterReason string `json:"dropCounterReason,omitempty"`
}

// JSONStageSpec is a parsing stage that reads the log line as JSON and accepts
// JMESPath expressions to extract data.
type JSONStageSpec struct {
	// Name from the extracted data to parse as JSON. If empty, uses entire log
	// message.
	Source string `json:"source,omitempty"`

	// Set of the key/value pairs of JMESPath expressions. The key will be the
	// key in the extracted data while the expression will be the value,
	// evaluated as a JMESPath from the source data.
	//
	// Literal JMESPath exprssions can be done by wrapping a key in double
	// quotes, which then must be wrapped again in single quotes in YAML
	// so they get passed to the JMESPath parser.
	Expressions map[string]string `json:"expressions,omitempty"`
}

// MatchStageSpec is a filtering stage that conditionally applies a set of
// stages or drop entries when a log entry matches a configurable LogQL stream
// selector and filter expressions.
type MatchStageSpec struct {
	// LogQL stream selector and filter expressions. Required.
	Selector string `json:"selector"`

	// Names the pipeline. When defined, creates an additional label
	// in the pipeline_duration_seconds histogram, where the value is
	// concatenated with job_name using an underscore.
	PipelineName string `json:"pipelineName,omitempty"`

	// Determines what action is taken when the selector matches the log line.
	// Can be keep or drop. Defaults to keep. When set to drop, entries will be
	// dropped and no later metrics will be recorded.
	// Stages must be empty when dropping metrics.
	Action string `json:"action,omitempty"`

	// Every time a log line is dropped the metric logentry_dropped_lines_total
	// will be incremented. A "reason" label is added, and can be customized by
	// providing a custom value here. Defaults to "match_stage."
	DropCounterReason string `json:"dropCounterReason,omitempty"`

	// Nested set of pipeline stages to execute when action: keep and the log
	// line matches selector.
	//
	// An example value for stages may be:
	//
	//   stages: |
	//     - json: {}
	//     - labelAllow: [foo, bar]
	//
	// Note that stages is a string because SIG API Machinery does not
	// support recursive types, and so it cannot be validated for correctness. Be
	// careful not to mistype anything.
	Stages string `json:"stages,omitempty"`
}

// MetricsStageSpec is an action stage that allows for defining and updating
// metrics based on data from the extracted map. Created metrics are not pushed
// to Loki or Prometheus and are instead exposed via the /metrics endpoint of
// the Grafana Agent pod. The Grafana Agent Operator should be configured with
// a MetricsInstance that discovers the logging DaemonSet to collect metrics
// created by this stage.
type MetricsStageSpec struct {
	// The metric type to create. Must be one of counter, gauge, histogram.
	// Required.
	Type string `json:"type"`

	// Sets the description for the created metric.
	Description string `json:"description,omitempty"`

	// Sets the custom prefix name for the metric. Defaults to "promtail_custom_".
	Prefix string `json:"prefix,omitempty"`

	// Key from the extracted data map to use for the metric. Defaults to the
	// metrics name if not present.
	Source string `json:"source,omitempty"`

	// Label values on metrics are dynamic which can cause exported metrics
	// to go stale. To prevent unbounded cardinality, any metrics not updated
	// within MaxIdleDuration will be removed.
	//
	// Must be greater or equal to 1s. Defaults to 5m.
	MaxIdleDuration string `json:"maxIdleDuration,omitempty"`

	// If true all log lines will be counted without attempting to match the
	// source to the extracted map. Mutually exclusive with value.
	//
	// Only valid for type: counter.
	MatchAll *bool `json:"matchAll,omitempty"`

	// If true all log line bytes will be counted. Can only be set with
	// matchAll: true and action: add.
	//
	// Only valid for type: counter.
	CountEntryBytes *bool `json:"countEntryBytes,omitempty"`

	// Filters down source data and only changes the metric if the targeted
	// value exactly matches the provided string. If not present, all
	// data will match.
	Value string `json:"value,omitempty"`

	// The action to take against the metric. Required.
	//
	// Must be either "inc" or "add" for type: counter or type: histogram.
	// When type: gauge, must be one of "set", "inc", "dec", "add", or "sub".
	//
	// "add", "set", or "sub" requires the extracted value to be convertible
	// to a positive float.
	Action string `json:"action"`

	// Buckets to create. Bucket values must be convertible to float64s. Extremely
	// large or small numbers are subject to some loss of precision.
	// Only valid for type: histogram.
	Buckets []string `json:"buckets,omitempty"`
}

// MultilineStageSpec merges multiple lines into a multiline block before
// passing it on to the next stage in the pipeline.
type MultilineStageSpec struct {
	// RE2 regular expression. Creates a new multiline block when matched.
	// Required.
	FirstLine string `json:"firstLine"`

	// Maximum time to wait before passing on the multiline block to the next
	// stage if no new lines are received. Defaults to 3s.
	MaxWaitTime string `json:"maxWaitTime,omitempty"`

	// Maximum number of lines a block can have. A new block is started if
	// the number of lines surpasses this value. Defaults to 128.
	MaxLines int `json:"maxLines,omitempty"`
}

// OutputStageSpec is an action stage that takes data from the extracted map
// and changes the log line that will be sent to Loki.
type OutputStageSpec struct {
	// Name from extract data to use for the log entry. Required.
	Source string `json:"source"`
}

// PackStageSpec is a transform stage that lets you embed extracted values and
// labels into the log line by packing the log line and labels inside of a JSON
// object.
type PackStageSpec struct {
	// Name from extracted data or line labels. Requiried.
	// Labels provided here are automatically removed from output labels.
	Labels []string `json:"labels"`

	// If the resulting log line should use any existing timestamp or use time.Now()
	// when the line was created. Set to true when combining several log streams from
	// different containers to avoid out of order errors.
	IngestTimestamp bool `json:"ingestTimestamp,omitempty"`
}

// RegexStageSpec is a parsing stage that parses a log line using a regular
// expression. Named capture groups in the regex allows for adding data into
// the extracted map.
type RegexStageSpec struct {
	// Name from extracted data to parse. If empty, defaults to using the log
	// message.
	Source string `json:"source,omitempty"`

	// RE2 regular expression. Each capture group MUST be named. Required.
	Expression string `json:"expression"`
}

// ReplaceStageSpec is a parsing stage that parses a log line using a regular
// expression and replaces the log line. Named capture groups in the regex
// allows for adding data into the extracted map.
type ReplaceStageSpec struct {
	// Name from extracted data to parse. If empty, defaults to using the log
	// message.
	Source string `json:"source,omitempty"`

	// RE2 regular expression. Each capture group MUST be named. Required.
	Expression string `json:"expression"`

	// Value to replace the captured group with.
	Replace string `json:"replace,omitempty"`
}

// TemplateStageSpec is a transform stage that manipulates the values in the
// extracted map using Go's template syntax.
type TemplateStageSpec struct {
	// Name from extracted data to parse. Required. If empty, defaults to using
	// the log message.
	Source string `json:"source"`

	// Go template string to use. Required. In additional to normal template
	// functions, ToLower, ToUpper, Replace, Trim, TrimLeft, TrimRight,
	// TrimPrefix, and TrimSpace are also available.
	Template string `json:"template"`
}

// TenantStageSpec is an action stage that sets the tenant ID for the log entry
// picking it from a field in the extracted data map.
type TenantStageSpec struct {
	// Name from extracted data to use as the tenant ID. Mutually exclusive with
	// value.
	Source string `json:"source,omitempty"`

	// Value to use for the template ID. Useful when this stage is used within a
	// conditional pipeline such as match. Mutually exclusive with source.
	Value string `json:"value,omitempty"`
}

// TimestampStageSpec is an action stage that can change the timestamp of a log
// line before it is sent to Loki.
type TimestampStageSpec struct {
	// Name from extracted data to use as the timestamp. Required.
	Source string `json:"source"`

	// Determines format of the time string. Required. Can be one of:
	// ANSIC, UnixDate, RubyDate, RFC822, RFC822Z, RFC850, RFC1123, RFC1123Z,
	// RFC3339, RFC3339Nano, Unix, UnixMs, UnixUs, UnixNs.
	Format string `json:"format"`

	// Fallback formats to try if format fails.
	FallbackFormats []string `json:"fallbackFormats,omitempty"`

	// IANA Timezone Database string.
	Location string `json:"location,omitempty"`

	// Action to take when the timestamp can't be extracted or parsed.
	// Can be skip or fudge. Defaults to fudge.
	ActionOnFailure string `json:"actionOnFailure,omitempty"`
}

'''
'''--- pkg/operator/apis/monitoring/v1alpha1/types_metrics.go ---
package v1alpha1

import (
	prom_v1 "github.com/prometheus-operator/prometheus-operator/pkg/apis/monitoring/v1"
	v1 "k8s.io/api/core/v1"
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
)

// MetricsSubsystemSpec defines global settings to apply across the
// Metrics subsystem.
type MetricsSubsystemSpec struct {
	// RemoteWrite controls default remote_write settings for all instances. If
	// an instance does not provide its own remoteWrite settings, these will be
	// used instead.
	RemoteWrite []RemoteWriteSpec `json:"remoteWrite,omitempty"`
	// Replicas of each shard to deploy for metrics pods. Number of replicas
	// multiplied by the number of shards is the total number of pods created.
	Replicas *int32 `json:"replicas,omitempty"`
	// Shards to distribute targets onto. Number of replicas multiplied by the
	// number of shards is the total number of pods created. Note that scaling
	// down shards will not reshard data onto remaining instances, it must be
	// manually moved. Increasing shards will not reshard data either but it will
	// continue to be available from the same instances. Sharding is performed on
	// the content of the __address__ target meta-label.
	Shards *int32 `json:"shards,omitempty"`
	// ReplicaExternalLabelName is the name of the metrics external label used
	// to denote replica name. Defaults to __replica__. External label will _not_
	// be added when value is set to the empty string.
	ReplicaExternalLabelName *string `json:"replicaExternalLabelName,omitempty"`
	// MetricsExternalLabelName is the name of the external label used to
	// denote Grafana Agent cluster. Defaults to "cluster." External label will
	// _not_ be added when value is set to the empty string.
	MetricsExternalLabelName *string `json:"metricsExternalLabelName,omitempty"`
	// ScrapeInterval is the time between consecutive scrapes.
	ScrapeInterval string `json:"scrapeInterval,omitempty"`
	// ScrapeTimeout is the time to wait for a target to respond before marking a
	// scrape as failed.
	ScrapeTimeout string `json:"scrapeTimeout,omitempty"`
	// ExternalLabels are labels to add to any time series when sending data over
	// remote_write.
	ExternalLabels map[string]string `json:"externalLabels,omitempty"`
	// ArbitraryFSAccessThroughSMs configures whether configuration based on a
	// ServiceMonitor can access arbitrary files on the file system of the
	// Grafana Agent container e.g. bearer token files.
	ArbitraryFSAccessThroughSMs prom_v1.ArbitraryFSAccessThroughSMsConfig `json:"arbitraryFSAccessThroughSMs,omitempty"`
	// OverrideHonorLabels, if true, overrides all configured honor_labels read
	// from ServiceMonitor or PodMonitor to false.
	OverrideHonorLabels bool `json:"overrideHonorLabels,omitempty"`
	// OverrideHonorTimestamps allows to globally enforce honoring timestamps in all scrape configs.
	OverrideHonorTimestamps bool `json:"overrideHonorTimestamps,omitempty"`
	// IgnoreNamespaceSelectors, if true, will ignore NamespaceSelector settings
	// from the PodMonitor and ServiceMonitor configs, and they will only
	// discover endpoints within their current namespace.
	IgnoreNamespaceSelectors bool `json:"ignoreNamespaceSelectors,omitempty"`
	// EnforcedNamespaceLabel enforces adding a namespace label of origin for
	// each metric that is user-created. The label value will always be the
	// namespace of the object that is being created.
	EnforcedNamespaceLabel string `json:"enforcedNamespaceLabel,omitempty"`
	// EnforcedSampleLimit defines global limit on the number of scraped samples
	// that will be accepted. This overrides any SampleLimit set per
	// ServiceMonitor and/or PodMonitor. It is meant to be used by admins to
	// enforce the SampleLimit to keep the overall number of samples and series
	// under the desired limit. Note that if a SampleLimit from a ServiceMonitor
	// or PodMonitor is lower, that value will be used instead.
	EnforcedSampleLimit *uint64 `json:"enforcedSampleLimit,omitempty"`
	// EnforcedTargetLimit defines a global limit on the number of scraped
	// targets. This overrides any TargetLimit set per ServiceMonitor and/or
	// PodMonitor. It is meant to be used by admins to enforce the TargetLimit to
	// keep the overall number of targets under the desired limit. Note that if a
	// TargetLimit from a ServiceMonitor or PodMonitor is higher, that value will
	// be used instead.
	EnforcedTargetLimit *uint64 `json:"enforcedTargetLimit,omitempty"`

	// InstanceSelector determines which MetricsInstances should be selected
	// for running. Each instance runs its own set of Metrics components,
	// including service discovery, scraping, and remote_write.
	InstanceSelector *metav1.LabelSelector `json:"instanceSelector,omitempty"`
	// InstanceNamespaceSelector are the set of labels to determine which
	// namespaces to watch for MetricsInstances. If not provided, only checks own namespace.
	InstanceNamespaceSelector *metav1.LabelSelector `json:"instanceNamespaceSelector,omitempty"`
}

// RemoteWriteSpec defines the remote_write configuration for Prometheus.
type RemoteWriteSpec struct {
	// Name of the remote_write queue. Must be unique if specified. The name is
	// used in metrics and logging in order to differentiate queues.
	Name string `json:"name,omitempty"`
	// URL of the endpoint to send samples to.
	URL string `json:"url"`
	// RemoteTimeout is the timeout for requests to the remote_write endpoint.
	RemoteTimeout string `json:"remoteTimeout,omitempty"`
	// Headers is a set of custom HTTP headers to be sent along with each
	// remote_write request. Be aware that any headers set by Grafana Agent
	// itself can't be overwritten.
	Headers map[string]string `json:"headers,omitempty"`
	// WriteRelabelConfigs holds relabel_configs to relabel samples before they are
	// sent to the remote_write endpoint.
	WriteRelabelConfigs []prom_v1.RelabelConfig `json:"writeRelabelConfigs,omitempty"`
	// BasicAuth for the URL.
	BasicAuth *prom_v1.BasicAuth `json:"basicAuth,omitempty"`
	// BearerToken used for remote_write.
	BearerToken string `json:"bearerToken,omitempty"`
	// BearerTokenFile used to read bearer token.
	BearerTokenFile string `json:"bearerTokenFile,omitempty"`
	// SigV4 configures SigV4-based authentication to the remote_write endpoint.
	// Will be used if SigV4 is defined, even with an empty object.
	SigV4 *SigV4Config `json:"sigv4,omitempty"`
	// TLSConfig to use for remote_write.
	TLSConfig *prom_v1.TLSConfig `json:"tlsConfig,omitempty"`
	// ProxyURL to proxy requests through. Optional.
	ProxyURL string `json:"proxyUrl,omitempty"`
	// QueueConfig allows tuning of the remote_write queue parameters.
	QueueConfig *QueueConfig `json:"queueConfig,omitempty"`
	// MetadataConfig configures the sending of series metadata to remote storage.
	MetadataConfig *MetadataConfig `json:"metadataConfig,omitempty"`
}

// SigV4Config specifies configuration to perform SigV4 authentication.
type SigV4Config struct {
	// Region of the AWS endpoint. If blank, the region from the default
	// credentials chain is used.
	Region string `json:"region,omitempty"`
	// AccessKey holds the secret of the AWS API access key to use for signing.
	// If not provided, The environment variable AWS_ACCESS_KEY_ID is used.
	AccessKey *v1.SecretKeySelector `json:"accessKey,omitempty"`
	// SecretKey of the AWS API to use for signing. If blank, the environment
	// variable AWS_SECRET_ACCESS_KEY is used.
	SecretKey *v1.SecretKeySelector `json:"secretKey,omitempty"`
	// Profile is the named AWS profile to use for authentication.
	Profile string `json:"profile,omitempty"`
	// RoleARN is the AWS Role ARN to use for authentication, as an alternative
	// for using the AWS API keys.
	RoleARN string `json:"roleARN,omitempty"`
}

// QueueConfig allows the tuning of remote_write queue_config parameters.
type QueueConfig struct {
	// Capacity is the number of samples to buffer per shard before we start dropping them.
	Capacity int `json:"capacity,omitempty"`
	// MinShards is the minimum number of shards, i.e. amount of concurrency.
	MinShards int `json:"minShards,omitempty"`
	// MaxShards is the maximum number of shards, i.e. amount of concurrency.
	MaxShards int `json:"maxShards,omitempty"`
	// MaxSamplesPerSend is the maximum number of samples per send.
	MaxSamplesPerSend int `json:"maxSamplesPerSend,omitempty"`
	// BatchSendDeadline is the maximum time a sample will wait in buffer.
	BatchSendDeadline string `json:"batchSendDeadline,omitempty"`
	// MaxRetries is the maximum number of times to retry a batch on recoverable errors.
	MaxRetries int `json:"maxRetries,omitempty"`
	// MinBackoff is the initial retry delay. Gets doubled for every retry.
	MinBackoff string `json:"minBackoff,omitempty"`
	// MaxBackoff is the maximum retry delay.
	MaxBackoff string `json:"maxBackoff,omitempty"`
	// RetryOnRateLimit retries requests when encountering rate limits.
	RetryOnRateLimit bool `json:"retryOnRateLimit,omitempty"`
}

// MetadataConfig configures the sending of series metadata to remote storage.
type MetadataConfig struct {
	// Send enables metric metadata to be sent to remote storage.
	Send bool `json:"send,omitempty"`
	// SendInterval controls how frequently metric metadata is sent to remote storage.
	SendInterval string `json:"sendInterval,omitempty"`
}

// +kubebuilder:object:root=true
// +kubebuilder:resource:path="metricsinstances"
// +kubebuilder:resource:singular="metricsinstance"
// +kubebuilder:resource:categories="agent-operator"

// MetricsInstance controls an individual Metrics instance within a
// Grafana Agent deployment.
type MetricsInstance struct {
	metav1.TypeMeta   `json:",inline"`
	metav1.ObjectMeta `json:"metadata,omitempty"`

	// Spec holds the specification of the desired behavior for the Metrics
	// instance.
	Spec MetricsInstanceSpec `json:"spec,omitempty"`
}

// ServiceMonitorSelector returns a selector to find ServiceMonitors.
func (p *MetricsInstance) ServiceMonitorSelector() ObjectSelector {
	return ObjectSelector{
		ObjectType:        &prom_v1.ServiceMonitor{},
		ParentNamespace:   p.Namespace,
		NamespaceSelector: p.Spec.ServiceMonitorNamespaceSelector,
		Labels:            p.Spec.ServiceMonitorSelector,
	}
}

// PodMonitorSelector returns a selector to find PodMonitors.
func (p *MetricsInstance) PodMonitorSelector() ObjectSelector {
	return ObjectSelector{
		ObjectType:        &prom_v1.PodMonitor{},
		ParentNamespace:   p.Namespace,
		NamespaceSelector: p.Spec.PodMonitorNamespaceSelector,
		Labels:            p.Spec.PodMonitorSelector,
	}
}

// ProbeSelector returns a selector to find Probes.
func (p *MetricsInstance) ProbeSelector() ObjectSelector {
	return ObjectSelector{
		ObjectType:        &prom_v1.Probe{},
		ParentNamespace:   p.Namespace,
		NamespaceSelector: p.Spec.ProbeNamespaceSelector,
		Labels:            p.Spec.ProbeSelector,
	}
}

// MetricsInstanceSpec controls how an individual instance will be used to discover PodMonitors.
type MetricsInstanceSpec struct {
	// WALTruncateFrequency specifies how frequently the WAL truncation process
	// should run. Higher values causes the WAL to increase and for old series to
	// stay in the WAL for longer, but reduces the chances of data loss when
	// remote_write is failing for longer than the given frequency.
	WALTruncateFrequency string `json:"walTruncateFrequency,omitempty"`
	// MinWALTime is the minimum amount of time series and samples may exist in
	// the WAL before being considered for deletion.
	MinWALTime string `json:"minWALTime,omitempty"`
	// MaxWALTime is the maximum amount of time series and asmples may exist in
	// the WAL before being forcibly deleted.
	MaxWALTime string `json:"maxWALTime,omitempty"`
	// RemoteFlushDeadline is the deadline for flushing data when an instance
	// shuts down.
	RemoteFlushDeadline string `json:"remoteFlushDeadline,omitempty"`
	// WriteStaleOnShutdown writes staleness markers on shutdown for all series.
	WriteStaleOnShutdown *bool `json:"writeStaleOnShutdown,omitempty"`
	// ServiceMonitorSelector determines which ServiceMonitors should be selected
	// for target discovery.
	ServiceMonitorSelector *metav1.LabelSelector `json:"serviceMonitorSelector,omitempty"`
	// ServiceMonitorNamespaceSelector are the set of labels to determine which
	// namespaces to watch for ServiceMonitor discovery. If nil, only checks own
	// namespace.
	ServiceMonitorNamespaceSelector *metav1.LabelSelector `json:"serviceMonitorNamespaceSelector,omitempty"`
	// PodMonitorSelector determines which PodMonitors should be selected for target
	// discovery. Experimental.
	PodMonitorSelector *metav1.LabelSelector `json:"podMonitorSelector,omitempty"`
	// PodMonitorNamespaceSelector are the set of labels to determine which
	// namespaces to watch for PodMonitor discovery. If nil, only checks own
	// namespace.
	PodMonitorNamespaceSelector *metav1.LabelSelector `json:"podMonitorNamespaceSelector,omitempty"`
	// ProbeSelector determines which Probes should be selected for target
	// discovery.
	ProbeSelector *metav1.LabelSelector `json:"probeSelector,omitempty"`
	// ProbeNamespaceSelector are the set of labels to determine which namespaces
	// to watch for Probe discovery. If nil, only checks own namespace.
	ProbeNamespaceSelector *metav1.LabelSelector `json:"probeNamespaceSelector,omitempty"`
	// RemoteWrite controls remote_write settings for this instance.
	RemoteWrite []RemoteWriteSpec `json:"remoteWrite,omitempty"`
	// AdditionalScrapeConfigs allows specifying a key of a Secret containing
	// additional Grafana Agent Prometheus scrape configurations. SCrape
	// configurations specified are appended to the configurations generated by
	// the Grafana Agent Operator. Job configurations specified must have the
	// form as specified in the official Prometheus documentation:
	// https://prometheus.io/docs/prometheus/latest/configuration/configuration/#scrape_config.
	// As scrape configs are appended, the user is responsible to make sure it is
	// valid. Note that using this feature may expose the possibility to break
	// upgrades of Grafana Agent. It is advised to review both Grafana Agent and
	// Prometheus release notes to ensure that no incompatible scrape configs are
	// going to break Grafana Agent after the upgrade.
	AdditionalScrapeConfigs *v1.SecretKeySelector `json:"additionalScrapeConfigs,omitempty"`
}

// +kubebuilder:object:root=true

// MetricsInstanceList is a list of MetricsInstance.
type MetricsInstanceList struct {
	metav1.TypeMeta `json:",inline"`
	metav1.ListMeta `json:"metadata,omitempty"`
	// Items is the list of MetricsInstance.
	Items []*MetricsInstance `json:"items"`
}

'''
'''--- pkg/operator/apis/monitoring/v1alpha1/zz_generated.deepcopy.go ---
//go:build !ignore_autogenerated
// +build !ignore_autogenerated

// Code generated by controller-gen. DO NOT EDIT.

package v1alpha1

import (
	"github.com/grafana/agent/pkg/operator/assets"
	"github.com/prometheus-operator/prometheus-operator/pkg/apis/monitoring/v1"
	corev1 "k8s.io/api/core/v1"
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
	runtime "k8s.io/apimachinery/pkg/runtime"
)

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *CRIStageSpec) DeepCopyInto(out *CRIStageSpec) {
	*out = *in
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new CRIStageSpec.
func (in *CRIStageSpec) DeepCopy() *CRIStageSpec {
	if in == nil {
		return nil
	}
	out := new(CRIStageSpec)
	in.DeepCopyInto(out)
	return out
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *Deployment) DeepCopyInto(out *Deployment) {
	*out = *in
	if in.Agent != nil {
		in, out := &in.Agent, &out.Agent
		*out = new(GrafanaAgent)
		(*in).DeepCopyInto(*out)
	}
	if in.Metrics != nil {
		in, out := &in.Metrics, &out.Metrics
		*out = make([]MetricsDeployment, len(*in))
		for i := range *in {
			(*in)[i].DeepCopyInto(&(*out)[i])
		}
	}
	if in.Logs != nil {
		in, out := &in.Logs, &out.Logs
		*out = make([]LogsDeployment, len(*in))
		for i := range *in {
			(*in)[i].DeepCopyInto(&(*out)[i])
		}
	}
	if in.Integrations != nil {
		in, out := &in.Integrations, &out.Integrations
		*out = make([]IntegrationsDeployment, len(*in))
		for i := range *in {
			(*in)[i].DeepCopyInto(&(*out)[i])
		}
	}
	if in.Secrets != nil {
		in, out := &in.Secrets, &out.Secrets
		*out = make(assets.SecretStore, len(*in))
		for key, val := range *in {
			(*out)[key] = val
		}
	}
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new Deployment.
func (in *Deployment) DeepCopy() *Deployment {
	if in == nil {
		return nil
	}
	out := new(Deployment)
	in.DeepCopyInto(out)
	return out
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *DockerStageSpec) DeepCopyInto(out *DockerStageSpec) {
	*out = *in
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new DockerStageSpec.
func (in *DockerStageSpec) DeepCopy() *DockerStageSpec {
	if in == nil {
		return nil
	}
	out := new(DockerStageSpec)
	in.DeepCopyInto(out)
	return out
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *DropStageSpec) DeepCopyInto(out *DropStageSpec) {
	*out = *in
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new DropStageSpec.
func (in *DropStageSpec) DeepCopy() *DropStageSpec {
	if in == nil {
		return nil
	}
	out := new(DropStageSpec)
	in.DeepCopyInto(out)
	return out
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *GrafanaAgent) DeepCopyInto(out *GrafanaAgent) {
	*out = *in
	out.TypeMeta = in.TypeMeta
	in.ObjectMeta.DeepCopyInto(&out.ObjectMeta)
	in.Spec.DeepCopyInto(&out.Spec)
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new GrafanaAgent.
func (in *GrafanaAgent) DeepCopy() *GrafanaAgent {
	if in == nil {
		return nil
	}
	out := new(GrafanaAgent)
	in.DeepCopyInto(out)
	return out
}

// DeepCopyObject is an autogenerated deepcopy function, copying the receiver, creating a new runtime.Object.
func (in *GrafanaAgent) DeepCopyObject() runtime.Object {
	if c := in.DeepCopy(); c != nil {
		return c
	}
	return nil
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *GrafanaAgentList) DeepCopyInto(out *GrafanaAgentList) {
	*out = *in
	out.TypeMeta = in.TypeMeta
	in.ListMeta.DeepCopyInto(&out.ListMeta)
	if in.Items != nil {
		in, out := &in.Items, &out.Items
		*out = make([]*GrafanaAgent, len(*in))
		for i := range *in {
			if (*in)[i] != nil {
				in, out := &(*in)[i], &(*out)[i]
				*out = new(GrafanaAgent)
				(*in).DeepCopyInto(*out)
			}
		}
	}
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new GrafanaAgentList.
func (in *GrafanaAgentList) DeepCopy() *GrafanaAgentList {
	if in == nil {
		return nil
	}
	out := new(GrafanaAgentList)
	in.DeepCopyInto(out)
	return out
}

// DeepCopyObject is an autogenerated deepcopy function, copying the receiver, creating a new runtime.Object.
func (in *GrafanaAgentList) DeepCopyObject() runtime.Object {
	if c := in.DeepCopy(); c != nil {
		return c
	}
	return nil
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *GrafanaAgentSpec) DeepCopyInto(out *GrafanaAgentSpec) {
	*out = *in
	if in.APIServerConfig != nil {
		in, out := &in.APIServerConfig, &out.APIServerConfig
		*out = new(v1.APIServerConfig)
		(*in).DeepCopyInto(*out)
	}
	if in.PodMetadata != nil {
		in, out := &in.PodMetadata, &out.PodMetadata
		*out = new(v1.EmbeddedObjectMetadata)
		(*in).DeepCopyInto(*out)
	}
	if in.Image != nil {
		in, out := &in.Image, &out.Image
		*out = new(string)
		**out = **in
	}
	if in.ImagePullSecrets != nil {
		in, out := &in.ImagePullSecrets, &out.ImagePullSecrets
		*out = make([]corev1.LocalObjectReference, len(*in))
		copy(*out, *in)
	}
	if in.Storage != nil {
		in, out := &in.Storage, &out.Storage
		*out = new(v1.StorageSpec)
		(*in).DeepCopyInto(*out)
	}
	if in.Volumes != nil {
		in, out := &in.Volumes, &out.Volumes
		*out = make([]corev1.Volume, len(*in))
		for i := range *in {
			(*in)[i].DeepCopyInto(&(*out)[i])
		}
	}
	if in.VolumeMounts != nil {
		in, out := &in.VolumeMounts, &out.VolumeMounts
		*out = make([]corev1.VolumeMount, len(*in))
		for i := range *in {
			(*in)[i].DeepCopyInto(&(*out)[i])
		}
	}
	in.Resources.DeepCopyInto(&out.Resources)
	if in.NodeSelector != nil {
		in, out := &in.NodeSelector, &out.NodeSelector
		*out = make(map[string]string, len(*in))
		for key, val := range *in {
			(*out)[key] = val
		}
	}
	if in.Secrets != nil {
		in, out := &in.Secrets, &out.Secrets
		*out = make([]string, len(*in))
		copy(*out, *in)
	}
	if in.ConfigMaps != nil {
		in, out := &in.ConfigMaps, &out.ConfigMaps
		*out = make([]string, len(*in))
		copy(*out, *in)
	}
	if in.Affinity != nil {
		in, out := &in.Affinity, &out.Affinity
		*out = new(corev1.Affinity)
		(*in).DeepCopyInto(*out)
	}
	if in.Tolerations != nil {
		in, out := &in.Tolerations, &out.Tolerations
		*out = make([]corev1.Toleration, len(*in))
		for i := range *in {
			(*in)[i].DeepCopyInto(&(*out)[i])
		}
	}
	if in.TopologySpreadConstraints != nil {
		in, out := &in.TopologySpreadConstraints, &out.TopologySpreadConstraints
		*out = make([]corev1.TopologySpreadConstraint, len(*in))
		for i := range *in {
			(*in)[i].DeepCopyInto(&(*out)[i])
		}
	}
	if in.SecurityContext != nil {
		in, out := &in.SecurityContext, &out.SecurityContext
		*out = new(corev1.PodSecurityContext)
		(*in).DeepCopyInto(*out)
	}
	if in.Containers != nil {
		in, out := &in.Containers, &out.Containers
		*out = make([]corev1.Container, len(*in))
		for i := range *in {
			(*in)[i].DeepCopyInto(&(*out)[i])
		}
	}
	if in.InitContainers != nil {
		in, out := &in.InitContainers, &out.InitContainers
		*out = make([]corev1.Container, len(*in))
		for i := range *in {
			(*in)[i].DeepCopyInto(&(*out)[i])
		}
	}
	in.Metrics.DeepCopyInto(&out.Metrics)
	in.Logs.DeepCopyInto(&out.Logs)
	in.Integrations.DeepCopyInto(&out.Integrations)
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new GrafanaAgentSpec.
func (in *GrafanaAgentSpec) DeepCopy() *GrafanaAgentSpec {
	if in == nil {
		return nil
	}
	out := new(GrafanaAgentSpec)
	in.DeepCopyInto(out)
	return out
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *Integration) DeepCopyInto(out *Integration) {
	*out = *in
	out.TypeMeta = in.TypeMeta
	in.ObjectMeta.DeepCopyInto(&out.ObjectMeta)
	in.Spec.DeepCopyInto(&out.Spec)
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new Integration.
func (in *Integration) DeepCopy() *Integration {
	if in == nil {
		return nil
	}
	out := new(Integration)
	in.DeepCopyInto(out)
	return out
}

// DeepCopyObject is an autogenerated deepcopy function, copying the receiver, creating a new runtime.Object.
func (in *Integration) DeepCopyObject() runtime.Object {
	if c := in.DeepCopy(); c != nil {
		return c
	}
	return nil
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *IntegrationList) DeepCopyInto(out *IntegrationList) {
	*out = *in
	out.TypeMeta = in.TypeMeta
	in.ListMeta.DeepCopyInto(&out.ListMeta)
	if in.Items != nil {
		in, out := &in.Items, &out.Items
		*out = make([]*Integration, len(*in))
		for i := range *in {
			if (*in)[i] != nil {
				in, out := &(*in)[i], &(*out)[i]
				*out = new(Integration)
				(*in).DeepCopyInto(*out)
			}
		}
	}
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new IntegrationList.
func (in *IntegrationList) DeepCopy() *IntegrationList {
	if in == nil {
		return nil
	}
	out := new(IntegrationList)
	in.DeepCopyInto(out)
	return out
}

// DeepCopyObject is an autogenerated deepcopy function, copying the receiver, creating a new runtime.Object.
func (in *IntegrationList) DeepCopyObject() runtime.Object {
	if c := in.DeepCopy(); c != nil {
		return c
	}
	return nil
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *IntegrationSpec) DeepCopyInto(out *IntegrationSpec) {
	*out = *in
	out.Type = in.Type
	in.Config.DeepCopyInto(&out.Config)
	if in.Volumes != nil {
		in, out := &in.Volumes, &out.Volumes
		*out = make([]corev1.Volume, len(*in))
		for i := range *in {
			(*in)[i].DeepCopyInto(&(*out)[i])
		}
	}
	if in.VolumeMounts != nil {
		in, out := &in.VolumeMounts, &out.VolumeMounts
		*out = make([]corev1.VolumeMount, len(*in))
		for i := range *in {
			(*in)[i].DeepCopyInto(&(*out)[i])
		}
	}
	if in.Secrets != nil {
		in, out := &in.Secrets, &out.Secrets
		*out = make([]corev1.SecretKeySelector, len(*in))
		for i := range *in {
			(*in)[i].DeepCopyInto(&(*out)[i])
		}
	}
	if in.ConfigMaps != nil {
		in, out := &in.ConfigMaps, &out.ConfigMaps
		*out = make([]corev1.ConfigMapKeySelector, len(*in))
		for i := range *in {
			(*in)[i].DeepCopyInto(&(*out)[i])
		}
	}
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new IntegrationSpec.
func (in *IntegrationSpec) DeepCopy() *IntegrationSpec {
	if in == nil {
		return nil
	}
	out := new(IntegrationSpec)
	in.DeepCopyInto(out)
	return out
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *IntegrationType) DeepCopyInto(out *IntegrationType) {
	*out = *in
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new IntegrationType.
func (in *IntegrationType) DeepCopy() *IntegrationType {
	if in == nil {
		return nil
	}
	out := new(IntegrationType)
	in.DeepCopyInto(out)
	return out
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *IntegrationsDeployment) DeepCopyInto(out *IntegrationsDeployment) {
	*out = *in
	if in.Instance != nil {
		in, out := &in.Instance, &out.Instance
		*out = new(Integration)
		(*in).DeepCopyInto(*out)
	}
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new IntegrationsDeployment.
func (in *IntegrationsDeployment) DeepCopy() *IntegrationsDeployment {
	if in == nil {
		return nil
	}
	out := new(IntegrationsDeployment)
	in.DeepCopyInto(out)
	return out
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *IntegrationsSubsystemSpec) DeepCopyInto(out *IntegrationsSubsystemSpec) {
	*out = *in
	if in.Selector != nil {
		in, out := &in.Selector, &out.Selector
		*out = new(metav1.LabelSelector)
		(*in).DeepCopyInto(*out)
	}
	if in.NamespaceSelector != nil {
		in, out := &in.NamespaceSelector, &out.NamespaceSelector
		*out = new(metav1.LabelSelector)
		(*in).DeepCopyInto(*out)
	}
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new IntegrationsSubsystemSpec.
func (in *IntegrationsSubsystemSpec) DeepCopy() *IntegrationsSubsystemSpec {
	if in == nil {
		return nil
	}
	out := new(IntegrationsSubsystemSpec)
	in.DeepCopyInto(out)
	return out
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *JSONStageSpec) DeepCopyInto(out *JSONStageSpec) {
	*out = *in
	if in.Expressions != nil {
		in, out := &in.Expressions, &out.Expressions
		*out = make(map[string]string, len(*in))
		for key, val := range *in {
			(*out)[key] = val
		}
	}
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new JSONStageSpec.
func (in *JSONStageSpec) DeepCopy() *JSONStageSpec {
	if in == nil {
		return nil
	}
	out := new(JSONStageSpec)
	in.DeepCopyInto(out)
	return out
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *LogsBackoffConfigSpec) DeepCopyInto(out *LogsBackoffConfigSpec) {
	*out = *in
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new LogsBackoffConfigSpec.
func (in *LogsBackoffConfigSpec) DeepCopy() *LogsBackoffConfigSpec {
	if in == nil {
		return nil
	}
	out := new(LogsBackoffConfigSpec)
	in.DeepCopyInto(out)
	return out
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *LogsClientSpec) DeepCopyInto(out *LogsClientSpec) {
	*out = *in
	if in.BasicAuth != nil {
		in, out := &in.BasicAuth, &out.BasicAuth
		*out = new(v1.BasicAuth)
		(*in).DeepCopyInto(*out)
	}
	if in.TLSConfig != nil {
		in, out := &in.TLSConfig, &out.TLSConfig
		*out = new(v1.TLSConfig)
		(*in).DeepCopyInto(*out)
	}
	if in.BackoffConfig != nil {
		in, out := &in.BackoffConfig, &out.BackoffConfig
		*out = new(LogsBackoffConfigSpec)
		**out = **in
	}
	if in.ExternalLabels != nil {
		in, out := &in.ExternalLabels, &out.ExternalLabels
		*out = make(map[string]string, len(*in))
		for key, val := range *in {
			(*out)[key] = val
		}
	}
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new LogsClientSpec.
func (in *LogsClientSpec) DeepCopy() *LogsClientSpec {
	if in == nil {
		return nil
	}
	out := new(LogsClientSpec)
	in.DeepCopyInto(out)
	return out
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *LogsDeployment) DeepCopyInto(out *LogsDeployment) {
	*out = *in
	if in.Instance != nil {
		in, out := &in.Instance, &out.Instance
		*out = new(LogsInstance)
		(*in).DeepCopyInto(*out)
	}
	if in.PodLogs != nil {
		in, out := &in.PodLogs, &out.PodLogs
		*out = make([]*PodLogs, len(*in))
		for i := range *in {
			if (*in)[i] != nil {
				in, out := &(*in)[i], &(*out)[i]
				*out = new(PodLogs)
				(*in).DeepCopyInto(*out)
			}
		}
	}
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new LogsDeployment.
func (in *LogsDeployment) DeepCopy() *LogsDeployment {
	if in == nil {
		return nil
	}
	out := new(LogsDeployment)
	in.DeepCopyInto(out)
	return out
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *LogsInstance) DeepCopyInto(out *LogsInstance) {
	*out = *in
	out.TypeMeta = in.TypeMeta
	in.ObjectMeta.DeepCopyInto(&out.ObjectMeta)
	in.Spec.DeepCopyInto(&out.Spec)
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new LogsInstance.
func (in *LogsInstance) DeepCopy() *LogsInstance {
	if in == nil {
		return nil
	}
	out := new(LogsInstance)
	in.DeepCopyInto(out)
	return out
}

// DeepCopyObject is an autogenerated deepcopy function, copying the receiver, creating a new runtime.Object.
func (in *LogsInstance) DeepCopyObject() runtime.Object {
	if c := in.DeepCopy(); c != nil {
		return c
	}
	return nil
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *LogsInstanceList) DeepCopyInto(out *LogsInstanceList) {
	*out = *in
	out.TypeMeta = in.TypeMeta
	in.ListMeta.DeepCopyInto(&out.ListMeta)
	if in.Items != nil {
		in, out := &in.Items, &out.Items
		*out = make([]*LogsInstance, len(*in))
		for i := range *in {
			if (*in)[i] != nil {
				in, out := &(*in)[i], &(*out)[i]
				*out = new(LogsInstance)
				(*in).DeepCopyInto(*out)
			}
		}
	}
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new LogsInstanceList.
func (in *LogsInstanceList) DeepCopy() *LogsInstanceList {
	if in == nil {
		return nil
	}
	out := new(LogsInstanceList)
	in.DeepCopyInto(out)
	return out
}

// DeepCopyObject is an autogenerated deepcopy function, copying the receiver, creating a new runtime.Object.
func (in *LogsInstanceList) DeepCopyObject() runtime.Object {
	if c := in.DeepCopy(); c != nil {
		return c
	}
	return nil
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *LogsInstanceSpec) DeepCopyInto(out *LogsInstanceSpec) {
	*out = *in
	if in.Clients != nil {
		in, out := &in.Clients, &out.Clients
		*out = make([]LogsClientSpec, len(*in))
		for i := range *in {
			(*in)[i].DeepCopyInto(&(*out)[i])
		}
	}
	if in.PodLogsSelector != nil {
		in, out := &in.PodLogsSelector, &out.PodLogsSelector
		*out = new(metav1.LabelSelector)
		(*in).DeepCopyInto(*out)
	}
	if in.PodLogsNamespaceSelector != nil {
		in, out := &in.PodLogsNamespaceSelector, &out.PodLogsNamespaceSelector
		*out = new(metav1.LabelSelector)
		(*in).DeepCopyInto(*out)
	}
	if in.AdditionalScrapeConfigs != nil {
		in, out := &in.AdditionalScrapeConfigs, &out.AdditionalScrapeConfigs
		*out = new(corev1.SecretKeySelector)
		(*in).DeepCopyInto(*out)
	}
	if in.TargetConfig != nil {
		in, out := &in.TargetConfig, &out.TargetConfig
		*out = new(LogsTargetConfigSpec)
		**out = **in
	}
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new LogsInstanceSpec.
func (in *LogsInstanceSpec) DeepCopy() *LogsInstanceSpec {
	if in == nil {
		return nil
	}
	out := new(LogsInstanceSpec)
	in.DeepCopyInto(out)
	return out
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *LogsSubsystemSpec) DeepCopyInto(out *LogsSubsystemSpec) {
	*out = *in
	if in.Clients != nil {
		in, out := &in.Clients, &out.Clients
		*out = make([]LogsClientSpec, len(*in))
		for i := range *in {
			(*in)[i].DeepCopyInto(&(*out)[i])
		}
	}
	if in.LogsExternalLabelName != nil {
		in, out := &in.LogsExternalLabelName, &out.LogsExternalLabelName
		*out = new(string)
		**out = **in
	}
	if in.InstanceSelector != nil {
		in, out := &in.InstanceSelector, &out.InstanceSelector
		*out = new(metav1.LabelSelector)
		(*in).DeepCopyInto(*out)
	}
	if in.InstanceNamespaceSelector != nil {
		in, out := &in.InstanceNamespaceSelector, &out.InstanceNamespaceSelector
		*out = new(metav1.LabelSelector)
		(*in).DeepCopyInto(*out)
	}
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new LogsSubsystemSpec.
func (in *LogsSubsystemSpec) DeepCopy() *LogsSubsystemSpec {
	if in == nil {
		return nil
	}
	out := new(LogsSubsystemSpec)
	in.DeepCopyInto(out)
	return out
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *LogsTargetConfigSpec) DeepCopyInto(out *LogsTargetConfigSpec) {
	*out = *in
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new LogsTargetConfigSpec.
func (in *LogsTargetConfigSpec) DeepCopy() *LogsTargetConfigSpec {
	if in == nil {
		return nil
	}
	out := new(LogsTargetConfigSpec)
	in.DeepCopyInto(out)
	return out
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *MatchStageSpec) DeepCopyInto(out *MatchStageSpec) {
	*out = *in
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new MatchStageSpec.
func (in *MatchStageSpec) DeepCopy() *MatchStageSpec {
	if in == nil {
		return nil
	}
	out := new(MatchStageSpec)
	in.DeepCopyInto(out)
	return out
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *MetadataConfig) DeepCopyInto(out *MetadataConfig) {
	*out = *in
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new MetadataConfig.
func (in *MetadataConfig) DeepCopy() *MetadataConfig {
	if in == nil {
		return nil
	}
	out := new(MetadataConfig)
	in.DeepCopyInto(out)
	return out
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *MetricsDeployment) DeepCopyInto(out *MetricsDeployment) {
	*out = *in
	if in.Instance != nil {
		in, out := &in.Instance, &out.Instance
		*out = new(MetricsInstance)
		(*in).DeepCopyInto(*out)
	}
	if in.ServiceMonitors != nil {
		in, out := &in.ServiceMonitors, &out.ServiceMonitors
		*out = make([]*v1.ServiceMonitor, len(*in))
		for i := range *in {
			if (*in)[i] != nil {
				in, out := &(*in)[i], &(*out)[i]
				*out = new(v1.ServiceMonitor)
				(*in).DeepCopyInto(*out)
			}
		}
	}
	if in.PodMonitors != nil {
		in, out := &in.PodMonitors, &out.PodMonitors
		*out = make([]*v1.PodMonitor, len(*in))
		for i := range *in {
			if (*in)[i] != nil {
				in, out := &(*in)[i], &(*out)[i]
				*out = new(v1.PodMonitor)
				(*in).DeepCopyInto(*out)
			}
		}
	}
	if in.Probes != nil {
		in, out := &in.Probes, &out.Probes
		*out = make([]*v1.Probe, len(*in))
		for i := range *in {
			if (*in)[i] != nil {
				in, out := &(*in)[i], &(*out)[i]
				*out = new(v1.Probe)
				(*in).DeepCopyInto(*out)
			}
		}
	}
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new MetricsDeployment.
func (in *MetricsDeployment) DeepCopy() *MetricsDeployment {
	if in == nil {
		return nil
	}
	out := new(MetricsDeployment)
	in.DeepCopyInto(out)
	return out
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *MetricsInstance) DeepCopyInto(out *MetricsInstance) {
	*out = *in
	out.TypeMeta = in.TypeMeta
	in.ObjectMeta.DeepCopyInto(&out.ObjectMeta)
	in.Spec.DeepCopyInto(&out.Spec)
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new MetricsInstance.
func (in *MetricsInstance) DeepCopy() *MetricsInstance {
	if in == nil {
		return nil
	}
	out := new(MetricsInstance)
	in.DeepCopyInto(out)
	return out
}

// DeepCopyObject is an autogenerated deepcopy function, copying the receiver, creating a new runtime.Object.
func (in *MetricsInstance) DeepCopyObject() runtime.Object {
	if c := in.DeepCopy(); c != nil {
		return c
	}
	return nil
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *MetricsInstanceList) DeepCopyInto(out *MetricsInstanceList) {
	*out = *in
	out.TypeMeta = in.TypeMeta
	in.ListMeta.DeepCopyInto(&out.ListMeta)
	if in.Items != nil {
		in, out := &in.Items, &out.Items
		*out = make([]*MetricsInstance, len(*in))
		for i := range *in {
			if (*in)[i] != nil {
				in, out := &(*in)[i], &(*out)[i]
				*out = new(MetricsInstance)
				(*in).DeepCopyInto(*out)
			}
		}
	}
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new MetricsInstanceList.
func (in *MetricsInstanceList) DeepCopy() *MetricsInstanceList {
	if in == nil {
		return nil
	}
	out := new(MetricsInstanceList)
	in.DeepCopyInto(out)
	return out
}

// DeepCopyObject is an autogenerated deepcopy function, copying the receiver, creating a new runtime.Object.
func (in *MetricsInstanceList) DeepCopyObject() runtime.Object {
	if c := in.DeepCopy(); c != nil {
		return c
	}
	return nil
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *MetricsInstanceSpec) DeepCopyInto(out *MetricsInstanceSpec) {
	*out = *in
	if in.WriteStaleOnShutdown != nil {
		in, out := &in.WriteStaleOnShutdown, &out.WriteStaleOnShutdown
		*out = new(bool)
		**out = **in
	}
	if in.ServiceMonitorSelector != nil {
		in, out := &in.ServiceMonitorSelector, &out.ServiceMonitorSelector
		*out = new(metav1.LabelSelector)
		(*in).DeepCopyInto(*out)
	}
	if in.ServiceMonitorNamespaceSelector != nil {
		in, out := &in.ServiceMonitorNamespaceSelector, &out.ServiceMonitorNamespaceSelector
		*out = new(metav1.LabelSelector)
		(*in).DeepCopyInto(*out)
	}
	if in.PodMonitorSelector != nil {
		in, out := &in.PodMonitorSelector, &out.PodMonitorSelector
		*out = new(metav1.LabelSelector)
		(*in).DeepCopyInto(*out)
	}
	if in.PodMonitorNamespaceSelector != nil {
		in, out := &in.PodMonitorNamespaceSelector, &out.PodMonitorNamespaceSelector
		*out = new(metav1.LabelSelector)
		(*in).DeepCopyInto(*out)
	}
	if in.ProbeSelector != nil {
		in, out := &in.ProbeSelector, &out.ProbeSelector
		*out = new(metav1.LabelSelector)
		(*in).DeepCopyInto(*out)
	}
	if in.ProbeNamespaceSelector != nil {
		in, out := &in.ProbeNamespaceSelector, &out.ProbeNamespaceSelector
		*out = new(metav1.LabelSelector)
		(*in).DeepCopyInto(*out)
	}
	if in.RemoteWrite != nil {
		in, out := &in.RemoteWrite, &out.RemoteWrite
		*out = make([]RemoteWriteSpec, len(*in))
		for i := range *in {
			(*in)[i].DeepCopyInto(&(*out)[i])
		}
	}
	if in.AdditionalScrapeConfigs != nil {
		in, out := &in.AdditionalScrapeConfigs, &out.AdditionalScrapeConfigs
		*out = new(corev1.SecretKeySelector)
		(*in).DeepCopyInto(*out)
	}
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new MetricsInstanceSpec.
func (in *MetricsInstanceSpec) DeepCopy() *MetricsInstanceSpec {
	if in == nil {
		return nil
	}
	out := new(MetricsInstanceSpec)
	in.DeepCopyInto(out)
	return out
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *MetricsStageSpec) DeepCopyInto(out *MetricsStageSpec) {
	*out = *in
	if in.MatchAll != nil {
		in, out := &in.MatchAll, &out.MatchAll
		*out = new(bool)
		**out = **in
	}
	if in.CountEntryBytes != nil {
		in, out := &in.CountEntryBytes, &out.CountEntryBytes
		*out = new(bool)
		**out = **in
	}
	if in.Buckets != nil {
		in, out := &in.Buckets, &out.Buckets
		*out = make([]string, len(*in))
		copy(*out, *in)
	}
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new MetricsStageSpec.
func (in *MetricsStageSpec) DeepCopy() *MetricsStageSpec {
	if in == nil {
		return nil
	}
	out := new(MetricsStageSpec)
	in.DeepCopyInto(out)
	return out
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *MetricsSubsystemSpec) DeepCopyInto(out *MetricsSubsystemSpec) {
	*out = *in
	if in.RemoteWrite != nil {
		in, out := &in.RemoteWrite, &out.RemoteWrite
		*out = make([]RemoteWriteSpec, len(*in))
		for i := range *in {
			(*in)[i].DeepCopyInto(&(*out)[i])
		}
	}
	if in.Replicas != nil {
		in, out := &in.Replicas, &out.Replicas
		*out = new(int32)
		**out = **in
	}
	if in.Shards != nil {
		in, out := &in.Shards, &out.Shards
		*out = new(int32)
		**out = **in
	}
	if in.ReplicaExternalLabelName != nil {
		in, out := &in.ReplicaExternalLabelName, &out.ReplicaExternalLabelName
		*out = new(string)
		**out = **in
	}
	if in.MetricsExternalLabelName != nil {
		in, out := &in.MetricsExternalLabelName, &out.MetricsExternalLabelName
		*out = new(string)
		**out = **in
	}
	if in.ExternalLabels != nil {
		in, out := &in.ExternalLabels, &out.ExternalLabels
		*out = make(map[string]string, len(*in))
		for key, val := range *in {
			(*out)[key] = val
		}
	}
	out.ArbitraryFSAccessThroughSMs = in.ArbitraryFSAccessThroughSMs
	if in.EnforcedSampleLimit != nil {
		in, out := &in.EnforcedSampleLimit, &out.EnforcedSampleLimit
		*out = new(uint64)
		**out = **in
	}
	if in.EnforcedTargetLimit != nil {
		in, out := &in.EnforcedTargetLimit, &out.EnforcedTargetLimit
		*out = new(uint64)
		**out = **in
	}
	if in.InstanceSelector != nil {
		in, out := &in.InstanceSelector, &out.InstanceSelector
		*out = new(metav1.LabelSelector)
		(*in).DeepCopyInto(*out)
	}
	if in.InstanceNamespaceSelector != nil {
		in, out := &in.InstanceNamespaceSelector, &out.InstanceNamespaceSelector
		*out = new(metav1.LabelSelector)
		(*in).DeepCopyInto(*out)
	}
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new MetricsSubsystemSpec.
func (in *MetricsSubsystemSpec) DeepCopy() *MetricsSubsystemSpec {
	if in == nil {
		return nil
	}
	out := new(MetricsSubsystemSpec)
	in.DeepCopyInto(out)
	return out
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *MultilineStageSpec) DeepCopyInto(out *MultilineStageSpec) {
	*out = *in
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new MultilineStageSpec.
func (in *MultilineStageSpec) DeepCopy() *MultilineStageSpec {
	if in == nil {
		return nil
	}
	out := new(MultilineStageSpec)
	in.DeepCopyInto(out)
	return out
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *OutputStageSpec) DeepCopyInto(out *OutputStageSpec) {
	*out = *in
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new OutputStageSpec.
func (in *OutputStageSpec) DeepCopy() *OutputStageSpec {
	if in == nil {
		return nil
	}
	out := new(OutputStageSpec)
	in.DeepCopyInto(out)
	return out
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *PackStageSpec) DeepCopyInto(out *PackStageSpec) {
	*out = *in
	if in.Labels != nil {
		in, out := &in.Labels, &out.Labels
		*out = make([]string, len(*in))
		copy(*out, *in)
	}
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new PackStageSpec.
func (in *PackStageSpec) DeepCopy() *PackStageSpec {
	if in == nil {
		return nil
	}
	out := new(PackStageSpec)
	in.DeepCopyInto(out)
	return out
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *PipelineStageSpec) DeepCopyInto(out *PipelineStageSpec) {
	*out = *in
	if in.CRI != nil {
		in, out := &in.CRI, &out.CRI
		*out = new(CRIStageSpec)
		**out = **in
	}
	if in.Docker != nil {
		in, out := &in.Docker, &out.Docker
		*out = new(DockerStageSpec)
		**out = **in
	}
	if in.Drop != nil {
		in, out := &in.Drop, &out.Drop
		*out = new(DropStageSpec)
		**out = **in
	}
	if in.JSON != nil {
		in, out := &in.JSON, &out.JSON
		*out = new(JSONStageSpec)
		(*in).DeepCopyInto(*out)
	}
	if in.LabelAllow != nil {
		in, out := &in.LabelAllow, &out.LabelAllow
		*out = make([]string, len(*in))
		copy(*out, *in)
	}
	if in.LabelDrop != nil {
		in, out := &in.LabelDrop, &out.LabelDrop
		*out = make([]string, len(*in))
		copy(*out, *in)
	}
	if in.Labels != nil {
		in, out := &in.Labels, &out.Labels
		*out = make(map[string]string, len(*in))
		for key, val := range *in {
			(*out)[key] = val
		}
	}
	if in.Match != nil {
		in, out := &in.Match, &out.Match
		*out = new(MatchStageSpec)
		**out = **in
	}
	if in.Metrics != nil {
		in, out := &in.Metrics, &out.Metrics
		*out = make(map[string]MetricsStageSpec, len(*in))
		for key, val := range *in {
			(*out)[key] = *val.DeepCopy()
		}
	}
	if in.Multiline != nil {
		in, out := &in.Multiline, &out.Multiline
		*out = new(MultilineStageSpec)
		**out = **in
	}
	if in.Output != nil {
		in, out := &in.Output, &out.Output
		*out = new(OutputStageSpec)
		**out = **in
	}
	if in.Pack != nil {
		in, out := &in.Pack, &out.Pack
		*out = new(PackStageSpec)
		(*in).DeepCopyInto(*out)
	}
	if in.Regex != nil {
		in, out := &in.Regex, &out.Regex
		*out = new(RegexStageSpec)
		**out = **in
	}
	if in.Replace != nil {
		in, out := &in.Replace, &out.Replace
		*out = new(ReplaceStageSpec)
		**out = **in
	}
	if in.Template != nil {
		in, out := &in.Template, &out.Template
		*out = new(TemplateStageSpec)
		**out = **in
	}
	if in.Tenant != nil {
		in, out := &in.Tenant, &out.Tenant
		*out = new(TenantStageSpec)
		**out = **in
	}
	if in.Timestamp != nil {
		in, out := &in.Timestamp, &out.Timestamp
		*out = new(TimestampStageSpec)
		(*in).DeepCopyInto(*out)
	}
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new PipelineStageSpec.
func (in *PipelineStageSpec) DeepCopy() *PipelineStageSpec {
	if in == nil {
		return nil
	}
	out := new(PipelineStageSpec)
	in.DeepCopyInto(out)
	return out
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *PodLogs) DeepCopyInto(out *PodLogs) {
	*out = *in
	out.TypeMeta = in.TypeMeta
	in.ObjectMeta.DeepCopyInto(&out.ObjectMeta)
	in.Spec.DeepCopyInto(&out.Spec)
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new PodLogs.
func (in *PodLogs) DeepCopy() *PodLogs {
	if in == nil {
		return nil
	}
	out := new(PodLogs)
	in.DeepCopyInto(out)
	return out
}

// DeepCopyObject is an autogenerated deepcopy function, copying the receiver, creating a new runtime.Object.
func (in *PodLogs) DeepCopyObject() runtime.Object {
	if c := in.DeepCopy(); c != nil {
		return c
	}
	return nil
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *PodLogsList) DeepCopyInto(out *PodLogsList) {
	*out = *in
	out.TypeMeta = in.TypeMeta
	in.ListMeta.DeepCopyInto(&out.ListMeta)
	if in.Items != nil {
		in, out := &in.Items, &out.Items
		*out = make([]*PodLogs, len(*in))
		for i := range *in {
			if (*in)[i] != nil {
				in, out := &(*in)[i], &(*out)[i]
				*out = new(PodLogs)
				(*in).DeepCopyInto(*out)
			}
		}
	}
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new PodLogsList.
func (in *PodLogsList) DeepCopy() *PodLogsList {
	if in == nil {
		return nil
	}
	out := new(PodLogsList)
	in.DeepCopyInto(out)
	return out
}

// DeepCopyObject is an autogenerated deepcopy function, copying the receiver, creating a new runtime.Object.
func (in *PodLogsList) DeepCopyObject() runtime.Object {
	if c := in.DeepCopy(); c != nil {
		return c
	}
	return nil
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *PodLogsSpec) DeepCopyInto(out *PodLogsSpec) {
	*out = *in
	if in.PodTargetLabels != nil {
		in, out := &in.PodTargetLabels, &out.PodTargetLabels
		*out = make([]string, len(*in))
		copy(*out, *in)
	}
	in.Selector.DeepCopyInto(&out.Selector)
	in.NamespaceSelector.DeepCopyInto(&out.NamespaceSelector)
	if in.PipelineStages != nil {
		in, out := &in.PipelineStages, &out.PipelineStages
		*out = make([]*PipelineStageSpec, len(*in))
		for i := range *in {
			if (*in)[i] != nil {
				in, out := &(*in)[i], &(*out)[i]
				*out = new(PipelineStageSpec)
				(*in).DeepCopyInto(*out)
			}
		}
	}
	if in.RelabelConfigs != nil {
		in, out := &in.RelabelConfigs, &out.RelabelConfigs
		*out = make([]*v1.RelabelConfig, len(*in))
		for i := range *in {
			if (*in)[i] != nil {
				in, out := &(*in)[i], &(*out)[i]
				*out = new(v1.RelabelConfig)
				(*in).DeepCopyInto(*out)
			}
		}
	}
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new PodLogsSpec.
func (in *PodLogsSpec) DeepCopy() *PodLogsSpec {
	if in == nil {
		return nil
	}
	out := new(PodLogsSpec)
	in.DeepCopyInto(out)
	return out
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *QueueConfig) DeepCopyInto(out *QueueConfig) {
	*out = *in
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new QueueConfig.
func (in *QueueConfig) DeepCopy() *QueueConfig {
	if in == nil {
		return nil
	}
	out := new(QueueConfig)
	in.DeepCopyInto(out)
	return out
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *RegexStageSpec) DeepCopyInto(out *RegexStageSpec) {
	*out = *in
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new RegexStageSpec.
func (in *RegexStageSpec) DeepCopy() *RegexStageSpec {
	if in == nil {
		return nil
	}
	out := new(RegexStageSpec)
	in.DeepCopyInto(out)
	return out
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *RemoteWriteSpec) DeepCopyInto(out *RemoteWriteSpec) {
	*out = *in
	if in.Headers != nil {
		in, out := &in.Headers, &out.Headers
		*out = make(map[string]string, len(*in))
		for key, val := range *in {
			(*out)[key] = val
		}
	}
	if in.WriteRelabelConfigs != nil {
		in, out := &in.WriteRelabelConfigs, &out.WriteRelabelConfigs
		*out = make([]v1.RelabelConfig, len(*in))
		for i := range *in {
			(*in)[i].DeepCopyInto(&(*out)[i])
		}
	}
	if in.BasicAuth != nil {
		in, out := &in.BasicAuth, &out.BasicAuth
		*out = new(v1.BasicAuth)
		(*in).DeepCopyInto(*out)
	}
	if in.SigV4 != nil {
		in, out := &in.SigV4, &out.SigV4
		*out = new(SigV4Config)
		(*in).DeepCopyInto(*out)
	}
	if in.TLSConfig != nil {
		in, out := &in.TLSConfig, &out.TLSConfig
		*out = new(v1.TLSConfig)
		(*in).DeepCopyInto(*out)
	}
	if in.QueueConfig != nil {
		in, out := &in.QueueConfig, &out.QueueConfig
		*out = new(QueueConfig)
		**out = **in
	}
	if in.MetadataConfig != nil {
		in, out := &in.MetadataConfig, &out.MetadataConfig
		*out = new(MetadataConfig)
		**out = **in
	}
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new RemoteWriteSpec.
func (in *RemoteWriteSpec) DeepCopy() *RemoteWriteSpec {
	if in == nil {
		return nil
	}
	out := new(RemoteWriteSpec)
	in.DeepCopyInto(out)
	return out
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *ReplaceStageSpec) DeepCopyInto(out *ReplaceStageSpec) {
	*out = *in
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new ReplaceStageSpec.
func (in *ReplaceStageSpec) DeepCopy() *ReplaceStageSpec {
	if in == nil {
		return nil
	}
	out := new(ReplaceStageSpec)
	in.DeepCopyInto(out)
	return out
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *SigV4Config) DeepCopyInto(out *SigV4Config) {
	*out = *in
	if in.AccessKey != nil {
		in, out := &in.AccessKey, &out.AccessKey
		*out = new(corev1.SecretKeySelector)
		(*in).DeepCopyInto(*out)
	}
	if in.SecretKey != nil {
		in, out := &in.SecretKey, &out.SecretKey
		*out = new(corev1.SecretKeySelector)
		(*in).DeepCopyInto(*out)
	}
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new SigV4Config.
func (in *SigV4Config) DeepCopy() *SigV4Config {
	if in == nil {
		return nil
	}
	out := new(SigV4Config)
	in.DeepCopyInto(out)
	return out
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *TemplateStageSpec) DeepCopyInto(out *TemplateStageSpec) {
	*out = *in
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new TemplateStageSpec.
func (in *TemplateStageSpec) DeepCopy() *TemplateStageSpec {
	if in == nil {
		return nil
	}
	out := new(TemplateStageSpec)
	in.DeepCopyInto(out)
	return out
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *TenantStageSpec) DeepCopyInto(out *TenantStageSpec) {
	*out = *in
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new TenantStageSpec.
func (in *TenantStageSpec) DeepCopy() *TenantStageSpec {
	if in == nil {
		return nil
	}
	out := new(TenantStageSpec)
	in.DeepCopyInto(out)
	return out
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *TimestampStageSpec) DeepCopyInto(out *TimestampStageSpec) {
	*out = *in
	if in.FallbackFormats != nil {
		in, out := &in.FallbackFormats, &out.FallbackFormats
		*out = make([]string, len(*in))
		copy(*out, *in)
	}
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new TimestampStageSpec.
func (in *TimestampStageSpec) DeepCopy() *TimestampStageSpec {
	if in == nil {
		return nil
	}
	out := new(TimestampStageSpec)
	in.DeepCopyInto(out)
	return out
}

'''
'''--- pkg/operator/assets/assets.go ---
// Package assets contains helper types used for loading in static assets when
// configuring the Grafana Agent.
package assets

import (
	"fmt"

	prom_v1 "github.com/prometheus-operator/prometheus-operator/pkg/apis/monitoring/v1"
	v1 "k8s.io/api/core/v1"
)

// Key is a path-like identifier representing a Secret or ConfigMap value. It is
// used for looking up values during config generation that cannot be loaded
// directly from a file (e.g., BasicAuth Username).
//
// The naming convention is either:
//   /secrets/<namespace>/<name>/<key>
// or:
//   /configMaps/<namespace>/<name>/<key>
//
// Resources associated with a key should be watched for changes and trigger a
// reconcile when modified.
type Key string

// SecretStore is an in-memory cache for secrets, intended to be used for
// static secrets in generated configuration files.
type SecretStore map[Key]string

// KeyForSecret returns the key for a given namespace and a secret key
// selector.
func KeyForSecret(namespace string, sel *v1.SecretKeySelector) Key {
	if sel == nil {
		return Key("")
	}
	return Key(fmt.Sprintf("/secrets/%s/%s/%s", namespace, sel.Name, sel.Key))
}

// KeyForConfigMap returns the key for a given namespace and a config map
// key selector.
func KeyForConfigMap(namespace string, sel *v1.ConfigMapKeySelector) Key {
	if sel == nil {
		return Key("")
	}
	return Key(fmt.Sprintf("/configMaps/%s/%s/%s", namespace, sel.Name, sel.Key))
}

// KeyForSelector retrives the key for a SecretOrConfigMap.
func KeyForSelector(namespace string, sel *prom_v1.SecretOrConfigMap) Key {
	switch {
	case sel.ConfigMap != nil:
		return KeyForConfigMap(namespace, sel.ConfigMap)
	case sel.Secret != nil:
		return KeyForSecret(namespace, sel.Secret)
	default:
		return Key("")
	}
}

'''
'''--- pkg/operator/build_hierarchy.go ---
package operator

import (
	"context"
	"fmt"

	"github.com/go-kit/log"
	"github.com/go-kit/log/level"
	gragent "github.com/grafana/agent/pkg/operator/apis/monitoring/v1alpha1"
	"github.com/grafana/agent/pkg/operator/assets"
	"github.com/grafana/agent/pkg/operator/config"
	"github.com/grafana/agent/pkg/operator/hierarchy"
	prom "github.com/prometheus-operator/prometheus-operator/pkg/apis/monitoring/v1"
	corev1 "k8s.io/api/core/v1"
	"k8s.io/apimachinery/pkg/api/meta"
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
	"k8s.io/apimachinery/pkg/runtime"
	"sigs.k8s.io/controller-runtime/pkg/client"
	"sigs.k8s.io/controller-runtime/pkg/client/apiutil"
)

// buildHierarchy constructs a resource hierarchy starting from root.
func buildHierarchy(ctx context.Context, l log.Logger, cli client.Client, root *gragent.GrafanaAgent) (deployment gragent.Deployment, watchers []hierarchy.Watcher, err error) {
	deployment.Agent = root

	// search is used throughout BuildHierarchy, where it will perform a list for
	// a set of objects in the hierarchy and populate the watchers return
	// variable.
	search := func(resources []hierarchyResource) error {
		for _, res := range resources {
			sel, err := res.Find(ctx, cli)
			if err != nil {
				gvk, _ := apiutil.GVKForObject(res.List, cli.Scheme())
				return fmt.Errorf("failed to find %q resource: %w", gvk.String(), err)
			}

			watchers = append(watchers, hierarchy.Watcher{
				Object:   res.Selector.ObjectType,
				Owner:    client.ObjectKeyFromObject(root),
				Selector: sel,
			})
		}
		return nil
	}

	// Root resources
	var (
		metricInstances gragent.MetricsInstanceList
		logsInstances   gragent.LogsInstanceList
		integrations    gragent.IntegrationList
	)
	var roots = []hierarchyResource{
		{List: &metricInstances, Selector: root.MetricsInstanceSelector()},
		{List: &logsInstances, Selector: root.LogsInstanceSelector()},
		{List: &integrations, Selector: root.IntegrationsSelector()},
	}
	if err := search(roots); err != nil {
		return deployment, nil, err
	}

	// Metrics resources
	for _, metricsInst := range metricInstances.Items {
		var (
			serviceMonitors prom.ServiceMonitorList
			podMonitors     prom.PodMonitorList
			probes          prom.ProbeList
		)
		var children = []hierarchyResource{
			{List: &serviceMonitors, Selector: metricsInst.ServiceMonitorSelector()},
			{List: &podMonitors, Selector: metricsInst.PodMonitorSelector()},
			{List: &probes, Selector: metricsInst.ProbeSelector()},
		}
		if err := search(children); err != nil {
			return deployment, nil, err
		}

		deployment.Metrics = append(deployment.Metrics, gragent.MetricsDeployment{
			Instance:        metricsInst,
			ServiceMonitors: filterServiceMonitors(l, root, &serviceMonitors).Items,
			PodMonitors:     podMonitors.Items,
			Probes:          probes.Items,
		})
	}

	// Logs resources
	for _, logsInst := range logsInstances.Items {
		var (
			podLogs gragent.PodLogsList
		)
		var children = []hierarchyResource{
			{List: &podLogs, Selector: logsInst.PodLogsSelector()},
		}
		if err := search(children); err != nil {
			return deployment, nil, err
		}

		deployment.Logs = append(deployment.Logs, gragent.LogsDeployment{
			Instance: logsInst,
			PodLogs:  podLogs.Items,
		})
	}

	// Integration resources
	for _, integration := range integrations.Items {
		deployment.Integrations = append(deployment.Integrations, gragent.IntegrationsDeployment{
			Instance: integration,
		})
	}

	// Finally, find all referenced secrets
	secrets, secretWatchers, err := buildSecrets(ctx, cli, deployment)
	if err != nil {
		return deployment, nil, fmt.Errorf("failed to discover secrets: %w", err)
	}
	deployment.Secrets = secrets
	watchers = append(watchers, secretWatchers...)

	return deployment, watchers, nil
}

type hierarchyResource struct {
	List     client.ObjectList      // List to populate
	Selector gragent.ObjectSelector // Raw selector to use for list
}

func (hr *hierarchyResource) Find(ctx context.Context, cli client.Client) (hierarchy.Selector, error) {
	sel, err := toSelector(hr.Selector)
	if err != nil {
		return nil, fmt.Errorf("failed to build selector: %w", err)
	}
	err = hierarchy.List(ctx, cli, hr.List, sel)
	if err != nil {
		return nil, fmt.Errorf("failed to list resources: %w", err)
	}
	return sel, nil
}

func toSelector(os gragent.ObjectSelector) (hierarchy.Selector, error) {
	var res hierarchy.LabelsSelector
	res.NamespaceName = os.ParentNamespace

	if os.NamespaceSelector != nil {
		sel, err := metav1.LabelSelectorAsSelector(os.NamespaceSelector)
		if err != nil {
			return nil, fmt.Errorf("invalid namespace selector: %w", err)
		}
		res.NamespaceLabels = sel
	}

	sel, err := metav1.LabelSelectorAsSelector(os.Labels)
	if err != nil {
		return nil, fmt.Errorf("invalid label selector: %w", err)
	}
	res.Labels = sel
	return &res, nil
}

func filterServiceMonitors(l log.Logger, root *gragent.GrafanaAgent, list *prom.ServiceMonitorList) *prom.ServiceMonitorList {
	items := make([]*prom.ServiceMonitor, 0, len(list.Items))

Item:
	for _, item := range list.Items {
		if root.Spec.Metrics.ArbitraryFSAccessThroughSMs.Deny {
			for _, ep := range item.Spec.Endpoints {
				err := testForArbitraryFSAccess(ep)
				if err == nil {
					continue
				}

				level.Warn(l).Log(
					"msg", "skipping service monitor",
					"agent", client.ObjectKeyFromObject(root),
					"servicemonitor", client.ObjectKeyFromObject(item),
					"err", err,
				)
				continue Item
			}
		}
		items = append(items, item)
	}

	return &prom.ServiceMonitorList{
		TypeMeta: list.TypeMeta,
		ListMeta: *list.ListMeta.DeepCopy(),
		Items:    items,
	}
}

func testForArbitraryFSAccess(e prom.Endpoint) error {
	if e.BearerTokenFile != "" {
		return fmt.Errorf("it accesses file system via bearer token file which is disallowed via GrafanaAgent specification")
	}

	if e.TLSConfig == nil {
		return nil
	}

	if e.TLSConfig.CAFile != "" || e.TLSConfig.CertFile != "" || e.TLSConfig.KeyFile != "" {
		return fmt.Errorf("it accesses file system via TLS config which is disallowed via GrafanaAgent specification")
	}

	return nil
}

func buildSecrets(ctx context.Context, cli client.Client, deploy gragent.Deployment) (secrets assets.SecretStore, watchers []hierarchy.Watcher, err error) {
	secrets = make(assets.SecretStore)

	// KeySelector caches to make sure we don't create duplicate watchers.
	var (
		usedSecretSelectors    = map[hierarchy.KeySelector]struct{}{}
		usedConfigMapSelectors = map[hierarchy.KeySelector]struct{}{}
	)

	for _, ref := range config.AssetReferences(deploy) {
		var (
			objectList client.ObjectList
			sel        hierarchy.KeySelector
		)

		switch {
		case ref.Reference.Secret != nil:
			objectList = &corev1.SecretList{}
			sel = hierarchy.KeySelector{
				Namespace: ref.Namespace,
				Name:      ref.Reference.Secret.Name,
			}
		case ref.Reference.ConfigMap != nil:
			objectList = &corev1.ConfigMapList{}
			sel = hierarchy.KeySelector{
				Namespace: ref.Namespace,
				Name:      ref.Reference.ConfigMap.Name,
			}
		}

		gvk, _ := apiutil.GVKForObject(objectList, cli.Scheme())
		if err := hierarchy.List(ctx, cli, objectList, &sel); err != nil {
			return nil, nil, fmt.Errorf("failed to find %q resource: %w", gvk.String(), err)
		}

		err := meta.EachListItem(objectList, func(o runtime.Object) error {
			var value string

			switch o := o.(type) {
			case *corev1.Secret:
				rawValue, ok := o.Data[ref.Reference.Secret.Key]
				if !ok {
					return fmt.Errorf("no key %s in Secret %s", ref.Reference.Secret.Key, o.Name)
				}
				value = string(rawValue)
			case *corev1.ConfigMap:
				var (
					dataValue, dataFound     = o.Data[ref.Reference.ConfigMap.Key]
					binaryValue, binaryFound = o.BinaryData[ref.Reference.ConfigMap.Key]
				)

				if dataFound {
					value = dataValue
				} else if binaryFound {
					value = string(binaryValue)
				} else {
					return fmt.Errorf("no key %s in ConfigMap %s", ref.Reference.ConfigMap.Key, o.Name)
				}
			}

			secrets[assets.KeyForSelector(ref.Namespace, &ref.Reference)] = value
			return nil
		})
		if err != nil {
			return nil, nil, fmt.Errorf("failed to iterate over %q list: %w", gvk.String(), err)
		}

		switch {
		case ref.Reference.Secret != nil:
			if _, used := usedSecretSelectors[sel]; used {
				continue
			}
			watchers = append(watchers, hierarchy.Watcher{
				Object:   &corev1.Secret{},
				Owner:    client.ObjectKeyFromObject(deploy.Agent),
				Selector: &sel,
			})
			usedSecretSelectors[sel] = struct{}{}
		case ref.Reference.ConfigMap != nil:
			if _, used := usedConfigMapSelectors[sel]; used {
				continue
			}
			watchers = append(watchers, hierarchy.Watcher{
				Object:   &corev1.ConfigMap{},
				Owner:    client.ObjectKeyFromObject(deploy.Agent),
				Selector: &sel,
			})
			usedConfigMapSelectors[sel] = struct{}{}
		}
	}

	return secrets, watchers, nil
}

'''
'''--- pkg/operator/build_hierarchy_test.go ---
//go:build !nonetwork && !nodocker && !race
// +build !nonetwork,!nodocker,!race

package operator

import (
	"context"
	"fmt"
	"sync"
	"testing"
	"time"

	gragent "github.com/grafana/agent/pkg/operator/apis/monitoring/v1alpha1"
	"github.com/grafana/agent/pkg/operator/hierarchy"
	"github.com/grafana/agent/pkg/util"
	"github.com/grafana/agent/pkg/util/k8s"
	"github.com/grafana/agent/pkg/util/structwalk"
	prom "github.com/prometheus-operator/prometheus-operator/pkg/apis/monitoring/v1"
	"github.com/stretchr/testify/require"
	v1 "k8s.io/api/core/v1"
	"k8s.io/apimachinery/pkg/labels"
	controller "sigs.k8s.io/controller-runtime"
	"sigs.k8s.io/controller-runtime/pkg/client"
	"sigs.k8s.io/controller-runtime/pkg/client/apiutil"
	"sigs.k8s.io/controller-runtime/pkg/manager"
)

// Test_buildHierarchy checks that an entire resource hierarchy can be
// discovered.
func Test_buildHierarchy(t *testing.T) {
	var wg sync.WaitGroup
	defer wg.Wait()

	ctx, cancel := context.WithTimeout(context.Background(), 3*time.Minute)
	defer cancel()

	l := util.TestLogger(t)
	cluster := NewTestCluster(ctx, t, l)
	cli := newTestControllerClient(t, cluster)

	resources := k8s.NewResourceSet(l, cluster)
	defer resources.Stop()
	require.NoError(t, resources.AddFile(ctx, "./testdata/test-resource-hierarchy.yaml"))

	// Get root resource
	var root gragent.GrafanaAgent
	err := cli.Get(ctx, client.ObjectKey{Namespace: "default", Name: "grafana-agent-example"}, &root)
	require.NoError(t, err)

	deployment, watchers, err := buildHierarchy(ctx, l, cli, &root)
	require.NoError(t, err)

	// Check resources in hierarchy
	{
		expectedResources := []string{
			"GrafanaAgent/grafana-agent-example",
			"MetricsInstance/primary",
			"Integration/node-exporter",
			"LogsInstance/primary",
			"PodMonitor/grafana-agents",
			"PodLogs/grafana-agents",
		}
		var gotResources []string
		structwalk.Walk(&resourceWalker{
			onResource: func(c client.Object) {
				gvk, _ := apiutil.GVKForObject(c, cli.Scheme())

				key := fmt.Sprintf("%s/%s", gvk.Kind, c.GetName())
				gotResources = append(gotResources, key)
			},
		}, deployment)

		require.ElementsMatch(t, expectedResources, gotResources)
	}

	// Check secrets
	{
		expectedSecrets := []string{
			"/secrets/default/prometheus-fake-credentials/fakeUsername",
			"/secrets/default/prometheus-fake-credentials/fakePassword",
		}
		var actualSecrets []string
		for key := range deployment.Secrets {
			actualSecrets = append(actualSecrets, string(key))
		}

		require.ElementsMatch(t, expectedSecrets, actualSecrets)
	}

	// Check configured watchers
	{
		expectedWatchers := []hierarchy.Watcher{
			{
				Object: &gragent.MetricsInstance{},
				Owner:  client.ObjectKey{Namespace: "default", Name: "grafana-agent-example"},
				Selector: &hierarchy.LabelsSelector{
					NamespaceName: "default",
					Labels:        labels.SelectorFromSet(labels.Set{"agent": "grafana-agent-example"}),
				},
			},
			{
				Object: &gragent.LogsInstance{},
				Owner:  client.ObjectKey{Namespace: "default", Name: "grafana-agent-example"},
				Selector: &hierarchy.LabelsSelector{
					NamespaceName: "default",
					Labels:        labels.SelectorFromSet(labels.Set{"agent": "grafana-agent-example"}),
				},
			},
			{
				Object: &gragent.Integration{},
				Owner:  client.ObjectKey{Namespace: "default", Name: "grafana-agent-example"},
				Selector: &hierarchy.LabelsSelector{
					NamespaceName: "default",
					Labels:        labels.SelectorFromSet(labels.Set{"agent": "grafana-agent-example"}),
				},
			},
			{
				Object: &prom.ServiceMonitor{},
				Owner:  client.ObjectKey{Namespace: "default", Name: "grafana-agent-example"},
				Selector: &hierarchy.LabelsSelector{
					NamespaceName:   "default",
					NamespaceLabels: labels.Everything(),
					Labels:          labels.SelectorFromSet(labels.Set{"instance": "primary"}),
				},
			},
			{
				Object: &prom.PodMonitor{},
				Owner:  client.ObjectKey{Namespace: "default", Name: "grafana-agent-example"},
				Selector: &hierarchy.LabelsSelector{
					NamespaceName:   "default",
					NamespaceLabels: labels.Everything(),
					Labels:          labels.SelectorFromSet(labels.Set{"instance": "primary"}),
				},
			},
			{
				Object: &prom.Probe{},
				Owner:  client.ObjectKey{Namespace: "default", Name: "grafana-agent-example"},
				Selector: &hierarchy.LabelsSelector{
					NamespaceName: "default",
					Labels:        labels.Nothing(),
				},
			},
			{
				Object: &gragent.PodLogs{},
				Owner:  client.ObjectKey{Namespace: "default", Name: "grafana-agent-example"},
				Selector: &hierarchy.LabelsSelector{
					NamespaceName:   "default",
					NamespaceLabels: labels.Everything(),
					Labels:          labels.SelectorFromSet(labels.Set{"instance": "primary"}),
				},
			},
			{
				Object: &v1.Secret{},
				Owner:  client.ObjectKey{Namespace: "default", Name: "grafana-agent-example"},
				Selector: &hierarchy.KeySelector{
					Namespace: "default",
					Name:      "prometheus-fake-credentials",
				},
			},
		}
		require.ElementsMatch(t, expectedWatchers, watchers)
	}
}

type resourceWalker struct {
	onResource func(c client.Object)
}

func (w *resourceWalker) Visit(v interface{}) (next structwalk.Visitor) {
	if v == nil {
		return nil
	}
	if obj, ok := v.(client.Object); ok {
		w.onResource(obj)
	}
	return w
}

// newTestControllerClient creates a Kubernetes client which uses a cache and
// index for retrieving objects. This more closely matches the behavior of the
// operator instead of using cluster.Client, which lacks a cache and always
// communicates directly with Kubernetes.
func newTestControllerClient(t *testing.T, cluster *k8s.Cluster) client.Client {
	t.Helper()

	ctx, cancel := context.WithCancel(context.Background())
	t.Cleanup(cancel)

	mgr, err := controller.NewManager(cluster.GetConfig(), manager.Options{
		Scheme: cluster.Client().Scheme(),
	})
	require.NoError(t, err)

	go func() {
		require.NoError(t, mgr.Start(ctx))
	}()
	require.True(t, mgr.GetCache().WaitForCacheSync(ctx))

	return mgr.GetClient()
}

'''
'''--- pkg/operator/clientutil/clientutil.go ---
package clientutil

import (
	"context"
	"fmt"
	"regexp"
	"strings"

	apps_v1 "k8s.io/api/apps/v1"
	v1 "k8s.io/api/core/v1"
	k8s_errors "k8s.io/apimachinery/pkg/api/errors"
	meta_v1 "k8s.io/apimachinery/pkg/apis/meta/v1"
	"k8s.io/apimachinery/pkg/types"
	"k8s.io/apimachinery/pkg/util/validation"
	"sigs.k8s.io/controller-runtime/pkg/client"
)

var invalidDNS1123Characters = regexp.MustCompile("[^-a-z0-9]+")

// SanitizeVolumeName ensures that the given volume name is a valid DNS-1123 label
// accepted by Kubernetes.
//
// Copied from github.com/prometheus-operator/prometheus-operator/pkg/k8sutil.
func SanitizeVolumeName(name string) string {
	name = strings.ToLower(name)
	name = invalidDNS1123Characters.ReplaceAllString(name, "-")
	if len(name) > validation.DNS1123LabelMaxLength {
		name = name[0:validation.DNS1123LabelMaxLength]
	}
	return strings.Trim(name, "-")
}

// CreateOrUpdateSecret applies the given secret against the client.
func CreateOrUpdateSecret(ctx context.Context, c client.Client, s *v1.Secret) error {
	var exist v1.Secret
	err := c.Get(ctx, client.ObjectKeyFromObject(s), &exist)
	if err != nil && !k8s_errors.IsNotFound(err) {
		return fmt.Errorf("failed to retrieve existing service: %w", err)
	}

	if k8s_errors.IsNotFound(err) {
		err := c.Create(ctx, s)
		if err != nil {
			return fmt.Errorf("failed to create service: %w", err)
		}
	} else {
		s.ResourceVersion = exist.ResourceVersion
		s.SetOwnerReferences(mergeOwnerReferences(s.GetOwnerReferences(), exist.GetOwnerReferences()))
		s.SetLabels(mergeMaps(s.Labels, exist.Labels))
		s.SetAnnotations(mergeMaps(s.Annotations, exist.Annotations))

		err := c.Update(ctx, s)
		if err != nil && !k8s_errors.IsNotFound(err) {
			return fmt.Errorf("failed to update service: %w", err)
		}
	}

	return nil
}

// CreateOrUpdateService applies the given svc against the client.
func CreateOrUpdateService(ctx context.Context, c client.Client, svc *v1.Service) error {
	var exist v1.Service
	err := c.Get(ctx, client.ObjectKeyFromObject(svc), &exist)
	if err != nil && !k8s_errors.IsNotFound(err) {
		return fmt.Errorf("failed to retrieve existing service: %w", err)
	}

	if k8s_errors.IsNotFound(err) {
		err := c.Create(ctx, svc)
		if err != nil {
			return fmt.Errorf("failed to create service: %w", err)
		}
	} else {
		svc.ResourceVersion = exist.ResourceVersion
		svc.Spec.IPFamilies = exist.Spec.IPFamilies
		svc.SetOwnerReferences(mergeOwnerReferences(svc.GetOwnerReferences(), exist.GetOwnerReferences()))
		svc.SetLabels(mergeMaps(svc.Labels, exist.Labels))
		svc.SetAnnotations(mergeMaps(svc.Annotations, exist.Annotations))

		err := c.Update(ctx, svc)
		if err != nil && !k8s_errors.IsNotFound(err) {
			return fmt.Errorf("failed to update service: %w", err)
		}
	}

	return nil
}

// CreateOrUpdateEndpoints applies the given eps against the client.
func CreateOrUpdateEndpoints(ctx context.Context, c client.Client, eps *v1.Endpoints) error {
	var exist v1.Endpoints
	err := c.Get(ctx, client.ObjectKeyFromObject(eps), &exist)
	if err != nil && !k8s_errors.IsNotFound(err) {
		return fmt.Errorf("failed to retrieve existing endpoints: %w", err)
	}

	if k8s_errors.IsNotFound(err) {
		err := c.Create(ctx, eps)
		if err != nil {
			return fmt.Errorf("failed to create endpoints: %w", err)
		}
	} else {
		eps.ResourceVersion = exist.ResourceVersion
		eps.SetOwnerReferences(mergeOwnerReferences(eps.GetOwnerReferences(), exist.GetOwnerReferences()))
		eps.SetLabels(mergeMaps(eps.Labels, exist.Labels))
		eps.SetAnnotations(mergeMaps(eps.Annotations, exist.Annotations))

		err := c.Update(ctx, eps)
		if err != nil && !k8s_errors.IsNotFound(err) {
			return fmt.Errorf("failed to update endpoints: %w", err)
		}
	}

	return nil
}

// CreateOrUpdateStatefulSet applies the given StatefulSet against the client.
func CreateOrUpdateStatefulSet(ctx context.Context, c client.Client, ss *apps_v1.StatefulSet) error {
	var exist apps_v1.StatefulSet
	err := c.Get(ctx, client.ObjectKeyFromObject(ss), &exist)
	if err != nil && !k8s_errors.IsNotFound(err) {
		return fmt.Errorf("failed to retrieve existing statefulset: %w", err)
	}

	if k8s_errors.IsNotFound(err) {
		err := c.Create(ctx, ss)
		if err != nil {
			return fmt.Errorf("failed to create statefulset: %w", err)
		}
	} else {
		ss.ResourceVersion = exist.ResourceVersion
		ss.SetOwnerReferences(mergeOwnerReferences(ss.GetOwnerReferences(), exist.GetOwnerReferences()))
		ss.SetLabels(mergeMaps(ss.Labels, exist.Labels))
		ss.SetAnnotations(mergeMaps(ss.Annotations, exist.Annotations))

		err := c.Update(ctx, ss)
		if k8s_errors.IsNotAcceptable(err) || k8s_errors.IsInvalid(err) {
			// Resource version should only be set when updating
			ss.ResourceVersion = ""

			err = c.Delete(ctx, ss)
			if err != nil {
				return fmt.Errorf("failed to update statefulset when deleting old statefulset: %w", err)
			}
			err = c.Create(ctx, ss)
			if err != nil {
				return fmt.Errorf("failed to update statefulset when creating replacement statefulset: %w", err)
			}
		} else if err != nil {
			return fmt.Errorf("failed to update statefulset: %w", err)
		}
	}

	return nil
}

// CreateOrUpdateDaemonSet applies the given DaemonSet against the client.
func CreateOrUpdateDaemonSet(ctx context.Context, c client.Client, ss *apps_v1.DaemonSet) error {
	var exist apps_v1.DaemonSet
	err := c.Get(ctx, client.ObjectKeyFromObject(ss), &exist)
	if err != nil && !k8s_errors.IsNotFound(err) {
		return fmt.Errorf("failed to retrieve existing daemonset: %w", err)
	}

	if k8s_errors.IsNotFound(err) {
		err := c.Create(ctx, ss)
		if err != nil {
			return fmt.Errorf("failed to create daemonset: %w", err)
		}
	} else {
		ss.ResourceVersion = exist.ResourceVersion
		ss.SetOwnerReferences(mergeOwnerReferences(ss.GetOwnerReferences(), exist.GetOwnerReferences()))
		ss.SetLabels(mergeMaps(ss.Labels, exist.Labels))
		ss.SetAnnotations(mergeMaps(ss.Annotations, exist.Annotations))

		err := c.Update(ctx, ss)
		if k8s_errors.IsNotAcceptable(err) || k8s_errors.IsInvalid(err) {
			// Resource version should only be set when updating
			ss.ResourceVersion = ""

			err = c.Delete(ctx, ss)
			if err != nil {
				return fmt.Errorf("failed to update daemonset: deleting old daemonset: %w", err)
			}
			err = c.Create(ctx, ss)
			if err != nil {
				return fmt.Errorf("failed to update daemonset: creating new deamonset: %w", err)
			}
		} else if err != nil {
			return fmt.Errorf("failed to update daemonset: %w", err)
		}
	}

	return nil
}

// CreateOrUpdateDeployment applies the given DaemonSet against the client.
func CreateOrUpdateDeployment(ctx context.Context, c client.Client, d *apps_v1.Deployment) error {
	var exist apps_v1.Deployment
	err := c.Get(ctx, client.ObjectKeyFromObject(d), &exist)
	if err != nil && !k8s_errors.IsNotFound(err) {
		return fmt.Errorf("failed to retrieve existing Deployment: %w", err)
	}

	if k8s_errors.IsNotFound(err) {
		err := c.Create(ctx, d)
		if err != nil {
			return fmt.Errorf("failed to create Deployment: %w", err)
		}
	} else {
		d.ResourceVersion = exist.ResourceVersion
		d.SetOwnerReferences(mergeOwnerReferences(d.GetOwnerReferences(), exist.GetOwnerReferences()))
		d.SetLabels(mergeMaps(d.Labels, exist.Labels))
		d.SetAnnotations(mergeMaps(d.Annotations, exist.Annotations))

		err := c.Update(ctx, d)
		if k8s_errors.IsNotAcceptable(err) || k8s_errors.IsInvalid(err) {
			// Resource version should only be set when updating
			d.ResourceVersion = ""

			err = c.Delete(ctx, d)
			if err != nil {
				return fmt.Errorf("failed to update Deployment: deleting old Deployment: %w", err)
			}
			err = c.Create(ctx, d)
			if err != nil {
				return fmt.Errorf("failed to update Deployment: creating new Deployment: %w", err)
			}
		} else if err != nil {
			return fmt.Errorf("failed to update Deployment: %w", err)
		}
	}

	return nil
}

func mergeOwnerReferences(new, old []meta_v1.OwnerReference) []meta_v1.OwnerReference {
	existing := make(map[types.UID]bool)
	for _, ref := range old {
		existing[ref.UID] = true
	}
	for _, ref := range new {
		if _, ok := existing[ref.UID]; !ok {
			old = append(old, ref)
		}
	}
	return old
}

func mergeMaps(new, old map[string]string) map[string]string {
	if old == nil {
		old = make(map[string]string, len(new))
	}
	for k, v := range new {
		old[k] = v
	}
	return old
}

'''
'''--- pkg/operator/clientutil/merge.go ---
package clientutil

import (
	"encoding/json"
	"fmt"

	v1 "k8s.io/api/core/v1"
	"k8s.io/apimachinery/pkg/util/strategicpatch"
)

// MergePatchContainers adds patches to base using a strategic merge patch and
// iterating by container name, failing on the first error.
//
// Copied from github.com/prometheus-operator/prometheus-operator/pkg/k8sutil.
func MergePatchContainers(base, patches []v1.Container) ([]v1.Container, error) {
	var out []v1.Container

	// map of containers that still need to be patched by name
	containersToPatch := make(map[string]v1.Container)
	for _, c := range patches {
		containersToPatch[c.Name] = c
	}

	for _, container := range base {
		// If we have a patch result, iterate over each container and try and calculate the patch
		if patchContainer, ok := containersToPatch[container.Name]; ok {
			// Get the json for the container and the patch
			containerBytes, err := json.Marshal(container)
			if err != nil {
				return nil, fmt.Errorf("failed to marshal json for container %s: %w", container.Name, err)
			}
			patchBytes, err := json.Marshal(patchContainer)
			if err != nil {
				return nil, fmt.Errorf("failed to marshal json for patch container %s: %w", container.Name, err)
			}

			// Calculate the patch result
			jsonResult, err := strategicpatch.StrategicMergePatch(containerBytes, patchBytes, v1.Container{})
			if err != nil {
				return nil, fmt.Errorf("failed to generate merge patch for %s: %w", container.Name, err)
			}
			var patchResult v1.Container
			if err := json.Unmarshal(jsonResult, &patchResult); err != nil {
				return nil, fmt.Errorf("failed to unmarshal merged container %s: %w", container.Name, err)
			}

			// Add the patch result and remove the corresponding key from the to do list
			out = append(out, patchResult)
			delete(containersToPatch, container.Name)
		} else {
			// This container didn't need to be patched
			out = append(out, container)
		}
	}

	// Iterate over the patches and add all the containers that were not previously part of a patch result
	for _, container := range patches {
		if _, ok := containersToPatch[container.Name]; ok {
			out = append(out, container)
		}
	}

	return out, nil
}

'''
'''--- pkg/operator/config/config.go ---
// Package config generates Grafana Agent configuration based on Kubernetes
// resources.
package config

import (
	"embed"
	"encoding/json"
	"fmt"
	"io/fs"
	"path"

	"github.com/fatih/structs"
	jsonnet "github.com/google/go-jsonnet"
	"github.com/google/go-jsonnet/ast"
	gragent "github.com/grafana/agent/pkg/operator/apis/monitoring/v1alpha1"
	"github.com/grafana/agent/pkg/operator/assets"
	"gopkg.in/yaml.v3"
)

// Type is the type of Agent deployment that a config is being generated
// for.
type Type int

const (
	// MetricsType generates a configuration for metrics.
	MetricsType Type = iota + 1
	// LogsType generates a configuration for logs.
	LogsType
	// IntegrationsType generates a configuration for integrations.
	IntegrationsType
)

// String returns the string form of Type.
func (t Type) String() string {
	switch t {
	case MetricsType:
		return "metrics"
	case LogsType:
		return "logs"
	case IntegrationsType:
		return "integrations"
	default:
		return fmt.Sprintf("unknown (%d)", int(t))
	}
}

//go:embed templates/*
var templates embed.FS

// TODO(rfratto): the "Optional" field of secrets is currently ignored.

// BuildConfig builds an Agent configuration file.
func BuildConfig(d *gragent.Deployment, ty Type) (string, error) {
	vm, err := createVM(d.Secrets)
	if err != nil {
		return "", err
	}

	bb, err := jsonnetMarshal(d)
	if err != nil {
		return "", err
	}

	vm.TLACode("ctx", string(bb))

	switch ty {
	case MetricsType:
		return vm.EvaluateFile("./agent-metrics.libsonnet")
	case LogsType:
		return vm.EvaluateFile("./agent-logs.libsonnet")
	case IntegrationsType:
		return vm.EvaluateFile("./agent-integrations.libsonnet")
	default:
		panic(fmt.Sprintf("unexpected config type %v", ty))
	}
}

func createVM(secrets assets.SecretStore) (*jsonnet.VM, error) {
	vm := jsonnet.MakeVM()
	vm.StringOutput = true

	templatesContents, err := fs.Sub(templates, "templates")
	if err != nil {
		return nil, err
	}

	vm.Importer(NewFSImporter(templatesContents, []string{"./"}))

	vm.NativeFunction(&jsonnet.NativeFunction{
		Name:   "marshalYAML",
		Params: ast.Identifiers{"object"},
		Func: func(i []interface{}) (interface{}, error) {
			bb, err := yaml.Marshal(i[0])
			if err != nil {
				return nil, jsonnet.RuntimeError{Msg: err.Error()}
			}
			return string(bb), nil
		},
	})
	vm.NativeFunction(&jsonnet.NativeFunction{
		Name:   "unmarshalYAML",
		Params: ast.Identifiers{"text"},
		Func:   unmarshalYAML,
	})
	vm.NativeFunction(&jsonnet.NativeFunction{
		Name:   "intoStages",
		Params: ast.Identifiers{"text"},
		Func:   intoStages,
	})

	vm.NativeFunction(&jsonnet.NativeFunction{
		Name:   "trimOptional",
		Params: ast.Identifiers{"value"},
		Func: func(i []interface{}) (interface{}, error) {
			m := i[0].(map[string]interface{})
			trimMap(m)
			return m, nil
		},
	})
	vm.NativeFunction(&jsonnet.NativeFunction{
		Name:   "secretLookup",
		Params: ast.Identifiers{"key"},
		Func: func(i []interface{}) (interface{}, error) {
			if i[0] == nil {
				return nil, nil
			}

			k := assets.Key(i[0].(string))
			val, ok := secrets[k]
			if !ok {
				return nil, jsonnet.RuntimeError{Msg: fmt.Sprintf("key not provided: %s", k)}
			}
			return val, nil
		},
	})
	vm.NativeFunction(&jsonnet.NativeFunction{
		Name:   "secretPath",
		Params: ast.Identifiers{"key"},
		Func: func(i []interface{}) (interface{}, error) {
			if i[0] == nil {
				return nil, nil
			}

			key := SanitizeLabelName(i[0].(string))
			return path.Join("/var/lib/grafana-agent/secrets", key), nil
		},
	})

	vm.NativeFunction(&jsonnet.NativeFunction{
		Name:   "sanitize",
		Params: ast.Identifiers{"text"},
		Func: func(i []interface{}) (interface{}, error) {
			if len(i) != 1 {
				return nil, jsonnet.RuntimeError{Msg: "inappropriate number of arguments"}
			}
			s, ok := i[0].(string)
			if !ok {
				return nil, jsonnet.RuntimeError{Msg: "text must be a string"}
			}
			return SanitizeLabelName(s), nil
		},
	})

	return vm, nil
}

// jsonnetMarshal marshals a value for passing to Jsonnet. This marshals to a
// JSON representation of the Go value, ignoring all json struct tags. Fields
// must be access as they would from Go, with the exception of embedded fields,
// which must be accessed through the embedded type name (a.Embedded.Field).
func jsonnetMarshal(v interface{}) ([]byte, error) {
	if structs.IsStruct(v) {
		return json.Marshal(structs.Map(v))
	}
	return json.Marshal(v)
}

'''
'''--- pkg/operator/config/config_references.go ---
package config

import (
	"github.com/grafana/agent/pkg/util/structwalk"
	prom "github.com/prometheus-operator/prometheus-operator/pkg/apis/monitoring/v1"
	corev1 "k8s.io/api/core/v1"
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
)

// AssetReference is a namespaced Secret or ConfigMap selector.
type AssetReference struct {
	Namespace string
	Reference prom.SecretOrConfigMap
}

// AssetReferences returns all secret or configmap selectors used throughout v.
func AssetReferences(v interface{}) []AssetReference {
	var refs []AssetReference
	w := assetReferencesWalker{
		addReference: func(ar AssetReference) {
			refs = append(refs, ar)
		},
	}
	structwalk.Walk(&w, v)
	return refs
}

type assetReferencesWalker struct {
	namespace    string
	addReference func(ar AssetReference)
}

func (arw *assetReferencesWalker) Visit(v interface{}) (w structwalk.Visitor) {
	if v == nil {
		return nil
	}

	// If we've come across a namespaced object, create a new visitor for that
	// namespace.
	if o, ok := v.(metav1.Object); ok {
		return &assetReferencesWalker{
			namespace:    o.GetNamespace(),
			addReference: arw.addReference,
		}
	}

	switch sel := v.(type) {
	case corev1.SecretKeySelector:
		if sel.Key != "" && sel.Name != "" {
			arw.addReference(AssetReference{
				Namespace: arw.namespace,
				Reference: prom.SecretOrConfigMap{Secret: &sel},
			})
		}
	case *corev1.SecretKeySelector:
		arw.addReference(AssetReference{
			Namespace: arw.namespace,
			Reference: prom.SecretOrConfigMap{Secret: sel},
		})
	case corev1.ConfigMapKeySelector:
		if sel.Key != "" && sel.Name != "" {
			arw.addReference(AssetReference{
				Namespace: arw.namespace,
				Reference: prom.SecretOrConfigMap{ConfigMap: &sel},
			})
		}
	case *corev1.ConfigMapKeySelector:
		arw.addReference(AssetReference{
			Namespace: arw.namespace,
			Reference: prom.SecretOrConfigMap{ConfigMap: sel},
		})
	}

	return arw
}

'''
'''--- pkg/operator/config/config_references_test.go ---
package config

import (
	"testing"

	gragent "github.com/grafana/agent/pkg/operator/apis/monitoring/v1alpha1"
	prom "github.com/prometheus-operator/prometheus-operator/pkg/apis/monitoring/v1"
	"github.com/stretchr/testify/require"
	corev1 "k8s.io/api/core/v1"
	v1 "k8s.io/apimachinery/pkg/apis/meta/v1"
)

func TestDeployment_AssetReferences(t *testing.T) {
	deployment := gragent.Deployment{
		Agent: &gragent.GrafanaAgent{
			ObjectMeta: v1.ObjectMeta{
				Namespace: "agent",
			},
			Spec: gragent.GrafanaAgentSpec{
				APIServerConfig: &prom.APIServerConfig{
					BasicAuth: &prom.BasicAuth{
						Username: corev1.SecretKeySelector{
							LocalObjectReference: corev1.LocalObjectReference{
								Name: "spec-apiserverconfig-basicauth-username",
							},
							Key: "key",
						},
					},
				},
			},
		},
		Metrics: []gragent.MetricsDeployment{{
			Instance: &gragent.MetricsInstance{
				ObjectMeta: v1.ObjectMeta{Namespace: "metrics-instance"},
			},
			PodMonitors: []*prom.PodMonitor{{
				ObjectMeta: v1.ObjectMeta{Namespace: "pmon"},
			}},
			Probes: []*prom.Probe{{
				ObjectMeta: v1.ObjectMeta{Namespace: "probe"},
			}},
			ServiceMonitors: []*prom.ServiceMonitor{{
				ObjectMeta: v1.ObjectMeta{
					Namespace: "smon",
				},
				Spec: prom.ServiceMonitorSpec{
					Endpoints: []prom.Endpoint{{
						BearerTokenSecret: corev1.SecretKeySelector{
							LocalObjectReference: corev1.LocalObjectReference{
								Name: "prometheis-servicemonitors-spec-endpoints-bearertokensecret",
							},
							Key: "key",
						},
					}},
				},
			}},
		}},
	}

	require.Equal(t, []AssetReference{
		{
			Namespace: "agent",
			Reference: prom.SecretOrConfigMap{
				Secret: &corev1.SecretKeySelector{
					LocalObjectReference: corev1.LocalObjectReference{
						Name: "spec-apiserverconfig-basicauth-username",
					},
					Key: "key",
				},
			},
		},
		{
			Namespace: "smon",
			Reference: prom.SecretOrConfigMap{
				Secret: &corev1.SecretKeySelector{
					LocalObjectReference: corev1.LocalObjectReference{
						Name: "prometheis-servicemonitors-spec-endpoints-bearertokensecret",
					},
					Key: "key",
				},
			},
		},
	}, AssetReferences(deployment))
}

'''
'''--- pkg/operator/config/config_test.go ---
package config

import (
	"fmt"
	"testing"

	"github.com/grafana/agent/pkg/operator/assets"
	"github.com/grafana/agent/pkg/util"
	"github.com/grafana/agent/pkg/util/subset"
	"github.com/stretchr/testify/assert"
	"github.com/stretchr/testify/require"
	v1 "k8s.io/api/core/v1"
	meta_v1 "k8s.io/apimachinery/pkg/apis/meta/v1"
	"k8s.io/utils/pointer"
	k8s_yaml "sigs.k8s.io/yaml"

	gragent "github.com/grafana/agent/pkg/operator/apis/monitoring/v1alpha1"
)

func TestBuildConfigMetrics(t *testing.T) {
	var store = make(assets.SecretStore)

	store[assets.Key("/secrets/default/example-secret/key")] = "somesecret"
	store[assets.Key("/configMaps/default/example-cm/key")] = "somecm"

	tt := []struct {
		input  string
		expect string
	}{
		{
			input: util.Untab(`
				metadata:
					name: example
					namespace: default
				spec:
					logLevel: debug
					metrics:
						scrapeInterval: 15s
						scrapeTimeout: 10s
						externalLabels:
							cluster: prod
							foo: bar
						remoteWrite:
						- name: rw-1
							url: http://localhost:9090/api/v1/write
			`),
			expect: util.Untab(`
				server:
					log_level: debug

				metrics:
					wal_directory: /var/lib/grafana-agent/data
					global:
						scrape_interval: 15s
						scrape_timeout: 10s
						external_labels:
							cluster: prod
							foo: bar
							__replica__: replica-$(STATEFULSET_ORDINAL_NUMBER)
						remote_write:
						- name: rw-1
							url: http://localhost:9090/api/v1/write
			`),
		},
		{
			input: util.Untab(`
					metadata:
						name: example
						namespace: default
					spec:
						logLevel: debug
						metrics:
							scrapeInterval: 15s
							scrapeTimeout: 10s
							externalLabels:
								cluster: prod
								foo: bar
							remoteWrite:
							- url: http://localhost:9090/api/v1/write
								basicAuth:
									username:
										name: example-secret
										key: key
									password:
										name: example-secret
										key: pword
								tlsConfig:
									ca:
										configMap:
											name:	example-cm
											key: key
									cert:
										secret:
											name: example-secret
											key: key
									keySecret:
										name: example-secret
										key: key
				`),
			expect: util.Untab(`
					server:
						log_level: debug

					metrics:
						wal_directory: /var/lib/grafana-agent/data
						global:
							scrape_interval: 15s
							scrape_timeout: 10s
							external_labels:
								cluster: prod
								foo: bar
								__replica__: replica-$(STATEFULSET_ORDINAL_NUMBER)
							remote_write:
							- url: http://localhost:9090/api/v1/write
								basic_auth:
									username: somesecret
									password_file: /var/lib/grafana-agent/secrets/_secrets_default_example_secret_pword
								tls_config:
									ca_file: /var/lib/grafana-agent/secrets/_configMaps_default_example_cm_key
									cert_file: /var/lib/grafana-agent/secrets/_secrets_default_example_secret_key
									key_file: /var/lib/grafana-agent/secrets/_secrets_default_example_secret_key
				`),
		},
	}

	for i, tc := range tt {
		t.Run(fmt.Sprintf("index_%d", i), func(t *testing.T) {
			var spec gragent.GrafanaAgent
			err := k8s_yaml.Unmarshal([]byte(tc.input), &spec)
			require.NoError(t, err)

			d := gragent.Deployment{Agent: &spec, Secrets: store}
			result, err := BuildConfig(&d, MetricsType)
			require.NoError(t, err)

			if !assert.YAMLEq(t, tc.expect, result) {
				fmt.Println(result)
			}
		})
	}
}

func TestAdditionalScrapeConfigsMetrics(t *testing.T) {
	var store = make(assets.SecretStore)

	additionalSelector := &v1.SecretKeySelector{
		LocalObjectReference: v1.LocalObjectReference{Name: "configs"},
		Key:                  "configs",
	}

	input := gragent.Deployment{
		Agent: &gragent.GrafanaAgent{
			ObjectMeta: meta_v1.ObjectMeta{
				Namespace: "operator",
				Name:      "agent",
			},
			Spec: gragent.GrafanaAgentSpec{
				Image:              pointer.String("grafana/agent:latest"),
				ServiceAccountName: "agent",
				Metrics: gragent.MetricsSubsystemSpec{
					InstanceSelector: &meta_v1.LabelSelector{
						MatchLabels: map[string]string{"agent": "agent"},
					},
				},
			},
		},
		Metrics: []gragent.MetricsDeployment{{
			Instance: &gragent.MetricsInstance{
				ObjectMeta: meta_v1.ObjectMeta{
					Namespace: "operator",
					Name:      "primary",
				},
				Spec: gragent.MetricsInstanceSpec{
					RemoteWrite: []gragent.RemoteWriteSpec{{
						URL: "http://cortex:80/api/prom/push",
					}},
					AdditionalScrapeConfigs: additionalSelector,
				},
			},
		}},

		Secrets: store,
	}

	store[assets.KeyForSecret("operator", additionalSelector)] = util.Untab(`
	- job_name: job
		kubernetes_sd_configs:
		- role: node
	- job_name: ec2
		ec2_sd_configs:
		- region: eu-west-1
		  port: 9100
	`)

	expect := util.Untab(`
server: {}

metrics:
  wal_directory: /var/lib/grafana-agent/data
  global:
    external_labels:
      __replica__: replica-$(STATEFULSET_ORDINAL_NUMBER)
      cluster: operator/agent
  configs:
  - name: operator/primary
    remote_write:
    - url: http://cortex:80/api/prom/push
    scrape_configs:
    - job_name: job
      kubernetes_sd_configs:
      - role: node
    - job_name: ec2
      ec2_sd_configs:
      - region: eu-west-1
        port: 9100
	`)

	result, err := BuildConfig(&input, MetricsType)
	require.NoError(t, err)

	if !assert.YAMLEq(t, expect, result) {
		fmt.Println(result)
	}
}

func TestBuildConfigLogs(t *testing.T) {
	var store = make(assets.SecretStore)

	store[assets.Key("/secrets/default/example-secret/key")] = "somesecret"
	store[assets.Key("/configMaps/default/example-cm/key")] = "somecm"

	tt := []struct {
		input  string
		expect string
	}{
		{
			input: util.Untab(`
				metadata:
					name: example
					namespace: default
				spec:
					logLevel: debug
			`),
			expect: util.Untab(`
				server:
					log_level: debug
				logs:
					positions_directory: /var/lib/grafana-agent/data
			`),
		},
	}

	for i, tc := range tt {
		t.Run(fmt.Sprintf("index_%d", i), func(t *testing.T) {
			var spec gragent.GrafanaAgent
			err := k8s_yaml.Unmarshal([]byte(tc.input), &spec)
			require.NoError(t, err)

			d := gragent.Deployment{Agent: &spec, Secrets: store}
			result, err := BuildConfig(&d, LogsType)
			require.NoError(t, err)

			if !assert.YAMLEq(t, tc.expect, result) {
				fmt.Println(result)
			}
		})
	}
}

func TestBuildConfigIntegrations(t *testing.T) {
	in := util.Untab(`
	Agent:
		kind: GrafanaAgent
		metadata:
			name: test-agent
			namespace: monitoring
	Integrations:
	- Instance:
			kind: MetricsIntegration
			metadata:
				name: mysql-a
				namespace: databases
			spec:
				name: mysqld_exporter
				config: 
					data_source_names: root@(server-a:3306)/
	- Instance:
			kind: MetricsIntegration
			metadata:
				name: node
				namespace: kube-system
			spec:
				name: node_exporter
				type:
					allNodes: true
					unique: true
				config: 
					rootfs_path: /host/root
					sysfs_path: /host/sys
					procfs_path: /host/proc
	- Instance:
			metadata:
				name: mysql-b
				namespace: databases
			spec:
				name: mysqld_exporter
				config: 
					data_source_names: root@(server-b:3306)/
	- Instance:
			kind: MetricsIntegration
			metadata:
				name: redis-a
				namespace: databases
			spec:
				name: redis_exporter
				config: 
					redis_addr: redis-a:6379
  `)

	var h gragent.Deployment
	err := k8s_yaml.UnmarshalStrict([]byte(in), &h)
	require.NoError(t, err)

	expect := util.Untab(`
	server: {}
	logs:
		positions_directory: /var/lib/grafana-agent/data
	metrics:
		global:
			external_labels:
				cluster: monitoring/test-agent
		wal_directory: /var/lib/grafana-agent/data
	integrations:
		metrics:
			autoscrape:
				enable: false
		mysqld_exporter_configs:
			- data_source_names: root@(server-a:3306)/
			- data_source_names: root@(server-b:3306)/
		node_exporter_configs:
			- rootfs_path: /host/root 
				sysfs_path: /host/sys
				procfs_path: /host/proc
		redis_exporter_configs:
			- redis_addr: redis-a:6379
  `)

	result, err := BuildConfig(&h, IntegrationsType)
	require.NoError(t, err)

	require.NoError(t, subset.YAMLAssert([]byte(expect), []byte(result)), "incomplete yaml\n%s", result)
}

// TestBuildConfigIntegrations_Instances ensures that metrics and logs
// instances are injected into the resulting config so integrations can use
// them for sending telemetry data.
func TestBuildConfigIntegrations_Instances(t *testing.T) {
	in := util.Untab(`
	Agent:
		kind: GrafanaAgent
		metadata:
			name: test-agent
			namespace: monitoring
	Metrics:
	- Instance:
			kind: MetricsInstance
			metadata:
				name: operator-metrics
				namespace: primary
			spec:
				remoteWrite:
				- url: http://cortex:80/api/prom/push
	Logs:
	- Instance:
			kind: LogsInstance
			metadata:
				name: operator-logs
				namespace: primary
			spec:
				clients:
				- url: http://loki:80/loki/api/v1/push
  `)

	var h gragent.Deployment
	err := k8s_yaml.UnmarshalStrict([]byte(in), &h)
	require.NoError(t, err)

	expect := util.Untab(`
	server: {}
	metrics:
		global:
			external_labels:
				cluster: monitoring/test-agent
		wal_directory: /var/lib/grafana-agent/data
		configs:
		- name: primary/operator-metrics
			remote_write:
			- url: http://cortex:80/api/prom/push
	logs:
		positions_directory: /var/lib/grafana-agent/data
		configs:
		- name: primary/operator-logs
			clients:
			- url: http://loki:80/loki/api/v1/push
	integrations:
		metrics:
			autoscrape:
				enable: false
  `)

	result, err := BuildConfig(&h, IntegrationsType)
	require.NoError(t, err)

	require.NoError(t, subset.YAMLAssert([]byte(expect), []byte(result)), "incomplete yaml\n%s", result)
}

'''
'''--- pkg/operator/config/fs_importer.go ---
package config

import (
	"bytes"
	"fmt"
	"io"
	"io/fs"
	"path"
	"strings"

	jsonnet "github.com/google/go-jsonnet"
)

// FSImporter implements jsonnet.Importer for a fs.FS.
type FSImporter struct {
	fs fs.FS

	cache map[string]jsonnet.Contents
	paths []string
}

// NewFSImporter creates a new jsonnet VM Importer that uses the given fs.
func NewFSImporter(f fs.FS, paths []string) *FSImporter {
	return &FSImporter{
		fs:    f,
		cache: make(map[string]jsonnet.Contents),
		paths: paths,
	}
}

// Import implements jsonnet.Importer.
func (i *FSImporter) Import(importedFrom, importedPath string) (contents jsonnet.Contents, foundAt string, err error) {
	tryPaths := append([]string{importedFrom}, i.paths...)
	for _, p := range tryPaths {
		cleanedPath := path.Clean(
			path.Join(path.Dir(p), importedPath),
		)
		cleanedPath = strings.TrimPrefix(cleanedPath, "./")

		c, fa, err := i.tryImport(cleanedPath)
		if err == nil {
			return c, fa, err
		}
	}

	return jsonnet.Contents{}, "", fmt.Errorf("no such file: %s", importedPath)
}

func (i *FSImporter) tryImport(path string) (contents jsonnet.Contents, foundAt string, err error) {
	// jsonnet expects the same "foundAt" to always return the same instance of
	// contents, so we need to return a cache here.
	if c, ok := i.cache[path]; ok {
		return c, path, nil
	}

	f, err := i.fs.Open(path)
	if err != nil {
		err = jsonnet.RuntimeError{Msg: err.Error()}
		return
	}

	var buf bytes.Buffer
	if _, copyErr := io.Copy(&buf, f); copyErr != nil {
		err = jsonnet.RuntimeError{Msg: copyErr.Error()}
		return
	}

	contents = jsonnet.MakeContents(buf.String())
	i.cache[path] = contents
	return contents, path, nil
}

'''
'''--- pkg/operator/config/integration_templates_test.go ---
package config

import (
	"testing"

	gragent "github.com/grafana/agent/pkg/operator/apis/monitoring/v1alpha1"
	"github.com/grafana/agent/pkg/util"
	"github.com/grafana/agent/pkg/util/subset"
	"github.com/stretchr/testify/require"
	apiext_v1 "k8s.io/apiextensions-apiserver/pkg/apis/apiextensions/v1"
	"sigs.k8s.io/yaml"
)

func TestIntegration(t *testing.T) {
	toJSON := func(in string) apiext_v1.JSON {
		t.Helper()
		out, err := yaml.YAMLToJSONStrict([]byte(in))
		require.NoError(t, err)
		return apiext_v1.JSON{Raw: out}
	}

	tt := []struct {
		name   string
		input  map[string]interface{}
		expect string
	}{
		{
			name: "configured integration",
			input: map[string]interface{}{
				"integration": &gragent.Integration{
					Spec: gragent.IntegrationSpec{
						Name: "mysqld_exporter",
						Config: toJSON(`
              data_source_names: root@(server-a:3306)/
            `),
					},
				},
			},
			expect: util.Untab(`
				data_source_names: root@(server-a:3306)/
      `),
		},
		{
			name: "integration no config",
			input: map[string]interface{}{
				"integration": &gragent.Integration{
					Spec: gragent.IntegrationSpec{
						Name: "mysqld_exporter",
					},
				},
			},
			expect: util.Untab(`{}`),
		},
	}

	for _, tc := range tt {
		t.Run(tc.name, func(t *testing.T) {
			vm, err := createVM(testStore())
			require.NoError(t, err)

			actual, err := runSnippetTLA(t, vm, "./integrations.libsonnet", tc.input)
			require.NoError(t, err)
			require.NoError(t, subset.YAMLAssert([]byte(tc.expect), []byte(actual)), "incomplete yaml\n%s", actual)
		})
	}
}

'''
'''--- pkg/operator/config/logs_templates_test.go ---
package config

import (
	"fmt"
	"strings"
	"testing"

	jsonnet "github.com/google/go-jsonnet"
	prom "github.com/prometheus-operator/prometheus-operator/pkg/apis/monitoring/v1"
	prom_v1 "github.com/prometheus-operator/prometheus-operator/pkg/apis/monitoring/v1"
	"github.com/stretchr/testify/require"
	v1 "k8s.io/api/core/v1"
	meta_v1 "k8s.io/apimachinery/pkg/apis/meta/v1"
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"

	gragent "github.com/grafana/agent/pkg/operator/apis/monitoring/v1alpha1"
	"github.com/grafana/agent/pkg/operator/assets"
	"github.com/grafana/agent/pkg/util"
)

func TestLogsClientConfig(t *testing.T) {
	agent := &gragent.GrafanaAgent{
		ObjectMeta: metav1.ObjectMeta{
			Namespace: "telemetry",
			Name:      "grafana-agent",
		},
	}

	tt := []struct {
		name   string
		input  map[string]interface{}
		expect string
	}{
		{
			name: "all-in-one URL",
			input: map[string]interface{}{
				"agent":     agent,
				"namespace": "operator",
				"spec": &gragent.LogsClientSpec{
					URL: "http://username:password@localhost:3100/loki/api/v1/push",
				},
			},
			expect: util.Untab(`
				url: http://username:password@localhost:3100/loki/api/v1/push
				external_labels:
					cluster: telemetry/grafana-agent
			`),
		},
		{
			name: "full basic config",
			input: map[string]interface{}{
				"agent":     agent,
				"namespace": "operator",
				"spec": &gragent.LogsClientSpec{
					URL:       "http://localhost:3100/loki/api/v1/push",
					TenantID:  "tenant",
					BatchWait: "5m",
					BatchSize: 500,
					Timeout:   "5m",
					ExternalLabels: map[string]string{
						"foo":  "bar",
						"fizz": "buzz",
					},
					ProxyURL: "http://proxy:3100/",
					BackoffConfig: &gragent.LogsBackoffConfigSpec{
						MinPeriod:  "500ms",
						MaxPeriod:  "5m",
						MaxRetries: 100,
					},
				},
			},
			expect: util.Untab(`
				url: http://localhost:3100/loki/api/v1/push
				tenant_id: tenant
				batchwait: 5m
				batchsize: 500
				proxy_url: http://proxy:3100/
				backoff_config:
					min_period: 500ms
					max_period: 5m
					max_retries: 100
				external_labels:
					cluster: telemetry/grafana-agent
					foo: bar
					fizz: buzz
				timeout: 5m
			`),
		},
		{
			name: "tls config",
			input: map[string]interface{}{
				"agent":     agent,
				"namespace": "operator",
				"spec": &gragent.LogsClientSpec{
					URL: "http://localhost:3100/loki/api/v1/push",
					TLSConfig: &prom.TLSConfig{
						CAFile:   "ca",
						KeyFile:  "key",
						CertFile: "cert",
					},
				},
			},
			expect: util.Untab(`
				url: http://localhost:3100/loki/api/v1/push
				tls_config:
					ca_file: ca
					key_file: key
					cert_file: cert
				external_labels:
					cluster: telemetry/grafana-agent
			`),
		},
		{
			name: "bearer tokens",
			input: map[string]interface{}{
				"agent":     agent,
				"namespace": "operator",
				"spec": &gragent.LogsClientSpec{
					URL:             "http://localhost:3100/loki/api/v1/push",
					BearerToken:     "tok",
					BearerTokenFile: "tokfile",
				},
			},
			expect: util.Untab(`
				url: http://localhost:3100/loki/api/v1/push
				bearer_token: tok
				bearer_token_file: tokfile
				external_labels:
					cluster: telemetry/grafana-agent
			`),
		},
		{
			name: "basic auth",
			input: map[string]interface{}{
				"agent":     agent,
				"namespace": "operator",
				"spec": &gragent.LogsClientSpec{
					URL: "http://localhost:3100/loki/api/v1/push",
					BasicAuth: &prom.BasicAuth{
						Username: v1.SecretKeySelector{
							LocalObjectReference: v1.LocalObjectReference{Name: "obj"},
							Key:                  "key",
						},
						Password: v1.SecretKeySelector{
							LocalObjectReference: v1.LocalObjectReference{Name: "obj"},
							Key:                  "key",
						},
					},
				},
			},
			expect: util.Untab(`
				url: http://localhost:3100/loki/api/v1/push
				basic_auth:
					username: secretkey
					password: secretkey
				external_labels:
					cluster: telemetry/grafana-agent
			`),
		},
	}

	for _, tc := range tt {
		t.Run(tc.name, func(t *testing.T) {
			vm, err := createVM(testStore())
			require.NoError(t, err)

			actual, err := runSnippetTLA(t, vm, "./component/logs/client.libsonnet", tc.input)
			require.NoError(t, err)
			require.YAMLEq(t, tc.expect, actual)
		})
	}
}

func TestLogsStages(t *testing.T) {
	tt := []struct {
		name   string
		input  map[string]interface{}
		expect string
	}{
		{
			name: "docker",
			input: map[string]interface{}{"spec": &gragent.PipelineStageSpec{
				Docker: &gragent.DockerStageSpec{},
			}},
			expect: util.Untab(`docker: {}`),
		},
		{
			name: "cri",
			input: map[string]interface{}{"spec": &gragent.PipelineStageSpec{
				CRI: &gragent.CRIStageSpec{},
			}},
			expect: util.Untab(`cri: {}`),
		},
		{
			name: "regex",
			input: map[string]interface{}{"spec": &gragent.PipelineStageSpec{
				Regex: &gragent.RegexStageSpec{
					Source:     "time",
					Expression: "^(?P<year>\\d+)",
				},
			}},
			expect: util.Untab(`
				regex:
					expression: '^(?P<year>\d+)'
					source: time
			`),
		},
		{
			name: "json",
			input: map[string]interface{}{"spec": &gragent.PipelineStageSpec{
				JSON: &gragent.JSONStageSpec{
					Expressions: map[string]string{"user": ""},
					Source:      "extra",
				},
			}},
			expect: util.Untab(`
				json:
					expressions:
						user: ""
					source: extra
			`),
		},
		{
			name: "labelallow",
			input: map[string]interface{}{"spec": &gragent.PipelineStageSpec{
				LabelAllow: []string{"foo", "bar"},
			}},
			expect: util.Untab(`
				labelallow: [foo, bar]
			`),
		},
		{
			name: "labeldrop",
			input: map[string]interface{}{"spec": &gragent.PipelineStageSpec{
				LabelDrop: []string{"foo", "bar"},
			}},
			expect: util.Untab(`
				labeldrop: [foo, bar]
			`),
		},
		{
			name: "labels",
			input: map[string]interface{}{"spec": &gragent.PipelineStageSpec{
				Labels: map[string]string{
					"foo":  "",
					"fizz": "buzz",
				},
			}},
			expect: util.Untab(`
				labels:
					foo: ""
					fizz: buzz
			`),
		},
		{
			name: "match",
			input: map[string]interface{}{"spec": &gragent.PipelineStageSpec{
				Match: &gragent.MatchStageSpec{
					PipelineName:      "app2",
					Selector:          `{app="pokey"}`,
					Action:            "keep",
					DropCounterReason: "no_pokey",
					Stages: util.Untab(`
					- json:
  			      expressions:
							  msg: msg
					`),
				},
			}},
			expect: util.Untab(`
				match:
					pipeline_name: app2
					selector: '{app="pokey"}'
					action: keep
					drop_counter_reason: no_pokey
					stages:
					- json:
							expressions:
								msg: msg
			`),
		},
		{
			name: "metrics",
			input: map[string]interface{}{"spec": &gragent.PipelineStageSpec{
				Metrics: map[string]gragent.MetricsStageSpec{
					"logs_line_total": {
						Type:            "counter",
						Description:     "total number of log lines",
						Prefix:          "my_promtail_custom_",
						MaxIdleDuration: "24h",
						MatchAll:        boolPtr(true),
						Action:          "inc",
					},
					"queue_elements": {
						Type:        "gauge",
						Description: "elements in queue",
						Action:      "add",
					},
					"http_response_time_seconds": {
						Type:    "histogram",
						Source:  "response_time",
						Action:  "inc",
						Buckets: []string{"0.001", "0.0025", "0.050"},
					},
				},
			}},
			expect: util.Untab(`
				metrics:
					logs_line_total:
						type: Counter
						description: total number of log lines
						prefix: my_promtail_custom_
						max_idle_duration: 24h
						config:
							match_all: true
							action: inc
					queue_elements:
						type: Gauge
						description: elements in queue
						config:
							action: add
					http_response_time_seconds:
						type: Histogram
						source: response_time
						config:
							action: inc
							buckets: [0.001, 0.0025, 0.050]
			`),
		},
		{
			name: "multiline",
			input: map[string]interface{}{"spec": &gragent.PipelineStageSpec{
				Multiline: &gragent.MultilineStageSpec{
					FirstLine:   "first",
					MaxWaitTime: "5m",
					MaxLines:    5,
				},
			}},
			expect: util.Untab(`
				multiline:
					firstline: first
					max_wait_time: 5m
					max_lines: 5
			`),
		},
		{
			name: "output",
			input: map[string]interface{}{"spec": &gragent.PipelineStageSpec{
				Output: &gragent.OutputStageSpec{Source: "message"},
			}},
			expect: util.Untab(`
				output:
					source: message
			`),
		},
		{
			name: "pack",
			input: map[string]interface{}{"spec": &gragent.PipelineStageSpec{
				Pack: &gragent.PackStageSpec{
					Labels:          []string{"foo", "bar"},
					IngestTimestamp: true,
				},
			}},
			expect: util.Untab(`
				pack:
					labels: [foo, bar]
					ingest_timestamp: true
			`),
		},
		{
			name: "regex",
			input: map[string]interface{}{"spec": &gragent.PipelineStageSpec{
				Regex: &gragent.RegexStageSpec{
					Source:     "msg",
					Expression: "some regex",
				},
			}},
			expect: util.Untab(`
				regex:
					source: msg
					expression: some regex
			`),
		},
		{
			name: "replace",
			input: map[string]interface{}{"spec": &gragent.PipelineStageSpec{
				Replace: &gragent.ReplaceStageSpec{
					Expression: "password (\\S+)",
					Replace:    "****",
					Source:     "msg",
				},
			}},
			expect: util.Untab(`
				replace:
					expression: 'password (\S+)'
					replace: '****'
					source: msg
			`),
		},
		{
			name: "template",
			input: map[string]interface{}{"spec": &gragent.PipelineStageSpec{
				Template: &gragent.TemplateStageSpec{
					Source:   "new_key",
					Template: "hello world!",
				},
			}},
			expect: util.Untab(`
				template:
					source: new_key
					template: "hello world!"
			`),
		},
		{
			name: "tenant",
			input: map[string]interface{}{"spec": &gragent.PipelineStageSpec{
				Tenant: &gragent.TenantStageSpec{
					Source: "customer_id",
					Value:  "fake",
				},
			}},
			expect: util.Untab(`
				tenant:
					source: customer_id
					value: fake
			`),
		},
		{
			name: "timestamp",
			input: map[string]interface{}{"spec": &gragent.PipelineStageSpec{
				Timestamp: &gragent.TimestampStageSpec{
					Source:          "time",
					Format:          "RFC3339Nano",
					FallbackFormats: []string{"UnixNs"},
					Location:        "America/New_York",
					ActionOnFailure: "fudge",
				},
			}},
			expect: util.Untab(`
				timestamp:
					source: time
					format: RFC3339Nano
					fallback_formats: [UnixNs]
					location: America/New_York
					action_on_failure: fudge
			`),
		},
	}

	for _, tc := range tt {
		t.Run(tc.name, func(t *testing.T) {
			vm, err := createVM(testStore())
			require.NoError(t, err)

			actual, err := runSnippetTLA(t, vm, "./component/logs/stages.libsonnet", tc.input)
			require.NoError(t, err)
			require.YAMLEq(t, tc.expect, actual)
		})
	}
}

func TestPodLogsConfig(t *testing.T) {
	tt := []struct {
		name   string
		input  map[string]interface{}
		expect string
	}{
		{
			name: "default",
			input: map[string]interface{}{
				"agentNamespace": "operator",
				"podLogs": gragent.PodLogs{
					ObjectMeta: meta_v1.ObjectMeta{
						Namespace: "operator",
						Name:      "podlogs",
					},
					Spec: gragent.PodLogsSpec{
						RelabelConfigs: []*prom_v1.RelabelConfig{{
							SourceLabels: []prom.LabelName{"input_a", "input_b"},
							Separator:    ";",
							TargetLabel:  "target_a",
							Regex:        "regex",
							Modulus:      1234,
							Replacement:  "foobar",
							Action:       "replace",
						}},
					},
				},
				"apiServer":                prom_v1.APIServerConfig{},
				"ignoreNamespaceSelectors": false,
				"enforcedNamespaceLabel":   "",
			},
			expect: util.Untab(`
				job_name: podLogs/operator/podlogs
				kubernetes_sd_configs:
				- role: pod
				  namespaces:
						names: [operator]
				relabel_configs:
				- source_labels: [job]
					target_label: __tmp_prometheus_job_name
				- source_labels: [__meta_kubernetes_namespace]
					target_label: namespace
				- source_labels: [__meta_kubernetes_service_name]
					target_label: service
				- source_labels: [__meta_kubernetes_pod_name]
					target_label: pod
				- source_labels: [__meta_kubernetes_pod_container_name]
					target_label: container
				- target_label: job
					replacement: operator/podlogs
				- source_labels: ['__meta_kubernetes_pod_uid', '__meta_kubernetes_pod_container_name']
					target_label: __path__
					separator: /
					replacement: /var/log/pods/*$1/*.log
				- source_labels: ["input_a", "input_b"]
					separator: ";"
					target_label: "target_a"
					regex: regex
					modulus: 1234
					replacement: foobar
					action: replace
			`),
		},
	}

	for _, tc := range tt {
		t.Run(tc.name, func(t *testing.T) {
			vm, err := createVM(testStore())
			require.NoError(t, err)

			actual, err := runSnippetTLA(t, vm, "./component/logs/pod_logs.libsonnet", tc.input)
			require.NoError(t, err)
			require.YAMLEq(t, tc.expect, actual)
		})
	}
}

func TestLogsConfig(t *testing.T) {
	agent := &gragent.GrafanaAgent{
		ObjectMeta: metav1.ObjectMeta{
			Namespace: "operator",
			Name:      "grafana-agent",
		},
	}

	tt := []struct {
		name   string
		input  map[string]interface{}
		expect string
	}{
		{
			name: "global clients",
			input: map[string]interface{}{
				"agent": agent,
				"global": &gragent.LogsSubsystemSpec{
					Clients: []gragent.LogsClientSpec{{URL: "global"}},
				},
				"instance": &gragent.LogsDeployment{
					Instance: &gragent.LogsInstance{
						ObjectMeta: metav1.ObjectMeta{
							Namespace: "inst",
							Name:      "default",
						},
						Spec: gragent.LogsInstanceSpec{},
					},
				},
				"apiServer": &prom.APIServerConfig{},

				"ignoreNamespaceSelectors": false,
				"enforcedNamespaceLabel":   "",
			},
			expect: util.Untab(`
				name: inst/default
				clients:
				- url: global
				  external_labels:
					  cluster: operator/grafana-agent
			`),
		},
		{
			name: "local clients",
			input: map[string]interface{}{
				"agent": agent,
				"global": &gragent.LogsSubsystemSpec{
					Clients: []gragent.LogsClientSpec{{URL: "global"}},
				},
				"instance": &gragent.LogsDeployment{
					Instance: &gragent.LogsInstance{
						ObjectMeta: metav1.ObjectMeta{
							Namespace: "inst",
							Name:      "default",
						},
						Spec: gragent.LogsInstanceSpec{
							Clients: []gragent.LogsClientSpec{{URL: "local"}},
						},
					},
				},
				"apiServer": &prom.APIServerConfig{},

				"ignoreNamespaceSelectors": false,
				"enforcedNamespaceLabel":   "",
			},
			expect: util.Untab(`
				name: inst/default
				clients:
				- url: local
				  external_labels:
					  cluster: operator/grafana-agent
			`),
		},
		{
			name: "pod logs",
			input: map[string]interface{}{
				"agent":  agent,
				"global": &gragent.LogsSubsystemSpec{},
				"instance": &gragent.LogsDeployment{
					Instance: &gragent.LogsInstance{
						ObjectMeta: metav1.ObjectMeta{Namespace: "inst", Name: "default"},
					},
					PodLogs: []*gragent.PodLogs{{
						ObjectMeta: metav1.ObjectMeta{Namespace: "app", Name: "pod"},
					}},
				},
				"apiServer": &prom.APIServerConfig{},

				"ignoreNamespaceSelectors": false,
				"enforcedNamespaceLabel":   "",
			},
			expect: util.Untab(`
				name: inst/default
				scrape_configs:
				- job_name: podLogs/app/pod
					kubernetes_sd_configs:
					- namespaces:
							names:
							- app
						role: pod
					relabel_configs:
					- source_labels:
						- job
						target_label: __tmp_prometheus_job_name
					- source_labels:
						- __meta_kubernetes_namespace
						target_label: namespace
					- source_labels:
						- __meta_kubernetes_service_name
						target_label: service
					- source_labels:
						- __meta_kubernetes_pod_name
						target_label: pod
					- source_labels:
						- __meta_kubernetes_pod_container_name
						target_label: container
					- replacement: app/pod
						target_label: job
					- source_labels: ['__meta_kubernetes_pod_uid', '__meta_kubernetes_pod_container_name']
						target_label: __path__
						separator: /
						replacement: /var/log/pods/*$1/*.log
			`),
		},
		{
			name: "additional scrape configs",
			input: map[string]interface{}{
				"agent":  agent,
				"global": &gragent.LogsSubsystemSpec{},
				"instance": &gragent.LogsDeployment{
					Instance: &gragent.LogsInstance{
						ObjectMeta: metav1.ObjectMeta{Namespace: "inst", Name: "default"},
						Spec: gragent.LogsInstanceSpec{
							AdditionalScrapeConfigs: &v1.SecretKeySelector{
								LocalObjectReference: v1.LocalObjectReference{Name: "additional"},
								Key:                  "configs",
							},
						},
					},
				},
				"apiServer": &prom.APIServerConfig{},

				"ignoreNamespaceSelectors": false,
				"enforcedNamespaceLabel":   "",
			},
			expect: util.Untab(`
				name: inst/default
				scrape_configs:
					- job_name: extra
			`),
		},
	}

	for _, tc := range tt {
		t.Run(tc.name, func(t *testing.T) {
			s := testStore()

			s[assets.KeyForSecret("inst", &v1.SecretKeySelector{
				LocalObjectReference: v1.LocalObjectReference{
					Name: "additional",
				},
				Key: "configs",
			})] = `[{ "job_name": "extra" }]`

			vm, err := createVM(s)
			require.NoError(t, err)

			actual, err := runSnippetTLA(t, vm, "./logs.libsonnet", tc.input)
			require.NoError(t, err)
			require.YAMLEq(t, tc.expect, actual)
		})
	}
}

func runSnippetTLA(t *testing.T, vm *jsonnet.VM, filename string, tla map[string]interface{}) (string, error) {
	t.Helper()

	args := make([]string, 0, len(tla))
	for arg := range tla {
		args = append(args, arg)
	}

	boundArgs := make([]string, len(args))
	for i := range args {
		boundArgs[i] = fmt.Sprintf("%[1]s=%[1]s", args[i])
	}

	// Bind argument to TLA.
	for arg, value := range tla {
		bb, err := jsonnetMarshal(value)
		require.NoError(t, err)
		vm.TLACode(arg, string(bb))
	}

	return vm.EvaluateAnonymousSnippet(
		filename,
		fmt.Sprintf(`
			local marshal = import './ext/marshal.libsonnet';
			local optionals = import './ext/optionals.libsonnet';
			local eval = import '%s';
			function(%s) marshal.YAML(optionals.trim(eval(%s)))
		`, filename, strings.Join(args, ","), strings.Join(boundArgs, ",")),
	)
}

func boolPtr(v bool) *bool { return &v }

'''
'''--- pkg/operator/config/metrics_templates_test.go ---
package config

import (
	"fmt"
	"os"
	"strings"
	"testing"

	jsonnet "github.com/google/go-jsonnet"
	gragent "github.com/grafana/agent/pkg/operator/apis/monitoring/v1alpha1"
	"github.com/grafana/agent/pkg/operator/assets"
	"github.com/grafana/agent/pkg/util"
	prom_v1 "github.com/prometheus-operator/prometheus-operator/pkg/apis/monitoring/v1"
	"github.com/stretchr/testify/assert"
	"github.com/stretchr/testify/require"
	v1 "k8s.io/api/core/v1"
	meta_v1 "k8s.io/apimachinery/pkg/apis/meta/v1"
	"k8s.io/utils/pointer"
)

func TestExternalLabels(t *testing.T) {
	tt := []struct {
		name       string
		input      interface{}
		addReplica bool
		expect     string
	}{
		{
			name:       "no replica",
			addReplica: false,
			input: gragent.Deployment{
				Agent: &gragent.GrafanaAgent{
					ObjectMeta: meta_v1.ObjectMeta{
						Namespace: "operator",
						Name:      "agent",
					},
				},
			},
			expect: util.Untab(`
				cluster: operator/agent
			`),
		},
		{
			name:       "defaults",
			addReplica: true,
			input: gragent.Deployment{
				Agent: &gragent.GrafanaAgent{
					ObjectMeta: meta_v1.ObjectMeta{
						Namespace: "operator",
						Name:      "agent",
					},
				},
			},
			expect: util.Untab(`
				cluster: operator/agent
				__replica__: replica-$(STATEFULSET_ORDINAL_NUMBER)
			`),
		},
		{
			name:       "external_labels",
			addReplica: true,
			input: gragent.Deployment{
				Agent: &gragent.GrafanaAgent{
					ObjectMeta: meta_v1.ObjectMeta{
						Namespace: "operator",
						Name:      "agent",
					},
					Spec: gragent.GrafanaAgentSpec{
						Metrics: gragent.MetricsSubsystemSpec{
							ExternalLabels: map[string]string{"foo": "bar"},
						},
					},
				},
			},
			expect: util.Untab(`
				cluster: operator/agent
				foo: bar
				__replica__: replica-$(STATEFULSET_ORDINAL_NUMBER)
			`),
		},
		{
			name:       "custom labels",
			addReplica: true,
			input: gragent.Deployment{
				Agent: &gragent.GrafanaAgent{
					ObjectMeta: meta_v1.ObjectMeta{
						Namespace: "operator",
						Name:      "agent",
					},
					Spec: gragent.GrafanaAgentSpec{
						Metrics: gragent.MetricsSubsystemSpec{
							MetricsExternalLabelName: pointer.String("deployment"),
							ReplicaExternalLabelName: pointer.String("replica"),
							ExternalLabels:           map[string]string{"foo": "bar"},
						},
					},
				},
			},
			expect: util.Untab(`
				deployment: operator/agent
				foo: bar
				replica: replica-$(STATEFULSET_ORDINAL_NUMBER)
			`),
		},
	}

	for _, tc := range tt {
		t.Run(tc.name, func(t *testing.T) {
			vm, err := createVM(nil)
			require.NoError(t, err)
			bb, err := jsonnetMarshal(tc.input)
			require.NoError(t, err)

			vm.TLACode("ctx", string(bb))
			vm.TLACode("addReplica", fmt.Sprintf("%v", tc.addReplica))
			actual, err := runSnippet(vm, "./component/metrics/external_labels.libsonnet", "ctx", "addReplica")
			require.NoError(t, err)
			require.YAMLEq(t, tc.expect, actual)
		})
	}
}

func TestKubeSDConfig(t *testing.T) {
	tt := []struct {
		name   string
		input  map[string]interface{}
		expect string
	}{
		{
			name: "defaults",
			input: map[string]interface{}{
				"namespace": "operator",
				"role":      "pod",
			},
			expect: util.Untab(`
				role: pod
			`),
		},
		{
			name: "defaults",
			input: map[string]interface{}{
				"namespace":  "operator",
				"namespaces": []string{"operator"},
				"role":       "pod",
			},
			expect: util.Untab(`
				role: pod
				namespaces:
					names: [operator]
			`),
		},
		{
			name: "host",
			input: map[string]interface{}{
				"namespace": "operator",
				"apiServer": &prom_v1.APIServerConfig{Host: "host"},
				"role":      "pod",
			},
			expect: util.Untab(`
				role: pod
				api_server: host
			`),
		},
		{
			name: "basic auth",
			input: map[string]interface{}{
				"namespace": "operator",
				"apiServer": &prom_v1.APIServerConfig{
					BasicAuth: &prom_v1.BasicAuth{
						Username: v1.SecretKeySelector{
							LocalObjectReference: v1.LocalObjectReference{Name: "obj"},
							Key:                  "key",
						},
						Password: v1.SecretKeySelector{
							LocalObjectReference: v1.LocalObjectReference{Name: "obj"},
							Key:                  "key",
						},
					},
				},
				"role": "pod",
			},
			expect: util.Untab(`
				role: pod
				basic_auth:
					username: secretkey
					password: secretkey
			`),
		},
		{
			name: "bearer auth",
			input: map[string]interface{}{
				"namespace": "operator",
				"apiServer": &prom_v1.APIServerConfig{
					BearerToken:     "bearer",
					BearerTokenFile: "file",
				},
				"role": "pod",
			},
			expect: util.Untab(`
				role: pod
				authorization:
					type: Bearer
					credentials: bearer
					credentials_file: file
			`),
		},
		{
			name: "tls_config",
			input: map[string]interface{}{
				"namespace": "operator",
				"apiServer": &prom_v1.APIServerConfig{
					TLSConfig: &prom_v1.TLSConfig{
						CAFile: "ca",
					},
				},
				"role": "pod",
			},
			expect: util.Untab(`
				role: pod
				tls_config:
					ca_file: ca
			`),
		},
	}

	for _, tc := range tt {
		t.Run(tc.name, func(t *testing.T) {
			vm, err := createVM(testStore())
			require.NoError(t, err)

			args := []string{"namespace", "namespaces", "apiServer", "role"}
			for _, arg := range args {
				bb, err := jsonnetMarshal(tc.input[arg])
				require.NoError(t, err)
				vm.TLACode(arg, string(bb))
			}

			actual, err := runSnippet(vm, "./component/metrics/kube_sd_config.libsonnet", args...)
			require.NoError(t, err)
			require.YAMLEq(t, tc.expect, actual)
		})
	}
}

func TestPodMonitor(t *testing.T) {
	tt := []struct {
		name   string
		input  map[string]interface{}
		expect string
	}{
		{
			name: "default",
			input: map[string]interface{}{
				"agentNamespace": "operator",
				"monitor": prom_v1.PodMonitor{
					ObjectMeta: meta_v1.ObjectMeta{
						Namespace: "operator",
						Name:      "podmonitor",
					},
				},
				"endpoint": prom_v1.PodMetricsEndpoint{
					Port: "metrics",
				},
				"index":                    0,
				"apiServer":                prom_v1.APIServerConfig{},
				"overrideHonorLabels":      false,
				"overrideHonorTimestamps":  false,
				"ignoreNamespaceSelectors": false,
				"enforcedNamespaceLabel":   "",
				"enforcedSampleLimit":      nil,
				"enforcedTargetLimit":      nil,
				"shards":                   1,
			},
			expect: util.Untab(`
				job_name: podMonitor/operator/podmonitor/0
				honor_labels: false
				kubernetes_sd_configs:
				- role: pod
				  namespaces:
						names: [operator]
				relabel_configs:
				- source_labels: [job]
					target_label: __tmp_prometheus_job_name
				- source_labels: [__meta_kubernetes_pod_container_port_name]
					regex: metrics
					action: keep
				- source_labels: [__meta_kubernetes_namespace]
					target_label: namespace
				- source_labels: [__meta_kubernetes_service_name]
					target_label: service
				- source_labels: [__meta_kubernetes_pod_name]
					target_label: pod
				- source_labels: [__meta_kubernetes_pod_container_name]
					target_label: container
				- target_label: job
					replacement: operator/podmonitor
				- target_label: endpoint
					replacement: metrics
				- source_labels: [__address__]
					target_label: __tmp_hash
					action: hashmod
					modulus: 1
				- source_labels: [__tmp_hash]
					action: keep
					regex: $(SHARD)
			`),
		},
	}

	for _, tc := range tt {
		t.Run(tc.name, func(t *testing.T) {
			vm, err := createVM(testStore())
			require.NoError(t, err)

			args := []string{
				"agentNamespace", "monitor", "endpoint", "index", "apiServer", "overrideHonorLabels",
				"overrideHonorTimestamps", "ignoreNamespaceSelectors", "enforcedNamespaceLabel",
				"enforcedSampleLimit", "enforcedTargetLimit", "shards",
			}
			for _, arg := range args {
				bb, err := jsonnetMarshal(tc.input[arg])
				require.NoError(t, err)
				vm.TLACode(arg, string(bb))
			}

			actual, err := runSnippet(vm, "./component/metrics/pod_monitor.libsonnet", args...)
			require.NoError(t, err)
			if !assert.YAMLEq(t, tc.expect, actual) {
				fmt.Fprintln(os.Stderr, actual)
			}
		})
	}
}

func TestProbe(t *testing.T) {
	tt := []struct {
		name   string
		input  map[string]interface{}
		expect string
	}{
		{
			name: "default",
			input: map[string]interface{}{
				"agentNamespace": "operator",
				"probe": prom_v1.Probe{
					ObjectMeta: meta_v1.ObjectMeta{
						Namespace: "operator",
						Name:      "probe",
					},
					Spec: prom_v1.ProbeSpec{
						Module: "mod",
						Targets: prom_v1.ProbeTargets{
							Ingress: &prom_v1.ProbeTargetIngress{
								Selector: meta_v1.LabelSelector{
									MatchLabels: map[string]string{"foo": "bar"},
								},
							},
						},
					},
				},
				"apiServer":                prom_v1.APIServerConfig{},
				"overrideHonorTimestamps":  false,
				"ignoreNamespaceSelectors": false,
				"enforcedNamespaceLabel":   "",
				"enforcedSampleLimit":      nil,
				"enforcedTargetLimit":      nil,
				"shards":                   1,
			},
			expect: util.Untab(`
				job_name: probe/operator/probe
				honor_timestamps: true
				kubernetes_sd_configs:
				- role: ingress
					namespaces:
						names: [operator]
				metrics_path: /probe
				params:
					module: ["mod"]
				relabel_configs:
				- source_labels: [job]
					target_label: __tmp_prometheus_job_name
				- action: keep
					regex: bar
					source_labels: [__meta_kubernetes_ingress_label_foo]
				- action: replace
					regex: (.+);(.+);(.+)
					replacement: $1://$2$3
					separator: ;
					source_labels:
						- __meta_kubernetes_ingress_scheme
						- __address__
						- __meta_kubernetes_ingress_path
					target_label: __param_target
				- source_labels: [__meta_kubernetes_namespace]
					target_label: namespace
				- source_labels: [__meta_kubernetes_ingress_name]
					target_label: ingress
				- source_labels: [__param_target]
					target_label: instance
				- replacement: ""
					target_label: __address__
			`),
		},
	}

	for _, tc := range tt {
		t.Run(tc.name, func(t *testing.T) {
			vm, err := createVM(testStore())
			require.NoError(t, err)

			args := []string{
				"agentNamespace", "probe", "apiServer", "overrideHonorTimestamps",
				"ignoreNamespaceSelectors", "enforcedNamespaceLabel",
				"enforcedSampleLimit", "enforcedTargetLimit", "shards",
			}
			for _, arg := range args {
				bb, err := jsonnetMarshal(tc.input[arg])
				require.NoError(t, err)
				vm.TLACode(arg, string(bb))
			}

			actual, err := runSnippet(vm, "./component/metrics/probe.libsonnet", args...)
			require.NoError(t, err)
			if !assert.YAMLEq(t, tc.expect, actual) {
				fmt.Fprintln(os.Stderr, actual)
			}
		})
	}
}

func TestRelabelConfig(t *testing.T) {
	tt := []struct {
		name   string
		input  interface{}
		expect string
	}{
		{
			name: "full",
			input: prom_v1.RelabelConfig{
				SourceLabels: []prom_v1.LabelName{"input_a", "input_b"},
				Separator:    ";",
				TargetLabel:  "target_a",
				Regex:        "regex",
				Modulus:      1234,
				Replacement:  "foobar",
				Action:       "replace",
			},
			expect: util.Untab(`
				source_labels: ["input_a", "input_b"]
				separator: ";"
				target_label: "target_a"
				regex: regex
				modulus: 1234
				replacement: foobar
				action: replace
			`),
		},
	}

	for _, tc := range tt {
		t.Run(tc.name, func(t *testing.T) {
			vm, err := createVM(nil)
			require.NoError(t, err)
			bb, err := jsonnetMarshal(tc.input)
			require.NoError(t, err)

			vm.TLACode("cfg", string(bb))
			actual, err := runSnippet(vm, "./component/metrics/relabel_config.libsonnet", "cfg")
			require.NoError(t, err)
			require.YAMLEq(t, tc.expect, actual)
		})
	}
}

func TestRemoteWrite(t *testing.T) {
	tt := []struct {
		name   string
		input  map[string]interface{}
		expect string
	}{
		{
			name: "bare",
			input: map[string]interface{}{
				"namespace": "operator",
				"rw": gragent.RemoteWriteSpec{
					URL: "http://cortex/api/prom/push",
				},
			},
			expect: util.Untab(`
				url: http://cortex/api/prom/push
			`),
		},
		{
			name: "base configs",
			input: map[string]interface{}{
				"namespace": "operator",
				"rw": gragent.RemoteWriteSpec{
					Name:          "cortex",
					URL:           "http://cortex/api/prom/push",
					RemoteTimeout: "5m",
					Headers:       map[string]string{"foo": "bar"},
				},
			},
			expect: util.Untab(`
				name: cortex
				url: http://cortex/api/prom/push
				remote_timeout: 5m
				headers:
					foo: bar
			`),
		},
		{
			name: "write_relabel_configs",
			input: map[string]interface{}{
				"namespace": "operator",
				"rw": gragent.RemoteWriteSpec{
					URL: "http://cortex/api/prom/push",
					WriteRelabelConfigs: []prom_v1.RelabelConfig{{
						SourceLabels: []prom_v1.LabelName{"__name__"},
						Action:       "drop",
					}},
				},
			},
			expect: util.Untab(`
				url: http://cortex/api/prom/push
				write_relabel_configs:
				- source_labels: [__name__]
					action: drop
			`),
		},
		{
			name: "tls_config",
			input: map[string]interface{}{
				"namespace": "operator",
				"rw": gragent.RemoteWriteSpec{
					URL: "http://cortex/api/prom/push",
					TLSConfig: &prom_v1.TLSConfig{
						CAFile:   "ca",
						CertFile: "cert",
					},
				},
			},
			expect: util.Untab(`
				url: http://cortex/api/prom/push
				tls_config:
					ca_file: ca
					cert_file: cert
			`),
		},
		{
			name: "basic_auth",
			input: map[string]interface{}{
				"namespace": "operator",
				"rw": gragent.RemoteWriteSpec{
					URL: "http://cortex/api/prom/push",
					BasicAuth: &prom_v1.BasicAuth{
						Username: v1.SecretKeySelector{
							LocalObjectReference: v1.LocalObjectReference{Name: "obj"},
							Key:                  "key",
						},
						Password: v1.SecretKeySelector{
							LocalObjectReference: v1.LocalObjectReference{Name: "obj"},
							Key:                  "key",
						},
					},
				},
			},
			expect: util.Untab(`
				url: http://cortex/api/prom/push
				basic_auth:
					username: secretkey
					password_file: /var/lib/grafana-agent/secrets/_secrets_operator_obj_key
			`),
		},
		{
			name: "sigv4",
			input: map[string]interface{}{
				"namespace": "operator",
				"rw": gragent.RemoteWriteSpec{
					URL: "http://cortex/api/prom/push",
					SigV4: &gragent.SigV4Config{
						Region: "region",
						AccessKey: &v1.SecretKeySelector{
							LocalObjectReference: v1.LocalObjectReference{Name: "obj"},
							Key:                  "key",
						},
						SecretKey: &v1.SecretKeySelector{
							LocalObjectReference: v1.LocalObjectReference{Name: "obj"},
							Key:                  "key",
						},
						Profile: "profile",
						RoleARN: "arn",
					},
				},
			},
			expect: util.Untab(`
				url: http://cortex/api/prom/push
				sigv4:
					region: region
					access_key: secretkey
					secret_key: secretkey
					profile: profile
					role_arn: arn
			`),
		},
		{
			name: "queue_config",
			input: map[string]interface{}{
				"namespace": "operator",
				"rw": gragent.RemoteWriteSpec{
					URL: "http://cortex/api/prom/push",
					QueueConfig: &gragent.QueueConfig{
						Capacity:          1000,
						MinShards:         1,
						MaxShards:         100,
						MaxSamplesPerSend: 500,
						BatchSendDeadline: "5m",
						MinBackoff:        "1m",
						MaxBackoff:        "5m",
					},
				},
			},
			expect: util.Untab(`
				url: http://cortex/api/prom/push
				queue_config:
					capacity: 1000
					min_shards: 1
					max_shards: 100
					max_samples_per_send: 500
					batch_send_deadline: 5m
					min_backoff: 1m
					max_backoff: 5m
			`),
		},
		{
			name: "metadata_config",
			input: map[string]interface{}{
				"namespace": "operator",
				"rw": gragent.RemoteWriteSpec{
					URL: "http://cortex/api/prom/push",
					MetadataConfig: &gragent.MetadataConfig{
						Send:         true,
						SendInterval: "5m",
					},
				},
			},
			expect: util.Untab(`
				url: http://cortex/api/prom/push
				metadata_config:
					send: true
					send_interval: 5m
			`),
		},
		{
			name: "proxy_url",
			input: map[string]interface{}{
				"namespace": "operator",
				"rw": gragent.RemoteWriteSpec{
					URL:      "http://cortex/api/prom/push",
					ProxyURL: "http://proxy",
				},
			},
			expect: util.Untab(`
        url: http://cortex/api/prom/push
        proxy_url: http://proxy
			`),
		},
	}

	for _, tc := range tt {
		t.Run(tc.name, func(t *testing.T) {
			vm, err := createVM(testStore())
			require.NoError(t, err)

			args := []string{"namespace", "rw"}
			for _, arg := range args {
				bb, err := jsonnetMarshal(tc.input[arg])
				require.NoError(t, err)
				vm.TLACode(arg, string(bb))
			}

			actual, err := runSnippet(vm, "./component/metrics/remote_write.libsonnet", args...)
			require.NoError(t, err)
			require.YAMLEq(t, tc.expect, actual)
		})
	}
}

func TestSafeTLSConfig(t *testing.T) {
	tt := []struct {
		name   string
		input  map[string]interface{}
		expect string
	}{
		{
			name: "configmap",
			input: map[string]interface{}{
				"namespace": "operator",
				"config": prom_v1.SafeTLSConfig{
					ServerName:         "server",
					InsecureSkipVerify: true,
					CA: prom_v1.SecretOrConfigMap{
						ConfigMap: &v1.ConfigMapKeySelector{
							LocalObjectReference: v1.LocalObjectReference{Name: "obj"},
							Key:                  "key",
						},
					},
					Cert: prom_v1.SecretOrConfigMap{
						ConfigMap: &v1.ConfigMapKeySelector{
							LocalObjectReference: v1.LocalObjectReference{Name: "obj"},
							Key:                  "key",
						},
					},
					KeySecret: &v1.SecretKeySelector{
						LocalObjectReference: v1.LocalObjectReference{Name: "obj"},
						Key:                  "key",
					},
				},
			},
			expect: util.Untab(`
				ca_file: /var/lib/grafana-agent/secrets/_configMaps_operator_obj_key
				cert_file: /var/lib/grafana-agent/secrets/_configMaps_operator_obj_key
				key_file: /var/lib/grafana-agent/secrets/_secrets_operator_obj_key
				server_name: server
				insecure_skip_verify: true
			`),
		},
		{
			name: "secrets",
			input: map[string]interface{}{
				"namespace": "operator",
				"config": prom_v1.SafeTLSConfig{
					ServerName:         "server",
					InsecureSkipVerify: true,
					CA: prom_v1.SecretOrConfigMap{
						Secret: &v1.SecretKeySelector{
							LocalObjectReference: v1.LocalObjectReference{Name: "obj"},
							Key:                  "key",
						},
					},
					Cert: prom_v1.SecretOrConfigMap{
						Secret: &v1.SecretKeySelector{
							LocalObjectReference: v1.LocalObjectReference{Name: "obj"},
							Key:                  "key",
						},
					},
					KeySecret: &v1.SecretKeySelector{
						LocalObjectReference: v1.LocalObjectReference{Name: "obj"},
						Key:                  "key",
					},
				},
			},
			expect: util.Untab(`
				ca_file: /var/lib/grafana-agent/secrets/_secrets_operator_obj_key
				cert_file: /var/lib/grafana-agent/secrets/_secrets_operator_obj_key
				key_file: /var/lib/grafana-agent/secrets/_secrets_operator_obj_key
				server_name: server
				insecure_skip_verify: true
			`),
		},
	}

	for _, tc := range tt {
		t.Run(tc.name, func(t *testing.T) {
			vm, err := createVM(testStore())
			require.NoError(t, err)

			args := []string{"namespace", "config"}
			for _, arg := range args {
				bb, err := jsonnetMarshal(tc.input[arg])
				require.NoError(t, err)
				vm.TLACode(arg, string(bb))
			}

			actual, err := runSnippet(vm, "./component/metrics/safe_tls_config.libsonnet", args...)
			require.NoError(t, err)
			require.YAMLEq(t, tc.expect, actual)
		})
	}
}

func TestServiceMonitor(t *testing.T) {
	tt := []struct {
		name   string
		input  map[string]interface{}
		expect string
	}{
		{
			name: "default",
			input: map[string]interface{}{
				"agentNamespace": "operator",
				"monitor": prom_v1.ServiceMonitor{
					ObjectMeta: meta_v1.ObjectMeta{
						Namespace: "operator",
						Name:      "servicemonitor",
					},
				},
				"endpoint": prom_v1.Endpoint{
					Port: "metrics",
				},
				"index":                    0,
				"apiServer":                prom_v1.APIServerConfig{},
				"overrideHonorLabels":      false,
				"overrideHonorTimestamps":  false,
				"ignoreNamespaceSelectors": false,
				"enforcedNamespaceLabel":   "",
				"enforcedSampleLimit":      nil,
				"enforcedTargetLimit":      nil,
				"shards":                   1,
			},
			expect: util.Untab(`
				job_name: serviceMonitor/operator/servicemonitor/0
				honor_labels: false
				kubernetes_sd_configs:
				- role: endpoints
				  namespaces:
						names: [operator]
				relabel_configs:
				- source_labels:
					- job
					target_label: __tmp_prometheus_job_name
				- action: keep
					regex: metrics
					source_labels:
					- __meta_kubernetes_endpoint_port_name
				- regex: Node;(.*)
					replacement: $1
					separator: ;
					source_labels:
					- __meta_kubernetes_endpoint_address_target_kind
					- __meta_kubernetes_endpoint_address_target_name
					target_label: node
				- regex: Pod;(.*)
					replacement: $1
					separator: ;
					source_labels:
					- __meta_kubernetes_endpoint_address_target_kind
					- __meta_kubernetes_endpoint_address_target_name
					target_label: pod
				- source_labels:
					- __meta_kubernetes_namespace
					target_label: namespace
				- source_labels:
					- __meta_kubernetes_service_name
					target_label: service
				- source_labels:
					- __meta_kubernetes_pod_name
					target_label: pod
				- source_labels:
					- __meta_kubernetes_pod_container_name
					target_label: container
				- replacement: $1
					source_labels:
					- __meta_kubernetes_service_name
					target_label: job
				- replacement: metrics
					target_label: endpoint
				- action: hashmod
					modulus: 1
					source_labels:
					- __address__
					target_label: __tmp_hash
				- action: keep
					regex: $(SHARD)
					source_labels:
					- __tmp_hash
			`),
		},
	}

	for _, tc := range tt {
		t.Run(tc.name, func(t *testing.T) {
			vm, err := createVM(testStore())
			require.NoError(t, err)

			args := []string{
				"agentNamespace", "monitor", "endpoint", "index", "apiServer", "overrideHonorLabels",
				"overrideHonorTimestamps", "ignoreNamespaceSelectors", "enforcedNamespaceLabel",
				"enforcedSampleLimit", "enforcedTargetLimit", "shards",
			}
			for _, arg := range args {
				bb, err := jsonnetMarshal(tc.input[arg])
				require.NoError(t, err)
				vm.TLACode(arg, string(bb))
			}

			actual, err := runSnippet(vm, "./component/metrics/service_monitor.libsonnet", args...)
			require.NoError(t, err)
			if !assert.YAMLEq(t, tc.expect, actual) {
				fmt.Fprintln(os.Stderr, actual)
			}
		})
	}
}

func TestTLSConfig(t *testing.T) {
	tt := []struct {
		name   string
		input  map[string]interface{}
		expect string
	}{
		{
			name: "passthrough",
			input: map[string]interface{}{
				"namespace": "operator",
				"config": prom_v1.TLSConfig{
					SafeTLSConfig: prom_v1.SafeTLSConfig{
						ServerName:         "server",
						InsecureSkipVerify: true,
						CA: prom_v1.SecretOrConfigMap{
							Secret: &v1.SecretKeySelector{
								LocalObjectReference: v1.LocalObjectReference{Name: "obj"},
								Key:                  "key",
							},
						},
						Cert: prom_v1.SecretOrConfigMap{
							Secret: &v1.SecretKeySelector{
								LocalObjectReference: v1.LocalObjectReference{Name: "obj"},
								Key:                  "key",
							},
						},
						KeySecret: &v1.SecretKeySelector{
							LocalObjectReference: v1.LocalObjectReference{Name: "obj"},
							Key:                  "key",
						},
					},
				},
			},
			expect: util.Untab(`
				ca_file: /var/lib/grafana-agent/secrets/_secrets_operator_obj_key
				cert_file: /var/lib/grafana-agent/secrets/_secrets_operator_obj_key
				key_file: /var/lib/grafana-agent/secrets/_secrets_operator_obj_key
				server_name: server
				insecure_skip_verify: true
			`),
		},
		{
			name: "overrides",
			input: map[string]interface{}{
				"namespace": "operator",
				"config": prom_v1.TLSConfig{
					SafeTLSConfig: prom_v1.SafeTLSConfig{
						ServerName:         "server",
						InsecureSkipVerify: true,
						CA: prom_v1.SecretOrConfigMap{
							Secret: &v1.SecretKeySelector{
								LocalObjectReference: v1.LocalObjectReference{Name: "obj"},
								Key:                  "key",
							},
						},
						Cert: prom_v1.SecretOrConfigMap{
							Secret: &v1.SecretKeySelector{
								LocalObjectReference: v1.LocalObjectReference{Name: "obj"},
								Key:                  "key",
							},
						},
						KeySecret: &v1.SecretKeySelector{
							LocalObjectReference: v1.LocalObjectReference{Name: "obj"},
							Key:                  "key",
						},
					},
					CAFile:   "ca",
					CertFile: "cert",
					KeyFile:  "key",
				},
			},
			expect: util.Untab(`
				ca_file: ca
				cert_file: cert
				key_file: key
				server_name: server
				insecure_skip_verify: true
			`),
		},
	}

	for _, tc := range tt {
		t.Run(tc.name, func(t *testing.T) {
			vm, err := createVM(testStore())
			require.NoError(t, err)

			args := []string{"namespace", "config"}
			for _, arg := range args {
				bb, err := jsonnetMarshal(tc.input[arg])
				require.NoError(t, err)
				vm.TLACode(arg, string(bb))
			}

			actual, err := runSnippet(vm, "./component/metrics/tls_config.libsonnet", args...)
			require.NoError(t, err)
			require.YAMLEq(t, tc.expect, actual)
		})
	}
}

func runSnippet(vm *jsonnet.VM, filename string, args ...string) (string, error) {
	boundArgs := make([]string, len(args))
	for i := range args {
		boundArgs[i] = fmt.Sprintf("%[1]s=%[1]s", args[i])
	}

	return vm.EvaluateAnonymousSnippet(
		filename,
		fmt.Sprintf(`
			local marshal = import './ext/marshal.libsonnet';
			local optionals = import './ext/optionals.libsonnet';
			local eval = import '%s';
			function(%s) marshal.YAML(optionals.trim(eval(%s)))
		`, filename, strings.Join(args, ","), strings.Join(boundArgs, ",")),
	)
}

func testStore() assets.SecretStore {
	store := make(assets.SecretStore)

	store[assets.KeyForConfigMap("operator", &v1.ConfigMapKeySelector{
		LocalObjectReference: v1.LocalObjectReference{Name: "obj"},
		Key:                  "key",
	})] = "secretcm"

	store[assets.KeyForSecret("operator", &v1.SecretKeySelector{
		LocalObjectReference: v1.LocalObjectReference{Name: "obj"},
		Key:                  "key",
	})] = "secretkey"

	return store
}

'''
'''--- pkg/operator/config/utils.go ---
package config

import (
	"encoding/json"
	"fmt"
	"regexp"

	"github.com/fatih/structs"
	jsonnet "github.com/google/go-jsonnet"
	gragent "github.com/grafana/agent/pkg/operator/apis/monitoring/v1alpha1"
	"sigs.k8s.io/yaml"
)

func unmarshalYAML(i []interface{}) (interface{}, error) {
	text, ok := i[0].(string)
	if !ok {
		return nil, jsonnet.RuntimeError{Msg: "unmarshalYAML text argument must be a string"}
	}
	var v interface{}
	err := yaml.Unmarshal([]byte(text), &v)
	if err != nil {
		return nil, jsonnet.RuntimeError{Msg: err.Error()}
	}
	return v, nil
}

// trimMap recursively deletes fields from m whose value is nil.
func trimMap(m map[string]interface{}) {
	for k, v := range m {
		if v == nil {
			delete(m, k)
			continue
		}

		if next, ok := v.(map[string]interface{}); ok {
			trimMap(next)
		}

		if arr, ok := v.([]interface{}); ok {
			m[k] = trimSlice(arr)
		}
	}
}

func trimSlice(s []interface{}) []interface{} {
	res := make([]interface{}, 0, len(s))

	for _, e := range s {
		if e == nil {
			continue
		}

		if next, ok := e.([]interface{}); ok {
			e = trimSlice(next)
		}

		if next, ok := e.(map[string]interface{}); ok {
			trimMap(next)
		}

		res = append(res, e)
	}

	return res
}

// intoStages converts the a yaml slice of stages into a Jsonnet array.
func intoStages(i []interface{}) (interface{}, error) {
	text, ok := i[0].(string)
	if !ok {
		return nil, jsonnet.RuntimeError{Msg: "text argument not string"}
	}

	// The way this works is really, really gross. We only need any of this
	// because Kubernetes CRDs can't recursively define types, which we need
	// for the match stage.
	//
	// 1. Convert YAML -> map[string]interface{}
	// 2. Convert map[string]interface{} -> JSON
	// 3. Convert JSON -> []*grafana.PipelineStageSpec
	// 4. Convert []*grafana.PipelineStageSpec into []interface{}, where
	//    each interface{} has the type information lost so marshaling it
	//    again to JSON doesn't break anything.
	var raw interface{}
	if err := yaml.Unmarshal([]byte(text), &raw); err != nil {
		return nil, jsonnet.RuntimeError{
			Msg: fmt.Sprintf("failed to unmarshal stages: %s", err.Error()),
		}
	}

	bb, err := json.Marshal(raw)
	if err != nil {
		return nil, jsonnet.RuntimeError{
			Msg: fmt.Sprintf("failed to unmarshal stages: %s", err.Error()),
		}
	}

	var ps []*gragent.PipelineStageSpec
	if err := json.Unmarshal(bb, &ps); err != nil {
		return nil, jsonnet.RuntimeError{
			Msg: fmt.Sprintf("failed to unmarshal stages: %s", err.Error()),
		}
	}

	// Then we need to convert each into their raw types.
	rawPS := make([]interface{}, 0, len(ps))
	for _, stage := range ps {
		bb, err := json.Marshal(structs.Map(stage))
		if err != nil {
			return nil, jsonnet.RuntimeError{
				Msg: fmt.Sprintf("failed to unmarshal stages: %s", err.Error()),
			}
		}

		var v interface{}
		if err := json.Unmarshal(bb, &v); err != nil {
			return nil, jsonnet.RuntimeError{
				Msg: fmt.Sprintf("failed to unmarshal stages: %s", err.Error()),
			}
		}

		rawPS = append(rawPS, v)
	}
	return rawPS, nil
}

var invalidLabelCharRE = regexp.MustCompile(`[^a-zA-Z0-9_]`)

// SanitizeLabelName sanitizes a label name for Prometheus.
func SanitizeLabelName(name string) string {
	return invalidLabelCharRE.ReplaceAllString(name, "_")
}

'''
'''--- pkg/operator/config/utils_test.go ---
package config

import (
	"testing"

	"github.com/stretchr/testify/require"
	"gopkg.in/yaml.v2"
)

func Test_unmarshalYAML(t *testing.T) {
	in := `
- a: 5
`

	out, err := unmarshalYAML([]interface{}{in})
	require.NoError(t, err)

	bb, err := yaml.Marshal(out)
	require.NoError(t, err)

	require.YAMLEq(t, in, string(bb))
}

'''
'''--- pkg/operator/defaults.go ---
package operator

// Supported versions of the Grafana Agent.
var (
	AgentCompatibilityMatrix = []string{
		"v0.14.0",
		"v0.15.0",
		// "v0.16.0", // Pulled due to critical bug fixed in v0.16.1.
		"v0.16.1",
		"v0.17.0",
		"v0.18.0",
		"v0.18.1",
		"v0.18.2",
		"v0.18.3",
		"v0.18.4",
		"v0.19.0",
		"v0.20.0",
		"v0.20.1",
		"v0.21.0",
		"v0.21.1",
		"v0.21.2",
		"v0.22.0",
		"v0.23.0",
		"v0.24.0",
		"v0.24.1",
		"v0.24.2",
		"v0.25.0",
		"v0.25.1",
		"v0.26.0",
		"v0.26.1",

		// NOTE(rfratto): when performing an upgrade, add the newest version above instead of changing the existing reference.
	}

	DefaultAgentVersion   = AgentCompatibilityMatrix[len(AgentCompatibilityMatrix)-1]
	DefaultAgentBaseImage = "grafana/agent"
	DefaultAgentImage     = DefaultAgentBaseImage + ":" + DefaultAgentVersion
)

'''
'''--- pkg/operator/hierarchy/hierarchy.go ---
// Package hierarchy provides tools to discover a resource hierarchy. A
// resource hierarchy is made when a resource has a set of rules to discover
// other resources.
package hierarchy

import (
	"context"
	"fmt"
	"sync"
	"time"

	"github.com/go-kit/log"
	"github.com/go-kit/log/level"
	"k8s.io/apimachinery/pkg/runtime/schema"
	"k8s.io/client-go/util/workqueue"
	"sigs.k8s.io/controller-runtime/pkg/client"
	"sigs.k8s.io/controller-runtime/pkg/client/apiutil"
	"sigs.k8s.io/controller-runtime/pkg/event"
	"sigs.k8s.io/controller-runtime/pkg/handler"
	"sigs.k8s.io/controller-runtime/pkg/reconcile"
)

// Notifier can be attached to a controller and generate reconciles when
// objects inside of a resource hierarchy change.
type Notifier struct {
	log    log.Logger
	client client.Client

	watchersMut sync.RWMutex
	watchers    map[schema.GroupVersionKind][]Watcher
}

// Watcher is something watching for changes to a resource.
type Watcher struct {
	Object   client.Object    // Object to watch for events against.
	Owner    client.ObjectKey // Owner to receive a reconcile for.
	Selector Selector         // Selector to use to match changed objects.
}

// NewNotifier creates a new Notifier which uses the provided client for
// performing hierarchy lookups.
func NewNotifier(l log.Logger, cli client.Client) *Notifier {
	return &Notifier{
		log:      l,
		client:   cli,
		watchers: make(map[schema.GroupVersionKind][]Watcher),
	}
}

// EventHandler returns an event handler that can be given to
// controller.Watches.
//
// controller.Watches should be called once per type in the resource hierarchy.
// Each call to controller.Watches should use the same Notifier.
func (n *Notifier) EventHandler() handler.EventHandler {
	// TODO(rfratto): It's possible to create a custom implementation of
	// source.Source so we wouldn't have to call controller.Watches a bunch of
	// times. I played around a little with an implementation but it was going to
	// be a lot of work to dynamically spin up/down informers, so I put it aside
	// for now. Maybe it's an improvement for the future.
	return &notifierEventHandler{Notifier: n}
}

// Notify configures reconciles to be generated for a set of watchers when
// watched resources change.
//
// Notify appends to the list of watchers. To remove out notifications for a
// specific owner, call StopNotify.
func (n *Notifier) Notify(watchers ...Watcher) error {
	n.watchersMut.Lock()
	defer n.watchersMut.Unlock()

	for _, w := range watchers {
		gvk, err := apiutil.GVKForObject(w.Object, n.client.Scheme())
		if err != nil {
			return fmt.Errorf("could not get GVK: %w", err)
		}

		n.watchers[gvk] = append(n.watchers[gvk], w)
	}

	return nil
}

// StopNotify removes all watches for a specific owner.
func (n *Notifier) StopNotify(owner client.ObjectKey) {
	n.watchersMut.Lock()
	defer n.watchersMut.Unlock()

	for key, watchers := range n.watchers {
		rem := make([]Watcher, 0, len(watchers))
		for _, w := range watchers {
			if w.Owner != owner {
				rem = append(rem, w)
			}
		}
		n.watchers[key] = rem
	}
}

type notifierEventHandler struct {
	*Notifier
}

var _ handler.EventHandler = (*notifierEventHandler)(nil)

func (h *notifierEventHandler) Create(ev event.CreateEvent, q workqueue.RateLimitingInterface) {
	h.handleEvent(ev.Object, q)
}

func (h *notifierEventHandler) Update(ev event.UpdateEvent, q workqueue.RateLimitingInterface) {
	h.handleEvent(ev.ObjectOld, q)
	h.handleEvent(ev.ObjectNew, q)
}

func (h *notifierEventHandler) Delete(ev event.DeleteEvent, q workqueue.RateLimitingInterface) {
	h.handleEvent(ev.Object, q)
}

func (h *notifierEventHandler) Generic(ev event.GenericEvent, q workqueue.RateLimitingInterface) {
	h.handleEvent(ev.Object, q)
}

func (h *notifierEventHandler) handleEvent(obj client.Object, q workqueue.RateLimitingInterface) {
	h.watchersMut.RLock()
	defer h.watchersMut.RUnlock()

	gvk, err := apiutil.GVKForObject(obj, h.client.Scheme())
	if err != nil {
		level.Error(h.log).Log("msg", "failed to get gvk for object", "err", err)
		return
	}

	ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)
	defer cancel()

	// Iterate through all of the watchers for the gvk and check to see if we
	// should trigger a reconcile.
	for _, watcher := range h.watchers[gvk] {
		matches, err := watcher.Selector.Matches(ctx, h.client, obj)
		if err != nil {
			level.Error(h.log).Log("msg", "failed to handle notifier event", "err", err)
			return
		}
		if matches {
			q.Add(reconcile.Request{NamespacedName: watcher.Owner})
		}
	}
}

'''
'''--- pkg/operator/hierarchy/hierarchy_test.go ---
//go:build !nonetwork && !nodocker && !race
// +build !nonetwork,!nodocker,!race

package hierarchy

import (
	"context"
	"testing"
	"time"

	"github.com/go-kit/log"
	"github.com/grafana/agent/pkg/util/k8s"
	"github.com/stretchr/testify/require"
	v1 "k8s.io/api/core/v1"
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
	"k8s.io/apimachinery/pkg/labels"
	"k8s.io/apimachinery/pkg/types"
	"k8s.io/client-go/util/workqueue"
	"sigs.k8s.io/controller-runtime/pkg/event"
)

// TestNotifier tests that notifier properly handles events for changed
// objects.
func TestNotifier(t *testing.T) {
	l := log.NewNopLogger()

	ctx, cancel := context.WithTimeout(context.Background(), 5*time.Minute)
	defer cancel()

	cluster, err := k8s.NewCluster(ctx, k8s.Options{})
	require.NoError(t, err)
	defer cluster.Stop()

	cli := cluster.Client()

	// Tests will rely on a namespace existing, so let's create a namespace with
	// some labels.
	testNs := v1.Namespace{
		TypeMeta: metav1.TypeMeta{
			APIVersion: "v1",
			Kind:       "Namespace",
		},
		ObjectMeta: metav1.ObjectMeta{
			Name:   "enqueue-test",
			Labels: map[string]string{"foo": "bar"},
		},
	}
	err = cli.Create(ctx, &testNs)
	require.NoError(t, err)

	testPod := &v1.Pod{ObjectMeta: metav1.ObjectMeta{
		Name:      "test-pod",
		Namespace: "enqueue-test",
		Labels:    map[string]string{"fizz": "buzz"},
	}}

	tt := []struct {
		name          string
		sel           Selector
		expectEnqueue bool
	}{
		{
			name:          "no watchers",
			sel:           nil,
			expectEnqueue: false,
		},
		{
			name: "matches watcher",
			sel: &LabelsSelector{
				NamespaceName:   "enqueue-test",
				NamespaceLabels: parseSelector(t, "foo in (bar)"),
				Labels:          parseSelector(t, "fizz in (buzz)"),
			},
			expectEnqueue: true,
		},
		{
			name: "matches watcher with explicit namespace",
			sel: &LabelsSelector{
				NamespaceName: "enqueue-test",
				Labels:        parseSelector(t, "fizz in (buzz)"),
			},
			expectEnqueue: true,
		},
		{
			name: "bad namespace name selector",
			sel: &LabelsSelector{
				NamespaceName: "default",
				Labels:        labels.Everything(),
			},
			expectEnqueue: false,
		},
		{
			name: "bad namespace label selector",
			sel: &LabelsSelector{
				NamespaceName:   "enqueue-test",
				NamespaceLabels: parseSelector(t, "foo notin (bar)"),
				Labels:          labels.Everything(),
			},
			expectEnqueue: false,
		},
		{
			name: "bad label selector",
			sel: &LabelsSelector{
				NamespaceName:   "default",
				NamespaceLabels: labels.Everything(),
				Labels:          parseSelector(t, "fizz notin (buzz)"),
			},
			expectEnqueue: false,
		},
	}

	for _, tc := range tt {
		t.Run(tc.name, func(t *testing.T) {
			limiter := workqueue.DefaultControllerRateLimiter()
			q := workqueue.NewRateLimitingQueue(limiter)

			notifier := NewNotifier(l, cli)

			if tc.sel != nil {
				err := notifier.Notify(Watcher{
					Object:   &v1.Pod{},
					Owner:    types.NamespacedName{Name: "watcher", Namespace: "enqueue-test"},
					Selector: tc.sel,
				})
				require.NoError(t, err)
			}

			e := notifier.EventHandler()
			e.Create(event.CreateEvent{Object: testPod}, q)
			if tc.expectEnqueue {
				require.Equal(t, 1, q.Len(), "expected change enqueue")
			} else {
				require.Equal(t, 0, q.Len(), "no changes should have been enqueued")
			}
		})
	}
}

func parseSelector(t *testing.T, selector string) labels.Selector {
	t.Helper()
	s, err := labels.Parse(selector)
	require.NoError(t, err)
	return s
}

'''
'''--- pkg/operator/hierarchy/list.go ---
package hierarchy

import (
	"context"
	"fmt"

	"k8s.io/apimachinery/pkg/api/meta"
	"k8s.io/apimachinery/pkg/runtime"
	"sigs.k8s.io/controller-runtime/pkg/client"
)

// List will populate list with elements that match sel.
func List(ctx context.Context, cli client.Client, list client.ObjectList, sel Selector) error {
	if err := cli.List(ctx, list, sel); err != nil {
		return fmt.Errorf("list failed: %w", err)
	}
	if err := filterList(ctx, cli, list, sel); err != nil {
		return fmt.Errorf("filter failed: %w", err)
	}
	return nil
}

// filterList updates the provided list to only elements which match sel.
func filterList(ctx context.Context, cli client.Client, list client.ObjectList, sel Selector) error {
	allElements, err := meta.ExtractList(list)
	if err != nil {
		return fmt.Errorf("failed to get list: %w", err)
	}

	filtered := make([]runtime.Object, 0, len(allElements))
	for _, element := range allElements {
		obj, ok := element.(client.Object)
		if !ok {
			return fmt.Errorf("unexpected object of type %T in list", element)
		}

		matches, err := sel.Matches(ctx, cli, obj)
		if err != nil {
			return fmt.Errorf("failed to validate object: %w", err)
		}
		if matches {
			filtered = append(filtered, obj)
		}
	}

	if err := meta.SetList(list, filtered); err != nil {
		return fmt.Errorf("failed to update list: %w", err)
	}
	return nil
}

'''
'''--- pkg/operator/hierarchy/selector.go ---
package hierarchy

import (
	"context"
	"fmt"

	corev1 "k8s.io/api/core/v1"
	"k8s.io/apimachinery/pkg/labels"
	"sigs.k8s.io/controller-runtime/pkg/client"
)

// Selector finding objects within the resource hierarchy.
type Selector interface {
	// ListOption can be passed to List to perform initial filtering of returned
	// objects.
	client.ListOption

	// Matches returns true if the Selector matches the provided Object. The
	// provided Client may be used to perform extra searches.
	Matches(context.Context, client.Client, client.Object) (bool, error)
}

// LabelsSelector is used for discovering a set of objects in a hierarchy based
// on labels.
type LabelsSelector struct {
	// NamespaceName is the default namespace to search for objects in when
	// NamespaceSelector is nil.
	NamespaceName string

	// NamespaceLabels causes all namespaces whose labels match NamespaceLabels
	// to be searched. When nil, only the namespace specified by NamespaceName
	// will be searched.
	NamespaceLabels labels.Selector

	// Labels discovers all objects whose labels match the selector. If nil,
	// no objects will be discovered.
	Labels labels.Selector
}

var _ Selector = (*LabelsSelector)(nil)

// ApplyToList implements Selector.
func (ls *LabelsSelector) ApplyToList(lo *client.ListOptions) {
	if ls.NamespaceLabels == nil {
		lo.Namespace = ls.NamespaceName
	}
	lo.LabelSelector = ls.Labels
}

// Matches implements Selector.
func (ls *LabelsSelector) Matches(ctx context.Context, cli client.Client, o client.Object) (bool, error) {
	if !ls.Labels.Matches(labels.Set(o.GetLabels())) {
		return false, nil
	}

	// Fast path: we don't need to retrieve the labels of the namespace.
	if ls.NamespaceLabels == nil {
		return o.GetNamespace() == ls.NamespaceName, nil
	}

	// Slow path: we need to look up the namespace to see if its labels match. As
	// long as cli implements caching, this won't be too bad.
	var ns corev1.Namespace
	if err := cli.Get(ctx, client.ObjectKey{Name: o.GetNamespace()}, &ns); err != nil {
		return false, fmt.Errorf("error looking up namespace %q: %w", o.GetNamespace(), err)
	}
	return ls.NamespaceLabels.Matches(labels.Set(ns.GetLabels())), nil
}

// KeySelector is used for discovering a single object based on namespace and
// name.
type KeySelector struct {
	Namespace, Name string
}

var _ Selector = (*KeySelector)(nil)

// ApplyToList implements Selector.
func (ks *KeySelector) ApplyToList(lo *client.ListOptions) {
	lo.Namespace = ks.Namespace
}

// Matches implements Selector.
func (ks *KeySelector) Matches(ctx context.Context, cli client.Client, o client.Object) (bool, error) {
	return ks.Name == o.GetName() && ks.Namespace == o.GetNamespace(), nil
}

'''
'''--- pkg/operator/kubelet.go ---
package operator

import (
	"context"
	"fmt"

	"github.com/go-kit/log"
	"github.com/go-kit/log/level"
	"github.com/grafana/agent/pkg/operator/clientutil"
	"github.com/grafana/agent/pkg/operator/logutil"
	core_v1 "k8s.io/api/core/v1"
	meta_v1 "k8s.io/apimachinery/pkg/apis/meta/v1"
	controller "sigs.k8s.io/controller-runtime"
	"sigs.k8s.io/controller-runtime/pkg/client"
)

type kubeletReconciler struct {
	client.Client
	kubeletNamespace, kubeletName string
}

func (r *kubeletReconciler) Reconcile(ctx context.Context, req controller.Request) (res controller.Result, err error) {
	l := logutil.FromContext(ctx)
	level.Info(l).Log("msg", "reconciling node")

	var nodes core_v1.NodeList
	if err := r.List(ctx, &nodes); err != nil {
		level.Error(l).Log("msg", "failed to list nodes for kubelet service", "err", err)
		return res, fmt.Errorf("unable to list nodes: %w", err)
	}
	nodeAddrs, err := getNodeAddrs(l, &nodes)
	if err != nil {
		level.Error(l).Log("msg", "could not get addresses from all nodes", "err", err)
		return res, fmt.Errorf("unable to get addresses from nodes: %w", err)
	}

	labels := mergeMaps(managedByOperatorLabels, map[string]string{
		// Labels taken from prometheus-operator:
		// https://github.com/prometheus-operator/prometheus-operator/blob/2c81b0cf6a5673e08057499a08ddce396b19dda4/pkg/prometheus/operator.go#L586-L587
		"k8s-app":                "kubelet",
		"app.kubernetes.io/name": "kubelet",
	})

	svc := &core_v1.Service{
		ObjectMeta: meta_v1.ObjectMeta{
			Name:      r.kubeletName,
			Namespace: r.kubeletNamespace,
			Labels:    labels,
		},
		Spec: core_v1.ServiceSpec{
			Type:      core_v1.ServiceTypeClusterIP,
			ClusterIP: "None",
			Ports: []core_v1.ServicePort{
				{Name: "https-metrics", Port: 10250},
				{Name: "http-metrics", Port: 10255},
				{Name: "cadvisor", Port: 4194},
			},
		},
	}

	eps := &core_v1.Endpoints{
		ObjectMeta: meta_v1.ObjectMeta{
			Name:      r.kubeletName,
			Namespace: r.kubeletNamespace,
			Labels:    labels,
		},
		Subsets: []core_v1.EndpointSubset{{
			Addresses: nodeAddrs,
			Ports: []core_v1.EndpointPort{
				// Taken from https://github.com/prometheus-operator/prometheus-operator/blob/2c81b0cf6a5673e08057499a08ddce396b19dda4/pkg/prometheus/operator.go#L593
				{Name: "https-metrics", Port: 10250},
				{Name: "http-metrics", Port: 10255},
				{Name: "cadvisor", Port: 4194},
			},
		}},
	}

	level.Debug(l).Log("msg", "reconciling kubelet service", "svc", client.ObjectKeyFromObject(svc))
	err = clientutil.CreateOrUpdateService(ctx, r.Client, svc)
	if err != nil {
		return res, fmt.Errorf("failed to reconcile kubelet service %s: %w", client.ObjectKeyFromObject(svc), err)
	}

	level.Debug(l).Log("msg", "reconciling kubelet endpoints", "eps", client.ObjectKeyFromObject(eps))
	err = clientutil.CreateOrUpdateEndpoints(ctx, r.Client, eps)
	if err != nil {
		return res, fmt.Errorf("failed to reconcile kubelet endpoints %s: %w", client.ObjectKeyFromObject(eps), err)
	}

	return
}

// mergeMaps merges the contents of b with a. Keys from b take precednece.
func mergeMaps(a, b map[string]string) map[string]string {
	res := make(map[string]string)
	for k, v := range a {
		res[k] = v
	}
	for k, v := range b {
		res[k] = v
	}
	return res
}

func getNodeAddrs(l log.Logger, nodes *core_v1.NodeList) (addrs []core_v1.EndpointAddress, err error) {
	var failed bool

	for _, n := range nodes.Items {
		addr, err := nodeAddress(n)
		if err != nil {
			level.Error(l).Log("msg", "failed to get address from node", "node", n.Name, "err", err)
			failed = true
		}

		addrs = append(addrs, core_v1.EndpointAddress{
			IP: addr,
			TargetRef: &core_v1.ObjectReference{
				Kind:       n.Kind,
				APIVersion: n.APIVersion,
				Name:       n.Name,
				UID:        n.UID,
			},
		})
	}

	if failed {
		return nil, fmt.Errorf("failed to get the address from one or more nodes")
	}
	return
}

// nodeAddresses returns the provided node's address, based on the priority:
//
// 1. NodeInternalIP
// 2. NodeExternalIP
//
// Copied from github.com/prometheus/prometheus/discovery/kubernetes/node.go
func nodeAddress(node core_v1.Node) (string, error) {
	m := map[core_v1.NodeAddressType][]string{}
	for _, a := range node.Status.Addresses {
		m[a.Type] = append(m[a.Type], a.Address)
	}

	if addresses, ok := m[core_v1.NodeInternalIP]; ok {
		return addresses[0], nil
	}
	if addresses, ok := m[core_v1.NodeExternalIP]; ok {
		return addresses[0], nil
	}
	return "", fmt.Errorf("host address unknown")
}

'''
'''--- pkg/operator/kubelet_test.go ---
//go:build !nonetwork && !nodocker && !race
// +build !nonetwork,!nodocker,!race

package operator

import (
	"context"
	"testing"
	"time"

	"github.com/grafana/agent/pkg/operator/logutil"
	"github.com/grafana/agent/pkg/util"
	"github.com/grafana/agent/pkg/util/k8s"
	"github.com/stretchr/testify/require"
	"sigs.k8s.io/controller-runtime/pkg/reconcile"

	core_v1 "k8s.io/api/core/v1"
	meta_v1 "k8s.io/apimachinery/pkg/apis/meta/v1"
	"k8s.io/apimachinery/pkg/types"

	clog "sigs.k8s.io/controller-runtime/pkg/log"
)

// TestKubelet tests the Kubelet reconciler.
func TestKubelet(t *testing.T) {
	l := util.TestLogger(t)

	ctx, cancel := context.WithTimeout(context.Background(), 5*time.Minute)
	defer cancel()
	ctx = clog.IntoContext(ctx, logutil.Wrap(l))

	cluster, err := k8s.NewCluster(ctx, k8s.Options{})
	require.NoError(t, err)
	defer cluster.Stop()

	cli := cluster.Client()

	nodes := []core_v1.Node{
		{
			ObjectMeta: meta_v1.ObjectMeta{Name: "node-a"},
			Status: core_v1.NodeStatus{
				Addresses: []core_v1.NodeAddress{
					{Type: core_v1.NodeInternalIP, Address: "10.0.0.10"},
				},
			},
		},
		{
			ObjectMeta: meta_v1.ObjectMeta{Name: "node-b"},
			Status: core_v1.NodeStatus{
				Addresses: []core_v1.NodeAddress{
					{Type: core_v1.NodeExternalIP, Address: "10.24.0.11"},
				},
			},
		},
		{
			ObjectMeta: meta_v1.ObjectMeta{Name: "node-c"},
			Status: core_v1.NodeStatus{
				Addresses: []core_v1.NodeAddress{
					{Type: core_v1.NodeExternalIP, Address: "10.24.0.12"},
					{Type: core_v1.NodeInternalIP, Address: "10.0.0.12"},
				},
			},
		},
	}

	for _, n := range nodes {
		err := cli.Create(ctx, &n)
		require.NoError(t, err)
	}

	ns := &core_v1.Namespace{
		ObjectMeta: meta_v1.ObjectMeta{Name: "kube-system"},
	}
	_ = cli.Create(ctx, ns)

	r := &kubeletReconciler{
		Client:           cli,
		kubeletNamespace: "kube-system",
		kubeletName:      "kubelet",
	}
	_, err = r.Reconcile(ctx, reconcile.Request{})
	require.NoError(t, err)

	var (
		eps core_v1.Endpoints
		svc core_v1.Service

		key = types.NamespacedName{Namespace: r.kubeletNamespace, Name: r.kubeletName}
	)
	require.NoError(t, cli.Get(ctx, key, &eps))
	require.NoError(t, cli.Get(ctx, key, &svc))

	require.Len(t, eps.Subsets, 1)

	expect := map[string]string{
		"node-a": "10.0.0.10",
		"node-b": "10.24.0.11",

		// When a node has internal and external IPs, use internal first.
		"node-c": "10.0.0.12",
	}
	for nodeName, expectIP := range expect {
		var epa *core_v1.EndpointAddress

		for _, addr := range eps.Subsets[0].Addresses {
			if addr.TargetRef.Name == nodeName {
				epa = &addr
				break
			}
		}

		require.NotNilf(t, epa, "did not find endpoint address for node %s", nodeName)
		require.Equalf(t, expectIP, epa.IP, "node %s had incorrect ip address", nodeName)
	}
}

'''
'''--- pkg/operator/logutil/log.go ---
// Package logutil implements an adaptor for the go-kit logger, which is used in the
// Grafana Agent project, and go-logr, which is used in controller-runtime.
package logutil

import (
	"context"

	"github.com/go-kit/log"
	"github.com/go-kit/log/level"
	"github.com/go-logr/logr"
	clog "sigs.k8s.io/controller-runtime/pkg/log"
)

// Wrap wraps a log.Logger into a logr.Logger.
func Wrap(l log.Logger) logr.Logger {
	return logr.New(&goKitLogger{l: l})
}

// FromContext returns a log.Logger from a context. Panics if the context doesn't
// have a Logger set.
func FromContext(ctx context.Context, kvps ...interface{}) log.Logger {
	gkl := clog.FromContext(ctx, kvps...).GetSink().(*goKitLogger)
	return gkl.namedLogger()
}

type goKitLogger struct {
	// name is a name field used by logr which can be appended to dynamically.
	name string
	kvps []interface{}
	l    log.Logger
}

var _ logr.LogSink = (*goKitLogger)(nil)

func (l *goKitLogger) Init(info logr.RuntimeInfo) {
	// no-op
}

func (l *goKitLogger) Enabled(level int) bool { return true }

func (l *goKitLogger) Info(logLevel int, msg string, keysAndValues ...interface{}) {
	args := append([]interface{}{"msg", msg}, keysAndValues...)
	level.Info(l.namedLogger()).Log(args...)
}

func (l *goKitLogger) Error(err error, msg string, keysAndValues ...interface{}) {
	args := append([]interface{}{"msg", msg, "err", err}, keysAndValues...)
	level.Error(l.namedLogger()).Log(args...)
}

func (l *goKitLogger) WithValues(keysAndValues ...interface{}) logr.LogSink {
	return &goKitLogger{name: l.name, l: l.l, kvps: append(l.kvps, keysAndValues...)}
}

// namedLogger gets log.Logger with component applied.
func (l *goKitLogger) namedLogger() log.Logger {
	logger := l.l
	if l.name != "" {
		logger = log.With(logger, "component", l.name)
	}
	logger = log.With(logger, l.kvps...)
	return logger
}

func (l *goKitLogger) WithName(name string) logr.LogSink {
	newName := name
	if l.name != "" {
		newName = l.name + "." + name
	}
	return &goKitLogger{name: newName, l: l.l}
}

'''
'''--- pkg/operator/operator.go ---
package operator

import (
	"context"
	"flag"
	"fmt"
	"strings"
	"sync"

	"github.com/go-kit/log"
	"github.com/go-kit/log/level"
	"github.com/weaveworks/common/logging"
	"k8s.io/apimachinery/pkg/runtime"
	controller "sigs.k8s.io/controller-runtime"
	"sigs.k8s.io/controller-runtime/pkg/builder"
	"sigs.k8s.io/controller-runtime/pkg/healthz"
	"sigs.k8s.io/controller-runtime/pkg/manager"
	"sigs.k8s.io/controller-runtime/pkg/predicate"
	"sigs.k8s.io/controller-runtime/pkg/reconcile"
	"sigs.k8s.io/controller-runtime/pkg/source"

	gragent "github.com/grafana/agent/pkg/operator/apis/monitoring/v1alpha1"
	"github.com/grafana/agent/pkg/operator/hierarchy"
	promop_v1 "github.com/prometheus-operator/prometheus-operator/pkg/apis/monitoring/v1"
	promop "github.com/prometheus-operator/prometheus-operator/pkg/operator"
	apps_v1 "k8s.io/api/apps/v1"
	core_v1 "k8s.io/api/core/v1"
	meta_v1 "k8s.io/apimachinery/pkg/apis/meta/v1"

	// Needed for clients.
	_ "k8s.io/client-go/plugin/pkg/client/auth"
	"k8s.io/client-go/rest"
)

// Config controls the configuration of the Operator.
type Config struct {
	LogLevel            logging.Level
	LogFormat           logging.Format
	Labels              promop.Labels
	Controller          controller.Options
	AgentSelector       string
	KubelsetServiceName string

	// RestConfig used to connect to cluster. One will be generated based on the
	// environment if not set.
	RestConfig *rest.Config

	// TODO(rfratto): extra settings from Prometheus Operator:
	//
	// 1. Reloader container image/requests/limits
	// 2. Namespaces allow/denylist.
	// 3. Namespaces for Prometheus resources.
}

// NewConfig creates a new Config and initializes default values.
// Flags will be regsitered against f if it is non-nil.
func NewConfig(f *flag.FlagSet) (*Config, error) {
	if f == nil {
		f = flag.NewFlagSet("temp", flag.PanicOnError)
	}

	var c Config
	err := c.registerFlags(f)
	if err != nil {
		return nil, err
	}
	return &c, nil
}

func (c *Config) registerFlags(f *flag.FlagSet) error {
	c.LogLevel.RegisterFlags(f)
	c.LogFormat.RegisterFlags(f)
	f.Var(&c.Labels, "labels", "Labels to add to all created operator resources")
	f.StringVar(&c.AgentSelector, "agent-selector", "", "Label selector to discover GrafanaAgent CRs. Defaults to all GrafanaAgent CRs.")

	f.StringVar(&c.Controller.Namespace, "namespace", "", "Namespace to restrict the Operator to.")
	f.StringVar(&c.Controller.Host, "listen-host", "", "Host to listen on. Empty string means all interfaces.")
	f.IntVar(&c.Controller.Port, "listen-port", 9443, "Port to listen on.")
	f.StringVar(&c.Controller.MetricsBindAddress, "metrics-listen-address", ":8080", "Address to expose Operator metrics on")
	f.StringVar(&c.Controller.HealthProbeBindAddress, "health-listen-address", "", "Address to expose Operator health probes on")

	f.StringVar(&c.KubelsetServiceName, "kubelet-service", "", "Service and Endpoints objects to write kubelets into. Allows for monitoring Kubelet and cAdvisor metrics using a ServiceMonitor. Must be in format \"namespace/name\". If empty, nothing will be created.")

	// Custom initial values for the endpoint names.
	c.Controller.ReadinessEndpointName = "/-/ready"
	c.Controller.LivenessEndpointName = "/-/healthy"

	c.Controller.Scheme = runtime.NewScheme()
	for _, add := range []func(*runtime.Scheme) error{
		core_v1.AddToScheme,
		apps_v1.AddToScheme,
		gragent.AddToScheme,
		promop_v1.AddToScheme,
	} {
		if err := add(c.Controller.Scheme); err != nil {
			return fmt.Errorf("unable to register scheme: %w", err)
		}
	}

	return nil
}

// Operator is the Grafana Agent Operator.
type Operator struct {
	log     log.Logger
	manager manager.Manager

	// New creates reconcilers to reconcile creating the kubelet service (if
	// configured) and Grafana Agent deployments. We store them as
	// lazyReconcilers so tests can update what the underlying reconciler
	// implementation is.

	kubeletReconciler *lazyReconciler // Unused if kubelet service unconfigured
	agentReconciler   *lazyReconciler
}

// New creates a new Operator.
func New(l log.Logger, c *Config) (*Operator, error) {
	var (
		lazyKubeletReconciler, lazyAgentReconciler lazyReconciler
	)

	restConfig := c.RestConfig
	if restConfig == nil {
		restConfig = controller.GetConfigOrDie()
	}
	manager, err := controller.NewManager(restConfig, c.Controller)
	if err != nil {
		return nil, fmt.Errorf("failed to create manager: %w", err)
	}

	if err := manager.AddReadyzCheck("running", healthz.Ping); err != nil {
		level.Warn(l).Log("msg", "failed to set up 'running' readyz check", "err", err)
	}
	if err := manager.AddHealthzCheck("running", healthz.Ping); err != nil {
		level.Warn(l).Log("msg", "failed to set up 'running' healthz check", "err", err)
	}

	var (
		agentPredicates []predicate.Predicate

		notifier        = hierarchy.NewNotifier(log.With(l, "component", "hierarchy_notifier"), manager.GetClient())
		notifierHandler = notifier.EventHandler()
	)

	// Initialize agentPredicates if an GrafanaAgent selector is configured.
	if c.AgentSelector != "" {
		sel, err := meta_v1.ParseToLabelSelector(c.AgentSelector)
		if err != nil {
			return nil, fmt.Errorf("unable to create predicate for selecting GrafanaAgent CRs: %w", err)
		}
		selPredicate, err := predicate.LabelSelectorPredicate(*sel)
		if err != nil {
			return nil, fmt.Errorf("unable to create predicate for selecting GrafanaAgent CRs: %w", err)
		}
		agentPredicates = append(agentPredicates, selPredicate)
	}

	if c.KubelsetServiceName != "" {
		parts := strings.Split(c.KubelsetServiceName, "/")
		if len(parts) != 2 {
			return nil, fmt.Errorf("invalid format for kubelet-service %q, must be formatted as \"namespace/name\"", c.KubelsetServiceName)
		}
		kubeletNamespace := parts[0]
		kubeletName := parts[1]

		err := controller.NewControllerManagedBy(manager).
			For(&core_v1.Node{}).
			Owns(&core_v1.Service{}).
			Owns(&core_v1.Endpoints{}).
			Complete(&lazyKubeletReconciler)
		if err != nil {
			return nil, fmt.Errorf("failed to create kubelet controller: %w", err)
		}

		lazyKubeletReconciler.Set(&kubeletReconciler{
			Client: manager.GetClient(),

			kubeletNamespace: kubeletNamespace,
			kubeletName:      kubeletName,
		})
	}

	err = controller.NewControllerManagedBy(manager).
		For(&gragent.GrafanaAgent{}, builder.WithPredicates(agentPredicates...)).
		Owns(&apps_v1.StatefulSet{}).
		Owns(&apps_v1.DaemonSet{}).
		Owns(&apps_v1.Deployment{}).
		Owns(&core_v1.Secret{}).
		Owns(&core_v1.Service{}).
		Watches(&source.Kind{Type: &core_v1.Secret{}}, notifierHandler).
		Watches(&source.Kind{Type: &gragent.LogsInstance{}}, notifierHandler).
		Watches(&source.Kind{Type: &gragent.PodLogs{}}, notifierHandler).
		Watches(&source.Kind{Type: &gragent.MetricsInstance{}}, notifierHandler).
		Watches(&source.Kind{Type: &gragent.Integration{}}, notifierHandler).
		Watches(&source.Kind{Type: &promop_v1.PodMonitor{}}, notifierHandler).
		Watches(&source.Kind{Type: &promop_v1.Probe{}}, notifierHandler).
		Watches(&source.Kind{Type: &promop_v1.ServiceMonitor{}}, notifierHandler).
		Watches(&source.Kind{Type: &core_v1.Secret{}}, notifierHandler).
		Watches(&source.Kind{Type: &core_v1.ConfigMap{}}, notifierHandler).
		Complete(&lazyAgentReconciler)
	if err != nil {
		return nil, fmt.Errorf("failed to create GrafanaAgent controller: %w", err)
	}

	lazyAgentReconciler.Set(&reconciler{
		Client:   manager.GetClient(),
		scheme:   manager.GetScheme(),
		notifier: notifier,
		config:   c,
	})

	return &Operator{
		log:     l,
		manager: manager,

		kubeletReconciler: &lazyKubeletReconciler,
		agentReconciler:   &lazyAgentReconciler,
	}, nil
}

// Start starts the operator. It will run until ctx is canceled.
func (o *Operator) Start(ctx context.Context) error {
	return o.manager.Start(ctx)
}

type lazyReconciler struct {
	mut   sync.RWMutex
	inner reconcile.Reconciler
}

// Get returns the current reconciler.
func (lr *lazyReconciler) Get() reconcile.Reconciler {
	lr.mut.RLock()
	defer lr.mut.RUnlock()
	return lr.inner
}

// Set updates the current reconciler.
func (lr *lazyReconciler) Set(inner reconcile.Reconciler) {
	lr.mut.Lock()
	defer lr.mut.Unlock()
	lr.inner = inner
}

// Wrap wraps the current reconciler with a middleware.
func (lr *lazyReconciler) Wrap(mw func(next reconcile.Reconciler) reconcile.Reconciler) {
	lr.mut.Lock()
	defer lr.mut.Unlock()
	lr.inner = mw(lr.inner)
}

// Reconcile calls Reconcile against the current reconciler.
func (lr *lazyReconciler) Reconcile(ctx context.Context, req reconcile.Request) (reconcile.Result, error) {
	lr.mut.RLock()
	defer lr.mut.RUnlock()
	if lr.inner == nil {
		return reconcile.Result{}, fmt.Errorf("no reconciler")
	}
	return lr.inner.Reconcile(ctx, req)
}

'''
'''--- pkg/operator/operator_test.go ---
//go:build !nonetwork && !nodocker && !race
// +build !nonetwork,!nodocker,!race

package operator

import (
	"context"
	"fmt"
	"os"
	"path/filepath"
	"sync"
	"testing"
	"time"

	"github.com/go-kit/log"
	"github.com/grafana/agent/pkg/operator/logutil"
	"github.com/grafana/agent/pkg/util"
	"github.com/grafana/agent/pkg/util/k8s"
	"github.com/grafana/agent/pkg/util/subset"
	"github.com/stretchr/testify/require"
	"k8s.io/apimachinery/pkg/apis/meta/v1/unstructured"
	"sigs.k8s.io/controller-runtime/pkg/client"
	"sigs.k8s.io/yaml"
)

// TestMetricsInstance deploys a basic MetricsInstance and validates expected
// resources were applied.
func TestMetricsInstance(t *testing.T) {
	ctx, cancel := context.WithTimeout(context.Background(), 3*time.Minute)
	defer cancel()

	inFile := "./testdata/test-metrics-instance.in.yaml"
	outFile := "./testdata/test-metrics-instance.out.yaml"
	ReconcileTest(ctx, t, inFile, outFile)
}

func TestCustomMounts(t *testing.T) {
	ctx, cancel := context.WithTimeout(context.Background(), 3*time.Minute)
	defer cancel()

	inFile := "./testdata/test-custom-mounts.in.yaml"
	outFile := "./testdata/test-custom-mounts.out.yaml"
	ReconcileTest(ctx, t, inFile, outFile)
}

func TestIntegrations(t *testing.T) {
	ctx, cancel := context.WithTimeout(context.Background(), 3*time.Minute)
	defer cancel()

	inFile := "./testdata/test-integrations.in.yaml"
	outFile := "./testdata/test-integrations.out.yaml"
	ReconcileTest(ctx, t, inFile, outFile)
}

// ReconcileTest deploys a cluster and runs the operator against it locally. It
// then does the following:
//
// 1. Deploys all resources in inFile, assuming a Reconcile will retrigger from
//    them
//
// 2. Loads the resources specified by outFile and checks if the equivalent
//    existing resources in the cluster are subsets of the loaded outFile
//    resources.
//
// The second step will run in a loop until the test passes or ctx is canceled.
//
// ReconcileTest cannot be used to check that the data of a Secret or a
// ConfigMap is a subset of expected data.
func ReconcileTest(ctx context.Context, t *testing.T, inFile, outFile string) {
	t.Helper()

	var wg sync.WaitGroup
	defer wg.Wait()

	ctx, cancel := context.WithCancel(ctx)
	defer cancel()

	l := util.TestLogger(t)
	cluster := NewTestCluster(ctx, t, l)

	cfg := NewTestConfig(t, cluster)
	op, err := New(l, cfg)
	require.NoError(t, err)

	// Deploy input resources
	resources := k8s.NewResourceSet(l, cluster)
	defer resources.Stop()
	require.NoError(t, resources.AddFile(ctx, inFile))

	// Start the operator.
	wg.Add(1)
	go func() {
		defer wg.Done()
		err := op.Start(ctx)
		require.NoError(t, err)
	}()

	// Load our expected resources, and then get the real resource for each and
	// ensure that it overlaps with our expected object.
	expectedFile, err := os.Open(outFile)
	require.NoError(t, err)
	defer expectedFile.Close()

	expectedSet, err := k8s.ReadUnstructuredObjects(expectedFile)
	require.NoError(t, err)

	for _, expected := range expectedSet {
		err := k8s.Wait(ctx, l, func() error {
			var actual unstructured.Unstructured
			actual.SetGroupVersionKind(expected.GroupVersionKind())

			objKey := client.ObjectKeyFromObject(expected)

			err := cluster.Client().Get(ctx, objKey, &actual)
			if err != nil {
				return fmt.Errorf("failed to get resource: %w", err)
			}

			expectedBytes, err := yaml.Marshal(expected)
			if err != nil {
				return fmt.Errorf("failed to marshal expected: %w", err)
			}

			actualBytes, err := yaml.Marshal(&actual)
			if err != nil {
				return fmt.Errorf("failed to marshal actual: %w", err)
			}

			err = subset.YAMLAssert(expectedBytes, actualBytes)
			if err != nil {
				return fmt.Errorf("assert failed for %s: %w", objKey, err)
			}
			return nil
		})

		require.NoError(t, err)
	}
}

// NewTestCluster creates a new testing cluster. The cluster will be removed
// when the test completes.
func NewTestCluster(ctx context.Context, t *testing.T, l log.Logger) *k8s.Cluster {
	t.Helper()

	cluster, err := k8s.NewCluster(ctx, k8s.Options{})
	require.NoError(t, err)
	t.Cleanup(cluster.Stop)

	// Apply CRDs to cluster
	crds := k8s.NewResourceSet(l, cluster)
	t.Cleanup(crds.Stop)

	crdPaths, err := filepath.Glob("../../production/operator/crds/*.yaml")
	require.NoError(t, err)

	for _, crd := range crdPaths {
		err := crds.AddFile(ctx, crd)
		require.NoError(t, err)
	}

	return cluster
}

// NewTestConfig generates a new base operator Config used for tests.
func NewTestConfig(t *testing.T, cluster *k8s.Cluster) *Config {
	t.Helper()

	cfg, err := NewConfig(nil)
	require.NoError(t, err)

	cfg.RestConfig = cluster.GetConfig()
	cfg.Controller.Logger = logutil.Wrap(util.TestLogger(t))

	// Listen on any port for testing purposes
	cfg.Controller.Port = 0
	cfg.Controller.MetricsBindAddress = "127.0.0.1:0"
	cfg.Controller.HealthProbeBindAddress = "127.0.0.1:0"

	return cfg
}

'''
'''--- pkg/operator/reconciler.go ---
package operator

import (
	"context"
	"fmt"

	"github.com/go-kit/log"
	"github.com/go-kit/log/level"
	gragent "github.com/grafana/agent/pkg/operator/apis/monitoring/v1alpha1"
	"github.com/grafana/agent/pkg/operator/clientutil"
	"github.com/grafana/agent/pkg/operator/config"
	"github.com/grafana/agent/pkg/operator/hierarchy"
	"github.com/grafana/agent/pkg/operator/logutil"
	core_v1 "k8s.io/api/core/v1"
	k8s_errors "k8s.io/apimachinery/pkg/api/errors"
	v1 "k8s.io/apimachinery/pkg/apis/meta/v1"
	"k8s.io/apimachinery/pkg/runtime"
	controller "sigs.k8s.io/controller-runtime"
	"sigs.k8s.io/controller-runtime/pkg/client"
)

type reconciler struct {
	client.Client
	scheme *runtime.Scheme
	config *Config

	notifier *hierarchy.Notifier
}

func (r *reconciler) Reconcile(ctx context.Context, req controller.Request) (controller.Result, error) {
	l := logutil.FromContext(ctx)
	level.Info(l).Log("msg", "reconciling grafana-agent")
	defer level.Debug(l).Log("msg", "done reconciling grafana-agent")

	// Reset our notifications while we re-handle the reconcile.
	r.notifier.StopNotify(req.NamespacedName)

	var agent gragent.GrafanaAgent
	if err := r.Get(ctx, req.NamespacedName, &agent); k8s_errors.IsNotFound(err) {
		level.Debug(l).Log("msg", "detected deleted agent")
		return controller.Result{}, nil
	} else if err != nil {
		level.Error(l).Log("msg", "unable to get grafana-agent", "err", err)
		return controller.Result{}, nil
	}

	if agent.Spec.Paused {
		return controller.Result{}, nil
	}

	deployment, watchers, err := buildHierarchy(ctx, l, r.Client, &agent)
	if err != nil {
		level.Error(l).Log("msg", "unable to build hierarchy", "err", err)
		return controller.Result{}, nil
	}
	if err := r.notifier.Notify(watchers...); err != nil {
		level.Error(l).Log("msg", "unable to update notifier", "err", err)
		return controller.Result{}, nil
	}

	type reconcileFunc func(context.Context, log.Logger, gragent.Deployment) error
	actors := []reconcileFunc{
		// Operator-wide resources
		r.createSecrets,

		// Metrics resources (may be a no-op if no metrics configured)
		r.createMetricsConfigurationSecret,
		r.createMetricsGoverningService,
		r.createMetricsStatefulSets,

		// Logs resources (may be a no-op if no logs configured)
		r.createLogsConfigurationSecret,
		r.createLogsDaemonSet,

		// Integration resources (may be a no-op if no integrations configured)
		r.newIntegrationsDeploymentSecret,
		r.newIntegrationsDaemonSetSecret,
		r.newIntegrationsDeployment,
		r.newIntegrationsDaemonSet,
	}
	for _, actor := range actors {
		err := actor(ctx, l, deployment)
		if err != nil {
			level.Error(l).Log("msg", "error during reconciling", "err", err)
			return controller.Result{Requeue: true}, nil
		}
	}

	return controller.Result{}, nil
}

// createSecrets creates secrets from the secret store.
func (r *reconciler) createSecrets(
	ctx context.Context,
	l log.Logger,
	d gragent.Deployment,
) error {

	blockOwnerDeletion := true

	data := make(map[string][]byte)
	for k, value := range d.Secrets {
		data[config.SanitizeLabelName(string(k))] = []byte(value)
	}

	secret := core_v1.Secret{
		ObjectMeta: v1.ObjectMeta{
			Namespace: d.Agent.Namespace,
			Name:      fmt.Sprintf("%s-secrets", d.Agent.Name),
			OwnerReferences: []v1.OwnerReference{{
				APIVersion:         d.Agent.APIVersion,
				BlockOwnerDeletion: &blockOwnerDeletion,
				Kind:               d.Agent.Kind,
				Name:               d.Agent.Name,
				UID:                d.Agent.UID,
			}},
			Labels: map[string]string{
				managedByOperatorLabel: managedByOperatorLabelValue,
			},
		},
		Data: data,
	}

	level.Info(l).Log("msg", "reconciling secret", "secret", secret.Name)
	err := clientutil.CreateOrUpdateSecret(ctx, r.Client, &secret)
	if err != nil {
		return fmt.Errorf("failed to reconcile secret: %w", err)
	}
	return nil
}

'''
'''--- pkg/operator/reconciler_integrations.go ---
package operator

import (
	"context"
	"fmt"

	"github.com/go-kit/log"
	"github.com/go-kit/log/level"
	gragent "github.com/grafana/agent/pkg/operator/apis/monitoring/v1alpha1"
	"github.com/grafana/agent/pkg/operator/clientutil"
	"github.com/grafana/agent/pkg/operator/config"
	apps_v1 "k8s.io/api/apps/v1"
	"k8s.io/apimachinery/pkg/types"
)

func (r *reconciler) newIntegrationsDeploymentSecret(
	ctx context.Context,
	l log.Logger,
	d gragent.Deployment,
) error {

	// The Deployment for integrations only has integrations where AllNodes is
	// false.
	d = deploymentIntegrationSubset(d, false)

	name := fmt.Sprintf("%s-integrations-deploy-config", d.Agent.Name)
	return r.createTelemetryConfigurationSecret(ctx, l, name, d, config.IntegrationsType)
}

func (r *reconciler) newIntegrationsDaemonSetSecret(
	ctx context.Context,
	l log.Logger,
	d gragent.Deployment,
) error {

	// The DaemonSet for integrations only has integrations where AllNodes is
	// true.
	d = deploymentIntegrationSubset(d, true)

	name := fmt.Sprintf("%s-integrations-ds-config", d.Agent.Name)
	return r.createTelemetryConfigurationSecret(ctx, l, name, d, config.IntegrationsType)
}

func deploymentIntegrationSubset(d gragent.Deployment, allNodes bool) gragent.Deployment {
	res := *d.DeepCopy()

	filteredIntegrations := make([]gragent.IntegrationsDeployment, 0, len(d.Integrations))
	for _, i := range d.Integrations {
		if i.Instance.Spec.Type.AllNodes == allNodes {
			filteredIntegrations = append(filteredIntegrations, i)
		}
	}

	res.Integrations = filteredIntegrations
	return res
}

func (r *reconciler) newIntegrationsDeployment(
	ctx context.Context,
	l log.Logger,
	d gragent.Deployment,
) error {

	// The Deployment for integrations only has integrations where AllNodes is
	// false.
	d = deploymentIntegrationSubset(d, false)

	name := fmt.Sprintf("%s-integrations-deploy", d.Agent.Name)
	deploy, err := newIntegrationsDeployment(r.config, name, d)
	if err != nil {
		return fmt.Errorf("failed to generate integrations Deployment: %w", err)
	}
	key := types.NamespacedName{Namespace: deploy.Namespace, Name: deploy.Name}

	if len(d.Integrations) == 0 {
		// There's nothing to deploy; delete anything that might've been deployed
		// from a previous reconcile.
		level.Info(l).Log("msg", "deleting integrations Deployment", "deploy", key)
		var deploy apps_v1.Deployment
		return deleteManagedResource(ctx, r.Client, key, &deploy)
	}

	level.Info(l).Log("msg", "reconciling integrations Deployment", "deploy", key)
	err = clientutil.CreateOrUpdateDeployment(ctx, r.Client, deploy)
	if err != nil {
		return fmt.Errorf("failed to reconcile integrations Deployment: %w", err)
	}
	return nil
}

func (r *reconciler) newIntegrationsDaemonSet(
	ctx context.Context,
	l log.Logger,
	d gragent.Deployment,
) error {

	// The DaemonSet for integrations only has integrations where AllNodes is
	// true.
	d = deploymentIntegrationSubset(d, true)

	name := fmt.Sprintf("%s-integrations-ds", d.Agent.Name)
	ds, err := newIntegrationsDaemonSet(r.config, name, d)
	if err != nil {
		return fmt.Errorf("failed to generate integrations DaemonSet: %w", err)
	}
	key := types.NamespacedName{Namespace: ds.Namespace, Name: ds.Name}

	if len(d.Integrations) == 0 {
		// There's nothing to deploy; delete anything that might've been deployed
		// from a previous reconcile.
		level.Info(l).Log("msg", "deleting integrations DaemonSet", "ds", key)
		var ds apps_v1.DaemonSet
		return deleteManagedResource(ctx, r.Client, key, &ds)
	}

	level.Info(l).Log("msg", "reconciling integrations DaemonSet", "ds", key)
	err = clientutil.CreateOrUpdateDaemonSet(ctx, r.Client, ds)
	if err != nil {
		return fmt.Errorf("failed to reconcile integrations DaemonSet: %w", err)
	}
	return nil
}

'''
'''--- pkg/operator/reconciler_integrations_test.go ---
package operator

import (
	"testing"

	gragent "github.com/grafana/agent/pkg/operator/apis/monitoring/v1alpha1"
	"github.com/stretchr/testify/require"
	meta_v1 "k8s.io/apimachinery/pkg/apis/meta/v1"
)

func Test_deploymentIntegrationSubset(t *testing.T) {
	var (
		nodeExporter = &gragent.Integration{
			ObjectMeta: meta_v1.ObjectMeta{
				Name:      "node_exporter",
				Namespace: "default",
			},
			Spec: gragent.IntegrationSpec{
				Name: "node_exporter",
				Type: gragent.IntegrationType{AllNodes: true},
			},
		}
		process = &gragent.Integration{
			ObjectMeta: meta_v1.ObjectMeta{
				Name:      "process",
				Namespace: "default",
			},
			Spec: gragent.IntegrationSpec{
				Name: "process",
				Type: gragent.IntegrationType{AllNodes: true},
			},
		}
		redis = &gragent.Integration{
			ObjectMeta: meta_v1.ObjectMeta{
				Name:      "redis",
				Namespace: "default",
			},
			Spec: gragent.IntegrationSpec{
				Name: "redis",
				Type: gragent.IntegrationType{AllNodes: false},
			},
		}

		deploy = gragent.Deployment{
			Integrations: []gragent.IntegrationsDeployment{
				{Instance: nodeExporter},
				{Instance: process},
				{Instance: redis},
			},
		}
	)

	tt := []struct {
		name     string
		allNodes bool
		expect   []*gragent.Integration
	}{
		{
			name:     "allNodes=false",
			allNodes: false,
			expect:   []*gragent.Integration{redis},
		},
		{
			name:     "allNodes=true",
			allNodes: true,
			expect:   []*gragent.Integration{nodeExporter, process},
		},
	}

	for _, tc := range tt {
		t.Run(tc.name, func(t *testing.T) {
			res := deploymentIntegrationSubset(deploy, tc.allNodes)

			integrations := make([]*gragent.Integration, 0, len(res.Integrations))
			for _, i := range res.Integrations {
				integrations = append(integrations, i.Instance)
			}

			require.Equal(t, tc.expect, integrations)
		})
	}
}

'''
'''--- pkg/operator/reconciler_logs.go ---
package operator

import (
	"context"
	"fmt"

	"github.com/go-kit/log"
	"github.com/go-kit/log/level"
	gragent "github.com/grafana/agent/pkg/operator/apis/monitoring/v1alpha1"
	"github.com/grafana/agent/pkg/operator/clientutil"
	"github.com/grafana/agent/pkg/operator/config"
	apps_v1 "k8s.io/api/apps/v1"
	"k8s.io/apimachinery/pkg/types"
)

// createLogsConfigurationSecret creates the Grafana Agent logs configuration
// and stores it into a secret.
func (r *reconciler) createLogsConfigurationSecret(
	ctx context.Context,
	l log.Logger,
	d gragent.Deployment,
) error {

	name := fmt.Sprintf("%s-logs-config", d.Agent.Name)
	return r.createTelemetryConfigurationSecret(ctx, l, name, d, config.LogsType)
}

// createLogsDaemonSet creates a DaemonSet for logs.
func (r *reconciler) createLogsDaemonSet(
	ctx context.Context,
	l log.Logger,
	d gragent.Deployment,
) error {

	name := fmt.Sprintf("%s-logs", d.Agent.Name)
	ds, err := generateLogsDaemonSet(r.config, name, d)
	if err != nil {
		return fmt.Errorf("failed to generate DaemonSet: %w", err)
	}
	key := types.NamespacedName{Namespace: ds.Namespace, Name: ds.Name}

	if len(d.Logs) == 0 {
		// There's nothing to deploy; delete anything that might've been deployed
		// from a previous reconcile.
		var ds apps_v1.DaemonSet
		return deleteManagedResource(ctx, r.Client, key, &ds)
	}

	level.Info(l).Log("msg", "reconciling logs daemonset", "ds", key)
	err = clientutil.CreateOrUpdateDaemonSet(ctx, r.Client, ds)
	if err != nil {
		return fmt.Errorf("failed to reconcile statefulset governing service: %w", err)
	}
	return nil
}

'''
'''--- pkg/operator/reconciler_metrics.go ---
package operator

import (
	"context"
	"errors"
	"fmt"
	"os"

	"github.com/go-kit/log"
	"github.com/go-kit/log/level"
	"github.com/google/go-jsonnet"
	gragent "github.com/grafana/agent/pkg/operator/apis/monitoring/v1alpha1"
	"github.com/grafana/agent/pkg/operator/clientutil"
	"github.com/grafana/agent/pkg/operator/config"
	apps_v1 "k8s.io/api/apps/v1"
	core_v1 "k8s.io/api/core/v1"
	v1 "k8s.io/apimachinery/pkg/apis/meta/v1"
	"k8s.io/apimachinery/pkg/labels"
	"k8s.io/apimachinery/pkg/types"
	"k8s.io/utils/pointer"
	"sigs.k8s.io/controller-runtime/pkg/client"
)

// createMetricsConfigurationSecret creates the Grafana Agent metrics configuration and stores
// it into a secret.
func (r *reconciler) createMetricsConfigurationSecret(
	ctx context.Context,
	l log.Logger,
	d gragent.Deployment,
) error {

	name := fmt.Sprintf("%s-config", d.Agent.Name)
	return r.createTelemetryConfigurationSecret(ctx, l, name, d, config.MetricsType)
}

func (r *reconciler) createTelemetryConfigurationSecret(
	ctx context.Context,
	l log.Logger,
	name string,
	d gragent.Deployment,
	ty config.Type,
) error {

	key := types.NamespacedName{
		Namespace: d.Agent.Namespace,
		Name:      name,
	}

	var shouldCreate bool
	switch ty {
	case config.MetricsType:
		shouldCreate = len(d.Metrics) > 0
	case config.LogsType:
		shouldCreate = len(d.Logs) > 0
	case config.IntegrationsType:
		shouldCreate = len(d.Integrations) > 0
	default:
		return fmt.Errorf("unknown telemetry type %s", ty)
	}

	// Delete the old Secret if one exists and we have nothing to create.
	if !shouldCreate {
		var secret core_v1.Secret
		return deleteManagedResource(ctx, r.Client, key, &secret)
	}

	rawConfig, err := config.BuildConfig(&d, ty)

	var jsonnetError jsonnet.RuntimeError
	if errors.As(err, &jsonnetError) {
		// Dump Jsonnet errors to the console to retain newlines and make them
		// easier to digest.
		fmt.Fprintf(os.Stderr, "%s", jsonnetError.Error())
	}
	if err != nil {
		return fmt.Errorf("unable to build config: %w", err)
	}

	secret := core_v1.Secret{
		ObjectMeta: v1.ObjectMeta{
			Namespace: key.Namespace,
			Name:      key.Name,
			Labels:    r.config.Labels.Merge(managedByOperatorLabels),
			OwnerReferences: []v1.OwnerReference{{
				APIVersion:         d.Agent.APIVersion,
				BlockOwnerDeletion: pointer.Bool(true),
				Kind:               d.Agent.Kind,
				Name:               d.Agent.Name,
				UID:                d.Agent.UID,
			}},
		},
		Data: map[string][]byte{"agent.yml": []byte(rawConfig)},
	}

	level.Info(l).Log("msg", "reconciling secret", "secret", secret.Name)
	err = clientutil.CreateOrUpdateSecret(ctx, r.Client, &secret)
	if err != nil {
		return fmt.Errorf("failed to reconcile secret: %w", err)
	}
	return nil
}

// createMetricsGoverningService creates the service that governs the (eventual)
// StatefulSet. It must be created before the StatefulSet.
func (r *reconciler) createMetricsGoverningService(
	ctx context.Context,
	l log.Logger,
	d gragent.Deployment,
) error {

	svc := generateMetricsStatefulSetService(r.config, d)

	// Delete the old Service if one exists and we have no prometheus instances.
	if len(d.Metrics) == 0 {
		var service core_v1.Service
		key := types.NamespacedName{Namespace: svc.Namespace, Name: svc.Name}
		return deleteManagedResource(ctx, r.Client, key, &service)
	}

	level.Info(l).Log("msg", "reconciling statefulset service", "service", svc.Name)
	err := clientutil.CreateOrUpdateService(ctx, r.Client, svc)
	if err != nil {
		return fmt.Errorf("failed to reconcile statefulset governing service: %w", err)
	}
	return nil
}

// createMetricsStatefulSets creates a set of Grafana Agent StatefulSets, one per shard.
func (r *reconciler) createMetricsStatefulSets(
	ctx context.Context,
	l log.Logger,
	d gragent.Deployment,
) error {

	shards := minShards
	if reqShards := d.Agent.Spec.Metrics.Shards; reqShards != nil && *reqShards > 1 {
		shards = *reqShards
	}

	// Keep track of generated stateful sets so we can delete ones that should
	// no longer exist.
	generated := make(map[string]struct{})

	for shard := int32(0); shard < shards; shard++ {
		// Don't generate anything if there weren't any instances.
		if len(d.Metrics) == 0 {
			continue
		}

		name := d.Agent.Name
		if shard > 0 {
			name = fmt.Sprintf("%s-shard-%d", name, shard)
		}

		ss, err := generateMetricsStatefulSet(r.config, name, d, shard)
		if err != nil {
			return fmt.Errorf("failed to generate statefulset for shard: %w", err)
		}

		level.Info(l).Log("msg", "reconciling statefulset", "statefulset", ss.Name)
		err = clientutil.CreateOrUpdateStatefulSet(ctx, r.Client, ss)
		if err != nil {
			return fmt.Errorf("failed to reconcile statefulset for shard: %w", err)
		}
		generated[ss.Name] = struct{}{}
	}

	// Clean up statefulsets that should no longer exist.
	var statefulSets apps_v1.StatefulSetList
	err := r.List(ctx, &statefulSets, &client.ListOptions{
		LabelSelector: labels.SelectorFromSet(labels.Set{
			managedByOperatorLabel: managedByOperatorLabelValue,
			agentNameLabelName:     d.Agent.Name,
		}),
	})
	if err != nil {
		return fmt.Errorf("failed to list statefulsets: %w", err)
	}
	for _, ss := range statefulSets.Items {
		if _, keep := generated[ss.Name]; keep || !isManagedResource(&ss) {
			continue
		}
		level.Info(l).Log("msg", "deleting stale statefulset", "name", ss.Name)
		if err := r.Delete(ctx, &ss); err != nil {
			return fmt.Errorf("failed to delete stale statefulset %s: %w", ss.Name, err)
		}
	}

	return nil
}

'''
'''--- pkg/operator/resources_integrations.go ---
package operator

import (
	"fmt"

	gragent "github.com/grafana/agent/pkg/operator/apis/monitoring/v1alpha1"
	"github.com/grafana/agent/pkg/operator/assets"
	"github.com/grafana/agent/pkg/operator/config"
	apps_v1 "k8s.io/api/apps/v1"
	core_v1 "k8s.io/api/core/v1"
)

func newIntegrationsDaemonSet(cfg *Config, name string, d gragent.Deployment) (*apps_v1.DaemonSet, error) {
	opts := integrationsPodTemplateOptions(name, d)
	tmpl, selector, err := generatePodTemplate(cfg, name, d, opts)
	if err != nil {
		return nil, err
	}

	spec := apps_v1.DaemonSetSpec{
		UpdateStrategy: apps_v1.DaemonSetUpdateStrategy{
			Type: apps_v1.RollingUpdateDaemonSetStrategyType,
		},
		Selector: selector,
		Template: tmpl,
	}

	return &apps_v1.DaemonSet{
		ObjectMeta: metadataFromPodTemplate(name, d, tmpl),
		Spec:       spec,
	}, nil
}

func newIntegrationsDeployment(cfg *Config, name string, d gragent.Deployment) (*apps_v1.Deployment, error) {
	opts := integrationsPodTemplateOptions(name, d)
	tmpl, selector, err := generatePodTemplate(cfg, name, d, opts)
	if err != nil {
		return nil, err
	}

	spec := apps_v1.DeploymentSpec{
		Strategy: apps_v1.DeploymentStrategy{
			Type: apps_v1.RollingUpdateDeploymentStrategyType,
		},
		Selector: selector,
		Template: tmpl,
	}

	return &apps_v1.Deployment{
		ObjectMeta: metadataFromPodTemplate(name, d, tmpl),
		Spec:       spec,
	}, nil
}

func integrationsPodTemplateOptions(name string, d gragent.Deployment) podTemplateOptions {
	// Integrations expect that the metrics and logs instances exist. This means
	// that we have to merge the podTemplateOptions used for metrics and logs
	// with the options used for integrations.

	// Since integrations may be running as a DaemonSet, it's not possible for us
	// to rely on a PVC template that metrics might be using. We'll force the WAL
	// to use an empty volume.
	d.Agent.Spec.Storage = nil

	integrationOpts := podTemplateOptions{
		ExtraSelectorLabels: map[string]string{
			agentTypeLabel: "integrations",
		},
	}

	// We need to iterate over all of our integrations to append extra Volumes,
	// VolumesMounts, and references to Secrets or ConfigMaps from the resource
	// hierarchy.
	var (
		secretsPaths []core_v1.KeyToPath
		mountedKeys  = map[assets.Key]struct{}{}
	)

	for _, i := range d.Integrations {
		inst := i.Instance
		volumePrefix := fmt.Sprintf("%s-%s-", inst.Namespace, inst.Name)

		for _, v := range inst.Spec.Volumes {
			// Prefix the key of the Integration CR so it doesn't potentially collide
			// with other loaded Integration CRs.
			v = *v.DeepCopy()
			v.Name = volumePrefix + v.Name

			integrationOpts.ExtraVolumes = append(integrationOpts.ExtraVolumes, v)
		}
		for _, vm := range inst.Spec.VolumeMounts {
			// Prefix the key of the Integration CR so it doesn't potentially collide
			// with other loaded Integration CRs.
			vm = *vm.DeepCopy()
			vm.Name = volumePrefix + vm.Name

			integrationOpts.ExtraVolumeMounts = append(integrationOpts.ExtraVolumeMounts, vm)
		}

		for _, s := range inst.Spec.Secrets {
			// We need to determine what the value for this Secret was in the shared
			// Secret resource.
			key := assets.KeyForSecret(inst.Namespace, &s)
			if _, mounted := mountedKeys[key]; mounted {
				continue
			}
			mountedKeys[key] = struct{}{}

			secretsPaths = append(secretsPaths, core_v1.KeyToPath{
				Key:  config.SanitizeLabelName(string(key)),
				Path: fmt.Sprintf("secrets/%s/%s/%s", inst.Namespace, s.Name, s.Key),
			})
		}

		for _, cm := range inst.Spec.ConfigMaps {
			// We need to determine what the value for this ConfigMap was in the shared
			// Secret resource.
			key := assets.KeyForConfigMap(inst.Namespace, &cm)
			if _, mounted := mountedKeys[key]; mounted {
				continue
			}
			mountedKeys[key] = struct{}{}

			secretsPaths = append(secretsPaths, core_v1.KeyToPath{
				Key:  config.SanitizeLabelName(string(key)),
				Path: fmt.Sprintf("configMaps/%s/%s/%s", inst.Namespace, cm.Name, cm.Key),
			})
		}
	}

	if len(secretsPaths) > 0 {
		// Load in references to Secrets and ConfigMaps.
		integrationSecretsName := fmt.Sprintf("%s-integrations-secrets", d.Agent.Name)

		integrationOpts.ExtraVolumes = append(integrationOpts.ExtraVolumes, core_v1.Volume{
			Name: integrationSecretsName,
			VolumeSource: core_v1.VolumeSource{
				Secret: &core_v1.SecretVolumeSource{
					// The reconcile-wide Secret holds all secrets and config maps
					// integrations may have used.
					SecretName: fmt.Sprintf("%s-secrets", d.Agent.Name),
					Items:      secretsPaths,
				},
			},
		})

		integrationOpts.ExtraVolumeMounts = append(integrationOpts.ExtraVolumeMounts, core_v1.VolumeMount{
			Name:      integrationSecretsName,
			MountPath: "/etc/grafana-agent/integrations",
			ReadOnly:  true,
		})
	}

	// Extra options to merge in.
	//
	// NOTE(rfratto): Merge order is important, as subsequent podTemplateOptions
	// have placeholders necessary to generate configs.
	var (
		metricsOpts = metricsPodTemplateOptions(name, d, 0)
		logsOpts    = logsPodTemplateOptions()
	)
	return mergePodTemplateOptions(&integrationOpts, &metricsOpts, &logsOpts)
}

// mergePodTemplateOptions merges the provided inputs into a single
// podTemplateOptions. Precedence for existing values is taken in input order;
// if an environment variable is defined in both inputs[0] and inputs[1], the
// value from inputs[0] is used.
func mergePodTemplateOptions(inputs ...*podTemplateOptions) podTemplateOptions {
	res := podTemplateOptions{
		ExtraSelectorLabels: make(map[string]string),
	}

	// Volumes are unique by both mount path or name. If a mount path already
	// exists, we want to ignore that volume and the respective volume mount
	// that uses it.

	var (
		mountNames  = map[string]struct{}{} // Consumed mount names
		mountPaths  = map[string]struct{}{} // Consumed mount paths
		volumeNames = map[string]struct{}{} // Consumed volume names
		varNames    = map[string]struct{}{} // Consumed variable names
	)

	for _, input := range inputs {
		for k, v := range input.ExtraSelectorLabels {
			if _, exist := res.ExtraSelectorLabels[k]; exist {
				continue
			}
			res.ExtraSelectorLabels[k] = v
		}

		// Merge in VolumeMounts before Volumes, allowing us to detect what volume
		// names specific to this input should be ignored.
		ignoreVolumes := map[string]struct{}{}

		for _, vm := range input.ExtraVolumeMounts {
			// Ignore a volume if the mount path or volume name already exists.
			var (
				_, exists  = mountNames[vm.Name]
				_, mounted = mountPaths[vm.MountPath]
			)
			if exists || mounted {
				ignoreVolumes[vm.Name] = struct{}{}
				continue
			}

			res.ExtraVolumeMounts = append(res.ExtraVolumeMounts, vm)
			mountNames[vm.Name] = struct{}{}
			mountPaths[vm.MountPath] = struct{}{}
		}

		// Merge in volumes that haven't been ignored or have a unique name.
		for _, v := range input.ExtraVolumes {
			if _, ignored := ignoreVolumes[v.Name]; ignored {
				continue
			} else if _, exists := volumeNames[v.Name]; exists {
				continue
			}

			res.ExtraVolumes = append(res.ExtraVolumes, v)
			volumeNames[v.Name] = struct{}{}
		}

		for _, ev := range input.ExtraEnvVars {
			if _, exists := varNames[ev.Name]; exists {
				continue
			}

			res.ExtraEnvVars = append(res.ExtraEnvVars, ev)
			varNames[ev.Name] = struct{}{}
		}
	}

	return res
}

'''
'''--- pkg/operator/resources_logs.go ---
package operator

import (
	gragent "github.com/grafana/agent/pkg/operator/apis/monitoring/v1alpha1"
	apps_v1 "k8s.io/api/apps/v1"
	v1 "k8s.io/api/core/v1"
)

func generateLogsDaemonSet(
	cfg *Config,
	name string,
	d gragent.Deployment,
) (*apps_v1.DaemonSet, error) {

	d = *(&d).DeepCopy()

	opts := logsPodTemplateOptions()
	tmpl, selector, err := generatePodTemplate(cfg, name, d, opts)
	if err != nil {
		return nil, err
	}

	spec := apps_v1.DaemonSetSpec{
		UpdateStrategy: apps_v1.DaemonSetUpdateStrategy{
			Type: apps_v1.RollingUpdateDaemonSetStrategyType,
		},
		Selector: selector,
		Template: tmpl,
	}

	return &apps_v1.DaemonSet{
		ObjectMeta: metadataFromPodTemplate(name, d, tmpl),
		Spec:       spec,
	}, nil
}

func logsPodTemplateOptions() podTemplateOptions {
	return podTemplateOptions{
		ExtraSelectorLabels: map[string]string{
			agentTypeLabel: "logs",
		},
		ExtraVolumes: []v1.Volume{
			{
				Name: "varlog",
				VolumeSource: v1.VolumeSource{
					HostPath: &v1.HostPathVolumeSource{Path: "/var/log"},
				},
			},
			{
				// Needed for docker. Kubernetes will symlink to this directory. For CRI
				// platforms, this doesn't change anything.
				Name: "dockerlogs",
				VolumeSource: v1.VolumeSource{
					HostPath: &v1.HostPathVolumeSource{Path: "/var/lib/docker/containers"},
				},
			},
			{
				// Needed for storing positions for recovery.
				Name: "data",
				VolumeSource: v1.VolumeSource{
					HostPath: &v1.HostPathVolumeSource{Path: "/var/lib/grafana-agent/data"},
				},
			},
		},
		ExtraVolumeMounts: []v1.VolumeMount{
			{
				Name:      "varlog",
				ReadOnly:  true,
				MountPath: "/var/log",
			}, {
				Name:      "dockerlogs",
				ReadOnly:  true,
				MountPath: "/var/lib/docker/containers",
			}, {
				Name:      "data",
				MountPath: "/var/lib/grafana-agent/data",
			},
		},
		ExtraEnvVars: []v1.EnvVar{
			{
				Name: "HOSTNAME",
				ValueFrom: &v1.EnvVarSource{
					FieldRef: &v1.ObjectFieldSelector{FieldPath: "spec.nodeName"},
				},
			},
			{
				// Not used anywhere for logs but passed to the config-reloader since it
				// expects everything is coming from a StatefulSet.
				Name:  "SHARD",
				Value: "0",
			},
		},
	}
}

'''
'''--- pkg/operator/resources_metrics.go ---
package operator

import (
	"context"
	"fmt"
	"strings"

	gragent "github.com/grafana/agent/pkg/operator/apis/monitoring/v1alpha1"
	prom_operator "github.com/prometheus-operator/prometheus-operator/pkg/operator"
	apps_v1 "k8s.io/api/apps/v1"
	core_v1 "k8s.io/api/core/v1"
	v1 "k8s.io/api/core/v1"
	k8s_errors "k8s.io/apimachinery/pkg/api/errors"
	meta_v1 "k8s.io/apimachinery/pkg/apis/meta/v1"
	"k8s.io/apimachinery/pkg/util/intstr"
	"k8s.io/utils/pointer"
	"sigs.k8s.io/controller-runtime/pkg/client"
)

const (
	defaultPortName = "http-metrics"
)

var (
	minShards                   int32 = 1
	minReplicas                 int32 = 1
	managedByOperatorLabel            = "app.kubernetes.io/managed-by"
	managedByOperatorLabelValue       = "grafana-agent-operator"
	managedByOperatorLabels           = map[string]string{
		managedByOperatorLabel: managedByOperatorLabelValue,
	}
	shardLabelName            = "operator.agent.grafana.com/shard"
	agentNameLabelName        = "operator.agent.grafana.com/name"
	agentTypeLabel            = "operator.agent.grafana.com/type"
	probeTimeoutSeconds int32 = 3
)

// deleteManagedResource deletes a managed resource. Ignores resources that are
// not managed.
func deleteManagedResource(ctx context.Context, cli client.Client, key client.ObjectKey, o client.Object) error {
	err := cli.Get(ctx, key, o)
	if k8s_errors.IsNotFound(err) || !isManagedResource(o) {
		return nil
	} else if err != nil {
		return fmt.Errorf("failed to find stale resource %s: %w", key, err)
	}
	err = cli.Delete(ctx, o)
	if err != nil {
		return fmt.Errorf("failed to delete stale resource %s: %w", key, err)
	}
	return nil
}

// isManagedResource returns true if the given object has a managed-by
// grafana-agent-operator label.
func isManagedResource(obj client.Object) bool {
	labelValue := obj.GetLabels()[managedByOperatorLabel]
	return labelValue == managedByOperatorLabelValue
}

func governingServiceName(agentName string) string {
	return fmt.Sprintf("%s-operated", agentName)
}

func generateMetricsStatefulSetService(cfg *Config, d gragent.Deployment) *v1.Service {
	d = *d.DeepCopy()

	if d.Agent.Spec.PortName == "" {
		d.Agent.Spec.PortName = defaultPortName
	}

	return &v1.Service{
		ObjectMeta: meta_v1.ObjectMeta{
			Name:      governingServiceName(d.Agent.Name),
			Namespace: d.Agent.Namespace,
			OwnerReferences: []meta_v1.OwnerReference{{
				APIVersion:         d.Agent.APIVersion,
				Kind:               d.Agent.Kind,
				Name:               d.Agent.Name,
				BlockOwnerDeletion: pointer.Bool(true),
				Controller:         pointer.Bool(true),
				UID:                d.Agent.UID,
			}},
			Labels: cfg.Labels.Merge(map[string]string{
				managedByOperatorLabel: managedByOperatorLabelValue,
				agentNameLabelName:     d.Agent.Name,
				"operated-agent":       "true",
			}),
		},
		Spec: v1.ServiceSpec{
			ClusterIP: "None",
			Ports: []v1.ServicePort{{
				Name:       d.Agent.Spec.PortName,
				Port:       8080,
				TargetPort: intstr.FromString(d.Agent.Spec.PortName),
			}},
			Selector: map[string]string{
				"app.kubernetes.io/name": "grafana-agent",
				agentNameLabelName:       d.Agent.Name,
			},
		},
	}
}

func generateMetricsStatefulSet(
	cfg *Config,
	name string,
	d gragent.Deployment,
	shard int32,
) (*apps_v1.StatefulSet, error) {

	d = *d.DeepCopy()

	opts := metricsPodTemplateOptions(name, d, shard)
	templateSpec, selector, err := generatePodTemplate(cfg, d.Agent.Name, d, opts)
	if err != nil {
		return nil, err
	}

	spec := &apps_v1.StatefulSetSpec{
		ServiceName:         governingServiceName(d.Agent.Name),
		Replicas:            d.Agent.Spec.Metrics.Replicas,
		PodManagementPolicy: apps_v1.ParallelPodManagement,
		UpdateStrategy: apps_v1.StatefulSetUpdateStrategy{
			Type: apps_v1.RollingUpdateStatefulSetStrategyType,
		},
		Selector: selector,
		Template: templateSpec,
	}

	ss := &apps_v1.StatefulSet{
		ObjectMeta: metadataFromPodTemplate(name, d, templateSpec),
		Spec:       *spec,
	}

	if deploymentUseVolumeClaimTemplate(&d) {
		storageSpec := d.Agent.Spec.Storage
		pvcTemplate := prom_operator.MakeVolumeClaimTemplate(storageSpec.VolumeClaimTemplate)
		if pvcTemplate.Name == "" {
			pvcTemplate.Name = fmt.Sprintf("%s-wal", name)
		}
		if storageSpec.VolumeClaimTemplate.Spec.AccessModes == nil {
			pvcTemplate.Spec.AccessModes = []v1.PersistentVolumeAccessMode{v1.ReadWriteOnce}
		} else {
			pvcTemplate.Spec.AccessModes = storageSpec.VolumeClaimTemplate.Spec.AccessModes
		}
		pvcTemplate.Spec.Resources = storageSpec.VolumeClaimTemplate.Spec.Resources
		pvcTemplate.Spec.Selector = storageSpec.VolumeClaimTemplate.Spec.Selector
		ss.Spec.VolumeClaimTemplates = append(ss.Spec.VolumeClaimTemplates, *pvcTemplate)
	}

	return ss, nil
}

func deploymentUseVolumeClaimTemplate(d *gragent.Deployment) bool {
	return d.Agent.Spec.Storage != nil && d.Agent.Spec.Storage.EmptyDir == nil
}

func metricsPodTemplateOptions(name string, d gragent.Deployment, shard int32) podTemplateOptions {
	shards := minShards
	if reqShards := d.Agent.Spec.Metrics.Shards; reqShards != nil && *reqShards > 1 {
		shards = *reqShards
	}

	walVolumeName := fmt.Sprintf("%s-wal", name)
	if d.Agent.Spec.Storage != nil {
		if d.Agent.Spec.Storage.VolumeClaimTemplate.Name != "" {
			walVolumeName = d.Agent.Spec.Storage.VolumeClaimTemplate.Name
		}
	}

	opts := podTemplateOptions{
		ExtraSelectorLabels: map[string]string{
			shardLabelName: fmt.Sprintf("%d", shard),
			agentTypeLabel: "metrics",
		},
		ExtraVolumeMounts: []v1.VolumeMount{{
			Name:      walVolumeName,
			ReadOnly:  false,
			MountPath: "/var/lib/grafana-agent/data",
		}},
		ExtraEnvVars: []v1.EnvVar{
			{
				Name:  "SHARD",
				Value: fmt.Sprintf("%d", shard),
			},
			{
				Name:  "SHARDS",
				Value: fmt.Sprintf("%d", shards),
			},
		},
	}

	// Add volumes if there's no PVC template
	storageSpec := d.Agent.Spec.Storage
	if storageSpec == nil {
		opts.ExtraVolumes = append(opts.ExtraVolumes, v1.Volume{
			Name: walVolumeName,
			VolumeSource: v1.VolumeSource{
				EmptyDir: &v1.EmptyDirVolumeSource{},
			},
		})
	} else if storageSpec.EmptyDir != nil {
		emptyDir := storageSpec.EmptyDir
		opts.ExtraVolumes = append(opts.ExtraVolumes, v1.Volume{
			Name: walVolumeName,
			VolumeSource: v1.VolumeSource{
				EmptyDir: emptyDir,
			},
		})
	}

	return opts
}

func metadataFromPodTemplate(name string, d gragent.Deployment, tmpl core_v1.PodTemplateSpec) meta_v1.ObjectMeta {
	return meta_v1.ObjectMeta{
		Name:        name,
		Namespace:   d.Agent.Namespace,
		Labels:      tmpl.Labels,
		Annotations: prepareAnnotations(d.Agent.Annotations),
		OwnerReferences: []meta_v1.OwnerReference{{
			APIVersion:         d.Agent.APIVersion,
			Kind:               d.Agent.Kind,
			BlockOwnerDeletion: pointer.Bool(true),
			Controller:         pointer.Bool(true),
			Name:               d.Agent.Name,
			UID:                d.Agent.UID,
		}},
	}
}

// prepareAnnotations returns annotations that are safe to be added to a
// generated resource.
func prepareAnnotations(source map[string]string) map[string]string {
	res := make(map[string]string, len(source))
	for k, v := range source {
		// Ignore kubectl annotations so kubectl doesn't prune the resource we
		// generated.
		if !strings.HasPrefix(k, "kubectl.kubernetes.io/") {
			res[k] = v
		}
	}
	return res
}

'''
'''--- pkg/operator/resources_pod_template.go ---
package operator

import (
	"fmt"
	"path"

	"github.com/grafana/agent/pkg/build"
	gragent "github.com/grafana/agent/pkg/operator/apis/monitoring/v1alpha1"
	"github.com/grafana/agent/pkg/operator/clientutil"
	core_v1 "k8s.io/api/core/v1"
	meta_v1 "k8s.io/apimachinery/pkg/apis/meta/v1"
	"k8s.io/apimachinery/pkg/util/intstr"
	"k8s.io/utils/pointer"
)

type podTemplateOptions struct {
	ExtraSelectorLabels map[string]string
	ExtraVolumes        []core_v1.Volume
	ExtraVolumeMounts   []core_v1.VolumeMount
	ExtraEnvVars        []core_v1.EnvVar
}

func generatePodTemplate(
	cfg *Config,
	name string,
	d gragent.Deployment,
	opts podTemplateOptions,
) (core_v1.PodTemplateSpec, *meta_v1.LabelSelector, error) {

	// generatePodTemplate assumes that the deployment has default values applied
	// to it.
	applyDeploymentDefaults(&d)

	useVersion := d.Agent.Spec.Version
	if useVersion == "" {
		useVersion = DefaultAgentVersion
	}
	imagePath := fmt.Sprintf("%s:%s", DefaultAgentBaseImage, useVersion)
	if d.Agent.Spec.Image != nil && *d.Agent.Spec.Image != "" {
		imagePath = *d.Agent.Spec.Image
	}

	agentArgs := []string{
		"-config.file=/var/lib/grafana-agent/config/agent.yml",
		"-config.expand-env=true",
		"-server.http.address=0.0.0.0:8080",
		"-enable-features=integrations-next",
	}

	enableConfigReadAPI := d.Agent.Spec.EnableConfigReadAPI
	if enableConfigReadAPI {
		agentArgs = append(agentArgs, "-config.enable-read-api")
	}

	// NOTE(rfratto): the Prometheus Operator supports a ListenLocal to prevent a
	// service from being created. Given the intent is that Agents can connect to
	// each other, ListenLocal isn't currently supported and we always create a
	// port.
	ports := []core_v1.ContainerPort{{
		Name:          d.Agent.Spec.PortName,
		ContainerPort: 8080,
		Protocol:      core_v1.ProtocolTCP,
	}}

	volumes := []core_v1.Volume{
		{
			Name: "config",
			VolumeSource: core_v1.VolumeSource{
				Secret: &core_v1.SecretVolumeSource{
					SecretName: fmt.Sprintf("%s-config", name),
				},
			},
		},
		{
			// We need a separate volume for storing the rendered config with
			// environment variables replaced. While the Agent supports environment
			// variable substitution, the value for __replica__ can only be
			// determined at runtime. We use a dedicated container for both config
			// reloading and rendering.
			Name: "config-out",
			VolumeSource: core_v1.VolumeSource{
				EmptyDir: &core_v1.EmptyDirVolumeSource{},
			},
		},
		{
			Name: "secrets",
			VolumeSource: core_v1.VolumeSource{
				Secret: &core_v1.SecretVolumeSource{
					SecretName: fmt.Sprintf("%s-secrets", d.Agent.Name),
				},
			},
		},
	}
	volumes = append(volumes, opts.ExtraVolumes...)
	volumes = append(volumes, d.Agent.Spec.Volumes...)

	volumeMounts := []core_v1.VolumeMount{
		{
			Name:      "config",
			ReadOnly:  true,
			MountPath: "/var/lib/grafana-agent/config-in",
		},
		{
			Name:      "config-out",
			MountPath: "/var/lib/grafana-agent/config",
		},
		{
			Name:      "secrets",
			ReadOnly:  true,
			MountPath: "/var/lib/grafana-agent/secrets",
		},
	}
	volumeMounts = append(volumeMounts, opts.ExtraVolumeMounts...)
	volumeMounts = append(volumeMounts, d.Agent.Spec.VolumeMounts...)

	for _, s := range d.Agent.Spec.Secrets {
		volumes = append(volumes, core_v1.Volume{
			Name: clientutil.SanitizeVolumeName("secret-" + s),
			VolumeSource: core_v1.VolumeSource{
				Secret: &core_v1.SecretVolumeSource{SecretName: s},
			},
		})
		volumeMounts = append(volumeMounts, core_v1.VolumeMount{
			Name:      clientutil.SanitizeVolumeName("secret-" + s),
			ReadOnly:  true,
			MountPath: path.Join("/var/lib/grafana-agent/extra-secrets", s),
		})
	}

	for _, c := range d.Agent.Spec.ConfigMaps {
		volumes = append(volumes, core_v1.Volume{
			Name: clientutil.SanitizeVolumeName("configmap-" + c),
			VolumeSource: core_v1.VolumeSource{
				ConfigMap: &core_v1.ConfigMapVolumeSource{
					LocalObjectReference: core_v1.LocalObjectReference{Name: c},
				},
			},
		})
		volumeMounts = append(volumeMounts, core_v1.VolumeMount{
			Name:      clientutil.SanitizeVolumeName("configmap-" + c),
			ReadOnly:  true,
			MountPath: path.Join("/var/lib/grafana-agent/extra-configmaps", c),
		})
	}

	var (
		podAnnotations    = map[string]string{}
		podLabels         = map[string]string{}
		podSelectorLabels = map[string]string{
			"app.kubernetes.io/name":     "grafana-agent",
			"app.kubernetes.io/version":  build.Version,
			"app.kubernetes.io/instance": d.Agent.Name,
			"grafana-agent":              d.Agent.Name,
			managedByOperatorLabel:       managedByOperatorLabelValue,
			agentNameLabelName:           d.Agent.Name,
		}
	)
	for k, v := range opts.ExtraSelectorLabels {
		podSelectorLabels[k] = v
	}

	if d.Agent.Spec.PodMetadata != nil {
		for k, v := range d.Agent.Spec.PodMetadata.Labels {
			podLabels[k] = v
		}
		for k, v := range d.Agent.Spec.PodMetadata.Annotations {
			podAnnotations[k] = v
		}
	}
	for k, v := range podSelectorLabels {
		podLabels[k] = v
	}

	podAnnotations["kubectl.kubernetes.io/default-container"] = "grafana-agent"

	var (
		finalSelectorLabels = cfg.Labels.Merge(podSelectorLabels)
		finalLabels         = cfg.Labels.Merge(podLabels)
	)

	envVars := []core_v1.EnvVar{{
		Name: "POD_NAME",
		ValueFrom: &core_v1.EnvVarSource{
			FieldRef: &core_v1.ObjectFieldSelector{FieldPath: "metadata.name"},
		},
	}}
	envVars = append(envVars, opts.ExtraEnvVars...)

	operatorContainers := []core_v1.Container{
		{
			Name:         "config-reloader",
			Image:        "quay.io/prometheus-operator/prometheus-config-reloader:v0.47.0",
			VolumeMounts: volumeMounts,
			Env:          envVars,
			SecurityContext: &core_v1.SecurityContext{
				Privileged: pointer.Bool(true),
				RunAsUser:  pointer.Int64(0),
			},
			Args: []string{
				"--config-file=/var/lib/grafana-agent/config-in/agent.yml",
				"--config-envsubst-file=/var/lib/grafana-agent/config/agent.yml",

				"--watch-interval=1m",
				"--statefulset-ordinal-from-envvar=POD_NAME",
				"--reload-url=http://127.0.0.1:8080/-/reload",
			},
		},
		{
			Name:         "grafana-agent",
			Image:        imagePath,
			Ports:        ports,
			Args:         agentArgs,
			VolumeMounts: volumeMounts,
			Env:          envVars,
			ReadinessProbe: &core_v1.Probe{
				ProbeHandler: core_v1.ProbeHandler{
					HTTPGet: &core_v1.HTTPGetAction{
						Path: "/-/ready",
						Port: intstr.FromString(d.Agent.Spec.PortName),
					},
				},
				TimeoutSeconds:   probeTimeoutSeconds,
				PeriodSeconds:    5,
				FailureThreshold: 120, // Allow up to 10m on startup for data recovery
			},
			Resources:                d.Agent.Spec.Resources,
			TerminationMessagePolicy: core_v1.TerminationMessageFallbackToLogsOnError,
		},
	}

	containers, err := clientutil.MergePatchContainers(operatorContainers, d.Agent.Spec.Containers)
	if err != nil {
		return core_v1.PodTemplateSpec{}, nil, fmt.Errorf("failed to merge containers spec: %w", err)
	}

	var pullSecrets []core_v1.LocalObjectReference
	if len(d.Agent.Spec.ImagePullSecrets) > 0 {
		pullSecrets = d.Agent.Spec.ImagePullSecrets
	}

	template := core_v1.PodTemplateSpec{
		ObjectMeta: meta_v1.ObjectMeta{
			Labels:      finalLabels,
			Annotations: podAnnotations,
		},
		Spec: core_v1.PodSpec{
			Containers:                    containers,
			ImagePullSecrets:              pullSecrets,
			InitContainers:                d.Agent.Spec.InitContainers,
			SecurityContext:               d.Agent.Spec.SecurityContext,
			ServiceAccountName:            d.Agent.Spec.ServiceAccountName,
			NodeSelector:                  d.Agent.Spec.NodeSelector,
			PriorityClassName:             d.Agent.Spec.PriorityClassName,
			TerminationGracePeriodSeconds: pointer.Int64(4800),
			Volumes:                       volumes,
			Tolerations:                   d.Agent.Spec.Tolerations,
			Affinity:                      d.Agent.Spec.Affinity,
			TopologySpreadConstraints:     d.Agent.Spec.TopologySpreadConstraints,
		},
	}
	return template, &meta_v1.LabelSelector{MatchLabels: finalSelectorLabels}, nil
}

func applyDeploymentDefaults(d *gragent.Deployment) {
	if d.Agent.Spec.Metrics.Replicas != nil && *d.Agent.Spec.Metrics.Replicas < 0 {
		intZero := int32(0)
		d.Agent.Spec.Metrics.Replicas = &intZero
	}

	if d.Agent.Spec.Resources.Requests == nil {
		d.Agent.Spec.Resources.Requests = core_v1.ResourceList{}
	}

	if d.Agent.Spec.Metrics.Replicas == nil {
		d.Agent.Spec.Metrics.Replicas = &minReplicas
	}

	if d.Agent.Spec.PortName == "" {
		d.Agent.Spec.PortName = defaultPortName
	}
}

'''
'''--- pkg/operator/resources_pod_template_test.go ---
package operator

import (
	"testing"

	gragent "github.com/grafana/agent/pkg/operator/apis/monitoring/v1alpha1"
	"github.com/stretchr/testify/require"
	v1 "k8s.io/apimachinery/pkg/apis/meta/v1"
)

func Test_generatePodTemplate(t *testing.T) {
	var (
		cfg  = &Config{}
		name = "example"
	)

	t.Run("image should have version", func(t *testing.T) {
		deploy := gragent.Deployment{
			Agent: &gragent.GrafanaAgent{
				ObjectMeta: v1.ObjectMeta{Name: name, Namespace: name},
			},
		}

		tmpl, _, err := generatePodTemplate(cfg, "agent", deploy, podTemplateOptions{})
		require.NoError(t, err)
		require.Equal(t, DefaultAgentImage, tmpl.Spec.Containers[1].Image)
	})

	t.Run("allow custom version", func(t *testing.T) {
		deploy := gragent.Deployment{
			Agent: &gragent.GrafanaAgent{
				ObjectMeta: v1.ObjectMeta{Name: name, Namespace: name},
				Spec: gragent.GrafanaAgentSpec{
					Version: "vX.Y.Z",
				},
			},
		}

		tmpl, _, err := generatePodTemplate(cfg, "agent", deploy, podTemplateOptions{})
		require.NoError(t, err)
		require.Equal(t, DefaultAgentBaseImage+":vX.Y.Z", tmpl.Spec.Containers[1].Image)
	})
}

'''
'''--- pkg/river/ast/ast.go ---
// Package ast exposes AST elements used by River.
//
// The various interfaces exposed by ast are all closed; only types within this
// package can satisfy an AST interface.
package ast

import (
	"fmt"

	"github.com/grafana/agent/pkg/river/token"
)

// Node represents any node in the AST.
type Node interface {
	astNode()
}

// Stmt is a type of statement wthin the body of a file or block.
type Stmt interface {
	Node
	astStmt()
}

// Expr is an expression within the AST.
type Expr interface {
	Node
	astExpr()
}

// File is a parsed file.
type File struct {
	Name     string         // Filename provided to parser
	Body     Body           // Content of File
	Comments []CommentGroup // List of all comments in the File
}

// Body is a list of statements.
type Body []Stmt

// A CommentGroup represents a sequence of comments that are not separated by
// any empty lines or other non-comment tokens.
type CommentGroup []*Comment

// A Comment represents a single line or block comment.
//
// The Text field contains the comment text without any carriage returns (\r)
// that may have been present in the source. Since carriage returns get
// removed, EndPos will not be accurate for any comment which contained
// carriage returns.
type Comment struct {
	StartPos token.Pos // Starting position of comment
	// Text of the comment. Text will not contain '\n' for line comments.
	Text string
}

// AttributeStmt is a key-value pair being set in a Body or BlockStmt.
type AttributeStmt struct {
	Name  *Ident
	Value Expr
}

// BlockStmt declares a block.
type BlockStmt struct {
	Name    []string
	NamePos token.Pos
	Label   string
	Body    Body

	LCurlyPos, RCurlyPos token.Pos
}

// Ident holds an identifier with its position.
type Ident struct {
	Name    string
	NamePos token.Pos
}

// IdentifierExpr refers to a named value.
type IdentifierExpr struct {
	Ident *Ident
}

// LiteralExpr is a constant value of a specific token kind.
type LiteralExpr struct {
	Kind     token.Token
	ValuePos token.Pos

	// Value holds the unparsed literal value. For example, if Kind ==
	// token.STRING, then Value would be wrapped in the original quotes (e.g.,
	// `"foobar"`).
	Value string
}

// ArrayExpr is an array of values.
type ArrayExpr struct {
	Elements             []Expr
	LBrackPos, RBrackPos token.Pos
}

// ObjectExpr declares an object of key-value pairs.
type ObjectExpr struct {
	Fields               []*ObjectField
	LCurlyPos, RCurlyPos token.Pos
}

// ObjectField defines an individual key-value pair within an object.
// ObjectField does not implement Node.
type ObjectField struct {
	Name   *Ident
	Quoted bool // True if the name was wrapped in quotes
	Value  Expr
}

// AccessExpr accesses a field in an object value by name.
type AccessExpr struct {
	Value Expr
	Name  *Ident
}

// IndexExpr accesses an index in an array value.
type IndexExpr struct {
	Value, Index         Expr
	LBrackPos, RBrackPos token.Pos
}

// CallExpr invokes a function value with a set of arguments.
type CallExpr struct {
	Value Expr
	Args  []Expr

	LParenPos, RParenPos token.Pos
}

// UnaryExpr performs a unary operation on a single value.
type UnaryExpr struct {
	Kind    token.Token
	KindPos token.Pos
	Value   Expr
}

// BinaryExpr performs a binary operation against two values.
type BinaryExpr struct {
	Kind        token.Token
	KindPos     token.Pos
	Left, Right Expr
}

// ParenExpr represents an expression wrapped in parenthesis.
type ParenExpr struct {
	Inner                Expr
	LParenPos, RParenPos token.Pos
}

// Type assertions

var (
	_ Node = (*File)(nil)
	_ Node = (*Body)(nil)
	_ Node = (*AttributeStmt)(nil)
	_ Node = (*BlockStmt)(nil)
	_ Node = (*Ident)(nil)
	_ Node = (*IdentifierExpr)(nil)
	_ Node = (*LiteralExpr)(nil)
	_ Node = (*ArrayExpr)(nil)
	_ Node = (*ObjectExpr)(nil)
	_ Node = (*AccessExpr)(nil)
	_ Node = (*IndexExpr)(nil)
	_ Node = (*CallExpr)(nil)
	_ Node = (*UnaryExpr)(nil)
	_ Node = (*BinaryExpr)(nil)
	_ Node = (*ParenExpr)(nil)

	_ Stmt = (*AttributeStmt)(nil)
	_ Stmt = (*BlockStmt)(nil)

	_ Expr = (*IdentifierExpr)(nil)
	_ Expr = (*LiteralExpr)(nil)
	_ Expr = (*ArrayExpr)(nil)
	_ Expr = (*ObjectExpr)(nil)
	_ Expr = (*AccessExpr)(nil)
	_ Expr = (*IndexExpr)(nil)
	_ Expr = (*CallExpr)(nil)
	_ Expr = (*UnaryExpr)(nil)
	_ Expr = (*BinaryExpr)(nil)
	_ Expr = (*ParenExpr)(nil)
)

func (n *File) astNode()           {}
func (n Body) astNode()            {}
func (n CommentGroup) astNode()    {}
func (n *Comment) astNode()        {}
func (n *AttributeStmt) astNode()  {}
func (n *BlockStmt) astNode()      {}
func (n *Ident) astNode()          {}
func (n *IdentifierExpr) astNode() {}
func (n *LiteralExpr) astNode()    {}
func (n *ArrayExpr) astNode()      {}
func (n *ObjectExpr) astNode()     {}
func (n *AccessExpr) astNode()     {}
func (n *IndexExpr) astNode()      {}
func (n *CallExpr) astNode()       {}
func (n *UnaryExpr) astNode()      {}
func (n *BinaryExpr) astNode()     {}
func (n *ParenExpr) astNode()      {}

func (n *AttributeStmt) astStmt() {}
func (n *BlockStmt) astStmt()     {}

func (n *IdentifierExpr) astExpr() {}
func (n *LiteralExpr) astExpr()    {}
func (n *ArrayExpr) astExpr()      {}
func (n *ObjectExpr) astExpr()     {}
func (n *AccessExpr) astExpr()     {}
func (n *IndexExpr) astExpr()      {}
func (n *CallExpr) astExpr()       {}
func (n *UnaryExpr) astExpr()      {}
func (n *BinaryExpr) astExpr()     {}
func (n *ParenExpr) astExpr()      {}

// StartPos returns the position of the first character belonging to a Node.
func StartPos(n Node) token.Pos {
	if n == nil {
		return token.NoPos
	}
	switch n := n.(type) {
	case *File:
		return StartPos(n.Body)
	case Body:
		if len(n) == 0 {
			return token.NoPos
		}
		return StartPos(n[0])
	case CommentGroup:
		if len(n) == 0 {
			return token.NoPos
		}
		return StartPos(n[0])
	case *Comment:
		return n.StartPos
	case *AttributeStmt:
		return StartPos(n.Name)
	case *BlockStmt:
		return n.NamePos
	case *Ident:
		return n.NamePos
	case *IdentifierExpr:
		return StartPos(n.Ident)
	case *LiteralExpr:
		return n.ValuePos
	case *ArrayExpr:
		return n.LBrackPos
	case *ObjectExpr:
		return n.LCurlyPos
	case *AccessExpr:
		return StartPos(n.Value)
	case *IndexExpr:
		return StartPos(n.Value)
	case *CallExpr:
		return StartPos(n.Value)
	case *UnaryExpr:
		return n.KindPos
	case *BinaryExpr:
		return StartPos(n.Left)
	case *ParenExpr:
		return n.LParenPos
	default:
		panic(fmt.Sprintf("Unhandled Node type %T", n))
	}
}

// EndPos returns the position of the final character in a Node.
func EndPos(n Node) token.Pos {
	if n == nil {
		return token.NoPos
	}
	switch n := n.(type) {
	case *File:
		return EndPos(n.Body)
	case Body:
		if len(n) == 0 {
			return token.NoPos
		}
		return EndPos(n[len(n)-1])
	case CommentGroup:
		if len(n) == 0 {
			return token.NoPos
		}
		return EndPos(n[len(n)-1])
	case *Comment:
		return n.StartPos.Add(len(n.Text) - 1)
	case *AttributeStmt:
		return EndPos(n.Value)
	case *BlockStmt:
		return n.RCurlyPos
	case *Ident:
		return n.NamePos.Add(len(n.Name) - 1)
	case *IdentifierExpr:
		return EndPos(n.Ident)
	case *LiteralExpr:
		return n.ValuePos.Add(len(n.Value) - 1)
	case *ArrayExpr:
		return n.RBrackPos
	case *ObjectExpr:
		return n.RCurlyPos
	case *AccessExpr:
		return EndPos(n.Name)
	case *IndexExpr:
		return n.RBrackPos
	case *CallExpr:
		return n.RParenPos
	case *UnaryExpr:
		return EndPos(n.Value)
	case *BinaryExpr:
		return EndPos(n.Right)
	case *ParenExpr:
		return n.RParenPos
	default:
		panic(fmt.Sprintf("Unhandled Node type %T", n))
	}
}

'''
'''--- pkg/river/ast/walk.go ---
package ast

import "fmt"

// A Visitor has its Visit method invoked for each node encountered by Walk. If
// the resulting visitor w is not nil, Walk visits each of the children of node
// with the visitor w, followed by a call of w.Visit(nil).
type Visitor interface {
	Visit(node Node) (w Visitor)
}

// Walk traverses an AST in depth-first order: it starts by calling
// v.Visit(node); node must not be nil. If the visitor w returned by
// v.Visit(node) is not nil, Walk is invoked recursively with visitor w for
// each of the non-nil children of node, followed by a call of w.Visit(nil).
func Walk(v Visitor, node Node) {
	if v = v.Visit(node); v == nil {
		return
	}

	// Walk children. The order of the cases matches the declared order of nodes
	// in ast.go.
	switch n := node.(type) {
	case *File:
		Walk(v, n.Body)
	case Body:
		for _, s := range n {
			Walk(v, s)
		}
	case *AttributeStmt:
		Walk(v, n.Name)
		Walk(v, n.Value)
	case *BlockStmt:
		Walk(v, n.Body)
	case *Ident:
		// Nothing to do
	case *IdentifierExpr:
		Walk(v, n.Ident)
	case *LiteralExpr:
		// Nothing to do
	case *ArrayExpr:
		for _, e := range n.Elements {
			Walk(v, e)
		}
	case *ObjectExpr:
		for _, f := range n.Fields {
			Walk(v, f.Name)
			Walk(v, f.Value)
		}
	case *AccessExpr:
		Walk(v, n.Value)
		Walk(v, n.Name)
	case *IndexExpr:
		Walk(v, n.Value)
		Walk(v, n.Index)
	case *CallExpr:
		Walk(v, n.Value)
		for _, a := range n.Args {
			Walk(v, a)
		}
	case *UnaryExpr:
		Walk(v, n.Value)
	case *BinaryExpr:
		Walk(v, n.Left)
		Walk(v, n.Right)
	case *ParenExpr:
		Walk(v, n.Inner)
	default:
		panic(fmt.Sprintf("river/ast: unexpected node type %T", n))
	}

	v.Visit(nil)
}

'''
'''--- pkg/river/diag/diag.go ---
// Package diag exposes error types used throughout River and a method to
// pretty-print them to the screen.
package diag

import (
	"fmt"

	"github.com/grafana/agent/pkg/river/token"
)

// Severity denotes the severity level of a diagnostic. The zero value of
// severity is invalid.
type Severity int

// Supported severity levels.
const (
	SeverityLevelWarn Severity = iota + 1
	SeverityLevelError
)

// Diagnostic is an individual diagnostic message. Diagnostic messages can have
// different levels of severities.
type Diagnostic struct {
	// Severity holds the severity level of this Diagnostic.
	Severity Severity

	// StartPos refers to a position in a file where this Diagnostic starts.
	StartPos token.Position

	// EndPos refers to an optional position in a file where this Diagnostic
	// ends. If EndPos is the zero value, the Diagnostic should be treated as
	// only covering a single character (i.e., StartPos == EndPos).
	//
	// When defined, EndPos must have the same Filename value as the StartPos.
	EndPos token.Position

	Message string
	Value   string
}

// As allows d to be interpreted as a list of Diagnostics.
func (d Diagnostic) As(v interface{}) bool {
	switch v := v.(type) {
	case *Diagnostics:
		*v = Diagnostics{d}
		return true
	}

	return false
}

// Error implements error.
func (d Diagnostic) Error() string {
	return fmt.Sprintf("%s: %s", d.StartPos, d.Message)
}

// Diagnostics is a collection of diagnostic messages.
type Diagnostics []Diagnostic

// Add adds an individual Diagnostic to the diagnostics list.
func (ds *Diagnostics) Add(d Diagnostic) {
	*ds = append(*ds, d)
}

// Error implements error.
func (ds Diagnostics) Error() string {
	switch len(ds) {
	case 0:
		return "no errors"
	case 1:
		return ds[0].Error()
	default:
		return fmt.Sprintf("%s (and %d more diagnostics)", ds[0], len(ds)-1)
	}
}

// ErrorOrNil returns an error interface if the list diagnostics is non-empty,
// nil otherwise.
func (ds Diagnostics) ErrorOrNil() error {
	if len(ds) == 0 {
		return nil
	}
	return ds
}

// HasErrors reports whether the list of Diagnostics contain any error-level
// diagnostic.
func (ds Diagnostics) HasErrors() bool {
	for _, d := range ds {
		if d.Severity == SeverityLevelError {
			return true
		}
	}
	return false
}

'''
'''--- pkg/river/diag/printer.go ---
package diag

import (
	"bufio"
	"fmt"
	"io"
	"strconv"
	"strings"

	"github.com/fatih/color"
	"github.com/grafana/agent/pkg/river/token"
)

const tabWidth = 4

// PrinterConfig controls different settings for the Printer.
type PrinterConfig struct {
	// When Color is true, the printer will output with color and special
	// formatting characters (such as underlines).
	//
	// This should be disabled when not printing to a terminal.
	Color bool

	// ContextLinesBefore and ContextLinesAfter controls how many context lines
	// before and after the range of the diagnostic are printed.
	ContextLinesBefore, ContextLinesAfter int
}

// A Printer pretty-prints Diagnostics.
type Printer struct {
	cfg PrinterConfig
}

// NewPrinter creates a new diagnostics Printer with the provided config.
func NewPrinter(cfg PrinterConfig) *Printer {
	return &Printer{cfg: cfg}
}

// Fprint creates a Printer with default settings and prints diagnostics to the
// provided writer. files is used to look up file contents by name for printing
// diagnostics context. files may be set to nil to avoid printing context.
func Fprint(w io.Writer, files map[string][]byte, diags Diagnostics) error {
	p := NewPrinter(PrinterConfig{
		Color:              false,
		ContextLinesBefore: 1,
		ContextLinesAfter:  1,
	})
	return p.Fprint(w, files, diags)
}

// Fprint pretty-prints errors to a writer. files is used to look up file
// contents by name when printing context. files may be nil to avoid printing
// context.
func (p *Printer) Fprint(w io.Writer, files map[string][]byte, diags Diagnostics) error {
	// Create a buffered writer since we'll have many small calls to Write while
	// we print errors.
	//
	// Buffers writers track the first write error received and will return it
	// (if any) when flushing, so we can ignore write errors throughout the code
	// until the very end.
	bw := bufio.NewWriter(w)

	for i, diag := range diags {
		p.printDiagnosticHeader(bw, diag)

		// If there's no ending position, set the ending position to be the same as
		// the start.
		if !diag.EndPos.Valid() {
			diag.EndPos = diag.StartPos
		}

		// We can print the file context if it was found.
		fileContents, foundFile := files[diag.StartPos.Filename]
		if foundFile && diag.StartPos.Filename == diag.EndPos.Filename {
			p.printRange(bw, fileContents, diag)
		}

		// Print a blank line to separate diagnostics.
		if i+1 < len(diags) {
			fmt.Fprintf(bw, "\n")
		}
	}

	return bw.Flush()
}

func (p *Printer) printDiagnosticHeader(w io.Writer, diag Diagnostic) {
	if p.cfg.Color {
		switch diag.Severity {
		case SeverityLevelError:
			cw := color.New(color.FgRed, color.Bold)
			_, _ = cw.Fprintf(w, "Error: ")
		case SeverityLevelWarn:
			cw := color.New(color.FgYellow, color.Bold)
			_, _ = cw.Fprintf(w, "Warning: ")
		}

		cw := color.New(color.Bold)
		_, _ = cw.Fprintf(w, "%s: %s\n", diag.StartPos, diag.Message)
		return
	}

	switch diag.Severity {
	case SeverityLevelError:
		_, _ = fmt.Fprintf(w, "Error: ")
	case SeverityLevelWarn:
		_, _ = fmt.Fprintf(w, "Warning: ")
	}
	fmt.Fprintf(w, "%s: %s\n", diag.StartPos, diag.Message)
}

func (p *Printer) printRange(w io.Writer, file []byte, diag Diagnostic) {
	var (
		start = diag.StartPos
		end   = diag.EndPos
	)

	fmt.Fprintf(w, "\n")

	var (
		lines = strings.Split(string(file), "\n")

		startLine = max(start.Line-p.cfg.ContextLinesBefore, 1)
		endLine   = min(end.Line+p.cfg.ContextLinesAfter, len(lines))

		multiline = end.Line-start.Line > 0
	)

	prefixWidth := len(strconv.Itoa(endLine))

	for lineNum := startLine; lineNum <= endLine; lineNum++ {
		line := lines[lineNum-1]

		// Print line number and margin.
		printPaddedNumber(w, prefixWidth, lineNum)
		fmt.Fprintf(w, " | ")

		if multiline {
			if inRange(lineNum, 1, start, end) {
				fmt.Fprint(w, "| ")
			} else {
				fmt.Fprint(w, "  ")
			}
		}

		// Print the line, but filter out any \r and replace tabs with spaces.
		for _, ch := range line {
			if ch == '\r' {
				continue
			}
			if ch == '\t' || ch == '\v' {
				printCh(w, tabWidth, ' ')
				continue
			}
			fmt.Fprintf(w, "%c", ch)
		}

		fmt.Fprintf(w, "\n")

		// Print the focus indicator if we're on a line that needs it.
		//
		// The focus indicator line must preserve whitespace present in the line
		// above it prior to the focus '^' characters. Tab characters are replaced
		// with spaces for consistent printing.
		if lineNum == start.Line || (multiline && lineNum == end.Line) {
			printCh(w, prefixWidth, ' ') // Add empty space where line number would be

			// Print the margin after the blank line number. On multi-line errors,
			// the arrow is printed all the way to the margin, with with straight
			// lines going down in between the lines.
			switch {
			case multiline && lineNum == start.Line:
				// |_ would look like an incorrect right angle, so the second bar
				// is dropped.
				fmt.Fprintf(w, " |  _")
			case multiline && lineNum == end.Line:
				fmt.Fprintf(w, " | |_")
			default:
				fmt.Fprintf(w, " | ")
			}

			p.printFocus(w, line, lineNum, diag)
			fmt.Fprintf(w, "\n")
		}
	}
}

// printFocus prints the focus indicator for the line number specified by line.
// The contents of the line should be represented by data so whitespace can be
// retained (injecting spaces where a tab should be, etc).
func (p *Printer) printFocus(w io.Writer, data string, line int, diag Diagnostic) {
	for i, ch := range data {
		column := i + 1

		if line == diag.EndPos.Line && column > diag.EndPos.Column {
			// Stop printing the formatting line after printing all the ^.
			break
		}

		blank := byte(' ')
		if diag.EndPos.Line-diag.StartPos.Line > 0 {
			blank = byte('_')
		}

		switch {
		case ch == '\t' || ch == '\v':
			printCh(w, tabWidth, blank)
		case inRange(line, column, diag.StartPos, diag.EndPos):
			fmt.Fprintf(w, "%c", '^')
		default:
			// Print a space.
			fmt.Fprintf(w, "%c", blank)
		}
	}
}

func inRange(line, col int, start, end token.Position) bool {
	if line < start.Line || line > end.Line {
		return false
	}

	switch line {
	case start.Line:
		// If the current line is on the starting line, we have to be past the
		// starting column.
		return col >= start.Column
	case end.Line:
		// If the current line is on the ending line, we have to be before the
		// final column.
		return col <= end.Column
	default:
		// Otherwise, every column across all the lines in between
		// is in the range.
		return true
	}
}

func printPaddedNumber(w io.Writer, width int, num int) {
	numStr := strconv.Itoa(num)
	for i := 0; i < width-len(numStr); i++ {
		_, _ = w.Write([]byte{' '})
	}
	_, _ = w.Write([]byte(numStr))
}

func printCh(w io.Writer, count int, ch byte) {
	for i := 0; i < count; i++ {
		_, _ = w.Write([]byte{ch})
	}
}

func min(a, b int) int {
	if a < b {
		return a
	}
	return b
}

func max(a, b int) int {
	if a > b {
		return a
	}
	return b
}

'''
'''--- pkg/river/diag/printer_test.go ---
package diag_test

import (
	"bytes"
	"fmt"
	"testing"

	"github.com/grafana/agent/pkg/river/diag"
	"github.com/grafana/agent/pkg/river/token"
	"github.com/stretchr/testify/require"
)

func TestFprint(t *testing.T) {
	// In all tests below, the filename is "testfile" and the severity is an
	// error.

	tt := []struct {
		name       string
		input      string
		start, end token.Position
		diag       diag.Diagnostic
		expect     string
	}{
		{
			name:  "highlight on same line",
			start: token.Position{Line: 2, Column: 2},
			end:   token.Position{Line: 2, Column: 5},
			input: `test.block "label" {
	attr       = 1
	other_attr = 2
}`,
			expect: `Error: testfile:2:2: synthetic error

1 | test.block "label" {
2 |     attr       = 1
  |     ^^^^
3 |     other_attr = 2
`,
		},

		{
			name:  "end positions should be optional",
			start: token.Position{Line: 1, Column: 4},
			input: `foo,bar`,
			expect: `Error: testfile:1:4: synthetic error

1 | foo,bar
  |    ^
`,
		},

		{
			name:  "padding should be inserted to fit line numbers of different lengths",
			start: token.Position{Line: 9, Column: 1},
			end:   token.Position{Line: 9, Column: 6},
			input: `LINE_1
LINE_2
LINE_3
LINE_4
LINE_5
LINE_6
LINE_7
LINE_8
LINE_9
LINE_10
LINE_11`,
			expect: `Error: testfile:9:1: synthetic error

 8 | LINE_8
 9 | LINE_9
   | ^^^^^^
10 | LINE_10
`,
		},

		{
			name:  "errors which cross multiple lines can be printed",
			start: token.Position{Line: 2, Column: 8},
			end:   token.Position{Line: 6, Column: 7},
			input: `FILE_BEGIN
before START
TEXT
	TEXT
		TEXT
			DONE after
FILE_END`,
			expect: `Error: testfile:2:8: synthetic error

1 |   FILE_BEGIN
2 |   before START
  |  ________^^^^^
3 | | TEXT
4 | |     TEXT
5 | |         TEXT
6 | |             DONE after
  | |_____________^^^^
7 |   FILE_END
`,
		},
	}

	for _, tc := range tt {
		files := map[string][]byte{
			"testfile": []byte(tc.input),
		}

		tc.start.Filename = "testfile"
		tc.end.Filename = "testfile"

		diags := diag.Diagnostics{{
			Severity: diag.SeverityLevelError,
			StartPos: tc.start,
			EndPos:   tc.end,
			Message:  "synthetic error",
		}}

		var buf bytes.Buffer
		_ = diag.Fprint(&buf, files, diags)
		requireEqualStrings(t, tc.expect, buf.String())
	}
}

func TestFprint_MultipleDiagnostics(t *testing.T) {
	fileA := `old_field = 15
3 & 4`
	fileB := `old_field = 22`

	files := map[string][]byte{
		"file_a": []byte(fileA),
		"file_b": []byte(fileB),
	}

	diags := diag.Diagnostics{
		{
			Severity: diag.SeverityLevelWarn,
			StartPos: token.Position{Filename: "file_a", Line: 1, Column: 1},
			EndPos:   token.Position{Filename: "file_a", Line: 1, Column: 9},
			Message:  "old_field is deprecated",
		},
		{
			Severity: diag.SeverityLevelError,
			StartPos: token.Position{Filename: "file_a", Line: 2, Column: 3},
			Message:  "unrecognized operator &",
		},
		{
			Severity: diag.SeverityLevelWarn,
			StartPos: token.Position{Filename: "file_b", Line: 1, Column: 1},
			EndPos:   token.Position{Filename: "file_b", Line: 1, Column: 9},
			Message:  "old_field is deprecated",
		},
	}

	expect := `Warning: file_a:1:1: old_field is deprecated

1 | old_field = 15
  | ^^^^^^^^^
2 | 3 & 4

Error: file_a:2:3: unrecognized operator &

1 | old_field = 15
2 | 3 & 4
  |   ^

Warning: file_b:1:1: old_field is deprecated

1 | old_field = 22
  | ^^^^^^^^^
`

	var buf bytes.Buffer
	_ = diag.Fprint(&buf, files, diags)
	requireEqualStrings(t, expect, buf.String())
}

// requireEqualStrings is like require.Equal with two strings but it
// pretty-prints multiline strings to make it easier to compare.
func requireEqualStrings(t *testing.T, expected, actual string) {
	if expected == actual {
		return
	}

	msg := fmt.Sprintf(
		"Not equal:\n"+
			"raw expected: %#v\n"+
			"raw actual  : %#v\n"+
			"\n"+
			"expected:\n%s\n"+
			"actual:\n%s\n",
		expected, actual,
		expected, actual,
	)

	require.Fail(t, msg)
}

'''
'''--- pkg/river/internal/rivertags/rivertags.go ---
// Package rivertags decodes a struct type into river object
// and structural tags.
package rivertags

import (
	"fmt"
	"reflect"
	"strings"
)

// Flags is a bitmap of flags associated with a field on a struct.
type Flags uint

// Valid flags.
const (
	FlagAttr  Flags = 1 << iota // FlagAttr treats a field as attribute
	FlagBlock                   // FlagBlock treats a field as a block

	FlagOptional // FlagOptional marks a field optional for decoding/encoding
	FlagLabel    // FlagLabel will store block labels in the field
)

// String returns the flags as a string.
func (f Flags) String() string {
	attrs := make([]string, 0, 5)

	if f&FlagAttr != 0 {
		attrs = append(attrs, "attr")
	}
	if f&FlagBlock != 0 {
		attrs = append(attrs, "block")
	}
	if f&FlagOptional != 0 {
		attrs = append(attrs, "optional")
	}
	if f&FlagLabel != 0 {
		attrs = append(attrs, "label")
	}

	return fmt.Sprintf("Flags(%s)", strings.Join(attrs, ","))
}

// GoString returns the %#v format of Flags.
func (f Flags) GoString() string { return f.String() }

// Field is a tagged field within a struct.
type Field struct {
	Name  []string // Name of tagged field
	Index []int    // Index into field (reflect.Value.FieldByIndex)
	Flags Flags    // Flags assigned to field
}

// IsAttr returns whether f is for an attribute.
func (f Field) IsAttr() bool { return f.Flags&FlagAttr != 0 }

// IsBlock returns whether f is for a block.
func (f Field) IsBlock() bool { return f.Flags&FlagBlock != 0 }

// IsOptional returns whether f is optional.
func (f Field) IsOptional() bool { return f.Flags&FlagOptional != 0 }

// Get returns the list of tagged fields for some struct type ty. Get panics if
// ty is not a struct type.
//
// Get examines each tagged field in ty for a river key. The river key is then
// parsed as containing a name for the field, followed by a required
// comma-separated list of options. The name may be empty for fields which do
// not require a name. Get will ignore any field that is not tagged with a
// river key.
//
// Get will treat anonymous struct fields as if the inner fields were fields in
// the outer struct.
//
// Examples of struct field tags and their meanings:
//
//     // Field is used as a required block named "my_block".
//     Field struct{} `river:"my_block,block"`
//
//     // Field is used as an optional block named "my_block".
//     Field struct{} `river:"my_block,block,optional"`
//
//     // Field is used as a required attribute named "my_attr".
//     Field string `river:"my_attr,attr"`
//
//     // Field is used as an optional attribute named "my_attr".
//     Field string `river:"my_attr,attr,optional"`
//
//     // Field is used for storing the label of the block which the struct
//     // represents.
//     Field string `river:",label"`
//
// With the exception of the `river:",label"` tag, all tagged fields must have a
// unique name.
//
// The type of tagged fields may be any Go type, with the exception of
// `river:",label"` tags, which must be strings.
func Get(ty reflect.Type) []Field {
	if k := ty.Kind(); k != reflect.Struct {
		panic(fmt.Sprintf("rivertags: Get requires struct kind, got %s", k))
	}

	var (
		fields []Field

		usedNames      = make(map[string][]int)
		usedLabelField = []int(nil)
	)

	for _, field := range reflect.VisibleFields(ty) {
		// River does not support embedding of fields
		if field.Anonymous {
			panic(fmt.Sprintf("river: anonymous fields not supported %s", printPathToField(ty, field.Index)))
		}

		tag, tagged := field.Tag.Lookup("river")
		if !tagged {
			continue
		}

		if !field.IsExported() {
			panic(fmt.Sprintf("river: river tag found on unexported field at %s", printPathToField(ty, field.Index)))
		}

		options := strings.SplitN(tag, ",", 2)
		if len(options) == 0 {
			panic(fmt.Sprintf("river: unsupported empty tag at %s", printPathToField(ty, field.Index)))
		}
		if len(options) != 2 {
			panic(fmt.Sprintf("river: field %s tag is missing options", printPathToField(ty, field.Index)))
		}

		fullName := options[0]

		tf := Field{
			Name:  strings.Split(fullName, "."),
			Index: field.Index,
		}

		if first, used := usedNames[fullName]; used && fullName != "" {
			panic(fmt.Sprintf("river: field name %s already used by %s", fullName, printPathToField(ty, first)))
		}
		usedNames[fullName] = tf.Index

		switch options[1] {
		case "attr":
			tf.Flags |= FlagAttr
		case "attr,optional":
			tf.Flags |= FlagAttr | FlagOptional
		case "block":
			tf.Flags |= FlagBlock
		case "block,optional":
			tf.Flags |= FlagBlock | FlagOptional
		case "label":
			tf.Flags |= FlagLabel
		default:
			panic(fmt.Sprintf("river: unrecognized river tag format %q at %s", tag, printPathToField(ty, tf.Index)))
		}

		if len(tf.Name) > 1 && tf.Flags&FlagBlock == 0 {
			panic(fmt.Sprintf("river: field names with `.` may only be used by blocks (found at %s)", printPathToField(ty, tf.Index)))
		}

		if tf.Flags&FlagLabel != 0 {
			if fullName != "" {
				panic(fmt.Sprintf("river: label field at %s must not have a name", printPathToField(ty, tf.Index)))
			}
			if field.Type.Kind() != reflect.String {
				panic(fmt.Sprintf("river: label field at %s must be a string", printPathToField(ty, tf.Index)))
			}

			if usedLabelField != nil {
				panic(fmt.Sprintf("river: label field already used by %s", printPathToField(ty, tf.Index)))
			}
			usedLabelField = tf.Index
		}

		if fullName == "" && tf.Flags&FlagLabel == 0 /* (e.g., *not* a label) */ {
			panic(fmt.Sprintf("river: non-empty field name required at %s", printPathToField(ty, tf.Index)))
		}

		fields = append(fields, tf)
	}

	return fields
}

func printPathToField(structTy reflect.Type, path []int) string {
	var sb strings.Builder

	sb.WriteString(structTy.String())
	sb.WriteString(".")

	cur := structTy
	for i, elem := range path {
		sb.WriteString(cur.Field(elem).Name)

		if i+1 < len(path) {
			sb.WriteString(".")
		}

		cur = cur.Field(i).Type
	}

	return sb.String()
}

'''
'''--- pkg/river/internal/rivertags/rivertags_test.go ---
package rivertags_test

import (
	"reflect"
	"testing"

	"github.com/grafana/agent/pkg/river/internal/rivertags"
	"github.com/stretchr/testify/require"
)

func Test_Get(t *testing.T) {
	type Struct struct {
		IgnoreMe bool

		ReqAttr  string   `river:"req_attr,attr"`
		OptAttr  string   `river:"opt_attr,attr,optional"`
		ReqBlock struct{} `river:"req_block,block"`
		OptBlock struct{} `river:"opt_block,block,optional"`
		Label    string   `river:",label"`
	}

	fs := rivertags.Get(reflect.TypeOf(Struct{}))

	expect := []rivertags.Field{
		{[]string{"req_attr"}, []int{1}, rivertags.FlagAttr},
		{[]string{"opt_attr"}, []int{2}, rivertags.FlagAttr | rivertags.FlagOptional},
		{[]string{"req_block"}, []int{3}, rivertags.FlagBlock},
		{[]string{"opt_block"}, []int{4}, rivertags.FlagBlock | rivertags.FlagOptional},
		{[]string{""}, []int{5}, rivertags.FlagLabel},
	}

	require.Equal(t, expect, fs)
}

func TestEmbedded(t *testing.T) {
	type InnerStruct struct {
		InnerField1 string `river:"inner_field_1,attr"`
		InnerField2 string `river:"inner_field_2,attr"`
	}

	type Struct struct {
		Field1 string `river:"parent_field_1,attr"`
		InnerStruct
		Field2 string `river:"parent_field_2,attr"`
	}
	require.PanicsWithValue(t, "river: anonymous fields not supported rivertags_test.Struct.InnerStruct", func() { rivertags.Get(reflect.TypeOf(Struct{})) })
}

func Test_Get_Panics(t *testing.T) {
	expectPanic := func(t *testing.T, expect string, v interface{}) {
		t.Helper()
		require.PanicsWithValue(t, expect, func() {
			_ = rivertags.Get(reflect.TypeOf(v))
		})
	}

	t.Run("Tagged fields must be exported", func(t *testing.T) {
		type Struct struct {
			attr string `river:"field,attr"` // nolint:unused
		}
		expect := `river: river tag found on unexported field at rivertags_test.Struct.attr`
		expectPanic(t, expect, Struct{})
	})

	t.Run("Options are required", func(t *testing.T) {
		type Struct struct {
			Attr string `river:"field"`
		}
		expect := `river: field rivertags_test.Struct.Attr tag is missing options`
		expectPanic(t, expect, Struct{})
	})

	t.Run("Field names must be unique", func(t *testing.T) {
		type Struct struct {
			Attr  string `river:"field1,attr"`
			Block string `river:"field1,block,optional"`
		}
		expect := `river: field name field1 already used by rivertags_test.Struct.Attr`
		expectPanic(t, expect, Struct{})
	})

	t.Run("Name is required for non-label field", func(t *testing.T) {
		type Struct struct {
			Attr string `river:",attr"`
		}
		expect := `river: non-empty field name required at rivertags_test.Struct.Attr`
		expectPanic(t, expect, Struct{})
	})

	t.Run("Only one label field may exist", func(t *testing.T) {
		type Struct struct {
			Label1 string `river:",label"`
			Label2 string `river:",label"`
		}
		expect := `river: label field already used by rivertags_test.Struct.Label2`
		expectPanic(t, expect, Struct{})
	})
}

'''
'''--- pkg/river/internal/stdlib/stdlib.go ---
// Package stdlib contains standard library functions exposed to River configs.
package stdlib

import (
	"encoding/json"
	"os"
	"reflect"

	"github.com/grafana/agent/pkg/river/internal/value"
)

var goAny = reflect.TypeOf((*interface{})(nil)).Elem()

// Functions returns the list of stdlib functions by name. The interface{}
// value is always a River-compatible function value, where functions have at
// least one non-error return value, with an optionally supported error return
// value as the second return value.
var Functions = map[string]interface{}{
	"env": os.Getenv,

	// concat is implemented as a raw function so it can bypass allocations
	// converting arguments into []interface{}. concat is optimized to allow it
	// to perform well when it is in the hot path for combining targets from many
	// other blocks.
	"concat": value.RawFunction(func(funcValue value.Value, args ...value.Value) (value.Value, error) {
		if len(args) == 0 {
			return value.Array(), nil
		}

		// finalSize is the final size of the resulting concatenated array. We type
		// check our arguments while computing what finalSize will be.
		var finalSize int
		for i, arg := range args {
			if arg.Type() != value.TypeArray {
				return value.Null, value.ArgError{
					Function: funcValue,
					Argument: arg,
					Index:    i,
					Inner: value.TypeError{
						Value:    arg,
						Expected: value.TypeArray,
					},
				}
			}

			finalSize += arg.Len()
		}

		// Optimization: if there's only one array, we can just return it directly.
		// This is done *after* the previous loop to ensure that args[0] is a River
		// array.
		if len(args) == 1 {
			return args[0], nil
		}

		// If the imcoming Go slices have the same type, we can have our resulting
		// slice use the same type. This will allow decoding to use the direct
		// assignment optimization.
		//
		// However, if the types don't match, then we're forced to fall back to
		// returning []interface{}.
		//
		// TODO(rfratto): This could fall back to checking the elements if the
		// array/slice types don't match. It would be slower, but the direct
		// assignment optimization probably justifies it.
		useType := args[0].Reflect().Type()
		for i := 1; i < len(args); i++ {
			if args[i].Reflect().Type() != useType {
				useType = reflect.SliceOf(goAny)
				break
			}
		}

		// Build out the final array.
		raw := reflect.MakeSlice(useType, finalSize, finalSize)

		var argNum int
		for _, arg := range args {
			for i := 0; i < arg.Len(); i++ {
				elem := arg.Index(i)
				if elem.Type() != value.TypeNull {
					raw.Index(argNum).Set(elem.Reflect())
				}
				argNum++
			}
		}

		return value.Encode(raw.Interface()), nil
	}),

	"unmarshal_json": func(in string) (interface{}, error) {
		var res interface{}
		err := json.Unmarshal([]byte(in), &res)
		if err != nil {
			return nil, err
		}
		return res, nil
	},
}

'''
'''--- pkg/river/internal/value/capsule.go ---
package value

import (
	"fmt"
)

// Capsule is a marker interface for Go values which forces a type to be
// represented as a River capsule. This is useful for types whose underlying
// value is not a capsule, such as:
//
//   // Secret is a secret value. It would normally be a River string since the
//   // underlying Go type is string, but it's a capsule since it implements
//   // the Capsule interface.
//   type Secret string
//
//   func (s Secret) RiverCapsule() {}
//
// Extension interfaces are used to describe additional behaviors for Capsules.
// ConvertibleCapsule allows defining custom conversion rules to convert
// between other Go values.
type Capsule interface {
	RiverCapsule()
}

// ErrNoConversion is returned by implementations of ConvertibleCapsule to
// denote that a custom conversion from or to a specific type is unavailable.
var ErrNoConversion = fmt.Errorf("no custom capsule conversion available")

// ConvertibleFromCapsule is a Capsule which supports custom conversion rules
// from any Go type which is not the same as the capsule type.
type ConvertibleFromCapsule interface {
	Capsule

	// ConvertFrom should modify the ConvertibleCapsule value based on the value
	// of src.
	//
	// ConvertFrom should return ErrNoConversion if no conversion is available
	// from src.
	ConvertFrom(src interface{}) error
}

// ConvertibleIntoCapsule is a Capsule which supports custom conversion rules
// into any Go type which is not the same as the capsule type.
type ConvertibleIntoCapsule interface {
	Capsule

	// ConvertInto should convert its value and store it into dst. dst will be a
	// pointer to a value which ConvertInto is expected to update.
	//
	// ConvertInto should return ErrNoConversion if no conversion into dst is
	// available.
	ConvertInto(dst interface{}) error
}

'''
'''--- pkg/river/internal/value/decode.go ---
package value

import (
	"encoding"
	"errors"
	"fmt"
	"reflect"
	"time"
)

// Unmarshaler is a custom type which can be used to hook into the decoder.
type Unmarshaler interface {
	// UnmarshalRiver is called when decoding a value. f should be invoked to
	// continue decoding with a value to decode into.
	UnmarshalRiver(f func(v interface{}) error) error
}

// Decode assigns a Value val to a Go pointer target. Pointers will be
// allocated as necessary when decoding.
//
// As a performance optimization, the underlying Go value of val will be
// assigned directly to target if the Go types match. This means that pointers,
// slices, and maps will be passed by reference. Callers should take care not
// to modify any Values after decoding, unless it is expected by the contract
// of the type (i.e., when the type exposes a goroutine-safe API). In other
// cases, new maps and slices will be allocated as necessary. Call DecodeCopy
// to make a copy of val instead.
//
// When a direct assignment is not done, Decode first checks to see if target
// implements the Unmarshaler or text.Unmarshaler interface, invoking methods
// as appropriate. It will also use time.ParseDuration if target is
// *time.Duration.
//
// Next, Decode will attempt to convert val to the type expected by target for
// assignment. If val or target implement ConvertibleCapsule, conversion
// between values will be attempted by calling ConvertFrom and ConvertInto as
// appropriate. If val cannot be converted, an error is returned.
//
// River null values will decode into a nil Go pointer or the zero value for
// the non-pointer type.
//
// Decode will panic if target is not a pointer.
func Decode(val Value, target interface{}) error {
	rt := reflect.ValueOf(target)
	if rt.Kind() != reflect.Pointer {
		panic("river/value: Decode called with non-pointer value")
	}

	var d decoder
	return d.decode(val, rt)
}

// DecodeCopy is like Decode but a deep copy of val is always made.
//
// Unlike Decode, DecodeCopy will always invoke Unmarshaler and
// text.Unmarshaler interfaces (if implemented by target).
func DecodeCopy(val Value, target interface{}) error {
	rt := reflect.ValueOf(target)
	if rt.Kind() != reflect.Pointer {
		panic("river/value: Decode called with non-pointer value")
	}

	d := decoder{makeCopy: true}
	return d.decode(val, rt)
}

type decoder struct {
	makeCopy bool
}

func (d *decoder) decode(val Value, into reflect.Value) error {
	// Store the raw value from val and try to address it so we can do underlying
	// type match assignment.
	rawValue := val.rv
	if rawValue.CanAddr() {
		rawValue = rawValue.Addr()
	}

	// Fully deference into and allocate pointers as necessary.
	for into.Kind() == reflect.Pointer {
		// Check for direct assignments before allocating pointers and deferencing.
		// This preservs pointer addresses when decoding an *int into an *int.
		switch {
		case into.CanSet() && val.Type() == TypeNull:
			into.Set(reflect.Zero(into.Type()))
			return nil
		case into.CanSet() && d.canDirectlyAssign(rawValue.Type(), into.Type()):
			into.Set(rawValue)
			return nil
		case into.CanSet() && d.canDirectlyAssign(val.rv.Type(), into.Type()):
			into.Set(val.rv)
			return nil
		}

		if into.IsNil() {
			into.Set(reflect.New(into.Type().Elem()))
		}
		into = into.Elem()
	}

	// Ww need to preform the same switch statement as above after the loop to
	// check for direct assignment one more time on the fully deferenced types.
	//
	// NOTE(rfratto): we skip the rawValue assignment check since that's meant
	// for assigning pointers, and into is never a pointer when we reach here.
	switch {
	case into.CanSet() && val.Type() == TypeNull:
		into.Set(reflect.Zero(into.Type()))
		return nil
	case into.CanSet() && d.canDirectlyAssign(val.rv.Type(), into.Type()):
		into.Set(val.rv)
		return nil
	}

	// Special decoding rules:
	//
	// 1. If into is an interface{}, go through decodeAny so it gets assigned
	//    predictable types.
	// 2. If into implements a supported interface, use the interface for
	//    decoding instead.
	if into.Type() == goAny {
		return d.decodeAny(val, into)
	} else if ok, err := d.decodeFromInterface(val, into); ok {
		return err
	}

	targetType := RiverType(into.Type())

	// Track a value to use for decoding. This value will be updated if
	// conversion is necessary.
	//
	// NOTE(rfratto): we don't reassign to val here, since Go 1.18 thinks that
	// means it escapes the heap. We need to create a local variable to avoid
	// extra allocations.
	convVal := val

	// Convert the value.
	switch {
	case val.rv.Type() == goByteSlice && into.Type() == goString: // []byte -> string
		into.Set(val.rv.Convert(goString))
		return nil
	case val.rv.Type() == goString && into.Type() == goByteSlice: // string -> []byte
		into.Set(val.rv.Convert(goByteSlice))
		return nil
	case convVal.Type() != targetType:
		converted, err := tryCapsuleConvert(convVal, into, targetType)
		if err != nil {
			return err
		} else if converted {
			return nil
		}

		convVal, err = convertValue(convVal, targetType)
		if err != nil {
			return err
		}
	}

	// Slowest case: recursive decoding. Once we've reached this point, we know
	// that convVal.rv and into are compatible Go types.
	switch convVal.Type() {
	case TypeNumber:
		into.Set(convertGoNumber(convVal.Number(), into.Type()))
		return nil
	case TypeString:
		// Call convVal.Text() to get the final string value, since convVal.rv
		// might not be a string.
		into.Set(reflect.ValueOf(convVal.Text()))
		return nil
	case TypeBool:
		into.Set(reflect.ValueOf(convVal.Bool()))
		return nil
	case TypeArray:
		return d.decodeArray(convVal, into)
	case TypeObject:
		return d.decodeObject(convVal, into)
	case TypeFunction:
		// The Go types for two functions must be the same.
		//
		// TODO(rfratto): we may want to consider being more lax here, potentially
		// creating an adapter between the two functions.
		if convVal.rv.Type() == into.Type() {
			into.Set(convVal.rv)
			return nil
		}

		return Error{
			Value: val,
			Inner: fmt.Errorf("expected function(%s), got function(%s)", into.Type(), convVal.rv.Type()),
		}
	case TypeCapsule:
		// The Go types for the capsules must be the same or able to be converted.
		if convVal.rv.Type() == into.Type() {
			into.Set(convVal.rv)
			return nil
		}

		converted, err := tryCapsuleConvert(convVal, into, targetType)
		if err != nil {
			return err
		} else if converted {
			return nil
		}

		// TODO(rfratto): return a TypeError for this instead. TypeError isn't
		// appropriate at the moment because it would just print "capsule", which
		// doesn't contain all the information the user would want to know (e.g., a
		// capsule of what inner type?).
		return Error{
			Value: val,
			Inner: fmt.Errorf("expected capsule(%q), got %s", into.Type(), convVal.Describe()),
		}
	default:
		panic("river/value: unexpected kind " + convVal.Type().String())
	}
}

// canDirectlyAssign returns true if the `from` type can be directly asssigned
// to the `into` type. This always returns false if the decoder is set to make
// copies or into contains an interface{} type anywhere in its type definition
// to allow for decoding interfaces{} into a set of known types.
func (d *decoder) canDirectlyAssign(from reflect.Type, into reflect.Type) bool {
	if d.makeCopy {
		return false
	}
	if from != into {
		return false
	}
	return !containsAny(into)
}

// containsAny recrusively traverses through into, returning true if it
// contains an interface{} value anywhere in its structure.
func containsAny(into reflect.Type) bool {
	// TODO(rfratto): cache result of this function?

	if into == goAny {
		return true
	}

	switch into.Kind() {
	case reflect.Array, reflect.Pointer, reflect.Slice:
		return containsAny(into.Elem())
	case reflect.Map:
		if into.Key() == goString {
			return containsAny(into.Elem())
		}
		return false

	case reflect.Struct:
		for i := 0; i < into.NumField(); i++ {
			if containsAny(into.Field(i).Type) {
				return true
			}
		}
		return false

	default:
		// Other kinds are not River types where the decodeAny check applies.
		return false
	}
}

func (d *decoder) decodeFromInterface(val Value, into reflect.Value) (ok bool, err error) {
	// into may only implement interface types for a pointer receiver, so we want
	// to address into if possible.
	if into.CanAddr() {
		into = into.Addr()
	}

	switch {
	case into.Type() == goDurationPtr:
		var s string
		err := d.decode(val, reflect.ValueOf(&s))
		if err != nil {
			return true, err
		}
		dur, err := time.ParseDuration(s)
		if err != nil {
			return true, Error{Value: val, Inner: err}
		}
		*into.Interface().(*time.Duration) = dur
		return true, nil

	case into.Type().Implements(goRiverDecoder):
		err := into.Interface().(Unmarshaler).UnmarshalRiver(func(v interface{}) error {
			return d.decode(val, reflect.ValueOf(v))
		})
		if err != nil {
			// TODO(rfratto): we need to detect if error is one of the error types
			// from this package and only wrap it in an Error if it isn't.
			return true, Error{Value: val, Inner: err}
		}
		return true, nil

	case into.Type().Implements(goTextUnmarshaler):
		var s string
		err := d.decode(val, reflect.ValueOf(&s))
		if err != nil {
			return true, err
		}
		err = into.Interface().(encoding.TextUnmarshaler).UnmarshalText([]byte(s))
		if err != nil {
			return true, Error{Value: val, Inner: err}
		}
		return true, nil
	}

	return false, nil
}

func tryCapsuleConvert(from Value, into reflect.Value, intoType Type) (ok bool, err error) {
	// Check to see if we can use capsule conversion.
	if from.Type() == TypeCapsule {
		cc, ok := from.Interface().(ConvertibleIntoCapsule)
		if ok {
			// It's always possible to Addr the reflect.Value below since we expect
			// it to be a settable non-pointer value.
			err := cc.ConvertInto(into.Addr().Interface())
			if err == nil {
				return true, nil
			} else if err != nil && !errors.Is(err, ErrNoConversion) {
				return false, Error{Value: from, Inner: err}
			}
		}
	}

	if intoType == TypeCapsule {
		cc, ok := into.Addr().Interface().(ConvertibleFromCapsule)
		if ok {
			err := cc.ConvertFrom(from.Interface())
			if err == nil {
				return true, nil
			} else if err != nil && !errors.Is(err, ErrNoConversion) {
				return false, Error{Value: from, Inner: err}
			}
		}
	}

	return false, nil
}

// decodeAny is invoked by decode when into is an interface{}. We assign the
// interface{} a known type based on the River value being decoded:
//
//   Null values:   nil
//   Number values: float64, int, or uint depending on the underlying Go type
//                  of the River value
//   Arrays:        []interface{}
//   Objects:       map[string]interface{}
//   Bool:          bool
//   String:        string
//   Function:      Passthrough of the underlying function value
//   Capsule:       Passthrough of the underlying capsule value
//
// In the cases where we do not passthrough the underlying value, we create a
// value of that type, recrusively call decode to populate that new value, and
// then store that value into the interface{}.
func (d *decoder) decodeAny(val Value, into reflect.Value) error {
	var ptr reflect.Value

	switch val.Type() {
	case TypeNull:
		into.Set(reflect.Zero(into.Type()))
		return nil

	case TypeNumber:
		switch val.Number().Kind() {
		case NumberKindFloat:
			var v float64
			ptr = reflect.ValueOf(&v)
		case NumberKindInt:
			var v int
			ptr = reflect.ValueOf(&v)
		case NumberKindUint:
			var v uint
			ptr = reflect.ValueOf(&v)
		default:
			panic("river/value: unreachable")
		}

	case TypeArray:
		var v []interface{}
		ptr = reflect.ValueOf(&v)

	case TypeObject:
		var v map[string]interface{}
		ptr = reflect.ValueOf(&v)

	case TypeBool:
		var v bool
		ptr = reflect.ValueOf(&v)

	case TypeString:
		var v string
		ptr = reflect.ValueOf(&v)

	case TypeFunction, TypeCapsule:
		// Functions and capsules must be directly assigned since there's no
		// "generic" representation for either.
		into.Set(val.rv)
		return nil

	default:
		panic("river/value: unreachable")
	}

	if err := d.decode(val, ptr); err != nil {
		return err
	}
	into.Set(ptr.Elem())
	return nil
}

func (d *decoder) decodeArray(val Value, rt reflect.Value) error {
	switch rt.Kind() {
	case reflect.Slice:
		res := reflect.MakeSlice(rt.Type(), val.Len(), val.Len())
		for i := 0; i < val.Len(); i++ {
			// Decode the original elements into the new elements.
			if err := d.decode(val.Index(i), res.Index(i)); err != nil {
				return ElementError{Value: val, Index: i, Inner: err}
			}
		}
		rt.Set(res)

	case reflect.Array:
		res := reflect.New(rt.Type()).Elem()

		if val.Len() != res.Len() {
			return Error{
				Value: val,
				Inner: fmt.Errorf("array must have exactly %d elements, got %d", res.Len(), val.Len()),
			}
		}

		for i := 0; i < val.Len(); i++ {
			if err := d.decode(val.Index(i), res.Index(i)); err != nil {
				return ElementError{Value: val, Index: i, Inner: err}
			}
		}
		rt.Set(res)

	default:
		panic(fmt.Sprintf("river/value: unexpected array type %s", val.rv.Kind()))
	}

	return nil
}

func (d *decoder) decodeObject(val Value, rt reflect.Value) error {
	switch rt.Kind() {
	case reflect.Struct:
		targetTags := getCachedTags(rt.Type())
		return d.decodeObjectToStruct(val, rt, targetTags, false)

	case reflect.Slice, reflect.Array: // Slice of labeled blocks
		keys := val.Keys()

		var res reflect.Value

		if rt.Kind() == reflect.Slice {
			res = reflect.MakeSlice(rt.Type(), len(keys), len(keys))
		} else { // Array
			res = reflect.New(rt.Type()).Elem()

			if res.Len() != len(keys) {
				return Error{
					Value: val,
					Inner: fmt.Errorf("object must have exactly %d keys, got %d", res.Len(), len(keys)),
				}
			}
		}

		fields := getCachedTags(rt.Type().Elem())
		labelField, _ := fields.LabelField()

		for i, key := range keys {
			// First decode the key into the label.
			elem := res.Index(i)
			elem.FieldByIndex(labelField.Index).Set(reflect.ValueOf(key))

			// Now decode the inner object.
			value, _ := val.Key(key)
			if err := d.decodeObjectToStruct(value, elem, fields, true); err != nil {
				return FieldError{Value: val, Field: key, Inner: err}
			}
		}
		rt.Set(res)

	case reflect.Map:
		if rt.Type().Key() != goString {
			// Maps with non-string types are treated as capsules and can't be
			// decoded from maps.
			return TypeError{Value: val, Expected: RiverType(rt.Type())}
		}

		res := reflect.MakeMapWithSize(rt.Type(), val.Len())

		// Create a shared value to decode each element into. This will be zeroed
		// out for each key, and then copied when setting the map index.
		into := reflect.New(rt.Type().Elem()).Elem()
		intoZero := reflect.Zero(into.Type())

		for i, key := range val.Keys() {
			// We ignore the ok value because we know it exists.
			value, _ := val.Key(key)

			// Zero out the value if it was decoded in the previous loop.
			if i > 0 {
				into.Set(intoZero)
			}
			// Decode into our element.
			if err := d.decode(value, into); err != nil {
				return FieldError{Value: val, Field: key, Inner: err}
			}

			// Then set the map index.
			res.SetMapIndex(reflect.ValueOf(key), into)
		}

		rt.Set(res)

	default:
		panic(fmt.Sprintf("river/value: unexpected target type %s", rt.Kind()))
	}

	return nil
}

func (d *decoder) decodeObjectToStruct(val Value, rt reflect.Value, fields *objectFields, decodedLabel bool) error {
	// TODO(rfratto): this needs to check for required keys being set

	for _, key := range val.Keys() {
		// We ignore the ok value because we know it exists.
		value, _ := val.Key(key)

		// Struct labels should be decoded first, since objects are wrapped in
		// labels. If we have yet to decode the label, decode it now.
		if lf, ok := fields.LabelField(); ok && !decodedLabel {
			// Safety check: if the inner field isn't an object, there's something
			// wrong here. It's unclear if a user can craft an expression that hits
			// this case, but it's left in for safety.
			if value.Type() != TypeObject {
				return FieldError{
					Value: val,
					Field: key,
					Inner: TypeError{Value: value, Expected: TypeObject},
				}
			}

			// Decode the key into the label.
			rt.FieldByIndex(lf.Index).Set(reflect.ValueOf(key))

			// ...and then code the rest of the object.
			if err := d.decodeObjectToStruct(value, rt, fields, true); err != nil {
				return err
			}
			continue
		}

		switch fields.Has(key) {
		case objectKeyTypeInvalid:
			return MissingKeyError{Value: value, Missing: key}
		case objectKeyTypeNestedField:
			next, _ := fields.NestedField(key)
			// Recruse the call with the inner value.
			if err := d.decodeObjectToStruct(value, rt, next, decodedLabel); err != nil {
				return err
			}
		case objectKeyTypeField:
			targetField, _ := fields.Field(key)
			if err := d.decodeToField(value, rt, targetField.Index); err != nil {
				return FieldError{Value: val, Field: key, Inner: err}
			}
		}
	}

	return nil
}

// decodeToField will decode val into a field within intoStruct indexed by the
// index slice. decodeToField will allocate pointers as necessary while
// traversing the struct fields.
func (d *decoder) decodeToField(val Value, intoStruct reflect.Value, index []int) error {
	curr := intoStruct
	for _, next := range index {
		for curr.Kind() == reflect.Pointer {
			if curr.IsNil() {
				curr.Set(reflect.New(curr.Type().Elem()))
			}
			curr = curr.Elem()
		}

		curr = curr.Field(next)
	}

	return d.decode(val, curr)
}

'''
'''--- pkg/river/internal/value/decode_benchmarks_test.go ---
package value_test

import (
	"fmt"
	"testing"

	"github.com/grafana/agent/pkg/river/internal/value"
)

func BenchmarkObjectDecode(b *testing.B) {
	b.StopTimer()

	// Create a value with 20 keys.
	source := make(map[string]string, 20)
	for i := 0; i < 20; i++ {
		var (
			key   = fmt.Sprintf("key_%d", i+1)
			value = fmt.Sprintf("value_%d", i+1)
		)
		source[key] = value
	}

	sourceVal := value.Encode(source)

	b.StartTimer()
	for i := 0; i < b.N; i++ {
		var dst map[string]string
		_ = value.Decode(sourceVal, &dst)
	}
}

'''
'''--- pkg/river/internal/value/decode_test.go ---
package value_test

import (
	"fmt"
	"reflect"
	"testing"
	"time"
	"unsafe"

	"github.com/grafana/agent/pkg/river/internal/value"
	"github.com/stretchr/testify/require"
)

func TestDecode_Numbers(t *testing.T) {
	// There's a lot of values that can represent numbers, so we construct a
	// matrix dynamically of all the combinations here.
	vals := []interface{}{
		int(15), int8(15), int16(15), int32(15), int64(15),
		uint(15), uint8(15), uint16(15), uint32(15), uint64(15),
		float32(15), float64(15),
		string("15"), // string holding a valid number (which can be converted to a number)
	}

	for _, input := range vals {
		for _, expect := range vals {
			val := value.Encode(input)

			name := fmt.Sprintf(
				"%s to %s",
				reflect.TypeOf(input),
				reflect.TypeOf(expect),
			)

			t.Run(name, func(t *testing.T) {
				vPtr := reflect.New(reflect.TypeOf(expect)).Interface()
				require.NoError(t, value.Decode(val, vPtr))

				actual := reflect.ValueOf(vPtr).Elem().Interface()
				require.Equal(t, expect, actual)
			})
		}
	}
}

func TestDecode(t *testing.T) {
	// Declare some types to use for testing. Person2 is used as a struct
	// equivalent to Person, but with a different Go type to force casting.
	type Person struct {
		Name string `river:"name,attr"`
	}

	type Person2 struct {
		Name string `river:"name,attr"`
	}

	tt := []struct {
		input, expect interface{}
	}{
		{nil, (*int)(nil)},

		// Non-number primitives.
		{string("Hello!"), string("Hello!")},
		{bool(true), bool(true)},

		// Arrays
		{[]int{1, 2, 3}, []int{1, 2, 3}},
		{[]int{1, 2, 3}, [...]int{1, 2, 3}},
		{[...]int{1, 2, 3}, []int{1, 2, 3}},
		{[...]int{1, 2, 3}, [...]int{1, 2, 3}},

		// Maps
		{map[string]int{"year": 2022}, map[string]uint{"year": 2022}},
		{map[string]string{"name": "John"}, map[string]string{"name": "John"}},
		{map[string]string{"name": "John"}, Person{Name: "John"}},
		{Person{Name: "John"}, map[string]string{"name": "John"}},
		{Person{Name: "John"}, Person{Name: "John"}},
		{Person{Name: "John"}, Person2{Name: "John"}},
		{Person2{Name: "John"}, Person{Name: "John"}},

		// NOTE(rfratto): we don't test capsules or functions here because they're
		// not comparable in the same way as we do the other tests.
		//
		// See TestDecode_Functions and TestDecode_Capsules for specific decoding
		// tests of those types.
	}

	for _, tc := range tt {
		val := value.Encode(tc.input)

		name := fmt.Sprintf(
			"%s (%s) to %s",
			val.Type(),
			reflect.TypeOf(tc.input),
			reflect.TypeOf(tc.expect),
		)

		t.Run(name, func(t *testing.T) {
			vPtr := reflect.New(reflect.TypeOf(tc.expect)).Interface()
			require.NoError(t, value.Decode(val, vPtr))

			actual := reflect.ValueOf(vPtr).Elem().Interface()

			require.Equal(t, tc.expect, actual)
		})
	}
}

// TestDecode_PreservePointer ensures that pointer addresses can be preserved
// when decoding.
func TestDecode_PreservePointer(t *testing.T) {
	num := 5
	val := value.Encode(&num)

	var nump *int
	require.NoError(t, value.Decode(val, &nump))
	require.Equal(t, unsafe.Pointer(nump), unsafe.Pointer(&num))
}

// TestDecode_PreserveMapReference ensures that map references can be preserved
// when decoding.
func TestDecode_PreserveMapReference(t *testing.T) {
	m := make(map[string]string)
	val := value.Encode(m)

	var actual map[string]string
	require.NoError(t, value.Decode(val, &actual))

	// We can't check to see if the pointers of m and actual match, but we can
	// modify m to see if actual is also modified.
	m["foo"] = "bar"
	require.Equal(t, "bar", actual["foo"])
}

// TestDecode_PreserveSliceReference ensures that slice references can be
// preserved when decoding.
func TestDecode_PreserveSliceReference(t *testing.T) {
	s := make([]string, 3)
	val := value.Encode(s)

	var actual []string
	require.NoError(t, value.Decode(val, &actual))

	// We can't check to see if the pointers of m and actual match, but we can
	// modify s to see if actual is also modified.
	s[0] = "Hello, world!"
	require.Equal(t, "Hello, world!", actual[0])
}
func TestDecode_Functions(t *testing.T) {
	val := value.Encode(func() int { return 15 })

	var f func() int
	require.NoError(t, value.Decode(val, &f))
	require.Equal(t, 15, f())
}

func TestDecode_Capsules(t *testing.T) {
	expect := make(chan int, 5)

	var actual chan int
	require.NoError(t, value.Decode(value.Encode(expect), &actual))
	require.Equal(t, expect, actual)
}

// TestDecodeCopy_SliceCopy ensures that copies are made during decoding
// instead of setting values directly.
func TestDecodeCopy_SliceCopy(t *testing.T) {
	orig := []int{1, 2, 3}

	var res []int
	require.NoError(t, value.DecodeCopy(value.Encode(orig), &res))

	res[0] = 10
	require.Equal(t, []int{1, 2, 3}, orig, "Original slice should not have been modified")
}

// TestDecodeCopy_ArrayCopy ensures that copies are made during decoding
// instead of setting values directly.
func TestDecode_ArrayCopy(t *testing.T) {
	orig := [...]int{1, 2, 3}

	var res [3]int
	require.NoError(t, value.DecodeCopy(value.Encode(orig), &res))

	res[0] = 10
	require.Equal(t, [3]int{1, 2, 3}, orig, "Original array should not have been modified")
}

func TestDecode_CustomTypes(t *testing.T) {
	t.Run("object to Unmarshaler", func(t *testing.T) {
		var actual customUnmarshaler
		require.NoError(t, value.Decode(value.Object(nil), &actual))
		require.True(t, actual.Called, "UnmarshalRiver was not invoked")
	})

	t.Run("TextMarshaler to TextUnmarshaler", func(t *testing.T) {
		now := time.Now()

		var actual time.Time
		require.NoError(t, value.Decode(value.Encode(now), &actual))
		require.True(t, now.Equal(actual))
	})

	t.Run("time.Duration to time.Duration", func(t *testing.T) {
		dur := 15 * time.Second

		var actual time.Duration
		require.NoError(t, value.Decode(value.Encode(dur), &actual))
		require.Equal(t, dur, actual)
	})

	t.Run("string to TextUnmarshaler", func(t *testing.T) {
		now := time.Now()
		nowBytes, _ := now.MarshalText()

		var actual time.Time
		require.NoError(t, value.Decode(value.String(string(nowBytes)), &actual))

		actualBytes, _ := actual.MarshalText()
		require.Equal(t, nowBytes, actualBytes)
	})

	t.Run("string to time.Duration", func(t *testing.T) {
		dur := 15 * time.Second

		var actual time.Duration
		require.NoError(t, value.Decode(value.String(dur.String()), &actual))
		require.Equal(t, dur.String(), actual.String())
	})
}

type customUnmarshaler struct {
	Called bool
}

func (cu *customUnmarshaler) UnmarshalRiver(f func(interface{}) error) error {
	cu.Called = true

	type s customUnmarshaler
	return f((*s)(cu))
}

type textEnumType bool

func (et *textEnumType) UnmarshalText(text []byte) error {
	*et = false

	switch string(text) {
	case "accepted_value":
		*et = true
		return nil
	default:
		return fmt.Errorf("unrecognized value %q", string(text))
	}
}

func TestDecode_TextUnmarshaler(t *testing.T) {
	t.Run("valid type and value", func(t *testing.T) {
		var et textEnumType
		require.NoError(t, value.Decode(value.String("accepted_value"), &et))
		require.Equal(t, textEnumType(true), et)
	})

	t.Run("invalid type", func(t *testing.T) {
		var et textEnumType
		err := value.Decode(value.Bool(true), &et)
		require.EqualError(t, err, "expected string, got bool")
	})

	t.Run("invalid value", func(t *testing.T) {
		var et textEnumType
		err := value.Decode(value.String("bad_value"), &et)
		require.EqualError(t, err, `unrecognized value "bad_value"`)
	})

	t.Run("unmarshaler nested in other value", func(t *testing.T) {
		input := value.Array(
			value.String("accepted_value"),
			value.String("accepted_value"),
			value.String("accepted_value"),
		)

		var ett []textEnumType
		require.NoError(t, value.Decode(input, &ett))
		require.Equal(t, []textEnumType{true, true, true}, ett)
	})
}

func TestDecode_ErrorChain(t *testing.T) {
	type Target struct {
		Key struct {
			Object struct {
				Field1 []int `river:"field1,attr"`
			} `river:"object,attr"`
		} `river:"key,attr"`
	}

	val := value.Object(map[string]value.Value{
		"key": value.Object(map[string]value.Value{
			"object": value.Object(map[string]value.Value{
				"field1": value.Array(
					value.Int(15),
					value.Int(30),
					value.String("Hello, world!"),
				),
			}),
		}),
	})

	// NOTE(rfratto): strings of errors from the value package are fairly limited
	// in the amount of information they show, since the value package doesn't
	// have a great way to pretty-print the chain of errors.
	//
	// For example, with the error below, the message doesn't explain where the
	// string is coming from, even though the error values hold that context.
	//
	// Callers consuming errors should print the error chain with extra context
	// so it's more useful to users.
	err := value.Decode(val, &Target{})
	expectErr := `expected number, got string`
	require.EqualError(t, err, expectErr)
}

type boolish int

var _ value.ConvertibleFromCapsule = (*boolish)(nil)
var _ value.ConvertibleIntoCapsule = (boolish)(0)

func (b boolish) RiverCapsule() {}

func (b *boolish) ConvertFrom(src interface{}) error {
	switch v := src.(type) {
	case bool:
		if v {
			*b = 1
		} else {
			*b = 0
		}
		return nil
	}

	return value.ErrNoConversion
}

func (b boolish) ConvertInto(dst interface{}) error {
	switch d := dst.(type) {
	case *bool:
		if b == 0 {
			*d = false
		} else {
			*d = true
		}
		return nil
	}

	return value.ErrNoConversion
}

func TestDecode_CustomConvert(t *testing.T) {
	t.Run("compatible type to custom", func(t *testing.T) {
		var b boolish
		err := value.Decode(value.Bool(true), &b)
		require.NoError(t, err)
		require.Equal(t, boolish(1), b)
	})

	t.Run("custom to compatible type", func(t *testing.T) {
		var b bool
		err := value.Decode(value.Encapsulate(boolish(10)), &b)
		require.NoError(t, err)
		require.Equal(t, true, b)
	})

	t.Run("incompatible type to custom", func(t *testing.T) {
		var b boolish
		err := value.Decode(value.String("true"), &b)
		require.EqualError(t, err, "expected capsule, got string")
	})

	t.Run("custom to incompatible type", func(t *testing.T) {
		src := boolish(10)

		var s string
		err := value.Decode(value.Encapsulate(&src), &s)
		require.EqualError(t, err, "expected string, got capsule")
	})
}

'''
'''--- pkg/river/internal/value/errors.go ---
package value

import "fmt"

// Error is used for reporting on a value-level error. It is the most general
// type of error for a value.
type Error struct {
	Value Value
	Inner error
}

// TypeError is used for reporting on a value having an unexpected type.
type TypeError struct {
	// Value which caused the error.
	Value    Value
	Expected Type
}

// Error returns the string form of the TypeError.
func (te TypeError) Error() string {
	return fmt.Sprintf("expected %s, got %s", te.Expected, te.Value.Type())
}

// Error returns the message of the decode error.
func (de Error) Error() string { return de.Inner.Error() }

// MissingKeyError is used for reporting that a value is missing a key.
type MissingKeyError struct {
	Value   Value
	Missing string
}

// Error returns the string form of the MissingKeyError.
func (mke MissingKeyError) Error() string {
	return fmt.Sprintf("key %q does not exist", mke.Missing)
}

// ElementError is used to report on an error inside of an array.
type ElementError struct {
	Value Value // The Array value
	Index int   // The index of the element with the issue
	Inner error // The error from the element
}

// Error returns the text of the inner error.
func (ee ElementError) Error() string { return ee.Inner.Error() }

// FieldError is used to report on an invalid field inside an object.
type FieldError struct {
	Value Value  // The Object value
	Field string // The field name with the issue
	Inner error  // The error from the field
}

// Error returns the text of the inner error.
func (fe FieldError) Error() string { return fe.Inner.Error() }

// ArgError is used to report on an invalid argument to a function.
type ArgError struct {
	Function Value
	Argument Value
	Index    int
	Inner    error
}

// Error returns the text of the inner error.
func (ae ArgError) Error() string { return ae.Inner.Error() }

// WalkError walks err for all value-related errors in this package.
// WalkError returns false if err is not an error from this package.
func WalkError(err error, f func(err error)) bool {
	var foundOne bool

	nextError := err
	for nextError != nil {
		switch ne := nextError.(type) {
		case Error:
			f(nextError)
			nextError = ne.Inner
			foundOne = true
		case TypeError:
			f(nextError)
			nextError = nil
			foundOne = true
		case MissingKeyError:
			f(nextError)
			nextError = nil
			foundOne = true
		case ElementError:
			f(nextError)
			nextError = ne.Inner
			foundOne = true
		case FieldError:
			f(nextError)
			nextError = ne.Inner
			foundOne = true
		case ArgError:
			f(nextError)
			nextError = ne.Inner
			foundOne = true
		default:
			nextError = nil
		}
	}

	return foundOne
}

'''
'''--- pkg/river/internal/value/number_value.go ---
package value

import (
	"math"
	"reflect"
	"strconv"
)

var (
	nativeIntBits  = reflect.TypeOf(int(0)).Bits()
	nativeUintBits = reflect.TypeOf(uint(0)).Bits()
)

// NumberKind categorizes a type of Go number.
type NumberKind uint8

const (
	// NumberKindInt represents an int-like type (e.g., int, int8, etc.).
	NumberKindInt NumberKind = iota
	// NumberKindUint represents a uint-like type (e.g., uint, uint8, etc.).
	NumberKindUint
	// NumberKindFloat represents both float32 and float64.
	NumberKindFloat
)

func makeNumberKind(k reflect.Kind) NumberKind {
	switch k {
	case reflect.Int, reflect.Int8, reflect.Int16, reflect.Int32, reflect.Int64:
		return NumberKindInt
	case reflect.Uint, reflect.Uint8, reflect.Uint16, reflect.Uint32, reflect.Uint64:
		return NumberKindUint
	case reflect.Float32, reflect.Float64:
		return NumberKindFloat
	default:
		panic("river/value: makeNumberKind called with unsupported Kind value")
	}
}

// Number is a generic representation of Go numbers. It is intended to be
// created on the fly for numerical operations when the real number type is not
// known.
type Number struct {
	// Value holds the raw data for the number. Note that for numberKindFloat,
	// value is the raw bits of the float64 and must be converted back to a
	// float64 before it can be used.
	value uint64

	bits uint8      // 8, 16, 32, 64, used for overflow checking
	k    NumberKind // int, uint, float
}

func newNumberValue(v reflect.Value) Number {
	var (
		val  uint64
		bits int
		nk   NumberKind
	)

	switch v.Kind() {
	case reflect.Int:
		val, bits, nk = uint64(v.Int()), nativeIntBits, NumberKindInt
	case reflect.Int8:
		val, bits, nk = uint64(v.Int()), 8, NumberKindInt
	case reflect.Int16:
		val, bits, nk = uint64(v.Int()), 16, NumberKindInt
	case reflect.Int32:
		val, bits, nk = uint64(v.Int()), 32, NumberKindInt
	case reflect.Int64:
		val, bits, nk = uint64(v.Int()), 64, NumberKindInt
	case reflect.Uint:
		val, bits, nk = v.Uint(), nativeUintBits, NumberKindUint
	case reflect.Uint8:
		val, bits, nk = v.Uint(), 8, NumberKindUint
	case reflect.Uint16:
		val, bits, nk = v.Uint(), 16, NumberKindUint
	case reflect.Uint32:
		val, bits, nk = v.Uint(), 32, NumberKindUint
	case reflect.Uint64:
		val, bits, nk = v.Uint(), 64, NumberKindUint
	case reflect.Float32:
		val, bits, nk = math.Float64bits(v.Float()), 32, NumberKindFloat
	case reflect.Float64:
		val, bits, nk = math.Float64bits(v.Float()), 64, NumberKindFloat
	default:
		panic("river/value: unrecognized Go number type " + v.Kind().String())
	}

	return Number{val, uint8(bits), nk}
}

// Kind returns the Number's NumberKind.
func (nv Number) Kind() NumberKind { return nv.k }

// Int converts the Number into an int64.
func (nv Number) Int() int64 {
	if nv.k == NumberKindFloat {
		return int64(math.Float64frombits(nv.value))
	}
	return int64(nv.value)
}

// Uint converts the Number into a uint64.
func (nv Number) Uint() uint64 {
	if nv.k == NumberKindFloat {
		return uint64(math.Float64frombits(nv.value))
	}
	return nv.value
}

// Float converts the Number into a float64.
func (nv Number) Float() float64 {
	if nv.k == NumberKindFloat {
		return math.Float64frombits(nv.value)
	}
	return float64(nv.value)
}

// ToString converts the Number to a string.
func (nv Number) ToString() string {
	switch nv.k {
	case NumberKindUint:
		return strconv.FormatUint(nv.value, 10)
	case NumberKindInt:
		return strconv.FormatInt(int64(nv.value), 10)
	case NumberKindFloat:
		return strconv.FormatFloat(math.Float64frombits(nv.value), 'f', -1, 64)
	}
	panic("river/value: unreachable")
}

'''
'''--- pkg/river/internal/value/raw_function.go ---
package value

// RawFunction allows creating function implemenations using raw River values.
// This is useful for functions which wish to operate over dynamic types while
// avoiding decoding to interface{} for performance reasons.
//
// The func value itself is provided as an argument so error types can be
// filled.
type RawFunction func(funcValue Value, args ...Value) (Value, error)

'''
'''--- pkg/river/internal/value/tag_cache.go ---
package value

import (
	"reflect"

	"github.com/grafana/agent/pkg/river/internal/rivertags"
)

// tagsCache caches the river tags for a struct type. This is never cleared,
// but since most structs will be statically created throughout the lifetime
// of the process, this will consume a negligible amount of memory.
var tagsCache = make(map[reflect.Type]*objectFields)

func getCachedTags(t reflect.Type) *objectFields {
	if t.Kind() != reflect.Struct {
		panic("getCachedTags called with non-struct type")
	}

	if entry, ok := tagsCache[t]; ok {
		return entry
	}

	ff := rivertags.Get(t)

	// Build a tree of keys.
	tree := &objectFields{
		fields:       make(map[string]rivertags.Field),
		nestedFields: make(map[string]*objectFields),
		keys:         []string{},
	}

	for _, f := range ff {
		if f.Flags&rivertags.FlagLabel != 0 {
			// Skip over label tags.
			tree.labelField = f
			continue
		}

		node := tree
		for i, name := range f.Name {
			// Add to the list of keys if this is a new key.
			if node.Has(name) == objectKeyTypeInvalid {
				node.keys = append(node.keys, name)
			}

			if i+1 == len(f.Name) {
				// Last fragment, add as a field.
				node.fields[name] = f
				continue
			}

			inner, ok := node.nestedFields[name]
			if !ok {
				inner = &objectFields{
					fields:       make(map[string]rivertags.Field),
					nestedFields: make(map[string]*objectFields),
					keys:         []string{},
				}
				node.nestedFields[name] = inner
			}
			node = inner
		}
	}

	tagsCache[t] = tree
	return tree
}

// objectFields is a parsed tree of fields in rivertags. It forms a tree where
// leaves are nested fields (e.g., for block names that have multiple name
// fragments) and nodes are the fields themselves.
type objectFields struct {
	fields       map[string]rivertags.Field
	nestedFields map[string]*objectFields
	keys         []string // Combination of fields + nestedFields
	labelField   rivertags.Field
}

type objectKeyType int

const (
	objectKeyTypeInvalid objectKeyType = iota
	objectKeyTypeField
	objectKeyTypeNestedField
)

// Has returns whether name exists as a field or a nested key inside keys.
// Returns objectKeyTypeInvalid if name does not exist as either.
func (of *objectFields) Has(name string) objectKeyType {
	if _, ok := of.fields[name]; ok {
		return objectKeyTypeField
	}
	if _, ok := of.nestedFields[name]; ok {
		return objectKeyTypeNestedField
	}
	return objectKeyTypeInvalid
}

// Len returns the number of named keys.
func (of *objectFields) Len() int { return len(of.keys) }

// Keys returns all named keys (fields and nested fields).
func (of *objectFields) Keys() []string { return of.keys }

// Field gets a non-nested field. Returns false if name is a nested field.
func (of *objectFields) Field(name string) (rivertags.Field, bool) {
	f, ok := of.fields[name]
	return f, ok
}

// NestedField gets a named nested field entry. Returns false if name is not a
// nested field.
func (of *objectFields) NestedField(name string) (*objectFields, bool) {
	nk, ok := of.nestedFields[name]
	return nk, ok
}

// LabelField returns the field used for the label (if any).
func (of *objectFields) LabelField() (rivertags.Field, bool) {
	return of.labelField, of.labelField.Index != nil
}

'''
'''--- pkg/river/internal/value/type.go ---
package value

import (
	"fmt"
	"reflect"
)

// Type represents the type of a River value loosely. For example, a Value may
// be TypeArray, but this does not imply anything about the type of that
// array's elements (all of which may be any type).
//
// TypeCapsule is a special type which encapsulates arbitrary Go values.
type Type uint8

// Supported Type values.
const (
	TypeNull Type = iota
	TypeNumber
	TypeString
	TypeBool
	TypeArray
	TypeObject
	TypeFunction
	TypeCapsule
)

var typeStrings = [...]string{
	TypeNull:     "null",
	TypeNumber:   "number",
	TypeString:   "string",
	TypeBool:     "bool",
	TypeArray:    "array",
	TypeObject:   "object",
	TypeFunction: "function",
	TypeCapsule:  "capsule",
}

// String returns the name of t.
func (t Type) String() string {
	if int(t) < len(typeStrings) {
		return typeStrings[t]
	}
	return fmt.Sprintf("Type(%d)", t)
}

// RiverType returns the River type from the Go type.
//
// Go types map to River types using the following rules:
//
//   1. Go numbers (ints, uints, floats) map to a River number
//   2. Go strings map to a River string
//   3. Go bools map to a River bool
//   4. Go arrays and slices map to a River array
//   5. Go map[string]T map to a River object
//   6. Go structs map to a River object
//   7. Valid Go functions map to a River function.
//   8. Go interfaces map to a River capsule
//   9. All other Go values map to a River capsule
//
// Go functions are only valid for River if they have one non-error return type
// (the first return type) and one optional error return type (the second
// return type). Other function types are treated as capsules.
//
// As an exception, any type which implements the Capsule interface is forced
// to be a capsule.
func RiverType(t reflect.Type) Type {
	// We don't know if the RiverCapsule interface is implemented for a pointer
	// or non-pointer type, so we have to check before and after dereferencing.

	for t.Kind() == reflect.Pointer {
		switch {
		case t.Implements(goCapsule):
			return TypeCapsule
		case t.Implements(goTextMarshaler):
			return TypeString
		}

		t = t.Elem()
	}

	switch {
	case t.Implements(goCapsule):
		return TypeCapsule
	case t.Implements(goTextMarshaler):
		return TypeString
	case t == goDuration:
		return TypeString
	}

	switch t.Kind() {
	case reflect.Invalid:
		return TypeNull

	case reflect.Int, reflect.Int8, reflect.Int16, reflect.Int32, reflect.Int64:
		return TypeNumber
	case reflect.Uint, reflect.Uint8, reflect.Uint16, reflect.Uint32, reflect.Uint64:
		return TypeNumber
	case reflect.Float32, reflect.Float64:
		return TypeNumber

	case reflect.String:
		return TypeString

	case reflect.Bool:
		return TypeBool

	case reflect.Array, reflect.Slice:
		if inner := t.Elem(); inner.Kind() == reflect.Struct {
			if _, labeled := getCachedTags(inner).LabelField(); labeled {
				// An slice/array of labeled blocks is an object, where each label is a
				// top-level key.
				return TypeObject
			}
		}
		return TypeArray

	case reflect.Map:
		if t.Key() != goString {
			// Objects must be keyed by string. Anything else is forced to be a
			// Capsule.
			return TypeCapsule
		}
		return TypeObject

	case reflect.Struct:
		return TypeObject

	case reflect.Func:
		switch t.NumOut() {
		case 1:
			if t.Out(0) == goError {
				return TypeCapsule
			}
			return TypeFunction
		case 2:
			if t.Out(0) == goError || t.Out(1) != goError {
				return TypeCapsule
			}
			return TypeFunction
		default:
			return TypeCapsule
		}

	case reflect.Interface:
		return TypeCapsule

	default:
		return TypeCapsule
	}
}

'''
'''--- pkg/river/internal/value/type_test.go ---
package value_test

import (
	"reflect"
	"testing"

	"github.com/grafana/agent/pkg/river/internal/value"
	"github.com/stretchr/testify/require"
)

type customCapsule bool

var _ value.Capsule = (customCapsule)(false)

func (customCapsule) RiverCapsule() {}

var typeTests = []struct {
	input  interface{}
	expect value.Type
}{
	{int(0), value.TypeNumber},
	{int8(0), value.TypeNumber},
	{int16(0), value.TypeNumber},
	{int32(0), value.TypeNumber},
	{int64(0), value.TypeNumber},
	{uint(0), value.TypeNumber},
	{uint8(0), value.TypeNumber},
	{uint16(0), value.TypeNumber},
	{uint32(0), value.TypeNumber},
	{uint64(0), value.TypeNumber},
	{float32(0), value.TypeNumber},
	{float64(0), value.TypeNumber},

	{string(""), value.TypeString},

	{bool(false), value.TypeBool},

	{[...]int{0, 1, 2}, value.TypeArray},
	{[]int{0, 1, 2}, value.TypeArray},

	{struct{}{}, value.TypeObject},

	// A slice of labeled blocks should be an object.
	{[]struct {
		Label string `river:",label"`
	}{}, value.TypeObject},

	{map[string]interface{}{}, value.TypeObject},

	// Go functions must have one non-error return type and one optional error
	// return type to be River functions. Everything else is a capsule.
	{(func() int)(nil), value.TypeFunction},
	{(func() (int, error))(nil), value.TypeFunction},
	{(func())(nil), value.TypeCapsule},                 // Must have non-error return type
	{(func() error)(nil), value.TypeCapsule},           // First return type must be non-error
	{(func() (error, int))(nil), value.TypeCapsule},    // First return type must be non-error
	{(func() (error, error))(nil), value.TypeCapsule},  // First return type must be non-error
	{(func() (int, int))(nil), value.TypeCapsule},      // Second return type must be error
	{(func() (int, int, int))(nil), value.TypeCapsule}, // Can only have 1 or 2 return types

	{make(chan struct{}), value.TypeCapsule},
	{map[bool]interface{}{}, value.TypeCapsule}, // Maps with non-string types are capsules

	// Types with capsule markers should be capsules.
	{customCapsule(false), value.TypeCapsule},
	{(*customCapsule)(nil), value.TypeCapsule},
	{(**customCapsule)(nil), value.TypeCapsule},
}

func Test_RiverType(t *testing.T) {
	for _, tc := range typeTests {
		rt := reflect.TypeOf(tc.input)

		t.Run(rt.String(), func(t *testing.T) {
			actual := value.RiverType(rt)
			require.Equal(t, tc.expect, actual, "Unexpected type for %#v", tc.input)
		})
	}
}

'''
'''--- pkg/river/internal/value/value.go ---
// Package value holds the internal representation for River values. River
// values act as a lightweight wrapper around reflect.Value.
package value

import (
	"encoding"
	"fmt"
	"reflect"
	"strconv"
	"strings"
	"time"
)

// Go types used throughout the package.
var (
	goAny             = reflect.TypeOf((*interface{})(nil)).Elem()
	goString          = reflect.TypeOf(string(""))
	goByteSlice       = reflect.TypeOf([]byte(nil))
	goError           = reflect.TypeOf((*error)(nil)).Elem()
	goTextMarshaler   = reflect.TypeOf((*encoding.TextMarshaler)(nil)).Elem()
	goTextUnmarshaler = reflect.TypeOf((*encoding.TextUnmarshaler)(nil)).Elem()
	goStructWrapper   = reflect.TypeOf(structWrapper{})
	goCapsule         = reflect.TypeOf((*Capsule)(nil)).Elem()
	goDuration        = reflect.TypeOf((time.Duration)(0))
	goDurationPtr     = reflect.TypeOf((*time.Duration)(nil))
	goRiverDecoder    = reflect.TypeOf((*Unmarshaler)(nil)).Elem()
	goRawRiverFunc    = reflect.TypeOf((RawFunction)(nil))
)

// NOTE(rfratto): This package is extremely sensitive to performance, so
// changes should be made with caution; run benchmarks when changing things.
//
// Value is optimized to be as small as possible and exist fully on the stack.
// This allows many values to avoid allocations, with the exception of creating
// arrays and objects.

// Value represents a River value.
type Value struct {
	rv reflect.Value
	ty Type
}

// Null is the null value.
var Null = Value{}

// Uint returns a Value from a uint64.
func Uint(u uint64) Value { return Value{rv: reflect.ValueOf(u), ty: TypeNumber} }

// Int returns a Value from an int64.
func Int(i int64) Value { return Value{rv: reflect.ValueOf(i), ty: TypeNumber} }

// Float returns a Value from a float64.
func Float(f float64) Value { return Value{rv: reflect.ValueOf(f), ty: TypeNumber} }

// String returns a Value from a string.
func String(s string) Value { return Value{rv: reflect.ValueOf(s), ty: TypeString} }

// Bool returns a Value from a bool.
func Bool(b bool) Value { return Value{rv: reflect.ValueOf(b), ty: TypeBool} }

// Object returns a new value from m. A copy of m is made for producing the
// Value.
func Object(m map[string]Value) Value {
	raw := reflect.MakeMapWithSize(reflect.TypeOf(map[string]interface{}(nil)), len(m))

	for k, v := range m {
		raw.SetMapIndex(reflect.ValueOf(k), v.rv)
	}

	return Value{rv: raw, ty: TypeObject}
}

// Array creates an array from the given values. A copy of the vv slice is made
// for producing the Value.
func Array(vv ...Value) Value {
	// Arrays should be slices otherwise any reference to them gets copied by
	// value into a new pointer.
	arrayType := reflect.SliceOf(goAny)
	raw := reflect.MakeSlice(arrayType, len(vv), len(vv))

	for i, v := range vv {
		if v.ty == TypeNull {
			continue
		}
		raw.Index(i).Set(v.rv)
	}

	return Value{rv: raw, ty: TypeArray}
}

// Func makes a new function Value from f. Func panics if f does not map to a
// River function.
func Func(f interface{}) Value {
	rv := reflect.ValueOf(f)
	if RiverType(rv.Type()) != TypeFunction {
		panic("river/value: Func called with non-function type")
	}
	return Value{rv: rv, ty: TypeFunction}
}

// Encapsulate creates a new Capsule value from v. Encapsulate panics if v does
// not map to a River capsule.
func Encapsulate(v interface{}) Value {
	rv := reflect.ValueOf(v)
	if RiverType(rv.Type()) != TypeCapsule {
		panic("river/value: Capsule called with non-capsule type")
	}
	return Value{rv: rv, ty: TypeCapsule}
}

// Encode creates a new Value from v. If v is a pointer, v must be considered
// immutable and not change while the Value is used.
func Encode(v interface{}) Value {
	if v == nil {
		return Null
	}
	return makeValue(reflect.ValueOf(v))
}

// Type returns the River type for the value.
func (v Value) Type() Type { return v.ty }

// Describe returns a descriptive type name for the value. For capsule values,
// this prints the underlying Go type name. For other values, it prints the
// normal River type.
func (v Value) Describe() string {
	if v.ty != TypeCapsule {
		return v.ty.String()
	}
	return fmt.Sprintf("capsule(%q)", v.rv.Type())
}

// Bool returns the boolean value for v. It panics if v is not a bool.
func (v Value) Bool() bool {
	if v.ty != TypeBool {
		panic("river/value: Bool called on non-bool type")
	}
	return v.rv.Bool()
}

// Number returns a Number value for v. It panics if v is not a Number.
func (v Value) Number() Number {
	if v.ty != TypeNumber {
		panic("river/value: Number called on non-number type")
	}
	return newNumberValue(v.rv)
}

// Int returns an int value for v. It panics if v is not a number.
func (v Value) Int() int64 {
	if v.ty != TypeNumber {
		panic("river/value: Int called on non-number type")
	}
	switch makeNumberKind(v.rv.Kind()) {
	case NumberKindInt:
		return v.rv.Int()
	case NumberKindUint:
		return int64(v.rv.Uint())
	case NumberKindFloat:
		return int64(v.rv.Float())
	}
	panic("river/value: unreachable")
}

// Uint returns an uint value for v. It panics if v is not a number.
func (v Value) Uint() uint64 {
	if v.ty != TypeNumber {
		panic("river/value: Uint called on non-number type")
	}
	switch makeNumberKind(v.rv.Kind()) {
	case NumberKindInt:
		return uint64(v.rv.Int())
	case NumberKindUint:
		return v.rv.Uint()
	case NumberKindFloat:
		return uint64(v.rv.Float())
	}
	panic("river/value: unreachable")
}

// Float returns a float value for v. It panics if v is not a number.
func (v Value) Float() float64 {
	if v.ty != TypeNumber {
		panic("river/value: Float called on non-number type")
	}
	switch makeNumberKind(v.rv.Kind()) {
	case NumberKindInt:
		return float64(v.rv.Int())
	case NumberKindUint:
		return float64(v.rv.Uint())
	case NumberKindFloat:
		return v.rv.Float()
	}
	panic("river/value: unreachable")
}

// Text returns a string value of v. It panics if v is not a string.
func (v Value) Text() string {
	if v.ty != TypeString {
		panic("river/value: Text called on non-string type")
	}

	// Attempt to get an address to v.rv for interface checking.
	//
	// The normal v.rv value is used for other checks.
	addrRV := v.rv
	if addrRV.CanAddr() {
		addrRV = addrRV.Addr()
	}
	switch {
	case addrRV.Type().Implements(goTextMarshaler):
		// TODO(rfratto): what should we do if this fails?
		text, _ := addrRV.Interface().(encoding.TextMarshaler).MarshalText()
		return string(text)

	case v.rv.Type() == goDuration:
		// Special case: v.rv is a duration and its String method should be used.
		return v.rv.Interface().(time.Duration).String()

	default:
		return v.rv.String()
	}
}

// Len returns the length of v. Panics if v is not an array or object.
func (v Value) Len() int {
	switch v.ty {
	case TypeArray:
		return v.rv.Len()
	case TypeObject:
		switch {
		case v.rv.Type() == goStructWrapper:
			return v.rv.Interface().(structWrapper).Len()
		case v.rv.Kind() == reflect.Array, v.rv.Kind() == reflect.Slice: // Array of labeled blocks
			return v.rv.Len()
		case v.rv.Kind() == reflect.Struct:
			return getCachedTags(v.rv.Type()).Len()
		case v.rv.Kind() == reflect.Map:
			return v.rv.Len()
		}
	}
	panic("river/value: Len called on non-array and non-object value")
}

// Index returns index i of the Value. Panics if the value is not an array or
// if it is out of bounds of the array's size.
func (v Value) Index(i int) Value {
	if v.ty != TypeArray {
		panic("river/value: Index called on non-array value")
	}
	return makeValue(v.rv.Index(i))
}

// Interface returns the underlying Go value for the Value.
func (v Value) Interface() interface{} {
	if v.ty == TypeNull {
		return nil
	}
	return v.rv.Interface()
}

// Reflect returns the raw reflection value backing v.
func (v Value) Reflect() reflect.Value { return v.rv }

// makeValue converts a reflect value into a Value, deferencing any pointers or
// interface{} values.
func makeValue(v reflect.Value) Value {
	// Early check: if v is interface{}, we need to deference it to get the
	// concrete value.
	if v.IsValid() && v.Type() == goAny {
		v = v.Elem()
	}

	// Before we get the River type of the Value, we need to see if it's possible
	// to get a pointer to v. This ensures that if v is a non-pointer field of an
	// addressable struct, still detect the type of v as if it was a pointer.
	if v.CanAddr() {
		v = v.Addr()
	}

	if !v.IsValid() {
		return Null
	}
	riverType := RiverType(v.Type())

	// Finally, deference the pointer fully and use the type we detected.
	for v.Kind() == reflect.Pointer {
		if v.IsNil() {
			return Null
		}
		v = v.Elem()
	}
	return Value{rv: v, ty: riverType}
}

// OrderedKeys reports if v represents an object with consistently ordered
// keys. If panics if v is not an object.
func (v Value) OrderedKeys() bool {
	if v.ty != TypeObject {
		panic("river/value: OrderedKeys called on non-object value")
	}

	// Maps are the only type of unordered River object, since their keys can't
	// be iterated over in a deterministic order. Every other type of River
	// object comes from a struct or a slice where the order of keys stays the
	// same.
	return v.rv.Kind() != reflect.Map
}

// Keys returns the keys in v in unspecified order. It panics if v is not an
// object.
func (v Value) Keys() []string {
	if v.ty != TypeObject {
		panic("river/value: Keys called on non-object value")
	}

	switch {
	case v.rv.Type() == goStructWrapper:
		return v.rv.Interface().(structWrapper).Keys()

	case v.rv.Kind() == reflect.Struct:
		return wrapStruct(v.rv, true).Keys()

	case v.rv.Kind() == reflect.Array, v.rv.Kind() == reflect.Slice:
		// List of labeled blocks.
		labelField, _ := getCachedTags(v.rv.Type().Elem()).LabelField()

		keys := make([]string, v.rv.Len())
		for i := range keys {
			keys[i] = v.rv.Index(i).FieldByIndex(labelField.Index).String()
		}
		return keys

	case v.rv.Kind() == reflect.Map:
		reflectKeys := v.rv.MapKeys()
		res := make([]string, len(reflectKeys))
		for i, rk := range reflectKeys {
			res[i] = rk.String()
		}
		return res
	}

	panic("river/value: unreachable")
}

// Key returns the value for a key in v. It panics if v is not an object. ok
// will be false if the key did not exist in the object.
func (v Value) Key(key string) (index Value, ok bool) {
	if v.ty != TypeObject {
		panic("river/value: Key called on non-object value")
	}

	switch {
	case v.rv.Type() == goStructWrapper:
		return v.rv.Interface().(structWrapper).Key(key)
	case v.rv.Kind() == reflect.Struct:
		// We return the struct with the label intact.
		return wrapStruct(v.rv, true).Key(key)
	case v.rv.Kind() == reflect.Map:
		val := v.rv.MapIndex(reflect.ValueOf(key))
		if !val.IsValid() || val.IsZero() {
			return
		}
		return makeValue(val), true

	case v.rv.Kind() == reflect.Slice, v.rv.Kind() == reflect.Array:
		// List of labeled blocks.
		labelField, _ := getCachedTags(v.rv.Type().Elem()).LabelField()

		for i := 0; i < v.rv.Len(); i++ {
			elem := v.rv.Index(i)

			label := elem.FieldByIndex(labelField.Index).String()
			if label == key {
				// We discard the label since the key here represents the label value.
				ws := wrapStruct(elem, false)
				return ws.Value(), true
			}
		}
	default:
		panic("river/value: unreachable")
	}

	return
}

// Call invokes a function value with the provided arguments. It panics if v is
// not a function. If v is a variadic function, args should be the full flat
// list of arguments.
//
// An ArgError will be returned if one of the arguments is invalid. An Error
// will be returned if the function call returns an error or if the number of
// arguments doesn't match.
func (v Value) Call(args ...Value) (Value, error) {
	if v.ty != TypeFunction {
		panic("river/value: Call called on non-function type")
	}

	if v.rv.Type() == goRawRiverFunc {
		return v.rv.Interface().(RawFunction)(v, args...)
	}

	var (
		variadic     = v.rv.Type().IsVariadic()
		expectedArgs = v.rv.Type().NumIn()
	)

	if variadic && len(args) < expectedArgs-1 {
		return Null, Error{
			Value: v,
			Inner: fmt.Errorf("expected at least %d args, got %d", expectedArgs-1, len(args)),
		}
	} else if !variadic && len(args) != expectedArgs {
		return Null, Error{
			Value: v,
			Inner: fmt.Errorf("expected %d args, got %d", expectedArgs, len(args)),
		}
	}

	reflectArgs := make([]reflect.Value, len(args))
	for i, arg := range args {
		var argVal reflect.Value
		if variadic && i >= expectedArgs-1 {
			argType := v.rv.Type().In(expectedArgs - 1).Elem()
			argVal = reflect.New(argType).Elem()
		} else {
			argType := v.rv.Type().In(i)
			argVal = reflect.New(argType).Elem()
		}

		var d decoder
		if err := d.decode(arg, argVal); err != nil {
			return Null, ArgError{
				Function: v,
				Argument: arg,
				Index:    i,
				Inner:    err,
			}
		}

		reflectArgs[i] = argVal
	}

	outs := v.rv.Call(reflectArgs)
	switch len(outs) {
	case 1:
		return makeValue(outs[0]), nil
	case 2:
		// When there's 2 return values, the second is always an error.
		err, _ := outs[1].Interface().(error)
		if err != nil {
			return Null, Error{Value: v, Inner: err}
		}
		return makeValue(outs[0]), nil

	default:
		// It's not possible to reach here; we enforce that function values always
		// have 1 or 2 return values.
		panic("river/value: unreachable")
	}
}

func convertValue(val Value, toType Type) (Value, error) {
	// TODO(rfratto): Use vm benchmarks to see if making this a method on Value
	// changes anything.

	fromType := val.Type()

	if fromType == toType {
		// no-op: val is already the right kind.
		return val, nil
	}

	switch fromType {
	case TypeNumber:
		switch toType {
		case TypeString: // number -> string
			strVal := newNumberValue(val.rv).ToString()
			return makeValue(reflect.ValueOf(strVal)), nil
		}

	case TypeString:
		sourceStr := val.rv.String()

		switch toType {
		case TypeNumber: // string -> number
			switch {
			case sourceStr == "":
				return Null, TypeError{Value: val, Expected: toType}

			case sourceStr[0] == '-':
				// String starts with a -; parse as a signed int.
				parsed, err := strconv.ParseInt(sourceStr, 10, 64)
				if err != nil {
					return Null, TypeError{Value: val, Expected: toType}
				}
				return Int(parsed), nil
			case strings.ContainsAny(sourceStr, ".eE"):
				// String contains something that a floating-point number would use;
				// convert.
				parsed, err := strconv.ParseFloat(sourceStr, 64)
				if err != nil {
					return Null, TypeError{Value: val, Expected: toType}
				}
				return Float(parsed), nil
			default:
				// Otherwise, treat the number as an unsigned int.
				parsed, err := strconv.ParseUint(sourceStr, 10, 64)
				if err != nil {
					return Null, TypeError{Value: val, Expected: toType}
				}
				return Uint(parsed), nil
			}
		}
	}

	return Null, TypeError{Value: val, Expected: toType}
}

func convertGoNumber(nval Number, target reflect.Type) reflect.Value {
	switch target.Kind() {
	case reflect.Int:
		return reflect.ValueOf(int(nval.Int()))
	case reflect.Int8:
		return reflect.ValueOf(int8(nval.Int()))
	case reflect.Int16:
		return reflect.ValueOf(int16(nval.Int()))
	case reflect.Int32:
		return reflect.ValueOf(int32(nval.Int()))
	case reflect.Int64:
		return reflect.ValueOf(nval.Int())
	case reflect.Uint:
		return reflect.ValueOf(uint(nval.Uint()))
	case reflect.Uint8:
		return reflect.ValueOf(uint8(nval.Uint()))
	case reflect.Uint16:
		return reflect.ValueOf(uint16(nval.Uint()))
	case reflect.Uint32:
		return reflect.ValueOf(uint32(nval.Uint()))
	case reflect.Uint64:
		return reflect.ValueOf(nval.Uint())
	case reflect.Float32:
		return reflect.ValueOf(float32(nval.Float()))
	case reflect.Float64:
		return reflect.ValueOf(nval.Float())
	}

	panic("unsupported number conversion")
}

'''
'''--- pkg/river/internal/value/value_object.go ---
package value

import "reflect"

// structWrapper allows for partially traversing structs which contain fields
// representing blocks. This is required due to how block names and labels
// change the object representation.
//
// If a block name is a.b.c, then it is represented as three nested objects:
//
//	{
// 	  a = {
//	    b = {
//	      c = { /* block contents */ },
//	    },
//	  }
//	}
//
// Similarly, if a block name is labeled (a.b.c "label"), then the label is the
// top-level key after c.
//
// structWrapper exposes Len, Keys, and Key methods similar to Value to allow
// traversing through the synthetic object. The values it returns are
// structWrappers.
//
// Code in value.go MUST check to see if a struct is a structWrapper *before*
// checking the value kind to ensure the appropriate methods are invoked.
type structWrapper struct {
	structVal reflect.Value
	fields    *objectFields
	label     string // Non-empty string if this struct is wrapped in a label.
}

func wrapStruct(val reflect.Value, keepLabel bool) structWrapper {
	if val.Kind() != reflect.Struct {
		panic("river/value: wrapStruct called on non-struct value")
	}

	fields := getCachedTags(val.Type())

	var label string
	if f, ok := fields.LabelField(); ok && keepLabel {
		label = val.FieldByIndex(f.Index).String()
	}

	return structWrapper{
		structVal: val,
		fields:    fields,
		label:     label,
	}
}

// Value turns sw into a value.
func (sw structWrapper) Value() Value {
	return Value{
		rv: reflect.ValueOf(sw),
		ty: TypeObject,
	}
}

func (sw structWrapper) Len() int {
	if len(sw.label) > 0 {
		return 1
	}
	return sw.fields.Len()
}

func (sw structWrapper) Keys() []string {
	if len(sw.label) > 0 {
		return []string{sw.label}
	}
	return sw.fields.Keys()
}

func (sw structWrapper) Key(key string) (index Value, ok bool) {
	if len(sw.label) > 0 {
		if key != sw.label {
			return
		}
		next := reflect.ValueOf(structWrapper{
			structVal: sw.structVal,
			fields:    sw.fields,
			// Unset the label now that we've traversed it
		})
		return Value{rv: next, ty: TypeObject}, true
	}

	keyType := sw.fields.Has(key)

	switch keyType {
	case objectKeyTypeInvalid:
		return // No such key

	case objectKeyTypeNestedField:
		// Continue traversing.
		nextNode, _ := sw.fields.NestedField(key)
		return Value{
			rv: reflect.ValueOf(structWrapper{
				structVal: sw.structVal,
				fields:    nextNode,
			}),
			ty: TypeObject,
		}, true

	case objectKeyTypeField:
		f, _ := sw.fields.Field(key)
		val, err := sw.structVal.FieldByIndexErr(f.Index)
		if err != nil {
			return Null, true
		}
		return makeValue(val), true
	}

	panic("river/value: unreachable")
}

'''
'''--- pkg/river/internal/value/value_object_test.go ---
package value_test

import (
	"testing"

	"github.com/grafana/agent/pkg/river/internal/value"
	"github.com/stretchr/testify/require"
)

// TestValue_Keys_Block ensures that the struct tags for blocks are represented
// correctly.
func TestBlockRepresentation(t *testing.T) {
	type UnlabledBlock struct {
		Value int `river:"value,attr"`
	}
	type LabeledBlock struct {
		Value int    `river:"value,attr"`
		Label string `river:",label"`
	}
	type OuterBlock struct {
		Attr1 string `river:"attr_1,attr"`
		Attr2 string `river:"attr_2,attr"`

		UnlabledBlock1 UnlabledBlock `river:"unlabeled.a,block"`
		UnlabledBlock2 UnlabledBlock `river:"unlabeled.b,block"`
		UnlabledBlock3 UnlabledBlock `river:"other_unlabeled,block"`

		LabeledBlock1 LabeledBlock `river:"labeled.a,block"`
		LabeledBlock2 LabeledBlock `river:"labeled.b,block"`
		LabeledBlock3 LabeledBlock `river:"other_labeled,block"`
	}

	val := OuterBlock{
		Attr1: "value_1",
		Attr2: "value_2",
		UnlabledBlock1: UnlabledBlock{
			Value: 1,
		},
		UnlabledBlock2: UnlabledBlock{
			Value: 2,
		},
		UnlabledBlock3: UnlabledBlock{
			Value: 3,
		},
		LabeledBlock1: LabeledBlock{
			Value: 4,
			Label: "label_a",
		},
		LabeledBlock2: LabeledBlock{
			Value: 5,
			Label: "label_b",
		},
		LabeledBlock3: LabeledBlock{
			Value: 6,
			Label: "label_c",
		},
	}

	t.Run("Map decode", func(t *testing.T) {
		var m map[string]interface{}
		require.NoError(t, value.Decode(value.Encode(val), &m))

		type object = map[string]interface{}

		expect := object{
			"attr_1": "value_1",
			"attr_2": "value_2",
			"unlabeled": object{
				"a": object{"value": 1},
				"b": object{"value": 2},
			},
			"other_unlabeled": object{"value": 3},
			"labeled": object{
				"a": object{
					"label_a": object{"value": 4},
				},
				"b": object{
					"label_b": object{"value": 5},
				},
			},
			"other_labeled": object{
				"label_c": object{"value": 6},
			},
		}

		require.Equal(t, m, expect)
	})

	t.Run("Object decode from other object", func(t *testing.T) {
		// Decode into a separate type which is structurally identical but not
		// literally the same.
		type OuterBlock2 OuterBlock

		var actualVal OuterBlock2
		require.NoError(t, value.Decode(value.Encode(val), &actualVal))
		require.Equal(t, val, OuterBlock(actualVal))
	})
}

func TestSliceOfBlocks(t *testing.T) {
	type UnlabledBlock struct {
		Value int `river:"value,attr"`
	}
	type LabeledBlock struct {
		Value int    `river:"value,attr"`
		Label string `river:",label"`
	}
	type OuterBlock struct {
		Attr1 string `river:"attr_1,attr"`
		Attr2 string `river:"attr_2,attr"`

		Unlabeled []UnlabledBlock `river:"unlabeled,block"`
		Labeled   []LabeledBlock  `river:"labeled,block"`
	}

	val := OuterBlock{
		Attr1: "value_1",
		Attr2: "value_2",
		Unlabeled: []UnlabledBlock{
			{Value: 1},
			{Value: 2},
			{Value: 3},
		},
		Labeled: []LabeledBlock{
			{Label: "label_a", Value: 4},
			{Label: "label_b", Value: 5},
			{Label: "label_c", Value: 6},
		},
	}

	t.Run("Map decode", func(t *testing.T) {
		var m map[string]interface{}
		require.NoError(t, value.Decode(value.Encode(val), &m))

		type object = map[string]interface{}
		type list = []interface{}

		expect := object{
			"attr_1": "value_1",
			"attr_2": "value_2",
			"unlabeled": list{
				object{"value": 1},
				object{"value": 2},
				object{"value": 3},
			},
			"labeled": object{
				"label_a": object{"value": 4},
				"label_b": object{"value": 5},
				"label_c": object{"value": 6},
			},
		}

		require.Equal(t, m, expect)
	})

	t.Run("Object decode from other object", func(t *testing.T) {
		// Decode into a separate type which is structurally identical but not
		// literally the same.
		type OuterBlock2 OuterBlock

		var actualVal OuterBlock2
		require.NoError(t, value.Decode(value.Encode(val), &actualVal))
		require.Equal(t, val, OuterBlock(actualVal))
	})
}

'''
'''--- pkg/river/internal/value/value_test.go ---
package value_test

import (
	"fmt"
	"testing"

	"github.com/grafana/agent/pkg/river/internal/value"
	"github.com/stretchr/testify/require"
)

// TestInterfacePointerReceiver tests various cases where Go values which only
// implement an interface for a pointer receiver are retained correctly
// throughout values.
func TestInterfacePointerReceiver(t *testing.T) {
	t.Run("Encode", func(t *testing.T) {
		pm := &pointerMarshaler{}

		val := value.Encode(pm)
		require.Equal(t, value.TypeString, val.Type())
		require.Equal(t, "Hello, world!", val.Text())
	})

	t.Run("From field", func(t *testing.T) {
		type Body struct {
			Data pointerMarshaler `river:"data,attr"`
		}

		b := &Body{}

		bodyVal := value.Encode(b)
		require.Equal(t, value.TypeObject, bodyVal.Type())

		val, ok := bodyVal.Key("data")
		require.True(t, ok, "data key did not exist")
		require.Equal(t, value.TypeString, val.Type())
		require.Equal(t, "Hello, world!", val.Text())
	})
}

type pointerMarshaler struct{}

func (*pointerMarshaler) MarshalText() ([]byte, error) {
	return []byte("Hello, world!"), nil
}

func TestValue_Call(t *testing.T) {
	t.Run("simple", func(t *testing.T) {
		add := func(a, b int) int { return a + b }
		addVal := value.Encode(add)

		res, err := addVal.Call(
			value.Int(15),
			value.Int(43),
		)
		require.NoError(t, err)
		require.Equal(t, int64(15+43), res.Int())
	})

	t.Run("fully variadic", func(t *testing.T) {
		add := func(nums ...int) int {
			var sum int
			for _, num := range nums {
				sum += num
			}
			return sum
		}
		addVal := value.Encode(add)

		t.Run("no args", func(t *testing.T) {
			res, err := addVal.Call()
			require.NoError(t, err)
			require.Equal(t, int64(0), res.Int())
		})

		t.Run("one arg", func(t *testing.T) {
			res, err := addVal.Call(value.Int(32))
			require.NoError(t, err)
			require.Equal(t, int64(32), res.Int())
		})

		t.Run("many args", func(t *testing.T) {
			res, err := addVal.Call(
				value.Int(32),
				value.Int(59),
				value.Int(12),
			)
			require.NoError(t, err)
			require.Equal(t, int64(32+59+12), res.Int())
		})
	})

	t.Run("partially variadic", func(t *testing.T) {
		add := func(firstNum int, nums ...int) int {
			sum := firstNum
			for _, num := range nums {
				sum += num
			}
			return sum
		}
		addVal := value.Encode(add)

		t.Run("no variadic args", func(t *testing.T) {
			res, err := addVal.Call(value.Int(52))
			require.NoError(t, err)
			require.Equal(t, int64(52), res.Int())
		})

		t.Run("one variadic arg", func(t *testing.T) {
			res, err := addVal.Call(value.Int(52), value.Int(32))
			require.NoError(t, err)
			require.Equal(t, int64(52+32), res.Int())
		})

		t.Run("many variadic args", func(t *testing.T) {
			res, err := addVal.Call(
				value.Int(32),
				value.Int(59),
				value.Int(12),
			)
			require.NoError(t, err)
			require.Equal(t, int64(32+59+12), res.Int())
		})
	})

	t.Run("returns error", func(t *testing.T) {
		failWhenTrue := func(val bool) (int, error) {
			if val {
				return 0, fmt.Errorf("function failed for a very good reason")
			}
			return 0, nil
		}
		funcVal := value.Encode(failWhenTrue)

		t.Run("no error", func(t *testing.T) {
			res, err := funcVal.Call(value.Bool(false))
			require.NoError(t, err)
			require.Equal(t, int64(0), res.Int())
		})

		t.Run("error", func(t *testing.T) {
			_, err := funcVal.Call(value.Bool(true))
			require.EqualError(t, err, "function failed for a very good reason")
		})
	})
}

'''
'''--- pkg/river/parser/error_test.go ---
package parser

import (
	"os"
	"path/filepath"
	"regexp"
	"strings"
	"testing"

	"github.com/grafana/agent/pkg/river/diag"
	"github.com/grafana/agent/pkg/river/scanner"
	"github.com/grafana/agent/pkg/river/token"
	"github.com/stretchr/testify/assert"
	"github.com/stretchr/testify/require"
)

// This file implements a parser test harness. The files in the testdata
// directory are parsed and the errors reported are compared against the error
// messages expected in the test files.
//
// Expected errors are indicated in the test files by putting a comment of the
// form /* ERROR "rx" */ immediately folloing an offending token. The harness
// will verify that an error matching the regular expression rx is reported at
// that source position.

// ERROR comments must be of the form /* ERROR "rx" */ and rx is a regular
// expression that matches the expected error message. The special form
// /* ERROR HERE "rx" */ must be used for error messages that appear immediately
// after a token rather than at a token's position.
var errRx = regexp.MustCompile(`^/\* *ERROR *(HERE)? *"([^"]*)" *\*/$`)

// expectedErrors collects the regular expressions of ERROR comments found in
// files and returns them as a map of error positions to error messages.
func expectedErrors(file *token.File, src []byte) map[token.Pos]string {
	errors := make(map[token.Pos]string)

	s := scanner.New(file, src, nil, scanner.IncludeComments)

	var (
		prev token.Pos // Position of last non-comment, non-terminator token
		here token.Pos // Position following after token at prev
	)

	for {
		pos, tok, lit := s.Scan()
		switch tok {
		case token.EOF:
			return errors
		case token.COMMENT:
			s := errRx.FindStringSubmatch(lit)
			if len(s) == 3 {
				pos := prev
				if s[1] == "HERE" {
					pos = here
				}
				errors[pos] = s[2]
			}
		case token.TERMINATOR:
			if lit == "\n" {
				break
			}
			fallthrough
		default:
			prev = pos
			var l int // Token length
			if isLiteral(tok) {
				l = len(lit)
			} else {
				l = len(tok.String())
			}
			here = prev.Add(l)
		}
	}
}

func isLiteral(t token.Token) bool {
	switch t {
	case token.IDENT, token.NUMBER, token.FLOAT, token.STRING:
		return true
	}
	return false
}

// compareErrors compes the map of expected error messages with the list of
// found errors and reports mismatches.
func compareErrors(t *testing.T, file *token.File, expected map[token.Pos]string, found diag.Diagnostics) {
	t.Helper()

	for _, checkError := range found {
		pos := file.Pos(checkError.StartPos.Offset)

		if msg, found := expected[pos]; found {
			// We expect a message at pos; check if it matches
			rx, err := regexp.Compile(msg)
			if !assert.NoError(t, err) {
				continue
			}
			assert.True(t,
				rx.MatchString(checkError.Message),
				"%s: %q does not match %q",
				checkError.StartPos, checkError.Message, msg,
			)
			delete(expected, pos) // Eliminate consumed error
		} else {
			assert.Fail(t,
				"Unexpected error",
				"unexpected error: %s: %s", checkError.StartPos.String(), checkError.Message,
			)
		}
	}

	// There should be no expected errors left
	if len(expected) > 0 {
		t.Errorf("%d errors not reported:", len(expected))
		for pos, msg := range expected {
			t.Errorf("%s: %s\n", file.PositionFor(pos), msg)
		}
	}
}

func TestErrors(t *testing.T) {
	list, err := os.ReadDir("testdata")
	require.NoError(t, err)

	for _, d := range list {
		name := d.Name()
		if d.IsDir() || !strings.HasSuffix(name, ".river") {
			continue
		}

		t.Run(name, func(t *testing.T) {
			checkErrors(t, filepath.Join("testdata", name))
		})
	}
}

func checkErrors(t *testing.T, filename string) {
	t.Helper()

	src, err := os.ReadFile(filename)
	require.NoError(t, err)

	p := newParser(filename, src)
	_ = p.ParseFile()

	expected := expectedErrors(p.file, src)
	compareErrors(t, p.file, expected, p.diags)
}

'''
'''--- pkg/river/parser/internal.go ---
package parser

import (
	"fmt"
	"strings"

	"github.com/grafana/agent/pkg/river/ast"
	"github.com/grafana/agent/pkg/river/diag"
	"github.com/grafana/agent/pkg/river/scanner"
	"github.com/grafana/agent/pkg/river/token"
)

// parser implements the River parser.
//
// It is only safe for callers to use exported methods as entrypoints for
// parsing.
//
// Each Parse* and parse* method will describe the EBNF grammar being used for
// parsing that nonterminal. The EBNF grammar will be written as LL(1) and
// should directly represent the code.
//
// The parser will continue on encountering errors to allow a more complete
// list of errors to be returned to the user. The resulting AST should be
// discarded if errors were encountered during parsing.
type parser struct {
	file     *token.File
	diags    diag.Diagnostics
	scanner  *scanner.Scanner
	comments []ast.CommentGroup

	pos token.Pos   // Current token position
	tok token.Token // Current token
	lit string      // Current token literal

	// Position of the last error written. Two parse errors on the same line are
	// ignored.
	lastError token.Position
}

// newParser creates a new parser which will parse the provided src.
func newParser(filename string, src []byte) *parser {
	file := token.NewFile(filename)

	p := &parser{
		file: file,
	}

	p.scanner = scanner.New(file, src, func(pos token.Pos, msg string) {
		p.diags.Add(diag.Diagnostic{
			Severity: diag.SeverityLevelError,
			StartPos: file.PositionFor(pos),
			Message:  msg,
		})
	}, scanner.IncludeComments)

	p.next()
	return p
}

// next advances the parser to the next non-comment token.
func (p *parser) next() {
	p.next0()

	for p.tok == token.COMMENT {
		p.consumeCommentGroup()
	}
}

// next0 advances the parser to the next token. next0 should not be used
// directly by parse methods; call next instead.
func (p *parser) next0() { p.pos, p.tok, p.lit = p.scanner.Scan() }

// consumeCommentGroup consumes a group of adjacent comments, adding it to p's
// comment list.
func (p *parser) consumeCommentGroup() {
	var list []*ast.Comment

	endline := p.pos.Position().Line
	for p.tok == token.COMMENT && p.pos.Position().Line <= endline+1 {
		var comment *ast.Comment
		comment, endline = p.consumeComment()
		list = append(list, comment)
	}

	p.comments = append(p.comments, ast.CommentGroup(list))
}

// consumeComment consumes a comment and returns it with the line number it
// ends on.
func (p *parser) consumeComment() (comment *ast.Comment, endline int) {
	endline = p.pos.Position().Line

	if p.lit[1] == '*' {
		// Block comments may end on a different line than where they start. Scan
		// the comment for newlines and adjust endline accordingly.
		//
		// NOTE: don't use range here, since range will unnecessarily decode
		// Unicode code points and slow down the parser.
		for i := 0; i < len(p.lit); i++ {
			if p.lit[i] == '\n' {
				endline++
			}
		}
	}

	comment = &ast.Comment{StartPos: p.pos, Text: p.lit}
	p.next0()
	return
}

// advance consumes tokens up to (but not including) the specified token.
// advance will stop consuming tokens if EOF is reached before to.
func (p *parser) advance(to token.Token) {
	for p.tok != token.EOF {
		if p.tok == to {
			return
		}
		p.next()
	}
}

// advanceAny consumes tokens up to (but not including) any of the tokens in
// the to set.
func (p *parser) advanceAny(to map[token.Token]struct{}) {
	for p.tok != token.EOF {
		if _, inSet := to[p.tok]; inSet {
			return
		}
		p.next()
	}
}

// expect consumes the next token. It records an error if the consumed token
// was not t.
func (p *parser) expect(t token.Token) (pos token.Pos, tok token.Token, lit string) {
	pos, tok, lit = p.pos, p.tok, p.lit
	if tok != t {
		p.addErrorf("expected %s, got %s", t, p.tok)
	}
	p.next()
	return
}

func (p *parser) addErrorf(format string, args ...interface{}) {
	pos := p.file.PositionFor(p.pos)

	// Ignore errors which occur on the same line.
	if p.lastError.Line == pos.Line {
		return
	}
	p.lastError = pos

	p.diags.Add(diag.Diagnostic{
		Severity: diag.SeverityLevelError,
		StartPos: pos,
		Message:  fmt.Sprintf(format, args...),
	})
}

// ParseFile parses an entire file.
//
//     File = Body
func (p *parser) ParseFile() *ast.File {
	body := p.parseBody(token.EOF)

	return &ast.File{
		Name:     p.file.Name(),
		Body:     body,
		Comments: p.comments,
	}
}

// parseBody parses a series of statements up to and including the "until"
// token, which terminates the body.
//
//     Body = [ Statement { terminator Statement } ]
func (p *parser) parseBody(until token.Token) ast.Body {
	var body ast.Body

	for p.tok != until && p.tok != token.EOF {
		stmt := p.parseStatement()
		if stmt != nil {
			body = append(body, stmt)
		}

		if p.tok == until {
			break
		}

		if p.tok != token.TERMINATOR {
			p.addErrorf("expected %s, got %s", token.TERMINATOR, p.tok)
			p.consumeStatement()
		}
		p.next()
	}

	return body
}

// consumeStatement consumes tokens for the remainder of a statement (i.e., up
// to but not including a terminator). consumeStatement will keep track of the
// number of {}, [], and () pairs, only returning after the count of pairs is
// <= 0.
func (p *parser) consumeStatement() {
	var curlyPairs, brackPairs, parenPairs int

	for p.tok != token.EOF {
		switch p.tok {
		case token.LCURLY:
			curlyPairs++
		case token.RCURLY:
			curlyPairs--
		case token.LBRACK:
			brackPairs++
		case token.RBRACK:
			brackPairs--
		case token.LPAREN:
			parenPairs++
		case token.RPAREN:
			parenPairs--
		}

		if p.tok == token.TERMINATOR {
			// Only return after we've consumed all pairs. It's possible for pairs to
			// be less than zero if our statement started in a surrounding pair.
			if curlyPairs <= 0 && brackPairs <= 0 && parenPairs <= 0 {
				return
			}
		}

		p.next()
	}
}

// parseStatement parses an individual statement within a body.
//
//     Statement = Attribute | Block
//     Attribute = identifier "=" Expression
//     Block     = BlockName "{" Body "}"
func (p *parser) parseStatement() ast.Stmt {
	blockName := p.parseBlockName()
	if blockName == nil {
		// parseBlockName failed; skip to the next identifier which would start a
		// new Statement.
		p.advance(token.IDENT)
		return nil
	}

	// p.tok is now the first token after the identifier in the attribute or
	// block name.
	switch p.tok {
	case token.ASSIGN: // Attribute
		p.next() // Consume "="

		if len(blockName.Fragments) != 1 {
			attrName := strings.Join(blockName.Fragments, ".")
			p.diags.Add(diag.Diagnostic{
				Severity: diag.SeverityLevelError,
				StartPos: blockName.Start.Position(),
				EndPos:   blockName.Start.Add(len(attrName) - 1).Position(),
				Message:  `attribute names may only consist of a single identifier with no "."`,
			})
		} else if blockName.LabelPos != token.NoPos {
			p.diags.Add(diag.Diagnostic{
				Severity: diag.SeverityLevelError,
				StartPos: blockName.LabelPos.Position(),
				// Add 1 to the end position to add in the end quote, which is stripped from the label value.
				EndPos:  blockName.LabelPos.Add(len(blockName.Label) + 1).Position(),
				Message: `attribute names may not have labels`,
			})
		}

		return &ast.AttributeStmt{
			Name: &ast.Ident{
				Name:    blockName.Fragments[0],
				NamePos: blockName.Start,
			},
			Value: p.ParseExpression(),
		}

	case token.LCURLY: // Block
		block := &ast.BlockStmt{
			Name:    blockName.Fragments,
			NamePos: blockName.Start,
			Label:   blockName.Label,
		}

		block.LCurlyPos, _, _ = p.expect(token.LCURLY)
		block.Body = p.parseBody(token.RCURLY)
		block.RCurlyPos, _, _ = p.expect(token.RCURLY)

		return block

	default:
		if blockName.ValidAttribute() {
			// The blockname could be used for an attribute or a block (no label,
			// only one name fragment), so inform the user of both cases.
			p.addErrorf("expected attribute assignment or block body, got %s", p.tok)
		} else {
			p.addErrorf("expected block body, got %s", p.tok)
		}

		// Give up on this statement and skip to the next identifier.
		p.advance(token.IDENT)
		return nil
	}
}

// parseBlockName parses the name used for a block.
//
//     BlockName = identifier { "." identifier } [ string ]
func (p *parser) parseBlockName() *blockName {
	if p.tok != token.IDENT {
		p.addErrorf("expected identifier, got %s", p.tok)
		return nil
	}

	var bn blockName

	bn.Fragments = append(bn.Fragments, p.lit) // Append first identifier
	bn.Start = p.pos
	p.next()

	// { "." identifier }
	for p.tok == token.DOT {
		p.next() // consume "."

		if p.tok != token.IDENT {
			p.addErrorf("expected identifier, got %s", p.tok)

			// Continue here to parse as much as possible, even though the block name
			// will be malformed.
		}

		bn.Fragments = append(bn.Fragments, p.lit)
		p.next()
	}

	// [ string ]
	if p.tok != token.ASSIGN && p.tok != token.LCURLY {
		if p.tok == token.STRING {
			// Strip the quotes if it's non empty. We then require any non-empty
			// label to be a valid identifier.
			if len(p.lit) > 2 {
				bn.Label = p.lit[1 : len(p.lit)-1]
				if !isValidIdentifier(bn.Label) {
					p.addErrorf("expected block label to be a valid identifier")
				}
			}
			bn.LabelPos = p.pos
		} else {
			p.addErrorf("expected block label, got %s", p.tok)
		}
		p.next()
	}

	return &bn
}

type blockName struct {
	Fragments []string // Name fragments (i.e., `a.b.c`)
	Label     string   // Optional user label

	Start    token.Pos
	LabelPos token.Pos
}

// ValidAttribute returns true if the blockName can be used as an attribute
// name.
func (n blockName) ValidAttribute() bool {
	return len(n.Fragments) == 1 && n.Label == ""
}

// ParseExpression parses a single expression.
//
//     Expression = BinOpExpr
func (p *parser) ParseExpression() ast.Expr {
	return p.parseBinOp(1)
}

// parseBinOp is the entrypoint for binary expressions. If there is no binary
// expressions in the current state, a single operand will be returned instead.
//
//     BinOpExpr = OrExpr
//     OrExpr    = AndExpr { "||"   AndExpr }
//     AndExpr   = CmpExpr { "&&"   CmpExpr }
//     CmpExpr   = AddExpr { cmp_op AddExpr }
//     AddExpr   = MulExpr { add_op MulExpr }
//     MulExpr   = PowExpr { mul_op PowExpr }
//
// parseBinOp avoids the need for multiple nonterminal functions by providing
// context for operator precedence in recursive calls. inPrec specifies the
// incoming operator precedence. On the first call to parseBinOp, inPrec should
// be 1.
//
// parseBinOp can only handle left-associative operators, so PowExpr is handled
// by parsePowExpr.
func (p *parser) parseBinOp(inPrec int) ast.Expr {
	// The EBNF documented by the function can be generalized into:
	//
	//     CurPrecExpr = NextPrecExpr { cur_prec_ops NextPrecExpr }
	//
	// The code below implements this specific grammar, continually collecting
	// everything at the same precedence level into the LHS of the expression
	// while recursively calling parseBinOp for higher-precedence operations.

	lhs := p.parsePowExpr()

	for {
		tok, pos, prec := p.tok, p.pos, p.tok.BinaryPrecedence()
		if prec < inPrec {
			// The next operator is lower precedence; drop up a level in our call
			// stack.
			return lhs
		}
		p.next() // Consume the operator

		// Recurse with a higher precedence level, which ensures that operators at
		// the same precedence level don't get handled in the recursive call.
		rhs := p.parseBinOp(prec + 1)

		lhs = &ast.BinaryExpr{
			Left:    lhs,
			Kind:    tok,
			KindPos: pos,
			Right:   rhs,
		}
	}
}

// parsePowExpr is like parseBinOp but handles the right-associative pow
// operator.
//
//   PowExpr = UnaryExpr [ "^" PowExpr ]
func (p *parser) parsePowExpr() ast.Expr {
	lhs := p.parseUnaryExpr()

	if p.tok == token.POW {
		pos := p.pos
		p.next() // Consume ^

		return &ast.BinaryExpr{
			Left:    lhs,
			Kind:    token.POW,
			KindPos: pos,
			Right:   p.parsePowExpr(),
		}
	}

	return lhs
}

// parseUnaryExpr parses a unary expression.
//
//     UnaryExpr = OperExpr | unary_op UnaryExpr
//
//     OperExpr   = PrimaryExpr { AccessExpr | IndexExpr | CallExpr }
//     AccessExpr = "." identifier
//     IndexExpr  = "[" Expression "]"
//     CallExpr   = "(" [ ExpressionList ] ")"
func (p *parser) parseUnaryExpr() ast.Expr {
	if isUnaryOp(p.tok) {
		op, pos := p.tok, p.pos
		p.next() // Consume op

		return &ast.UnaryExpr{
			Kind:    op,
			KindPos: pos,
			Value:   p.parseUnaryExpr(),
		}
	}

	primary := p.parsePrimaryExpr()

NextOper:
	for {
		switch p.tok {
		case token.DOT: // AccessExpr
			p.next()
			namePos, _, name := p.expect(token.IDENT)

			primary = &ast.AccessExpr{
				Value: primary,
				Name: &ast.Ident{
					Name:    name,
					NamePos: namePos,
				},
			}

		case token.LBRACK: // IndexExpr
			lBrack, _, _ := p.expect(token.LBRACK)
			index := p.ParseExpression()
			rBrack, _, _ := p.expect(token.RBRACK)

			primary = &ast.IndexExpr{
				Value:     primary,
				LBrackPos: lBrack,
				Index:     index,
				RBrackPos: rBrack,
			}

		case token.LPAREN: // CallExpr
			var args []ast.Expr

			lParen, _, _ := p.expect(token.LPAREN)
			if p.tok != token.RPAREN {
				args = p.parseExpressionList(token.RPAREN)
			}
			rParen, _, _ := p.expect(token.RPAREN)

			primary = &ast.CallExpr{
				Value:     primary,
				LParenPos: lParen,
				Args:      args,
				RParenPos: rParen,
			}

		case token.STRING, token.LCURLY:
			// A user might be trying to assign a block to an attribute. let's
			// attempt to parse the remainder as a block to tell them something is
			// wrong.
			//
			// If we can't parse the remainder of the expression as a block, we give
			// up and parse the remainder of the entire statement.
			if p.tok == token.STRING {
				p.next()
			}
			if _, tok, _ := p.expect(token.LCURLY); tok != token.LCURLY {
				p.consumeStatement()
				return primary
			}
			p.parseBody(token.RCURLY)

			end, tok, _ := p.expect(token.RCURLY)
			if tok != token.RCURLY {
				p.consumeStatement()
				return primary
			}

			p.diags.Add(diag.Diagnostic{
				Severity: diag.SeverityLevelError,
				StartPos: ast.StartPos(primary).Position(),
				EndPos:   end.Position(),
				Message:  "cannot use a block as an expression",
			})

		default:
			break NextOper
		}
	}

	return primary
}

func isUnaryOp(tok token.Token) bool {
	switch tok {
	case token.NOT, token.SUB:
		return true
	default:
		return false
	}
}

// parsePrimaryExpr parses a primary expression.
//
//     PrimaryExpr = LiteralValue | ArrayExpr | ObjectExpr
//
//     LiteralValue = identifier | string | number | float | bool | null |
//                    "(" Expression ")"
//
//     ArrayExpr  = "[" [ ExpressionList ] "]"
//     ObjectExpr = "{" [ FieldList ] "}"
func (p *parser) parsePrimaryExpr() ast.Expr {
	switch p.tok {
	case token.IDENT:
		res := &ast.IdentifierExpr{
			Ident: &ast.Ident{
				Name:    p.lit,
				NamePos: p.pos,
			},
		}
		p.next()
		return res

	case token.STRING, token.NUMBER, token.FLOAT, token.BOOL, token.NULL:
		res := &ast.LiteralExpr{
			Kind:     p.tok,
			Value:    p.lit,
			ValuePos: p.pos,
		}
		p.next()
		return res

	case token.LPAREN:
		lParen, _, _ := p.expect(token.LPAREN)
		expr := p.ParseExpression()
		rParen, _, _ := p.expect(token.RPAREN)

		return &ast.ParenExpr{
			LParenPos: lParen,
			Inner:     expr,
			RParenPos: rParen,
		}

	case token.LBRACK:
		var res ast.ArrayExpr

		res.LBrackPos, _, _ = p.expect(token.LBRACK)
		if p.tok != token.RBRACK {
			res.Elements = p.parseExpressionList(token.RBRACK)
		}
		res.RBrackPos, _, _ = p.expect(token.RBRACK)
		return &res

	case token.LCURLY:
		var res ast.ObjectExpr

		res.LCurlyPos, _, _ = p.expect(token.LCURLY)
		if p.tok != token.RBRACK {
			res.Fields = p.parseFieldList(token.RCURLY)
		}
		res.RCurlyPos, _, _ = p.expect(token.RCURLY)
		return &res
	}

	p.addErrorf("expected expression, got %s", p.tok)
	res := &ast.LiteralExpr{Kind: token.NULL, Value: "null", ValuePos: p.pos}
	p.advanceAny(statementEnd) // Eat up the rest of the line
	return res
}

var statementEnd = map[token.Token]struct{}{
	token.TERMINATOR: {},
	token.RPAREN:     {},
	token.RCURLY:     {},
	token.RBRACK:     {},
	token.COMMA:      {},
}

// parseExpressionList parses a list of expressions.
//
//     ExpressionList = Expression { "," Expression } [ "," ]
func (p *parser) parseExpressionList(until token.Token) []ast.Expr {
	var exprs []ast.Expr

	for p.tok != until && p.tok != token.EOF {
		exprs = append(exprs, p.ParseExpression())

		if p.tok == until {
			break
		}
		if p.tok != token.COMMA {
			p.addErrorf("missing ',' in expression list")
		}
		p.next()
	}

	return exprs
}

// parseFieldList parses a list of fields in an object.
//
//     FieldList = Field { "," Field } [ "," ]
func (p *parser) parseFieldList(until token.Token) []*ast.ObjectField {
	var fields []*ast.ObjectField

	for p.tok != until && p.tok != token.EOF {
		fields = append(fields, p.parseField())

		if p.tok == until {
			break
		}
		if p.tok != token.COMMA {
			p.addErrorf("missing ',' in field list")
		}
		p.next()
	}

	return fields
}

// parseField parses a field in an object.
//
//    Field = ( string | identifier ) "=" Expression
func (p *parser) parseField() *ast.ObjectField {
	if p.tok != token.STRING && p.tok != token.IDENT {
		p.addErrorf("expected field name (string or identifier), got %s", p.tok)
		p.advanceAny(fieldStarter)
		return nil
	}

	field := &ast.ObjectField{
		Name: &ast.Ident{
			Name:    p.lit,
			NamePos: p.pos,
		},
	}
	if p.tok == token.STRING && len(p.lit) > 2 {
		// The field name a string literal; unwrap the quotes.
		field.Name.Name = p.lit[1 : len(p.lit)-1]
		field.Quoted = true
	}
	p.next() // Consume field name

	p.expect(token.ASSIGN)

	field.Value = p.ParseExpression()
	return field
}

var fieldStarter = map[token.Token]struct{}{
	token.STRING: {},
	token.IDENT:  {},
}

func isValidIdentifier(in string) bool {
	s := scanner.New(nil, []byte(in), nil, 0)
	_, tok, lit := s.Scan()
	return tok == token.IDENT && lit == in
}

'''
'''--- pkg/river/parser/internal_test.go ---
package parser

import (
	"testing"

	"github.com/stretchr/testify/assert"
)

func TestObjectFieldName(t *testing.T) {
	tt := []string{
		`field_a   = 5`,
		`"field_a" = 5`, // Quotes should be removed from the field name
	}

	for _, tc := range tt {
		p := newParser(t.Name(), []byte(tc))

		res := p.parseField()

		assert.Equal(t, "field_a", res.Name.Name)
	}
}

'''
'''--- pkg/river/parser/parser.go ---
// Package parser implements utilities for parsing River configuration files.
package parser

import (
	"github.com/grafana/agent/pkg/river/ast"
)

// ParseFile parses an entire River configuration file. The data parameter
// should hold the file contents to parse, while the filename parameter is used
// for reporting errors.
//
// If an error was encountered during parsing, the returned AST will be nil and
// err will be an diag.Diagnostics all the errors encountered during parsing.
func ParseFile(filename string, data []byte) (*ast.File, error) {
	p := newParser(filename, data)

	f := p.ParseFile()
	if len(p.diags) > 0 {
		return nil, p.diags
	}
	return f, nil
}

// ParseExpression parses a single River expression from expr.
//
// If an error was encountered during parsing, the returned expression will be
// nil and err will be an ErrorList with all the errors encountered during
// parsing.
func ParseExpression(expr string) (ast.Expr, error) {
	p := newParser("", []byte(expr))

	e := p.ParseExpression()
	if len(p.diags) > 0 {
		return nil, p.diags
	}
	return e, nil
}

'''
'''--- pkg/river/parser/parser_test.go ---
package parser

import (
	"io/fs"
	"os"
	"path/filepath"
	"testing"

	"github.com/stretchr/testify/require"
)

func FuzzParser(f *testing.F) {
	filepath.WalkDir("./testdata/valid", func(path string, d fs.DirEntry, _ error) error {
		if d.IsDir() {
			return nil
		}

		bb, err := os.ReadFile(path)
		require.NoError(f, err)
		f.Add(bb)
		return nil
	})

	f.Fuzz(func(t *testing.T, input []byte) {
		p := newParser(t.Name(), input)

		_ = p.ParseFile()
		if len(p.diags) > 0 {
			t.SkipNow()
		}
	})
}

// TestValid parses every *.river file in testdata, which is expected to be
// valid.
func TestValid(t *testing.T) {
	filepath.WalkDir("./testdata/valid", func(path string, d fs.DirEntry, _ error) error {
		if d.IsDir() {
			return nil
		}

		t.Run(filepath.Base(path), func(t *testing.T) {
			bb, err := os.ReadFile(path)
			require.NoError(t, err)

			p := newParser(path, bb)

			res := p.ParseFile()
			require.NotNil(t, res)
			require.Len(t, p.diags, 0)
		})

		return nil
	})
}

func TestParseExpressions(t *testing.T) {
	tt := map[string]string{
		"literal number": `10`,
		"literal float":  `15.0`,
		"literal string": `"Hello, world!"`,
		"literal ident":  `some_ident`,
		"literal null":   `null`,
		"literal true":   `true`,
		"literal false":  `false`,

		"empty array":          `[]`,
		"array one element":    `[1]`,
		"array many elements":  `[0, 1, 2, 3]`,
		"array trailing comma": `[0, 1, 2, 3,]`,
		"nested array":         `[[0, 1, 2], [3, 4, 5]]`,
		"array multiline": `[
			0,
			1, 
			2,
		]`,

		"empty object":           `{}`,
		"object one field":       `{ field_a = 5 }`,
		"object multiple fields": `{ field_a = 5, field_b = 10 }`,
		"object trailing comma":  `{ field_a = 5, field_b = 10, }`,
		"nested objects":         `{ field_a = { nested_field = 100 } }`,
		"object multiline": `{
			field_a = 5,
			field_b = 10,
		}`,

		"unary not": `!true`,
		"unary neg": `-5`,

		"math":         `1 + 2 - 3 * 4 / 5 % 6`,
		"compare ops":  `1 == 2 != 3 < 4 > 5 <= 6 >= 7`,
		"logical ops":  `true || false && true`,
		"pow operator": "1 ^ 2 ^ 3",

		"field access":   `a.b.c.d`,
		"element access": `a[0][1][2]`,

		"call no args":             `a()`,
		"call one arg":             `a(1)`,
		"call multiple args":       `a(1,2,3)`,
		"call with trailing comma": `a(1,2,3,)`,
		"call multiline": `a(
			1,
			2,
			3,
		)`,

		"parens": `(1 + 5) * 100`,

		"mixed exprsssion": `(a.b.c)(1, 3 * some_list[magic_index * 2]).resulting_field`,
	}

	for name, input := range tt {
		t.Run(name, func(t *testing.T) {
			p := newParser(name, []byte(input))

			res := p.ParseExpression()
			require.NotNil(t, res)
			require.Len(t, p.diags, 0)
		})
	}
}

'''
'''--- pkg/river/printer/printer.go ---
// Package printer contains utilities for pretty-printing River ASTs.
package printer

import (
	"fmt"
	"io"
	"math"
	"text/tabwriter"

	"github.com/grafana/agent/pkg/river/ast"
	"github.com/grafana/agent/pkg/river/token"
)

// Config configures behavior of the printer.
type Config struct {
	Indent int // Identation to apply to all emitted code. Default 0.
}

// Fprint pretty-prints the specified node to w. The Node type must be an
// *ast.File, ast.Body, or a type that implements ast.Stmt or ast.Expr.
func (c *Config) Fprint(w io.Writer, node ast.Node) (err error) {
	var p printer
	p.Init(c)

	// Pass all of our text through a trimmer to ignore trailing whitespace.
	w = &trimmer{next: w}

	if err = (&walker{p: &p}).Walk(node); err != nil {
		return
	}

	// Call flush one more time to write trailing comments.
	p.flush(token.Position{
		Offset: math.MaxInt,
		Line:   math.MaxInt,
		Column: math.MaxInt,
	}, token.EOF)

	w = tabwriter.NewWriter(w, 0, 8, 1, ' ', tabwriter.DiscardEmptyColumns|tabwriter.TabIndent)

	if _, err = w.Write(p.output); err != nil {
		return
	}
	if tw, _ := w.(*tabwriter.Writer); tw != nil {
		// Flush tabwriter if defined
		err = tw.Flush()
	}

	return
}

// Fprint pretty-prints the specified node to w. The Node type must be an
// *ast.File, ast.Body, or a type that implements ast.Stmt or ast.Expr.
func Fprint(w io.Writer, node ast.Node) error {
	c := &Config{}
	return c.Fprint(w, node)
}

// The printer writes lexical tokens and whitespace to an internal buffer.
// Comments are written by the printer itself, while all other tokens and
// formatting characters are sent through calls to Write.
//
// Internally, printer depends on a tabwriter for formatting text and aligning
// runs of characters. Horizontal '\t' and vertical '\v' tab characters are
// used to introduce new columns in the row. Runs of characters are stopped
// be either introducing a linefeed '\f' or by having a line with a different
// number of columns from the previous line. See the text/tabwriter package for
// more information on the elastic tabstop algorithm it uses for formatting
// text.
type printer struct {
	cfg Config

	// State variables

	output  []byte
	indent  int         // Current indentation level
	lastTok token.Token // Last token printed (token.LITERAL if it's whitespace)

	// Whitespace holds a buffer of whitespace characters to print prior to the
	// next non-whitespace token. Whitespace is held in a buffer to avoid
	// printing unnecessary whitespace at the end of a file.
	whitespace []whitespace

	// comments stores comments to be processed as elements are printed.
	comments commentInfo

	// pos is an approximation of the current position in AST space, and is used
	// to determine space between AST elements (e.g., if a comment should come
	// before a token). pos automatically as elements are written and can be manually
	// set to guarantee an accurate position by passing a token.Pos to Write.
	pos  token.Position
	last token.Position // Last pos written to output (through writeString)

	// out is an accurate representation of the current position in output space,
	// used to inject extra formatting like indentation based on the output
	// position.
	//
	// out may differ from pos in terms of whitespace.
	out token.Position
}

type commentInfo struct {
	list []ast.CommentGroup
	idx  int
	cur  ast.CommentGroup
	pos  token.Pos
}

func (ci *commentInfo) commentBefore(next token.Position) bool {
	return ci.pos != token.NoPos && ci.pos.Offset() <= next.Offset
}

// nextComment preloads the next comment.
func (ci *commentInfo) nextComment() {
	for ci.idx < len(ci.list) {
		c := ci.list[ci.idx]
		ci.idx++
		if len(c) > 0 {
			ci.cur = c
			ci.pos = ast.StartPos(c[0])
			return
		}
	}
	ci.pos = token.NoPos
}

// Init initializes the printer for printing. Init is intended to be called
// once per printer and doesn't fully reset its state.
func (p *printer) Init(cfg *Config) {
	p.cfg = *cfg
	p.pos = token.Position{Line: 1, Column: 1}
	p.out = token.Position{Line: 1, Column: 1}
	// Capacity is set low since most whitespace sequences are short.
	p.whitespace = make([]whitespace, 0, 16)
}

// SetComments set the comments to use.
func (p *printer) SetComments(comments []ast.CommentGroup) {
	p.comments = commentInfo{
		list: comments,
		idx:  0,
		pos:  token.NoPos,
	}
	p.comments.nextComment()
}

// Write writes a list of writable arguments to the printer.
//
// Arguments can be one of the types described below:
//
// If arg is a whitespace value, it is accumulated into a buffer and flushed
// only after a non-whitespace value is processed. The whitespace buffer will
// be forcibly flushed if the buffer becomes full without writing a
// non-whitespace token.
//
// If arg is an *ast.IdentifierExpr, *ast.LiteralExpr, or a token.Token, the
// human-readable representation of that value will be written.
//
// When writing text, comments which need to appear before that text in
// AST-space are written first, followed by leftover whitespace and then the
// text to write. The written text will update the AST-space position.
//
// If arg is a token.Pos, the AST-space position of the printer is updated to
// the provided Pos. Writing token.Pos values can help make sure the printer's
// AST-space position is accurate, as AST-space position is otherwise an
// estimation based on written data.
func (p *printer) Write(args ...interface{}) {
	for _, arg := range args {
		var (
			data  string
			isLit bool
		)

		switch arg := arg.(type) {
		case whitespace:
			// Whitespace token; add it to our token buffer. Note that a whitespace
			// token is different than the actual whitespace which will get written
			// (e.g., wsIndent increases indentation level by one instead of setting
			// it to one.)
			if arg == wsIgnore {
				continue
			}
			i := len(p.whitespace)
			if i == cap(p.whitespace) {
				// We built up too much whitespace; this can happen if too many calls
				// to Write happen without appending a non-comment token. We will
				// force-flush the existing whitespace to avoid a panic.
				//
				// Ideally this line is never hit based on how we walk the AST, but
				// it's kept for safety.
				p.writeWritespace(i)
				i = 0
			}
			p.whitespace = p.whitespace[0 : i+1]
			p.whitespace[i] = arg
			p.lastTok = token.LITERAL
			continue

		case *ast.Ident:
			data = arg.Name
			p.lastTok = token.IDENT

		case *ast.LiteralExpr:
			data = arg.Value
			p.lastTok = arg.Kind

		case token.Pos:
			if arg.Valid() {
				p.pos = arg.Position()
			}
			// Don't write anything; token.Pos is an instruction and doesn't include
			// any text to write.
			continue

		case token.Token:
			s := arg.String()
			data = s

			// We will need to inject whitespace if the previous token and the
			// current token would combine into a single token when re-scanned. This
			// ensures that the sequence of tokens emitted by the output of the
			// printer match the sequence of tokens from the input.
			if mayCombine(p.lastTok, s[0]) {
				if len(p.whitespace) != 0 {
					// It shouldn't be possible for the whitespace buffer to be not empty
					// here; p.lastTok would've had to been a non-whitespace token and so
					// whitespace would've been flushed when it was written to the output
					// buffer.
					panic("whitespace buffer not empty")
				}
				p.whitespace = p.whitespace[0:1]
				p.whitespace[0] = ' '
			}
			p.lastTok = arg

		default:
			panic(fmt.Sprintf("printer: unsupported argument %v (%T)\n", arg, arg))
		}

		next := p.pos

		p.flush(next, p.lastTok)
		p.writeString(next, data, isLit)
	}
}

// mayCombine returns true if two tokes must not be combined, because combining
// them would format in a different token sequence being generated.
func mayCombine(prev token.Token, next byte) (b bool) {
	switch prev {
	case token.NUMBER:
		return next == '.' // 1.
	case token.DIV:
		return next == '*' // /*
	default:
		return false
	}
}

// flush prints any pending comments and whitespace occurring textually before
// the position of the next token tok. The flush result indicates if a newline
// was written or if a formfeed \f character was dropped from the whitespace
// buffer.
func (p *printer) flush(next token.Position, tok token.Token) {
	if p.comments.commentBefore(next) {
		p.injectComments(next, tok)
	} else if tok != token.EOF {
		// Write all remaining whitespace.
		p.writeWritespace(len(p.whitespace))
	}
}

func (p *printer) injectComments(next token.Position, tok token.Token) {
	var lastComment *ast.Comment

	for p.comments.commentBefore(next) {
		for _, c := range p.comments.cur {
			p.writeCommentPrefix(next, c)
			p.writeComment(next, c)
			lastComment = c
		}
		p.comments.nextComment()
	}

	p.writeCommentSuffix(next, tok, lastComment)
}

// writeCommentPrefix writes whitespace that should appear before c.
func (p *printer) writeCommentPrefix(next token.Position, c *ast.Comment) {
	if len(p.output) == 0 {
		// The comment is the first thing written to the output. Don't write any
		// whitespace before it.
		return
	}

	cPos := c.StartPos.Position()

	if cPos.Line == p.last.Line {
		// Our comment is on the same line as the last token. Write a separator
		// between the last token and the comment.
		separator := byte('\t')
		if cPos.Line == next.Line {
			// The comment is on the same line as the next token, which means it has
			// to be a block comment (since line comments run to the end of the
			// line.) Use a space as the separator instead since a tab in the middle
			// of a line between comments would look weird.
			separator = byte(' ')
		}
		p.writeByte(separator, 1)
	} else {
		// Our comment is on a different line from the last token. First write
		// pending whitespace from the last token up to the first newline.
		var wsCount int

		for i, ws := range p.whitespace {
			switch ws {
			case wsBlank, wsVTab:
				// Drop any whitespace before the comment.
				p.whitespace[i] = wsIgnore
			case wsIndent, wsUnindent:
				// Allow indentation to be applied.
				continue
			case wsNewline, wsFormfeed:
				// Drop the whitespace since we're about to write our own.
				p.whitespace[i] = wsIgnore
			}
			wsCount = i
			break
		}
		p.writeWritespace(wsCount)

		var newlines int
		if cPos.Valid() && p.last.Valid() {
			newlines = cPos.Line - p.last.Line
		}
		if newlines > 0 {
			p.writeByte('\f', newlineLimit(newlines))
		}
	}
}

func (p *printer) writeComment(next token.Position, c *ast.Comment) {
	p.writeString(c.StartPos.Position(), c.Text, true)
}

// writeCommentSuffix writes any whitespace necessary between the last comment
// and next. lastComment should be the final comment written.
func (p *printer) writeCommentSuffix(next token.Position, tok token.Token, lastComment *ast.Comment) {
	if tok == token.EOF {
		// We don't want to add any blank newlines before the end of the file;
		// return early.
		return
	}

	// If our final comment is a block comment and is on the same line as the
	// next token, add a space as a suffix to separate them.
	lastCommentPos := ast.EndPos(lastComment).Position()
	if lastComment.Text[1] == '*' && next.Line == lastCommentPos.Line {
		p.writeByte(' ', 1)
	}

	newlines := next.Line - p.last.Line

	for i, ws := range p.whitespace {
		switch ws {
		case wsBlank, wsVTab:
			p.whitespace[i] = wsIgnore
		case wsIndent, wsUnindent:
			continue
		case wsNewline, wsFormfeed:
			p.whitespace[i] = wsIgnore
		}
	}
	p.writeWritespace(len(p.whitespace))

	// Write newlines as long as the next token isn't EOF (so that there's no
	// blank newlines at the end of the file).
	if newlines > 0 {
		p.writeByte('\n', newlineLimit(newlines))
	}
}

// writeString writes the literal string s into the printer's output.
// Formatting characters in s such as '\t' and '\n' will be interpreted by
// underlying tabwriter unless isLit is set.
func (p *printer) writeString(pos token.Position, s string, isLit bool) {
	if p.out.Column == 1 {
		// We haven't written any text to this line yet; prepend our indentation
		// for the line.
		p.writeIndent()
	}

	if pos.Valid() {
		// Update p.pos if pos is valid. This is done *after* handling indentation
		// since we want to interpret pos as the literal position for s (and
		// writeIndent will update p.pos).
		p.pos = pos
	}

	if isLit {
		// Wrap our literal string in tabwriter.Escape if it's meant to be written
		// without interpretation by the tabwriter.
		p.output = append(p.output, tabwriter.Escape)

		defer func() {
			p.output = append(p.output, tabwriter.Escape)
		}()
	}

	p.output = append(p.output, s...)

	var (
		newlines       int
		lastNewlineIdx int
	)

	for i := 0; i < len(s); i++ {
		if ch := s[i]; ch == '\n' || ch == '\f' {
			newlines++
			lastNewlineIdx = i
		}
	}

	p.pos.Offset += len(s)

	if newlines > 0 {
		p.pos.Line += newlines
		p.out.Line += newlines

		newColumn := len(s) - lastNewlineIdx
		p.pos.Column = newColumn
		p.out.Column = newColumn
	} else {
		p.pos.Column += len(s)
		p.out.Column += len(s)
	}

	p.last = p.pos
}

func (p *printer) writeIndent() {
	depth := p.cfg.Indent + p.indent
	for i := 0; i < depth; i++ {
		p.output = append(p.output, '\t')
	}

	p.pos.Offset += depth
	p.pos.Column += depth
	p.out.Column += depth
}

// writeByte writes ch n times to the output, updating the position of the
// printer. writeByte is only used for writing whitespace characters.
func (p *printer) writeByte(ch byte, n int) {
	if p.out.Column == 1 {
		p.writeIndent()
	}

	for i := 0; i < n; i++ {
		p.output = append(p.output, ch)
	}

	// Update positions.
	p.pos.Offset += n
	if ch == '\n' || ch == '\f' {
		p.pos.Line += n
		p.out.Line += n
		p.pos.Column = 1
		p.out.Column = 1
		return
	}
	p.pos.Column += n
	p.out.Column += n
}

// writeWhitespace writes the first n whitespace entries in the whitespace
// buffer.
//
// writeWritespace is only safe to be called when len(p.whitespace) >= n.
func (p *printer) writeWritespace(n int) {
	for i := 0; i < n; i++ {
		switch ch := p.whitespace[i]; ch {
		case wsIgnore: // no-op
		case wsIndent:
			p.indent++
		case wsUnindent:
			p.indent--
			if p.indent < 0 {
				panic("printer: negative indentation")
			}
		default:
			p.writeByte(byte(ch), 1)
		}
	}

	// Shift remaining entries down
	l := copy(p.whitespace, p.whitespace[n:])
	p.whitespace = p.whitespace[:l]
}

const maxNewlines = 2

// newlineLimit limits a newline count to maxNewlines.
func newlineLimit(count int) int {
	if count > maxNewlines {
		count = maxNewlines
	}
	return count
}

// whitespace represents a whitespace token to write to the printer's internal
// buffer.
type whitespace byte

const (
	wsIgnore   = whitespace(0)
	wsBlank    = whitespace(' ')
	wsVTab     = whitespace('\v')
	wsNewline  = whitespace('\n')
	wsFormfeed = whitespace('\f')
	wsIndent   = whitespace('>')
	wsUnindent = whitespace('<')
)

func (ws whitespace) String() string {
	switch ws {
	case wsIgnore:
		return "wsIgnore"
	case wsBlank:
		return "wsBlank"
	case wsVTab:
		return "wsVTab"
	case wsNewline:
		return "wsNewline"
	case wsFormfeed:
		return "wsFormfeed"
	case wsIndent:
		return "wsIndent"
	case wsUnindent:
		return "wsUnindent"
	default:
		return fmt.Sprintf("whitespace(%d)", ws)
	}
}

'''
'''--- pkg/river/printer/printer_test.go ---
package printer_test

import (
	"bytes"
	"io/fs"
	"os"
	"path/filepath"
	"strings"
	"testing"
	"unicode"

	"github.com/grafana/agent/pkg/river/parser"
	"github.com/grafana/agent/pkg/river/printer"
	"github.com/stretchr/testify/require"
)

func TestPrinter(t *testing.T) {
	filepath.WalkDir("testdata", func(path string, d fs.DirEntry, _ error) error {
		if d.IsDir() {
			return nil
		}

		if strings.HasSuffix(path, ".in") {
			inputFile := path
			expectFile := strings.TrimSuffix(path, ".in") + ".expect"

			inputBB, err := os.ReadFile(inputFile)
			require.NoError(t, err)
			expectBB, err := os.ReadFile(expectFile)
			require.NoError(t, err)

			caseName := filepath.Base(path)
			caseName = strings.TrimSuffix(caseName, ".in")

			t.Run(caseName, func(t *testing.T) {
				testPrinter(t, inputBB, expectBB)
			})
		}

		return nil
	})
}

func testPrinter(t *testing.T, input, expect []byte) {
	f, err := parser.ParseFile(t.Name()+".rvr", input)
	require.NoError(t, err)

	var buf bytes.Buffer
	require.NoError(t, printer.Fprint(&buf, f))

	trimmed := strings.TrimRightFunc(string(expect), unicode.IsSpace)
	require.Equal(t, trimmed, buf.String(), "%s", buf.String())
}

'''
'''--- pkg/river/printer/trimmer.go ---
package printer

import (
	"io"
	"text/tabwriter"
)

// A trimmer is an io.Writer which filters tabwriter.Escape characters,
// trailing blanks and tabs from lines, and converting \f and \v characters
// into \n and \t (if no text/tabwriter is used when printing).
//
// Text wrapped by tabwriter.Escape characters is written to the underlying
// io.Writer unmodified.
type trimmer struct {
	next  io.Writer
	state int
	space []byte
}

const (
	trimStateSpace  = iota // Trimmer is reading space characters
	trimStateEscape        // Trimmer is reading escaped characters
	trimStateText          // Trimmer is reading text
)

func (t *trimmer) discardWhitespace() {
	t.state = trimStateSpace
	t.space = t.space[0:0]
}

func (t *trimmer) Write(data []byte) (n int, err error) {
	// textStart holds the index of the start of a chunk of text not containing
	// whitespace. It is reset every time a new chunk of text is encountered.
	var textStart int

	for off, b := range data {
		// Convert \v to \t
		if b == '\v' {
			b = '\t'
		}

		switch t.state {
		case trimStateSpace:
			// Accumulate tabs and spaces in t.space until finding a non-tab or
			// non-space character.
			//
			// If we find a newline, we write it directly and discard our pending
			// whitespace (so that trailing whitespace up to the newline is ignored).
			//
			// If we find a tabwriter.Escape or text character we transition states.
			switch b {
			case '\t', ' ':
				t.space = append(t.space, b)
			case '\n', '\f':
				// Disard all unwritten whitespace before the end of the line and write
				// a newline.
				t.discardWhitespace()
				_, err = t.next.Write([]byte("\n"))
			case tabwriter.Escape:
				_, err = t.next.Write(t.space)
				t.state = trimStateEscape
				textStart = off + 1 // Skip escape character
			default:
				// Non-space character. Write our pending whitespace
				// and then move to text state.
				_, err = t.next.Write(t.space)
				t.state = trimStateText
				textStart = off
			}

		case trimStateText:
			// We're reading a chunk of text. Accumulate characters in the chunk
			// until we find a whitespace character or a tabwriter.Escape.
			switch b {
			case '\t', ' ':
				_, err = t.next.Write(data[textStart:off])
				t.discardWhitespace()
				t.space = append(t.space, b)
			case '\n', '\f':
				_, err = t.next.Write(data[textStart:off])
				t.discardWhitespace()
				if err == nil {
					_, err = t.next.Write([]byte("\n"))
				}
			case tabwriter.Escape:
				_, err = t.next.Write(data[textStart:off])
				t.state = trimStateEscape
				textStart = off + 1 // +1: skip tabwriter.Escape
			}

		case trimStateEscape:
			// Accumulate everything until finding the closing tabwriter.Escape.
			if b == tabwriter.Escape {
				_, err = t.next.Write(data[textStart:off])
				t.discardWhitespace()
			}

		default:
			panic("unreachable")
		}
		if err != nil {
			return off, err
		}
	}
	n = len(data)

	// Flush the remainder of the text (as long as it's not whitespace).
	switch t.state {
	case trimStateEscape, trimStateText:
		_, err = t.next.Write(data[textStart:n])
		t.discardWhitespace()
	}

	return
}

'''
'''--- pkg/river/printer/walker.go ---
package printer

import (
	"fmt"
	"strings"

	"github.com/grafana/agent/pkg/river/ast"
	"github.com/grafana/agent/pkg/river/token"
)

// A walker walks an AST and sends lexical tokens and formatting information to
// a printer.
type walker struct {
	p *printer
}

func (w *walker) Walk(node ast.Node) error {
	switch node := node.(type) {
	case *ast.File:
		w.walkFile(node)
	case ast.Body:
		w.walkStmts(node)
	case ast.Stmt:
		w.walkStmt(node)
	case ast.Expr:
		w.walkExpr(node)
	default:
		return fmt.Errorf("unsupported node type %T", node)
	}

	return nil
}

func (w *walker) walkFile(f *ast.File) {
	w.p.SetComments(f.Comments)
	w.walkStmts(f.Body)
}

func (w *walker) walkStmts(ss []ast.Stmt) {
	for i, s := range ss {
		var addedSpacing bool

		// Two blocks should always be separated by a blank line.
		if _, isBlock := s.(*ast.BlockStmt); i > 0 && isBlock {
			w.p.Write(wsNewline)
			addedSpacing = true
		}

		// A blank line should always be added if there is a blank line in the
		// source between two statements.
		if i > 0 && !addedSpacing {
			var (
				prevLine = ast.EndPos(ss[i-1]).Position().Line
				curLine  = ast.StartPos(ss[i-0]).Position().Line

				lineDiff = curLine - prevLine
			)

			if lineDiff > 1 {
				w.p.Write(wsFormfeed)
			}
		}

		w.walkStmt(s)

		// Statements which cross multiple lines don't belong to the same row run.
		// Add a formfeed to start a new row run if the node crossed more than one
		// line, otherwise add the normal newline.
		if nodeLines(s) > 1 {
			w.p.Write(wsFormfeed)
		} else {
			w.p.Write(wsNewline)
		}
	}
}

func nodeLines(n ast.Node) int {
	var (
		startLine = ast.StartPos(n).Position().Line
		endLine   = ast.EndPos(n).Position().Line
	)

	return endLine - startLine + 1
}

func (w *walker) walkStmt(s ast.Stmt) {
	switch s := s.(type) {
	case *ast.AttributeStmt:
		w.walkAttributeStmt(s)
	case *ast.BlockStmt:
		w.walkBlockStmt(s)
	}
}

func (w *walker) walkAttributeStmt(s *ast.AttributeStmt) {
	w.p.Write(s.Name.NamePos, s.Name, wsVTab, token.ASSIGN, wsBlank)
	w.walkExpr(s.Value)
}

func (w *walker) walkBlockStmt(s *ast.BlockStmt) {
	joined := strings.Join(s.Name, ".")

	// TODO(rfratto): Should blocks have a oneline format if they're short or
	// empty? e.g.: `empty_block { attr = 5 }`, `empty_block {}`

	w.p.Write(
		s.NamePos,
		&ast.Ident{Name: joined, NamePos: s.NamePos},
	)

	if s.Label != "" {
		label := fmt.Sprintf("%q", s.Label)

		w.p.Write(
			wsBlank,
			&ast.LiteralExpr{Kind: token.STRING, Value: label},
		)
	}

	w.p.Write(
		wsBlank,
		s.LCurlyPos, token.LCURLY, wsIndent,
		wsNewline,
	)

	w.walkStmts(s.Body)

	w.p.Write(wsUnindent, s.RCurlyPos, token.RCURLY)
}

func (w *walker) walkExpr(e ast.Expr) {
	switch e := e.(type) {
	case *ast.LiteralExpr:
		w.p.Write(e.ValuePos, e)

	case *ast.ArrayExpr:
		w.walkArrayExpr(e)

	case *ast.ObjectExpr:
		w.walkObjectExpr(e)

	case *ast.IdentifierExpr:
		w.p.Write(e.Ident.NamePos, e.Ident)

	case *ast.AccessExpr:
		w.walkExpr(e.Value)
		w.p.Write(token.DOT, e.Name)

	case *ast.IndexExpr:
		w.walkExpr(e.Value)
		w.p.Write(e.LBrackPos, token.LBRACK)
		w.walkExpr(e.Index)
		w.p.Write(e.RBrackPos, token.RBRACK)

	case *ast.CallExpr:
		// TODO(rfratto): allow arguments to be on a new line
		w.walkExpr(e.Value)
		w.p.Write(token.LPAREN)
		for i, arg := range e.Args {
			w.walkExpr(arg)

			if i+1 < len(e.Args) {
				w.p.Write(token.COMMA, wsBlank)
			}
		}
		w.p.Write(token.RPAREN)

	case *ast.UnaryExpr:
		w.p.Write(e.KindPos, e.Kind)
		w.walkExpr(e.Value)

	case *ast.BinaryExpr:
		// TODO(rfratto):
		//
		//   1. allow RHS to be on a new line
		//
		//   2. remove spacing between some operators to make precedence
		//      clearer like Go does
		w.walkExpr(e.Left)
		w.p.Write(wsBlank, e.KindPos, e.Kind, wsBlank)
		w.walkExpr(e.Right)

	case *ast.ParenExpr:
		w.p.Write(token.LPAREN)
		w.walkExpr(e.Inner)
		w.p.Write(token.RPAREN)
	}
}

func (w *walker) walkArrayExpr(e *ast.ArrayExpr) {
	w.p.Write(e.LBrackPos, token.LBRACK)
	prevPos := e.LBrackPos

	for i := 0; i < len(e.Elements); i++ {
		var addedNewline bool

		elementPos := ast.StartPos(e.Elements[i])

		// Add a newline if this element starts on a different line than the last
		// element ended.
		if differentLines(prevPos, elementPos) {
			w.p.Write(wsFormfeed, wsIndent)
			addedNewline = true
		} else if i > 0 {
			// Make sure a space is injected before the next element if two
			// successive elements are on the same line.
			w.p.Write(wsBlank)
		}
		prevPos = ast.EndPos(e.Elements[i])

		// Write the expression.
		w.walkExpr(e.Elements[i])

		// Always add commas in between successive elements.
		if i+1 < len(e.Elements) {
			w.p.Write(token.COMMA)
		}

		if addedNewline {
			w.p.Write(wsUnindent)
		}
	}

	// If the closing bracket is on a different line than the final element,
	// we need to add a trailing comma.
	if len(e.Elements) > 0 && differentLines(prevPos, e.RBrackPos) {
		w.p.Write(token.COMMA, wsFormfeed)
	}

	w.p.Write(e.RBrackPos, token.RBRACK)
}

func (w *walker) walkObjectExpr(e *ast.ObjectExpr) {
	w.p.Write(e.LCurlyPos, token.LCURLY, wsIndent)

	prevPos := e.LCurlyPos

	for i := 0; i < len(e.Fields); i++ {
		field := e.Fields[i]
		elementPos := ast.StartPos(field.Name)

		// Add a newline if this element starts on a different line than the last
		// element ended.
		if differentLines(prevPos, elementPos) {
			// We want to align the equal sign for object attributes if the previous
			// field only crossed one line.
			if i > 0 && nodeLines(e.Fields[i-1].Value) == 1 {
				w.p.Write(wsNewline)
			} else {
				w.p.Write(wsFormfeed)
			}
		} else if i > 0 {
			// Make sure a space is injected before the next element if two successive
			// elements are on the same line.
			w.p.Write(wsBlank)
		}
		prevPos = ast.EndPos(field.Name)

		w.p.Write(field.Name.NamePos)

		// Write the field.
		if field.Quoted {
			w.p.Write(&ast.LiteralExpr{
				Kind:     token.STRING,
				ValuePos: field.Name.NamePos,
				Value:    fmt.Sprintf("%q", field.Name.Name),
			})
		} else {
			w.p.Write(field.Name)
		}

		w.p.Write(wsVTab, token.ASSIGN, wsBlank)
		w.walkExpr(field.Value)

		// Always add commas in between successive elements.
		if i+1 < len(e.Fields) {
			w.p.Write(token.COMMA)
		}
	}

	// If the closing bracket is on a different line than the final element,
	// we need to add a trailing comma.
	if len(e.Fields) > 0 && differentLines(prevPos, e.RCurlyPos) {
		w.p.Write(token.COMMA, wsFormfeed)
	}

	w.p.Write(wsUnindent, e.RCurlyPos, token.RCURLY)
}

// differentLines returns true if a and b are on different lines.
func differentLines(a, b token.Pos) bool {
	return a.Position().Line != b.Position().Line
}

'''
'''--- pkg/river/scanner/scanner.go ---
// Package scanner implements a lexical scanner for River source files.
package scanner

import (
	"fmt"
	"unicode"
	"unicode/utf8"

	"github.com/grafana/agent/pkg/river/token"
)

// EBNF for the scanner:
//
//   letter           = /* any unicode letter class character */ | "_"
//   number           = /* any unicode number class character */
//   digit            = /* ASCII characters 0 through 9 */
//   digits           = digit { digit }
//   string_character = /* any unicode character that isn't '"' */
//
//   COMMENT       = line_comment | block_comment
//   line_comment  = "//" { character }
//   block_comment = "/*" { character | newline } "*/"
//
//   IDENT   = letter { letter | number }
//   NULL    = "null"
//   BOOL    = "true" | "false"
//   NUMBER  = digits
//   FLOAT   = ( digits | "." digits ) [ "e" [ "+" | "-" ] digits ]
//   STRING  = '"' { string_character | escape_sequence } '"'
//   OR      = "||"
//   AND     = "&&"
//   NOT     = "!"
//   NEQ     = "!="
//   ASSIGN  = "="
//   EQ      = "=="
//   LT      = "<"
//   LTE     = "<="
//   GT      = ">"
//   GTE     = ">="
//   ADD     = "+"
//   SUB     = "-"
//   MUL     = "*"
//   DIV     = "/"
//   MOD     = "%"
//   POW     = "^"
//   LCURLY  = "{"
//   RCURLY  = "}"
//   LPAREN  = "("
//   RPAREN  = ")"
//   LBRACK  = "["
//   RBRACK  = "]"
//   COMMA   = ","
//   DOT     = "."
//
// The EBNF for escape_sequence is currently undocumented; see scanEscape for
// details. The escape sequences supported by River are the same as the escape
// sequences supported by Go, except that it is always valid to use \' in
// strings (which in Go, is only valid to use in character literals).

// ErrorHandler is invoked whenever there is an error.
type ErrorHandler func(pos token.Pos, msg string)

// Mode is a set of bitwise flags which control scanner behavior.
type Mode uint

const (
	// IncludeComments will cause comments to be returned as comment tokens.
	// Otherwise, comments are ignored.
	IncludeComments Mode = 1 << iota

	// Avoids automatic insertion of terminators (for testing only).
	dontInsertTerms
)

const (
	bom = 0xFEFF // byte order mark, permitted as very first character
	eof = -1     // end of file
)

// Scanner holds the internal state for the tokenizer while processing configs.
type Scanner struct {
	file  *token.File  // Config file handle for tracking line offsets
	input []byte       // Input config
	err   ErrorHandler // Error reporting (may be nil)
	mode  Mode

	// scanning state variables:

	ch         rune // Current character
	offset     int  // Byte offset of ch
	readOffset int  // Byte offset of first character *after* ch
	insertTerm bool // Insert a newline before the next newline
	numErrors  int  // Number of errors encountered during scanning
}

// New creates a new scanner to tokenize the provided input config. The scanner
// uses the provided file for adding line information for each token. The mode
// parameter customizes scanner behavior.
//
// Calls to Scan will invoke the error handler eh when a lexical error is found
// if eh is not nil.
func New(file *token.File, input []byte, eh ErrorHandler, mode Mode) *Scanner {
	s := &Scanner{
		file:  file,
		input: input,
		err:   eh,
		mode:  mode,
	}

	// Preload first character.
	s.next()
	if s.ch == bom {
		s.next() // Ignore BOM if it's the first character.
	}
	return s
}

// peek gets the next byte after the current character without advancing the
// scanner. Returns 0 if the scanner is at EOF.
func (s *Scanner) peek() byte {
	if s.readOffset < len(s.input) {
		return s.input[s.readOffset]
	}
	return 0
}

// next advances the scanner and reads the next Unicode character into s.ch.
// s.ch == eof indicates end of file.
func (s *Scanner) next() {
	if s.readOffset >= len(s.input) {
		s.offset = len(s.input)
		if s.ch == '\n' {
			// Make sure we track final newlines at the end of the file
			s.file.AddLine(s.offset)
		}
		s.ch = eof
		return
	}

	s.offset = s.readOffset
	if s.ch == '\n' {
		s.file.AddLine(s.offset)
	}

	r, width := rune(s.input[s.readOffset]), 1
	switch {
	case r == 0:
		s.onError(s.offset, "illegal character NUL")
	case r >= utf8.RuneSelf:
		r, width = utf8.DecodeRune(s.input[s.readOffset:])
		if r == utf8.RuneError && width == 1 {
			s.onError(s.offset, "illegal UTF-8 encoding")
		} else if r == bom && s.offset > 0 {
			s.onError(s.offset, "illegal byte order mark")
		}
	}
	s.readOffset += width
	s.ch = r
}

func (s *Scanner) onError(offset int, msg string) {
	if s.err != nil {
		s.err(s.file.Pos(offset), msg)
	}
	s.numErrors++
}

// NumErrors returns the current number of errors encountered during scanning.
// This is useful as a fallback to detect errors when no ErrorHandler was
// provided to the scanner.
func (s *Scanner) NumErrors() int { return s.numErrors }

// Scan scans the next token and returns the token's position, the token
// itself, and the token's literal string (when applicable). The end of the
// input is indicated by token.EOF.
//
// If the returned token is a literal (such as token.STRING), then lit contains
// the corresponding literal text (including surrounding quotes).
//
// If the returned token is a keyword, lit is the keyword text that was
// scanned.
//
// If the returned token is token.TERMINATOR, lit will contain "\n".
//
// If the returned token is token.ILLEGAL, lit contains the offending
// character.
//
// In all other cases, lit will be an empty string.
//
// For more tolerant parsing, Scan returns a valid token character whenever
// possible when a syntax error was encountered. Callers must check NumErrors
// or the number of times the provided ErrorHandler was invoked to ensure there
// were no errors found during scanning.
//
// Scan will inject line information to the file provided by NewScanner.
// Returned token positions are relative to that file.
func (s *Scanner) Scan() (pos token.Pos, tok token.Token, lit string) {
scanAgain:
	s.skipWhitespace()

	// Start of current token.
	pos = s.file.Pos(s.offset)

	var insertTerm bool

	// Determine token value
	switch ch := s.ch; {
	case isLetter(ch):
		lit = s.scanIdentifier()
		if len(lit) > 1 { // Keywords are always > 1 char
			tok = token.Lookup(lit)
			switch tok {
			case token.IDENT, token.NULL, token.BOOL:
				insertTerm = true
			}
		} else {
			insertTerm = true
			tok = token.IDENT
		}

	case isDecimal(ch) || (ch == '.' && isDecimal(rune(s.peek()))):
		insertTerm = true
		tok, lit = s.scanNumber()

	default:
		s.next() // Make progress

		// ch is now the first character in a sequence and s.ch is the second
		// character.

		switch ch {
		case eof:
			if s.insertTerm {
				s.insertTerm = false // Consumed EOF
				return pos, token.TERMINATOR, "\n"
			}
			tok = token.EOF

		case '\n':
			// This case is only reachable when s.insertTerm is true, since otherwise
			// skipWhitespace consumes all other newlines.
			s.insertTerm = false // Consumed newline
			return pos, token.TERMINATOR, "\n"

		case '\'':
			s.onError(pos.Offset(), "illegal single-quoted string; use double quotes")
			insertTerm = true
			tok = token.ILLEGAL
			lit = s.scanString('\'')

		case '"':
			insertTerm = true
			tok = token.STRING
			lit = s.scanString('"')

		case '|':
			if s.ch != '|' {
				s.onError(s.offset, "missing second | in ||")
			} else {
				s.next() // consume second '|'
			}
			tok = token.OR
		case '&':
			if s.ch != '&' {
				s.onError(s.offset, "missing second & in &&")
			} else {
				s.next() // consume second '&'
			}
			tok = token.AND

		case '!': // !, !=
			tok = s.switch2(token.NOT, token.NEQ, '=')
		case '=': // =, ==
			tok = s.switch2(token.ASSIGN, token.EQ, '=')
		case '<': // <, <=
			tok = s.switch2(token.LT, token.LTE, '=')
		case '>': // >, >=
			tok = s.switch2(token.GT, token.GTE, '=')
		case '+':
			tok = token.ADD
		case '-':
			tok = token.SUB
		case '*':
			tok = token.MUL
		case '/':
			if s.ch == '/' || s.ch == '*' {
				// //- or /*-style comment.
				//
				// If we're expected to inject a terminator, we can only do so if our
				// comment goes to the end of the line. Otherwise, the terminator will
				// have to be injected after the comment token.
				if s.insertTerm && s.findLineEnd() {
					// Reset position to the beginning of the comment.
					s.ch = '/'
					s.offset = pos.Offset()
					s.readOffset = s.offset + 1
					s.insertTerm = false // Consumed newline
					return pos, token.TERMINATOR, "\n"
				}
				comment := s.scanComment()
				if s.mode&IncludeComments == 0 {
					// Skip over comment
					s.insertTerm = false // Consumed newline
					goto scanAgain
				}
				tok = token.COMMENT
				lit = comment
			} else {
				tok = token.DIV
			}

		case '%':
			tok = token.MOD
		case '^':
			tok = token.POW
		case '{':
			tok = token.LCURLY
		case '}':
			insertTerm = true
			tok = token.RCURLY
		case '(':
			tok = token.LPAREN
		case ')':
			insertTerm = true
			tok = token.RPAREN
		case '[':
			tok = token.LBRACK
		case ']':
			insertTerm = true
			tok = token.RBRACK
		case ',':
			tok = token.COMMA
		case '.':
			// NOTE: Fractions starting with '.' are handled by outer switch
			tok = token.DOT

		default:
			// s.next() reports invalid BOMs so we don't need to repeat the error.
			if ch != bom {
				s.onError(pos.Offset(), fmt.Sprintf("illegal character %#U", ch))
			}
			insertTerm = s.insertTerm // Preserve previous s.insertTerm state
			tok = token.ILLEGAL
			lit = string(ch)
		}
	}

	if s.mode&dontInsertTerms == 0 {
		s.insertTerm = insertTerm
	}
	return
}

func (s *Scanner) skipWhitespace() {
	for s.ch == ' ' || s.ch == '\t' || s.ch == '\r' || (s.ch == '\n' && !s.insertTerm) {
		s.next()
	}
}

func isLetter(ch rune) bool {
	// We check for ASCII first as an optimization, and leave checking unicode
	// (the slowest) to the very end.
	return (lower(ch) >= 'a' && lower(ch) <= 'z') ||
		ch == '_' ||
		(ch >= utf8.RuneSelf && unicode.IsLetter(ch))
}

func lower(ch rune) rune     { return ('a' - 'A') | ch }
func isDecimal(ch rune) bool { return '0' <= ch && ch <= '9' }
func isDigit(ch rune) bool {
	return isDecimal(ch) || (ch >= utf8.RuneSelf && unicode.IsDigit(ch))
}

// scanIdentifier reads the string of valid identifier characters starting at
// s.offet. It must only be called when s.ch is a valid character which starts
// an identifier.
//
// scanIdentifier is highly optimized for identifiers are modifications must be
// made carefully.
func (s *Scanner) scanIdentifier() string {
	off := s.offset

	// Optimize for common case of ASCII identifiers.
	//
	// Ranging over s.input[s.readOffset:] avoids bounds checks and avoids
	// conversions to runes.
	//
	// We'll fall back to the slower path if we find a non-ASCII character.
	for readOffset, b := range s.input[s.readOffset:] {
		if (b >= 'a' && b <= 'z') || (b >= 'A' && b <= 'Z') || b == '_' || (b >= '0' && b <= '9') {
			// Common case: ASCII character; don't assign a rune.
			continue
		}
		s.readOffset += readOffset
		if b > 0 && b < utf8.RuneSelf {
			// Optimization: ASCII character that isn't a letter or number; we've
			// reached the end of the identifier sequence and can terminate. We avoid
			// the call to s.next() and the corresponding setup.
			//
			// This optimization only works because we know that s.ch (the current
			// character when scanIdentifier was called) is never '\n' since '\n'
			// cannot start an identifier.
			s.ch = rune(b)
			s.offset = s.readOffset
			s.readOffset++
			goto exit
		}

		// The preceding character is valid for an identifier because
		// scanIdentifier is only called when s.ch is a letter; calling s.next() at
		// s.readOffset will reset the scanner state.
		s.next()
		for isLetter(s.ch) || isDigit(s.ch) {
			s.next()
		}

		// No more valid characters for the identifier; terminate.
		goto exit
	}

	s.offset = len(s.input)
	s.readOffset = len(s.input)
	s.ch = eof

exit:
	return string(s.input[off:s.offset])
}

func (s *Scanner) scanNumber() (tok token.Token, lit string) {
	tok = token.NUMBER
	off := s.offset

	// Integer part of number
	if s.ch != '.' {
		s.digits()
	}

	// Fractional part of number
	if s.ch == '.' {
		tok = token.FLOAT

		s.next()
		s.digits()
	}

	// Exponent
	if lower(s.ch) == 'e' {
		tok = token.FLOAT

		s.next()
		if s.ch == '+' || s.ch == '-' {
			s.next()
		}

		if s.digits() == 0 {
			s.onError(off, "exponent has no digits")
		}
	}

	return tok, string(s.input[off:s.offset])
}

// digits scans a sequence of digits.
func (s *Scanner) digits() (count int) {
	for isDecimal(s.ch) {
		s.next()
		count++
	}
	return
}

func (s *Scanner) scanString(until rune) string {
	// subtract 1 to account for the opening '"' which was already consumed by
	// the scanner forcing progress.
	off := s.offset - 1

	for {
		ch := s.ch
		if ch == '\n' || ch == eof {
			s.onError(off, "string literal not terminated")
			break
		}
		s.next()
		if ch == until {
			break
		}
		if ch == '\\' {
			s.scanEscape()
		}
	}

	return string(s.input[off:s.offset])
}

// scanEscape parses an escape sequence. In case of a syntax error, scanEscape
// stops at the offending character without consuming it.
func (s *Scanner) scanEscape() {
	off := s.offset

	var (
		n         int
		base, max uint32
	)

	switch s.ch {
	case 'a', 'b', 'f', 'n', 'r', 't', 'v', '\\', '"':
		s.next()
		return
	case '0', '1', '2', '3', '4', '5', '6', '7':
		n, base, max = 3, 8, 255
	case 'x':
		s.next()
		n, base, max = 2, 16, 255
	case 'u':
		s.next()
		n, base, max = 4, 16, unicode.MaxRune
	case 'U':
		s.next()
		n, base, max = 8, 16, unicode.MaxRune
	default:
		msg := "unknown escape sequence"
		if s.ch == eof {
			msg = "escape sequence not terminated"
		}
		s.onError(off, msg)
		return
	}

	var x uint32
	for n > 0 {
		d := uint32(digitVal(s.ch))
		if d >= base {
			msg := fmt.Sprintf("illegal character %#U in escape sequence", s.ch)
			if s.ch == eof {
				msg = "escape sequence not terminated"
			}
			s.onError(off, msg)
			return
		}
		x = x*base + d
		s.next()
		n--
	}

	if x > max || x >= 0xD800 && x < 0xE000 {
		s.onError(off, "escape sequence is invalid Unicode code point")
	}
}

func digitVal(ch rune) int {
	switch {
	case ch >= '0' && ch <= '9':
		return int(ch - '0')
	case lower(ch) >= 'a' && lower(ch) <= 'f':
		return int(lower(ch) - 'a' + 10)
	}
	return 16 // Larger than any legal digit val
}

func (s *Scanner) scanComment() string {
	// The initial character in the comment was already consumed from the scanner
	// forcing progress.
	//
	// slashComment will be true when the comment is a //- or /*-style comment.

	var (
		off   = s.offset - 1 // Offset of initial character
		numCR = 0

		blockComment = false
	)

	if s.ch == '/' { // NOTE: s.ch is second character in comment sequence
		// //-style comment.
		//
		// The final '\n' is not considered to be part of the comment.
		if s.ch == '/' {
			s.next() // Consume second '/'
		}

		for s.ch != '\n' && s.ch != eof {
			if s.ch == '\r' {
				numCR++
			}
			s.next()
		}

		goto exit
	}

	// /*-style comment.
	blockComment = true
	s.next()
	for s.ch != eof {
		ch := s.ch
		if ch == '\r' {
			numCR++
		}
		s.next()
		if ch == '*' && s.ch == '/' {
			s.next()
			goto exit
		}
	}

	s.onError(off, "block comment not terminated")

exit:
	lit := s.input[off:s.offset]

	// On Windows, a single comment line may end in "\r\n". We want to remove the
	// final \r.
	if numCR > 0 && len(lit) >= 1 && lit[len(lit)-1] == '\r' {
		lit = lit[:len(lit)-1]
		numCR--
	}

	if numCR > 0 {
		lit = stripCR(lit, blockComment)
	}

	return string(lit)
}

func stripCR(b []byte, blockComment bool) []byte {
	c := make([]byte, len(b))
	i := 0

	for j, ch := range b {
		if ch != '\r' || blockComment && i > len("/*") && c[i-1] == '*' && j+1 < len(b) && b[j+1] == '/' {
			c[i] = ch
			i++
		}
	}

	return c[:i]
}

// findLineEnd checks to see if a comment runs to the end of the line.
func (s *Scanner) findLineEnd() bool {
	// NOTE: initial '/' is already consumed by forcing the scanner to progress.

	defer func(off int) {
		// Reset scanner state to where it was upon calling findLineEnd.
		s.ch = '/'
		s.offset = off
		s.readOffset = off + 1
		s.next() // Consume initial starting '/' again
	}(s.offset - 1)

	// Read ahead until a newline, EOF, or non-comment token is found.
	// We loop to consume multiple sequences of comment tokens.
	for s.ch == '/' || s.ch == '*' {
		if s.ch == '/' {
			// //-style comments always contain newlines.
			return true
		}

		// We're looking at a /*-style comment; look for its newline.
		s.next()
		for s.ch != eof {
			ch := s.ch
			if ch == '\n' {
				return true
			}
			s.next()
			if ch == '*' && s.ch == '/' { // End of block comment
				s.next()
				break
			}
		}

		// Check to see if there's a newline after the block comment.
		s.skipWhitespace() // s.insertTerm is set
		if s.ch == eof || s.ch == '\n' {
			return true
		}
		if s.ch != '/' {
			// Non-comment token
			return false
		}
		s.next() // Consume '/' at the end of the /* style-comment
	}

	return false
}

// switch2 returns a if s.ch is next, b otherwise. The scanner will be advanced
// if b is returned.
//
// This is used for tokens which can either be a single character but also are
// the starting character for a 2-length token (i.e., = and ==).
func (s *Scanner) switch2(a, b token.Token, next rune) token.Token { //nolint:unparam
	if s.ch == next {
		s.next()
		return b
	}
	return a
}

'''
'''--- pkg/river/scanner/scanner_test.go ---
package scanner

import (
	"path/filepath"
	"testing"

	"github.com/grafana/agent/pkg/river/token"
	"github.com/stretchr/testify/assert"
)

type tokenExample struct {
	tok token.Token
	lit string
}

var tokens = []tokenExample{
	// Special tokens
	{token.COMMENT, "/* a comment */"},
	{token.COMMENT, "// a comment \n"},
	{token.COMMENT, "/*\r*/"},
	{token.COMMENT, "/**\r/*/"}, // golang/go#11151
	{token.COMMENT, "/**\r\r/*/"},
	{token.COMMENT, "//\r\n"},

	// Identifiers and basic type literals
	{token.IDENT, "foobar"},
	{token.IDENT, "a"},
	{token.IDENT, "foo"},
	{token.IDENT, "bar"},
	{token.IDENT, ""},    // golang/go#4000
	{token.IDENT, "foo"}, // golang/go#4000
	{token.NUMBER, "0"},
	{token.NUMBER, "1"},
	{token.NUMBER, "123456789012345678890"},
	{token.NUMBER, "01234567"},
	{token.FLOAT, "0."},
	{token.FLOAT, ".0"},
	{token.FLOAT, "3.14159265"},
	{token.FLOAT, "1e0"},
	{token.FLOAT, "1e+100"},
	{token.FLOAT, "1e-100"},
	{token.FLOAT, "2.71828e-1000"},
	{token.STRING, `"Hello, world!"`},

	// Operators and delimiters
	{token.ADD, "+"},
	{token.SUB, "-"},
	{token.MUL, "*"},
	{token.DIV, "/"},
	{token.MOD, "%"},
	{token.POW, "^"},

	{token.AND, "&&"},
	{token.OR, "||"},

	{token.EQ, "=="},
	{token.LT, "<"},
	{token.GT, ">"},
	{token.ASSIGN, "="},
	{token.NOT, "!"},

	{token.NEQ, "!="},
	{token.LTE, "<="},
	{token.GTE, ">="},

	{token.LPAREN, "("},
	{token.LBRACK, "["},
	{token.LCURLY, "{"},
	{token.COMMA, ","},
	{token.DOT, "."},

	{token.RPAREN, ")"},
	{token.RBRACK, "]"},
	{token.RCURLY, "}"},

	// Keywords
	{token.NULL, "null"},
	{token.BOOL, "true"},
	{token.BOOL, "false"},
}

const whitespace = "  \t  \n\n\n" // Various whitespace to separate tokens

var source = func() []byte {
	var src []byte
	for _, t := range tokens {
		src = append(src, t.lit...)
		src = append(src, whitespace...)
	}
	return src
}()

// FuzzScanner ensures that the scanner will always be able to reach EOF
// regardless of input.
func FuzzScanner(f *testing.F) {
	// Add each token into the corpus
	for _, t := range tokens {
		f.Add([]byte(t.lit))
	}
	// Then add the entire source
	f.Add(source)

	f.Fuzz(func(t *testing.T, input []byte) {
		f := token.NewFile(t.Name())

		s := New(f, input, nil, IncludeComments)

		for {
			_, tok, _ := s.Scan()
			if tok == token.EOF {
				break
			}
		}
	})
}

func TestScanner_Scan(t *testing.T) {
	whitespaceLinecount := newlineCount(whitespace)

	var eh ErrorHandler = func(_ token.Pos, msg string) {
		t.Errorf("ErrorHandler called (msg = %s)", msg)
	}

	f := token.NewFile(t.Name())
	s := New(f, source, eh, IncludeComments|dontInsertTerms)

	// Configure expected position
	expectPos := token.Position{
		Filename: t.Name(),
		Offset:   0,
		Line:     1,
		Column:   1,
	}

	index := 0
	for {
		pos, tok, lit := s.Scan()

		// Check position
		checkPos(t, lit, tok, pos, expectPos)

		// Check token
		e := tokenExample{token.EOF, ""}
		if index < len(tokens) {
			e = tokens[index]
			index++
		}
		assert.Equal(t, e.tok, tok)

		// Check literal
		expectLit := ""
		switch e.tok {
		case token.COMMENT:
			// no CRs in comments
			expectLit = string(stripCR([]byte(e.lit), e.lit[1] == '*'))
			if expectLit[1] == '/' {
				// Line comment literals doesn't contain newline
				expectLit = expectLit[0 : len(expectLit)-1]
			}
		case token.IDENT:
			expectLit = e.lit
		case token.NUMBER, token.FLOAT, token.STRING, token.NULL, token.BOOL:
			expectLit = e.lit
		}
		assert.Equal(t, expectLit, lit)

		if tok == token.EOF {
			break
		}

		// Update position
		expectPos.Offset += len(e.lit) + len(whitespace)
		expectPos.Line += newlineCount(e.lit) + whitespaceLinecount
	}

	if s.NumErrors() != 0 {
		assert.Zero(t, s.NumErrors(), "expected number of scanning errors to be 0")
	}
}

func newlineCount(s string) int {
	var n int
	for i := 0; i < len(s); i++ {
		if s[i] == '\n' {
			n++
		}
	}
	return n
}

func checkPos(t *testing.T, lit string, tok token.Token, p token.Pos, expected token.Position) {
	t.Helper()

	pos := p.Position()

	// Check cleaned filenames so that we don't have to worry about different
	// os.PathSeparator values.
	if pos.Filename != expected.Filename && filepath.Clean(pos.Filename) != filepath.Clean(expected.Filename) {
		assert.Equal(t, expected.Filename, pos.Filename, "Bad filename for %s (%q)", tok, lit)
	}

	assert.Equal(t, expected.Offset, pos.Offset, "Bad offset for %s (%q)", tok, lit)
	assert.Equal(t, expected.Line, pos.Line, "Bad line for %s (%q)", tok, lit)
	assert.Equal(t, expected.Column, pos.Column, "Bad column for %s (%q)", tok, lit)
}

var errorTests = []struct {
	input string
	tok   token.Token
	pos   int
	lit   string
	err   string
}{
	{"\a", token.ILLEGAL, 0, "", "illegal character U+0007"},
	{``, token.ILLEGAL, 0, "", "illegal character U+2026 ''"},
	{"..", token.DOT, 0, "", ""}, // two periods, not invalid token (golang/go#28112)
	{`'illegal string'`, token.ILLEGAL, 0, "", "illegal single-quoted string; use double quotes"},
	{`""`, token.STRING, 0, `""`, ""},
	{`"abc`, token.STRING, 0, `"abc`, "string literal not terminated"},
	{"\"abc\n", token.STRING, 0, `"abc`, "string literal not terminated"},
	{"\"abc\n   ", token.STRING, 0, `"abc`, "string literal not terminated"},
	{"\"abc\x00def\"", token.STRING, 4, "\"abc\x00def\"", "illegal character NUL"},
	{"\"abc\x80def\"", token.STRING, 4, "\"abc\x80def\"", "illegal UTF-8 encoding"},
	{"\ufeff\ufeff", token.ILLEGAL, 3, "\ufeff\ufeff", "illegal byte order mark"},                        // only first BOM is ignored
	{"//\ufeff", token.COMMENT, 2, "//\ufeff", "illegal byte order mark"},                                // only first BOM is ignored
	{`"` + "abc\ufeffdef" + `"`, token.STRING, 4, `"` + "abc\ufeffdef" + `"`, "illegal byte order mark"}, // only first BOM is ignored
	{"abc\x00def", token.IDENT, 3, "abc", "illegal character NUL"},
	{"abc\x00", token.IDENT, 3, "abc", "illegal character NUL"},
	{"10E", token.FLOAT, 0, "10E", "exponent has no digits"},
}

func TestScanner_Scan_Errors(t *testing.T) {
	for _, e := range errorTests {
		checkError(t, e.input, e.tok, e.pos, e.lit, e.err)
	}
}

func checkError(t *testing.T, src string, tok token.Token, pos int, lit, err string) {
	t.Helper()

	var (
		actualErrors int
		latestError  string
		latestPos    token.Pos
	)

	eh := func(pos token.Pos, msg string) {
		actualErrors++
		latestError = msg
		latestPos = pos
	}

	f := token.NewFile(t.Name())
	s := New(f, []byte(src), eh, IncludeComments|dontInsertTerms)

	_, actualTok, actualLit := s.Scan()

	assert.Equal(t, tok, actualTok)
	if actualTok != token.ILLEGAL {
		assert.Equal(t, lit, actualLit)
	}

	expectErrors := 0
	if err != "" {
		expectErrors = 1
	}

	assert.Equal(t, expectErrors, actualErrors, "Unexpected error count in src %q", src)
	assert.Equal(t, err, latestError, "Unexpected error message in src %q", src)
	assert.Equal(t, pos, latestPos.Offset(), "Unexpected offset in src %q", src)
}

'''
'''--- pkg/river/token/builder/builder.go ---
// Package builder exposes an API to create a River configuration file by
// constructing a set of tokens.
package builder

import (
	"bytes"
	"fmt"
	"io"
	"reflect"
	"strings"

	"github.com/grafana/agent/pkg/river/internal/rivertags"
	"github.com/grafana/agent/pkg/river/token"
)

// An Expr represents a single River expression.
type Expr struct {
	rawTokens []Token
}

// NewExpr creates a new Expr.
func NewExpr() *Expr { return &Expr{} }

// Tokens returns the Expr as a set of Tokens.
func (e *Expr) Tokens() []Token { return e.rawTokens }

// SetValue sets the Expr to a River value converted from a Go value. The Go
// value is encoded using the normal Go to River encoding rules. If any value
// reachable from goValue implements Tokenizer, the printed tokens will instead
// be retrieved by calling the RiverTokenize method.
func (e *Expr) SetValue(goValue interface{}) {
	e.rawTokens = tokenEncode(goValue)
}

// WriteTo renders and formats the File, writing the contents to w.
func (e *Expr) WriteTo(w io.Writer) (int64, error) {
	n, err := printExprTokens(w, e.Tokens())
	return int64(n), err
}

// Bytes renders the File to a formatted byte slice.
func (e *Expr) Bytes() []byte {
	var buf bytes.Buffer
	_, _ = e.WriteTo(&buf)
	return buf.Bytes()
}

// A File represents a River configuration file.
type File struct {
	body *Body
}

// NewFile creates a new File.
func NewFile() *File { return &File{body: newBody()} }

// Tokens returns the File as a set of Tokens.
func (f *File) Tokens() []Token { return f.Body().Tokens() }

// Body returns the Body contents of the file.
func (f *File) Body() *Body { return f.body }

// WriteTo renders and formats the File, writing the contents to w.
func (f *File) WriteTo(w io.Writer) (int64, error) {
	n, err := printFileTokens(w, f.Tokens())
	return int64(n), err
}

// Bytes renders the File to a formatted byte slice.
func (f *File) Bytes() []byte {
	var buf bytes.Buffer
	_, _ = f.WriteTo(&buf)
	return buf.Bytes()
}

// Body is a list of block and attribute statements. A Body cannot be manually
// created, but is retrieved from a File or Block.
type Body struct {
	nodes []tokenNode
}

// A tokenNode is a structural element which can be converted into a set of
// Tokens.
type tokenNode interface {
	// Tokens builds the set of Tokens from the node.
	Tokens() []Token
}

func newBody() *Body {
	return &Body{}
}

// Tokens returns the File as a set of Tokens.
func (b *Body) Tokens() []Token {
	var rawToks []Token
	for i, node := range b.nodes {
		rawToks = append(rawToks, node.Tokens()...)

		if i+1 < len(b.nodes) {
			// Append a terminator between each statement in the Body.
			rawToks = append(rawToks, Token{
				Tok: token.LITERAL,
				Lit: "\n",
			})
		}
	}
	return rawToks
}

// AppendTokens appens raw tokens to the Body.
func (b *Body) AppendTokens(tokens []Token) {
	b.nodes = append(b.nodes, tokensSlice(tokens))
}

// AppendBlock adds a new block inside of the Body.
func (b *Body) AppendBlock(block *Block) {
	b.nodes = append(b.nodes, block)
}

// AppendFrom sets attributes and appends blocks defined by goValue into the
// Body. If any value reachable from goValue implements Tokenizer, the printed
// tokens will instead be retrieved by calling the RiverTokenize method.
//
// goValue must be a struct or a pointer to a struct that contains River struct
// tags.
func (b *Body) AppendFrom(goValue interface{}) {
	if goValue == nil {
		return
	}

	rv := reflect.ValueOf(goValue)
	b.encodeFields(rv)
}

func (b *Body) encodeFields(rv reflect.Value) {
	for rv.Kind() == reflect.Pointer {
		if rv.IsNil() {
			return
		}
		rv = rv.Elem()
	}
	if rv.Kind() != reflect.Struct {
		panic(fmt.Sprintf("river/token/builder: can only encode struct values to bodies, got %s", rv.Type()))
	}

	fields := rivertags.Get(rv.Type())

	for _, field := range fields {
		fieldVal := rv.FieldByIndex(field.Index)
		b.encodeField(field, fieldVal)
	}
}

func (b *Body) encodeField(field rivertags.Field, fieldValue reflect.Value) {
	fieldName := strings.Join(field.Name, ".")

	for fieldValue.Kind() == reflect.Pointer {
		if fieldValue.IsNil() {
			break
		}
		fieldValue = fieldValue.Elem()
	}
	if field.Flags&rivertags.FlagOptional != 0 && fieldValue.IsZero() {
		return
	}

	switch {
	case field.Flags&rivertags.FlagAttr != 0:
		b.SetAttributeValue(fieldName, fieldValue.Interface())

	case field.Flags&rivertags.FlagBlock != 0:
		switch {
		case fieldValue.IsZero():
			// It shouldn't be possible to have a required block which is unset, but
			// we'll encode something anyway.
			inner := NewBlock(field.Name, "")
			b.AppendBlock(inner)

		case fieldValue.Kind() == reflect.Slice, fieldValue.Kind() == reflect.Array:
			for i := 0; i < fieldValue.Len(); i++ {
				elem := fieldValue.Index(i)

				// Recursively call encodeField for each element in the slice/array.
				// The recurisve call will hit the case below and add a new block for
				// each field encountered.
				b.encodeField(field, elem)
			}

		case fieldValue.Kind() == reflect.Struct:
			inner := NewBlock(field.Name, getBlockLabel(fieldValue))
			inner.Body().encodeFields(fieldValue)
			b.AppendBlock(inner)
		}
	}
}

func getBlockLabel(rv reflect.Value) string {
	tags := rivertags.Get(rv.Type())
	for _, tag := range tags {
		if tag.Flags&rivertags.FlagLabel != 0 {
			return rv.FieldByIndex(tag.Index).String()
		}
	}

	return ""
}

// SetAttributeTokens sets an attribute to the Body whose value is a set of raw
// tokens. If the attribute was previously set, its value tokens are updated.
//
// Attributes will be written out in the order they were initially created.
func (b *Body) SetAttributeTokens(name string, tokens []Token) {
	attr := b.getOrCreateAttribute(name)
	attr.RawTokens = tokens
}

func (b *Body) getOrCreateAttribute(name string) *attribute {
	for _, n := range b.nodes {
		if attr, ok := n.(*attribute); ok && attr.Name == name {
			return attr
		}
	}

	newAttr := &attribute{Name: name}
	b.nodes = append(b.nodes, newAttr)
	return newAttr
}

// SetAttributeValue sets an attribute in the Body whose value is converted
// from a Go value to a River value. The Go value is encoded using the normal
// Go to River encoding rules. If any value reachable from goValue implements
// Tokenizer, the printed tokens will instead be retrieved by calling the
// RiverTokenize method.
//
// If the attribute was previously set, its value tokens are updated.
//
// Attributes will be written out in the order they were initially crated.
func (b *Body) SetAttributeValue(name string, goValue interface{}) {
	attr := b.getOrCreateAttribute(name)
	attr.RawTokens = tokenEncode(goValue)
}

type attribute struct {
	Name      string
	RawTokens []Token
}

func (attr *attribute) Tokens() []Token {
	var toks []Token

	toks = append(toks, Token{Tok: token.IDENT, Lit: attr.Name})
	toks = append(toks, Token{Tok: token.ASSIGN})
	toks = append(toks, attr.RawTokens...)

	return toks
}

// A Block encapsulates a body within a named and labeled River block. Blocks
// must be created by calling NewBlock, but its public struct fields may be
// safely modified by callers.
type Block struct {
	// Public fields, safe to be changed by callers:

	Name  []string
	Label string

	// Private fields:

	body *Body
}

// NewBlock returns a new Block with the given name and label. The name/label
// can be updated later by modifying the Block's public fields.
func NewBlock(name []string, label string) *Block {
	return &Block{
		Name:  name,
		Label: label,

		body: newBody(),
	}
}

// Tokens returns the File as a set of Tokens.
func (b *Block) Tokens() []Token {
	var toks []Token

	for i, frag := range b.Name {
		toks = append(toks, Token{Tok: token.IDENT, Lit: frag})
		if i+1 < len(b.Name) {
			toks = append(toks, Token{Tok: token.DOT})
		}
	}

	toks = append(toks, Token{Tok: token.LITERAL, Lit: " "})

	if b.Label != "" {
		toks = append(toks, Token{Tok: token.STRING, Lit: fmt.Sprintf("%q", b.Label)})
	}

	toks = append(toks, Token{Tok: token.LCURLY}, Token{Tok: token.LITERAL, Lit: "\n"})
	toks = append(toks, b.body.Tokens()...)
	toks = append(toks, Token{Tok: token.LITERAL, Lit: "\n"}, Token{Tok: token.RCURLY})

	return toks
}

// Body returns the Body contained within the Block.
func (b *Block) Body() *Body { return b.body }

type tokensSlice []Token

func (tn tokensSlice) Tokens() []Token { return []Token(tn) }

'''
'''--- pkg/river/token/builder/builder_test.go ---
package builder_test

import (
	"bytes"
	"fmt"
	"testing"
	"time"

	"github.com/grafana/agent/pkg/river/parser"
	"github.com/grafana/agent/pkg/river/printer"
	"github.com/grafana/agent/pkg/river/token"
	"github.com/grafana/agent/pkg/river/token/builder"
	"github.com/stretchr/testify/require"
)

func TestBuilder_File(t *testing.T) {
	f := builder.NewFile()

	f.Body().SetAttributeTokens("attr_1", []builder.Token{{Tok: token.NUMBER, Lit: "15"}})
	f.Body().SetAttributeTokens("attr_2", []builder.Token{{Tok: token.BOOL, Lit: "true"}})

	b1 := builder.NewBlock([]string{"test", "block"}, "")
	b1.Body().SetAttributeTokens("inner_attr", []builder.Token{{Tok: token.STRING, Lit: `"block 1"`}})
	f.Body().AppendBlock(b1)

	b2 := builder.NewBlock([]string{"test", "block"}, "labeled")
	b2.Body().SetAttributeTokens("inner_attr", []builder.Token{{Tok: token.STRING, Lit: `"block 2"`}})
	f.Body().AppendBlock(b2)

	expect := format(t, `
		attr_1 = 15
		attr_2 = true

		test.block {
			inner_attr = "block 1"
		}

		test.block "labeled" {
			inner_attr = "block 2"
		}
	`)

	require.Equal(t, expect, string(f.Bytes()))
}

func TestBuilder_GoEncode(t *testing.T) {
	f := builder.NewFile()

	f.Body().AppendTokens([]builder.Token{{token.COMMENT, "// Hello, world!"}})
	f.Body().SetAttributeValue("null_value", nil)
	f.Body().AppendTokens([]builder.Token{{token.LITERAL, "\n"}})

	f.Body().SetAttributeValue("num", 15)
	f.Body().SetAttributeValue("string", "Hello, world!")
	f.Body().SetAttributeValue("bool", true)
	f.Body().SetAttributeValue("list", []int{0, 1, 2})
	f.Body().SetAttributeValue("func", func(int, int) int { return 0 })
	f.Body().SetAttributeValue("capsule", make(chan int))
	f.Body().AppendTokens([]builder.Token{{token.LITERAL, "\n"}})

	f.Body().SetAttributeValue("map", map[string]interface{}{"foo": "bar"})
	f.Body().SetAttributeValue("map_2", map[string]interface{}{"non ident": "bar"})
	f.Body().AppendTokens([]builder.Token{{token.LITERAL, "\n"}})

	f.Body().SetAttributeValue("mixed_list", []interface{}{
		0,
		true,
		map[string]interface{}{"key": true},
		"Hello!",
	})

	expect := format(t, `
		// Hello, world!
		null_value = null
	
		num     = 15 
		string  = "Hello, world!"
		bool    = true
		list    = [0, 1, 2]
		func    = function
		capsule = capsule("chan int")

		map = {
			foo = "bar",
		}
		map_2 = {
			"non ident" = "bar",
		}

		mixed_list = [0, true, {
			key = true,
		}, "Hello!"]
	`)

	require.Equal(t, expect, string(f.Bytes()))
}

// TestBuilder_GoEncode_SortMapKeys ensures that object literals from unordered
// values (i.e., Go maps) are printed in a deterministic order by sorting the
// keys lexicographically. Other object literals should be printed in the order
// the keys are reported in (i.e., in the order presented by the Go structs).
func TestBuilder_GoEncode_SortMapKeys(t *testing.T) {
	f := builder.NewFile()

	type Ordered struct {
		SomeKey  string `river:"some_key,attr"`
		OtherKey string `river:"other_key,attr"`
	}

	// Maps are unordered because you can't iterate over their keys in a
	// consistent order.
	var unordered = map[string]interface{}{
		"key_a": 1,
		"key_c": 3,
		"key_b": 2,
	}

	f.Body().SetAttributeValue("ordered", Ordered{SomeKey: "foo", OtherKey: "bar"})
	f.Body().SetAttributeValue("unordered", unordered)

	expect := format(t, `
		ordered = {
			some_key  = "foo",
			other_key = "bar",
		}
		unordered = {
			key_a = 1,
			key_b = 2,
			key_c = 3,
		}
	`)

	require.Equal(t, expect, string(f.Bytes()))
}

func TestBuilder_AppendFrom(t *testing.T) {
	type InnerBlock struct {
		Number int `river:"number,attr"`
	}

	type Structure struct {
		Field string `river:"field,attr"`

		Block       InnerBlock   `river:"block,block"`
		OtherBlocks []InnerBlock `river:"other_block,block"`
	}

	f := builder.NewFile()
	f.Body().AppendFrom(Structure{
		Field: "some_value",

		Block: InnerBlock{Number: 1},
		OtherBlocks: []InnerBlock{
			{Number: 2},
			{Number: 3},
		},
	})

	expect := format(t, `
		field = "some_value"
	
		block {
			number = 1
		}

		other_block {
			number = 2
		}

		other_block {
			number = 3
		}
	`)

	require.Equal(t, expect, string(f.Bytes()))
}

func TestBuilder_SkipOptional(t *testing.T) {
	type Structure struct {
		OptFieldA string `river:"opt_field_a,attr,optional"`
		OptFieldB string `river:"opt_field_b,attr,optional"`
		ReqFieldA string `river:"req_field_a,attr"`
		ReqFieldB string `river:"req_field_b,attr"`
	}

	f := builder.NewFile()
	f.Body().AppendFrom(Structure{
		OptFieldA: "some_value",
		OptFieldB: "", // Zero value
		ReqFieldA: "some_value",
		ReqFieldB: "", // Zero value
	})

	expect := format(t, `
		opt_field_a = "some_value"
		req_field_a = "some_value"
		req_field_b = ""
	`)

	require.Equal(t, expect, string(f.Bytes()))
}

func format(t *testing.T, in string) string {
	t.Helper()

	f, err := parser.ParseFile(t.Name(), []byte(in))
	require.NoError(t, err)

	var buf bytes.Buffer
	require.NoError(t, printer.Fprint(&buf, f))

	return buf.String()
}

type CustomTokenizer bool

var _ builder.Tokenizer = (CustomTokenizer)(false)

func (ct CustomTokenizer) RiverTokenize() []builder.Token {
	return []builder.Token{{Tok: token.LITERAL, Lit: "CUSTOM_TOKENS"}}
}

func TestBuilder_GoEncode_Tokenizer(t *testing.T) {
	t.Run("Tokenizer", func(t *testing.T) {
		f := builder.NewFile()
		f.Body().SetAttributeValue("value", CustomTokenizer(true))

		expect := format(t, `value = CUSTOM_TOKENS`)
		require.Equal(t, expect, string(f.Bytes()))
	})

	t.Run("TextMarshaler", func(t *testing.T) {
		now := time.Now()
		expectBytes, err := now.MarshalText()
		require.NoError(t, err)

		f := builder.NewFile()
		f.Body().SetAttributeValue("value", now)

		expect := format(t, fmt.Sprintf(`value = %q`, string(expectBytes)))
		require.Equal(t, expect, string(f.Bytes()))
	})

	t.Run("Duration", func(t *testing.T) {
		dur := 15 * time.Second

		f := builder.NewFile()
		f.Body().SetAttributeValue("value", dur)

		expect := format(t, fmt.Sprintf(`value = %q`, dur.String()))
		require.Equal(t, expect, string(f.Bytes()))
	})
}

'''
'''--- pkg/river/token/builder/token.go ---
package builder

import (
	"bytes"
	"io"

	"github.com/grafana/agent/pkg/river/parser"
	"github.com/grafana/agent/pkg/river/printer"
	"github.com/grafana/agent/pkg/river/token"
)

// A Token is a wrapper around token.Token which contains the token type
// alongside its literal. Use LiteralTok as the Tok field to write literal
// characters such as whitespace.
type Token struct {
	Tok token.Token
	Lit string
}

// printFileTokens prints out the tokens as River text and formats them, writing
// the final result to w.
func printFileTokens(w io.Writer, toks []Token) (int, error) {
	var raw bytes.Buffer
	for _, tok := range toks {
		switch {
		case tok.Tok == token.LITERAL:
			raw.WriteString(tok.Lit)
		case tok.Tok == token.COMMENT:
			raw.WriteString(tok.Lit)
		case tok.Tok.IsLiteral() || tok.Tok.IsKeyword():
			raw.WriteString(tok.Lit)
		default:
			raw.WriteString(tok.Tok.String())
		}
	}

	f, err := parser.ParseFile("", raw.Bytes())
	if err != nil {
		return 0, err
	}

	wc := &writerCount{w: w}
	err = printer.Fprint(wc, f)
	return wc.n, err
}

// printExprTokens prints out the tokens as River text and formats them,
// writing the final result to w.
func printExprTokens(w io.Writer, toks []Token) (int, error) {
	var raw bytes.Buffer
	for _, tok := range toks {
		switch {
		case tok.Tok == token.LITERAL:
			raw.WriteString(tok.Lit)
		case tok.Tok.IsLiteral() || tok.Tok.IsKeyword():
			raw.WriteString(tok.Lit)
		default:
			raw.WriteString(tok.Tok.String())
		}
	}

	expr, err := parser.ParseExpression(raw.String())
	if err != nil {
		return 0, err
	}

	wc := &writerCount{w: w}
	err = printer.Fprint(wc, expr)
	return wc.n, err
}

type writerCount struct {
	w io.Writer
	n int
}

func (wc *writerCount) Write(p []byte) (n int, err error) {
	n, err = wc.w.Write(p)
	wc.n += n
	return
}

'''
'''--- pkg/river/token/builder/value_tokens.go ---
package builder

import (
	"fmt"
	"sort"

	"github.com/grafana/agent/pkg/river/internal/value"
	"github.com/grafana/agent/pkg/river/scanner"
	"github.com/grafana/agent/pkg/river/token"
)

// TODO(rfratto): check for optional values

// Tokenizer is any value which can return a raw set of tokens.
type Tokenizer interface {
	// RiverTokenize returns the raw set of River tokens which are used when
	// printing out the value with river/token/builder.
	RiverTokenize() []Token
}

func tokenEncode(val interface{}) []Token {
	return valueTokens(value.Encode(val))
}

func valueTokens(v value.Value) []Token {
	var toks []Token

	// If v is a Tokenizer, allow it to override what tokens get generated.
	if tk, ok := v.Interface().(Tokenizer); ok {
		return tk.RiverTokenize()
	}

	switch v.Type() {
	case value.TypeNull:
		toks = append(toks, Token{token.NULL, "null"})

	case value.TypeNumber:
		toks = append(toks, Token{token.NUMBER, v.Number().ToString()})

	case value.TypeString:
		toks = append(toks, Token{token.STRING, fmt.Sprintf("%q", v.Text())})

	case value.TypeBool:
		toks = append(toks, Token{token.STRING, fmt.Sprintf("%v", v.Bool())})

	case value.TypeArray:
		toks = append(toks, Token{token.LBRACK, ""})
		elems := v.Len()
		for i := 0; i < elems; i++ {
			elem := v.Index(i)

			toks = append(toks, valueTokens(elem)...)
			if i+1 < elems {
				toks = append(toks, Token{token.COMMA, ""})
			}
		}
		toks = append(toks, Token{token.RBRACK, ""})

	case value.TypeObject:
		toks = append(toks, Token{token.LCURLY, ""}, Token{token.LITERAL, "\n"})

		keys := v.Keys()

		// If v isn't an ordered object (i.e., a go map), sort the keys so they
		// have a deterministic print order.
		if !v.OrderedKeys() {
			sort.Strings(keys)
		}

		for i := 0; i < len(keys); i++ {
			if isValidIdentifier(keys[i]) {
				toks = append(toks, Token{token.IDENT, keys[i]})
			} else {
				toks = append(toks, Token{token.STRING, fmt.Sprintf("%q", keys[i])})
			}

			field, _ := v.Key(keys[i])
			toks = append(toks, Token{token.ASSIGN, ""})
			toks = append(toks, valueTokens(field)...)
			toks = append(toks, Token{token.COMMA, ""}, Token{token.LITERAL, "\n"})
		}
		toks = append(toks, Token{token.RCURLY, ""})

	case value.TypeFunction:
		toks = append(toks, Token{token.LITERAL, v.Describe()})

	case value.TypeCapsule:
		toks = append(toks, Token{token.LITERAL, v.Describe()})

	default:
		panic(fmt.Sprintf("river/token/builder: unrecognized value type %q", v.Type()))
	}

	return toks
}

func isValidIdentifier(in string) bool {
	s := scanner.New(nil, []byte(in), nil, 0)
	_, tok, lit := s.Scan()
	return tok == token.IDENT && lit == in
}

'''
'''--- pkg/river/token/file.go ---
package token

import (
	"fmt"
	"sort"
	"strconv"
)

// NoPos is the zero value for Pos. It has no file or line information
// associated with it, and NoPos.Valid is false.
var NoPos = Pos{}

// Pos is a compact representation of a position within a file. It can be
// converted into a Position for a more convenient, but larger, representation.
type Pos struct {
	file *File
	off  int
}

// String returns the string form of the Pos (the offset).
func (p Pos) String() string { return strconv.Itoa(p.off) }

// File returns the file used by the Pos. This will be nil for invalid
// positions.
func (p Pos) File() *File { return p.file }

// Position converts the Pos into a Position.
func (p Pos) Position() Position { return p.file.PositionFor(p) }

// Add creates a new Pos relative to p.
func (p Pos) Add(n int) Pos {
	return Pos{
		file: p.file,
		off:  p.off + n,
	}
}

// Offset returns the byte offset associated with Pos.
func (p Pos) Offset() int { return p.off }

// Valid reports whether the Pos is valid.
func (p Pos) Valid() bool { return p != NoPos }

// Position holds full position information for a location within an individual
// file.
type Position struct {
	Filename string // Filename (if any)
	Offset   int    // Byte offset (starting at 0)
	Line     int    // Line number (starting at 1)
	Column   int    // Offset from start of line (starting at 1)
}

// Valid reports whether the position is valid. Valid positions must have a
// Line value greater than 0.
func (pos *Position) Valid() bool { return pos.Line > 0 }

// String returns a string in one of the following forms:
//
//     file:line:column   Valid position with file name
//     file:line          Valid position with file name but no column
//     line:column        Valid position with no file name
//     line               Valid position with no file name or column
//     file               Invalid position with file name
//     -                  Invalid position with no file name
func (pos Position) String() string {
	s := pos.Filename

	if pos.Valid() {
		if s != "" {
			s += ":"
		}
		s += fmt.Sprintf("%d", pos.Line)
		if pos.Column != 0 {
			s += fmt.Sprintf(":%d", pos.Column)
		}
	}

	if s == "" {
		s = "-"
	}
	return s
}

// File holds position information for a specific file.
type File struct {
	filename string
	lines    []int // Byte offset of each line number (first element is always 0).
}

// NewFile creates a new File for storing position information.
func NewFile(filename string) *File {
	return &File{
		filename: filename,
		lines:    []int{0},
	}
}

// Pos returns a Pos given a byte offset. Pos panics if off is < 0.
func (f *File) Pos(off int) Pos {
	if off < 0 {
		panic("Pos: illegal offset")
	}
	return Pos{file: f, off: off}
}

// Name returns the name of the file.
func (f *File) Name() string { return f.filename }

// AddLine tracks a new line from a byte offset. The line offset must be larger
// than the offset for the previous line, otherwise the line offset is ignored.
func (f *File) AddLine(offset int) {
	lines := len(f.lines)
	if f.lines[lines-1] < offset {
		f.lines = append(f.lines, offset)
	}
}

// PositionFor returns a Position from an offset.
func (f *File) PositionFor(p Pos) Position {
	if p == NoPos {
		return Position{}
	}

	// Search through our line offsets to find the line/column info. The else
	// case should never happen here, but if it does, Position.Valid will return
	// false.
	var line, column int
	if i := searchInts(f.lines, p.off); i >= 0 {
		line, column = i+1, p.off-f.lines[i]+1
	}

	return Position{
		Filename: f.filename,
		Offset:   p.off,
		Line:     line,
		Column:   column,
	}
}

func searchInts(a []int, x int) int {
	return sort.Search(len(a), func(i int) bool { return a[i] > x }) - 1
}

'''
'''--- pkg/river/token/token.go ---
// Package token defines the lexical elements of a River config and utilities
// surrounding their position.
package token

// Token is an individual River lexical token.
type Token int

// List of all lexical tokens and examples that represent them.
//
// LITERAL is used by token/builder to represent literal strings for writing
// tokens, but never used for reading (so scanner never returns a
// token.LITERAL).
const (
	ILLEGAL Token = iota // Invalid token.
	LITERAL              // Literal text.
	EOF                  // End-of-file.
	COMMENT              // // Hello, world!

	literalBeg
	IDENT  // foobar
	NUMBER // 1234
	FLOAT  // 1234.0
	STRING // "foobar"
	literalEnd

	keywordBeg
	BOOL // true
	NULL // null
	keywordEnd

	operatorBeg
	OR  // ||
	AND // &&
	NOT // !

	ASSIGN // =

	EQ  // ==
	NEQ // !=
	LT  // <
	LTE // <=
	GT  // >
	GTE // >=

	ADD // +
	SUB // -
	MUL // *
	DIV // /
	MOD // %
	POW // ^

	LCURLY // {
	RCURLY // }
	LPAREN // (
	RPAREN // )
	LBRACK // [
	RBRACK // ]
	COMMA  // ,
	DOT    // .
	operatorEnd

	TERMINATOR // \n
)

var tokenNames = [...]string{
	ILLEGAL: "ILLEGAL",
	LITERAL: "LITERAL",
	EOF:     "EOF",
	COMMENT: "COMMENT",

	IDENT:  "IDENT",
	NUMBER: "NUMBER",
	FLOAT:  "FLOAT",
	STRING: "STRING",
	BOOL:   "BOOL",
	NULL:   "NULL",

	OR:  "||",
	AND: "&&",
	NOT: "!",

	ASSIGN: "=",
	EQ:     "==",
	NEQ:    "!=",
	LT:     "<",
	LTE:    "<=",
	GT:     ">",
	GTE:    ">=",

	ADD: "+",
	SUB: "-",
	MUL: "*",
	DIV: "/",
	MOD: "%",
	POW: "^",

	LCURLY: "{",
	RCURLY: "}",
	LPAREN: "(",
	RPAREN: ")",
	LBRACK: "[",
	RBRACK: "]",
	COMMA:  ",",
	DOT:    ".",

	TERMINATOR: "TERMINATOR",
}

// Lookup maps a string to its keyword token or IDENT if it's not a keyword.
func Lookup(ident string) Token {
	switch ident {
	case "true", "false":
		return BOOL
	case "null":
		return NULL
	default:
		return IDENT
	}
}

// String returns the string representation corresponding to the token.
func (t Token) String() string {
	if int(t) >= len(tokenNames) {
		return "ILLEGAL"
	}

	name := tokenNames[t]
	if name == "" {
		return "ILLEGAL"
	}
	return name
}

// GoString returns the %#v format of t.
func (t Token) GoString() string { return t.String() }

// IsKeyword returns true if the token corresponds to a keyword.
func (t Token) IsKeyword() bool { return t > keywordBeg && t < keywordEnd }

// IsLiteral returns true if the token corresponds to a literal token or
// identifier.
func (t Token) IsLiteral() bool { return t > literalBeg && t < literalEnd }

// IsOperator returns true if the token corresponds to an operator or
// delimiter.
func (t Token) IsOperator() bool { return t > operatorBeg && t < operatorEnd }

// BinaryPrecedence returns the operator precedence of the binary operator t.
// If t is not a binary operator, the result is LowestPrecedence.
func (t Token) BinaryPrecedence() int {
	switch t {
	case OR:
		return 1
	case AND:
		return 2
	case EQ, NEQ, LT, LTE, GT, GTE:
		return 3
	case ADD, SUB:
		return 4
	case MUL, DIV, MOD:
		return 5
	case POW:
		return 6
	}

	return LowestPrecedence
}

// Levels of precedence for operator tokens.
const (
	LowestPrecedence  = 0 // non-operators
	UnaryPrecedence   = 7
	HighestPrecedence = 8
)

'''
'''--- pkg/river/types.go ---
package river

import "github.com/grafana/agent/pkg/river/internal/value"

// Our types in this file are re-impelemntations of interfaces from
// value.Capsule. They are *not* defined as type aliases, since pkg.go.dev
// would show the type alias instead of the contents of that type (which IMO is
// a frustrating user experience).
//
// The types below must be kept in sync with the internal package, and the
// checks below ensure they're compatible.
var (
	_ value.Unmarshaler            = (Unmarshaler)(nil)
	_ value.Capsule                = (Capsule)(nil)
	_ value.ConvertibleFromCapsule = (ConvertibleFromCapsule)(nil)
	_ value.ConvertibleIntoCapsule = (ConvertibleIntoCapsule)(nil)
)

// The Unmarshaler interface allows a type to hook into River decoding and
// decode into another type or provide pre-decoding logic.
type Unmarshaler interface {
	// UnmarshalRiver is invoked when decoding a River value into a Go value. f
	// should be called with a pointer to a value to decode into.
	UnmarshalRiver(f func(v interface{}) error) error
}

// Capsule is an interface marker which tells River that a type should always
// be treated as a "capsule type" instead of the default type River would
// assign.
//
// Capsule types are useful for passing around arbitrary Go values in River
// expressions and for declaring new synthetic types with custom conversion
// rules.
//
// By default, only two capsule values of the same underlying Go type are
// compatible. Types which implement ConvertibleFromCapsule or
// ConvertibleToCapsule can provide custom logic for conversions from and to
// other types.
type Capsule interface {
	// RiverCapsule marks the type as a Capsule. RiverCapsule is never invoked by
	// River.
	RiverCapsule()
}

// ErrNoConversion is returned by implementations of ConvertibleFromCapsule and
// ConvertibleToCapsule when a conversion with a specific type is unavailable.
//
// Returning this error causes River to fall back to default conversion rules.
var ErrNoConversion = value.ErrNoConversion

// ConvertibleFromCapsule is a Capsule which supports custom conversion from
// any Go type which is not the same as the capsule type.
type ConvertibleFromCapsule interface {
	Capsule

	// ConvertFrom updates the ConvertibleFromCapsule value based on the value of
	// src. src may be any Go value, not just other capsules.
	//
	// ConvertFrom should return ErrNoConversion if no conversion is available
	// from src. Other errors are treated as a River decoding error.
	ConvertFrom(src interface{}) error
}

// ConvertibleIntoCapsule is a Capsule which supports custom conversion into
// into any Go type which is not the same as the capsule type.
type ConvertibleIntoCapsule interface {
	Capsule

	// ConvertInto should convert its value and store it into dst. dst will be a
	// pointer to a Go value of any type.
	//
	// ConvertInto should return ErrNoConversion if no conversion into dst is
	// available. Other errors are treated as a River decoding error.
	ConvertInto(dst interface{}) error
}

'''
'''--- pkg/river/vm/constant.go ---
package vm

import (
	"fmt"
	"strconv"

	"github.com/grafana/agent/pkg/river/internal/value"
	"github.com/grafana/agent/pkg/river/token"
)

func valueFromLiteral(lit string, tok token.Token) (value.Value, error) {
	// NOTE(rfratto): this function should never return an error, since the
	// parser only produces valid tokens; it can only fail if a user hand-builds
	// an AST with invalid literals.

	switch tok {
	case token.NULL:
		return value.Null, nil

	case token.NUMBER:
		v, err := strconv.ParseInt(lit, 0, 64)
		if err != nil {
			return value.Null, err
		}
		return value.Int(v), nil

	case token.FLOAT:
		v, err := strconv.ParseFloat(lit, 64)
		if err != nil {
			return value.Null, err
		}
		return value.Float(v), nil

	case token.STRING:
		v, err := strconv.Unquote(lit)
		if err != nil {
			return value.Null, err
		}
		return value.String(v), nil

	case token.BOOL:
		switch lit {
		case "true":
			return value.Bool(true), nil
		case "false":
			return value.Bool(false), nil
		default:
			return value.Null, fmt.Errorf("invalid boolean literal %q", lit)
		}
	default:
		panic(fmt.Sprintf("%v is not a valid token", tok))
	}
}

'''
'''--- pkg/river/vm/error.go ---
package vm

import (
	"fmt"
	"strings"

	"github.com/grafana/agent/pkg/river/ast"
	"github.com/grafana/agent/pkg/river/diag"
	"github.com/grafana/agent/pkg/river/internal/value"
	"github.com/grafana/agent/pkg/river/printer"
	"github.com/grafana/agent/pkg/river/token/builder"
)

// makeDiagnostic tries to convert err into a diag.Diagnostic. err must be an
// error from the river/internal/value package, otherwise err will be returned
// unmodified.
func makeDiagnostic(err error, assoc map[value.Value]ast.Node) error {
	var (
		node    ast.Node
		expr    strings.Builder
		message string
		cause   value.Value

		// Until we find a node, we're not a literal error.
		literal = false
	)

	isValueError := value.WalkError(err, func(err error) {
		var val value.Value

		switch ne := err.(type) {
		case value.Error:
			message = ne.Error()
			val = ne.Value
		case value.TypeError:
			message = fmt.Sprintf("should be %s, got %s", ne.Expected, ne.Value.Type())
			val = ne.Value
		case value.MissingKeyError:
			message = fmt.Sprintf("does not have field named %q", ne.Missing)
			val = ne.Value
		case value.ElementError:
			fmt.Fprintf(&expr, "[%d]", ne.Index)
			val = ne.Value
		case value.FieldError:
			fmt.Fprintf(&expr, ".%s", ne.Field)
			val = ne.Value
		}

		cause = val

		if foundNode, ok := assoc[val]; ok {
			// If we just found a direct node, we can reset the expression buffer so
			// we don't unnecessarily print element and field accesses for we can see
			// directly in the file.
			if literal {
				expr.Reset()
			}

			node = foundNode
			literal = true
		} else {
			literal = false
		}
	})
	if !isValueError {
		return err
	}

	if node != nil {
		var nodeText strings.Builder
		if err := printer.Fprint(&nodeText, node); err != nil {
			// This should never panic; printer.Fprint only fails when given an
			// unexpected type, which we never do here.
			panic(err)
		}

		// Merge the node text with the expression together (which will be relative
		// accesses to the expression).
		message = fmt.Sprintf("%s%s %s", nodeText.String(), expr.String(), message)
	} else {
		message = fmt.Sprintf("%s %s", expr.String(), message)
	}

	// Render the underlying problematic value as a string.
	var valueText string
	if cause != value.Null {
		be := builder.NewExpr()
		be.SetValue(cause.Interface())
		valueText = string(be.Bytes())
	}
	if literal {
		// Hide the value if the node itself has the error we were worried about.
		valueText = ""
	}

	d := diag.Diagnostic{
		Severity: diag.SeverityLevelError,
		Message:  message,
		Value:    valueText,
	}
	if node != nil {
		d.StartPos = ast.StartPos(node).Position()
		d.EndPos = ast.EndPos(node).Position()
	}
	return d
}

'''
'''--- pkg/river/vm/op_binary.go ---
package vm

import (
	"fmt"
	"math"
	"reflect"

	"github.com/grafana/agent/pkg/river/internal/value"
	"github.com/grafana/agent/pkg/river/token"
)

func evalBinop(lhs value.Value, op token.Token, rhs value.Value) (value.Value, error) {
	// TODO(rfratto): evalBinop should check for underflows and overflows

	// We have special handling for EQ and NEQ since it's valid to attempt to
	// compare values of any two types.
	switch op {
	case token.EQ:
		return value.Bool(valuesEqual(lhs, rhs)), nil
	case token.NEQ:
		return value.Bool(!valuesEqual(lhs, rhs)), nil
	}

	// The type of lhs and rhs must be acceptable for the binary operator.
	if !acceptableBinopType(lhs, op) {
		return value.Null, value.Error{
			Value: lhs,
			Inner: fmt.Errorf("should be one of %s for binop %s, got %s", binopAllowedTypes[op], op, lhs.Type()),
		}
	} else if !acceptableBinopType(rhs, op) {
		return value.Null, value.Error{
			Value: rhs,
			Inner: fmt.Errorf("should be one of %s for binop %s, got %s", binopAllowedTypes[op], op, rhs.Type()),
		}
	}

	// At this point, regardless of the operator, lhs and rhs must have the same
	// type.
	if lhs.Type() != rhs.Type() {
		return value.Null, value.TypeError{Value: rhs, Expected: lhs.Type()}
	}

	switch op {
	case token.OR: // bool || bool
		return value.Bool(lhs.Bool() || rhs.Bool()), nil
	case token.AND: // bool && Bool
		return value.Bool(lhs.Bool() && rhs.Bool()), nil

	case token.ADD: // number + number, string + string
		if lhs.Type() == value.TypeString {
			return value.String(lhs.Text() + rhs.Text()), nil
		}

		lhsNum, rhsNum := lhs.Number(), rhs.Number()
		switch fitNumberKinds(lhsNum.Kind(), rhsNum.Kind()) {
		case value.NumberKindUint:
			return value.Uint(lhsNum.Uint() + rhsNum.Uint()), nil
		case value.NumberKindInt:
			return value.Int(lhsNum.Int() + rhsNum.Int()), nil
		case value.NumberKindFloat:
			return value.Float(lhsNum.Float() + rhsNum.Float()), nil
		}

	case token.SUB: // number - number
		lhsNum, rhsNum := lhs.Number(), rhs.Number()
		switch fitNumberKinds(lhsNum.Kind(), rhsNum.Kind()) {
		case value.NumberKindUint:
			return value.Uint(lhsNum.Uint() - rhsNum.Uint()), nil
		case value.NumberKindInt:
			return value.Int(lhsNum.Int() - rhsNum.Int()), nil
		case value.NumberKindFloat:
			return value.Float(lhsNum.Float() - rhsNum.Float()), nil
		}

	case token.MUL: // number * number
		lhsNum, rhsNum := lhs.Number(), rhs.Number()
		switch fitNumberKinds(lhsNum.Kind(), rhsNum.Kind()) {
		case value.NumberKindUint:
			return value.Uint(lhsNum.Uint() * rhsNum.Uint()), nil
		case value.NumberKindInt:
			return value.Int(lhsNum.Int() * rhsNum.Int()), nil
		case value.NumberKindFloat:
			return value.Float(lhsNum.Float() * rhsNum.Float()), nil
		}

	case token.DIV: // number / number
		lhsNum, rhsNum := lhs.Number(), rhs.Number()
		switch fitNumberKinds(lhsNum.Kind(), rhsNum.Kind()) {
		case value.NumberKindUint:
			return value.Uint(lhsNum.Uint() / rhsNum.Uint()), nil
		case value.NumberKindInt:
			return value.Int(lhsNum.Int() / rhsNum.Int()), nil
		case value.NumberKindFloat:
			return value.Float(lhsNum.Float() / rhsNum.Float()), nil
		}

	case token.MOD: // number % number
		lhsNum, rhsNum := lhs.Number(), rhs.Number()
		switch fitNumberKinds(lhsNum.Kind(), rhsNum.Kind()) {
		case value.NumberKindUint:
			return value.Uint(lhsNum.Uint() % rhsNum.Uint()), nil
		case value.NumberKindInt:
			return value.Int(lhsNum.Int() % rhsNum.Int()), nil
		case value.NumberKindFloat:
			return value.Float(math.Mod(lhsNum.Float(), rhsNum.Float())), nil
		}

	case token.POW: // number ^ number
		lhsNum, rhsNum := lhs.Number(), rhs.Number()
		switch fitNumberKinds(lhsNum.Kind(), rhsNum.Kind()) {
		case value.NumberKindUint:
			return value.Uint(intPow(lhsNum.Uint(), rhsNum.Uint())), nil
		case value.NumberKindInt:
			return value.Int(intPow(lhsNum.Int(), rhsNum.Int())), nil
		case value.NumberKindFloat:
			return value.Float(math.Pow(lhsNum.Float(), rhsNum.Float())), nil
		}

	case token.LT: // number < number, string < string
		// Check string first.
		if lhs.Type() == value.TypeString {
			return value.Bool(lhs.Text() < rhs.Text()), nil
		}

		// Not a string; must be a number.
		lhsNum, rhsNum := lhs.Number(), rhs.Number()
		switch fitNumberKinds(lhsNum.Kind(), rhsNum.Kind()) {
		case value.NumberKindUint:
			return value.Bool(lhsNum.Uint() < rhsNum.Uint()), nil
		case value.NumberKindInt:
			return value.Bool(lhsNum.Int() < rhsNum.Int()), nil
		case value.NumberKindFloat:
			return value.Bool(lhsNum.Float() < rhsNum.Float()), nil
		}

	case token.GT: // number > number, string > string
		// Check string first.
		if lhs.Type() == value.TypeString {
			return value.Bool(lhs.Text() > rhs.Text()), nil
		}

		// Not a string; must be a number.
		lhsNum, rhsNum := lhs.Number(), rhs.Number()
		switch fitNumberKinds(lhsNum.Kind(), rhsNum.Kind()) {
		case value.NumberKindUint:
			return value.Bool(lhsNum.Uint() > rhsNum.Uint()), nil
		case value.NumberKindInt:
			return value.Bool(lhsNum.Int() > rhsNum.Int()), nil
		case value.NumberKindFloat:
			return value.Bool(lhsNum.Float() > rhsNum.Float()), nil
		}

	case token.LTE: // number <= number, string <= string
		// Check string first.
		if lhs.Type() == value.TypeString {
			return value.Bool(lhs.Text() <= rhs.Text()), nil
		}

		// Not a string; must be a number.
		lhsNum, rhsNum := lhs.Number(), rhs.Number()
		switch fitNumberKinds(lhsNum.Kind(), rhsNum.Kind()) {
		case value.NumberKindUint:
			return value.Bool(lhsNum.Uint() <= rhsNum.Uint()), nil
		case value.NumberKindInt:
			return value.Bool(lhsNum.Int() <= rhsNum.Int()), nil
		case value.NumberKindFloat:
			return value.Bool(lhsNum.Float() <= rhsNum.Float()), nil
		}

	case token.GTE: // number >= number, string >= string
		// Check string first.
		if lhs.Type() == value.TypeString {
			return value.Bool(lhs.Text() >= rhs.Text()), nil
		}

		// Not a string; must be a number.
		lhsNum, rhsNum := lhs.Number(), rhs.Number()
		switch fitNumberKinds(lhsNum.Kind(), rhsNum.Kind()) {
		case value.NumberKindUint:
			return value.Bool(lhsNum.Uint() >= rhsNum.Uint()), nil
		case value.NumberKindInt:
			return value.Bool(lhsNum.Int() >= rhsNum.Int()), nil
		case value.NumberKindFloat:
			return value.Bool(lhsNum.Float() >= rhsNum.Float()), nil
		}
	}

	panic("river/vm: unreachable")
}

// valuesEqual returns true if two River Values are equal.
func valuesEqual(lhs value.Value, rhs value.Value) bool {
	if lhs.Type() != rhs.Type() {
		// Two values with different types are never equal.
		return false
	}

	switch lhs.Type() {
	case value.TypeNull:
		// Nothing to compare here: both lhs and rhs have the null type,
		// so they're equal.
		return true

	case value.TypeNumber:
		// Two numbers are equal if they have equal values. However, we have to
		// determine what comparison we want to do and upcast the values to a
		// different Go type as needed (so that 3 == 3.0 is true).
		lhsNum, rhsNum := lhs.Number(), rhs.Number()
		switch fitNumberKinds(lhsNum.Kind(), rhsNum.Kind()) {
		case value.NumberKindUint:
			return lhsNum.Uint() == rhsNum.Uint()
		case value.NumberKindInt:
			return lhsNum.Int() == rhsNum.Int()
		case value.NumberKindFloat:
			return lhsNum.Float() == rhsNum.Float()
		}

	case value.TypeString:
		return lhs.Text() == rhs.Text()

	case value.TypeBool:
		return lhs.Bool() == rhs.Bool()

	case value.TypeArray:
		// Two arrays are equal if they have equal elements.
		if lhs.Len() != rhs.Len() {
			return false
		}
		for i := 0; i < lhs.Len(); i++ {
			if !valuesEqual(lhs.Index(i), rhs.Index(i)) {
				return false
			}
		}
		return true

	case value.TypeObject:
		// Two objects are equal if they have equal elements.
		if lhs.Len() != rhs.Len() {
			return false
		}
		for _, key := range lhs.Keys() {
			lhsElement, _ := lhs.Key(key)
			rhsElement, inRHS := rhs.Key(key)
			if !inRHS {
				return false
			}
			if !valuesEqual(lhsElement, rhsElement) {
				return false
			}
		}
		return true

	case value.TypeFunction:
		// Two functions are never equal. We can't compare functions in Go, so
		// there's no way to compare them in River right now.
		return false

	case value.TypeCapsule:
		// Two capsules are only equal if the underlying values are deeply equal.
		return reflect.DeepEqual(lhs.Interface(), rhs.Interface())
	}

	panic("river/vm: unreachable")
}

// binopAllowedTypes maps what type of values are permitted for a specific
// binary operation.
//
// token.EQ and token.NEQ are not included as they're handled separately from
// other binary ops.
var binopAllowedTypes = map[token.Token][]value.Type{
	token.OR:  {value.TypeBool},
	token.AND: {value.TypeBool},

	token.ADD: {value.TypeNumber, value.TypeString},
	token.SUB: {value.TypeNumber},
	token.MUL: {value.TypeNumber},
	token.DIV: {value.TypeNumber},
	token.MOD: {value.TypeNumber},
	token.POW: {value.TypeNumber},

	token.LT:  {value.TypeNumber, value.TypeString},
	token.GT:  {value.TypeNumber, value.TypeString},
	token.LTE: {value.TypeNumber, value.TypeString},
	token.GTE: {value.TypeNumber, value.TypeString},
}

func acceptableBinopType(val value.Value, op token.Token) bool {
	allowed, ok := binopAllowedTypes[op]
	if !ok {
		panic("river/vm: unexpected binop type")
	}

	actualType := val.Type()
	for _, allowType := range allowed {
		if allowType == actualType {
			return true
		}
	}
	return false
}

func fitNumberKinds(a, b value.NumberKind) value.NumberKind {
	aPrec, bPrec := numberKindPrec[a], numberKindPrec[b]
	if aPrec > bPrec {
		return a
	}
	return b
}

var numberKindPrec = map[value.NumberKind]int{
	value.NumberKindUint:  0,
	value.NumberKindInt:   1,
	value.NumberKindFloat: 2,
}

func intPow[Number int64 | uint64](n, m Number) Number {
	if m == 0 {
		return 1
	}
	result := n
	for i := Number(2); i <= m; i++ {
		result *= n
	}
	return result
}

'''
'''--- pkg/river/vm/op_unary.go ---
package vm

import (
	"github.com/grafana/agent/pkg/river/internal/value"
	"github.com/grafana/agent/pkg/river/token"
)

func evalUnaryOp(op token.Token, val value.Value) (value.Value, error) {
	switch op {
	case token.NOT:
		if val.Type() != value.TypeBool {
			return value.Null, value.TypeError{Value: val, Expected: value.TypeBool}
		}
		return value.Bool(!val.Bool()), nil

	case token.SUB:
		if val.Type() != value.TypeNumber {
			return value.Null, value.TypeError{Value: val, Expected: value.TypeNumber}
		}

		valNum := val.Number()
		switch valNum.Kind() {
		case value.NumberKindInt, value.NumberKindUint:
			// It doesn't make much sense to invert a uint, so we always cast to an
			// int and return an int.
			return value.Int(-valNum.Int()), nil
		case value.NumberKindFloat:
			return value.Float(-valNum.Float()), nil
		}
	}

	panic("river/vm: unreachable")
}

'''
'''--- pkg/river/vm/vm.go ---
// Package vm provides a River expression evaluator.
package vm

import (
	"fmt"
	"reflect"
	"strings"

	"github.com/grafana/agent/pkg/river/ast"
	"github.com/grafana/agent/pkg/river/diag"
	"github.com/grafana/agent/pkg/river/internal/rivertags"
	"github.com/grafana/agent/pkg/river/internal/stdlib"
	"github.com/grafana/agent/pkg/river/internal/value"
)

// Evaluator evaluates River AST nodes into Go values. Each Evaluator is bound
// to a single AST node. To evaluate the node, call Evaluate.
type Evaluator struct {
	// node for the AST.
	//
	// Each Evaluator is bound to a single node to allow for future performance
	// optimizations, allowing for precomputing and storing the result of
	// anything that is constant.
	node ast.Node
}

// New creates a new Evaluator for the given AST node. The given node must be
// either an *ast.File, *ast.BlockStmt, ast.Body, or assignable to an ast.Expr.
func New(node ast.Node) *Evaluator {
	return &Evaluator{node: node}
}

// Evaluate evaluates the Evaluator's node into a River value and decodes that
// value into the Go value v.
//
// Each call to Evaluate may provide a different scope with new values for
// available variables. If a variable used by the Evaluator's node isn't
// defined in scope or any of the parent scopes, Evaluate will return an error.
func (vm *Evaluator) Evaluate(scope *Scope, v interface{}) (err error) {
	// Track a map that allows us to associate values with ast.Nodes so we can
	// return decorated error messages.
	assoc := make(map[value.Value]ast.Node)

	defer func() {
		if err != nil {
			// Decorate the error on return.
			err = makeDiagnostic(err, assoc)
		}
	}()

	switch node := vm.node.(type) {
	case *ast.BlockStmt, ast.Body:
		rv := reflect.ValueOf(v)
		if rv.Kind() != reflect.Pointer {
			panic(fmt.Sprintf("river/vm: expected pointer, got %s", rv.Kind()))
		}
		return vm.evaluateBlockOrBody(scope, assoc, node, rv)
	case *ast.File:
		rv := reflect.ValueOf(v)
		if rv.Kind() != reflect.Pointer {
			panic(fmt.Sprintf("river/vm: expected pointer, got %s", rv.Kind()))
		}
		return vm.evaluateBlockOrBody(scope, assoc, node.Body, rv)
	default:
		expr, ok := node.(ast.Expr)
		if !ok {
			panic(fmt.Sprintf("river/vm: unexpected value type %T", node))
		}
		val, err := vm.evaluateExpr(scope, assoc, expr)
		if err != nil {
			return err
		}
		return value.Decode(val, v)
	}
}

func (vm *Evaluator) evaluateBlockOrBody(scope *Scope, assoc map[value.Value]ast.Node, node ast.Node, rv reflect.Value) error {
	// TODO(rfratto): the errors returned by this function are missing context to
	// be able to print line numbers. We need to return decorated error types.

	// Before decoding the block, we need to temporarily take the address of rv
	// to handle the case of it implementing the unmarshaler interface.
	if rv.CanAddr() {
		rv = rv.Addr()
	}

	if ru, ok := rv.Interface().(value.Unmarshaler); ok {
		return ru.UnmarshalRiver(func(v interface{}) error {
			rv := reflect.ValueOf(v)
			if rv.Kind() != reflect.Pointer {
				panic(fmt.Sprintf("river/vm: expected pointer, got %s", rv.Kind()))
			}
			return vm.evaluateBlockOrBody(scope, assoc, node, rv.Elem())
		})
	}

	// Fully deference rv and allocate pointers as necessary.
	for rv.Kind() == reflect.Pointer {
		if rv.IsNil() {
			rv.Set(reflect.New(rv.Type().Elem()))
		}
		rv = rv.Elem()
	}

	// TODO(rfratto): potentially loosen this restriction and allow decoding into
	// an interface{} or map[string]interface{}.
	if rv.Kind() != reflect.Struct {
		panic(fmt.Sprintf("river/vm: can only evaluate blocks into structs, got %s", rv.Kind()))
	}

	tfs := rivertags.Get(rv.Type())

	var stmts ast.Body
	switch node := node.(type) {
	case *ast.BlockStmt:
		// Decode the block label first.
		if err := vm.evaluateBlockLabel(node, tfs, rv); err != nil {
			return err
		}
		stmts = node.Body
	case ast.Body:
		stmts = node
	default:
		panic(fmt.Sprintf("river/vm: unrecognized node type %T", node))
	}

	var (
		foundAttrs  = make(map[string][]*ast.AttributeStmt, len(tfs))
		foundBlocks = make(map[string][]*ast.BlockStmt, len(tfs))
	)
	for _, stmt := range stmts {
		switch stmt := stmt.(type) {
		case *ast.AttributeStmt:
			name := stmt.Name.Name
			foundAttrs[name] = append(foundAttrs[name], stmt)

		case *ast.BlockStmt:
			name := strings.Join(stmt.Name, ".")
			foundBlocks[name] = append(foundBlocks[name], stmt)

		default:
			panic(fmt.Sprintf("river: unrecognized ast.Stmt type %T", stmt))
		}
	}

	var (
		consumedAttrs  = make(map[string]struct{}, len(foundAttrs))
		consumedBlocks = make(map[string]struct{}, len(foundBlocks))
	)
	for _, tf := range tfs {
		fullName := strings.Join(tf.Name, ".")

		if tf.IsAttr() {
			consumedAttrs[fullName] = struct{}{}
		} else if tf.IsBlock() {
			consumedBlocks[fullName] = struct{}{}
		}

		// Skip over fields that aren't attributes or blocks.
		if !tf.IsAttr() && !tf.IsBlock() {
			continue
		}

		var (
			attrs  = foundAttrs[fullName]
			blocks = foundBlocks[fullName]
		)

		// Validity checks for attributes and blocks
		switch {
		case len(attrs) == 0 && len(blocks) == 0 && tf.IsOptional():
			// Optional field with no set values. Skip.
			continue

		case tf.IsAttr() && len(blocks) > 0:
			return fmt.Errorf("%q must be an attribute, but is used as a block", fullName)
		case tf.IsAttr() && len(attrs) == 0 && !tf.IsOptional():
			return fmt.Errorf("missing required attribute %q", fullName)
		case tf.IsAttr() && len(attrs) > 1:
			// While blocks may be specified multiple times (when the struct field
			// accepts a slice or an array), attributes may only ever be specified
			// once.
			return fmt.Errorf("attribute %q may only be set once", fullName)

		case tf.IsBlock() && len(attrs) > 0:
			return fmt.Errorf("%q must be a block, but is used as an attribute", fullName)
		case tf.IsBlock() && len(blocks) == 0 && !tf.IsOptional():
			// TODO(rfratto): does it ever make sense for children blocks to be required?
			return fmt.Errorf("missing required block %q", fullName)

		case len(attrs) > 0 && len(blocks) > 0:
			// NOTE(rfratto): it's not possible to reach this condition given the
			// statements above, but this is left in defensively in case there is a
			// bug with the validity checks.
			return fmt.Errorf("%q may only be used as a block or an attribute, but found both", fullName)
		}

		field := rv.FieldByIndex(tf.Index)

		// Decode.
		switch {
		case tf.IsBlock():
			decodeField := prepareDecodeValue(field)

			switch decodeField.Kind() {
			case reflect.Slice:
				// Reset the slice length to zero.
				decodeField.Set(reflect.MakeSlice(decodeField.Type(), len(blocks), len(blocks)))

				// Now, iterate over all of the block values and decode them
				// individually into the slice.
				for i, block := range blocks {
					decodeElement := prepareDecodeValue(decodeField.Index(i))
					err := vm.evaluateBlockOrBody(scope, assoc, block, decodeElement)
					if err != nil {
						return err
					}
				}

			case reflect.Array:
				if decodeField.Len() != len(blocks) {
					return fmt.Errorf(
						"block %q must be specified exactly %d times, but was specified %d times",
						fullName,
						decodeField.Len(),
						len(blocks),
					)
				}

				for i := 0; i < decodeField.Len(); i++ {
					decodeElement := prepareDecodeValue(decodeField.Index(i))
					err := vm.evaluateBlockOrBody(scope, assoc, blocks[i], decodeElement)
					if err != nil {
						return err
					}
				}

			default:
				if len(blocks) > 1 {
					return fmt.Errorf("block %q may only be specified once", tf.Name)
				}
				err := vm.evaluateBlockOrBody(scope, assoc, blocks[0], decodeField)
				if err != nil {
					return err
				}
			}

		case tf.IsAttr():
			val, err := vm.evaluateExpr(scope, assoc, attrs[0].Value)
			if err != nil {
				return err
			}

			// We're reconverting our reflect.Value back into an interface{}, so we
			// need to also turn it back into a pointer for decoding.
			if err := value.Decode(val, field.Addr().Interface()); err != nil {
				return err
			}
		}
	}

	// Make sure that all of the attributes and blocks defined in the AST node
	// matched up with a field from our struct.
	for attr := range foundAttrs {
		if _, consumed := consumedAttrs[attr]; !consumed {
			return fmt.Errorf("unrecognized attribute name %q", attr)
		}
	}
	for block := range foundBlocks {
		if _, consumed := consumedBlocks[block]; !consumed {
			return fmt.Errorf("unrecognized block name %q", block)
		}
	}

	return nil
}

func (vm *Evaluator) evaluateBlockLabel(node *ast.BlockStmt, tfs []rivertags.Field, rv reflect.Value) error {
	var (
		labelField rivertags.Field
		foundField bool
	)
	for _, tf := range tfs {
		if tf.Flags&rivertags.FlagLabel != 0 {
			labelField = tf
			foundField = true
			break
		}
	}

	// Check for user errors first.
	//
	// We return parser.Error here to restrict the position of the error to just
	// the name. We might be able to clean this up in the future by extending
	// ValueError to have an explicit position.
	switch {
	case node.Label == "" && foundField: // No user label, but struct expects one
		return diag.Diagnostic{
			Severity: diag.SeverityLevelError,
			StartPos: node.NamePos.Position(),
			EndPos:   node.LCurlyPos.Position(),
			Message:  fmt.Sprintf("block %q requires non-empty label", strings.Join(node.Name, ".")),
		}
	case node.Label != "" && !foundField: // User label, but struct doesn't expect one
		return diag.Diagnostic{
			Severity: diag.SeverityLevelError,
			StartPos: node.NamePos.Position(),
			EndPos:   node.LCurlyPos.Position(),
			Message:  fmt.Sprintf("block %q does not support specifying labels", strings.Join(node.Name, ".")),
		}
	}

	if node.Label == "" {
		// no-op: no labels to set.
		return nil
	}

	var (
		field     = rv.FieldByIndex(labelField.Index)
		fieldType = field.Type()
	)
	if !reflect.TypeOf(node.Label).AssignableTo(fieldType) {
		// The Label struct field needs to be a string.
		panic(fmt.Sprintf("river/vm: cannot assign block label to non-string type %s", fieldType))
	}
	field.Set(reflect.ValueOf(node.Label))
	return nil
}

// prepareDecodeValue prepares v for decoding. Pointers will be fully
// deferenced until finding a non-pointer value. nil pointers will be
// allocated.
func prepareDecodeValue(v reflect.Value) reflect.Value {
	for v.Kind() == reflect.Pointer {
		if v.IsNil() {
			v.Set(reflect.New(v.Type().Elem()))
		}
		v = v.Elem()
	}
	return v
}

func (vm *Evaluator) evaluateExpr(scope *Scope, assoc map[value.Value]ast.Node, expr ast.Expr) (v value.Value, err error) {
	defer func() {
		if v != value.Null {
			assoc[v] = expr
		}
	}()

	switch expr := expr.(type) {
	case *ast.LiteralExpr:
		return valueFromLiteral(expr.Value, expr.Kind)

	case *ast.BinaryExpr:
		lhs, err := vm.evaluateExpr(scope, assoc, expr.Left)
		if err != nil {
			return value.Null, err
		}
		rhs, err := vm.evaluateExpr(scope, assoc, expr.Right)
		if err != nil {
			return value.Null, err
		}
		return evalBinop(lhs, expr.Kind, rhs)

	case *ast.ArrayExpr:
		vals := make([]value.Value, len(expr.Elements))
		for i, element := range expr.Elements {
			val, err := vm.evaluateExpr(scope, assoc, element)
			if err != nil {
				return value.Null, err
			}
			vals[i] = val
		}
		return value.Array(vals...), nil

	case *ast.ObjectExpr:
		fields := make(map[string]value.Value, len(expr.Fields))
		for _, field := range expr.Fields {
			val, err := vm.evaluateExpr(scope, assoc, field.Value)
			if err != nil {
				return value.Null, err
			}
			fields[field.Name.Name] = val
		}
		return value.Object(fields), nil

	case *ast.IdentifierExpr:
		val, found := scope.Lookup(expr.Ident.Name)
		if !found {
			return value.Null, diag.Diagnostic{
				Severity: diag.SeverityLevelError,
				StartPos: ast.StartPos(expr).Position(),
				EndPos:   ast.EndPos(expr).Position(),
				Message:  fmt.Sprintf("identifier %q does not exist", expr.Ident.Name),
			}
		}
		return value.Encode(val), nil

	case *ast.AccessExpr:
		val, err := vm.evaluateExpr(scope, assoc, expr.Value)
		if err != nil {
			return value.Null, err
		}

		switch val.Type() {
		case value.TypeObject:
			res, ok := val.Key(expr.Name.Name)
			if !ok {
				return value.Null, diag.Diagnostic{
					Severity: diag.SeverityLevelError,
					StartPos: ast.StartPos(expr.Name).Position(),
					EndPos:   ast.EndPos(expr.Name).Position(),
					Message:  fmt.Sprintf("field %q does not exist", expr.Name.Name),
				}
			}
			return res, nil
		default:
			return value.Null, value.Error{
				Value: val,
				Inner: fmt.Errorf("cannot access field %q on value of type %s", expr.Name.Name, val.Type()),
			}
		}

	case *ast.IndexExpr:
		val, err := vm.evaluateExpr(scope, assoc, expr.Value)
		if err != nil {
			return value.Null, err
		}
		idx, err := vm.evaluateExpr(scope, assoc, expr.Index)
		if err != nil {
			return value.Null, err
		}

		switch val.Type() {
		case value.TypeArray:
			// Arrays are indexed with a number.
			if idx.Type() != value.TypeNumber {
				return value.Null, value.TypeError{Value: idx, Expected: value.TypeNumber}
			}
			intIndex := int(idx.Int())

			if intIndex < 0 || intIndex >= val.Len() {
				return value.Null, value.Error{
					Value: idx,
					Inner: fmt.Errorf("index %d is out of range of array with length %d", intIndex, val.Len()),
				}
			}
			return val.Index(intIndex), nil

		case value.TypeObject:
			// Objects are indexed with a string.
			if idx.Type() != value.TypeString {
				return value.Null, value.TypeError{Value: idx, Expected: value.TypeNumber}
			}

			field, ok := val.Key(idx.Text())
			if !ok {
				return value.Null, diag.Diagnostic{
					Severity: diag.SeverityLevelError,
					StartPos: ast.StartPos(expr.Index).Position(),
					EndPos:   ast.EndPos(expr.Index).Position(),
					Message:  fmt.Sprintf("field %q does not exist", idx.Text()),
				}
			}
			return field, nil

		default:
			return value.Null, value.Error{
				Value: val,
				Inner: fmt.Errorf("expected object or array, got %s", val.Type()),
			}
		}

	case *ast.ParenExpr:
		return vm.evaluateExpr(scope, assoc, expr.Inner)

	case *ast.UnaryExpr:
		val, err := vm.evaluateExpr(scope, assoc, expr.Value)
		if err != nil {
			return value.Null, err
		}
		return evalUnaryOp(expr.Kind, val)

	case *ast.CallExpr:
		funcVal, err := vm.evaluateExpr(scope, assoc, expr.Value)
		if err != nil {
			return funcVal, err
		}
		if funcVal.Type() != value.TypeFunction {
			return value.Null, value.TypeError{Value: funcVal, Expected: value.TypeFunction}
		}

		args := make([]value.Value, len(expr.Args))
		for i := 0; i < len(expr.Args); i++ {
			args[i], err = vm.evaluateExpr(scope, assoc, expr.Args[i])
			if err != nil {
				return value.Null, err
			}
		}
		return funcVal.Call(args...)

	default:
		panic(fmt.Sprintf("river/vm: unexpected ast.Expr type %T", expr))
	}
}

// A Scope exposes a set of variables available to use during evaluation.
type Scope struct {
	// Parent optionally points to a parent Scope containing more variable.
	// Variables defined in children scopes take precedence over variables of the
	// same name found in parent scopes.
	Parent *Scope

	// Variables holds the list of available variable names that can be used when
	// evaluating a node.
	//
	// Values in the Variables map should considered immutable after passed to
	// Evaluate; maps and slices will be copied by reference for performance
	// optimizations.
	Variables map[string]interface{}
}

// Lookup looks up a named identifier from the scope, all of the scope's
// parents, and the stdlib.
func (s *Scope) Lookup(name string) (interface{}, bool) {
	// Traverse the scope first, then fall back to stdlib.
	for s != nil {
		if val, ok := s.Variables[name]; ok {
			return val, true
		}
		s = s.Parent
	}
	if fn, ok := stdlib.Functions[name]; ok {
		return fn, true
	}
	return nil, false
}

'''
'''--- pkg/river/vm/vm_benchmarks_test.go ---
package vm_test

import (
	"reflect"
	"testing"

	"github.com/grafana/agent/pkg/river/parser"
	"github.com/grafana/agent/pkg/river/vm"
	"github.com/stretchr/testify/require"
)

func BenchmarkExprs(b *testing.B) {
	// Shared scope across all tests below
	scope := &vm.Scope{
		Variables: map[string]interface{}{
			"foobar": int(42),
		},
	}

	tt := []struct {
		name   string
		input  string
		expect interface{}
	}{
		// Binops
		{"or", `false || true`, bool(true)},
		{"and", `true && false`, bool(false)},
		{"math/eq", `3 == 5`, bool(false)},
		{"math/neq", `3 != 5`, bool(true)},
		{"math/lt", `3 < 5`, bool(true)},
		{"math/lte", `3 <= 5`, bool(true)},
		{"math/gt", `3 > 5`, bool(false)},
		{"math/gte", `3 >= 5`, bool(false)},
		{"math/add", `3 + 5`, int(8)},
		{"math/sub", `3 - 5`, int(-2)},
		{"math/mul", `3 * 5`, int(15)},
		{"math/div", `3 / 5`, int(0)},
		{"math/mod", `5 % 3`, int(2)},
		{"math/pow", `3 ^ 5`, int(243)},
		{"binop chain", `3 + 5 * 2`, int(13)}, // Chain multiple binops

		// Identifier
		{"ident lookup", `foobar`, int(42)},

		// Arrays
		{"array", `[0, 1, 2]`, []int{0, 1, 2}},

		// Objects
		{"object to map", `{ a = 5, b = 10 }`, map[string]int{"a": 5, "b": 10}},
		{
			name: "object to struct",
			input: `{
					name = "John Doe", 
					age = 42,
			}`,
			expect: struct {
				Name    string `river:"name,attr"`
				Age     int    `river:"age,attr"`
				Country string `river:"country,attr,optional"`
			}{
				Name: "John Doe",
				Age:  42,
			},
		},

		// Access
		{"access", `{ a = 15 }.a`, int(15)},
		{"nested access", `{ a = { b = 12 } }.a.b`, int(12)},

		// Indexing
		{"index", `[0, 1, 2][1]`, int(1)},
		{"nested index", `[[1,2,3]][0][2]`, int(3)},

		// Paren
		{"paren", `(15)`, int(15)},

		// Unary
		{"unary not", `!true`, bool(false)},
		{"unary neg", `-15`, int(-15)},
	}

	for _, tc := range tt {
		b.Run(tc.name, func(b *testing.B) {
			b.StopTimer()
			expr, err := parser.ParseExpression(tc.input)
			require.NoError(b, err)

			eval := vm.New(expr)
			b.StartTimer()

			expectType := reflect.TypeOf(tc.expect)

			for i := 0; i < b.N; i++ {
				vPtr := reflect.New(expectType).Interface()
				_ = eval.Evaluate(scope, vPtr)
			}
		})
	}
}

'''
'''--- pkg/river/vm/vm_block_test.go ---
package vm_test

import (
	"testing"

	"github.com/grafana/agent/pkg/river/ast"
	"github.com/grafana/agent/pkg/river/parser"
	"github.com/grafana/agent/pkg/river/vm"
	"github.com/stretchr/testify/require"
)

// This file contains tests for decoding blocks.

func TestVM_File(t *testing.T) {
	type block struct {
		String string `river:"string,attr"`
		Number int    `river:"number,attr,optional"`
	}
	type file struct {
		SettingA int `river:"setting_a,attr"`
		SettingB int `river:"setting_b,attr,optional"`

		Block block `river:"some_block,block,optional"`
	}

	input := `
	setting_a = 15 

	some_block {
		string = "Hello, world!"
	}
	`

	expect := file{
		SettingA: 15,
		Block: block{
			String: "Hello, world!",
		},
	}

	res, err := parser.ParseFile(t.Name(), []byte(input))
	require.NoError(t, err)

	eval := vm.New(res)

	var actual file
	require.NoError(t, eval.Evaluate(nil, &actual))
	require.Equal(t, expect, actual)
}

func TestVM_Block_Attributes(t *testing.T) {
	t.Run("Decodes attributes", func(t *testing.T) {
		type block struct {
			Number int    `river:"number,attr"`
			String string `river:"string,attr"`
		}

		input := `some_block {
			number = 15 
			string = "Hello, world!"
		}`
		eval := vm.New(parseBlock(t, input))

		var actual block
		require.NoError(t, eval.Evaluate(nil, &actual))
		require.Equal(t, 15, actual.Number)
		require.Equal(t, "Hello, world!", actual.String)
	})

	t.Run("Fails if attribute used as block", func(t *testing.T) {
		type block struct {
			Number int `river:"number,attr"`
		}

		input := `some_block {
			number {} 
		}`
		eval := vm.New(parseBlock(t, input))

		err := eval.Evaluate(nil, &block{})
		require.EqualError(t, err, `"number" must be an attribute, but is used as a block`)
	})

	t.Run("Fails if required attributes are not present", func(t *testing.T) {
		type block struct {
			Number int    `river:"number,attr"`
			String string `river:"string,attr"`
		}

		input := `some_block {
			number = 15 
		}`
		eval := vm.New(parseBlock(t, input))

		err := eval.Evaluate(nil, &block{})
		require.EqualError(t, err, `missing required attribute "string"`)
	})

	t.Run("Succeeds if optional attributes are not present", func(t *testing.T) {
		type block struct {
			Number int    `river:"number,attr"`
			String string `river:"string,attr,optional"`
		}

		input := `some_block {
			number = 15 
		}`
		eval := vm.New(parseBlock(t, input))

		var actual block
		require.NoError(t, eval.Evaluate(nil, &actual))
		require.Equal(t, 15, actual.Number)
		require.Equal(t, "", actual.String)
	})

	t.Run("Fails if attribute is not defined in struct", func(t *testing.T) {
		type block struct {
			Number int `river:"number,attr"`
		}

		input := `some_block {
			number  = 15 
			invalid = "This attribute does not exist!"
		}`
		eval := vm.New(parseBlock(t, input))

		err := eval.Evaluate(nil, &block{})
		require.EqualError(t, err, `unrecognized attribute name "invalid"`)
	})

	t.Run("Supports arbitrarily nested struct pointer fields", func(t *testing.T) {
		type block struct {
			NumberA int    `river:"number_a,attr"`
			NumberB *int   `river:"number_b,attr"`
			NumberC **int  `river:"number_c,attr"`
			NumberD ***int `river:"number_d,attr"`
		}

		input := `some_block {
			number_a = 15 
			number_b = 20
			number_c = 25
			number_d = 30
		}`
		eval := vm.New(parseBlock(t, input))

		var actual block
		require.NoError(t, eval.Evaluate(nil, &actual))
		require.Equal(t, 15, actual.NumberA)
		require.Equal(t, 20, *actual.NumberB)
		require.Equal(t, 25, **actual.NumberC)
		require.Equal(t, 30, ***actual.NumberD)
	})
}

func TestVM_Block_Children_Blocks(t *testing.T) {
	type childBlock struct {
		Attr bool `river:"attr,attr"`
	}

	t.Run("Decodes children blocks", func(t *testing.T) {
		type block struct {
			Value int        `river:"value,attr"`
			Child childBlock `river:"child.block,block"`
		}

		input := `some_block {
			value = 15 

			child.block { attr = true }
		}`
		eval := vm.New(parseBlock(t, input))

		var actual block
		require.NoError(t, eval.Evaluate(nil, &actual))
		require.Equal(t, 15, actual.Value)
		require.True(t, actual.Child.Attr)
	})

	t.Run("Decodes multiple instances of children blocks", func(t *testing.T) {
		type block struct {
			Value    int          `river:"value,attr"`
			Children []childBlock `river:"child.block,block"`
		}

		input := `some_block {
			value = 10 

			child.block { attr = true }
			child.block { attr = false }
			child.block { attr = true }
		}`
		eval := vm.New(parseBlock(t, input))

		var actual block
		require.NoError(t, eval.Evaluate(nil, &actual))
		require.Equal(t, 10, actual.Value)
		require.Len(t, actual.Children, 3)
		require.Equal(t, true, actual.Children[0].Attr)
		require.Equal(t, false, actual.Children[1].Attr)
		require.Equal(t, true, actual.Children[2].Attr)
	})

	t.Run("Decodes multiple instances of children blocks into an array", func(t *testing.T) {
		type block struct {
			Value    int           `river:"value,attr"`
			Children [3]childBlock `river:"child.block,block"`
		}

		input := `some_block {
			value = 15

			child.block { attr = true }
			child.block { attr = false }
			child.block { attr = true }
		}`
		eval := vm.New(parseBlock(t, input))

		var actual block
		require.NoError(t, eval.Evaluate(nil, &actual))
		require.Equal(t, 15, actual.Value)
		require.Equal(t, true, actual.Children[0].Attr)
		require.Equal(t, false, actual.Children[1].Attr)
		require.Equal(t, true, actual.Children[2].Attr)
	})

	t.Run("Fails if block used as an attribute", func(t *testing.T) {
		type block struct {
			Child childBlock `river:"child,block"`
		}

		input := `some_block {
			child = 15
		}`
		eval := vm.New(parseBlock(t, input))

		err := eval.Evaluate(nil, &block{})
		require.EqualError(t, err, `"child" must be a block, but is used as an attribute`)
	})

	t.Run("Fails if required children blocks are not present", func(t *testing.T) {
		type block struct {
			Value int        `river:"value,attr"`
			Child childBlock `river:"child.block,block"`
		}

		input := `some_block {
			value = 15
		}`
		eval := vm.New(parseBlock(t, input))

		err := eval.Evaluate(nil, &block{})
		require.EqualError(t, err, `missing required block "child.block"`)
	})

	t.Run("Succeeds if optional children blocks are not present", func(t *testing.T) {
		type block struct {
			Value int        `river:"value,attr"`
			Child childBlock `river:"child.block,block,optional"`
		}

		input := `some_block {
			value = 15 
		}`
		eval := vm.New(parseBlock(t, input))

		var actual block
		require.NoError(t, eval.Evaluate(nil, &actual))
		require.Equal(t, 15, actual.Value)
	})

	t.Run("Fails if child block is not defined in struct", func(t *testing.T) {
		type block struct {
			Value int `river:"value,attr"`
		}

		input := `some_block {
			value = 15

			child.block { attr = true }
		}`
		eval := vm.New(parseBlock(t, input))

		err := eval.Evaluate(nil, &block{})
		require.EqualError(t, err, `unrecognized block name "child.block"`)
	})

	t.Run("Supports arbitrarily nested struct pointer fields", func(t *testing.T) {
		type block struct {
			BlockA childBlock    `river:"block_a,block"`
			BlockB *childBlock   `river:"block_b,block"`
			BlockC **childBlock  `river:"block_c,block"`
			BlockD ***childBlock `river:"block_d,block"`
		}

		input := `some_block {
			block_a { attr = true } 
			block_b { attr = false } 
			block_c { attr = true } 
			block_d { attr = false } 
		}`
		eval := vm.New(parseBlock(t, input))

		var actual block
		require.NoError(t, eval.Evaluate(nil, &actual))
		require.Equal(t, true, (actual.BlockA).Attr)
		require.Equal(t, false, (*actual.BlockB).Attr)
		require.Equal(t, true, (**actual.BlockC).Attr)
		require.Equal(t, false, (***actual.BlockD).Attr)
	})

	// TODO(rfratto): decode all blocks into a []*ast.BlockStmt field.
}

func TestVM_Block_Label(t *testing.T) {
	t.Run("Decodes label into string field", func(t *testing.T) {
		type block struct {
			Label string `river:",label"`
		}

		input := `some_block "label_value_1" {}`
		eval := vm.New(parseBlock(t, input))

		var actual block
		require.NoError(t, eval.Evaluate(nil, &actual))
		require.Equal(t, "label_value_1", actual.Label)
	})

	t.Run("Struct must have label field if block is labeled", func(t *testing.T) {
		type block struct{}

		input := `some_block "label_value_2" {}`
		eval := vm.New(parseBlock(t, input))

		err := eval.Evaluate(nil, &block{})
		require.EqualError(t, err, `1:1: block "some_block" does not support specifying labels`)
	})

	t.Run("Block must have label if struct accepts label", func(t *testing.T) {
		type block struct {
			Label string `river:",label"`
		}

		input := `some_block {}`
		eval := vm.New(parseBlock(t, input))

		err := eval.Evaluate(nil, &block{})
		require.EqualError(t, err, `1:1: block "some_block" requires non-empty label`)
	})

	t.Run("Block must have non-empty label if struct accepts label", func(t *testing.T) {
		type block struct {
			Label string `river:",label"`
		}

		input := `some_block "" {}`
		eval := vm.New(parseBlock(t, input))

		err := eval.Evaluate(nil, &block{})
		require.EqualError(t, err, `1:1: block "some_block" requires non-empty label`)
	})
}

func TestVM_Block_Unmarshaler(t *testing.T) {
	type OuterBlock struct {
		FieldA   string  `river:"field_a,attr"`
		Settings Setting `river:"some.settings,block"`
	}

	input := `
		field_a = "foobar"
		some.settings {
			field_a = "fizzbuzz"
			field_b = "helloworld"
		}
	`

	file, err := parser.ParseFile(t.Name(), []byte(input))
	require.NoError(t, err)

	eval := vm.New(file)

	var actual OuterBlock
	require.NoError(t, eval.Evaluate(nil, &actual))
	require.True(t, actual.Settings.Called, "UnmarshalRiver did not get invoked")
}

type Setting struct {
	FieldA string `river:"field_a,attr"`
	FieldB string `river:"field_b,attr"`

	Called bool
}

func (s *Setting) UnmarshalRiver(f func(interface{}) error) error {
	s.Called = true
	type setting Setting
	return f((*setting)(s))
}

func parseBlock(t *testing.T, input string) *ast.BlockStmt {
	t.Helper()

	res, err := parser.ParseFile("", []byte(input))
	require.NoError(t, err)
	require.Len(t, res.Body, 1)

	stmt, ok := res.Body[0].(*ast.BlockStmt)
	require.True(t, ok, "Expected stmt to be a ast.BlockStmt, got %T", res.Body[0])
	return stmt
}

'''
'''--- pkg/river/vm/vm_errors_test.go ---
package vm_test

import (
	"testing"

	"github.com/grafana/agent/pkg/river/parser"
	"github.com/grafana/agent/pkg/river/vm"
	"github.com/stretchr/testify/require"
)

func TestVM_ExprErrors(t *testing.T) {
	type Target struct {
		Key struct {
			Object struct {
				Field1 []int `river:"field1,attr"`
			} `river:"object,attr"`
		} `river:"key,attr"`
	}

	tt := []struct {
		name   string
		input  string
		into   interface{}
		scope  *vm.Scope
		expect string
	}{
		{
			name:   "basic wrong type",
			input:  `key = true`,
			into:   &Target{},
			expect: "test:1:7: true should be object, got bool",
		},
		{
			name: "deeply nested literal",
			input: `
				key = {
					object = {
						field1 = [15, 30, "Hello, world!"],
					},
				}
			`,
			into:   &Target{},
			expect: `test:4:25: "Hello, world!" should be number, got string`,
		},
		{
			name:  "deeply nested indirect",
			input: `key = key_value`,
			into:  &Target{},
			scope: &vm.Scope{
				Variables: map[string]interface{}{
					"key_value": map[string]interface{}{
						"object": map[string]interface{}{
							"field1": []interface{}{15, 30, "Hello, world!"},
						},
					},
				},
			},
			expect: `test:1:7: key_value.object.field1[2] should be number, got string`,
		},
		{
			name:  "complex expr",
			input: `key = [0, 1, 2]`,
			into: &struct {
				Key string `river:"key,attr"`
			}{},
			expect: `test:1:7: [0, 1, 2] should be string, got array`,
		},
	}

	for _, tc := range tt {
		t.Run(tc.name, func(t *testing.T) {
			res, err := parser.ParseFile("test", []byte(tc.input))
			require.NoError(t, err)

			eval := vm.New(res)
			err = eval.Evaluate(tc.scope, tc.into)
			require.EqualError(t, err, tc.expect)
		})
	}
}

'''
'''--- pkg/river/vm/vm_stdlib_test.go ---
package vm_test

import (
	"fmt"
	"testing"

	"github.com/grafana/agent/pkg/river/parser"
	"github.com/grafana/agent/pkg/river/vm"
	"github.com/stretchr/testify/require"
)

func TestVM_Stdlib(t *testing.T) {
	t.Setenv("TEST_VAR", "Hello!")

	tt := []struct {
		name   string
		input  string
		expect interface{}
	}{
		{"env", `env("TEST_VAR")`, string("Hello!")},
		{"concat", `concat([true, "foo"], [], [false, 1])`, []interface{}{true, "foo", false, 1}},
		{"unmarshal_json object", `unmarshal_json("{\"foo\": \"bar\"}")`, map[string]interface{}{"foo": "bar"}},
		{"unmarshal_json array", `unmarshal_json("[0, 1, 2]")`, []interface{}{float64(0), float64(1), float64(2)}},
		{"unmarshal_json nil field", `unmarshal_json("{\"foo\": null}")`, map[string]interface{}{"foo": nil}},
		{"unmarshal_json nil array element", `unmarshal_json("[0, null]")`, []interface{}{float64(0), nil}},
	}

	for _, tc := range tt {
		t.Run(tc.name, func(t *testing.T) {
			expr, err := parser.ParseExpression(tc.input)
			require.NoError(t, err)

			eval := vm.New(expr)

			var v interface{}
			require.NoError(t, eval.Evaluate(nil, &v))
			require.Equal(t, tc.expect, v)
		})
	}
}

func BenchmarkConcat(b *testing.B) {
	// There's a bit of setup work to do here: we want to create a scope
	// holding a slice of the Data type, which has a fair amount of data in
	// it.
	//
	// We then want to pass it through concat.
	//
	// If the code path is fully optimized, there will be no intermediate
	// translations to interface{}.
	type Data map[string]string
	type Body struct {
		Values []Data `river:"values,attr"`
	}

	in := `values = concat(values_ref)`
	f, err := parser.ParseFile("", []byte(in))
	require.NoError(b, err)

	eval := vm.New(f)

	valuesRef := make([]Data, 0, 20)
	for i := 0; i < 20; i++ {
		data := make(Data, 20)
		for j := 0; j < 20; j++ {
			var (
				key   = fmt.Sprintf("key_%d", i+1)
				value = fmt.Sprintf("value_%d", i+1)
			)
			data[key] = value
		}
		valuesRef = append(valuesRef, data)
	}
	scope := &vm.Scope{
		Variables: map[string]interface{}{
			"values_ref": valuesRef,
		},
	}

	// Reset timer before running the actual test
	b.ResetTimer()

	for i := 0; i < b.N; i++ {
		var b Body
		_ = eval.Evaluate(scope, &b)
	}
}

'''
'''--- pkg/river/vm/vm_test.go ---
package vm_test

import (
	"reflect"
	"strings"
	"testing"
	"unicode"

	"github.com/grafana/agent/pkg/river/parser"
	"github.com/grafana/agent/pkg/river/scanner"
	"github.com/grafana/agent/pkg/river/token"
	"github.com/grafana/agent/pkg/river/vm"
	"github.com/stretchr/testify/require"
)

func TestVM_Evaluate_Literals(t *testing.T) {
	tt := map[string]struct {
		input  string
		expect interface{}
	}{
		"number to int":     {`12`, int(12)},
		"number to int8":    {`13`, int8(13)},
		"number to int16":   {`14`, int16(14)},
		"number to int32":   {`15`, int32(15)},
		"number to int64":   {`16`, int64(16)},
		"number to uint":    {`17`, uint(17)},
		"number to uint8":   {`18`, uint8(18)},
		"number to uint16":  {`19`, uint16(19)},
		"number to uint32":  {`20`, uint32(20)},
		"number to uint64":  {`21`, uint64(21)},
		"number to float32": {`22`, float32(22)},
		"number to float64": {`23`, float64(23)},
		"number to string":  {`24`, string("24")},

		"float to float32": {`3.2`, float32(3.2)},
		"float to float64": {`3.5`, float64(3.5)},
		"float to string":  {`3.9`, string("3.9")},

		"string to string":  {`"Hello, world!"`, string("Hello, world!")},
		"string to int":     {`"12"`, int(12)},
		"string to float64": {`"12"`, float64(12)},
	}

	for name, tc := range tt {
		t.Run(name, func(t *testing.T) {
			expr, err := parser.ParseExpression(tc.input)
			require.NoError(t, err)

			eval := vm.New(expr)

			vPtr := reflect.New(reflect.TypeOf(tc.expect)).Interface()
			require.NoError(t, eval.Evaluate(nil, vPtr))

			actual := reflect.ValueOf(vPtr).Elem().Interface()
			require.Equal(t, tc.expect, actual)
		})
	}
}

func TestVM_Evaluate(t *testing.T) {
	// Shared scope across all tests below
	scope := &vm.Scope{
		Variables: map[string]interface{}{
			"foobar": int(42),
		},
	}

	tt := []struct {
		input  string
		expect interface{}
	}{
		// Binops
		{`true || false`, bool(true)},
		{`false || false`, bool(false)},
		{`true && false`, bool(false)},
		{`true && true`, bool(true)},
		{`3 == 5`, bool(false)},
		{`3 == 3`, bool(true)},
		{`3 != 5`, bool(true)},
		{`3 < 5`, bool(true)},
		{`3 <= 5`, bool(true)},
		{`3 > 5`, bool(false)},
		{`3 >= 5`, bool(false)},
		{`3 + 5`, int(8)},
		{`3 - 5`, int(-2)},
		{`3 * 5`, int(15)},
		{`3.0 / 5.0`, float64(0.6)},
		{`5 % 3`, int(2)},
		{`3 ^ 5`, int(243)},
		{`3 + 5 * 2`, int(13)}, // Chain multiple binops

		// Identifier
		{`foobar`, int(42)},

		// Arrays
		{`[]`, []int{}},
		{`[0, 1, 2]`, []int{0, 1, 2}},
		{`[true, false]`, []bool{true, false}},

		// Objects
		{`{ a = 5, b = 10 }`, map[string]int{"a": 5, "b": 10}},
		{
			input: `{
					name = "John Doe", 
					age = 42,
			}`,
			expect: struct {
				Name    string `river:"name,attr"`
				Age     int    `river:"age,attr"`
				Country string `river:"country,attr,optional"`
			}{
				Name: "John Doe",
				Age:  42,
			},
		},

		// Access
		{`{ a = 15 }.a`, int(15)},
		{`{ a = { b = 12 } }.a.b`, int(12)},

		// Indexing
		{`[0, 1, 2][1]`, int(1)},
		{`[[1,2,3]][0][2]`, int(3)},
		{`[true, false][0]`, bool(true)},

		// Paren
		{`(15)`, int(15)},

		// Unary
		{`!true`, bool(false)},
		{`!false`, bool(true)},
		{`-15`, int(-15)},
	}

	for _, tc := range tt {
		name := trimWhitespace(tc.input)

		t.Run(name, func(t *testing.T) {
			expr, err := parser.ParseExpression(tc.input)
			require.NoError(t, err)

			eval := vm.New(expr)

			vPtr := reflect.New(reflect.TypeOf(tc.expect)).Interface()
			require.NoError(t, eval.Evaluate(scope, vPtr))

			actual := reflect.ValueOf(vPtr).Elem().Interface()
			require.Equal(t, tc.expect, actual)
		})
	}
}

func TestVM_Evaluate_Null(t *testing.T) {
	expr, err := parser.ParseExpression("null")
	require.NoError(t, err)

	eval := vm.New(expr)

	var v interface{}
	require.NoError(t, eval.Evaluate(nil, &v))
	require.Nil(t, v)
}

func TestVM_Evaluate_IdentifierExpr(t *testing.T) {
	t.Run("Valid lookup", func(t *testing.T) {
		scope := &vm.Scope{
			Variables: map[string]interface{}{
				"foobar": 15,
			},
		}

		expr, err := parser.ParseExpression(`foobar`)
		require.NoError(t, err)

		eval := vm.New(expr)

		var actual int
		require.NoError(t, eval.Evaluate(scope, &actual))
		require.Equal(t, 15, actual)
	})

	t.Run("Invalid lookup", func(t *testing.T) {
		expr, err := parser.ParseExpression(`foobar`)
		require.NoError(t, err)

		eval := vm.New(expr)

		var v interface{}
		err = eval.Evaluate(nil, &v)
		require.EqualError(t, err, `1:1: identifier "foobar" does not exist`)
	})
}

func TestVM_Evaluate_AccessExpr(t *testing.T) {
	t.Run("Lookup optional field", func(t *testing.T) {
		type Person struct {
			Name string `river:"name,attr,optional"`
		}

		scope := &vm.Scope{
			Variables: map[string]interface{}{
				"person": Person{},
			},
		}

		expr, err := parser.ParseExpression(`person.name`)
		require.NoError(t, err)

		eval := vm.New(expr)

		var actual string
		require.NoError(t, eval.Evaluate(scope, &actual))
		require.Equal(t, "", actual)
	})

	t.Run("Invalid lookup", func(t *testing.T) {
		expr, err := parser.ParseExpression(`{ a = 15 }.b`)
		require.NoError(t, err)

		eval := vm.New(expr)

		var v interface{}
		err = eval.Evaluate(nil, &v)
		require.EqualError(t, err, `1:12: field "b" does not exist`)
	})
}

func trimWhitespace(in string) string {
	f := token.NewFile("")

	s := scanner.New(f, []byte(in), nil, 0)

	var out strings.Builder

	for {
		_, tok, lit := s.Scan()
		if tok == token.EOF {
			break
		}

		if lit != "" {
			_, _ = out.WriteString(lit)
		} else {
			_, _ = out.WriteString(tok.String())
		}
	}

	return strings.TrimFunc(out.String(), unicode.IsSpace)
}

'''
'''--- pkg/server/config.go ---
package server

import (
	"flag"

	"github.com/weaveworks/common/logging"
)

// Config holds dynamic configuration options for a Server.
type Config struct {
	LogLevel  logging.Level  `yaml:"log_level"`
	LogFormat logging.Format `yaml:"log_format"`

	GRPC GRPCConfig `yaml:",inline"`
	HTTP HTTPConfig `yaml:",inline"`
}

// UnmarshalYAML unmarshals the server config with defaults applied.
func (c *Config) UnmarshalYAML(unmarshal func(interface{}) error) error {
	*c = DefaultConfig

	type config Config
	return unmarshal((*config)(c))
}

// HTTPConfig holds dynamic configuration options for the HTTP server.
type HTTPConfig struct {
	TLSConfig TLSConfig `yaml:"http_tls_config"`
}

// GRPCConfig holds dynamic configuration options for the gRPC server.
type GRPCConfig struct {
	TLSConfig TLSConfig `yaml:"grpc_tls_config"`
}

// Default configuration structs.
var (
	DefaultConfig = Config{
		GRPC:      DefaultGRPCConfig,
		HTTP:      DefaultHTTPConfig,
		LogLevel:  DefaultLogLevel,
		LogFormat: DefaultLogFormat,
	}

	DefaultHTTPConfig = HTTPConfig{
		// No non-zero defaults yet
	}

	DefaultGRPCConfig = GRPCConfig{
		// No non-zero defaults yet
	}

	emptyFlagSet    = flag.NewFlagSet("", flag.ExitOnError)
	DefaultLogLevel = func() logging.Level {
		var lvl logging.Level
		lvl.RegisterFlags(emptyFlagSet)
		return lvl
	}()
	DefaultLogFormat = func() logging.Format {
		var fmt logging.Format
		fmt.RegisterFlags(emptyFlagSet)
		return fmt
	}()
)

'''
'''--- pkg/server/flags.go ---
package server

import (
	"flag"
	"math"
	"net"
	"strconv"
	"time"
)

// Flags hold static configuration options for a Server.
type Flags struct {
	RegisterInstrumentation bool
	GracefulShutdownTimeout time.Duration

	LogSourceIPs       bool
	LogSourceIPsHeader string
	LogSourceIPsRegex  string

	GRPC GRPCFlags
	HTTP HTTPFlags
}

// HTTPFlags hold static configuration options for the HTTP server.
type HTTPFlags struct {
	UseTLS bool

	InMemoryAddr string

	ListenNetwork string
	ListenAddress string // host:port
	ConnLimit     int

	ReadTimeout  time.Duration
	WriteTimeout time.Duration
	IdleTimeout  time.Duration
}

// ListenHostPort splits the ListenAddress into a listen host and listen port.
// Returns an error if the ListenAddress isn't valid.
func (f HTTPFlags) ListenHostPort() (host string, port int, err error) {
	var portStr string
	host, portStr, err = net.SplitHostPort(f.ListenAddress)
	if err != nil {
		return
	}
	port, err = strconv.Atoi(portStr)
	return
}

// GRPCFlags hold static configuration options for the gRPC server.
type GRPCFlags struct {
	UseTLS bool

	InMemoryAddr string

	ListenNetwork string
	ListenAddress string // host:port
	ConnLimit     int

	MaxRecvMsgSize           int
	MaxSendMsgSize           int
	MaxConcurrentStreams     uint
	MaxConnectionIdle        time.Duration
	MaxConnectionAge         time.Duration
	MaxConnectionAgeGrace    time.Duration
	KeepaliveTime            time.Duration
	KeepaliveTimeout         time.Duration
	MinTimeBetweenPings      time.Duration
	PingWithoutStreamAllowed bool
}

// ListenHostPort splits the ListenAddress into a listen host and listen port.
// Returns an error if the ListenAddress isn't valid.
func (f GRPCFlags) ListenHostPort() (host string, port int, err error) {
	var portStr string
	host, portStr, err = net.SplitHostPort(f.ListenAddress)
	if err != nil {
		return
	}
	port, err = strconv.Atoi(portStr)
	return
}

var infinity = time.Duration(math.MaxInt64)

// Default options structs.
var (
	DefaultFlags = Flags{
		RegisterInstrumentation: true,
		GracefulShutdownTimeout: 30 * time.Second,

		HTTP: DefaultHTTPFlags,
		GRPC: DefaultGRPCFlags,
	}

	DefaultHTTPFlags = HTTPFlags{
		InMemoryAddr:  "agent.internal:12345",
		ListenNetwork: "tcp",
		ListenAddress: "127.0.0.1:12345",
		ReadTimeout:   30 * time.Second,
		WriteTimeout:  30 * time.Second,
		IdleTimeout:   120 * time.Second,
	}

	DefaultGRPCFlags = GRPCFlags{
		InMemoryAddr:          "agent.internal:12346",
		ListenNetwork:         "tcp",
		ListenAddress:         "127.0.0.1:12346",
		MaxRecvMsgSize:        4 * 1024 * 1024,
		MaxSendMsgSize:        4 * 1024 * 1024,
		MaxConcurrentStreams:  100,
		MaxConnectionIdle:     infinity,
		MaxConnectionAge:      infinity,
		MaxConnectionAgeGrace: infinity,
		KeepaliveTime:         2 * time.Hour,
		KeepaliveTimeout:      20 * time.Second,
		MinTimeBetweenPings:   5 * time.Minute,
	}
)

// RegisterFlags registers flags for c to the given FlagSet.
func (f *Flags) RegisterFlags(fs *flag.FlagSet) {
	d := DefaultFlags

	fs.BoolVar(&f.RegisterInstrumentation, "server.register-instrumentation", d.RegisterInstrumentation, "Register the intrumentation handlers (e.g., /metrics)")
	fs.DurationVar(&f.GracefulShutdownTimeout, "server.graceful-shutdown-timeout", d.GracefulShutdownTimeout, "Timeout for a graceful server shutdown")
	fs.BoolVar(&f.LogSourceIPs, "server.log.source-ips.enabled", d.LogSourceIPs, "Log IP address of client for incoming requests")
	fs.StringVar(&f.LogSourceIPsHeader, "server.log.source-ips.header", d.LogSourceIPsHeader, "Header field storing the source IPs. Only used if server.log-source-ips-enabled is true. Defaults to Forwarded, X-Real-IP, and X-Forwarded-For")
	fs.StringVar(&f.LogSourceIPsRegex, "server.log.source-ips.regex", d.LogSourceIPsRegex, "Regex for extracting the source IPs from the matched header. The first capture group will be used for the extracted IP address. Only used if server.log-source-ips-enabled is true.")

	f.HTTP.RegisterFlags(fs)
	f.GRPC.RegisterFlags(fs)
}

// RegisterFlags registers flags for c to the given FlagSet.
func (f *HTTPFlags) RegisterFlags(fs *flag.FlagSet) {
	d := DefaultHTTPFlags

	fs.BoolVar(&f.UseTLS, "server.http.enable-tls", d.UseTLS, "Enable TLS for the HTTP server.")
	fs.StringVar(&f.ListenAddress, "server.http.address", d.ListenAddress, "HTTP server listen host:port. Takes precedence over YAML listen flags when set.")
	fs.StringVar(&f.ListenNetwork, "server.http.network", d.ListenNetwork, "HTTP server listen network")
	fs.IntVar(&f.ConnLimit, "server.http.conn-limit", d.ConnLimit, "Maximum number of simultaneous HTTP connections (0 = unlimited)")
	fs.DurationVar(&f.ReadTimeout, "server.http.read-timeout", d.ReadTimeout, "HTTP server read timeout")
	fs.DurationVar(&f.WriteTimeout, "server.http.write-timeout", d.WriteTimeout, "HTTP server write timeout")
	fs.DurationVar(&f.IdleTimeout, "server.http.idle-timeout", d.IdleTimeout, "HTTP server idle timeout")
	fs.StringVar(&f.InMemoryAddr, "server.http.in-memory-addr", d.InMemoryAddr, "Address used to internally make in-memory requests to the HTTP server. Override if it collides with a real URL.")
}

// RegisterFlags registers flags for c to the given FlagSet.
func (f *GRPCFlags) RegisterFlags(fs *flag.FlagSet) {
	d := DefaultGRPCFlags

	fs.BoolVar(&f.UseTLS, "server.grpc.enable-tls", d.UseTLS, "Enable TLS for the gRPC server.")
	fs.StringVar(&f.ListenAddress, "server.grpc.address", d.ListenAddress, "gRPC server listen host:port. Takes precedence over YAML listen flags when set.")
	fs.StringVar(&f.ListenNetwork, "server.grpc.network", d.ListenNetwork, "gRPC server listen network")
	fs.IntVar(&f.ConnLimit, "server.grpc.conn-limit", d.ConnLimit, "Maximum number of simultaneous gRPC connections (0 = unlimited)")
	fs.IntVar(&f.MaxRecvMsgSize, "server.grpc.max-recv-msg-size-bytes", d.MaxRecvMsgSize, "Maximum size in bytes for received gRPC messages")
	fs.IntVar(&f.MaxSendMsgSize, "server.grpc.max-send-msg-size-bytes", d.MaxSendMsgSize, "Maximum size in bytes for send gRPC messages")
	fs.UintVar(&f.MaxConcurrentStreams, "server.grpc.max-concurrent-streams", d.MaxConcurrentStreams, "Maximum number of concurrent gRPC streams (0 = unlimited)")
	fs.DurationVar(&f.MaxConnectionIdle, "server.grpc.keepalive.max-connection-idle", d.MaxConnectionIdle, "Time to wait before closing idle gRPC connections")
	fs.DurationVar(&f.MaxConnectionAge, "server.grpc.keepalive.max-connection-age", d.MaxConnectionAge, "Maximum age for any gRPC connection for a graceful shutdown")
	fs.DurationVar(&f.MaxConnectionAgeGrace, "server.grpc.keepalive.max-connection-age-grace", d.MaxConnectionAgeGrace, "Grace period to forceibly close connections after a graceful shutdown starts")
	fs.DurationVar(&f.KeepaliveTime, "server.grpc.keepalive.time", d.KeepaliveTime, "Frequency to send keepalive pings from the server")
	fs.DurationVar(&f.KeepaliveTimeout, "server.grpc.keepalive.timeout", d.KeepaliveTimeout, "How long to wait for a keepalive pong before closing the connection")
	fs.DurationVar(&f.MinTimeBetweenPings, "server.grpc.keepalive.min-time-between-pings", d.MinTimeBetweenPings, "Maximum frequency that clients may send pings at")
	fs.BoolVar(&f.PingWithoutStreamAllowed, "server.grpc.keepalive.ping-without-stream-allowed", d.PingWithoutStreamAllowed, "Allow clients to send pings without having a gRPC stream")
	fs.StringVar(&f.InMemoryAddr, "server.grpc.in-memory-addr", d.InMemoryAddr, "Address used to internally make in-memory requests to the gRPC server. Override if it collides with a real URL.")
}

'''
'''--- pkg/server/logger.go ---
package server

import (
	"sync"

	"github.com/go-kit/log"
	"github.com/weaveworks/common/logging"

	cortex_log "github.com/cortexproject/cortex/pkg/util/log"
)

// Logger implements Go Kit's log.Logger interface. It supports being
// dynamically updated at runtime.
type Logger struct {
	// mut protects against race conditions accessing l, which can be modified
	// and accessed concurrently if ApplyConfig and Log are called at the same
	// time.
	mut sync.RWMutex
	l   log.Logger

	// makeLogger will default to defaultLogger. It's a struct
	// member to make testing work properly.
	makeLogger func(*Config) (log.Logger, error)
}

// NewLogger creates a new Logger.
func NewLogger(cfg *Config) *Logger {
	return newLogger(cfg, defaultLogger)
}

// NewLoggerFromLevel creates a new logger from logging.Level and logging.Format.
func NewLoggerFromLevel(lvl logging.Level, fmt logging.Format) *Logger {
	logger, err := makeDefaultLogger(lvl, fmt)
	if err != nil {
		panic(err)
	}
	return &Logger{
		l: logger,
	}
}

func newLogger(cfg *Config, ctor func(*Config) (log.Logger, error)) *Logger {
	l := Logger{makeLogger: ctor}
	if err := l.ApplyConfig(cfg); err != nil {
		panic(err)
	}
	return &l
}

// ApplyConfig applies configuration changes to the logger.
func (l *Logger) ApplyConfig(cfg *Config) error {
	l.mut.Lock()
	defer l.mut.Unlock()

	newLogger, err := l.makeLogger(cfg)
	if err != nil {
		return err
	}

	l.l = newLogger
	return nil
}

func defaultLogger(cfg *Config) (log.Logger, error) {
	return makeDefaultLogger(cfg.LogLevel, cfg.LogFormat)
}

func makeDefaultLogger(lvl logging.Level, fmt logging.Format) (log.Logger, error) {
	var l log.Logger

	l, err := cortex_log.NewPrometheusLogger(lvl, fmt)
	if err != nil {
		return nil, err
	}

	// There are two wrappers on the log so skip two extra stacks vs default
	return log.With(l, "caller", log.Caller(5)), nil
}

// Log logs a log line.
func (l *Logger) Log(kvps ...interface{}) error {
	l.mut.RLock()
	defer l.mut.RUnlock()
	return l.l.Log(kvps...)
}

// GoKitLogger creates a logging.Interface from a log.Logger.
func GoKitLogger(l log.Logger) logging.Interface {
	return logging.GoKit(l)
}

'''
'''--- pkg/server/logger_test.go ---
package server

import (
	"bytes"
	"testing"

	"github.com/go-kit/log"
	"github.com/go-kit/log/level"
	"github.com/stretchr/testify/require"
	"gopkg.in/yaml.v2"
)

func TestLogger_DefaultParameters(t *testing.T) {
	makeLogger := func(cfg *Config) (log.Logger, error) {
		var l log.Logger
		require.Equal(t, "info", cfg.LogLevel.String())
		require.Equal(t, "logfmt", cfg.LogFormat.String())
		return l, nil
	}
	newLogger(&DefaultConfig, makeLogger).makeLogger(&DefaultConfig)
}

func TestLogger_ApplyConfig(t *testing.T) {
	var buf bytes.Buffer
	makeLogger := func(cfg *Config) (log.Logger, error) {
		l := log.NewLogfmtLogger(log.NewSyncWriter(&buf))
		if cfg.LogFormat.String() == "json" {
			l = log.NewJSONLogger(log.NewSyncWriter(&buf))
		}
		l = level.NewFilter(l, cfg.LogLevel.Gokit)
		return l, nil
	}

	var cfg Config
	cfgText := `log_level: error`

	err := yaml.Unmarshal([]byte(cfgText), &cfg)
	require.NoError(t, err)

	l := newLogger(&cfg, makeLogger)
	level.Debug(l).Log("msg", "this should not appear")

	cfgText = `
log_level: debug
log_format: json`
	err = yaml.Unmarshal([]byte(cfgText), &cfg)
	require.NoError(t, err)

	err = l.ApplyConfig(&cfg)
	require.NoError(t, err)

	level.Debug(l).Log("msg", "this should appear")
	require.JSONEq(t, `{
		"level":"debug",
		"msg":"this should appear"
	}`, buf.String())
}

'''
'''--- pkg/server/logger_windows.go ---
package server

import (
	"runtime"
	"strings"

	"github.com/weaveworks/common/logging"

	"github.com/go-kit/log/level"

	"github.com/go-kit/log"
	el "golang.org/x/sys/windows/svc/eventlog"
)

// Default name for the Grafana Agent under Windows
const ServiceName = "Grafana Agent"

// NewWindowsEventLogger creates a new logger that writes to the event log
func NewWindowsEventLogger(cfg *Config) *Logger {
	return newLogger(cfg, makeWindowsEventLogger)
}

func makeWindowsEventLogger(cfg *Config) (log.Logger, error) {
	// Setup the log in windows events
	err := el.InstallAsEventCreate(ServiceName, el.Error|el.Info|el.Warning)

	// Agent should expect an error of 'already exists' if the Event Log sink has already previously been installed
	if err != nil && !strings.Contains(err.Error(), "already exists") {
		return nil, err
	}
	il, err := el.Open(ServiceName)
	if err != nil {
		return nil, err
	}

	// Ensure the logger gets closed when the GC runs. It's valid to have more than one win logger open concurrently.
	runtime.SetFinalizer(il, func(l *el.Log) {
		l.Close()
	})

	// These are setup to be writers for each Windows log level
	// Setup this way so we can utilize all the benefits of logformatter
	infoLogger := newWinLogWrapper(cfg.LogFormat, func(p []byte) error {
		return il.Info(1, string(p))
	})
	warningLogger := newWinLogWrapper(cfg.LogFormat, func(p []byte) error {
		return il.Warning(1, string(p))
	})

	errorLogger := newWinLogWrapper(cfg.LogFormat, func(p []byte) error {
		return il.Error(1, string(p))
	})

	wl := &winLogger{
		errorLogger:   errorLogger,
		infoLogger:    infoLogger,
		warningLogger: warningLogger,
	}
	return level.NewFilter(wl, cfg.LogLevel.Gokit), nil
}

// Looks through the key value pairs in the log for level and extract the value
func getLevel(keyvals ...interface{}) level.Value {
	for i := 0; i < len(keyvals); i++ {
		if vo, ok := keyvals[i].(level.Value); ok {
			return vo
		}
	}
	return nil
}

func newWinLogWrapper(format logging.Format, write func(p []byte) error) log.Logger {
	infoWriter := &winLogWriter{writer: write}
	infoLogger := log.NewLogfmtLogger(infoWriter)
	if format.String() == "json" {
		infoLogger = log.NewJSONLogger(infoWriter)
	}
	return infoLogger
}

type winLogger struct {
	errorLogger   log.Logger
	infoLogger    log.Logger
	warningLogger log.Logger
}

func (w *winLogger) Log(keyvals ...interface{}) error {
	lvl := getLevel(keyvals...)
	// 3 different loggers are used so that agent can utilize the formatting features of go-kit logging
	// if agent did not use this then the windows logger uses different function calls for different levels
	// this is paired with the fact that the io.Writer interface only gives a byte array.
	switch lvl {
	case level.DebugValue():
		return w.infoLogger.Log(keyvals...)
	case level.InfoValue():
		return w.infoLogger.Log(keyvals...)
	case level.WarnValue():
		return w.warningLogger.Log(keyvals...)
	case level.ErrorValue():
		return w.errorLogger.Log(keyvals...)
	default:
		return w.infoLogger.Log(keyvals...)
	}
}

type winLogWriter struct {
	writer func(p []byte) error
}

func (i *winLogWriter) Write(p []byte) (n int, err error) {
	return len(p), i.writer(p)
}

'''
'''--- pkg/server/server.go ---
// Package server implements the HTTP and gRPC server used throughout Grafana
// Agent.
//
// It is a grafana/agent-specific fork of github.com/weaveworks/common/server.
package server

import (
	"context"
	"errors"
	"fmt"
	"net"
	"net/http"
	_ "net/http/pprof" // anonymous import to get the pprof handler registered
	"sync"

	"github.com/go-kit/log"
	"github.com/go-kit/log/level"
	"github.com/gorilla/mux"
	grpc_middleware "github.com/grpc-ecosystem/go-grpc-middleware"
	"github.com/hashicorp/go-multierror"
	"github.com/oklog/run"
	otgrpc "github.com/opentracing-contrib/go-grpc"
	"github.com/opentracing/opentracing-go"
	"github.com/prometheus/client_golang/prometheus"
	"github.com/prometheus/client_golang/prometheus/promhttp"
	"github.com/rfratto/ckit/memconn"
	"github.com/weaveworks/common/logging"
	"github.com/weaveworks/common/middleware"
	"golang.org/x/net/netutil"
	"google.golang.org/grpc"
	"google.golang.org/grpc/keepalive"
)

// DialContextFunc is a function matching the signature of
// net.Dialer.DialContext.
type DialContextFunc func(ctx context.Context, network string, addr string) (net.Conn, error)

// Server wraps an HTTP and gRPC server with some common initialization.
//
// Unless instrumentation is disabled in the Servers config, Prometheus metrics
// will be automatically generated for the server.
type Server struct {
	flagsMut sync.Mutex
	flags    Flags

	// Listeners for in-memory connections. These never use TLS.
	httpMemListener *memconn.Listener
	grpcMemListener *memconn.Listener

	// Listeners to use for connections. These will use TLS when TLS is enabled.
	httpListener net.Listener
	grpcListener net.Listener

	updateHTTPTLS func(TLSConfig) error
	updateGRPCTLS func(TLSConfig) error

	HTTP       *mux.Router
	HTTPServer *http.Server
	GRPC       *grpc.Server

	// DialContext creates a connection to the given network/address. If address
	// matches the Server's internal HTTP or gRPC address, an internal in-memory
	// connection will be opened.
	DialContext DialContextFunc
}

type metrics struct {
	tcpConnections      *prometheus.GaugeVec
	tcpConnectionsLimit *prometheus.GaugeVec
	requestDuration     *prometheus.HistogramVec
	receivedMessageSize *prometheus.HistogramVec
	sentMessageSize     *prometheus.HistogramVec
	inflightRequests    *prometheus.GaugeVec
}

func newMetrics(r prometheus.Registerer) (*metrics, error) {
	var m metrics

	// Create metrics for the server
	m.tcpConnections = prometheus.NewGaugeVec(prometheus.GaugeOpts{
		Name: "agent_tcp_connections",
		Help: "Current number of accepted TCP connections.",
	}, []string{"protocol"})
	m.tcpConnectionsLimit = prometheus.NewGaugeVec(prometheus.GaugeOpts{
		Name: "agent_tcp_connections_limit",
		Help: "The maximum number of TCP connections that can be accepted (0 = unlimited)",
	}, []string{"protocol"})
	m.requestDuration = prometheus.NewHistogramVec(prometheus.HistogramOpts{
		Name: "agent_request_duration_seconds",
		Help: "Time in seconds spent serving HTTP requests.",
	}, []string{"method", "route", "status_code", "ws"})
	m.receivedMessageSize = prometheus.NewHistogramVec(prometheus.HistogramOpts{
		Name:    "agent_request_message_bytes",
		Help:    "Size (in bytes) of messages received in the request.",
		Buckets: middleware.BodySizeBuckets,
	}, []string{"method", "route"})
	m.sentMessageSize = prometheus.NewHistogramVec(prometheus.HistogramOpts{
		Name:    "agent_response_message_bytes",
		Help:    "Size (in bytes) of messages sent in response.",
		Buckets: middleware.BodySizeBuckets,
	}, []string{"method", "route"})
	m.inflightRequests = prometheus.NewGaugeVec(prometheus.GaugeOpts{
		Name: "agent_inflight_requests",
		Help: "Current number of inflight requests.",
	}, []string{"method", "route"})

	if r != nil {
		// Register all of our metrics
		cc := []prometheus.Collector{
			m.tcpConnections, m.tcpConnectionsLimit, m.requestDuration, m.receivedMessageSize,
			m.sentMessageSize, m.inflightRequests,
		}
		for _, c := range cc {
			if err := r.Register(c); err != nil {
				return nil, fmt.Errorf("failed registering server metrics: %w", err)
			}
		}
	}
	return &m, nil
}

// New creates a new Server with the given config.
//
// r is used to register Server-specific metrics. If r is nil, no metrics will
// be registered.
//
// g is used for collecting metrics from the instrumentation handlers, when
// enabled. If g is nil, a /metrics endpoint will not be registered.
func New(l log.Logger, r prometheus.Registerer, g prometheus.Gatherer, cfg Config, flags Flags) (srv *Server, err error) {
	if l == nil {
		l = log.NewNopLogger()
	}
	wrappedLogger := GoKitLogger(l)

	switch {
	case flags.HTTP.InMemoryAddr == "":
		return nil, fmt.Errorf("in memory HTTP address must be configured")
	case flags.GRPC.InMemoryAddr == "":
		return nil, fmt.Errorf("in memory gRPC address must be configured")
	case flags.HTTP.InMemoryAddr == flags.GRPC.InMemoryAddr:
		return nil, fmt.Errorf("in memory HTTP and gRPC address must be different")
	}

	m, err := newMetrics(r)
	if err != nil {
		return nil, err
	}

	// Create listeners first so we can fail early if the port is in use.
	httpListener, err := newHTTPListener(&flags.HTTP, m)
	if err != nil {
		return nil, err
	}
	defer func() {
		if err != nil {
			_ = httpListener.Close()
		}
	}()
	grpcListener, err := newGRPCListener(&flags.GRPC, m)
	if err != nil {
		return nil, err
	}
	defer func() {
		if err != nil {
			_ = httpListener.Close()
		}
	}()

	// Configure TLS
	var (
		updateHTTPTLS func(TLSConfig) error
		updateGRPCTLS func(TLSConfig) error
	)
	if flags.HTTP.UseTLS {
		httpTLSListener, err := newTLSListener(httpListener, cfg.HTTP.TLSConfig, l)
		if err != nil {
			return nil, fmt.Errorf("generating HTTP TLS config: %w", err)
		}
		httpListener = httpTLSListener
		updateHTTPTLS = httpTLSListener.ApplyConfig
	}
	if flags.GRPC.UseTLS {
		grpcTLSListener, err := newTLSListener(grpcListener, cfg.GRPC.TLSConfig, l)
		if err != nil {
			return nil, fmt.Errorf("generating GRPC TLS config: %w", err)
		}
		grpcListener = grpcTLSListener
		updateGRPCTLS = grpcTLSListener.ApplyConfig
	}

	level.Info(l).Log(
		"msg", "server listening on addresses",
		"http", httpListener.Addr(), "grpc", grpcListener.Addr(),
		"http_tls_enabled", flags.HTTP.UseTLS, "grpc_tls_enabled", flags.GRPC.UseTLS,
	)

	// Build servers
	grpcServer := newGRPCServer(wrappedLogger, &flags.GRPC, m)
	httpServer, router, err := newHTTPServer(wrappedLogger, g, &flags, m)
	if err != nil {
		return nil, err
	}

	// Build in-memory listeners and dial function
	var (
		httpMemListener = memconn.NewListener(nil)
		grpcMemListener = memconn.NewListener(nil)
	)
	dialFunc := func(ctx context.Context, network string, address string) (net.Conn, error) {
		switch address {
		case flags.HTTP.InMemoryAddr:
			return httpMemListener.DialContext(ctx)
		case flags.GRPC.InMemoryAddr:
			return grpcMemListener.DialContext(ctx)
		default:
			return (&net.Dialer{}).DialContext(ctx, network, address)
		}
	}

	return &Server{
		flags:           flags,
		httpListener:    httpListener,
		grpcListener:    grpcListener,
		httpMemListener: httpMemListener,
		grpcMemListener: grpcMemListener,

		updateHTTPTLS: updateHTTPTLS,
		updateGRPCTLS: updateGRPCTLS,

		HTTP:        router,
		HTTPServer:  httpServer,
		GRPC:        grpcServer,
		DialContext: dialFunc,
	}, nil
}

func newHTTPListener(opts *HTTPFlags, m *metrics) (net.Listener, error) {
	httpAddress := opts.ListenAddress
	if httpAddress == "" {
		return nil, fmt.Errorf("http address not set")
	}
	httpListener, err := net.Listen(opts.ListenNetwork, httpAddress)
	if err != nil {
		return nil, fmt.Errorf("creating HTTP listener: %w", err)
	}
	httpListener = middleware.CountingListener(httpListener, m.tcpConnections.WithLabelValues("http"))

	m.tcpConnectionsLimit.WithLabelValues("http").Set(float64(opts.ConnLimit))
	if opts.ConnLimit > 0 {
		httpListener = netutil.LimitListener(httpListener, opts.ConnLimit)
	}
	return httpListener, nil
}

func newGRPCListener(opts *GRPCFlags, m *metrics) (net.Listener, error) {
	grpcAddress := opts.ListenAddress
	if grpcAddress == "" {
		return nil, fmt.Errorf("gRPC address not set")
	}
	grpcListener, err := net.Listen(opts.ListenNetwork, grpcAddress)
	if err != nil {
		return nil, fmt.Errorf("creating gRPC listener: %w", err)
	}
	grpcListener = middleware.CountingListener(grpcListener, m.tcpConnections.WithLabelValues("grpc"))

	m.tcpConnectionsLimit.WithLabelValues("grpc").Set(float64(opts.ConnLimit))
	if opts.ConnLimit > 0 {
		grpcListener = netutil.LimitListener(grpcListener, opts.ConnLimit)
	}
	return grpcListener, nil
}

func newGRPCServer(l logging.Interface, opts *GRPCFlags, m *metrics) *grpc.Server {
	serverLog := middleware.GRPCServerLog{
		WithRequest: true,
		Log:         l,
	}
	grpcOptions := []grpc.ServerOption{
		grpc.UnaryInterceptor(grpc_middleware.ChainUnaryServer(
			serverLog.UnaryServerInterceptor,
			otgrpc.OpenTracingServerInterceptor(opentracing.GlobalTracer()),
			middleware.UnaryServerInstrumentInterceptor(m.requestDuration),
		)),
		grpc.StreamInterceptor(grpc_middleware.ChainStreamServer(
			serverLog.StreamServerInterceptor,
			otgrpc.OpenTracingStreamServerInterceptor(opentracing.GlobalTracer()),
			middleware.StreamServerInstrumentInterceptor(m.requestDuration),
		)),
		grpc.KeepaliveParams(keepalive.ServerParameters{
			MaxConnectionIdle:     opts.MaxConnectionIdle,
			MaxConnectionAge:      opts.MaxConnectionAge,
			MaxConnectionAgeGrace: opts.MaxConnectionAgeGrace,
			Time:                  opts.KeepaliveTime,
			Timeout:               opts.KeepaliveTimeout,
		}),
		grpc.KeepaliveEnforcementPolicy(keepalive.EnforcementPolicy{
			MinTime:             opts.MinTimeBetweenPings,
			PermitWithoutStream: opts.PingWithoutStreamAllowed,
		}),
		grpc.MaxRecvMsgSize(opts.MaxRecvMsgSize),
		grpc.MaxSendMsgSize(opts.MaxSendMsgSize),
		grpc.MaxConcurrentStreams(uint32(opts.MaxConcurrentStreams)),
		grpc.StatsHandler(middleware.NewStatsHandler(m.receivedMessageSize, m.sentMessageSize, m.inflightRequests)),
	}

	return grpc.NewServer(grpcOptions...)
}

func newHTTPServer(l logging.Interface, g prometheus.Gatherer, opts *Flags, m *metrics) (*http.Server, *mux.Router, error) {
	router := mux.NewRouter()
	if opts.RegisterInstrumentation && g != nil {
		router.Handle("/metrics", promhttp.HandlerFor(g, promhttp.HandlerOpts{
			EnableOpenMetrics: true,
		}))
		router.PathPrefix("/debug/pprof").Handler(http.DefaultServeMux)
	}

	var sourceIPs *middleware.SourceIPExtractor
	if opts.LogSourceIPs {
		var err error
		sourceIPs, err = middleware.NewSourceIPs(opts.LogSourceIPsHeader, opts.LogSourceIPsRegex)
		if err != nil {
			return nil, nil, fmt.Errorf("error setting up source IP extraction: %v", err)
		}
	}

	httpMiddleware := []middleware.Interface{
		middleware.Tracer{
			RouteMatcher: router,
			SourceIPs:    sourceIPs,
		},
		middleware.Log{
			Log:       l,
			SourceIPs: sourceIPs,
		},
		middleware.Instrument{
			RouteMatcher:     router,
			Duration:         m.requestDuration,
			RequestBodySize:  m.receivedMessageSize,
			ResponseBodySize: m.sentMessageSize,
			InflightRequests: m.inflightRequests,
		},
	}

	httpServer := &http.Server{
		ReadTimeout:  opts.HTTP.ReadTimeout,
		WriteTimeout: opts.HTTP.WriteTimeout,
		IdleTimeout:  opts.HTTP.IdleTimeout,
		Handler:      middleware.Merge(httpMiddleware...).Wrap(router),
	}

	return httpServer, router, nil
}

// HTTPAddress returns the HTTP net.Addr of this Server.
func (s *Server) HTTPAddress() net.Addr { return s.httpListener.Addr() }

// GRPCAddress returns the GRPC net.Addr of this Server.
func (s *Server) GRPCAddress() net.Addr { return s.grpcListener.Addr() }

// ApplyConfig applies changes to the Server block.
func (s *Server) ApplyConfig(cfg Config) error {
	s.flagsMut.Lock()
	defer s.flagsMut.Unlock()

	// N.B. LogLevel/LogFormat support dynamic updating but are never used in
	// *Server, so they're ignored here.

	if s.updateHTTPTLS != nil {
		if err := s.updateHTTPTLS(cfg.HTTP.TLSConfig); err != nil {
			return fmt.Errorf("updating HTTP TLS settings: %w", err)
		}
	}
	if s.updateGRPCTLS != nil {
		if err := s.updateGRPCTLS(cfg.GRPC.TLSConfig); err != nil {
			return fmt.Errorf("updating gRPC TLS settings: %w", err)
		}
	}

	return nil
}

// Run the server until en error is received or the given context is canceled.
// Run may not be re-called after it exits.
func (s *Server) Run(ctx context.Context) error {
	ctx, cancel := context.WithCancel(ctx)
	defer cancel()

	var g run.Group

	g.Add(func() error {
		<-ctx.Done()
		return nil
	}, func(_ error) {
		cancel()
	})

	httpListeners := []net.Listener{
		s.httpListener,
		s.httpMemListener,
	}
	for i := range httpListeners {
		listener := httpListeners[i]
		g.Add(func() error {
			err := s.HTTPServer.Serve(listener)
			if errors.Is(err, http.ErrServerClosed) {
				err = nil
			}
			return err
		}, func(_ error) {
			ctx, cancel := context.WithTimeout(context.Background(), s.flags.GracefulShutdownTimeout)
			defer cancel()
			_ = s.HTTPServer.Shutdown(ctx)
		})
	}

	grpcListeners := []net.Listener{
		s.grpcListener,
		s.grpcMemListener,
	}
	for i := range grpcListeners {
		listener := grpcListeners[i]
		g.Add(func() error {
			err := s.GRPC.Serve(listener)
			if errors.Is(err, grpc.ErrServerStopped) {
				err = nil
			}
			return err
		}, func(_ error) {
			s.GRPC.GracefulStop()
		})
	}

	return g.Run()
}

// Close forcibly closes the server's listeners.
func (s *Server) Close() error {
	errs := multierror.Append(
		s.httpListener.Close(),
		s.grpcListener.Close(),
	)
	return errs.ErrorOrNil()
}

'''
'''--- pkg/server/server_test.go ---
package server

import (
	"context"
	"crypto/tls"
	"fmt"
	"net"
	"net/http"
	"testing"

	"github.com/go-kit/log"
	"github.com/stretchr/testify/require"
	"google.golang.org/grpc"
	"google.golang.org/grpc/credentials"
	"google.golang.org/grpc/credentials/insecure"
	"google.golang.org/grpc/health"
	"google.golang.org/grpc/health/grpc_health_v1"
)

const anyLocalhost = "127.0.0.1:0"

func TestServer(t *testing.T) {
	cfg := newTestConfig()
	flags := newTestFlags()
	srv := runExampleServer(t, cfg, flags)

	// Validate HTTP
	resp, err := http.Get(fmt.Sprintf("http://%s/testing", srv.HTTPAddress()))
	require.NoError(t, err)
	require.Equal(t, http.StatusOK, resp.StatusCode)
	_ = resp.Body.Close()

	// Validate gRPC
	creds := grpc.WithTransportCredentials(insecure.NewCredentials())
	cc, err := grpc.Dial(srv.GRPCAddress().String(), creds)
	require.NoError(t, err)
	_, err = grpc_health_v1.NewHealthClient(cc).Check(context.Background(), &grpc_health_v1.HealthCheckRequest{})
	require.NoError(t, err)
}

func TestServer_InMemory(t *testing.T) {
	cfg := newTestConfig()
	flags := newTestFlags()
	srv := runExampleServer(t, cfg, flags)

	// Validate HTTP
	var httpClient http.Client
	httpClient.Transport = &http.Transport{DialContext: srv.DialContext}
	resp, err := httpClient.Get(fmt.Sprintf("http://%s/testing", flags.HTTP.InMemoryAddr))
	require.NoError(t, err)
	require.Equal(t, http.StatusOK, resp.StatusCode)
	_ = resp.Body.Close()

	// Validate gRPC
	grpcDialer := grpc.WithContextDialer(func(ctx context.Context, s string) (net.Conn, error) {
		return srv.DialContext(ctx, "", s)
	})
	cc, err := grpc.Dial(flags.GRPC.InMemoryAddr, grpc.WithTransportCredentials(insecure.NewCredentials()), grpcDialer)
	require.NoError(t, err)
	_, err = grpc_health_v1.NewHealthClient(cc).Check(context.Background(), &grpc_health_v1.HealthCheckRequest{})
	require.NoError(t, err)
}

func newTestConfig() Config {
	cfg := DefaultConfig
	return cfg
}

func newTestFlags() Flags {
	flags := DefaultFlags
	flags.HTTP.ListenAddress = anyLocalhost
	flags.GRPC.ListenAddress = anyLocalhost
	return flags
}

func runExampleServer(t *testing.T, cfg Config, flags Flags) *Server {
	t.Helper()

	srv, err := New(log.NewNopLogger(), nil, nil, cfg, flags)
	require.NoError(t, err)

	// Set up some expected services for us to test against.
	srv.HTTP.HandleFunc("/testing", func(w http.ResponseWriter, _ *http.Request) {
		w.WriteHeader(http.StatusOK)
	})
	grpc_health_v1.RegisterHealthServer(srv.GRPC, health.NewServer())

	// Run our server.
	ctx, cancel := context.WithCancel(context.Background())
	t.Cleanup(cancel)
	go func() {
		require.NoError(t, srv.Run(ctx))
	}()

	return srv
}

func TestServer_TLS(t *testing.T) {
	cfg := newTestConfig()
	flags := newTestFlags()

	flags.HTTP.UseTLS = true
	flags.GRPC.UseTLS = true

	tlsConfig := TLSConfig{
		TLSCertPath: "testdata/example-cert.pem",
		TLSKeyPath:  "testdata/example-key.pem",
	}
	cfg.HTTP.TLSConfig = tlsConfig
	cfg.GRPC.TLSConfig = tlsConfig

	srv := runExampleServer(t, cfg, flags)

	// Validate HTTPS
	cli := http.Client{
		Transport: &http.Transport{
			TLSClientConfig: &tls.Config{InsecureSkipVerify: true},
		},
	}
	resp, err := cli.Get(fmt.Sprintf("https://%s/testing", srv.HTTPAddress()))
	require.NoError(t, err)
	require.Equal(t, http.StatusOK, resp.StatusCode)
	_ = resp.Body.Close()

	// Validate gRPC TLS
	creds := credentials.NewTLS(&tls.Config{InsecureSkipVerify: true})
	cc, err := grpc.Dial(srv.GRPCAddress().String(), grpc.WithTransportCredentials(creds))
	require.NoError(t, err)
	_, err = grpc_health_v1.NewHealthClient(cc).Check(context.Background(), &grpc_health_v1.HealthCheckRequest{})
	require.NoError(t, err)
}

// TestRunReturnsError validates that Run exits with an error when the
// HTTP/GRPC servers stop unexpectedly.
func TestRunReturnsError(t *testing.T) {
	cfg := newTestConfig()
	flags := newTestFlags()

	t.Run("http", func(t *testing.T) {
		srv, err := New(nil, nil, nil, cfg, flags)
		require.NoError(t, err)

		ctx, cancel := context.WithCancel(context.Background())
		defer cancel()

		errChan := make(chan error, 1)
		go func() {
			errChan <- srv.Run(ctx)
		}()

		require.NoError(t, srv.httpListener.Close())
		require.NotNil(t, <-errChan)
	})

	t.Run("grpc", func(t *testing.T) {
		srv, err := New(nil, nil, nil, cfg, flags)
		require.NoError(t, err)

		ctx, cancel := context.WithCancel(context.Background())
		defer cancel()

		errChan := make(chan error, 1)
		go func() {
			errChan <- srv.Run(ctx)
		}()

		require.NoError(t, srv.grpcListener.Close())
		require.NotNil(t, <-errChan)
	})
}

func TestServer_ApplyConfig(t *testing.T) {
	t.Run("no changes", func(t *testing.T) {
		cfg := newTestConfig()
		flags := newTestFlags()

		srv, err := New(nil, nil, nil, cfg, flags)
		require.NoError(t, err)

		require.NoError(t, srv.ApplyConfig(cfg))
	})

	t.Run("valid changes", func(t *testing.T) {
		cfg := newTestConfig()
		flags := newTestFlags()

		srv, err := New(nil, nil, nil, cfg, flags)
		require.NoError(t, err)

		cfg.LogLevel.Set("debug")
		require.NoError(t, srv.ApplyConfig(cfg))
	})
}

'''
'''--- pkg/server/signal_context.go ---
package server

import (
	"context"

	"github.com/go-kit/log"
	"github.com/weaveworks/common/signals"
	"go.uber.org/atomic"
)

var signalContexts atomic.Int64

// SignalContext wraps a ctx which will be canceled if an interrupt is
// received.
//
// It is invalid to have two simultaneous SignalContexts per binary.
func SignalContext(ctx context.Context, l log.Logger) (context.Context, context.CancelFunc) {
	if !signalContexts.CAS(0, 1) {
		panic("bug: multiple SignalContexts found")
	}

	if l == nil {
		l = log.NewNopLogger()
	}

	ctx, cancel := context.WithCancel(ctx)

	handler := signals.NewHandler(GoKitLogger(l))
	go func() {
		handler.Loop()
		signalContexts.Store(0)
		cancel()
	}()
	go func() {
		<-ctx.Done()
		handler.Stop()
		signalContexts.Store(0)
	}()

	return ctx, cancel
}

'''
'''--- pkg/server/testdata/windows/README.md ---
The files here are for usage with windows TLS. They need to be installed to the Users certificate store in the `My` location if using the included agent configuration. 

Running ` .\curl.exe -v -GET --key .\client_key_unencrypted.key --cert .\client_cert.crt --insecure https://localhost:12345/metrics` will let you see the correct metrics. NOTE: You will need to likely download [curl](https://curl.se/windows/dl-7.82.0_2/curl-7.82.0_2-win64-mingw.zip) compiled explicitly with windows crypto support. 
'''
'''--- pkg/server/testdata/windows/agent-config.yml ---
server:
  log_level: debug
  http_tls_config:
    client_auth_type: RequireAndVerifyClientCert
    windows_certificate_filter:
      client_store: My
      client_system_store: CurrentUser
      client_issuer_common_names: [test-WINDOWS-VM-AGEN-CA]
      server_store: My
      server_system_store: CurrentUser
      server_template_id: "1.3.6.1.4.1.311.21.8.2114893.1300005.13648014.4673963.7606721.204.5968300.2521631"
metrics:
  wal_directory: c:\programdata\agent
  global:
    scrape_interval: 60s
    remote_write:
      - url: https://prometheus-us-central1.grafana.net/api/prom/push
        basic_auth:
          username: <user>>
          password: <password>
integrations:
  windows_exporter:
    enabled: true
  agent:
    enabled: true

'''
'''--- pkg/server/tls.go ---
package server

import (
	"context"
	"crypto/tls"
	"crypto/x509"
	"errors"
	"fmt"
	"io/ioutil"
	"net"
	"sync"
	"time"

	"github.com/go-kit/log"
)

// TLSConfig holds dynamic configuration options for TLS.
type TLSConfig struct {
	TLSCertPath              string                    `yaml:"cert_file,omitempty"`
	TLSKeyPath               string                    `yaml:"key_file,omitempty"`
	ClientAuth               string                    `yaml:"client_auth_type,omitempty"`
	ClientCAs                string                    `yaml:"client_ca_file,omitempty"`
	CipherSuites             []TLSCipher               `yaml:"cipher_suites,omitempty"`
	CurvePreferences         []TLSCurve                `yaml:"curve_preferences,omitempty"`
	MinVersion               TLSVersion                `yaml:"min_version,omitempty"`
	MaxVersion               TLSVersion                `yaml:"max_version,omitempty"`
	PreferServerCipherSuites bool                      `yaml:"prefer_server_cipher_suites,omitempty"`
	WindowsCertificateFilter *WindowsCertificateFilter `yaml:"windows_certificate_filter,omitempty"`
}

// WindowsCertificateFilter represents the configuration for accessing the Windows store
type WindowsCertificateFilter struct {
	Server *WindowsServerFilter `yaml:"server,omitempty"`
	Client *WindowsClientFilter `yaml:"client,omitempty"`
}

// WindowsClientFilter is used to select a client root CA certificate
type WindowsClientFilter struct {
	IssuerCommonNames []string `yaml:"issuer_common_names,omitempty"`
	SubjectRegEx      string   `yaml:"subject_regex,omitempty"`
	TemplateID        string   `yaml:"template_id,omitempty"`
}

// WindowsServerFilter is used to select a server certificate
type WindowsServerFilter struct {
	Store             string   `yaml:"store,omitempty"`
	SystemStore       string   `yaml:"system_store,omitempty"`
	IssuerCommonNames []string `yaml:"issuer_common_names,omitempty"`
	TemplateID        string   `yaml:"template_id,omitempty"`

	RefreshInterval time.Duration `yaml:"refresh_interval,omitempty"`
}

// TLSCipher holds the ID of a tls.CipherSuite.
type TLSCipher uint16

// UnmarshalYAML unmarshals the name of a cipher suite to its ID.
func (c *TLSCipher) UnmarshalYAML(unmarshal func(interface{}) error) error {
	var s string
	err := unmarshal(&s)
	if err != nil {
		return err
	}
	for _, cs := range tls.CipherSuites() {
		if cs.Name == s {
			*c = (TLSCipher)(cs.ID)
			return nil
		}
	}
	return errors.New("unknown cipher: " + s)
}

// MarshalYAML marshals the name of the cipher suite.
func (c TLSCipher) MarshalYAML() (interface{}, error) {
	return tls.CipherSuiteName((uint16)(c)), nil
}

// TLSCurve holds the ID of a TLS elliptic curve.
type TLSCurve tls.CurveID

var curves = map[string]TLSCurve{
	"CurveP256": (TLSCurve)(tls.CurveP256),
	"CurveP384": (TLSCurve)(tls.CurveP384),
	"CurveP521": (TLSCurve)(tls.CurveP521),
	"X25519":    (TLSCurve)(tls.X25519),
}

// UnmarshalYAML unmarshals the name of a TLS elliptic curve into its ID.
func (c *TLSCurve) UnmarshalYAML(unmarshal func(interface{}) error) error {
	var s string
	err := unmarshal(&s)
	if err != nil {
		return err
	}
	if curveid, ok := curves[s]; ok {
		*c = curveid
		return nil
	}
	return errors.New("unknown curve: " + s)
}

// MarshalYAML marshals the ID of a TLS elliptic curve into its name.
func (c *TLSCurve) MarshalYAML() (interface{}, error) {
	for s, curveid := range curves {
		if *c == curveid {
			return s, nil
		}
	}
	return fmt.Sprintf("%v", c), nil
}

// TLSVersion holds a TLS version ID.
type TLSVersion uint16

var tlsVersions = map[string]TLSVersion{
	"TLS13": (TLSVersion)(tls.VersionTLS13),
	"TLS12": (TLSVersion)(tls.VersionTLS12),
	"TLS11": (TLSVersion)(tls.VersionTLS11),
	"TLS10": (TLSVersion)(tls.VersionTLS10),
}

// UnmarshalYAML unmarshals the name of a TLS version into its ID.
func (tv *TLSVersion) UnmarshalYAML(unmarshal func(interface{}) error) error {
	var s string
	err := unmarshal(&s)
	if err != nil {
		return err
	}
	if v, ok := tlsVersions[s]; ok {
		*tv = v
		return nil
	}
	return errors.New("unknown TLS version: " + s)
}

// MarshalYAML marshals the ID of a TLS version into its name.
func (tv *TLSVersion) MarshalYAML() (interface{}, error) {
	for s, v := range tlsVersions {
		if *tv == v {
			return s, nil
		}
	}
	return fmt.Sprintf("%v", tv), nil
}

// tlsListener is a net.Listener for establishing TLS connections. tlsListener
// supports dynamically updating the TLS settings used to establish
// connections.
type tlsListener struct {
	mut       sync.RWMutex
	cfg       TLSConfig
	tlsConfig *tls.Config
	log       log.Logger

	innerListener net.Listener

	windowsCertHandler *winCertStoreHandler
	cancelWindowsCert  context.CancelFunc //nolint
}

// newTLSListener creates and configures a new tlsListener.
func newTLSListener(inner net.Listener, c TLSConfig, log log.Logger) (*tlsListener, error) {
	tl := &tlsListener{
		innerListener: inner,
		log:           log,
	}
	return tl, tl.ApplyConfig(c)
}

// Accept implements net.Listener and returns the next connection. Connections
func (l *tlsListener) Accept() (net.Conn, error) {
	nc, err := l.innerListener.Accept()
	if err != nil {
		return nc, err
	}

	l.mut.RLock()
	defer l.mut.RUnlock()
	return tls.Server(nc, l.tlsConfig), nil
}

// Close implements net.Listener and closes the tlsListener, preventing any new
// connections from being formed. Existing connections will be kept alive.
func (l *tlsListener) Close() error {
	if l.cancelWindowsCert != nil {
		l.cancelWindowsCert()
	}
	return l.innerListener.Close()
}

// Addr implements net.Listener and returns the listener's network address.
func (l *tlsListener) Addr() net.Addr {
	return l.innerListener.Addr()
}

// ApplyConfig updates the tlsListener with new settings for creating TLS
// connections.
//
// Existing TLS connections will be kept alive after updating the TLS settings.
// New connections cannot be established while ApplyConfig is running.
func (l *tlsListener) ApplyConfig(c TLSConfig) error {
	l.mut.Lock()
	defer l.mut.Unlock()
	if c.WindowsCertificateFilter != nil {
		return l.applyWindowsCertificateStore(c)
	}
	return l.applyNormalTLS(c)
}

func (l *tlsListener) applyNormalTLS(c TLSConfig) error {
	if l.windowsCertHandler != nil {
		panic("windows certificate handler is set this should never happen")
	}
	// Convert our TLSConfig into a new *tls.Config.
	//
	// While *tls.Config supports callbacks and doesn't need to be fully
	// replaced, some of our dynamic settings from TLSConfig can't be dynamically
	// updated (e.g., ciphers, min/max version, etc.).
	//
	// To make life easier on ourselves we just replace the whole thing with a new TLS listener.

	// Make sure that the certificates exist
	if c.TLSCertPath == "" {
		return fmt.Errorf("missing certificate file")
	}
	if c.TLSKeyPath == "" {
		return fmt.Errorf("missing key file")
	}
	_, err := tls.LoadX509KeyPair(c.TLSCertPath, c.TLSKeyPath)
	if err != nil {
		return fmt.Errorf("failed to load key pair: %w", err)
	}

	newConfig := &tls.Config{
		MinVersion:               (uint16)(c.MinVersion),
		MaxVersion:               (uint16)(c.MaxVersion),
		PreferServerCipherSuites: c.PreferServerCipherSuites,

		GetCertificate: l.getCertificate,
	}

	var cf []uint16
	for _, c := range c.CipherSuites {
		cf = append(cf, (uint16)(c))
	}
	if len(cf) > 0 {
		newConfig.CipherSuites = cf
	}

	var cp []tls.CurveID
	for _, c := range c.CurvePreferences {
		cp = append(cp, (tls.CurveID)(c))
	}
	if len(cp) > 0 {
		newConfig.CurvePreferences = cp
	}

	if c.ClientCAs != "" {
		clientCAPool := x509.NewCertPool()
		clientCAFile, err := ioutil.ReadFile(c.ClientCAs)
		if err != nil {
			return err
		}
		clientCAPool.AppendCertsFromPEM(clientCAFile)
		newConfig.ClientCAs = clientCAPool
	}

	clientAuth, err := getClientAuthFromString(c.ClientAuth)
	if err != nil {
		return err
	}
	newConfig.ClientAuth = clientAuth
	if c.ClientCAs != "" && newConfig.ClientAuth == tls.NoClientCert {
		return fmt.Errorf("Client CAs have been configured without a ClientAuth policy")
	}

	l.tlsConfig = newConfig
	l.cfg = c
	return nil
}

func (l *tlsListener) getCertificate(*tls.ClientHelloInfo) (*tls.Certificate, error) {
	l.mut.RLock()
	defer l.mut.RUnlock()

	cert, err := tls.LoadX509KeyPair(l.cfg.TLSCertPath, l.cfg.TLSKeyPath)
	if err != nil {
		return nil, fmt.Errorf("failed to load key pair: %w", err)
	}
	return &cert, nil
}

func getClientAuthFromString(clientAuth string) (tls.ClientAuthType, error) {
	switch clientAuth {
	case "RequestClientCert":
		return tls.RequestClientCert, nil
	case "RequireAnyClientCert", "RequireClientCert": // Preserved for backwards compatibility.
		return tls.RequireAnyClientCert, nil
	case "VerifyClientCertIfGiven":
		return tls.VerifyClientCertIfGiven, nil
	case "RequireAndVerifyClientCert":
		return tls.RequireAndVerifyClientCert, nil
	case "", "NoClientCert":
		return tls.NoClientCert, nil
	default:
		return tls.NoClientCert, fmt.Errorf("invalid ClientAuth %q", clientAuth)
	}
}

'''
'''--- pkg/server/tls_certstore_stub.go ---
//go:build !windows
// +build !windows

package server

import "fmt"

func (l *tlsListener) applyWindowsCertificateStore(_ TLSConfig) error {
	return fmt.Errorf("cannot use Windows certificate store on non-Windows platforms")
}

type winCertStoreHandler struct {
}

'''
'''--- pkg/server/tls_certstore_windows.go ---
package server

import (
	"context"
	"crypto"
	"crypto/tls"
	"crypto/x509"
	"encoding/asn1"
	"fmt"
	"github.com/github/smimesign/certstore"
	"github.com/go-kit/log"
	"github.com/go-kit/log/level"
	"regexp"
	"sort"
	"sync"
	"time"
)

// winCertStoreHandler handles the finding of certificates, validating them and injecting into the default TLS pipeline
type winCertStoreHandler struct {
	cfg          WindowsCertificateFilter
	subjectRegEx *regexp.Regexp
	log          log.Logger

	winMut       sync.Mutex
	serverCert   *x509.Certificate
	serverSigner crypto.PrivateKey
	// We have to store the identity to access the signer (it's a win32 api call), if we close the identity
	// we lose access to the signer
	// the client does NOT need the signer
	serverIdentity certstore.Identity
	clientAuth     tls.ClientAuthType

	cancelContext context.Context
}

func (l *tlsListener) applyWindowsCertificateStore(c TLSConfig) error {

	// Restrict normal TLS options when using windows certificate store
	if c.TLSCertPath != "" {
		return fmt.Errorf("at most one of cert_file and windows_certificate_filter can be configured")
	}
	if c.TLSKeyPath != "" {
		return fmt.Errorf("at most one of cert_key and windows_certificate_filter can be configured")
	}
	if c.WindowsCertificateFilter.Server == nil {
		return fmt.Errorf("windows certificate filter requires a server block defined")
	}

	var subjectRegEx *regexp.Regexp
	var err error
	if c.WindowsCertificateFilter.Client != nil && c.WindowsCertificateFilter.Client.SubjectRegEx != "" {
		subjectRegEx, err = regexp.Compile(c.WindowsCertificateFilter.Client.SubjectRegEx)
		if err != nil {
			return fmt.Errorf("error compiling subject common name regular expression: %w", err)
		}
	}

	// If there is an existing windows certhandler notify it to stop refreshing
	if l.cancelWindowsCert != nil {
		l.cancelWindowsCert()
		l.cancelWindowsCert = nil
	}
	cancelCtx := context.Background()
	cancelCtx, cancelHandler := context.WithCancel(cancelCtx)
	l.cancelWindowsCert = cancelHandler
	cn := &winCertStoreHandler{
		cfg:           *c.WindowsCertificateFilter,
		subjectRegEx:  subjectRegEx,
		cancelContext: cancelCtx,
		log:           l.log,
	}
	err = cn.refreshCerts()
	if err != nil {
		return err
	}

	config := &tls.Config{
		VerifyPeerCertificate: cn.VerifyPeer,
		GetCertificate: func(info *tls.ClientHelloInfo) (*tls.Certificate, error) {
			cn.winMut.Lock()
			defer cn.winMut.Unlock()
			cert := &tls.Certificate{
				Certificate: [][]byte{cn.serverCert.Raw},
				PrivateKey:  cn.serverSigner,
				Leaf:        cn.serverCert,
				// These seem to the be safest to use, tested on Win10, Server 2016, 2019, 2022
				SupportedSignatureAlgorithms: []tls.SignatureScheme{
					tls.PKCS1WithSHA512,
					tls.PKCS1WithSHA384,
					tls.PKCS1WithSHA256,
				},
			}
			return cert, nil
		},
		// Windows has broad support for 1.2, only 2022 has support for 1.3
		MaxVersion: tls.VersionTLS12,
	}

	ca, err := getClientAuthFromString(c.ClientAuth)
	if err != nil {
		return err
	}
	config.ClientAuth = ca
	cn.clientAuth = ca
	// Kick off the refresh handler
	go cn.startUpdateTimer()
	l.windowsCertHandler = cn
	l.tlsConfig = config
	l.cfg = c
	return nil
}

// VerifyPeer is called by the TLS pipeline, and specified in tls.config, this is where any custom verification happens
func (c *winCertStoreHandler) VerifyPeer(_ [][]byte, verifiedChains [][]*x509.Certificate) error {
	opts := x509.VerifyOptions{}
	clientCert := verifiedChains[0][0]

	// Check for issuer
	issuerMatches := len(c.cfg.Client.IssuerCommonNames) == 0
	for _, cn := range c.cfg.Client.IssuerCommonNames {
		if cn == clientCert.Issuer.CommonName {
			issuerMatches = true
			break
		}
	}
	if !issuerMatches {
		return fmt.Errorf("unable to match client issuer")
	}

	// Check for subject
	subjectMatches := true
	if c.subjectRegEx != nil {
		if !c.subjectRegEx.MatchString(clientCert.Subject.CommonName) {
			subjectMatches = false
		}
	}
	if !subjectMatches {
		return fmt.Errorf("unable to match client subject")
	}

	// Check for template id
	if c.cfg.Client.TemplateID != "" {
		templateid := getTemplateID(clientCert)
		if templateid != c.cfg.Client.TemplateID {
			return fmt.Errorf("unable to match client template id")
		}
	}

	// call the normal pipeline
	_, err := clientCert.Verify(opts)
	return err

}

// this is the ASN1 Object Identifier for TemplateID
var asnTemplateOID = "1.3.6.1.4.1.311.21.7"

type templateInformation struct {
	Template     asn1.ObjectIdentifier
	MajorVersion int
	MinorVersion int
}

func (c *winCertStoreHandler) startUpdateTimer() {
	refreshInterval := 5 * time.Minute
	c.winMut.Lock()
	if c.cfg.Server.RefreshInterval != 0 {
		refreshInterval = c.cfg.Server.RefreshInterval
	}
	c.winMut.Unlock()
	for {
		select {
		case <-c.cancelContext.Done():
			if c.serverIdentity != nil {
				c.serverIdentity.Close()
			}
			c.serverCert = nil
			c.serverSigner = nil
			return
		case <-time.After(refreshInterval):
			err := c.refreshCerts()
			if err != nil {
				level.Error(c.log).Log("msg", "error refreshing Windows certificates", "err", err)
			}

		}
	}
}

// refreshCerts is the main work item in certificate store, responsible for finding the right certificate
func (c *winCertStoreHandler) refreshCerts() (err error) {
	c.winMut.Lock()
	defer c.winMut.Unlock()
	level.Debug(c.log).Log("msg", "refreshing Windows certificates")
	// Close the server identity if already set
	if c.serverIdentity != nil {
		c.serverIdentity.Close()
	}
	var serverIdentity certstore.Identity
	// This handles closing all our various handles
	defer func() {
		// we have to keep the server identity open if we want to use it, BUT only if an error occurred, else we need it
		// open to sign
		if serverIdentity != nil && err != nil {
			serverIdentity.Close()
		}
	}()
	serverIdentity, err = c.findServerIdentity()
	if err != nil {
		return fmt.Errorf("failed finding server identity %w", err)
	}
	sc, err := serverIdentity.Certificate()
	if err != nil {
		return fmt.Errorf("failed getting server certificate %w", err)
	}
	signer, err := serverIdentity.Signer()
	if err != nil {
		return fmt.Errorf("failed getting server signer %w", err)

	}

	c.serverCert = sc
	c.serverSigner = signer
	c.serverIdentity = serverIdentity
	return
}

func (c *winCertStoreHandler) findServerIdentity() (certstore.Identity, error) {
	return c.findCertificate(c.cfg.Server.SystemStore, c.cfg.Server.Store, c.cfg.Server.IssuerCommonNames, c.cfg.Server.TemplateID, nil, c.getStore)
}

// getStore converts the string representation to the enum representation
func (c *winCertStoreHandler) getStore(systemStore string, storeName string) (certstore.Store, error) {
	st, err := certstore.StringToStoreType(systemStore)
	if err != nil {
		return nil, err
	}
	store, err := certstore.OpenSpecificStore(st, storeName)
	if err != nil {
		return nil, err
	}
	return store, nil
}

type getStoreFunc func(systemStore, storeName string) (certstore.Store, error)

// findCertificate applies the filters to get the server certificate
func (c *winCertStoreHandler) findCertificate(systemStore string, storeName string, commonNames []string, templateID string, subjectRegEx *regexp.Regexp, getStore getStoreFunc) (certstore.Identity, error) {
	var store certstore.Store
	var validIdentity certstore.Identity
	var identities []certstore.Identity
	// Lots of cleanup here for pointers to windows handles.
	defer func() {
		if store != nil {
			store.Close()
		}
		// Now lets clean up any identities that are NOT the one we want
		for _, i := range identities {
			if i != validIdentity {
				i.Close()
			}
		}
	}()
	store, err := getStore(systemStore, storeName)
	if err != nil {
		return nil, err
	}
	identities, err = store.Identities()

	filtered, err := c.filterByIssuerCommonNames(identities, commonNames)
	if err != nil {
		return nil, err
	}
	filtered, err = c.filterByTemplateID(filtered, templateID)
	if err != nil {
		return nil, err
	}
	filtered, err = c.filterBySubjectRegularExpression(filtered, subjectRegEx)
	if err != nil {
		return nil, err
	}
	if len(filtered) == 0 {
		return nil, fmt.Errorf("no certificates found")
	}
	// order oldest to newest
	sort.Slice(filtered, func(certI, certJ int) bool {
		// Already accessed this so the error will not happen
		a, _ := filtered[certI].Certificate()
		b, _ := filtered[certJ].Certificate()

		return a.NotBefore.Before(b.NotBefore)
	})

	// Grab the most recent valid one
	for i := len(filtered) - 1; i >= 0; i-- {
		fc, _ := filtered[i].Certificate()
		if time.Now().Before(fc.NotAfter) && time.Now().After(fc.NotBefore) {
			validIdentity = filtered[i]
			break
		}
	}
	if validIdentity == nil {
		return nil, fmt.Errorf("no certificates found")
	}

	return validIdentity, nil
}

func (c *winCertStoreHandler) filterByIssuerCommonNames(input []certstore.Identity, commonNames []string) ([]certstore.Identity, error) {
	if len(commonNames) == 0 {
		return input, nil
	}
	returnIdentities := make([]certstore.Identity, 0)
	for _, identity := range input {
		cert, err := identity.Certificate()
		if err != nil {
			return nil, err
		}
		for _, cfgName := range commonNames {
			if cert.Issuer.CommonName == cfgName {
				returnIdentities = append(returnIdentities, identity)
				break
			}
		}
	}
	return returnIdentities, nil
}

func (c *winCertStoreHandler) filterByTemplateID(input []certstore.Identity, id string) ([]certstore.Identity, error) {
	if id == "" {
		return input, nil
	}
	returnIdentities := make([]certstore.Identity, 0)

	for _, identity := range input {
		cert, err := identity.Certificate()
		if err != nil {
			return nil, err
		}
		templateid := getTemplateID(cert)
		if templateid == id {
			returnIdentities = append(returnIdentities, identity)
		}
	}
	return returnIdentities, nil
}

func getTemplateID(cert *x509.Certificate) string {
	for _, ext := range cert.Extensions {
		if ext.Id.String() == asnTemplateOID {
			templateInfo := &templateInformation{}
			_, err := asn1.Unmarshal(ext.Value, templateInfo)
			if err != nil {
				return ""
			}
			return templateInfo.Template.String()
		}
	}
	return ""
}

func (c *winCertStoreHandler) filterBySubjectRegularExpression(input []certstore.Identity, regEx *regexp.Regexp) ([]certstore.Identity, error) {
	if regEx == nil {
		return input, nil
	}
	returnIdentities := make([]certstore.Identity, 0)

	for _, identity := range input {
		cert, err := identity.Certificate()
		if err != nil {
			return nil, err
		}
		if regEx.MatchString(cert.Subject.CommonName) {
			returnIdentities = append(returnIdentities, identity)
		}
	}
	return returnIdentities, nil
}

'''
'''--- pkg/server/tls_certstore_windows_test.go ---
package server

import (
	"crypto"
	"crypto/x509"
	"crypto/x509/pkix"
	"encoding/asn1"
	"math/big"
	"testing"
	"time"

	"github.com/github/smimesign/certstore"
	"github.com/stretchr/testify/require"
)

func TestEasyFilter(t *testing.T) {
	c := &winCertStoreHandler{
		cfg: WindowsCertificateFilter{
			Server: &WindowsServerFilter{
				Store:       "My",
				SystemStore: "LocalMachine",
			},
		},
	}
	serverSt := newFakeStore()
	sc := makeCert(time.Now().Add(time.Duration(-1)*time.Minute), time.Now().Add(5*time.Minute), []int{1, 2, 3}, "", "")
	serverSt.identities = append(serverSt.identities, newFakeIdentity(sc))
	findCert := func(systemStore, _ string) (certstore.Store, error) {
		return serverSt, nil
	}
	serverIdentity, err := c.findCertificate(c.cfg.Server.SystemStore, c.cfg.Server.Store, c.cfg.Server.IssuerCommonNames, c.cfg.Server.TemplateID, nil, findCert)
	require.NoError(t, err)
	require.NotNil(t, serverIdentity)
	foundCert, err := serverIdentity.Certificate()
	require.NoError(t, err)
	require.True(t, foundCert == sc)
}

func TestTemplateIDFilter(t *testing.T) {
	c := &winCertStoreHandler{
		cfg: WindowsCertificateFilter{
			Server: &WindowsServerFilter{
				Store:       "My",
				SystemStore: "LocalMachine",
				TemplateID:  "1.2.3",
			},
		},
	}
	serverSt := newFakeStore()
	sc := makeCert(time.Now().Add(time.Duration(-1)*time.Minute), time.Now().Add(5*time.Minute), []int{1, 2, 3}, "", "")
	serverSt.identities = append(serverSt.identities, newFakeIdentity(sc))
	findCert := func(systemStore, _ string) (certstore.Store, error) {
		return serverSt, nil
	}
	serverIdentity, err := c.findCertificate(c.cfg.Server.SystemStore, c.cfg.Server.Store, c.cfg.Server.IssuerCommonNames, c.cfg.Server.TemplateID, nil, findCert)
	require.NoError(t, err)
	require.NotNil(t, serverIdentity)
	foundCert, err := serverIdentity.Certificate()
	require.NoError(t, err)
	require.Equal(t, foundCert, sc)
}

func TestCommonName(t *testing.T) {
	c := &winCertStoreHandler{
		cfg: WindowsCertificateFilter{
			Server: &WindowsServerFilter{
				Store:             "My",
				SystemStore:       "LocalMachine",
				TemplateID:        "1.2.3",
				IssuerCommonNames: []string{"TEST"},
			},
		},
	}
	serverSt := newFakeStore()
	sc := makeCert(time.Now().Add(time.Duration(-1)*time.Minute), time.Now().Add(5*time.Minute), []int{1, 2, 3}, "TEST", "")
	serverSt.identities = append(serverSt.identities, newFakeIdentity(sc))
	findCert := func(systemStore, _ string) (certstore.Store, error) {
		return serverSt, nil
	}
	serverIdentity, err := c.findCertificate(c.cfg.Server.SystemStore, c.cfg.Server.Store, c.cfg.Server.IssuerCommonNames, c.cfg.Server.TemplateID, nil, findCert)
	require.NoError(t, err)
	require.NotNil(t, serverIdentity)
	foundCert, err := serverIdentity.Certificate()
	require.NoError(t, err)
	require.Equal(t, foundCert, sc)
}

func TestCommonName_Fail(t *testing.T) {
	c := &winCertStoreHandler{
		cfg: WindowsCertificateFilter{
			Server: &WindowsServerFilter{
				Store:             "My",
				SystemStore:       "LocalMachine",
				TemplateID:        "1.2.3",
				IssuerCommonNames: []string{"TEST"},
			},
		},
	}
	serverSt := newFakeStore()
	sc := makeCert(time.Now().Add(time.Duration(-1)*time.Minute), time.Now().Add(5*time.Minute), []int{1, 2, 3}, "BAD_EXAMPLE", "")
	serverSt.identities = append(serverSt.identities, newFakeIdentity(sc))
	findCert := func(systemStore, _ string) (certstore.Store, error) {
		return serverSt, nil
	}
	_, err := c.findCertificate(c.cfg.Server.SystemStore, c.cfg.Server.Store, c.cfg.Server.IssuerCommonNames, c.cfg.Server.TemplateID, nil, findCert)
	require.Error(t, err)
}

func TestTemplateIDFilter_Fail(t *testing.T) {
	c := &winCertStoreHandler{
		cfg: WindowsCertificateFilter{
			Server: &WindowsServerFilter{
				Store:       "My",
				SystemStore: "LocalMachine",
				TemplateID:  "1.2.3",
			},
		},
	}
	serverSt := newFakeStore()
	sc := makeCert(time.Now().Add(time.Duration(-1)*time.Minute), time.Now().Add(5*time.Minute), []int{1, 2}, "", "")
	serverSt.identities = append(serverSt.identities, newFakeIdentity(sc))
	findCert := func(systemStore, _ string) (certstore.Store, error) {
		return serverSt, nil
	}
	_, err := c.findCertificate(c.cfg.Server.SystemStore, c.cfg.Server.Store, c.cfg.Server.IssuerCommonNames, c.cfg.Server.TemplateID, nil, findCert)
	require.Error(t, err)
}

func TestMatching2CertsGetMostRecent(t *testing.T) {
	c := &winCertStoreHandler{
		cfg: WindowsCertificateFilter{
			Server: &WindowsServerFilter{
				Store:       "My",
				SystemStore: "LocalMachine",
				TemplateID:  "1.2.3",
			},
		},
	}
	serverSt := newFakeStore()
	sc := makeCert(time.Now().Add(time.Duration(-5)*time.Minute), time.Now().Add(5*time.Minute), []int{1, 2, 3}, "", "")
	shouldFind := makeCert(time.Now().Add(time.Duration(-1)*time.Minute), time.Now().Add(5*time.Minute), []int{1, 2, 3}, "", "")
	serverSt.identities = append(serverSt.identities, newFakeIdentity(sc))
	serverSt.identities = append(serverSt.identities, newFakeIdentity(shouldFind))

	findCert := func(systemStore, _ string) (certstore.Store, error) {
		return serverSt, nil
	}
	identity, err := c.findCertificate(c.cfg.Server.SystemStore, c.cfg.Server.Store, c.cfg.Server.IssuerCommonNames, c.cfg.Server.TemplateID, nil, findCert)

	require.NoError(t, err)
	foundCert, err := identity.Certificate()
	require.NoError(t, err)
	require.Equal(t, foundCert, shouldFind)
}

type fakeStore struct {
	identities []fakeIdentity
	closed     bool
}

func newFakeStore() fakeStore {
	return fakeStore{
		identities: make([]fakeIdentity, 0),
		closed:     false,
	}
}

func (f fakeStore) Identities() ([]certstore.Identity, error) {
	ids := make([]certstore.Identity, len(f.identities))
	for i, id := range f.identities {
		ids[i] = id
	}
	return ids, nil
}

func (f fakeStore) Import(data []byte, password string) error {
	panic("should not be called")
}

func (f fakeStore) Close() {
	f.closed = true
}

var testAsnTemplateID = []int{1, 3, 6, 1, 4, 1, 311, 21, 7}

type fakeIdentity struct {
	cert   *x509.Certificate
	closed bool
}

func newFakeIdentity(cert *x509.Certificate) fakeIdentity {
	return fakeIdentity{cert: cert}
}

func (f fakeIdentity) Certificate() (*x509.Certificate, error) {
	return f.cert, nil
}

func makeCert(start, end time.Time, templateID []int, commonName string, subject string) *x509.Certificate {
	cert := &x509.Certificate{
		SerialNumber: big.NewInt(2019),
		Subject: pkix.Name{
			Organization:  []string{"Company, INC."},
			Country:       []string{"US"},
			Province:      []string{""},
			Locality:      []string{"San Francisco"},
			StreetAddress: []string{"Golden Gate Bridge"},
			PostalCode:    []string{"94016"},
			CommonName:    commonName,
		},
		NotBefore:             start,
		NotAfter:              end,
		IsCA:                  false,
		ExtKeyUsage:           []x509.ExtKeyUsage{x509.ExtKeyUsageClientAuth, x509.ExtKeyUsageServerAuth},
		KeyUsage:              x509.KeyUsageDigitalSignature | x509.KeyUsageCertSign,
		BasicConstraintsValid: true,
		Issuer: pkix.Name{
			SerialNumber: subject,
			CommonName:   commonName,
		},
	}
	if len(templateID) != 0 {
		templateInfo := templateInformation{}
		templateInfo.Template = templateID
		ti, err := asn1.Marshal(templateInfo)
		if err != nil {
			println(err.Error())
			return nil
		}
		cert.Extensions = append(cert.Extensions, pkix.Extension{
			Id:       testAsnTemplateID,
			Critical: false,
			Value:    ti,
		})
	}
	return cert
}

func (f fakeIdentity) CertificateChain() ([]*x509.Certificate, error) {
	panic("should not be called")
}

func (f fakeIdentity) Signer() (crypto.Signer, error) {
	panic("should not be called")
}

func (f fakeIdentity) Delete() error {
	panic("should not be called")
}

func (f fakeIdentity) Close() {
	f.closed = true
}

'''
'''--- pkg/server/tls_test.go ---
package server

import (
	"crypto/tls"
	"fmt"
	"io"
	"log"
	"net"
	"net/http"
	"net/url"
	"testing"

	kitlog "github.com/go-kit/log"
	"github.com/stretchr/testify/require"
)

func Test_tlsListener(t *testing.T) {
	rawLis, err := net.Listen("tcp", "127.0.0.1:0")
	require.NoError(t, err)

	tlsConfig := TLSConfig{
		TLSCertPath: "testdata/example-cert.pem",
		TLSKeyPath:  "testdata/example-key.pem",
		ClientAuth:  "NoClientCert",
	}
	tlsLis, err := newTLSListener(rawLis, tlsConfig, kitlog.NewNopLogger())
	require.NoError(t, err)

	httpSrv := &http.Server{
		ErrorLog: log.New(io.Discard, "", 0),
	}
	go func() {
		_ = httpSrv.Serve(tlsLis)
	}()
	defer func() {
		httpSrv.Close()
	}()

	httpTransport := &http.Transport{
		TLSClientConfig: &tls.Config{
			InsecureSkipVerify: true,
		},
	}
	cli := http.Client{Transport: httpTransport}

	resp, err := cli.Get(fmt.Sprintf("https://%s", tlsLis.Addr()))
	if err == nil {
		resp.Body.Close()
	}
	require.NoError(t, err)

	// Update our TLSConfig to require a client cert.
	tlsConfig.ClientAuth = "RequireAndVerifyClientCert"
	require.NoError(t, tlsLis.ApplyConfig(tlsConfig))

	// Close our idle connections so our next request forces a new dial.
	httpTransport.CloseIdleConnections()

	// Create a second connection which should now fail because we don't supply a
	resp, err = cli.Get(fmt.Sprintf("https://%s", tlsLis.Addr()))
	if err == nil {
		resp.Body.Close()
	}

	var urlError *url.Error
	require.ErrorAs(t, err, &urlError)
	require.Contains(t, urlError.Err.Error(), "tls: bad certificate")
}

'''
'''--- pkg/traces/automaticloggingprocessor/automaticloggingprocessor.go ---
package automaticloggingprocessor

import (
	"context"
	"errors"
	"fmt"
	"strconv"
	"time"

	util "github.com/cortexproject/cortex/pkg/util/log"
	"github.com/go-kit/log"
	"github.com/go-kit/log/level"
	"github.com/go-logfmt/logfmt"
	"github.com/grafana/agent/pkg/logs"
	"github.com/grafana/agent/pkg/operator/config"
	"github.com/grafana/agent/pkg/traces/contextkeys"
	"github.com/grafana/loki/clients/pkg/promtail/api"
	"github.com/grafana/loki/pkg/logproto"
	"github.com/prometheus/common/model"
	"go.opentelemetry.io/collector/component"
	"go.opentelemetry.io/collector/consumer"
	pdata_internal "go.opentelemetry.io/collector/pdata/external"
	"go.opentelemetry.io/collector/pdata/pcommon"
	"go.opentelemetry.io/collector/pdata/ptrace"
	semconv "go.opentelemetry.io/collector/semconv/v1.6.1"
	"go.uber.org/atomic"
)

const (
	defaultLogsTag     = "traces"
	defaultServiceKey  = "svc"
	defaultSpanNameKey = "span"
	defaultStatusKey   = "status"
	defaultDurationKey = "dur"
	defaultTraceIDKey  = "tid"

	defaultTimeout = time.Millisecond

	typeSpan    = "span"
	typeRoot    = "root"
	typeProcess = "process"
)

type automaticLoggingProcessor struct {
	nextConsumer consumer.Traces

	cfg          *AutomaticLoggingConfig
	logToStdout  bool
	logsInstance *logs.Instance
	done         atomic.Bool

	labels map[string]struct{}

	logger log.Logger
}

func newTraceProcessor(nextConsumer consumer.Traces, cfg *AutomaticLoggingConfig) (component.TracesProcessor, error) {
	logger := log.With(util.Logger, "component", "traces automatic logging")

	if nextConsumer == nil {
		return nil, component.ErrNilNextConsumer
	}

	if !cfg.Roots && !cfg.Processes && !cfg.Spans {
		return nil, errors.New("automaticLoggingProcessor requires one of roots, processes, or spans to be enabled")
	}

	if cfg.Timeout == 0 {
		cfg.Timeout = defaultTimeout
	}

	if cfg.Backend == "" {
		cfg.Backend = BackendStdout
	}

	if cfg.Backend != BackendLogs && cfg.Backend != BackendStdout {
		return nil, fmt.Errorf("automaticLoggingProcessor requires a backend of type '%s' or '%s'", BackendLogs, BackendStdout)
	}

	logToStdout := false
	if cfg.Backend == BackendStdout {
		logToStdout = true
	}

	cfg.Overrides.LogsTag = override(cfg.Overrides.LogsTag, defaultLogsTag)
	cfg.Overrides.ServiceKey = override(cfg.Overrides.ServiceKey, defaultServiceKey)
	cfg.Overrides.SpanNameKey = override(cfg.Overrides.SpanNameKey, defaultSpanNameKey)
	cfg.Overrides.StatusKey = override(cfg.Overrides.StatusKey, defaultStatusKey)
	cfg.Overrides.DurationKey = override(cfg.Overrides.DurationKey, defaultDurationKey)
	cfg.Overrides.TraceIDKey = override(cfg.Overrides.TraceIDKey, defaultTraceIDKey)

	labels := make(map[string]struct{}, len(cfg.Labels))
	for _, l := range cfg.Labels {
		labels[l] = struct{}{}
	}

	return &automaticLoggingProcessor{
		nextConsumer: nextConsumer,
		cfg:          cfg,
		logToStdout:  logToStdout,
		logger:       logger,
		done:         atomic.Bool{},
		labels:       labels,
	}, nil
}

func (p *automaticLoggingProcessor) ConsumeTraces(ctx context.Context, td ptrace.Traces) error {
	rsLen := td.ResourceSpans().Len()
	for i := 0; i < rsLen; i++ {
		rs := td.ResourceSpans().At(i)
		ssLen := rs.ScopeSpans().Len()

		var svc string
		svcAtt, ok := rs.Resource().Attributes().Get(semconv.AttributeServiceName)
		if ok {
			svc = svcAtt.StringVal()
		}

		for j := 0; j < ssLen; j++ {
			ss := rs.ScopeSpans().At(j)
			spanLen := ss.Spans().Len()

			lastTraceID := ""
			for k := 0; k < spanLen; k++ {
				span := ss.Spans().At(k)
				traceID := span.TraceID().HexString()

				if p.cfg.Spans {
					keyValues := append(p.spanKeyVals(span), p.processKeyVals(rs.Resource(), svc)...)
					p.exportToLogsInstance(typeSpan, traceID, p.spanLabels(keyValues), keyValues...)
				}

				if p.cfg.Roots && span.ParentSpanID().IsEmpty() {
					keyValues := append(p.spanKeyVals(span), p.processKeyVals(rs.Resource(), svc)...)
					p.exportToLogsInstance(typeRoot, traceID, p.spanLabels(keyValues), keyValues...)
				}

				if p.cfg.Processes && lastTraceID != traceID {
					lastTraceID = traceID
					keyValues := p.processKeyVals(rs.Resource(), svc)
					p.exportToLogsInstance(typeProcess, traceID, p.spanLabels(keyValues), keyValues...)
				}
			}
		}
	}

	return p.nextConsumer.ConsumeTraces(ctx, td)
}

func (p *automaticLoggingProcessor) spanLabels(keyValues []interface{}) model.LabelSet {
	if len(keyValues) == 0 {
		return model.LabelSet{}
	}
	ls := make(map[model.LabelName]model.LabelValue, len(keyValues)/2)
	var (
		k, v string
		ok   bool
	)
	for i := 0; i < len(keyValues); i += 2 {
		if k, ok = keyValues[i].(string); !ok {
			// Should never happen, all keys are strings
			level.Error(p.logger).Log("msg", "error casting label key to string", "key", keyValues[i])
			continue
		}
		// Try to cast value to string
		if v, ok = keyValues[i+1].(string); !ok {
			// If it's not a string, format it to its string representation
			v = fmt.Sprintf("%v", keyValues[i+1])
		}
		if _, ok := p.labels[k]; ok {
			// Loki does not accept "." as a valid character for labels
			// Dots . are replaced by underscores _
			k = config.SanitizeLabelName(k)

			ls[model.LabelName(k)] = model.LabelValue(v)
		}
	}
	return ls
}

func (p *automaticLoggingProcessor) Capabilities() consumer.Capabilities {
	return consumer.Capabilities{}
}

// Start is invoked during service startup.
func (p *automaticLoggingProcessor) Start(ctx context.Context, _ component.Host) error {
	if !p.logToStdout {
		logs, ok := ctx.Value(contextkeys.Logs).(*logs.Logs)
		if !ok {
			return fmt.Errorf("key does not contain a logs instance")
		}
		p.logsInstance = logs.Instance(p.cfg.LogsName)
		if p.logsInstance == nil {
			return fmt.Errorf("logs instance %s not found", p.cfg.LogsName)
		}
	}
	return nil
}

// Shutdown is invoked during service shutdown.
func (p *automaticLoggingProcessor) Shutdown(context.Context) error {
	p.done.Store(true)

	return nil
}

func (p *automaticLoggingProcessor) processKeyVals(resource pcommon.Resource, svc string) []interface{} {
	atts := make([]interface{}, 0, 2) // 2 for service name
	rsAtts := resource.Attributes()

	// name
	atts = append(atts, p.cfg.Overrides.ServiceKey)
	atts = append(atts, svc)

	for _, name := range p.cfg.ProcessAttributes {
		att, ok := rsAtts.Get(name)
		if ok {
			// name/key val pairs
			atts = append(atts, name)
			atts = append(atts, attributeValue(att))
		}
	}

	return atts
}

func (p *automaticLoggingProcessor) spanKeyVals(span ptrace.Span) []interface{} {
	atts := make([]interface{}, 0, 8) // 8 for name, duration, service name and status

	atts = append(atts, p.cfg.Overrides.SpanNameKey)
	atts = append(atts, span.Name())

	atts = append(atts, p.cfg.Overrides.DurationKey)
	atts = append(atts, spanDuration(span))

	// Skip STATUS_CODE_UNSET to be less spammy
	if span.Status().Code() != pdata_internal.StatusCodeUnset {
		atts = append(atts, p.cfg.Overrides.StatusKey)
		atts = append(atts, span.Status().Code())
	}

	for _, name := range p.cfg.SpanAttributes {
		att, ok := span.Attributes().Get(name)
		if ok {
			atts = append(atts, name)
			atts = append(atts, attributeValue(att))
		}
	}

	return atts
}

func (p *automaticLoggingProcessor) exportToLogsInstance(kind string, traceID string, labels model.LabelSet, keyvals ...interface{}) {
	if p.done.Load() {
		return
	}

	keyvals = append(keyvals, []interface{}{p.cfg.Overrides.TraceIDKey, traceID}...)
	line, err := logfmt.MarshalKeyvals(keyvals...)
	if err != nil {
		level.Warn(p.logger).Log("msg", "unable to marshal keyvals", "err", err)
		return
	}

	// if we're logging to stdout, log and bail
	if p.logToStdout {
		level.Info(p.logger).Log(keyvals...)
		return
	}

	// Add logs instance label
	labels[model.LabelName(p.cfg.Overrides.LogsTag)] = model.LabelValue(kind)

	sent := p.logsInstance.SendEntry(api.Entry{
		Labels: labels,
		Entry: logproto.Entry{
			Timestamp: time.Now(),
			Line:      string(line),
		},
	}, p.cfg.Timeout)

	if !sent {
		level.Warn(p.logger).Log("msg", "failed to autolog to logs pipeline", "kind", kind, "traceid", traceID)
	}
}

func spanDuration(span ptrace.Span) string {
	dur := int64(span.EndTimestamp() - span.StartTimestamp())
	return strconv.FormatInt(dur, 10) + "ns"
}

func attributeValue(att pcommon.Value) interface{} {
	switch att.Type() {
	case pcommon.ValueTypeString:
		return att.StringVal()
	case pcommon.ValueTypeInt:
		return att.IntVal()
	case pcommon.ValueTypeDouble:
		return att.DoubleVal()
	case pcommon.ValueTypeBool:
		return att.BoolVal()
	case pcommon.ValueTypeMap:
		return att.MapVal()
	case pcommon.ValueTypeSlice:
		return att.SliceVal()
	}
	return nil
}

func override(cfgValue string, defaultValue string) string {
	if cfgValue == "" {
		return defaultValue
	}
	return cfgValue
}

'''
'''--- pkg/traces/automaticloggingprocessor/automaticloggingprocessor_test.go ---
package automaticloggingprocessor

import (
	"context"
	"testing"
	"time"

	"github.com/grafana/agent/pkg/logs"
	"github.com/grafana/agent/pkg/util"
	"github.com/prometheus/common/model"
	"github.com/stretchr/testify/assert"
	"github.com/stretchr/testify/require"
	"go.opentelemetry.io/collector/component/componenttest"
	pdata "go.opentelemetry.io/collector/pdata/external"
	"go.opentelemetry.io/collector/pdata/pcommon"
	"go.opentelemetry.io/collector/pdata/ptrace"
	"gopkg.in/yaml.v3"
)

func TestSpanKeyVals(t *testing.T) {
	tests := []struct {
		spanName  string
		spanAttrs map[string]interface{}
		spanStart time.Time
		spanEnd   time.Time
		cfg       AutomaticLoggingConfig
		expected  []interface{}
	}{
		{
			expected: []interface{}{
				"span", "",
				"dur", "0ns",
				"status", pdata.StatusCode(1),
			},
		},
		{
			spanName: "test",
			expected: []interface{}{
				"span", "test",
				"dur", "0ns",
				"status", pdata.StatusCode(1),
			},
		},
		{
			expected: []interface{}{
				"span", "",
				"dur", "0ns",
				"status", pdata.StatusCode(1),
			},
		},
		{
			spanStart: time.Unix(0, 0),
			spanEnd:   time.Unix(0, 10),
			expected: []interface{}{
				"span", "",
				"dur", "10ns",
				"status", pdata.StatusCode(1),
			},
		},
		{
			spanStart: time.Unix(0, 10),
			spanEnd:   time.Unix(0, 100),
			expected: []interface{}{
				"span", "",
				"dur", "90ns",
				"status", pdata.StatusCode(1),
			},
		},
		{
			spanAttrs: map[string]interface{}{
				"xstr": "test",
			},
			expected: []interface{}{
				"span", "",
				"dur", "0ns",
				"status", pdata.StatusCode(1),
			},
		},
		{
			spanAttrs: map[string]interface{}{
				"xstr": "test",
			},
			cfg: AutomaticLoggingConfig{
				SpanAttributes: []string{"xstr"},
			},
			expected: []interface{}{
				"span", "",
				"dur", "0ns",
				"status", pdata.StatusCode(1),
				"xstr", "test",
			},
		},
		{
			cfg: AutomaticLoggingConfig{
				Overrides: OverrideConfig{
					SpanNameKey: "a",
					DurationKey: "c",
					StatusKey:   "d",
				},
			},
			expected: []interface{}{
				"a", "",
				"c", "0ns",
				"d", pdata.StatusCode(1),
			},
		},
	}

	for _, tc := range tests {
		tc.cfg.Backend = BackendStdout
		tc.cfg.Spans = true
		p, err := newTraceProcessor(&automaticLoggingProcessor{}, &tc.cfg)
		require.NoError(t, err)

		span := ptrace.NewSpan()
		span.SetName(tc.spanName)
		pcommon.NewMapFromRaw(tc.spanAttrs).Sort().CopyTo(span.Attributes())
		span.SetStartTimestamp(pcommon.NewTimestampFromTime(tc.spanStart))
		span.SetEndTimestamp(pcommon.NewTimestampFromTime(tc.spanEnd))
		span.Status().SetCode(pdata.StatusCodeOk)

		actual := p.(*automaticLoggingProcessor).spanKeyVals(span)
		assert.Equal(t, tc.expected, actual)
	}
}

func TestProcessKeyVals(t *testing.T) {
	tests := []struct {
		processAttrs map[string]interface{}
		svc          string
		cfg          AutomaticLoggingConfig
		expected     []interface{}
	}{
		{
			expected: []interface{}{
				"svc", "",
			},
		},
		{
			processAttrs: map[string]interface{}{
				"xstr": "test",
			},
			expected: []interface{}{
				"svc", "",
			},
		},
		{
			processAttrs: map[string]interface{}{
				"xstr": "test",
			},
			cfg: AutomaticLoggingConfig{
				ProcessAttributes: []string{"xstr"},
			},
			expected: []interface{}{
				"svc", "",
				"xstr", "test",
			},
		},
	}

	for _, tc := range tests {
		tc.cfg.Backend = BackendStdout
		tc.cfg.Spans = true
		p, err := newTraceProcessor(&automaticLoggingProcessor{}, &tc.cfg)
		require.NoError(t, err)

		process := pcommon.NewResource()
		pcommon.NewMapFromRaw(tc.processAttrs).Sort().CopyTo(process.Attributes())

		actual := p.(*automaticLoggingProcessor).processKeyVals(process, tc.svc)
		assert.Equal(t, tc.expected, actual)
	}
}

func TestBadConfigs(t *testing.T) {
	tests := []struct {
		cfg *AutomaticLoggingConfig
	}{
		{
			cfg: &AutomaticLoggingConfig{},
		},
		{
			cfg: &AutomaticLoggingConfig{
				Backend: "blarg",
				Spans:   true,
			},
		},
		{
			cfg: &AutomaticLoggingConfig{
				Backend: "logs",
			},
		},
		{
			cfg: &AutomaticLoggingConfig{
				Backend: "loki",
			},
		},
		{
			cfg: &AutomaticLoggingConfig{
				Backend: "stdout",
			},
		},
	}

	for _, tc := range tests {
		p, err := newTraceProcessor(&automaticLoggingProcessor{}, tc.cfg)
		require.Error(t, err)
		require.Nil(t, p)
	}
}

func TestLogToStdoutSet(t *testing.T) {
	cfg := &AutomaticLoggingConfig{
		Backend: BackendStdout,
		Spans:   true,
	}

	p, err := newTraceProcessor(&automaticLoggingProcessor{}, cfg)
	require.NoError(t, err)
	require.True(t, p.(*automaticLoggingProcessor).logToStdout)

	err = p.Start(context.Background(), componenttest.NewNopHost())
	require.NoError(t, err)

	cfg = &AutomaticLoggingConfig{
		Backend: BackendLogs,
		Spans:   true,
	}

	p, err = newTraceProcessor(&automaticLoggingProcessor{}, cfg)
	require.NoError(t, err)
	require.False(t, p.(*automaticLoggingProcessor).logToStdout)
}

func TestDefaults(t *testing.T) {
	cfg := &AutomaticLoggingConfig{
		Spans: true,
	}

	p, err := newTraceProcessor(&automaticLoggingProcessor{}, cfg)
	require.NoError(t, err)
	require.Equal(t, BackendStdout, p.(*automaticLoggingProcessor).cfg.Backend)
	require.Equal(t, defaultTimeout, p.(*automaticLoggingProcessor).cfg.Timeout)
	require.True(t, p.(*automaticLoggingProcessor).logToStdout)

	require.Equal(t, defaultLogsTag, p.(*automaticLoggingProcessor).cfg.Overrides.LogsTag)
	require.Equal(t, defaultServiceKey, p.(*automaticLoggingProcessor).cfg.Overrides.ServiceKey)
	require.Equal(t, defaultSpanNameKey, p.(*automaticLoggingProcessor).cfg.Overrides.SpanNameKey)
	require.Equal(t, defaultStatusKey, p.(*automaticLoggingProcessor).cfg.Overrides.StatusKey)
	require.Equal(t, defaultDurationKey, p.(*automaticLoggingProcessor).cfg.Overrides.DurationKey)
	require.Equal(t, defaultTraceIDKey, p.(*automaticLoggingProcessor).cfg.Overrides.TraceIDKey)
}

func TestLokiNameMigration(t *testing.T) {
	logsConfig := &logs.Config{
		Configs: []*logs.InstanceConfig{{Name: "default"}},
	}

	input := util.Untab(`
		backend: loki
		loki_name: default
		overrides:
			loki_tag: traces
	`)
	expect := util.Untab(`
		backend: logs_instance
		logs_instance_name: default
		overrides:
			logs_instance_tag: traces
	`)

	var cfg AutomaticLoggingConfig
	require.NoError(t, yaml.Unmarshal([]byte(input), &cfg))
	require.NoError(t, cfg.Validate(logsConfig))

	bb, err := yaml.Marshal(cfg)
	require.NoError(t, err)
	require.YAMLEq(t, expect, string(bb))
}

func TestLabels(t *testing.T) {
	tests := []struct {
		name           string
		labels         []string
		keyValues      []interface{}
		expectedLabels model.LabelSet
	}{
		{
			name:      "happy case",
			labels:    []string{"loki", "svc"},
			keyValues: []interface{}{"loki", "loki", "svc", "gateway", "duration", "1s"},
			expectedLabels: map[model.LabelName]model.LabelValue{
				"loki": "loki",
				"svc":  "gateway",
			},
		},
		{
			name:      "happy case with dots",
			labels:    []string{"loki", "service.name"},
			keyValues: []interface{}{"loki", "loki", "service.name", "gateway", "duration", "1s"},
			expectedLabels: map[model.LabelName]model.LabelValue{
				"loki":         "loki",
				"service_name": "gateway",
			},
		},
		{
			name:           "no labels",
			labels:         []string{},
			keyValues:      []interface{}{"loki", "loki", "svc", "gateway", "duration", "1s"},
			expectedLabels: map[model.LabelName]model.LabelValue{},
		},
		{
			name:      "label not present in keyValues",
			labels:    []string{"loki", "svc"},
			keyValues: []interface{}{"loki", "loki", "duration", "1s"},
			expectedLabels: map[model.LabelName]model.LabelValue{
				"loki": "loki",
			},
		},
		{
			name:      "label value is not type string",
			labels:    []string{"loki"},
			keyValues: []interface{}{"loki", 42, "duration", "1s"},
			expectedLabels: map[model.LabelName]model.LabelValue{
				"loki": "42",
			},
		},
		{
			name:      "stringifies value if possible",
			labels:    []string{"status"},
			keyValues: []interface{}{"status", pdata.StatusCode(1)},
			expectedLabels: map[model.LabelName]model.LabelValue{
				"status": model.LabelValue(pdata.StatusCode(1).String()),
			},
		},
		{
			name:           "no keyValues",
			labels:         []string{"status"},
			keyValues:      []interface{}{},
			expectedLabels: map[model.LabelName]model.LabelValue{},
		},
	}

	for _, tc := range tests {
		t.Run(tc.name, func(t *testing.T) {
			cfg := &AutomaticLoggingConfig{
				Spans:  true,
				Labels: tc.labels,
			}
			p, err := newTraceProcessor(&automaticLoggingProcessor{}, cfg)
			require.NoError(t, err)

			ls := p.(*automaticLoggingProcessor).spanLabels(tc.keyValues)
			assert.Equal(t, tc.expectedLabels, ls)
		})
	}
}

'''
'''--- pkg/traces/automaticloggingprocessor/factory.go ---
package automaticloggingprocessor

import (
	"context"
	"fmt"
	"time"

	"github.com/grafana/agent/pkg/logs"
	"go.opentelemetry.io/collector/component"
	"go.opentelemetry.io/collector/config"
	"go.opentelemetry.io/collector/consumer"
)

// TypeStr is the unique identifier for the Automatic Logging processor.
const TypeStr = "automatic_logging"

// Config holds the configuration for the Automatic Logging processor.
type Config struct {
	config.ProcessorSettings `mapstructure:",squash"`

	LoggingConfig *AutomaticLoggingConfig `mapstructure:"automatic_logging"`
}

// AutomaticLoggingConfig holds config information for automatic logging
type AutomaticLoggingConfig struct {
	Backend           string         `mapstructure:"backend" yaml:"backend,omitempty"`
	LogsName          string         `mapstructure:"logs_instance_name" yaml:"logs_instance_name,omitempty"`
	Spans             bool           `mapstructure:"spans" yaml:"spans,omitempty"`
	Roots             bool           `mapstructure:"roots" yaml:"roots,omitempty"`
	Processes         bool           `mapstructure:"processes" yaml:"processes,omitempty"`
	SpanAttributes    []string       `mapstructure:"span_attributes" yaml:"span_attributes,omitempty"`
	ProcessAttributes []string       `mapstructure:"process_attributes" yaml:"process_attributes,omitempty"`
	Overrides         OverrideConfig `mapstructure:"overrides" yaml:"overrides,omitempty"`
	Timeout           time.Duration  `mapstructure:"timeout" yaml:"timeout,omitempty"`
	Labels            []string       `mapstructure:"labels" yaml:"labels,omitempty"`

	// Deprecated fields:
	LokiName string `mapstructure:"loki_name" yaml:"loki_name,omitempty"` // Superseded by LogsName
}

// Validate ensures that the AutomaticLoggingConfig is valid.
func (c *AutomaticLoggingConfig) Validate(logsConfig *logs.Config) error {
	if c.Backend == BackendLoki {
		c.Backend = BackendLogs
	}

	if c.LogsName != "" && c.LokiName != "" {
		return fmt.Errorf("must configure at most one of logs_instance_name and loki_name. loki_name is deprecated in favor of logs_instance_name")
	}

	if c.LogsName != "" && logsConfig == nil {
		return fmt.Errorf("logs instance %s is set but no logs config is provided", c.LogsName)
	}

	// Migrate deprecated config to new one
	if c.LogsName == "" && c.LokiName != "" {
		c.LogsName, c.LokiName = c.LokiName, ""
	}

	if c.Overrides.LogsTag != "" && c.Overrides.LokiTag != "" {
		return fmt.Errorf("must configure at most one of overrides.logs_instance_tag and overrides.loki_tag. loki_tag is deprecated in favor of logs_instance_tag")
	}

	// Migrate deprecated config to new one
	if c.Overrides.LogsTag == "" && c.Overrides.LokiTag != "" {
		c.Overrides.LogsTag, c.Overrides.LokiTag = c.Overrides.LokiTag, ""
	}

	// Ensure the logging instance exists when using it as a backend.
	if c.Backend == BackendLogs {
		var found bool
		for _, inst := range logsConfig.Configs {
			if inst.Name == c.LogsName {
				found = true
				break
			}
		}
		if !found {
			return fmt.Errorf("specified logs config %s not found in agent config", c.LogsName)
		}
	}

	return nil
}

// OverrideConfig contains overrides for various strings
type OverrideConfig struct {
	LogsTag     string `mapstructure:"logs_instance_tag" yaml:"logs_instance_tag,omitempty"`
	ServiceKey  string `mapstructure:"service_key" yaml:"service_key,omitempty"`
	SpanNameKey string `mapstructure:"span_name_key" yaml:"span_name_key,omitempty"`
	StatusKey   string `mapstructure:"status_key" yaml:"status_key,omitempty"`
	DurationKey string `mapstructure:"duration_key" yaml:"duration_key,omitempty"`
	TraceIDKey  string `mapstructure:"trace_id_key" yaml:"trace_id_key,omitempty"`

	// Deprecated fields:
	LokiTag string `mapstructure:"loki_tag" yaml:"loki_tag,omitempty"` // Superseded by LogsTag
}

const (
	// BackendLogs is the backend config for sending logs to a Loki pipeline
	BackendLogs = "logs_instance"
	// BackendLoki is an alias to BackendLogs. DEPRECATED.
	BackendLoki = "loki"
	// BackendStdout is the backend config value for sending logs to stdout
	BackendStdout = "stdout"
)

// NewFactory returns a new factory for the Attributes processor.
func NewFactory() component.ProcessorFactory {
	return component.NewProcessorFactory(
		TypeStr,
		createDefaultConfig,
		component.WithTracesProcessor(createTraceProcessor),
	)
}

func createDefaultConfig() config.Processor {
	return &Config{
		ProcessorSettings: config.NewProcessorSettings(config.NewComponentIDWithName(TypeStr, TypeStr)),
	}
}

func createTraceProcessor(
	_ context.Context,
	cp component.ProcessorCreateSettings,
	cfg config.Processor,
	nextConsumer consumer.Traces,
) (component.TracesProcessor, error) {

	oCfg := cfg.(*Config)
	return newTraceProcessor(nextConsumer, oCfg.LoggingConfig)
}

'''
'''--- pkg/traces/config.go ---
package traces

import (
	"encoding/base64"
	"errors"
	"fmt"
	"io/ioutil"
	"net"
	"sort"
	"strings"
	"time"

	"github.com/mitchellh/mapstructure"
	"github.com/open-telemetry/opentelemetry-collector-contrib/exporter/jaegerexporter"
	"github.com/open-telemetry/opentelemetry-collector-contrib/exporter/loadbalancingexporter"
	"github.com/open-telemetry/opentelemetry-collector-contrib/exporter/prometheusexporter"
	"github.com/open-telemetry/opentelemetry-collector-contrib/extension/oauth2clientauthextension"
	"github.com/open-telemetry/opentelemetry-collector-contrib/processor/attributesprocessor"
	"github.com/open-telemetry/opentelemetry-collector-contrib/processor/spanmetricsprocessor"
	"github.com/open-telemetry/opentelemetry-collector-contrib/processor/tailsamplingprocessor"
	"github.com/open-telemetry/opentelemetry-collector-contrib/receiver/jaegerreceiver"
	"github.com/open-telemetry/opentelemetry-collector-contrib/receiver/kafkareceiver"
	"github.com/open-telemetry/opentelemetry-collector-contrib/receiver/opencensusreceiver"
	"github.com/open-telemetry/opentelemetry-collector-contrib/receiver/zipkinreceiver"
	"github.com/prometheus/client_golang/prometheus"
	prom_config "github.com/prometheus/common/config"
	"go.opentelemetry.io/collector/component"
	"go.opentelemetry.io/collector/config"
	"go.opentelemetry.io/collector/config/configtest"
	"go.opentelemetry.io/collector/confmap"
	"go.opentelemetry.io/collector/exporter/otlpexporter"
	"go.opentelemetry.io/collector/exporter/otlphttpexporter"
	"go.opentelemetry.io/collector/processor/batchprocessor"
	"go.opentelemetry.io/collector/receiver/otlpreceiver"
	"go.opentelemetry.io/collector/service/external/configunmarshaler"
	"go.uber.org/multierr"

	"github.com/grafana/agent/pkg/logs"
	"github.com/grafana/agent/pkg/traces/automaticloggingprocessor"
	"github.com/grafana/agent/pkg/traces/noopreceiver"
	"github.com/grafana/agent/pkg/traces/promsdprocessor"
	"github.com/grafana/agent/pkg/traces/pushreceiver"
	"github.com/grafana/agent/pkg/traces/remotewriteexporter"
	"github.com/grafana/agent/pkg/traces/servicegraphprocessor"
	"github.com/grafana/agent/pkg/util"
)

const (
	spanMetricsPipelineName = "metrics/spanmetrics"

	// defaultDecisionWait is the default time to wait for a trace before making a sampling decision
	defaultDecisionWait = time.Second * 5

	// defaultLoadBalancingPort is the default port the agent uses for internal load balancing
	defaultLoadBalancingPort = "4318"
	// agent's load balancing options
	dnsTagName    = "dns"
	staticTagName = "static"

	// sampling policies
	alwaysSamplePolicy = "always_sample"

	// otlp receiver
	otlpReceiverName = "otlp"
)

// Config controls the configuration of Traces trace pipelines.
type Config struct {
	Configs []InstanceConfig `yaml:"configs,omitempty"`

	// Unmarshaled is true when the Config was unmarshaled from YAML.
	Unmarshaled bool `yaml:"-"`
}

// UnmarshalYAML implements yaml.Unmarshaler.
func (c *Config) UnmarshalYAML(unmarshal func(interface{}) error) error {
	c.Unmarshaled = true
	type plain Config
	return unmarshal((*plain)(c))
}

// Validate ensures that the Config is valid.
func (c *Config) Validate(logsConfig *logs.Config) error {
	names := make(map[string]struct{}, len(c.Configs))
	for idx, c := range c.Configs {
		if c.Name == "" {
			return fmt.Errorf("traces config at index %d is missing a name", idx)
		}
		if _, exist := names[c.Name]; exist {
			return fmt.Errorf("found multiple traces configs with name %s", c.Name)
		}
		names[c.Name] = struct{}{}
	}

	for _, inst := range c.Configs {
		if inst.AutomaticLogging != nil {
			if err := inst.AutomaticLogging.Validate(logsConfig); err != nil {
				return fmt.Errorf("failed to validate automatic_logging for traces config %s: %w", inst.Name, err)
			}
		}
	}

	return nil
}

// InstanceConfig configures an individual Traces trace pipeline.
type InstanceConfig struct {
	Name string `yaml:"name"`

	// RemoteWrite defines one or multiple backends that can receive the pipeline's traffic.
	RemoteWrite []RemoteWriteConfig `yaml:"remote_write,omitempty"`

	// Receivers: https://github.com/open-telemetry/opentelemetry-collector/blob/7d7ae2eb34b5d387627875c498d7f43619f37ee3/receiver/README.md
	Receivers ReceiverMap `yaml:"receivers,omitempty"`

	// Batch: https://github.com/open-telemetry/opentelemetry-collector/blob/7d7ae2eb34b5d387627875c498d7f43619f37ee3/processor/batchprocessor/config.go#L24
	Batch map[string]interface{} `yaml:"batch,omitempty"`

	// Attributes: https://github.com/open-telemetry/opentelemetry-collector/blob/7d7ae2eb34b5d387627875c498d7f43619f37ee3/processor/attributesprocessor/config.go#L30
	Attributes map[string]interface{} `yaml:"attributes,omitempty"`

	// prom service discovery config
	ScrapeConfigs   []interface{} `yaml:"scrape_configs,omitempty"`
	OperationType   string        `yaml:"prom_sd_operation_type,omitempty"`
	PodAssociations []string      `yaml:"prom_sd_pod_associations,omitempty"`

	// SpanMetricsProcessor: https://github.com/open-telemetry/opentelemetry-collector-contrib/blob/main/processor/spanmetricsprocessor/README.md
	SpanMetrics *SpanMetricsConfig `yaml:"spanmetrics,omitempty"`

	// AutomaticLogging
	AutomaticLogging *automaticloggingprocessor.AutomaticLoggingConfig `yaml:"automatic_logging,omitempty"`

	// TailSampling defines a sampling strategy for the pipeline
	TailSampling *tailSamplingConfig `yaml:"tail_sampling,omitempty"`

	// LoadBalancing is used to distribute spans of the same trace to the same agent instance
	LoadBalancing *loadBalancingConfig `yaml:"load_balancing"`

	// ServiceGraphs
	ServiceGraphs *serviceGraphsConfig `yaml:"service_graphs,omitempty"`
}

// ReceiverMap stores a set of receivers. Because receivers may be configured
// with an unknown set of sensitive information, ReceiverMap will marshal as
// YAML to the text "<secret>".
type ReceiverMap map[string]interface{}

// UnmarshalYAML implements yaml.Unmarshaler.
func (r *ReceiverMap) UnmarshalYAML(unmarshal func(interface{}) error) error {
	type plain ReceiverMap
	if err := unmarshal((*plain)(r)); err != nil {
		return err
	}

	protocols := []string{protocolHTTP, protocolGRPC}
	// enable include_metadata by default if receiver is OTLP
	for k := range *r {
		if strings.HasPrefix(k, otlpReceiverName) {
			// for http and grpc receivers, include_metadata is set to true by default
			protocolsCfg, ok := (*r)[k].(map[interface{}]interface{})["protocols"].(map[interface{}]interface{})
			if !ok {
				return fmt.Errorf("failed to parse OTLP receiver config: %s", k)
			}

			for _, p := range protocols {
				if cfg, ok := protocolsCfg[p]; ok {
					if cfg == nil {
						protocolsCfg[p] = map[interface{}]interface{}{"include_metadata": true}
					} else {
						if _, ok := cfg.(map[interface{}]interface{})["include_metadata"]; !ok {
							protocolsCfg[p].(map[interface{}]interface{})["include_metadata"] = true
						}
					}
				}
			}
		}
	}

	return nil
}

// MarshalYAML implements yaml.Marshaler.
func (r ReceiverMap) MarshalYAML() (interface{}, error) {
	return "<secret>", nil
}

const (
	compressionNone = "none"
	compressionGzip = "gzip"
	protocolGRPC    = "grpc"
	protocolHTTP    = "http"
)

const (
	formatOtlp   = "otlp"
	formatJaeger = "jaeger"
)

// DefaultRemoteWriteConfig holds the default settings for a PushConfig.
var DefaultRemoteWriteConfig = RemoteWriteConfig{
	Compression: compressionGzip,
	Protocol:    protocolGRPC,
	Format:      formatOtlp,
}

// TLSClientSetting configures the oauth2client extension TLS; compatible with configtls.TLSClientSetting
type TLSClientSetting struct {
	CAFile             string `yaml:"ca_file,omitempty"`
	CertFile           string `yaml:"cert_file,omitempty"`
	KeyFile            string `yaml:"key_file,omitempty"`
	MinVersion         string `yaml:"min_version,omitempty"`
	MaxVersion         string `yaml:"max_version,omitempty"`
	Insecure           bool   `yaml:"insecure"`
	InsecureSkipVerify bool   `yaml:"insecure_skip_verify"`
	ServerNameOverride string `yaml:"server_name_override,omitempty"`
}

// OAuth2Config configures the oauth2client extension for a remote_write exporter
// compatible with oauth2clientauthextension.Config
type OAuth2Config struct {
	ClientID     string           `yaml:"client_id"`
	ClientSecret string           `yaml:"client_secret"`
	TokenURL     string           `yaml:"token_url"`
	Scopes       []string         `yaml:"scopes,omitempty"`
	TLS          TLSClientSetting `yaml:"tls,omitempty"`
	Timeout      time.Duration    `yaml:"timeout,omitempty"`
}

// Agent uses standard YAML unmarshalling, while the oauth2clientauthextension relies on
// mapstructure without providing YAML labels. `toOtelConfig` marshals `Oauth2Config` to configuration type expected by
// the oauth2clientauthextension Extension Factory
func (c OAuth2Config) toOtelConfig() (*oauth2clientauthextension.Config, error) {
	var result *oauth2clientauthextension.Config
	decoderConfig := &mapstructure.DecoderConfig{
		MatchName:        func(s, t string) bool { return util.CamelToSnake(s) == t },
		Result:           &result,
		WeaklyTypedInput: true,
		DecodeHook: mapstructure.ComposeDecodeHookFunc(
			mapstructure.StringToSliceHookFunc(","),
			mapstructure.StringToTimeDurationHookFunc(),
		),
	}
	decoder, _ := mapstructure.NewDecoder(decoderConfig)
	if err := decoder.Decode(c); err != nil {
		return nil, err
	}
	return result, nil
}

// RemoteWriteConfig controls the configuration of an exporter
type RemoteWriteConfig struct {
	Endpoint    string `yaml:"endpoint,omitempty"`
	Compression string `yaml:"compression,omitempty"`
	Protocol    string `yaml:"protocol,omitempty"`
	Insecure    bool   `yaml:"insecure,omitempty"`
	Format      string `yaml:"format,omitempty"`
	// Deprecated
	InsecureSkipVerify bool                   `yaml:"insecure_skip_verify,omitempty"`
	TLSConfig          *prom_config.TLSConfig `yaml:"tls_config,omitempty"`
	BasicAuth          *prom_config.BasicAuth `yaml:"basic_auth,omitempty"`
	Oauth2             *OAuth2Config          `yaml:"oauth2,omitempty"`
	Headers            map[string]string      `yaml:"headers,omitempty"`
	SendingQueue       map[string]interface{} `yaml:"sending_queue,omitempty"`    // https://github.com/open-telemetry/opentelemetry-collector/blob/7d7ae2eb34b5d387627875c498d7f43619f37ee3/exporter/exporterhelper/queued_retry.go#L30
	RetryOnFailure     map[string]interface{} `yaml:"retry_on_failure,omitempty"` // https://github.com/open-telemetry/opentelemetry-collector/blob/7d7ae2eb34b5d387627875c498d7f43619f37ee3/exporter/exporterhelper/queued_retry.go#L54
}

// UnmarshalYAML implements yaml.Unmarshaler.
func (c *RemoteWriteConfig) UnmarshalYAML(unmarshal func(interface{}) error) error {
	*c = DefaultRemoteWriteConfig

	type plain RemoteWriteConfig

	if err := unmarshal((*plain)(c)); err != nil {
		return err
	}

	if c.Compression != compressionGzip && c.Compression != compressionNone {
		return fmt.Errorf("unsupported compression '%s', expected 'gzip' or 'none'", c.Compression)
	}

	if c.Format != formatOtlp && c.Format != formatJaeger {
		return fmt.Errorf("unsupported format '%s', expected 'otlp' or 'jaeger'", c.Format)
	}
	return nil
}

// SpanMetricsConfig controls the configuration of spanmetricsprocessor and the related metrics exporter.
type SpanMetricsConfig struct {
	LatencyHistogramBuckets []time.Duration                  `yaml:"latency_histogram_buckets,omitempty"`
	Dimensions              []spanmetricsprocessor.Dimension `yaml:"dimensions,omitempty"`
	// Namespace if set, exports metrics under the provided value.
	Namespace string `yaml:"namespace,omitempty"`
	// ConstLabels are values that are applied for every exported metric.
	ConstLabels *prometheus.Labels `yaml:"const_labels,omitempty"`
	// MetricsInstance is the Agent's metrics instance that will be used to push metrics
	MetricsInstance string `yaml:"metrics_instance"`
	// HandlerEndpoint is the address where a prometheus exporter will be exposed
	HandlerEndpoint string `yaml:"handler_endpoint"`
}

// tailSamplingConfig is the configuration for tail-based sampling
type tailSamplingConfig struct {
	// Policies are the strategies used for sampling. Multiple policies can be used in the same pipeline.
	// For more information, refer to https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/processor/tailsamplingprocessor
	Policies []policy `yaml:"policies"`
	// DecisionWait defines the time to wait for a complete trace before making a decision
	DecisionWait time.Duration `yaml:"decision_wait,omitempty"`
}

type policy struct {
	Name   string                 `yaml:"name,omitempty"`
	Type   string                 `yaml:"type"`
	Policy map[string]interface{} `yaml:",inline"`
}

// loadBalancingConfig defines the configuration for load balancing spans between agent instances
// loadBalancingConfig is an OTel exporter's config with extra resolver config
type loadBalancingConfig struct {
	Exporter exporterConfig         `yaml:"exporter"`
	Resolver map[string]interface{} `yaml:"resolver"`
	// ReceiverPort is the port the instance will use to receive load balanced traces
	ReceiverPort string `yaml:"receiver_port"`
}

// exporterConfig defined the config for an otlp exporter for load balancing
type exporterConfig struct {
	Compression        string                 `yaml:"compression,omitempty"`
	Insecure           bool                   `yaml:"insecure,omitempty"`
	InsecureSkipVerify bool                   `yaml:"insecure_skip_verify,omitempty"`
	BasicAuth          *prom_config.BasicAuth `yaml:"basic_auth,omitempty"`
	Format             string                 `yaml:"format,omitempty"`
}

type serviceGraphsConfig struct {
	Enabled  bool          `yaml:"enabled,omitempty"`
	Wait     time.Duration `yaml:"wait,omitempty"`
	MaxItems int           `yaml:"max_items,omitempty"`
}

// exporter builds an OTel exporter from RemoteWriteConfig
func exporter(rwCfg RemoteWriteConfig) (map[string]interface{}, error) {
	if len(rwCfg.Endpoint) == 0 {
		return nil, errors.New("must have a configured a backend endpoint")
	}

	headers := map[string]string{}
	if rwCfg.Headers != nil {
		headers = rwCfg.Headers
	}

	if rwCfg.BasicAuth != nil && rwCfg.Oauth2 != nil {
		return nil, fmt.Errorf("only one auth type may be configured per exporter (basic_auth or oauth2)")
	}

	if rwCfg.BasicAuth != nil {
		password := string(rwCfg.BasicAuth.Password)

		if len(rwCfg.BasicAuth.PasswordFile) > 0 {
			buff, err := ioutil.ReadFile(rwCfg.BasicAuth.PasswordFile)
			if err != nil {
				return nil, fmt.Errorf("unable to load password file %s: %w", rwCfg.BasicAuth.PasswordFile, err)
			}
			password = strings.TrimSpace(string(buff))
		}

		encodedAuth := base64.StdEncoding.EncodeToString([]byte(rwCfg.BasicAuth.Username + ":" + password))
		headers["authorization"] = "Basic " + encodedAuth
	}

	compression := rwCfg.Compression
	if compression == "" {
		compression = compressionNone
	}

	// Default OTLP exporter config awaits an empty headers map. Other exporters
	// (e.g. Jaeger) may expect a nil value instead
	if len(headers) == 0 && rwCfg.Format == formatJaeger {
		headers = nil
	}
	exporter := map[string]interface{}{
		"endpoint":         rwCfg.Endpoint,
		"compression":      compression,
		"headers":          headers,
		"sending_queue":    rwCfg.SendingQueue,
		"retry_on_failure": rwCfg.RetryOnFailure,
	}

	tlsConfig := map[string]interface{}{
		"insecure": rwCfg.Insecure,
	}
	if !rwCfg.Insecure {
		// If there is a TLSConfig use it
		if rwCfg.TLSConfig != nil {
			tlsConfig["ca_file"] = rwCfg.TLSConfig.CAFile
			tlsConfig["cert_file"] = rwCfg.TLSConfig.CertFile
			tlsConfig["key_file"] = rwCfg.TLSConfig.KeyFile
			tlsConfig["insecure_skip_verify"] = rwCfg.TLSConfig.InsecureSkipVerify
		} else {
			// If not, set whatever value is specified in the old config.
			tlsConfig["insecure_skip_verify"] = rwCfg.InsecureSkipVerify
		}
	}
	exporter["tls"] = tlsConfig

	// Apply some sane defaults to the exporter. The
	// sending_queue.retry_on_failure default is 300s which prevents any
	// sending-related errors to not be logged for 5 minutes. We'll lower that
	// to 60s.
	if retryConfig := exporter["retry_on_failure"].(map[string]interface{}); retryConfig == nil {
		exporter["retry_on_failure"] = map[string]interface{}{
			"max_elapsed_time": "60s",
		}
	} else if retryConfig["max_elapsed_time"] == nil {
		retryConfig["max_elapsed_time"] = "60s"
	}

	return exporter, nil
}

func getExporterName(index int, protocol string, format string) (string, error) {
	switch format {
	case formatOtlp:
		switch protocol {
		case protocolGRPC:
			return fmt.Sprintf("otlp/%d", index), nil
		case protocolHTTP:
			return fmt.Sprintf("otlphttp/%d", index), nil
		default:
			return "", errors.New("unknown protocol, expected either 'http' or 'grpc'")
		}
	case formatJaeger:
		switch protocol {
		case protocolGRPC:
			return fmt.Sprintf("jaeger/%d", index), nil
		default:
			return "", errors.New("unknown protocol, expected 'grpc'")
		}
	default:
		return "", errors.New("unknown format, expected either 'otlp' or 'jaeger'")
	}
}

// exporters builds one or multiple exporters from a remote_write block.
func (c *InstanceConfig) exporters() (map[string]interface{}, error) {
	exporters := map[string]interface{}{}
	for i, remoteWriteConfig := range c.RemoteWrite {
		exporter, err := exporter(remoteWriteConfig)
		if err != nil {
			return nil, err
		}
		exporterName, err := getExporterName(i, remoteWriteConfig.Protocol, remoteWriteConfig.Format)
		if err != nil {
			return nil, err
		}
		if remoteWriteConfig.Oauth2 != nil {
			exporter["auth"] = map[string]string{"authenticator": getAuthExtensionName(exporterName)}
		}
		exporters[exporterName] = exporter
	}
	return exporters, nil
}

func getAuthExtensionName(exporterName string) string {
	return fmt.Sprintf("oauth2client/%s", strings.Replace(exporterName, "/", "", -1))
}

// builds oauth2clientauth extensions required to support RemoteWriteConfigurations.
func (c *InstanceConfig) extensions() (map[string]interface{}, error) {
	extensions := map[string]interface{}{}
	for i, remoteWriteConfig := range c.RemoteWrite {
		if remoteWriteConfig.Oauth2 == nil {
			continue
		}
		exporterName, err := getExporterName(i, remoteWriteConfig.Protocol, remoteWriteConfig.Format)
		if err != nil {
			return nil, err
		}
		oauthConfig, err := remoteWriteConfig.Oauth2.toOtelConfig()
		if err != nil {
			return nil, err
		}
		extensions[getAuthExtensionName(exporterName)] = oauthConfig
	}
	return extensions, nil
}

func resolver(config map[string]interface{}) (map[string]interface{}, error) {
	if len(config) == 0 {
		return nil, fmt.Errorf("must configure one resolver (dns or static)")
	}
	resolverCfg := make(map[string]interface{})
	for typ, cfg := range config {
		switch typ {
		case dnsTagName, staticTagName:
			resolverCfg[typ] = cfg
		default:
			return nil, fmt.Errorf("unsupported resolver config type: %s", typ)
		}
	}
	return resolverCfg, nil
}

func (c *InstanceConfig) loadBalancingExporter() (map[string]interface{}, error) {
	exporter, err := exporter(RemoteWriteConfig{
		// Endpoint is omitted in OTel load balancing exporter
		Endpoint:    "noop",
		Compression: c.LoadBalancing.Exporter.Compression,
		Insecure:    c.LoadBalancing.Exporter.Insecure,
		TLSConfig:   &prom_config.TLSConfig{InsecureSkipVerify: c.LoadBalancing.Exporter.InsecureSkipVerify},
		BasicAuth:   c.LoadBalancing.Exporter.BasicAuth,
		Format:      c.LoadBalancing.Exporter.Format,
		Headers:     map[string]string{},
	})
	if err != nil {
		return nil, err
	}
	resolverCfg, err := resolver(c.LoadBalancing.Resolver)
	if err != nil {
		return nil, err
	}
	return map[string]interface{}{
		"protocol": map[string]interface{}{
			"otlp": exporter,
		},
		"resolver": resolverCfg,
	}, nil
}

// formatPolicies creates sampling policies (i.e. rules) compatible with OTel's tail sampling processor
// https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/v0.46.0/processor/tailsamplingprocessor
func formatPolicies(cfg []policy) ([]map[string]interface{}, error) {
	policies := make([]map[string]interface{}, 0, len(cfg))
	for i, policy := range cfg {
		typ, name := policy.Type, policy.Name
		if typ == "" {
			return nil, fmt.Errorf("policy %d must have a type", i)
		}

		if name == "" {
			name = fmt.Sprintf("%s/%d", typ, i)
		}

		switch typ {
		case alwaysSamplePolicy:
			policies = append(policies, map[string]interface{}{
				"name": name,
				"type": typ,
			})
		default:
			policies = append(policies, map[string]interface{}{
				"name": name,
				"type": typ,
				typ:    policy.Policy[typ],
			})
		}
	}
	return policies, nil
}

func (c *InstanceConfig) otelConfig() (*config.Config, error) {
	otelMapStructure := map[string]interface{}{}

	if len(c.Receivers) == 0 {
		return nil, errors.New("must have at least one configured receiver")
	}

	// add a hacky push receiver for when an integration
	// wants to push traces directly, eg app agent receiver.
	// it can only accept traces programatically from inside the agent
	c.Receivers[pushreceiver.TypeStr] = nil

	extensions, err := c.extensions()
	if err != nil {
		return nil, err
	}
	extensionsNames := make([]string, 0, len(extensions))
	for name := range extensions {
		extensionsNames = append(extensionsNames, name)
	}

	exporters, err := c.exporters()
	if err != nil {
		return nil, err
	}
	exportersNames := make([]string, 0, len(exporters))
	for name := range exporters {
		exportersNames = append(exportersNames, name)
	}

	// processors
	processors := map[string]interface{}{}
	processorNames := []string{}
	if c.ScrapeConfigs != nil {
		opType := promsdprocessor.OperationTypeUpsert
		if c.OperationType != "" {
			opType = c.OperationType
		}
		processorNames = append(processorNames, promsdprocessor.TypeStr)
		processors[promsdprocessor.TypeStr] = map[string]interface{}{
			"scrape_configs":   c.ScrapeConfigs,
			"operation_type":   opType,
			"pod_associations": c.PodAssociations,
		}
	}

	if c.AutomaticLogging != nil {
		processorNames = append(processorNames, automaticloggingprocessor.TypeStr)
		processors[automaticloggingprocessor.TypeStr] = map[string]interface{}{
			"automatic_logging": c.AutomaticLogging,
		}
	}

	if c.Attributes != nil {
		processors["attributes"] = c.Attributes
		processorNames = append(processorNames, "attributes")
	}

	if c.Batch != nil {
		processors["batch"] = c.Batch
		processorNames = append(processorNames, "batch")
	}

	pipelines := make(map[string]interface{})
	if c.SpanMetrics != nil {
		// Configure the metrics exporter.
		namespace := "traces_spanmetrics"
		if len(c.SpanMetrics.Namespace) != 0 {
			namespace = fmt.Sprintf("%s_%s", c.SpanMetrics.Namespace, namespace)
		}

		var exporterName string
		if len(c.SpanMetrics.MetricsInstance) != 0 && len(c.SpanMetrics.HandlerEndpoint) == 0 {
			exporterName = remotewriteexporter.TypeStr
			exporters[remotewriteexporter.TypeStr] = map[string]interface{}{
				"namespace":        namespace,
				"const_labels":     c.SpanMetrics.ConstLabels,
				"metrics_instance": c.SpanMetrics.MetricsInstance,
			}
		} else if len(c.SpanMetrics.MetricsInstance) == 0 && len(c.SpanMetrics.HandlerEndpoint) != 0 {
			exporterName = "prometheus"
			exporters[exporterName] = map[string]interface{}{
				"endpoint":     c.SpanMetrics.HandlerEndpoint,
				"namespace":    namespace,
				"const_labels": c.SpanMetrics.ConstLabels,
			}
		} else {
			return nil, fmt.Errorf("must specify a prometheus instance or a metrics handler endpoint to export the metrics")
		}

		processorNames = append(processorNames, "spanmetrics")
		processors["spanmetrics"] = map[string]interface{}{
			"metrics_exporter":          exporterName,
			"latency_histogram_buckets": c.SpanMetrics.LatencyHistogramBuckets,
			"dimensions":                c.SpanMetrics.Dimensions,
		}

		pipelines[spanMetricsPipelineName] = map[string]interface{}{
			"receivers": []string{noopreceiver.TypeStr},
			"exporters": []string{exporterName},
		}
	}

	// receivers
	receiverNames := []string{}
	for name := range c.Receivers {
		receiverNames = append(receiverNames, name)
	}

	if c.TailSampling != nil {
		wait := defaultDecisionWait
		if c.TailSampling.DecisionWait != 0 {
			wait = c.TailSampling.DecisionWait
		}

		policies, err := formatPolicies(c.TailSampling.Policies)
		if err != nil {
			return nil, err
		}

		// tail_sampling should be executed before the batch processor
		// TODO(mario.rodriguez): put attributes processor before tail_sampling. Maybe we want to sample on mutated spans
		processorNames = append([]string{"tail_sampling"}, processorNames...)
		processors["tail_sampling"] = map[string]interface{}{
			"policies":      policies,
			"decision_wait": wait,
		}
	}

	if c.LoadBalancing != nil {
		internalExporter, err := c.loadBalancingExporter()
		if err != nil {
			return nil, err
		}
		exporters["loadbalancing"] = internalExporter

		receiverPort := defaultLoadBalancingPort
		if c.LoadBalancing.ReceiverPort != "" {
			receiverPort = c.LoadBalancing.ReceiverPort
		}
		c.Receivers["otlp/lb"] = map[string]interface{}{
			"protocols": map[string]interface{}{
				"grpc": map[string]interface{}{
					"endpoint": net.JoinHostPort("0.0.0.0", receiverPort),
				},
			},
		}
	}

	if c.ServiceGraphs != nil && c.ServiceGraphs.Enabled {
		processors[servicegraphprocessor.TypeStr] = map[string]interface{}{
			"wait":      c.ServiceGraphs.Wait,
			"max_items": c.ServiceGraphs.MaxItems,
		}
		processorNames = append(processorNames, servicegraphprocessor.TypeStr)
	}

	// Build Pipelines
	splitPipeline := c.LoadBalancing != nil
	orderedSplitProcessors := orderProcessors(processorNames, splitPipeline)
	if splitPipeline {
		// load balancing pipeline
		pipelines["traces/0"] = map[string]interface{}{
			"receivers":  receiverNames,
			"processors": orderedSplitProcessors[0],
			"exporters":  []string{"loadbalancing"},
		}
		// processing pipeline
		pipelines["traces/1"] = map[string]interface{}{
			"exporters":  exportersNames,
			"processors": orderedSplitProcessors[1],
			"receivers":  []string{"otlp/lb"},
		}
	} else {
		pipelines["traces"] = map[string]interface{}{
			"exporters":  exportersNames,
			"processors": orderedSplitProcessors[0],
			"receivers":  receiverNames,
		}
	}

	if c.SpanMetrics != nil {
		// Insert a noop receiver in the metrics pipeline.
		// Added to pass validation requiring at least one receiver in a pipeline.
		c.Receivers[noopreceiver.TypeStr] = nil
	}

	receiversMap := map[string]interface{}(c.Receivers)

	otelMapStructure["extensions"] = extensions
	otelMapStructure["exporters"] = exporters
	otelMapStructure["processors"] = processors
	otelMapStructure["receivers"] = receiversMap

	// pipelines
	serviceMap := map[string]interface{}{
		"pipelines": pipelines,
	}
	if len(extensionsNames) > 0 {
		serviceMap["extensions"] = extensionsNames
	}
	otelMapStructure["service"] = serviceMap

	factories, err := tracingFactories()
	if err != nil {
		return nil, fmt.Errorf("failed to create factories: %w", err)
	}

	if err := validateConfigFromFactories(factories); err != nil {
		return nil, fmt.Errorf("failed to validate factories: %w", err)
	}

	configMap := confmap.NewFromStringMap(otelMapStructure)
	otelCfg, err := configunmarshaler.New().Unmarshal(configMap, factories)
	if err != nil {
		return nil, fmt.Errorf("failed to load OTel config: %w", err)
	}

	return otelCfg, nil
}

// tracingFactories() only creates the needed factories.  if we decide to add support for a new
// processor, exporter, receiver we need to add it here
func tracingFactories() (component.Factories, error) {
	extensions, err := component.MakeExtensionFactoryMap(
		oauth2clientauthextension.NewFactory(),
	)
	if err != nil {
		return component.Factories{}, err
	}

	receivers, err := component.MakeReceiverFactoryMap(
		jaegerreceiver.NewFactory(),
		zipkinreceiver.NewFactory(),
		otlpreceiver.NewFactory(),
		opencensusreceiver.NewFactory(),
		kafkareceiver.NewFactory(),
		noopreceiver.NewFactory(),
		pushreceiver.NewFactory(),
	)
	if err != nil {
		return component.Factories{}, err
	}

	exporters, err := component.MakeExporterFactoryMap(
		otlpexporter.NewFactory(),
		otlphttpexporter.NewFactory(),
		jaegerexporter.NewFactory(),
		loadbalancingexporter.NewFactory(),
		prometheusexporter.NewFactory(),
		remotewriteexporter.NewFactory(),
	)
	if err != nil {
		return component.Factories{}, err
	}

	processors, err := component.MakeProcessorFactoryMap(
		batchprocessor.NewFactory(),
		attributesprocessor.NewFactory(),
		promsdprocessor.NewFactory(),
		spanmetricsprocessor.NewFactory(),
		automaticloggingprocessor.NewFactory(),
		tailsamplingprocessor.NewFactory(),
		servicegraphprocessor.NewFactory(),
	)
	if err != nil {
		return component.Factories{}, err
	}

	return component.Factories{
		Extensions: extensions,
		Receivers:  receivers,
		Processors: processors,
		Exporters:  exporters,
	}, nil
}

// orders the passed processors into their preferred order in a tracing pipeline. pass
// true to splitPipelines if this function should split the input pipelines into two
// sets: before and after load balancing
func orderProcessors(processors []string, splitPipelines bool) [][]string {
	order := map[string]int{
		"attributes":        0,
		"spanmetrics":       1,
		"service_graphs":    2,
		"tail_sampling":     3,
		"automatic_logging": 4,
		"batch":             5,
	}

	sort.Slice(processors, func(i, j int) bool {
		iVal := order[processors[i]]
		jVal := order[processors[j]]

		return iVal < jVal
	})

	if !splitPipelines {
		return [][]string{
			processors,
		}
	}

	// if we're splitting pipelines we have to look for the first processor that belongs in the second
	// stage and split on that. if nothing belongs in the second stage just leave them all in the first
	foundAt := len(processors)
	for i, processor := range processors {
		if processor == "batch" ||
			processor == "tail_sampling" ||
			processor == "automatic_logging" ||
			processor == "service_graphs" {

			foundAt = i
			break
		}
	}

	return [][]string{
		processors[:foundAt],
		processors[foundAt:],
	}
}

// Code taken from OTel's service/configcheck.go
// https://github.com/grafana/opentelemetry-collector/blob/0.40-grafana/service/configcheck.go#L26-L43
func validateConfigFromFactories(factories component.Factories) error {
	var errs error

	for _, factory := range factories.Receivers {
		errs = multierr.Append(errs, configtest.CheckConfigStruct(factory.CreateDefaultConfig()))
	}
	for _, factory := range factories.Processors {
		errs = multierr.Append(errs, configtest.CheckConfigStruct(factory.CreateDefaultConfig()))
	}
	for _, factory := range factories.Exporters {
		errs = multierr.Append(errs, configtest.CheckConfigStruct(factory.CreateDefaultConfig()))
	}
	for _, factory := range factories.Extensions {
		errs = multierr.Append(errs, configtest.CheckConfigStruct(factory.CreateDefaultConfig()))
	}

	return errs
}

'''
'''--- pkg/traces/config_test.go ---
package traces

import (
	"io/ioutil"
	"os"
	"sort"
	"strings"
	"testing"

	"github.com/grafana/agent/pkg/traces/pushreceiver"
	"github.com/stretchr/testify/assert"
	"github.com/stretchr/testify/require"
	"go.opentelemetry.io/collector/config"
	"go.opentelemetry.io/collector/confmap"
	"go.opentelemetry.io/collector/service/external/configunmarshaler"
	"gopkg.in/yaml.v2"
)

func tmpFile(t *testing.T, content string) (*os.File, func()) {
	f, err := ioutil.TempFile("", "")
	require.NoError(t, err)

	_, err = f.Write([]byte(content))
	require.NoError(t, err)

	err = f.Close()
	require.NoError(t, err)

	return f, func() {
		os.Remove(f.Name())
	}
}

func TestOTelConfig(t *testing.T) {
	// create a password file to test the password file logic
	password := "password_in_file"
	passwordFile, teardown := tmpFile(t, password)
	defer teardown()

	// Extra linefeed in password_file. Spaces, tabs line feeds should be
	// stripped when reading it
	passwordFileExtraNewline, teardown := tmpFile(t, password+"\n")
	defer teardown()

	// tests!
	tt := []struct {
		name           string
		cfg            string
		expectedError  bool
		expectedConfig string
	}{
		{
			name:          "disabled",
			cfg:           "",
			expectedError: true,
		},
		{
			name: "no receivers",
			cfg: `
receivers:
`,
			expectedError: true,
		},
		{
			name: "no rw endpoint",
			cfg: `
receivers:
  jaeger:
`,
			expectedError: true,
		},
		{
			name: "empty receiver config",
			cfg: `
receivers:
  jaeger:
remote_write:
  - endpoint: example.com:12345
`,
			expectedError: true,
		},
		{
			name: "basic config",
			cfg: `
receivers:
  jaeger:
    protocols:
      grpc:
remote_write:
  - endpoint: example.com:12345
`,
			expectedConfig: `
receivers:
  push_receiver: {}
  jaeger:
    protocols:
      grpc:
exporters:
  otlp/0:
    endpoint: example.com:12345
    compression: gzip
    retry_on_failure:
      max_elapsed_time: 60s
service:
  pipelines:
    traces:
      exporters: ["otlp/0"]
      processors: []
      receivers: ["push_receiver", "jaeger"]
`,
		},
		{
			name: "processor config",
			cfg: `
receivers:
  jaeger:
    protocols:
      grpc:
attributes:
  actions:
  - key: montgomery
    value: forever
    action: update
batch:
  timeout: 5s
  send_batch_size: 100
remote_write:
  - endpoint: example.com:12345
    retry_on_failure:
      initial_interval: 10s
    sending_queue:
      num_consumers: 15
`,
			expectedConfig: `
receivers:
  push_receiver: {}
  jaeger:
    protocols:
      grpc:
exporters:
  otlp/0:
    endpoint: example.com:12345
    compression: gzip
    retry_on_failure:
      initial_interval: 10s
      max_elapsed_time: 60s
    sending_queue:
      num_consumers: 15
processors:
  attributes:
    actions:
    - key: montgomery
      value: forever
      action: update
  batch:
    timeout: 5s
    send_batch_size: 100
service:
  pipelines:
    traces:
      exporters: ["otlp/0"]
      processors: ["attributes", "batch"]
      receivers: ["push_receiver", "jaeger"]
`,
		},
		{
			name: "password in file",
			cfg: `
receivers:
  jaeger:
    protocols:
      grpc:
remote_write:
  - insecure: true
    endpoint: example.com:12345
    basic_auth:
      username: test
      password_file: ` + passwordFile.Name(),
			expectedConfig: `
receivers:
  push_receiver: {}
  jaeger:
    protocols:
      grpc:
exporters:
  otlp/0:
    endpoint: example.com:12345
    compression: gzip
    tls:
      insecure: true
    headers:
      authorization: Basic dGVzdDpwYXNzd29yZF9pbl9maWxl
    retry_on_failure:
      max_elapsed_time: 60s
service:
  pipelines:
    traces:
      exporters: ["otlp/0"]
      processors: []
      receivers: ["push_receiver", "jaeger"]
`,
		},
		{
			name: "password in file with extra newline",
			cfg: `
receivers:
  jaeger:
    protocols:
      grpc:
remote_write:
  - insecure: true
    endpoint: example.com:12345
    format: otlp
    basic_auth:
      username: test
      password_file: ` + passwordFileExtraNewline.Name(),
			expectedConfig: `
receivers:
  push_receiver: {}
  jaeger:
    protocols:
      grpc:
exporters:
  otlp/0:
    endpoint: example.com:12345
    compression: gzip
    tls:
      insecure: true
    headers:
      authorization: Basic dGVzdDpwYXNzd29yZF9pbl9maWxl
    retry_on_failure:
      max_elapsed_time: 60s
service:
  pipelines:
    traces:
      exporters: ["otlp/0"]
      processors: []
      receivers: ["push_receiver", "jaeger"]
`,
		},
		{
			name: "insecure skip verify",
			cfg: `
receivers:
  jaeger:
    protocols:
      grpc:
remote_write:
  - insecure_skip_verify: true
    endpoint: example.com:12345`,
			expectedConfig: `
receivers:
  push_receiver: {}
  jaeger:
    protocols:
      grpc:
exporters:
  otlp/0:
    endpoint: example.com:12345
    compression: gzip
    tls:
      insecure_skip_verify: true
    retry_on_failure:
      max_elapsed_time: 60s
service:
  pipelines:
    traces:
      exporters: ["otlp/0"]
      processors: []
      receivers: ["push_receiver", "jaeger"]
`,
		},
		{
			name: "no compression",
			cfg: `
receivers:
  jaeger:
    protocols:
      grpc:
remote_write:
  - insecure_skip_verify: true
    endpoint: example.com:12345
    compression: none`,
			expectedConfig: `
receivers:
  push_receiver: {}
  jaeger:
    protocols:
      grpc:
exporters:
  otlp/0:
    endpoint: example.com:12345
    tls:
      insecure_skip_verify: true
    retry_on_failure:
      max_elapsed_time: 60s
    compression: none
service:
  pipelines:
    traces:
      exporters: ["otlp/0"]
      processors: []
      receivers: ["push_receiver", "jaeger"]
`,
		},
		{
			name: "jaeger receiver remote_sampling TLS config",
			cfg: `
receivers:
  jaeger:
    protocols:
      grpc:
    remote_sampling:
      strategy_file: file_path
      tls:
        insecure: true
        insecure_skip_verify: true
        server_name_override: hostname
remote_write:
  - endpoint: example.com:12345
`,
			expectedConfig: `
receivers:
  push_receiver: {}
  jaeger:
    protocols:
      grpc:
    remote_sampling:
      strategy_file: file_path
      tls:
        insecure: true
        insecure_skip_verify: true
        server_name_override: hostname
exporters:
  otlp/0:
    endpoint: example.com:12345
    compression: gzip
    retry_on_failure:
      max_elapsed_time: 60s
service:
  pipelines:
    traces:
      exporters: ["otlp/0"]
      processors: []
      receivers: ["push_receiver", "jaeger"]
`,
		},
		{
			name: "push_config and remote_write",
			cfg: `
receivers:
  jaeger:
push_config:
  endpoint: example:12345
remote_write:
  - endpoint: anotherexample.com:12345
`,
			expectedError: true,
		},
		{
			name: "push_config.batch and batch",
			cfg: `
receivers:
  jaeger:
push_config:
  endpoint: example:12345
  batch:
    timeout: 5s
    send_batch_size: 100
batch:
  timeout: 5s
  send_batch_size: 100
remote_write:
  - endpoint: anotherexample.com:12345
`,
			expectedError: true,
		},
		{
			name: "one backend with remote_write",
			cfg: `
receivers:
  jaeger:
    protocols:
      grpc:
remote_write:
  - endpoint: example.com:12345
    headers:
      x-some-header: Some value!
`,
			expectedConfig: `
receivers:
  push_receiver: {}
  jaeger:
    protocols:
      grpc:
exporters:
  otlp/0:
    endpoint: example.com:12345
    compression: gzip
    headers:
      x-some-header: Some value!
    retry_on_failure:
      max_elapsed_time: 60s
service:
  pipelines:
    traces:
      exporters: ["otlp/0"]
      processors: []
      receivers: ["push_receiver", "jaeger"]
`,
		},
		{
			name: "two backends in a remote_write block",
			cfg: `
receivers:
  jaeger:
    protocols:
      grpc:
remote_write:
  - endpoint: example.com:12345
    basic_auth:
      username: test
      password: blerg
  - endpoint: anotherexample.com:12345
    compression: none
    insecure: false
    insecure_skip_verify: true
    basic_auth:
      username: test
      password_file: ` + passwordFile.Name() + `
    retry_on_failure:
      initial_interval: 10s
    sending_queue:
      num_consumers: 15
`,
			expectedConfig: `
receivers:
  push_receiver: {}
  jaeger:
    protocols:
      grpc:
exporters:
  otlp/0:
    endpoint: example.com:12345
    compression: gzip
    headers:
      authorization: Basic dGVzdDpibGVyZw==
    retry_on_failure:
      max_elapsed_time: 60s
  otlp/1:
    endpoint: anotherexample.com:12345
    tls:
      insecure: false
      insecure_skip_verify: true
    headers:
      authorization: Basic dGVzdDpwYXNzd29yZF9pbl9maWxl
    retry_on_failure:
      initial_interval: 10s
      max_elapsed_time: 60s
    sending_queue:
      num_consumers: 15
    compression: none
service:
  pipelines:
    traces:
      exporters: ["otlp/1", "otlp/0"]
      processors: []
      receivers: ["push_receiver", "jaeger"]
`,
		},
		{
			name: "batch block",
			cfg: `
receivers:
  jaeger:
    protocols:
      grpc:
remote_write:
  - endpoint: example.com:12345
batch:
  timeout: 5s
  send_batch_size: 100
`,
			expectedConfig: `
receivers:
  push_receiver: {}
  jaeger:
    protocols:
      grpc:
exporters:
  otlp/0:
    endpoint: example.com:12345
    compression: gzip
    retry_on_failure:
      max_elapsed_time: 60s
processors:
  batch:
    timeout: 5s
    send_batch_size: 100
service:
  pipelines:
    traces:
      exporters: ["otlp/0"]
      processors: ["batch"]
      receivers: ["push_receiver", "jaeger"]
`,
		},
		{
			name: "span metrics remote write exporter",
			cfg: `
receivers:
  jaeger:
    protocols:
      grpc:
remote_write:
  - endpoint: example.com:12345
spanmetrics:
  latency_histogram_buckets: [2ms, 6ms, 10ms, 100ms, 250ms]
  dimensions:
    - name: http.method
      default: GET
    - name: http.status_code
  metrics_instance: traces
`,
			expectedConfig: `
receivers:
  push_receiver: {}
  noop:
  jaeger:
    protocols:
      grpc:
exporters:
  otlp/0:
    endpoint: example.com:12345
    compression: gzip
    retry_on_failure:
      max_elapsed_time: 60s
  remote_write:
    namespace: traces_spanmetrics
    metrics_instance: traces
processors:
  spanmetrics:
    metrics_exporter: remote_write
    latency_histogram_buckets: [2ms, 6ms, 10ms, 100ms, 250ms]
    dimensions:
      - name: http.method
        default: GET
      - name: http.status_code
service:
  pipelines:
    traces:
      exporters: ["otlp/0"]
      processors: ["spanmetrics"]
      receivers: ["push_receiver", "jaeger"]
    metrics/spanmetrics:
      exporters: ["remote_write"]
      receivers: ["noop"]
`,
		},
		{
			name: "span metrics prometheus exporter",
			cfg: `
receivers:
  jaeger:
    protocols:
      grpc:
remote_write:
  - endpoint: example.com:12345
spanmetrics:
  handler_endpoint: "0.0.0.0:8889"
`,
			expectedConfig: `
receivers:
  push_receiver: {}
  noop:
  jaeger:
    protocols:
      grpc:
exporters:
  otlp/0:
    endpoint: example.com:12345
    compression: gzip
    retry_on_failure:
      max_elapsed_time: 60s
  prometheus:
    endpoint: "0.0.0.0:8889"
    namespace: traces_spanmetrics
processors:
  spanmetrics:
    metrics_exporter: prometheus
service:
  pipelines:
    traces:
      exporters: ["otlp/0"]
      processors: ["spanmetrics"]
      receivers: ["push_receiver", "jaeger"]
    metrics/spanmetrics:
      exporters: ["prometheus"]
      receivers: ["noop"]
`,
		},
		{
			name: "span metrics prometheus and remote write exporters fail",
			cfg: `
receivers:
  jaeger:
    protocols:
      grpc:
remote_write:
  - endpoint: example.com:12345
spanmetrics:
  handler_endpoint: "0.0.0.0:8889"
  metrics_instance: traces
`,
			expectedError: true,
		},
		{
			name: "tail sampling config",
			cfg: `
receivers:
  jaeger:
    protocols:
      grpc:
remote_write:
  - endpoint: example.com:12345
tail_sampling:
  policies:
    - type: always_sample
    - type: latency
      latency:
        threshold_ms: 100
    - type: numeric_attribute
      numeric_attribute:
        key: key1
        min_value: 50
        max_value: 100
    - type: probabilistic
      probabilistic:
        sampling_percentage: 10
    - type: status_code
      status_code:
        status_codes:
          - ERROR
          - UNSET
    - type: string_attribute
      string_attribute:
        key: key
        values:
          - value1
          - value2
    - type: rate_limiting
      rate_limiting:
        spans_per_second: 35
`,
			expectedConfig: `
receivers:
  push_receiver: {}
  jaeger:
    protocols:
      grpc:
exporters:
  otlp/0:
    endpoint: example.com:12345
    compression: gzip
    retry_on_failure:
      max_elapsed_time: 60s
processors:
  tail_sampling:
    decision_wait: 5s
    policies:
      - name: always_sample/0
        type: always_sample
      - name: latency/1
        type: latency
        latency:
          threshold_ms: 100
      - name: numeric_attribute/2
        type: numeric_attribute
        numeric_attribute:
          key: key1
          min_value: 50
          max_value: 100
      - name: probabilistic/3
        type: probabilistic
        probabilistic:
          sampling_percentage: 10
      - name: status_code/4
        type: status_code
        status_code:
          status_codes:
            - ERROR
            - UNSET
      - name: string_attribute/5
        type: string_attribute
        string_attribute:
          key: key
          values:
            - value1
            - value2
      - name: rate_limiting/6
        type: rate_limiting
        rate_limiting:
          spans_per_second: 35
service:
  pipelines:
    traces:
      exporters: ["otlp/0"]
      processors: ["tail_sampling"]
      receivers: ["push_receiver", "jaeger"]
`,
		},
		{
			name: "tail sampling config with load balancing",
			cfg: `
receivers:
  jaeger:
    protocols:
      grpc:
remote_write:
  - endpoint: example.com:12345
tail_sampling:
  policies:
    - type: always_sample
    - type: string_attribute
      string_attribute:
        key: key
        values:
          - value1
          - value2
load_balancing:
  receiver_port: 8080
  exporter:
    insecure: true
  resolver:
    dns:
      hostname: agent
      port: 8080
`,
			expectedConfig: `
receivers:
  jaeger:
    protocols:
      grpc:
  push_receiver: {}
  otlp/lb:
    protocols:
      grpc:
        endpoint: "0.0.0.0:8080"
exporters:
  otlp/0:
    endpoint: example.com:12345
    compression: gzip
    retry_on_failure:
      max_elapsed_time: 60s
  loadbalancing:
    protocol:
      otlp:
        tls:
          insecure: true
        endpoint: noop
        retry_on_failure:
          max_elapsed_time: 60s
        compression: none
    resolver:
      dns:
        hostname: agent
        port: 8080
processors:
  tail_sampling:
    decision_wait: 5s
    policies:
      - name: always_sample/0
        type: always_sample
      - name: string_attribute/1
        type: string_attribute
        string_attribute:
          key: key
          values:
            - value1
            - value2
service:
  pipelines:
    traces/0:
      exporters: ["loadbalancing"]
      processors: []
      receivers: ["jaeger", "push_receiver"]
    traces/1:
      exporters: ["otlp/0"]
      processors: ["tail_sampling"]
      receivers: ["otlp/lb"]
`,
		},
		{
			name: "automatic logging : default",
			cfg: `
receivers:
  jaeger:
    protocols:
      grpc:
remote_write:
  - endpoint: example.com:12345
automatic_logging:
  spans: true
`,
			expectedConfig: `
receivers:
  push_receiver: {}
  jaeger:
    protocols:
      grpc:
processors:
  automatic_logging:
    automatic_logging:
      spans: true
exporters:
  otlp/0:
    endpoint: example.com:12345
    compression: gzip
    retry_on_failure:
      max_elapsed_time: 60s
service:
  pipelines:
    traces:
      exporters: ["otlp/0"]
      processors: ["automatic_logging"]
      receivers: ["push_receiver", "jaeger"]
      `,
		},
		{
			name: "tls config",
			cfg: `
receivers:
  jaeger:
    protocols:
      grpc:
remote_write:
  - insecure: false
    tls_config:
      ca_file: server.crt
      cert_file: client.crt
      key_file: client.key
    endpoint: example.com:12345
`,
			expectedConfig: `
receivers:
  push_receiver: {}
  jaeger:
    protocols:
      grpc:
exporters:
  otlp/0:
    endpoint: example.com:12345
    tls:
      insecure: false
      ca_file: server.crt
      cert_file: client.crt
      key_file: client.key
    compression: gzip
    retry_on_failure:
      max_elapsed_time: 60s
service:
  pipelines:
    traces:
      exporters: ["otlp/0"]
      processors: []
      receivers: ["push_receiver", "jaeger"]
`,
		},
		{
			name: "otlp http & grpc exporters",
			cfg: `
receivers:
  jaeger:
    protocols:
      grpc:
remote_write:
  - endpoint: example.com:12345
    protocol: http
  - endpoint: example.com:12345
    protocol: grpc
`,
			expectedConfig: `
receivers:
  push_receiver: {}
  jaeger:
    protocols:
      grpc:
exporters:
  otlphttp/0:
    endpoint: example.com:12345
    compression: gzip
    retry_on_failure:
      max_elapsed_time: 60s
  otlp/1:
    endpoint: example.com:12345
    compression: gzip
    retry_on_failure:
      max_elapsed_time: 60s
service:
  pipelines:
    traces:
      exporters: ["otlphttp/0", "otlp/1"]
      processors: []
      receivers: ["push_receiver", "jaeger"]
`,
		},
		{
			name: "prom SD config",
			cfg: `
receivers:
  jaeger:
    protocols:
      grpc:
remote_write:
  - endpoint: example.com:12345
    protocol: grpc
scrape_configs:
  - im_a_scrape_config
prom_sd_operation_type: update
`,
			expectedConfig: `
receivers:
  push_receiver: {}
  jaeger:
    protocols:
      grpc:
exporters:
  otlp/0:
    endpoint: example.com:12345
    compression: gzip
    retry_on_failure:
      max_elapsed_time: 60s
processors:
  prom_sd_processor:
    scrape_configs:
      - im_a_scrape_config
    operation_type: update
service:
  pipelines:
    traces:
      exporters: ["otlp/0"]
      processors: ["prom_sd_processor"]
      receivers: ["push_receiver", "jaeger"]
`,
		},
		{
			name: "service graphs",
			cfg: `
receivers:
  jaeger:
    protocols:
      grpc:
remote_write:
  - endpoint: example.com:12345
service_graphs:
  enabled: true
`,
			expectedConfig: `
receivers:
  push_receiver: {}
  jaeger:
    protocols:
      grpc:
exporters:
  otlp/0:
    endpoint: example.com:12345
    compression: gzip
    retry_on_failure:
      max_elapsed_time: 60s
processors:
  service_graphs:
service:
  pipelines:
    traces:
      exporters: ["otlp/0"]
      processors: ["service_graphs"]
      receivers: ["push_receiver", "jaeger"]
`,
		},
		{
			name: "jaeger exporter",
			cfg: `
receivers:
  jaeger:
    protocols:
      grpc:
remote_write:
  - insecure: true
    format: jaeger
    endpoint: example.com:12345
`,
			expectedConfig: `
receivers:
  push_receiver: {}
  jaeger:
    protocols:
      grpc:
exporters:
  jaeger/0:
    endpoint: example.com:12345
    compression: gzip
    tls:
      insecure: true
    retry_on_failure:
      max_elapsed_time: 60s
service:
  pipelines:
    traces:
      exporters: ["jaeger/0"]
      processors: []
      receivers: ["push_receiver", "jaeger"]
`,
		},
		{
			name: "jaeger exporter with basic auth",
			cfg: `
receivers:
  jaeger:
    protocols:
      grpc:
remote_write:
  - insecure: true
    format: jaeger
    protocol: grpc
    basic_auth:
      username: test
      password_file: ` + passwordFile.Name() + `
    endpoint: example.com:12345
`,
			expectedConfig: `
receivers:
  push_receiver: {}
  jaeger:
    protocols:
      grpc:
exporters:
  jaeger/0:
    endpoint: example.com:12345
    compression: gzip
    tls:
      insecure: true
    headers:
      authorization: Basic dGVzdDpwYXNzd29yZF9pbl9maWxl
    retry_on_failure:
      max_elapsed_time: 60s
service:
  pipelines:
    traces:
      exporters: ["jaeger/0"]
      processors: []
      receivers: ["push_receiver", "jaeger"]
`,
		},
		{
			name: "two exporters different format",
			cfg: `
receivers:
  jaeger:
    protocols:
      grpc:
remote_write:
  - insecure: true
    format: jaeger
    endpoint: example.com:12345
  - insecure: true
    format: otlp
    endpoint: something.com:123
`,
			expectedConfig: `
receivers:
  push_receiver: {}
  jaeger:
    protocols:
      grpc:
exporters:
  jaeger/0:
    endpoint: example.com:12345
    compression: gzip
    tls:
      insecure: true
    retry_on_failure:
      max_elapsed_time: 60s
  otlp/1:
    endpoint: something.com:123
    compression: gzip
    tls:
      insecure: true
    retry_on_failure:
      max_elapsed_time: 60s
service:
  pipelines:
    traces:
      exporters: ["jaeger/0", "otlp/1"]
      processors: []
      receivers: ["push_receiver", "jaeger"]
`,
		},
		{
			name: "one exporter with oauth2 and basic auth",
			cfg: `
receivers:
  jaeger:
    protocols:
      grpc:
remote_write:
  - endpoint: example.com:12345
    basic_auth:
      username: test
      password: blerg
    oauth2:
      client_id: somecclient
      client_secret: someclientsecret
`,
			expectedError: true,
		},
		{
			name: "simple oauth2 config",
			cfg: `
receivers:
  jaeger:
    protocols:
      grpc:
remote_write:
  - endpoint: example.com:12345
    protocol: http
    oauth2:
      client_id: someclientid
      client_secret: someclientsecret
      token_url: https://example.com/oauth2/default/v1/token
      scopes: ["api.metrics"]
      timeout: 2s
`,
			expectedConfig: `
receivers:
  push_receiver: {}
  jaeger:
    protocols:
      grpc:
extensions:
  oauth2client/otlphttp0:
    client_id: someclientid
    client_secret: someclientsecret
    token_url: https://example.com/oauth2/default/v1/token
    scopes: ["api.metrics"]
    timeout: 2s
exporters:
  otlphttp/0:
    endpoint: example.com:12345
    compression: gzip
    retry_on_failure:
      max_elapsed_time: 60s
    auth:
      authenticator: oauth2client/otlphttp0
service:
  extensions: ["oauth2client/otlphttp0"]
  pipelines:
    traces:
      exporters: ["otlphttp/0"]
      processors: []
      receivers: ["push_receiver", "jaeger"]
`,
		},
		{
			name: "oauth2 TLS",
			cfg: `
receivers:
  jaeger:
    protocols:
      grpc:
remote_write:
  - endpoint: example.com:12345
    protocol: http
    oauth2:
      client_id: someclientid
      client_secret: someclientsecret
      token_url: https://example.com/oauth2/default/v1/token
      scopes: ["api.metrics"]
      timeout: 2s
      tls:
        insecure: true
        ca_file: /var/lib/mycert.pem
        cert_file: certfile
        key_file: keyfile
`,
			expectedConfig: `
receivers:
  push_receiver: {}
  jaeger:
    protocols:
      grpc:
extensions:
  oauth2client/otlphttp0:
    client_id: someclientid
    client_secret: someclientsecret
    token_url: https://example.com/oauth2/default/v1/token
    scopes: ["api.metrics"]
    timeout: 2s
    tls:
      insecure: true
      ca_file: /var/lib/mycert.pem
      cert_file: certfile
      key_file: keyfile
exporters:
  otlphttp/0:
    endpoint: example.com:12345
    compression: gzip
    retry_on_failure:
      max_elapsed_time: 60s
    auth:
      authenticator: oauth2client/otlphttp0
service:
  extensions: ["oauth2client/otlphttp0"]
  pipelines:
    traces:
      exporters: ["otlphttp/0"]
      processors: []
      receivers: ["push_receiver", "jaeger"]
`,
		},
		{
			name: "2 exporters different auth",
			cfg: `
receivers:
 jaeger:
   protocols:
     grpc:
remote_write:
 - endpoint: example.com:12345
   protocol: http
   oauth2:
     client_id: someclientid
     client_secret: someclientsecret
     token_url: https://example.com/oauth2/default/v1/token
     scopes: ["api.metrics"]
     timeout: 2s
 - endpoint: example.com:12345
   protocol: grpc
   oauth2:
     client_id: anotherclientid
     client_secret: anotherclientsecret
     token_url: https://example.com/oauth2/default/v1/token
     scopes: ["api.metrics"]
     timeout: 2s
`,
			expectedConfig: `
receivers:
 push_receiver: {}
 jaeger:
   protocols:
     grpc:
extensions:
 oauth2client/otlphttp0:
   client_id: someclientid
   client_secret: someclientsecret
   token_url: https://example.com/oauth2/default/v1/token
   scopes: ["api.metrics"]
   timeout: 2s
 oauth2client/otlp1:
   client_id: anotherclientid
   client_secret: anotherclientsecret
   token_url: https://example.com/oauth2/default/v1/token
   scopes: ["api.metrics"]
   timeout: 2s
exporters:
  otlphttp/0:
    endpoint: example.com:12345
    compression: gzip
    retry_on_failure:
      max_elapsed_time: 60s
    auth:
      authenticator: oauth2client/otlphttp0
  otlp/1:
    endpoint: example.com:12345
    compression: gzip
    retry_on_failure:
      max_elapsed_time: 60s
    auth:
      authenticator: oauth2client/otlp1
service:
  extensions: ["oauth2client/otlphttp0", "oauth2client/otlp1"]
  pipelines:
    traces:
      exporters: ["otlphttp/0", "otlp/1"]
      processors: []
      receivers: ["push_receiver", "jaeger"]
`,
		},
		{
			name: "exporter with insecure oauth",
			cfg: `
receivers:
  jaeger:
    protocols:
      grpc:
remote_write:
  - endpoint: http://example.com:12345
    insecure: true
    protocol: http
    oauth2:
      client_id: someclientid
      client_secret: someclientsecret
      token_url: https://example.com/oauth2/default/v1/token
      scopes: ["api.metrics"]
      timeout: 2s
      tls:
        insecure: true
`,
			expectedConfig: `
receivers:
  push_receiver: {}
  jaeger:
    protocols:
      grpc:
extensions:
  oauth2client/otlphttp0:
    client_id: someclientid
    client_secret: someclientsecret
    token_url: https://example.com/oauth2/default/v1/token
    scopes: ["api.metrics"]
    timeout: 2s
    tls:
      insecure: true
exporters:
  otlphttp/0:
    endpoint: http://example.com:12345
    tls:
      insecure: true
    compression: gzip
    retry_on_failure:
      max_elapsed_time: 60s
    auth:
      authenticator: oauth2client/otlphttp0
service:
  extensions: ["oauth2client/otlphttp0"]
  pipelines:
    traces:
      exporters: ["otlphttp/0"]
      processors: []
      receivers: ["push_receiver", "jaeger"]
`,
		},
		{
			name: "OTLP receivers get include_metadata set to true by default",
			cfg: `
receivers:
  otlp/0:
    protocols:
      grpc:
      http:
        endpoint: localhost:4318
  otlp/1:
    protocols:
      grpc:
        include_metadata: false
      http:
        include_metadata: false
        endpoint: localhost:4318
remote_write:
  - endpoint: example.com:12345
`,
			expectedConfig: `
receivers:
  push_receiver:
  otlp/0:
    protocols:
      grpc:
        include_metadata: true
      http:
        include_metadata: true
        endpoint: localhost:4318
  otlp/1:
    protocols:
      grpc:
        include_metadata: false
      http:
        include_metadata: false
        endpoint: localhost:4318
exporters:
  otlp/0:
    endpoint: example.com:12345
    compression: gzip
    retry_on_failure:
      max_elapsed_time: 60s
service:
  pipelines:
    traces:
      exporters: ["otlp/0"]
      processors: []
      receivers: ["push_receiver", "otlp/0", "otlp/1"]
`,
		},
	}

	for _, tc := range tt {
		t.Run(tc.name, func(t *testing.T) {
			var cfg InstanceConfig
			err := yaml.Unmarshal([]byte(tc.cfg), &cfg)
			require.NoError(t, err)
			// check error
			actualConfig, err := cfg.otelConfig()
			if tc.expectedError {
				assert.Error(t, err)
				return
			}
			require.NoError(t, err)

			// convert actual config to otel config
			otelMapStructure := map[string]interface{}{}
			err = yaml.Unmarshal([]byte(tc.expectedConfig), otelMapStructure)
			require.NoError(t, err)

			factories, err := tracingFactories()
			require.NoError(t, err)

			configMap := confmap.NewFromStringMap(otelMapStructure)
			cfgUnmarshaler := configunmarshaler.New()
			expectedConfig, err := cfgUnmarshaler.Unmarshal(configMap, factories)
			require.NoError(t, err)

			// Exporters/Receivers/Processors in the config's service.Pipelines, as well as
			// service.Extensions have to be in the same order for them to be asserted as equal.
			sortService(actualConfig)
			sortService(expectedConfig)

			assert.Equal(t, expectedConfig, actualConfig)
		})
	}
}

func TestProcessorOrder(t *testing.T) {
	// tests!
	tt := []struct {
		name               string
		cfg                string
		expectedProcessors map[string][]config.ComponentID
	}{
		{
			name: "no processors",
			cfg: `
receivers:
  jaeger:
    protocols:
      grpc:
remote_write:
  - endpoint: example.com:12345
    headers:
      x-some-header: Some value!
`,
			expectedProcessors: map[string][]config.ComponentID{
				"traces": nil,
			},
		},
		{
			name: "all processors w/o load balancing",
			cfg: `
receivers:
  jaeger:
    protocols:
      grpc:
remote_write:
  - endpoint: example.com:12345
    headers:
      x-some-header: Some value!
attributes:
  actions:
  - key: montgomery
    value: forever
    action: update
spanmetrics:
  latency_histogram_buckets: [2ms, 6ms, 10ms, 100ms, 250ms]
  dimensions:
    - name: http.method
      default: GET
    - name: http.status_code
  metrics_instance: traces
automatic_logging:
  spans: true
batch:
  timeout: 5s
  send_batch_size: 100
tail_sampling:
  policies:
    - type: always_sample
    - type: string_attribute
      string_attribute:
        key: key
        values:
          - value1
          - value2
service_graphs:
  enabled: true
`,
			expectedProcessors: map[string][]config.ComponentID{
				"traces": {
					config.NewComponentID("attributes"),
					config.NewComponentID("spanmetrics"),
					config.NewComponentID("service_graphs"),
					config.NewComponentID("tail_sampling"),
					config.NewComponentID("automatic_logging"),
					config.NewComponentID("batch"),
				},
				spanMetricsPipelineName: nil,
			},
		},
		{
			name: "all processors with load balancing",
			cfg: `
receivers:
  jaeger:
    protocols:
      grpc:
remote_write:
  - endpoint: example.com:12345
    headers:
      x-some-header: Some value!
attributes:
  actions:
  - key: montgomery
    value: forever
    action: update
spanmetrics:
  latency_histogram_buckets: [2ms, 6ms, 10ms, 100ms, 250ms]
  dimensions:
    - name: http.method
      default: GET
    - name: http.status_code
  metrics_instance: traces
automatic_logging:
  spans: true
batch:
  timeout: 5s
  send_batch_size: 100
tail_sampling:
  policies:
    - type: always_sample
    - type: string_attribute
      string_attribute:
        key: key
        values:
          - value1
          - value2
load_balancing:
  exporter:
    tls:
      insecure: true
  resolver:
    dns:
      hostname: agent
      port: 4318
service_graphs:
  enabled: true
`,
			expectedProcessors: map[string][]config.ComponentID{
				"traces/0": {
					config.NewComponentID("attributes"),
					config.NewComponentID("spanmetrics"),
				},
				"traces/1": {
					config.NewComponentID("service_graphs"),
					config.NewComponentID("tail_sampling"),
					config.NewComponentID("automatic_logging"),
					config.NewComponentID("batch"),
				},
				spanMetricsPipelineName: nil,
			},
		},
		{
			name: "load balancing without tail sampling",
			cfg: `
receivers:
  jaeger:
    protocols:
      grpc:
remote_write:
  - endpoint: example.com:12345
    headers:
      x-some-header: Some value!
attributes:
  actions:
  - key: montgomery
    value: forever
    action: update
spanmetrics:
  latency_histogram_buckets: [2ms, 6ms, 10ms, 100ms, 250ms]
  dimensions:
    - name: http.method
      default: GET
    - name: http.status_code
  metrics_instance: traces
automatic_logging:
  spans: true
batch:
  timeout: 5s
  send_batch_size: 100
load_balancing:
  exporter:
    tls:
      insecure: true
  resolver:
    dns:
      hostname: agent
      port: 4318
`,
			expectedProcessors: map[string][]config.ComponentID{
				"traces/0": {
					config.NewComponentID("attributes"),
					config.NewComponentID("spanmetrics"),
				},
				"traces/1": {
					config.NewComponentID("automatic_logging"),
					config.NewComponentID("batch"),
				},
				spanMetricsPipelineName: nil,
			},
		},
	}

	for _, tc := range tt {
		t.Run(tc.name, func(t *testing.T) {
			var cfg InstanceConfig
			err := yaml.Unmarshal([]byte(tc.cfg), &cfg)
			require.NoError(t, err)

			// check error
			actualConfig, err := cfg.otelConfig()
			require.NoError(t, err)

			require.Equal(t, len(tc.expectedProcessors), len(actualConfig.Pipelines))
			for k := range tc.expectedProcessors {
				if len(tc.expectedProcessors[k]) > 0 {
					componentID, err := config.NewComponentIDFromString(k)
					require.NoError(t, err)

					assert.Equal(t, tc.expectedProcessors[k], actualConfig.Pipelines[componentID].Processors)
				}
			}
		})
	}
}

func TestOrderProcessors(t *testing.T) {
	tests := []struct {
		processors     []string
		splitPipelines bool
		expected       [][]string
	}{
		{
			expected: [][]string{
				nil,
			},
		},
		{
			processors: []string{
				"tail_sampling",
			},
			expected: [][]string{
				{"tail_sampling"},
			},
		},
		{
			processors: []string{
				"batch",
				"tail_sampling",
				"automatic_logging",
			},
			expected: [][]string{
				{
					"tail_sampling",
					"automatic_logging",
					"batch",
				},
			},
		},
		{
			processors: []string{
				"spanmetrics",
				"batch",
				"tail_sampling",
				"attributes",
				"automatic_logging",
			},
			expected: [][]string{
				{
					"attributes",
					"spanmetrics",
					"tail_sampling",
					"automatic_logging",
					"batch",
				},
			},
		},
		{
			splitPipelines: true,
			expected: [][]string{
				nil,
				nil,
			},
		},
		{
			processors: []string{
				"spanmetrics",
				"batch",
				"tail_sampling",
				"attributes",
				"automatic_logging",
			},
			splitPipelines: true,
			expected: [][]string{
				{
					"attributes",
					"spanmetrics",
				},
				{
					"tail_sampling",
					"automatic_logging",
					"batch",
				},
			},
		},
		{
			processors: []string{
				"batch",
				"tail_sampling",
				"automatic_logging",
			},
			splitPipelines: true,
			expected: [][]string{
				{},
				{
					"tail_sampling",
					"automatic_logging",
					"batch",
				},
			},
		},
		{
			processors: []string{
				"spanmetrics",
				"attributes",
			},
			splitPipelines: true,
			expected: [][]string{
				{
					"attributes",
					"spanmetrics",
				},
				{},
			},
		},
	}

	for _, tc := range tests {
		actual := orderProcessors(tc.processors, tc.splitPipelines)
		assert.Equal(t, tc.expected, actual)
	}
}

func TestScrubbedReceivers(t *testing.T) {
	test := `
receivers:
  jaeger:
    protocols:
      grpc:`
	var cfg InstanceConfig
	err := yaml.Unmarshal([]byte(test), &cfg)
	assert.Nil(t, err)
	data, err := yaml.Marshal(cfg)
	assert.Nil(t, err)
	assert.True(t, strings.Contains(string(data), "<secret>"))
}

func TestCreatingPushReceiver(t *testing.T) {
	test := `
receivers:
  jaeger:
    protocols:
      grpc:`
	cfg := InstanceConfig{}
	err := yaml.Unmarshal([]byte(test), &cfg)
	assert.Nil(t, err)
	otel, err := cfg.otelConfig()
	assert.Nil(t, err)
	assert.Contains(t, otel.Service.Pipelines[config.NewComponentID("traces")].Receivers, config.NewComponentID(pushreceiver.TypeStr))
}

// sortService is a helper function to lexicographically sort all
// the possibly unsorted elements of a given cfg.Service
func sortService(cfg *config.Config) {
	sort.Slice(cfg.Service.Extensions, func(i, j int) bool { return cfg.Service.Extensions[i].String() > cfg.Service.Extensions[j].String() })

	for _, pipeline := range cfg.Pipelines {
		sort.Slice(pipeline.Exporters, func(i, j int) bool { return pipeline.Exporters[i].String() > pipeline.Exporters[j].String() })
		sort.Slice(pipeline.Receivers, func(i, j int) bool { return pipeline.Receivers[i].String() > pipeline.Receivers[j].String() })
		sort.Slice(pipeline.Processors, func(i, j int) bool { return pipeline.Processors[i].String() > pipeline.Processors[j].String() })
	}
}

'''
'''--- pkg/traces/contextkeys/keys.go ---
package contextkeys

type key int

const (
	// Logs is used to pass *logs.Logs through the context
	Logs key = iota

	// Metrics is used to pass instance.Manager through the context
	Metrics

	// PrometheusRegisterer is used to pass prometheus.Registerer through the context
	PrometheusRegisterer
)

'''
'''--- pkg/traces/instance.go ---
package traces

import (
	"context"
	"fmt"
	"sync"
	"time"

	"github.com/prometheus/client_golang/prometheus"
	"go.opencensus.io/stats/view"
	"go.opentelemetry.io/collector/component"
	"go.opentelemetry.io/collector/config"
	"go.opentelemetry.io/collector/service/external/extensions"
	"go.opentelemetry.io/collector/service/external/pipelines"
	"go.opentelemetry.io/otel/metric/nonrecording"
	"go.opentelemetry.io/otel/trace"
	"go.uber.org/zap"

	"github.com/grafana/agent/pkg/build"
	"github.com/grafana/agent/pkg/logs"
	"github.com/grafana/agent/pkg/metrics/instance"
	"github.com/grafana/agent/pkg/traces/automaticloggingprocessor"
	"github.com/grafana/agent/pkg/traces/contextkeys"
	"github.com/grafana/agent/pkg/util"
)

// Instance wraps the OpenTelemetry collector to enable tracing pipelines
type Instance struct {
	mut         sync.Mutex
	cfg         InstanceConfig
	logger      *zap.Logger
	metricViews []*view.View

	extensions *extensions.Extensions
	pipelines  *pipelines.Pipelines
	factories  component.Factories
}

var _ component.Host = (*Instance)(nil)

// NewInstance creates and starts an instance of tracing pipelines.
func NewInstance(logsSubsystem *logs.Logs, reg prometheus.Registerer, cfg InstanceConfig, logger *zap.Logger, promInstanceManager instance.Manager) (*Instance, error) {
	var err error

	instance := &Instance{}
	instance.logger = logger
	instance.metricViews, err = newMetricViews(reg)
	if err != nil {
		return nil, fmt.Errorf("failed to create metric views: %w", err)
	}

	if err := instance.ApplyConfig(logsSubsystem, promInstanceManager, reg, cfg); err != nil {
		return nil, err
	}
	return instance, nil
}

// ApplyConfig updates the configuration of the Instance.
func (i *Instance) ApplyConfig(logsSubsystem *logs.Logs, promInstanceManager instance.Manager, reg prometheus.Registerer, cfg InstanceConfig) error {
	i.mut.Lock()
	defer i.mut.Unlock()

	if util.CompareYAML(cfg, i.cfg) {
		// No config change
		return nil
	}
	i.cfg = cfg

	// Shut down any existing pipeline
	i.stop()

	err := i.buildAndStartPipeline(context.Background(), cfg, logsSubsystem, promInstanceManager, reg)
	if err != nil {
		return fmt.Errorf("failed to create pipeline: %w", err)
	}

	return nil
}

// Stop stops the OpenTelemetry collector subsystem
func (i *Instance) Stop() {
	i.mut.Lock()
	defer i.mut.Unlock()

	i.stop()
	view.Unregister(i.metricViews...)
}

func (i *Instance) stop() {
	shutdownCtx, cancel := context.WithTimeout(context.Background(), 30*time.Second)
	defer cancel()

	if i.extensions != nil {
		err := i.extensions.NotifyPipelineNotReady()
		if err != nil {
			i.logger.Error("failed to notify extension of pipeline shutdown", zap.Error(err))
		}
	}

	dependencies := []struct {
		name     string
		shutdown func() error
	}{
		{
			name: "pipelines",
			shutdown: func() error {
				if i.pipelines == nil {
					return nil
				}
				return i.pipelines.ShutdownAll(shutdownCtx)
			},
		},
		{
			name: "extensions",
			shutdown: func() error {
				if i.extensions == nil {
					return nil
				}
				return i.extensions.ShutdownAll(shutdownCtx)
			},
		},
	}

	for _, dep := range dependencies {
		i.logger.Info(fmt.Sprintf("shutting down %s", dep.name))
		if err := dep.shutdown(); err != nil {
			i.logger.Error(fmt.Sprintf("failed to shutdown %s", dep.name), zap.Error(err))
		}
	}

	i.pipelines = nil
	i.extensions = nil
}

func (i *Instance) buildAndStartPipeline(ctx context.Context, cfg InstanceConfig, logs *logs.Logs, instManager instance.Manager, reg prometheus.Registerer) error {
	// create component factories
	otelConfig, err := cfg.otelConfig()
	if err != nil {
		return fmt.Errorf("failed to load otelConfig from agent traces config: %w", err)
	}
	for _, rw := range cfg.RemoteWrite {
		if rw.InsecureSkipVerify {
			i.logger.Warn("Configuring TLS with insecure_skip_verify. Use tls_config.insecure_skip_verify instead")
		}
		if rw.TLSConfig != nil && rw.TLSConfig.ServerName != "" {
			i.logger.Warn("Configuring unsupported tls_config.server_name")
		}
	}

	if cfg.SpanMetrics != nil && len(cfg.SpanMetrics.MetricsInstance) != 0 {
		ctx = context.WithValue(ctx, contextkeys.Metrics, instManager)
	}

	if cfg.LoadBalancing == nil && (cfg.TailSampling != nil || cfg.ServiceGraphs != nil) {
		i.logger.Warn("Configuring tail_sampling and/or service_graphs without load_balance." +
			"Load balancing is required for those features to properly work in multi agent deployments")
	}

	if cfg.AutomaticLogging != nil && cfg.AutomaticLogging.Backend != automaticloggingprocessor.BackendStdout {
		ctx = context.WithValue(ctx, contextkeys.Logs, logs)
	}

	if cfg.ServiceGraphs != nil {
		ctx = context.WithValue(ctx, contextkeys.PrometheusRegisterer, reg)
	}

	factories, err := tracingFactories()
	if err != nil {
		return fmt.Errorf("failed to load tracing factories: %w", err)
	}
	i.factories = factories

	appinfo := component.BuildInfo{
		Command:     "agent",
		Description: "agent",
		Version:     build.Version,
	}

	settings := component.TelemetrySettings{
		Logger:         i.logger,
		TracerProvider: trace.NewNoopTracerProvider(),
		MeterProvider:  nonrecording.NewNoopMeterProvider(),
	}

	// start extensions
	i.extensions, err = extensions.Build(ctx, extensions.Settings{
		Telemetry: settings,
		BuildInfo: appinfo,

		Factories:         factories.Extensions,
		Configs:           otelConfig.Extensions,
		ServiceExtensions: otelConfig.Service.Extensions,
	})
	if err != nil {
		i.logger.Error(fmt.Sprintf("failed to build extensions: %s", err.Error()))
		return fmt.Errorf("failed to create extensions builder: %w", err)
	}
	err = i.extensions.StartAll(ctx, i)
	if err != nil {
		i.logger.Error(fmt.Sprintf("failed to start extensions: %s", err.Error()))
		return fmt.Errorf("failed to start extensions: %w", err)
	}

	i.pipelines, err = pipelines.Build(ctx, pipelines.Settings{
		Telemetry: settings,
		BuildInfo: appinfo,

		ReceiverFactories:  factories.Receivers,
		ReceiverConfigs:    otelConfig.Receivers,
		ProcessorFactories: factories.Processors,
		ProcessorConfigs:   otelConfig.Processors,
		ExporterFactories:  factories.Exporters,
		ExporterConfigs:    otelConfig.Exporters,

		PipelineConfigs: otelConfig.Pipelines,
	})
	if err != nil {
		return fmt.Errorf("failed to create pipelines: %w", err)
	}
	if err := i.pipelines.StartAll(ctx, i); err != nil {
		i.logger.Error(fmt.Sprintf("failed to start pipelines: %s", err.Error()))
		return fmt.Errorf("failed to start pipelines: %w", err)
	}

	return i.extensions.NotifyPipelineReady()
}

// ReportFatalError implements component.Host
func (i *Instance) ReportFatalError(err error) {
	i.logger.Error("fatal error reported", zap.Error(err))
}

// GetFactory implements component.Host
func (i *Instance) GetFactory(kind component.Kind, componentType config.Type) component.Factory {
	switch kind {
	case component.KindReceiver:
		return i.factories.Receivers[componentType]
	default:
		return nil
	}
}

// GetExtensions implements component.Host
func (i *Instance) GetExtensions() map[config.ComponentID]component.Extension {
	return i.extensions.GetExtensions()
}

// GetExporters implements component.Host
func (i *Instance) GetExporters() map[config.DataType]map[config.ComponentID]component.Exporter {
	// SpanMetricsProcessor needs to get the configured exporters.
	return i.pipelines.GetExporters()
}

'''
'''--- pkg/traces/internal/traceutils/server.go ---
package traceutils

import (
	"context"
	"fmt"
	"math/rand"
	"strings"
	"testing"
	"time"

	"github.com/grafana/agent/pkg/util"
	"github.com/open-telemetry/opentelemetry-collector-contrib/processor/spanmetricsprocessor/mocks"
	"github.com/stretchr/testify/assert"
	"go.opentelemetry.io/collector/component"
	"go.opentelemetry.io/collector/config"
	"go.opentelemetry.io/collector/confmap"
	"go.opentelemetry.io/collector/consumer"
	"go.opentelemetry.io/collector/pdata/ptrace"
	"go.opentelemetry.io/collector/receiver/otlpreceiver"
	"go.opentelemetry.io/collector/service/external/configunmarshaler"
	"go.opentelemetry.io/collector/service/external/pipelines"
	"go.opentelemetry.io/otel/metric/nonrecording"
	"go.opentelemetry.io/otel/trace"
	"go.uber.org/zap"
	"gopkg.in/yaml.v3"
)

// Server is a Tracing testing server that invokes a function every time a span
// is received.
type Server struct {
	pipelines *pipelines.Pipelines
}

// NewTestServer creates a new Server for testing, where received traces will
// call the callback function. The returned string is the address where traces
// can be sent using OTLP.
func NewTestServer(t *testing.T, callback func(ptrace.Traces)) string {
	t.Helper()

	srv, listenAddr, err := NewServerWithRandomPort(callback)
	if err != nil {
		t.Fatalf("failed to create OTLP server: %s", err)
	}
	t.Cleanup(func() {
		err := srv.Stop()
		assert.NoError(t, err)
	})

	return listenAddr
}

// NewServerWithRandomPort calls NewServer with a random port >49152 and
// <65535. It will try up to five times before failing.
func NewServerWithRandomPort(callback func(ptrace.Traces)) (srv *Server, addr string, err error) {
	var lastError error

	for i := 0; i < 5; i++ {
		port := rand.Intn(65535-49152) + 49152
		listenAddr := fmt.Sprintf("127.0.0.1:%d", port)

		srv, err = NewServer(listenAddr, callback)
		if err != nil {
			lastError = err
			continue
		}

		return srv, listenAddr, nil
	}

	return nil, "", fmt.Errorf("failed 5 times to create a server. last error: %w", lastError)
}

// NewServer creates an OTLP-accepting server that calls a function when a
// trace is received. This is primarily useful for testing.
func NewServer(addr string, callback func(ptrace.Traces)) (*Server, error) {
	conf := util.Untab(fmt.Sprintf(`
processors:
	func_processor:
receivers:
  otlp:
		protocols:
			grpc:
				endpoint: %s
exporters:
  noop:
service:
	pipelines:
		traces:
			receivers: [otlp]
			processors: [func_processor]
			exporters: [noop]
	`, addr))

	var cfg map[string]interface{}
	if err := yaml.NewDecoder(strings.NewReader(conf)).Decode(&cfg); err != nil {
		panic("could not decode config: " + err.Error())
	}

	extensionsFactory, err := component.MakeExtensionFactoryMap()
	if err != nil {
		return nil, fmt.Errorf("failed to make extension factory map: %w", err)
	}

	receiversFactory, err := component.MakeReceiverFactoryMap(otlpreceiver.NewFactory())
	if err != nil {
		return nil, fmt.Errorf("failed to make receiver factory map: %w", err)
	}

	exportersFactory, err := component.MakeExporterFactoryMap(newNoopExporterFactory())
	if err != nil {
		return nil, fmt.Errorf("failed to make exporter factory map: %w", err)
	}

	processorsFactory, err := component.MakeProcessorFactoryMap(
		newFuncProcessorFactory(callback),
	)
	if err != nil {
		return nil, fmt.Errorf("failed to make processor factory map: %w", err)
	}

	factories := component.Factories{
		Extensions: extensionsFactory,
		Receivers:  receiversFactory,
		Processors: processorsFactory,
		Exporters:  exportersFactory,
	}

	configMap := confmap.NewFromStringMap(cfg)
	cfgUnmarshaler := configunmarshaler.New()
	otelCfg, err := cfgUnmarshaler.Unmarshal(configMap, factories)
	if err != nil {
		return nil, fmt.Errorf("failed to make otel config: %w", err)
	}

	var (
		logger    = zap.NewNop()
		startInfo component.BuildInfo
	)

	settings := component.TelemetrySettings{
		Logger:         logger,
		TracerProvider: trace.NewNoopTracerProvider(),
		MeterProvider:  nonrecording.NewNoopMeterProvider(),
	}

	pipelines, err := pipelines.Build(context.Background(), pipelines.Settings{
		Telemetry: settings,
		BuildInfo: startInfo,

		ReceiverFactories:  factories.Receivers,
		ReceiverConfigs:    otelCfg.Receivers,
		ProcessorFactories: factories.Processors,
		ProcessorConfigs:   otelCfg.Processors,
		ExporterFactories:  factories.Exporters,
		ExporterConfigs:    otelCfg.Exporters,

		PipelineConfigs: otelCfg.Pipelines,
	})
	if err != nil {
		return nil, fmt.Errorf("failed to build pipelines: %w", err)
	}

	h := &mocks.Host{}
	h.On("GetExtensions").Return(nil)
	if err := pipelines.StartAll(context.Background(), h); err != nil {
		return nil, fmt.Errorf("failed to start receivers: %w", err)
	}

	return &Server{
		pipelines: pipelines,
	}, nil
}

// Stop stops the testing server.
func (s *Server) Stop() error {
	shutdownCtx, cancel := context.WithTimeout(context.Background(), 30*time.Second)
	defer cancel()

	return s.pipelines.ShutdownAll(shutdownCtx)
}

func newFuncProcessorFactory(callback func(ptrace.Traces)) component.ProcessorFactory {
	return component.NewProcessorFactory(
		"func_processor",
		func() config.Processor {
			processorSettings := config.NewProcessorSettings(config.NewComponentIDWithName("func_processor", "func_processor"))
			return &processorSettings
		},
		component.WithTracesProcessor(func(
			_ context.Context,
			_ component.ProcessorCreateSettings,
			_ config.Processor,
			next consumer.Traces,
		) (component.TracesProcessor, error) {

			return &funcProcessor{
				Callback: callback,
				Next:     next,
			}, nil
		}),
	)
}

type funcProcessor struct {
	Callback func(ptrace.Traces)
	Next     consumer.Traces
}

func (p *funcProcessor) ConsumeTraces(ctx context.Context, td ptrace.Traces) error {
	if p.Callback != nil {
		p.Callback(td)
	}
	return p.Next.ConsumeTraces(ctx, td)
}

func (p *funcProcessor) Capabilities() consumer.Capabilities {
	return consumer.Capabilities{MutatesData: true}
}

func (p *funcProcessor) Start(context.Context, component.Host) error { return nil }
func (p *funcProcessor) Shutdown(context.Context) error              { return nil }

func newNoopExporterFactory() component.ExporterFactory {
	return component.NewExporterFactory(
		"noop",
		func() config.Exporter {
			exporterSettings := config.NewExporterSettings(config.NewComponentIDWithName("noop", "noop"))
			return &exporterSettings
		},
		component.WithTracesExporter(func(
			context.Context,
			component.ExporterCreateSettings,
			config.Exporter) (
			component.TracesExporter,
			error) {

			return &noopExporter{}, nil
		}),
	)
}

type noopExporter struct{}

func (n noopExporter) Start(context.Context, component.Host) error { return nil }

func (n noopExporter) Shutdown(context.Context) error { return nil }

func (n noopExporter) Capabilities() consumer.Capabilities { return consumer.Capabilities{} }

func (n noopExporter) ConsumeTraces(context.Context, ptrace.Traces) error { return nil }

'''
'''--- pkg/traces/noopreceiver/factory.go ---
package noopreceiver

import (
	"context"

	"go.opentelemetry.io/collector/component"
	"go.opentelemetry.io/collector/config"
	"go.opentelemetry.io/collector/consumer"
)

const (
	// TypeStr for noop receiver.
	TypeStr = "noop"
)

// NewFactory creates noop receiver factory.
func NewFactory() component.ReceiverFactory {
	return component.NewReceiverFactory(
		TypeStr,
		createDefaultConfig,
		component.WithMetricsReceiver(createMetricsReceiver),
	)
}

// Config defines configuration for noop receiver.
type Config struct {
	config.Receiver `mapstructure:",squash"` // squash ensures fields are correctly decoded in embedded struct.
}

func createDefaultConfig() config.Receiver {
	s := config.NewReceiverSettings(config.NewComponentIDWithName(TypeStr, TypeStr))
	return &s
}

// noop receiver is used in the metrics pipeline so we need to
// implement a metrics receiver.
func createMetricsReceiver(
	_ context.Context,
	_ component.ReceiverCreateSettings,
	_ config.Receiver,
	_ consumer.Metrics,
) (component.MetricsReceiver, error) {

	return newNoopReceiver(nil, nil, nil), nil
}

'''
'''--- pkg/traces/noopreceiver/receiver.go ---
package noopreceiver

import (
	"context"

	"go.opentelemetry.io/collector/component"
	"go.opentelemetry.io/collector/consumer"
	"go.uber.org/zap"
)

type noopReceiver struct{}

// New creates a dummy receiver.
func newNoopReceiver(_ *zap.Logger, _ *Config, _ consumer.Metrics) *noopReceiver {
	return &noopReceiver{}
}

// Start implements the Component interface.
func (r *noopReceiver) Start(_ context.Context, _ component.Host) error {
	return nil
}

// Shutdown implements the Component interface.
func (r *noopReceiver) Shutdown(context.Context) error {
	return nil
}

'''
'''--- pkg/traces/promsdprocessor/factory.go ---
package promsdprocessor

import (
	"context"
	"fmt"

	prom_config "github.com/prometheus/prometheus/config"
	"go.opentelemetry.io/collector/component"
	"go.opentelemetry.io/collector/config"
	"go.opentelemetry.io/collector/consumer"
	"gopkg.in/yaml.v2"
)

// TypeStr is the unique identifier for the Prometheus SD processor.
const TypeStr = "prom_sd_processor"

const (
	// OperationTypeInsert inserts a new k/v if it isn't already present
	OperationTypeInsert = "insert"
	// OperationTypeUpdate only modifies an existing k/v
	OperationTypeUpdate = "update"
	// OperationTypeUpsert does both of above
	OperationTypeUpsert = "upsert"

	podAssociationIPLabel       = "ip"
	podAssociationOTelIPLabel   = "net.host.ip"
	podAssociationk8sIPLabel    = "k8s.pod.ip"
	podAssociationHostnameLabel = "hostname"
	podAssociationConnectionIP  = "connection"
)

// Config holds the configuration for the Prometheus SD processor.
type Config struct {
	config.ProcessorSettings `mapstructure:",squash"`
	ScrapeConfigs            []interface{} `mapstructure:"scrape_configs"`
	OperationType            string        `mapstructure:"operation_type"`
	PodAssociations          []string      `mapstructure:"pod_associations"`
}

// NewFactory returns a new factory for the Attributes processor.
func NewFactory() component.ProcessorFactory {
	return component.NewProcessorFactory(
		TypeStr,
		createDefaultConfig,
		component.WithTracesProcessor(createTraceProcessor),
	)
}

func createDefaultConfig() config.Processor {
	return &Config{
		ProcessorSettings: config.NewProcessorSettings(config.NewComponentIDWithName(TypeStr, TypeStr)),
	}
}

func createTraceProcessor(
	_ context.Context,
	cp component.ProcessorCreateSettings,
	cfg config.Processor,
	nextConsumer consumer.Traces,
) (component.TracesProcessor, error) {

	oCfg := cfg.(*Config)
	out, err := yaml.Marshal(oCfg.ScrapeConfigs)
	if err != nil {
		return nil, fmt.Errorf("unable to marshal scrapeConfigs interface{} to yaml: %w", err)
	}

	scrapeConfigs := make([]*prom_config.ScrapeConfig, 0)
	err = yaml.Unmarshal(out, &scrapeConfigs)
	if err != nil {
		return nil, fmt.Errorf("unable to unmarshal bytes to []*config.ScrapeConfig: %w", err)
	}

	return newTraceProcessor(nextConsumer, oCfg.OperationType, oCfg.PodAssociations, scrapeConfigs)
}

'''
'''--- pkg/traces/promsdprocessor/prom_sd_processor.go ---
package promsdprocessor

import (
	"context"
	"fmt"
	"net"
	"strings"
	"sync"

	util "github.com/cortexproject/cortex/pkg/util/log"
	"github.com/go-kit/log"
	"github.com/go-kit/log/level"
	"github.com/prometheus/common/model"
	"github.com/prometheus/prometheus/config"
	"github.com/prometheus/prometheus/discovery"
	"github.com/prometheus/prometheus/discovery/targetgroup"
	"github.com/prometheus/prometheus/model/labels"
	"github.com/prometheus/prometheus/model/relabel"
	"go.opentelemetry.io/collector/client"
	"go.opentelemetry.io/collector/component"
	"go.opentelemetry.io/collector/consumer"
	"go.opentelemetry.io/collector/pdata/pcommon"
	"go.opentelemetry.io/collector/pdata/ptrace"
	semconv "go.opentelemetry.io/collector/semconv/v1.6.1"
)

type promServiceDiscoProcessor struct {
	nextConsumer     consumer.Traces
	discoveryMgr     *discovery.Manager
	discoveryMgrStop context.CancelFunc
	discoveryMgrCtx  context.Context

	relabelConfigs map[string][]*relabel.Config
	hostLabels     map[string]model.LabelSet
	mtx            sync.Mutex

	operationType   string
	podAssociations []string

	logger log.Logger
}

func newTraceProcessor(nextConsumer consumer.Traces, operationType string, podAssociations []string, scrapeConfigs []*config.ScrapeConfig) (component.TracesProcessor, error) {
	ctx, cancel := context.WithCancel(context.Background())

	logger := log.With(util.Logger, "component", "traces service disco")
	mgr := discovery.NewManager(ctx, logger, discovery.Name("traces service disco"))

	relabelConfigs := map[string][]*relabel.Config{}
	managerConfig := map[string]discovery.Configs{}
	for _, v := range scrapeConfigs {
		managerConfig[v.JobName] = v.ServiceDiscoveryConfigs
		relabelConfigs[v.JobName] = v.RelabelConfigs
	}

	err := mgr.ApplyConfig(managerConfig)
	if err != nil {
		cancel()
		return nil, err
	}

	switch operationType {
	case OperationTypeUpsert, OperationTypeInsert, OperationTypeUpdate:
	case "": // Use Upsert by default
		operationType = OperationTypeUpsert
	default:
		cancel()
		return nil, fmt.Errorf("unknown operation type %s", operationType)
	}

	for _, podAssociation := range podAssociations {
		switch podAssociation {
		case podAssociationIPLabel, podAssociationOTelIPLabel, podAssociationk8sIPLabel, podAssociationHostnameLabel, podAssociationConnectionIP:
		default:
			cancel()
			return nil, fmt.Errorf("unknown pod association %s", podAssociation)
		}
	}

	if len(podAssociations) == 0 {
		podAssociations = []string{podAssociationIPLabel, podAssociationOTelIPLabel, podAssociationk8sIPLabel, podAssociationHostnameLabel, podAssociationConnectionIP}
	}

	if nextConsumer == nil {
		cancel()
		return nil, component.ErrNilNextConsumer
	}
	return &promServiceDiscoProcessor{
		nextConsumer:     nextConsumer,
		discoveryMgr:     mgr,
		discoveryMgrStop: cancel,
		discoveryMgrCtx:  ctx,
		relabelConfigs:   relabelConfigs,
		hostLabels:       make(map[string]model.LabelSet),
		logger:           logger,
		operationType:    operationType,
		podAssociations:  podAssociations,
	}, nil
}

func (p *promServiceDiscoProcessor) ConsumeTraces(ctx context.Context, td ptrace.Traces) error {
	rss := td.ResourceSpans()
	for i := 0; i < rss.Len(); i++ {
		rs := rss.At(i)

		p.processAttributes(ctx, rs.Resource().Attributes())
	}

	return p.nextConsumer.ConsumeTraces(ctx, td)
}

func stringAttributeFromMap(attrs pcommon.Map, key string) string {
	if attr, ok := attrs.Get(key); ok {
		if attr.Type() == pcommon.ValueTypeString {
			return attr.StringVal()
		}
	}
	return ""
}

func (p *promServiceDiscoProcessor) getConnectionIP(ctx context.Context) string {
	c := client.FromContext(ctx)
	if c.Addr == nil {
		return ""
	}

	host := c.Addr.String()
	if strings.Contains(host, ":") {
		var err error
		splitHost, _, err := net.SplitHostPort(host)
		if err != nil {
			// It's normal for this to fail for IPv6 address strings that don't actually include a port.
			level.Debug(p.logger).Log("msg", "unable to split connection host and port", "host", host, "err", err)
		} else {
			host = splitHost
		}
	}

	return host
}

func (p *promServiceDiscoProcessor) getPodIP(ctx context.Context, attrs pcommon.Map) string {
	for _, podAssociation := range p.podAssociations {
		switch podAssociation {
		case podAssociationIPLabel, podAssociationOTelIPLabel, podAssociationk8sIPLabel:
			ip := stringAttributeFromMap(attrs, podAssociation)
			if ip != "" {
				return ip
			}
		case podAssociationHostnameLabel:
			hostname := stringAttributeFromMap(attrs, semconv.AttributeHostName)
			if net.ParseIP(hostname) != nil {
				return hostname
			}
		case podAssociationConnectionIP:
			ip := p.getConnectionIP(ctx)
			if ip != "" {
				return ip
			}
		}
	}
	return ""
}

func (p *promServiceDiscoProcessor) processAttributes(ctx context.Context, attrs pcommon.Map) {
	ip := p.getPodIP(ctx, attrs)
	// have to have an ip for labels lookup
	if ip == "" {
		level.Debug(p.logger).Log("msg", "unable to find ip in span attributes, skipping attribute addition")
		return
	}

	p.mtx.Lock()
	defer p.mtx.Unlock()

	labels, ok := p.hostLabels[ip]
	if !ok {
		level.Debug(p.logger).Log("msg", "unable to find matching hostLabels", "ip", ip)
		return
	}

	for k, v := range labels {
		switch p.operationType {
		case OperationTypeUpsert:
			attrs.UpsertString(string(k), string(v))
		case OperationTypeInsert:
			attrs.InsertString(string(k), string(v))
		case OperationTypeUpdate:
			attrs.UpdateString(string(k), string(v))
		}
	}
}

func (p *promServiceDiscoProcessor) Capabilities() consumer.Capabilities {
	return consumer.Capabilities{MutatesData: true}
}

// Start is invoked during service startup.
func (p *promServiceDiscoProcessor) Start(_ context.Context, _ component.Host) error {
	go p.watchServiceDiscovery()

	go func() {
		err := p.discoveryMgr.Run()
		if err != nil && err != context.Canceled {
			level.Error(p.logger).Log("msg", "failed to start prom svc disco.  relabeling disabled", "err", err)
		}
	}()

	return nil
}

// Shutdown is invoked during service shutdown.
func (p *promServiceDiscoProcessor) Shutdown(context.Context) error {
	if p.discoveryMgrStop != nil {
		p.discoveryMgrStop()
	}
	return nil
}

func (p *promServiceDiscoProcessor) watchServiceDiscovery() {
	for {
		// p.discoveryMgr.SyncCh() is never closed so we need to watch the context as well to properly exit this goroutine
		select {
		case targetGroups := <-p.discoveryMgr.SyncCh():
			hostLabels := make(map[string]model.LabelSet)
			level.Debug(p.logger).Log("msg", "syncing target groups", "count", len(targetGroups))
			for jobName, groups := range targetGroups {
				p.syncGroups(jobName, groups, hostLabels)
			}
			p.mtx.Lock()
			p.hostLabels = hostLabels
			p.mtx.Unlock()
		case <-p.discoveryMgrCtx.Done():
			return
		}
	}
}

func (p *promServiceDiscoProcessor) syncGroups(jobName string, groups []*targetgroup.Group, hostLabels map[string]model.LabelSet) {
	level.Debug(p.logger).Log("msg", "syncing target group", "jobName", jobName)
	for _, g := range groups {
		p.syncTargets(jobName, g, hostLabels)
	}
}

func (p *promServiceDiscoProcessor) syncTargets(jobName string, group *targetgroup.Group, hostLabels map[string]model.LabelSet) {
	level.Debug(p.logger).Log("msg", "syncing targets", "count", len(group.Targets))

	relabelConfig := p.relabelConfigs[jobName]
	if relabelConfig == nil {
		level.Warn(p.logger).Log("msg", "relabel config not found for job. skipping labeling", "jobName", jobName)
		return
	}

	for _, t := range group.Targets {
		discoveredLabels := group.Labels.Merge(t)

		level.Debug(p.logger).Log("discoveredLabels", discoveredLabels)
		var labelMap = make(map[string]string)
		for k, v := range discoveredLabels.Clone() {
			labelMap[string(k)] = string(v)
		}
		processedLabels := relabel.Process(labels.FromMap(labelMap), relabelConfig...)
		level.Debug(p.logger).Log("processedLabels", processedLabels)
		if processedLabels == nil { // dropped
			continue
		}

		var labels = make(model.LabelSet)
		for k, v := range processedLabels.Map() {
			labels[model.LabelName(k)] = model.LabelValue(v)
		}

		address, ok := labels[model.AddressLabel]
		if !ok {
			level.Warn(p.logger).Log("msg", "ignoring target, unable to find address", "labels", labels.String())
			continue
		}

		host := string(address)
		if strings.Contains(host, ":") {
			var err error
			host, _, err = net.SplitHostPort(host)
			if err != nil {
				level.Warn(p.logger).Log("msg", "unable to split host port", "address", address, "err", err)
				continue
			}
		}

		for k := range labels {
			if strings.HasPrefix(string(k), "__") {
				delete(labels, k)
			}
		}

		level.Debug(p.logger).Log("msg", "adding host to hostLabels", "host", host)
		hostLabels[host] = labels
	}
}

'''
'''--- pkg/traces/promsdprocessor/prom_sd_processor_test.go ---
package promsdprocessor

import (
	"context"
	"net"
	"testing"

	"github.com/go-kit/log"
	"github.com/prometheus/common/model"
	"github.com/prometheus/prometheus/discovery/targetgroup"
	"github.com/prometheus/prometheus/model/relabel"
	"github.com/stretchr/testify/assert"
	"github.com/stretchr/testify/require"
	"go.opentelemetry.io/collector/client"
	"go.opentelemetry.io/collector/consumer/consumertest"
	"go.opentelemetry.io/collector/pdata/pcommon"
	semconv "go.opentelemetry.io/collector/semconv/v1.6.1"
)

func TestSyncGroups(t *testing.T) {
	tests := []struct {
		name        string
		jobToSync   string
		relabelCfgs map[string][]*relabel.Config
		targets     []model.LabelSet
		expected    map[string]model.LabelSet
	}{
		{
			name:        "empty",
			jobToSync:   "",
			relabelCfgs: map[string][]*relabel.Config{},
			targets:     []model.LabelSet{},
			expected:    map[string]model.LabelSet{},
		},
		{
			name:      "no relabeling",
			jobToSync: "job",
			relabelCfgs: map[string][]*relabel.Config{
				"job": {},
			},
			targets: []model.LabelSet{
				{
					"__address__": "127.0.0.1",
				},
			},
			expected: map[string]model.LabelSet{
				"127.0.0.1": {},
			},
		},
		{
			name:      "strip port",
			jobToSync: "job",
			relabelCfgs: map[string][]*relabel.Config{
				"job": {},
			},
			targets: []model.LabelSet{
				{
					"__address__": "127.0.0.1:8888",
					"label":       "val",
				},
			},
			expected: map[string]model.LabelSet{
				"127.0.0.1": {
					"label": "val",
				},
			},
		},
		{
			name:      "passthrough",
			jobToSync: "job",
			relabelCfgs: map[string][]*relabel.Config{
				"job": {},
			},
			targets: []model.LabelSet{
				{
					"__address__": "127.0.0.1",
					"label":       "val",
				},
			},
			expected: map[string]model.LabelSet{
				"127.0.0.1": {
					"label": "val",
				},
			},
		},
		{
			name:      "ignore metadata",
			jobToSync: "job",
			relabelCfgs: map[string][]*relabel.Config{
				"job": {},
			},
			targets: []model.LabelSet{
				{
					"__address__": "127.0.0.1",
					"__ignore":    "ignore",
				},
			},
			expected: map[string]model.LabelSet{
				"127.0.0.1": {},
			},
		},
	}

	for _, tc := range tests {
		t.Run(tc.name, func(t *testing.T) {
			groups := []*targetgroup.Group{
				{
					Targets: tc.targets,
				},
			}

			p := &promServiceDiscoProcessor{
				logger:         log.NewNopLogger(),
				relabelConfigs: tc.relabelCfgs,
			}

			hostLabels := make(map[string]model.LabelSet)
			p.syncGroups(tc.jobToSync, groups, hostLabels)

			assert.Equal(t, tc.expected, hostLabels)
		})
	}
}

func TestOperationType(t *testing.T) {
	const (
		attrKey = "key"
		attrIP  = "1.1.1.1"
	)
	testCases := []struct {
		name            string
		operationType   string
		attributeExists bool
		newValue        string
		expectedValue   string
	}{
		{
			name:            "Upsert updates the attribute already exists",
			operationType:   OperationTypeUpsert,
			attributeExists: true,
			newValue:        "new-value",
			expectedValue:   "new-value",
		},
		{
			name:            "Update updates the attribute already exists",
			operationType:   OperationTypeUpdate,
			attributeExists: true,
			newValue:        "new-value",
			expectedValue:   "new-value",
		},
		{
			name:            "Insert does not update the attribute if it's already present",
			operationType:   OperationTypeInsert,
			attributeExists: true,
			newValue:        "new-value",
			expectedValue:   "old-value",
		},
		{
			name:            "Upsert updates the attribute if it isn't present",
			operationType:   OperationTypeUpsert,
			attributeExists: false,
			newValue:        "new-value",
			expectedValue:   "new-value",
		},
		{
			name:            "Update updates the attribute already exists",
			operationType:   OperationTypeUpdate,
			attributeExists: false,
			newValue:        "new-value",
			expectedValue:   "",
		},
		{
			name:            "Insert updates the attribute if it isn't present",
			operationType:   OperationTypeInsert,
			attributeExists: false,
			newValue:        "new-value",
			expectedValue:   "new-value",
		},
	}

	for _, tc := range testCases {
		t.Run(tc.name, func(t *testing.T) {
			mockProcessor := new(consumertest.TracesSink)
			p, err := newTraceProcessor(mockProcessor, tc.operationType, nil, nil)
			require.NoError(t, err)

			attrValue := pcommon.NewValueString("old-value")
			ipAttrValue := pcommon.NewValueString(attrIP)

			attrMap := pcommon.NewMap()
			if tc.attributeExists {
				attrMap.Insert(attrKey, attrValue)
			}
			attrMap.Insert(semconv.AttributeNetHostIP, ipAttrValue)

			hostLabels := map[string]model.LabelSet{
				attrIP: {
					attrKey: model.LabelValue(tc.newValue),
				},
			}
			p.(*promServiceDiscoProcessor).hostLabels = hostLabels
			p.(*promServiceDiscoProcessor).processAttributes(context.TODO(), attrMap)

			actualAttrValue, _ := attrMap.Get(attrKey)
			assert.Equal(t, tc.expectedValue, actualAttrValue.StringVal())
		})
	}
}

func TestPodAssociation(t *testing.T) {
	const ipStr = "1.1.1.1"

	testCases := []struct {
		name            string
		podAssociations []string
		ctxFn           func(t *testing.T) context.Context
		attrMapFn       func(t *testing.T) pcommon.Map
		expectedIP      string
	}{
		{
			name: "connection IP (HTTP & gRPC)",
			ctxFn: func(t *testing.T) context.Context {
				info := client.Info{
					Addr: &net.IPAddr{
						IP: net.ParseIP(net.ParseIP(ipStr).String()),
					},
				}
				return client.NewContext(context.Background(), info)
			},
			attrMapFn:  func(*testing.T) pcommon.Map { return pcommon.NewMap() },
			expectedIP: ipStr,
		},
		{
			name: "connection IP that includes a port number",
			ctxFn: func(t *testing.T) context.Context {
				info := client.Info{
					Addr: &net.TCPAddr{
						IP:   net.ParseIP(net.ParseIP(ipStr).String()),
						Port: 1234,
					},
				}
				return client.NewContext(context.Background(), info)
			},
			attrMapFn:  func(*testing.T) pcommon.Map { return pcommon.NewMap() },
			expectedIP: ipStr,
		},
		{
			name:            "connection IP is empty",
			podAssociations: []string{podAssociationConnectionIP},
			ctxFn: func(t *testing.T) context.Context {
				c := client.FromContext(context.Background())
				return client.NewContext(context.Background(), c)
			},
			attrMapFn:  func(*testing.T) pcommon.Map { return pcommon.NewMap() },
			expectedIP: "",
		},
		{
			name:  "ip attribute",
			ctxFn: func(t *testing.T) context.Context { return context.Background() },
			attrMapFn: func(*testing.T) pcommon.Map {
				attrMap := pcommon.NewMap()
				attrMap.Insert("ip", pcommon.NewValueString(ipStr))
				return attrMap
			},
			expectedIP: ipStr,
		},
		{
			name:  "net.host.ip attribute",
			ctxFn: func(t *testing.T) context.Context { return context.Background() },
			attrMapFn: func(*testing.T) pcommon.Map {
				attrMap := pcommon.NewMap()
				attrMap.Insert(semconv.AttributeNetHostIP, pcommon.NewValueString(ipStr))
				return attrMap
			},
			expectedIP: ipStr,
		},
		{
			name:  "k8s ip attribute",
			ctxFn: func(t *testing.T) context.Context { return context.Background() },
			attrMapFn: func(*testing.T) pcommon.Map {
				attrMap := pcommon.NewMap()
				attrMap.Insert("k8s.pod.ip", pcommon.NewValueString(ipStr))
				return attrMap
			},
			expectedIP: ipStr,
		},
		{
			name:  "ip from hostname",
			ctxFn: func(t *testing.T) context.Context { return context.Background() },
			attrMapFn: func(*testing.T) pcommon.Map {
				attrMap := pcommon.NewMap()
				attrMap.Insert(semconv.AttributeHostName, pcommon.NewValueString(ipStr))
				return attrMap
			},
			expectedIP: ipStr,
		},
		{
			name: "uses attr before context (default associations)",
			ctxFn: func(t *testing.T) context.Context {
				info := client.Info{
					Addr: &net.IPAddr{
						IP: net.ParseIP("2.2.2.2"),
					},
				}
				return client.NewContext(context.Background(), info)
			},
			attrMapFn: func(*testing.T) pcommon.Map {
				attrMap := pcommon.NewMap()
				attrMap.Insert(semconv.AttributeNetHostIP, pcommon.NewValueString(ipStr))
				return attrMap
			},
			expectedIP: ipStr,
		},
		{
			name:  "uses attr before hostname (default associations)",
			ctxFn: func(t *testing.T) context.Context { return context.Background() },
			attrMapFn: func(*testing.T) pcommon.Map {
				attrMap := pcommon.NewMap()
				attrMap.Insert(semconv.AttributeNetHostIP, pcommon.NewValueString(ipStr))
				attrMap.Insert(semconv.AttributeHostName, pcommon.NewValueString("3.3.3.3"))
				return attrMap
			},
			expectedIP: ipStr,
		},
		{
			name:            "ip attribute but not as pod association",
			podAssociations: []string{podAssociationk8sIPLabel},
			ctxFn:           func(t *testing.T) context.Context { return context.Background() },
			attrMapFn: func(*testing.T) pcommon.Map {
				attrMap := pcommon.NewMap()
				attrMap.Insert("ip", pcommon.NewValueString(ipStr))
				return attrMap
			},
			expectedIP: "",
		},
		{
			name:            "uses hostname before attribute (reverse order from default)",
			podAssociations: []string{podAssociationHostnameLabel, podAssociationOTelIPLabel},
			ctxFn:           func(t *testing.T) context.Context { return context.Background() },
			attrMapFn: func(*testing.T) pcommon.Map {
				attrMap := pcommon.NewMap()
				attrMap.Insert(semconv.AttributeNetHostIP, pcommon.NewValueString("3.3.3.3"))
				attrMap.Insert(semconv.AttributeHostName, pcommon.NewValueString(ipStr))
				return attrMap
			},
			expectedIP: ipStr,
		},
	}

	for _, tc := range testCases {
		t.Run(tc.name, func(t *testing.T) {
			mockProcessor := new(consumertest.TracesSink)
			p, err := newTraceProcessor(mockProcessor, "", tc.podAssociations, nil)
			require.NoError(t, err)

			ip := p.(*promServiceDiscoProcessor).getPodIP(tc.ctxFn(t), tc.attrMapFn(t))
			assert.Equal(t, tc.expectedIP, ip)
		})
	}
}

'''
'''--- pkg/traces/pushreceiver/factory.go ---
package pushreceiver

import (
	"context"

	"go.opentelemetry.io/collector/component"
	"go.opentelemetry.io/collector/config"
	"go.opentelemetry.io/collector/consumer"
)

const (
	//TypeStr for push receiver.
	TypeStr = "push_receiver"
)

// Type returns the receiver type that PushReceiverFactory produces
func (f Factory) Type() config.Type {
	return TypeStr
}

// NewFactory creates a new push receiver factory.
func NewFactory() component.ReceiverFactory {
	return &Factory{}
}

// CreateDefaultConfig creates a default push receiver config.
func (f *Factory) CreateDefaultConfig() config.Receiver {
	s := config.NewReceiverSettings(config.NewComponentIDWithName(TypeStr, TypeStr))
	return &s
}

// Factory is a factory that sneakily exposes a Traces consumer for use within the agent.
type Factory struct {
	component.Factory
	Consumer consumer.Traces
}

// StabilityLevel implements component.Factory.
func (f *Factory) StabilityLevel(config.DataType) component.StabilityLevel {
	return component.StabilityLevelUndefined
}

// CreateTracesReceiver creates a stub receiver while also sneakily keeping a reference to the provided Traces consumer.
func (f *Factory) CreateTracesReceiver(
	_ context.Context,
	_ component.ReceiverCreateSettings,
	_ config.Receiver,
	c consumer.Traces,
) (component.TracesReceiver, error) {

	r, err := newPushReceiver()
	f.Consumer = c

	return r, err
}

// CreateMetricsReceiver returns an error because metrics are not supported by push receiver.
func (f *Factory) CreateMetricsReceiver(ctx context.Context, set component.ReceiverCreateSettings,
	cfg config.Receiver, nextConsumer consumer.Metrics) (component.MetricsReceiver, error) {

	return nil, component.ErrDataTypeIsNotSupported
}

// CreateLogsReceiver returns an error because logs are not supported by push receiver.
func (f *Factory) CreateLogsReceiver(ctx context.Context, set component.ReceiverCreateSettings,
	cfg config.Receiver, nextConsumer consumer.Logs) (component.LogsReceiver, error) {

	return nil, component.ErrDataTypeIsNotSupported
}

'''
'''--- pkg/traces/pushreceiver/receiver.go ---
package pushreceiver

import (
	"context"

	"go.opentelemetry.io/collector/component"
)

type receiver struct{}

func (r *receiver) Start(_ context.Context, _ component.Host) error {
	return nil
}

func (r *receiver) Shutdown(_ context.Context) error {
	return nil
}

func newPushReceiver() (component.TracesReceiver, error) {
	return &receiver{}, nil
}

'''
'''--- pkg/traces/remotewriteexporter/exporter.go ---
package remotewriteexporter

import (
	"context"
	"fmt"
	"strconv"
	"strings"
	"sync"
	"time"

	util "github.com/cortexproject/cortex/pkg/util/log"
	"github.com/go-kit/log"
	"github.com/go-kit/log/level"
	"github.com/grafana/agent/pkg/metrics/instance"
	"github.com/grafana/agent/pkg/traces/contextkeys"
	"github.com/prometheus/prometheus/model/labels"
	"go.opentelemetry.io/collector/component"
	"go.opentelemetry.io/collector/consumer"
	"go.opentelemetry.io/collector/pdata/pcommon"
	"go.opentelemetry.io/collector/pdata/pmetric"
)

const (
	nameLabelKey = "__name__"
	sumSuffix    = "sum"
	countSuffix  = "count"
	bucketSuffix = "bucket"
	leStr        = "le"
	infBucket    = "+Inf"
	noSuffix     = ""
)

type datapoint struct {
	ts int64
	v  float64
	l  labels.Labels
}

type remoteWriteExporter struct {
	mtx sync.Mutex

	close  chan struct{}
	closed chan struct{}

	manager      instance.Manager
	promInstance string

	constLabels labels.Labels
	namespace   string

	seriesMap    map[uint64]*datapoint
	staleTime    int64
	lastFlush    int64
	loopInterval time.Duration

	logger log.Logger
}

func newRemoteWriteExporter(cfg *Config) (component.MetricsExporter, error) {
	logger := log.With(util.Logger, "component", "traces remote write exporter")

	ls := make(labels.Labels, 0, len(cfg.ConstLabels))

	for name, value := range cfg.ConstLabels {
		ls = append(ls, labels.Label{Name: name, Value: value})
	}

	staleTime := (15 * time.Minute).Milliseconds()
	if cfg.StaleTime > 0 {
		staleTime = cfg.StaleTime.Milliseconds()
	}

	loopInterval := time.Second
	if cfg.LoopInterval > 0 {
		loopInterval = cfg.LoopInterval
	}

	return &remoteWriteExporter{
		mtx:          sync.Mutex{},
		close:        make(chan struct{}),
		closed:       make(chan struct{}),
		constLabels:  ls,
		namespace:    cfg.Namespace,
		promInstance: cfg.PromInstance,
		seriesMap:    make(map[uint64]*datapoint),
		staleTime:    staleTime,
		loopInterval: loopInterval,
		logger:       logger,
	}, nil
}

func (e *remoteWriteExporter) Start(ctx context.Context, _ component.Host) error {
	manager, ok := ctx.Value(contextkeys.Metrics).(instance.Manager)
	if !ok || manager == nil {
		return fmt.Errorf("key does not contain a InstanceManager instance")
	}
	e.manager = manager

	go e.appenderLoop()

	return nil
}

func (e *remoteWriteExporter) Shutdown(ctx context.Context) error {
	close(e.close)

	select {
	case <-e.closed:
		return nil
	case <-ctx.Done():
		return ctx.Err()
	}
}

func (e *remoteWriteExporter) Capabilities() consumer.Capabilities {
	return consumer.Capabilities{}
}

func (e *remoteWriteExporter) ConsumeMetrics(ctx context.Context, md pmetric.Metrics) error {
	select {
	case <-e.closed:
		return nil
	default:
	}

	resourceMetrics := md.ResourceMetrics()
	for i := 0; i < resourceMetrics.Len(); i++ {
		resourceMetric := resourceMetrics.At(i)
		scopeMetricsSlice := resourceMetric.ScopeMetrics()
		for j := 0; j < scopeMetricsSlice.Len(); j++ {
			metricSlice := scopeMetricsSlice.At(j).Metrics()
			for k := 0; k < metricSlice.Len(); k++ {
				switch metric := metricSlice.At(k); metric.DataType() {
				case pmetric.MetricDataTypeGauge:
					dataPoints := metric.Sum().DataPoints()
					if err := e.handleNumberDataPoints(metric.Name(), dataPoints); err != nil {
						return err
					}
				case pmetric.MetricDataTypeSum:
					if metric.Sum().AggregationTemporality() != pmetric.MetricAggregationTemporalityCumulative {
						continue // Only cumulative metrics are supported
					}
					dataPoints := metric.Sum().DataPoints()
					if err := e.handleNumberDataPoints(metric.Name(), dataPoints); err != nil {
						return err
					}
				case pmetric.MetricDataTypeHistogram:
					if metric.Histogram().AggregationTemporality() != pmetric.MetricAggregationTemporalityCumulative {
						continue // Only cumulative metrics are supported
					}
					dataPoints := metric.Histogram().DataPoints()
					e.handleHistogramDataPoints(metric.Name(), dataPoints)
				case pmetric.MetricDataTypeSummary:
					return fmt.Errorf("unsupported metric data type %s", metric.DataType())
				default:
					return fmt.Errorf("unsupported metric data type %s", metric.DataType())
				}
			}
		}
	}

	return nil
}

func (e *remoteWriteExporter) handleNumberDataPoints(name string, dataPoints pmetric.NumberDataPointSlice) error {
	for ix := 0; ix < dataPoints.Len(); ix++ {
		dataPoint := dataPoints.At(ix)
		lbls := e.createLabelSet(name, noSuffix, dataPoint.Attributes(), labels.Labels{})
		if err := e.appendNumberDataPoint(dataPoint, lbls); err != nil {
			return fmt.Errorf("failed to process datapoints %s", err)
		}
	}
	return nil
}

func (e *remoteWriteExporter) appendNumberDataPoint(dataPoint pmetric.NumberDataPoint, labels labels.Labels) error {
	var val float64
	switch dataPoint.ValueType() {
	case pmetric.NumberDataPointValueTypeDouble:
		val = dataPoint.DoubleVal()
	case pmetric.NumberDataPointValueTypeInt:
		val = float64(dataPoint.IntVal())
	default:
		return fmt.Errorf("unknown data point type: %s", dataPoint.ValueType())
	}
	ts := e.timestamp()

	e.appendDatapointForSeries(labels, ts, val)

	return nil
}

func (e *remoteWriteExporter) handleHistogramDataPoints(name string, dataPoints pmetric.HistogramDataPointSlice) {
	for ix := 0; ix < dataPoints.Len(); ix++ {
		dataPoint := dataPoints.At(ix)
		ts := e.timestamp()

		// Append sum value
		sumLabels := e.createLabelSet(name, sumSuffix, dataPoint.Attributes(), labels.Labels{})
		e.appendDatapointForSeries(sumLabels, ts, dataPoint.Sum())

		// Append count value
		countLabels := e.createLabelSet(name, countSuffix, dataPoint.Attributes(), labels.Labels{})
		e.appendDatapointForSeries(countLabels, ts, float64(dataPoint.Count()))

		var cumulativeCount uint64
		for ix := 0; ix < dataPoint.ExplicitBounds().Len(); ix++ {
			eb := dataPoint.ExplicitBounds().At(ix)

			if ix >= dataPoint.BucketCounts().Len() {
				break
			}
			cumulativeCount += dataPoint.BucketCounts().At(ix)
			boundStr := strconv.FormatFloat(eb, 'f', -1, 64)
			bucketLabels := e.createLabelSet(name, bucketSuffix, dataPoint.Attributes(), labels.Labels{{Name: leStr, Value: boundStr}})
			e.appendDatapointForSeries(bucketLabels, ts, float64(cumulativeCount))
		}

		// add le=+Inf bucket
		cumulativeCount += dataPoint.BucketCounts().At(dataPoint.BucketCounts().Len() - 1)
		infBucketLabels := e.createLabelSet(name, bucketSuffix, dataPoint.Attributes(), labels.Labels{{Name: leStr, Value: infBucket}})
		e.appendDatapointForSeries(infBucketLabels, ts, float64(cumulativeCount))
	}
}

func (e *remoteWriteExporter) appendDatapointForSeries(l labels.Labels, ts int64, v float64) {
	e.mtx.Lock()
	defer e.mtx.Unlock()

	series := l.Hash()
	if lastDatapoint, ok := e.seriesMap[series]; ok {
		if lastDatapoint.ts >= ts {
			return
		}
		lastDatapoint.ts = ts
		lastDatapoint.v = v
		return
	}

	e.seriesMap[series] = &datapoint{l: l, ts: ts, v: v}
}

func (e *remoteWriteExporter) appenderLoop() {
	t := time.NewTicker(e.loopInterval)

	for {
		select {
		case <-t.C:
			e.mtx.Lock()
			inst, err := e.manager.GetInstance(e.promInstance)
			if err != nil {
				level.Error(e.logger).Log("msg", "failed to get prom instance", "err", err)
				continue
			}
			appender := inst.Appender(context.Background())

			now := time.Now().UnixMilli()
			for _, dp := range e.seriesMap {
				// If the datapoint hasn't been updated since the last loop, don't append it
				if dp.ts < e.lastFlush {
					// If the datapoint is older than now - staleTime, it is stale and gets removed.
					if now-dp.ts > e.staleTime {
						delete(e.seriesMap, dp.l.Hash())
					}
					continue
				}

				if _, err := appender.Append(0, dp.l, dp.ts, dp.v); err != nil {
					level.Error(e.logger).Log("msg", "failed to append datapoint", "err", err)
				}
			}

			if err := appender.Commit(); err != nil {
				level.Error(e.logger).Log("msg", "failed to commit appender", "err", err)
			}

			e.lastFlush = now
			e.mtx.Unlock()

		case <-e.close:
			close(e.closed)
			return
		}
	}
}

func (e *remoteWriteExporter) createLabelSet(name, suffix string, labelMap pcommon.Map, customLabels labels.Labels) labels.Labels {
	ls := make(labels.Labels, 0, labelMap.Len()+1+len(e.constLabels)+len(customLabels))
	// Labels from spanmetrics processor
	labelMap.Range(func(k string, v pcommon.Value) bool {
		ls = append(ls, labels.Label{
			Name:  strings.Replace(k, ".", "_", -1),
			Value: v.StringVal(),
		})
		return true
	})
	// Metric name label
	ls = append(ls, labels.Label{
		Name:  nameLabelKey,
		Value: metricName(e.namespace, name, suffix),
	})
	// Const labels
	ls = append(ls, e.constLabels...)
	// Custom labels
	ls = append(ls, customLabels...)
	return ls
}

func (e *remoteWriteExporter) timestamp() int64 {
	return time.Now().UnixMilli()
}

func metricName(namespace, metric, suffix string) string {
	if len(suffix) != 0 {
		return fmt.Sprintf("%s_%s_%s", namespace, metric, suffix)
	}
	return fmt.Sprintf("%s_%s", namespace, metric)
}

'''
'''--- pkg/traces/remotewriteexporter/exporter_test.go ---
package remotewriteexporter

import (
	"context"
	"testing"
	"time"

	"github.com/grafana/agent/pkg/metrics/instance"
	"github.com/grafana/agent/pkg/traces/contextkeys"
	"github.com/prometheus/prometheus/model/exemplar"
	"github.com/prometheus/prometheus/model/labels"
	"github.com/prometheus/prometheus/storage"
	"github.com/stretchr/testify/require"
	"go.opentelemetry.io/collector/config"
	internal "go.opentelemetry.io/collector/pdata/external"
	"go.opentelemetry.io/collector/pdata/pcommon"
	"go.opentelemetry.io/collector/pdata/pmetric"
)

const (
	callsMetric  = "traces_spanmetrics_calls_total"
	sumMetric    = "traces_spanmetrics_latency_sum"
	countMetric  = "traces_spanmetrics_latency_count"
	bucketMetric = "traces_spanmetrics_latency_bucket"
)

func TestRemoteWriteExporter_ConsumeMetrics(t *testing.T) {
	var (
		countValue     uint64  = 20
		sumValue       float64 = 100
		bucketCounts           = []uint64{1, 2, 3, 4, 5, 6}
		explicitBounds         = []float64{1, 2.5, 5, 7.5, 10}
		ts                     = time.Date(2020, 1, 2, 3, 4, 5, 6, time.UTC)
	)

	cfg := Config{
		ExporterSettings: config.ExporterSettings{},
		ConstLabels:      nil,
		Namespace:        "traces",
		PromInstance:     "traces",
	}
	exp, err := newRemoteWriteExporter(&cfg)
	require.NoError(t, err)

	manager := &mockManager{}
	ctx := context.WithValue(context.Background(), contextkeys.Metrics, manager)
	require.NoError(t, exp.Start(ctx, nil))

	metrics := pmetric.NewMetrics()
	ilm := metrics.ResourceMetrics().AppendEmpty().ScopeMetrics().AppendEmpty()
	ilm.Scope().SetName("spanmetrics")

	// Append sum metric
	sm := ilm.Metrics().AppendEmpty()
	sm.SetDataType(pmetric.MetricDataTypeSum)
	sm.SetName("spanmetrics_calls_total")
	sm.Sum().SetAggregationTemporality(pmetric.MetricAggregationTemporalityCumulative)

	sdp := sm.Sum().DataPoints().AppendEmpty()
	sdp.SetTimestamp(pcommon.NewTimestampFromTime(ts.UTC()))
	sdp.SetDoubleVal(sumValue)

	// Append histogram
	hm := ilm.Metrics().AppendEmpty()
	hm.SetDataType(pmetric.MetricDataTypeHistogram)
	hm.SetName("spanmetrics_latency")
	hm.Histogram().SetAggregationTemporality(pmetric.MetricAggregationTemporalityCumulative)

	hdp := hm.Histogram().DataPoints().AppendEmpty()
	hdp.SetTimestamp(pcommon.NewTimestampFromTime(ts.UTC()))
	hdp.SetBucketCounts(internal.NewImmutableUInt64Slice(bucketCounts))
	hdp.SetExplicitBounds(internal.NewImmutableFloat64Slice(explicitBounds))
	hdp.SetCount(countValue)
	hdp.SetSum(sumValue)

	err = exp.ConsumeMetrics(context.TODO(), metrics)
	require.NoError(t, err)

	time.Sleep(5 * time.Second)

	require.NoError(t, exp.Shutdown(context.TODO()))

	// Verify calls
	calls := manager.instance.GetAppended(callsMetric)
	require.Equal(t, len(calls), 1)
	require.Equal(t, calls[0].v, sumValue)
	require.Equal(t, calls[0].l, labels.Labels{{Name: nameLabelKey, Value: "traces_spanmetrics_calls_total"}})

	// Verify _sum
	sum := manager.instance.GetAppended(sumMetric)
	require.Equal(t, len(sum), 1)
	require.Equal(t, sum[0].v, sumValue)
	require.Equal(t, sum[0].l, labels.Labels{{Name: nameLabelKey, Value: "traces_spanmetrics_latency_" + sumSuffix}})

	// Check _count
	count := manager.instance.GetAppended(countMetric)
	require.Equal(t, len(count), 1)
	require.Equal(t, count[0].v, float64(countValue))
	require.Equal(t, count[0].l, labels.Labels{{Name: nameLabelKey, Value: "traces_spanmetrics_latency_" + countSuffix}})

	// Check _bucket
	buckets := manager.instance.GetAppended(bucketMetric)
	require.Equal(t, len(buckets), len(bucketCounts))
}

type mockManager struct {
	instance *mockInstance
}

func (m *mockManager) GetInstance(string) (instance.ManagedInstance, error) {
	if m.instance == nil {
		m.instance = &mockInstance{}
	}
	return m.instance, nil
}

func (m *mockManager) ListInstances() map[string]instance.ManagedInstance { return nil }

func (m *mockManager) ListConfigs() map[string]instance.Config { return nil }

func (m *mockManager) ApplyConfig(_ instance.Config) error { return nil }

func (m *mockManager) DeleteConfig(_ string) error { return nil }

func (m *mockManager) Stop() {}

type mockInstance struct {
	instance.NoOpInstance
	appender *mockAppender
}

func (m *mockInstance) Appender(_ context.Context) storage.Appender {
	if m.appender == nil {
		m.appender = &mockAppender{}
	}
	return m.appender
}

func (m *mockInstance) GetAppended(n string) []metric {
	return m.appender.GetAppended(n)
}

type metric struct {
	l labels.Labels
	t int64
	v float64
}

type mockAppender struct {
	appendedMetrics []metric
}

func (a *mockAppender) GetAppended(n string) []metric {
	var ms []metric
	for _, m := range a.appendedMetrics {
		if n == m.l.Get(nameLabelKey) {
			ms = append(ms, m)
		}
	}
	return ms
}

func (a *mockAppender) Append(_ storage.SeriesRef, l labels.Labels, t int64, v float64) (storage.SeriesRef, error) {
	a.appendedMetrics = append(a.appendedMetrics, metric{l: l, t: t, v: v})
	return 0, nil
}

func (a *mockAppender) Commit() error { return nil }

func (a *mockAppender) Rollback() error { return nil }

func (a *mockAppender) AppendExemplar(_ storage.SeriesRef, _ labels.Labels, _ exemplar.Exemplar) (storage.SeriesRef, error) {
	return 0, nil
}

'''
'''--- pkg/traces/remotewriteexporter/factory.go ---
package remotewriteexporter

import (
	"context"
	"time"

	"github.com/prometheus/client_golang/prometheus"
	"go.opentelemetry.io/collector/component"
	"go.opentelemetry.io/collector/config"
)

const (
	// TypeStr is the unique identifier for the Prometheus remote write exporter.
	// TODO: Rename to walexporter (?). Remote write makes no sense, it appends to a WAL.
	TypeStr = "remote_write"
)

var _ config.Exporter = (*Config)(nil)

// Config holds the configuration for the Prometheus remote write processor.
type Config struct {
	config.ExporterSettings `mapstructure:",squash"`

	ConstLabels  prometheus.Labels `mapstructure:"const_labels"`
	Namespace    string            `mapstructure:"namespace"`
	PromInstance string            `mapstructure:"metrics_instance"`
	// StaleTime is the duration after which a series is considered stale and will be removed.
	StaleTime time.Duration `mapstructure:"stale_time"`
	// LoopInterval is the duration after which the exporter will be checked for new data.
	// New data is flushed to a WAL.
	LoopInterval time.Duration `mapstructure:"loop_interval"`
}

// NewFactory returns a new factory for the Prometheus remote write processor.
func NewFactory() component.ExporterFactory {
	return component.NewExporterFactory(
		TypeStr,
		createDefaultConfig,
		component.WithMetricsExporter(createMetricsExporter),
	)
}

func createDefaultConfig() config.Exporter {
	return &Config{
		ExporterSettings: config.NewExporterSettings(config.NewComponentIDWithName(TypeStr, TypeStr)),
	}
}

func createMetricsExporter(
	_ context.Context,
	_ component.ExporterCreateSettings,
	cfg config.Exporter,
) (component.MetricsExporter, error) {

	eCfg := cfg.(*Config)
	return newRemoteWriteExporter(eCfg)
}

'''
'''--- pkg/traces/servicegraphprocessor/factory.go ---
package servicegraphprocessor

import (
	"context"
	"time"

	"go.opentelemetry.io/collector/component"
	"go.opentelemetry.io/collector/config"
	"go.opentelemetry.io/collector/consumer"
)

const (
	// TypeStr is the unique identifier for the Prometheus service graph exporter.
	TypeStr = "service_graphs"

	// DefaultWait is the default value to wait for an edge to be completed
	DefaultWait = time.Second * 10
	// DefaultMaxItems is the default amount of edges that will be stored in the storeMap
	DefaultMaxItems = 10_000
	// DefaultWorkers is the default amount of workers that will be used to process the edges
	DefaultWorkers = 10
)

// Config holds the configuration for the Prometheus service graph processor.
type Config struct {
	config.ProcessorSettings `mapstructure:",squash"`

	Wait     time.Duration `mapstructure:"wait"`
	MaxItems int           `mapstructure:"max_items"`

	Workers int `mapstructure:"workers"`

	SuccessCodes *successCodes `mapstructure:"success_codes"`
}

type successCodes struct {
	http []int64 `mapstructure:"http"`
	grpc []int64 `mapstructure:"grpc"`
}

// NewFactory returns a new factory for the Prometheus service graph processor.
func NewFactory() component.ProcessorFactory {
	return component.NewProcessorFactory(
		TypeStr,
		createDefaultConfig,
		component.WithTracesProcessor(createTracesProcessor),
	)
}

func createDefaultConfig() config.Processor {
	return &Config{
		ProcessorSettings: config.NewProcessorSettings(config.NewComponentIDWithName(TypeStr, TypeStr)),
	}
}

func createTracesProcessor(
	_ context.Context,
	_ component.ProcessorCreateSettings,
	cfg config.Processor,
	nextConsumer consumer.Traces,
) (component.TracesProcessor, error) {

	eCfg := cfg.(*Config)
	return newProcessor(nextConsumer, eCfg), nil
}

'''
'''--- pkg/traces/servicegraphprocessor/processor.go ---
package servicegraphprocessor

import (
	"context"
	"errors"
	"fmt"
	"time"

	util "github.com/cortexproject/cortex/pkg/util/log"
	"github.com/go-kit/log"
	"github.com/go-kit/log/level"
	"github.com/grafana/agent/pkg/traces/contextkeys"
	"github.com/prometheus/client_golang/prometheus"
	"go.opentelemetry.io/collector/component"
	"go.opentelemetry.io/collector/consumer"
	pdata_internal "go.opentelemetry.io/collector/pdata/external"
	"go.opentelemetry.io/collector/pdata/ptrace"
	semconv "go.opentelemetry.io/collector/semconv/v1.6.1"
	"google.golang.org/grpc/codes"
)

type tooManySpansError struct {
	droppedSpans int
}

func (t tooManySpansError) Error() string {
	return fmt.Sprintf("dropped %d spans", t.droppedSpans)
}

// edge is an edge between two nodes in the graph
type edge struct {
	key string

	serverService, clientService string
	serverLatency, clientLatency time.Duration

	// If either the client or the server spans have status code error,
	// the edge will be considered as failed.
	failed bool

	// expiration is the time at which the edge expires, expressed as Unix time
	expiration int64
}

func newEdge(key string, ttl time.Duration) *edge {
	return &edge{
		key: key,

		expiration: time.Now().Add(ttl).Unix(),
	}
}

// isCompleted returns true if the corresponding client and server
// pair spans have been processed for the given edge
func (e *edge) isCompleted() bool {
	return len(e.clientService) != 0 && len(e.serverService) != 0
}

func (e *edge) isExpired() bool {
	return time.Now().Unix() >= e.expiration
}

var _ component.TracesProcessor = (*processor)(nil)

type processor struct {
	nextConsumer consumer.Traces
	reg          prometheus.Registerer

	store *store

	wait     time.Duration
	maxItems int

	// completed edges are pushed through this channel to be processed.
	collectCh chan string

	serviceGraphRequestTotal           *prometheus.CounterVec
	serviceGraphRequestFailedTotal     *prometheus.CounterVec
	serviceGraphRequestServerHistogram *prometheus.HistogramVec
	serviceGraphRequestClientHistogram *prometheus.HistogramVec
	serviceGraphUnpairedSpansTotal     *prometheus.CounterVec
	serviceGraphDroppedSpansTotal      *prometheus.CounterVec

	httpSuccessCodeMap map[int]struct{}
	grpcSuccessCodeMap map[int]struct{}

	logger  log.Logger
	closeCh chan struct{}
}

func newProcessor(nextConsumer consumer.Traces, cfg *Config) *processor {
	logger := log.With(util.Logger, "component", "service graphs")

	if cfg.Wait == 0 {
		cfg.Wait = DefaultWait
	}
	if cfg.MaxItems == 0 {
		cfg.MaxItems = DefaultMaxItems
	}
	if cfg.Workers == 0 {
		cfg.Workers = DefaultWorkers
	}

	var (
		httpSuccessCodeMap = make(map[int]struct{})
		grpcSuccessCodeMap = make(map[int]struct{})
	)
	if cfg.SuccessCodes != nil {
		for _, sc := range cfg.SuccessCodes.http {
			httpSuccessCodeMap[int(sc)] = struct{}{}
		}
		for _, sc := range cfg.SuccessCodes.grpc {
			grpcSuccessCodeMap[int(sc)] = struct{}{}
		}
	}

	p := &processor{
		nextConsumer: nextConsumer,
		logger:       logger,

		wait:               cfg.Wait,
		maxItems:           cfg.MaxItems,
		httpSuccessCodeMap: httpSuccessCodeMap,
		grpcSuccessCodeMap: grpcSuccessCodeMap,

		collectCh: make(chan string, cfg.Workers),

		closeCh: make(chan struct{}, 1),
	}

	for i := 0; i < cfg.Workers; i++ {
		go func() {
			for {
				select {
				case k := <-p.collectCh:
					p.store.evictEdgeWithLock(k)

				case <-p.closeCh:
					return
				}
			}
		}()
	}

	return p
}

func (p *processor) Start(ctx context.Context, _ component.Host) error {
	// initialize store
	p.store = newStore(p.wait, p.maxItems, p.collectEdge)

	reg, ok := ctx.Value(contextkeys.PrometheusRegisterer).(prometheus.Registerer)
	if !ok || reg == nil {
		return fmt.Errorf("key does not contain a prometheus registerer")
	}
	p.reg = reg
	return p.registerMetrics()
}

func (p *processor) registerMetrics() error {
	p.serviceGraphRequestTotal = prometheus.NewCounterVec(prometheus.CounterOpts{
		Namespace: "traces",
		Name:      "service_graph_request_total",
		Help:      "Total count of requests between two nodes",
	}, []string{"client", "server"})
	p.serviceGraphRequestFailedTotal = prometheus.NewCounterVec(prometheus.CounterOpts{
		Namespace: "traces",
		Name:      "service_graph_request_failed_total",
		Help:      "Total count of failed requests between two nodes",
	}, []string{"client", "server"})
	p.serviceGraphRequestServerHistogram = prometheus.NewHistogramVec(prometheus.HistogramOpts{
		Namespace: "traces",
		Name:      "service_graph_request_server_seconds",
		Help:      "Time for a request between two nodes as seen from the server",
		Buckets:   prometheus.ExponentialBuckets(0.01, 2, 12),
	}, []string{"client", "server"})
	p.serviceGraphRequestClientHistogram = prometheus.NewHistogramVec(prometheus.HistogramOpts{
		Namespace: "traces",
		Name:      "service_graph_request_client_seconds",
		Help:      "Time for a request between two nodes as seen from the client",
		Buckets:   prometheus.ExponentialBuckets(0.01, 2, 12),
	}, []string{"client", "server"})
	p.serviceGraphUnpairedSpansTotal = prometheus.NewCounterVec(prometheus.CounterOpts{
		Namespace: "traces",
		Name:      "service_graph_unpaired_spans_total",
		Help:      "Total count of unpaired spans",
	}, []string{"client", "server"})
	p.serviceGraphDroppedSpansTotal = prometheus.NewCounterVec(prometheus.CounterOpts{
		Namespace: "traces",
		Name:      "service_graph_dropped_spans_total",
		Help:      "Total count of dropped spans",
	}, []string{"client", "server"})

	cs := []prometheus.Collector{
		p.serviceGraphRequestTotal,
		p.serviceGraphRequestFailedTotal,
		p.serviceGraphRequestServerHistogram,
		p.serviceGraphRequestClientHistogram,
		p.serviceGraphUnpairedSpansTotal,
		p.serviceGraphDroppedSpansTotal,
	}

	for _, c := range cs {
		if err := p.reg.Register(c); err != nil {
			return err
		}
	}

	return nil
}

func (p *processor) Shutdown(context.Context) error {
	close(p.closeCh)
	p.unregisterMetrics()
	return nil
}

func (p *processor) unregisterMetrics() {
	cs := []prometheus.Collector{
		p.serviceGraphRequestTotal,
		p.serviceGraphRequestFailedTotal,
		p.serviceGraphRequestServerHistogram,
		p.serviceGraphRequestClientHistogram,
		p.serviceGraphUnpairedSpansTotal,
	}

	for _, c := range cs {
		p.reg.Unregister(c)
	}
}

func (p *processor) Capabilities() consumer.Capabilities {
	return consumer.Capabilities{}
}

func (p *processor) ConsumeTraces(ctx context.Context, td ptrace.Traces) error {
	// Evict expired edges
	p.store.expire()

	if err := p.consume(td); err != nil {
		if errors.As(err, &tooManySpansError{}) {
			level.Warn(p.logger).Log("msg", "skipped processing of spans", "maxItems", p.maxItems, "err", err)
		} else {
			level.Error(p.logger).Log("msg", "failed consuming traces", "err", err)
		}
		return nil
	}

	return p.nextConsumer.ConsumeTraces(ctx, td)
}

// collectEdge records the metrics for the given edge.
// Returns true if the edge is completed or expired and should be deleted.
func (p *processor) collectEdge(e *edge) {
	if e.isCompleted() {
		p.serviceGraphRequestTotal.WithLabelValues(e.clientService, e.serverService).Inc()
		if e.failed {
			p.serviceGraphRequestFailedTotal.WithLabelValues(e.clientService, e.serverService).Inc()
		}
		p.serviceGraphRequestServerHistogram.WithLabelValues(e.clientService, e.serverService).Observe(e.serverLatency.Seconds())
		p.serviceGraphRequestClientHistogram.WithLabelValues(e.clientService, e.serverService).Observe(e.clientLatency.Seconds())
	} else if e.isExpired() {
		p.serviceGraphUnpairedSpansTotal.WithLabelValues(e.clientService, e.serverService).Inc()
	}
}

func (p *processor) consume(trace ptrace.Traces) error {
	var totalDroppedSpans int
	rSpansSlice := trace.ResourceSpans()
	for i := 0; i < rSpansSlice.Len(); i++ {
		rSpan := rSpansSlice.At(i)

		svc, ok := rSpan.Resource().Attributes().Get(semconv.AttributeServiceName)
		if !ok || svc.StringVal() == "" {
			continue
		}

		ssSlice := rSpan.ScopeSpans()
		for j := 0; j < ssSlice.Len(); j++ {
			ils := ssSlice.At(j)

			for k := 0; k < ils.Spans().Len(); k++ {
				span := ils.Spans().At(k)

				switch span.Kind() {
				case ptrace.SpanKindClient:
					k := key(span.TraceID().HexString(), span.SpanID().HexString())

					edge, err := p.store.upsertEdge(k, func(e *edge) {
						e.clientService = svc.StringVal()
						e.clientLatency = spanDuration(span)
						e.failed = e.failed || p.spanFailed(span) // keep request as failed if any span is failed
					})

					if errors.Is(err, errTooManyItems) {
						totalDroppedSpans++
						p.serviceGraphDroppedSpansTotal.WithLabelValues(svc.StringVal(), "").Inc()
						continue
					}
					// upsertEdge will only return this errTooManyItems
					if err != nil {
						return err
					}

					if edge.isCompleted() {
						p.collectCh <- k
					}

				case ptrace.SpanKindServer:
					k := key(span.TraceID().HexString(), span.ParentSpanID().HexString())

					edge, err := p.store.upsertEdge(k, func(e *edge) {
						e.serverService = svc.StringVal()
						e.serverLatency = spanDuration(span)
						e.failed = e.failed || p.spanFailed(span) // keep request as failed if any span is failed
					})

					if errors.Is(err, errTooManyItems) {
						totalDroppedSpans++
						p.serviceGraphDroppedSpansTotal.WithLabelValues("", svc.StringVal()).Inc()
						continue
					}
					// upsertEdge will only return this errTooManyItems
					if err != nil {
						return err
					}

					if edge.isCompleted() {
						p.collectCh <- k
					}

				default:
				}
			}
		}
	}

	if totalDroppedSpans > 0 {
		return &tooManySpansError{
			droppedSpans: totalDroppedSpans,
		}
	}
	return nil
}

func (p *processor) spanFailed(span ptrace.Span) bool {
	// Request considered failed if status is not 2XX or added as a successful status code
	if statusCode, ok := span.Attributes().Get(semconv.AttributeHTTPStatusCode); ok {
		sc := int(statusCode.IntVal())
		if _, ok := p.httpSuccessCodeMap[sc]; !ok && sc/100 != 2 {
			return true
		}
	}

	// Request considered failed if status is not OK or added as a successful status code
	if statusCode, ok := span.Attributes().Get(semconv.AttributeRPCGRPCStatusCode); ok {
		sc := int(statusCode.IntVal())
		if _, ok := p.grpcSuccessCodeMap[sc]; !ok && sc != int(codes.OK) {
			return true
		}
	}

	return span.Status().Code() == pdata_internal.StatusCodeError
}

func spanDuration(span ptrace.Span) time.Duration {
	return span.EndTimestamp().AsTime().Sub(span.StartTimestamp().AsTime())
}

func key(k1, k2 string) string {
	return fmt.Sprintf("%s-%s", k1, k2)
}

'''
'''--- pkg/traces/servicegraphprocessor/processor_test.go ---
package servicegraphprocessor

import (
	"bytes"
	"context"
	"io/ioutil"
	"testing"
	"time"

	"github.com/grafana/agent/pkg/traces/contextkeys"
	"github.com/prometheus/client_golang/prometheus"
	"github.com/prometheus/client_golang/prometheus/testutil"
	"github.com/stretchr/testify/assert"
	"github.com/stretchr/testify/require"
	"go.opentelemetry.io/collector/consumer"
	"go.opentelemetry.io/collector/pdata/ptrace"
)

const (
	traceSamplePath         = "testdata/trace-sample.json"
	unpairedTraceSamplePath = "testdata/unpaired-trace-sample.json"
)

func TestConsumeMetrics(t *testing.T) {
	for _, tc := range []struct {
		name            string
		sampleDataPath  string
		cfg             *Config
		expectedMetrics string
	}{
		{
			name:           "happy case",
			sampleDataPath: traceSamplePath,
			cfg: &Config{
				Wait: time.Hour,
			},
			expectedMetrics: happyCaseExpectedMetrics,
		},
		{
			name:           "unpaired spans",
			sampleDataPath: unpairedTraceSamplePath,
			cfg: &Config{
				Wait: -time.Millisecond,
			},
			expectedMetrics: `
				# HELP traces_service_graph_unpaired_spans_total Total count of unpaired spans
				# TYPE traces_service_graph_unpaired_spans_total counter
				traces_service_graph_unpaired_spans_total{client="",server="db"} 2
				traces_service_graph_unpaired_spans_total{client="app",server=""} 3
				traces_service_graph_unpaired_spans_total{client="lb",server=""} 3
`,
		},
		{
			name:           "max items in storeMap is reached",
			sampleDataPath: traceSamplePath,
			cfg: &Config{
				Wait:     -time.Millisecond,
				MaxItems: 1, // Configure max number of items in storeMap to 1. Only one edge will be processed.
			},
			expectedMetrics: droppedSpansCaseMetrics,
		},
		{
			name:           `success codes`,
			sampleDataPath: traceSamplePath,
			cfg: &Config{
				Wait: -time.Millisecond,
				SuccessCodes: &successCodes{
					http: []int64{404},
				},
			},
			expectedMetrics: successCodesCaseMetrics,
		},
	} {
		t.Run(tc.name, func(t *testing.T) {
			p := newProcessor(&mockConsumer{}, tc.cfg)
			close(p.closeCh) // Don't collect any edges, leave that to the test.

			reg := prometheus.NewRegistry()
			ctx := context.WithValue(context.Background(), contextkeys.PrometheusRegisterer, reg)

			err := p.Start(ctx, nil)
			require.NoError(t, err)

			traces := traceSamples(t, tc.sampleDataPath)
			err = p.ConsumeTraces(context.Background(), traces)
			require.NoError(t, err)

			collectMetrics(p)

			assert.Eventually(t, func() bool {
				return testutil.GatherAndCompare(reg, bytes.NewBufferString(tc.expectedMetrics)) == nil
			}, time.Second, time.Millisecond*100)
			err = testutil.GatherAndCompare(reg, bytes.NewBufferString(tc.expectedMetrics))
			require.NoError(t, err)
		})
	}
}

func traceSamples(t *testing.T, path string) ptrace.Traces {
	b, err := ioutil.ReadFile(path)
	require.NoError(t, err)

	traces, err := ptrace.NewJSONUnmarshaler().UnmarshalTraces(b)
	require.NoError(t, err)

	return traces
}

// helper function to force collection of all metrics
func collectMetrics(p *processor) {
	p.store.mtx.Lock()
	defer p.store.mtx.Unlock()

	for h := p.store.l.Front(); h != nil; h = p.store.l.Front() {
		edge := h.Value.(*edge)
		p.collectEdge(edge)
		delete(p.store.m, edge.key)
		p.store.l.Remove(h)
	}
}

type mockConsumer struct{}

func (m *mockConsumer) Capabilities() consumer.Capabilities { return consumer.Capabilities{} }

func (m *mockConsumer) ConsumeTraces(context.Context, ptrace.Traces) error { return nil }

const (
	happyCaseExpectedMetrics = `
		# HELP traces_service_graph_request_client_seconds Time for a request between two nodes as seen from the client
		# TYPE traces_service_graph_request_client_seconds histogram
		traces_service_graph_request_client_seconds_bucket{client="app",server="db",le="0.01"} 0
		traces_service_graph_request_client_seconds_bucket{client="app",server="db",le="0.02"} 0
		traces_service_graph_request_client_seconds_bucket{client="app",server="db",le="0.04"} 0
		traces_service_graph_request_client_seconds_bucket{client="app",server="db",le="0.08"} 0
		traces_service_graph_request_client_seconds_bucket{client="app",server="db",le="0.16"} 0
		traces_service_graph_request_client_seconds_bucket{client="app",server="db",le="0.32"} 0
		traces_service_graph_request_client_seconds_bucket{client="app",server="db",le="0.64"} 0
		traces_service_graph_request_client_seconds_bucket{client="app",server="db",le="1.28"} 2
		traces_service_graph_request_client_seconds_bucket{client="app",server="db",le="2.56"} 3
		traces_service_graph_request_client_seconds_bucket{client="app",server="db",le="5.12"} 3
		traces_service_graph_request_client_seconds_bucket{client="app",server="db",le="10.24"} 3
		traces_service_graph_request_client_seconds_bucket{client="app",server="db",le="20.48"} 3
		traces_service_graph_request_client_seconds_bucket{client="app",server="db",le="+Inf"} 3
		traces_service_graph_request_client_seconds_sum{client="app",server="db"} 4.4
		traces_service_graph_request_client_seconds_count{client="app",server="db"} 3
		traces_service_graph_request_client_seconds_bucket{client="lb",server="app",le="0.01"} 0
		traces_service_graph_request_client_seconds_bucket{client="lb",server="app",le="0.02"} 0
		traces_service_graph_request_client_seconds_bucket{client="lb",server="app",le="0.04"} 0
		traces_service_graph_request_client_seconds_bucket{client="lb",server="app",le="0.08"} 0
		traces_service_graph_request_client_seconds_bucket{client="lb",server="app",le="0.16"} 0
		traces_service_graph_request_client_seconds_bucket{client="lb",server="app",le="0.32"} 0
		traces_service_graph_request_client_seconds_bucket{client="lb",server="app",le="0.64"} 0
		traces_service_graph_request_client_seconds_bucket{client="lb",server="app",le="1.28"} 0
		traces_service_graph_request_client_seconds_bucket{client="lb",server="app",le="2.56"} 2
		traces_service_graph_request_client_seconds_bucket{client="lb",server="app",le="5.12"} 3
		traces_service_graph_request_client_seconds_bucket{client="lb",server="app",le="10.24"} 3
		traces_service_graph_request_client_seconds_bucket{client="lb",server="app",le="20.48"} 3
		traces_service_graph_request_client_seconds_bucket{client="lb",server="app",le="+Inf"} 3
		traces_service_graph_request_client_seconds_sum{client="lb",server="app"} 7.8
		traces_service_graph_request_client_seconds_count{client="lb",server="app"} 3
		# HELP traces_service_graph_request_failed_total Total count of failed requests between two nodes
		# TYPE traces_service_graph_request_failed_total counter
		traces_service_graph_request_failed_total{client="lb",server="app"} 2
		# HELP traces_service_graph_request_server_seconds Time for a request between two nodes as seen from the server
		# TYPE traces_service_graph_request_server_seconds histogram
		traces_service_graph_request_server_seconds_bucket{client="app",server="db",le="0.01"} 0
		traces_service_graph_request_server_seconds_bucket{client="app",server="db",le="0.02"} 0
		traces_service_graph_request_server_seconds_bucket{client="app",server="db",le="0.04"} 0
		traces_service_graph_request_server_seconds_bucket{client="app",server="db",le="0.08"} 0
		traces_service_graph_request_server_seconds_bucket{client="app",server="db",le="0.16"} 0
		traces_service_graph_request_server_seconds_bucket{client="app",server="db",le="0.32"} 0
		traces_service_graph_request_server_seconds_bucket{client="app",server="db",le="0.64"} 0
		traces_service_graph_request_server_seconds_bucket{client="app",server="db",le="1.28"} 1
		traces_service_graph_request_server_seconds_bucket{client="app",server="db",le="2.56"} 3
		traces_service_graph_request_server_seconds_bucket{client="app",server="db",le="5.12"} 3
		traces_service_graph_request_server_seconds_bucket{client="app",server="db",le="10.24"} 3
		traces_service_graph_request_server_seconds_bucket{client="app",server="db",le="20.48"} 3
		traces_service_graph_request_server_seconds_bucket{client="app",server="db",le="+Inf"} 3
		traces_service_graph_request_server_seconds_sum{client="app",server="db"} 5
		traces_service_graph_request_server_seconds_count{client="app",server="db"} 3
		traces_service_graph_request_server_seconds_bucket{client="lb",server="app",le="0.01"} 0
		traces_service_graph_request_server_seconds_bucket{client="lb",server="app",le="0.02"} 0
		traces_service_graph_request_server_seconds_bucket{client="lb",server="app",le="0.04"} 0
		traces_service_graph_request_server_seconds_bucket{client="lb",server="app",le="0.08"} 0
		traces_service_graph_request_server_seconds_bucket{client="lb",server="app",le="0.16"} 0
		traces_service_graph_request_server_seconds_bucket{client="lb",server="app",le="0.32"} 0
		traces_service_graph_request_server_seconds_bucket{client="lb",server="app",le="0.64"} 0
		traces_service_graph_request_server_seconds_bucket{client="lb",server="app",le="1.28"} 1
		traces_service_graph_request_server_seconds_bucket{client="lb",server="app",le="2.56"} 2
		traces_service_graph_request_server_seconds_bucket{client="lb",server="app",le="5.12"} 3
		traces_service_graph_request_server_seconds_bucket{client="lb",server="app",le="10.24"} 3
		traces_service_graph_request_server_seconds_bucket{client="lb",server="app",le="20.48"} 3
		traces_service_graph_request_server_seconds_bucket{client="lb",server="app",le="+Inf"} 3
		traces_service_graph_request_server_seconds_sum{client="lb",server="app"} 6.2
		traces_service_graph_request_server_seconds_count{client="lb",server="app"} 3
		# HELP traces_service_graph_request_total Total count of requests between two nodes
		# TYPE traces_service_graph_request_total counter
		traces_service_graph_request_total{client="app",server="db"} 3
		traces_service_graph_request_total{client="lb",server="app"} 3
`
	droppedSpansCaseMetrics = `
        # HELP traces_service_graph_dropped_spans_total Total count of dropped spans
        # TYPE traces_service_graph_dropped_spans_total counter
        traces_service_graph_dropped_spans_total{client="",server="app"} 2
        traces_service_graph_dropped_spans_total{client="",server="db"} 3
        traces_service_graph_dropped_spans_total{client="app",server=""} 3
        traces_service_graph_dropped_spans_total{client="lb",server=""} 2
        # HELP traces_service_graph_request_client_seconds Time for a request between two nodes as seen from the client
        # TYPE traces_service_graph_request_client_seconds histogram
        traces_service_graph_request_client_seconds_bucket{client="lb",server="app",le="0.01"} 0
        traces_service_graph_request_client_seconds_bucket{client="lb",server="app",le="0.02"} 0
        traces_service_graph_request_client_seconds_bucket{client="lb",server="app",le="0.04"} 0
        traces_service_graph_request_client_seconds_bucket{client="lb",server="app",le="0.08"} 0
        traces_service_graph_request_client_seconds_bucket{client="lb",server="app",le="0.16"} 0
        traces_service_graph_request_client_seconds_bucket{client="lb",server="app",le="0.32"} 0
        traces_service_graph_request_client_seconds_bucket{client="lb",server="app",le="0.64"} 0
        traces_service_graph_request_client_seconds_bucket{client="lb",server="app",le="1.28"} 0
        traces_service_graph_request_client_seconds_bucket{client="lb",server="app",le="2.56"} 1
        traces_service_graph_request_client_seconds_bucket{client="lb",server="app",le="5.12"} 1
        traces_service_graph_request_client_seconds_bucket{client="lb",server="app",le="10.24"} 1
        traces_service_graph_request_client_seconds_bucket{client="lb",server="app",le="20.48"} 1
        traces_service_graph_request_client_seconds_bucket{client="lb",server="app",le="+Inf"} 1
        traces_service_graph_request_client_seconds_sum{client="lb",server="app"} 2.5
        traces_service_graph_request_client_seconds_count{client="lb",server="app"} 1
        # HELP traces_service_graph_request_failed_total Total count of failed requests between two nodes
        # TYPE traces_service_graph_request_failed_total counter
        traces_service_graph_request_failed_total{client="lb",server="app"} 1
        # HELP traces_service_graph_request_server_seconds Time for a request between two nodes as seen from the server
        # TYPE traces_service_graph_request_server_seconds histogram
        traces_service_graph_request_server_seconds_bucket{client="lb",server="app",le="0.01"} 0
        traces_service_graph_request_server_seconds_bucket{client="lb",server="app",le="0.02"} 0
        traces_service_graph_request_server_seconds_bucket{client="lb",server="app",le="0.04"} 0
        traces_service_graph_request_server_seconds_bucket{client="lb",server="app",le="0.08"} 0
        traces_service_graph_request_server_seconds_bucket{client="lb",server="app",le="0.16"} 0
        traces_service_graph_request_server_seconds_bucket{client="lb",server="app",le="0.32"} 0
        traces_service_graph_request_server_seconds_bucket{client="lb",server="app",le="0.64"} 0
        traces_service_graph_request_server_seconds_bucket{client="lb",server="app",le="1.28"} 1
        traces_service_graph_request_server_seconds_bucket{client="lb",server="app",le="2.56"} 1
        traces_service_graph_request_server_seconds_bucket{client="lb",server="app",le="5.12"} 1
        traces_service_graph_request_server_seconds_bucket{client="lb",server="app",le="10.24"} 1
        traces_service_graph_request_server_seconds_bucket{client="lb",server="app",le="20.48"} 1
        traces_service_graph_request_server_seconds_bucket{client="lb",server="app",le="+Inf"} 1
        traces_service_graph_request_server_seconds_sum{client="lb",server="app"} 1
        traces_service_graph_request_server_seconds_count{client="lb",server="app"} 1
        # HELP traces_service_graph_request_total Total count of requests between two nodes
        # TYPE traces_service_graph_request_total counter
        traces_service_graph_request_total{client="lb",server="app"} 1
`
	// has only one failed span instead of 2
	successCodesCaseMetrics = `
        # HELP traces_service_graph_request_client_seconds Time for a request between two nodes as seen from the client
        # TYPE traces_service_graph_request_client_seconds histogram
        traces_service_graph_request_client_seconds_bucket{client="app",server="db",le="0.01"} 0
        traces_service_graph_request_client_seconds_bucket{client="app",server="db",le="0.02"} 0
        traces_service_graph_request_client_seconds_bucket{client="app",server="db",le="0.04"} 0
        traces_service_graph_request_client_seconds_bucket{client="app",server="db",le="0.08"} 0
        traces_service_graph_request_client_seconds_bucket{client="app",server="db",le="0.16"} 0
        traces_service_graph_request_client_seconds_bucket{client="app",server="db",le="0.32"} 0
        traces_service_graph_request_client_seconds_bucket{client="app",server="db",le="0.64"} 0
        traces_service_graph_request_client_seconds_bucket{client="app",server="db",le="1.28"} 2
        traces_service_graph_request_client_seconds_bucket{client="app",server="db",le="2.56"} 3
        traces_service_graph_request_client_seconds_bucket{client="app",server="db",le="5.12"} 3
        traces_service_graph_request_client_seconds_bucket{client="app",server="db",le="10.24"} 3
        traces_service_graph_request_client_seconds_bucket{client="app",server="db",le="20.48"} 3
        traces_service_graph_request_client_seconds_bucket{client="app",server="db",le="+Inf"} 3
        traces_service_graph_request_client_seconds_sum{client="app",server="db"} 4.4
        traces_service_graph_request_client_seconds_count{client="app",server="db"} 3
        traces_service_graph_request_client_seconds_bucket{client="lb",server="app",le="0.01"} 0
        traces_service_graph_request_client_seconds_bucket{client="lb",server="app",le="0.02"} 0
        traces_service_graph_request_client_seconds_bucket{client="lb",server="app",le="0.04"} 0
        traces_service_graph_request_client_seconds_bucket{client="lb",server="app",le="0.08"} 0
        traces_service_graph_request_client_seconds_bucket{client="lb",server="app",le="0.16"} 0
        traces_service_graph_request_client_seconds_bucket{client="lb",server="app",le="0.32"} 0
        traces_service_graph_request_client_seconds_bucket{client="lb",server="app",le="0.64"} 0
        traces_service_graph_request_client_seconds_bucket{client="lb",server="app",le="1.28"} 0
        traces_service_graph_request_client_seconds_bucket{client="lb",server="app",le="2.56"} 2
        traces_service_graph_request_client_seconds_bucket{client="lb",server="app",le="5.12"} 3
        traces_service_graph_request_client_seconds_bucket{client="lb",server="app",le="10.24"} 3
        traces_service_graph_request_client_seconds_bucket{client="lb",server="app",le="20.48"} 3
        traces_service_graph_request_client_seconds_bucket{client="lb",server="app",le="+Inf"} 3
        traces_service_graph_request_client_seconds_sum{client="lb",server="app"} 7.8
        traces_service_graph_request_client_seconds_count{client="lb",server="app"} 3
        # HELP traces_service_graph_request_failed_total Total count of failed requests between two nodes
        # TYPE traces_service_graph_request_failed_total counter
        traces_service_graph_request_failed_total{client="lb",server="app"} 1
        # HELP traces_service_graph_request_server_seconds Time for a request between two nodes as seen from the server
        # TYPE traces_service_graph_request_server_seconds histogram
        traces_service_graph_request_server_seconds_bucket{client="app",server="db",le="0.01"} 0
        traces_service_graph_request_server_seconds_bucket{client="app",server="db",le="0.02"} 0
        traces_service_graph_request_server_seconds_bucket{client="app",server="db",le="0.04"} 0
        traces_service_graph_request_server_seconds_bucket{client="app",server="db",le="0.08"} 0
        traces_service_graph_request_server_seconds_bucket{client="app",server="db",le="0.16"} 0
        traces_service_graph_request_server_seconds_bucket{client="app",server="db",le="0.32"} 0
        traces_service_graph_request_server_seconds_bucket{client="app",server="db",le="0.64"} 0
        traces_service_graph_request_server_seconds_bucket{client="app",server="db",le="1.28"} 1
        traces_service_graph_request_server_seconds_bucket{client="app",server="db",le="2.56"} 3
        traces_service_graph_request_server_seconds_bucket{client="app",server="db",le="5.12"} 3
        traces_service_graph_request_server_seconds_bucket{client="app",server="db",le="10.24"} 3
        traces_service_graph_request_server_seconds_bucket{client="app",server="db",le="20.48"} 3
        traces_service_graph_request_server_seconds_bucket{client="app",server="db",le="+Inf"} 3
        traces_service_graph_request_server_seconds_sum{client="app",server="db"} 5
        traces_service_graph_request_server_seconds_count{client="app",server="db"} 3
        traces_service_graph_request_server_seconds_bucket{client="lb",server="app",le="0.01"} 0
        traces_service_graph_request_server_seconds_bucket{client="lb",server="app",le="0.02"} 0
        traces_service_graph_request_server_seconds_bucket{client="lb",server="app",le="0.04"} 0
        traces_service_graph_request_server_seconds_bucket{client="lb",server="app",le="0.08"} 0
        traces_service_graph_request_server_seconds_bucket{client="lb",server="app",le="0.16"} 0
        traces_service_graph_request_server_seconds_bucket{client="lb",server="app",le="0.32"} 0
        traces_service_graph_request_server_seconds_bucket{client="lb",server="app",le="0.64"} 0
        traces_service_graph_request_server_seconds_bucket{client="lb",server="app",le="1.28"} 1
        traces_service_graph_request_server_seconds_bucket{client="lb",server="app",le="2.56"} 2
        traces_service_graph_request_server_seconds_bucket{client="lb",server="app",le="5.12"} 3
        traces_service_graph_request_server_seconds_bucket{client="lb",server="app",le="10.24"} 3
        traces_service_graph_request_server_seconds_bucket{client="lb",server="app",le="20.48"} 3
        traces_service_graph_request_server_seconds_bucket{client="lb",server="app",le="+Inf"} 3
        traces_service_graph_request_server_seconds_sum{client="lb",server="app"} 6.2
        traces_service_graph_request_server_seconds_count{client="lb",server="app"} 3
        # HELP traces_service_graph_request_total Total count of requests between two nodes
        # TYPE traces_service_graph_request_total counter
        traces_service_graph_request_total{client="app",server="db"} 3
        traces_service_graph_request_total{client="lb",server="app"} 3
`
)

'''
'''--- pkg/traces/servicegraphprocessor/store.go ---
package servicegraphprocessor

import (
	"container/list"
	"errors"
	"sync"
	"time"
)

var (
	errTooManyItems = errors.New("too many items")
)

type storeCallback func(e *edge)

type store struct {
	l   *list.List
	mtx *sync.RWMutex
	m   map[string]*list.Element

	evictCallback storeCallback
	ttl           time.Duration
	maxItems      int
}

func newStore(ttl time.Duration, maxItems int, evictCallback storeCallback) *store {
	s := &store{
		l:   list.New(),
		mtx: &sync.RWMutex{},
		m:   make(map[string]*list.Element),

		evictCallback: evictCallback,
		ttl:           ttl,
		maxItems:      maxItems,
	}

	return s
}

func (s *store) len() int {
	s.mtx.RLock()
	defer s.mtx.RUnlock()

	return s.l.Len()
}

// shouldEvictHead checks if the oldest item (head of list) has expired and should be evicted.
// Returns true if the item has expired, false otherwise.
//
// Must be called under lock.
func (s *store) shouldEvictHead() bool {
	h := s.l.Front()
	if h == nil {
		return false
	}
	ts := h.Value.(*edge).expiration
	return ts < time.Now().Unix()
}

// evictHead removes the head from the store (and map).
// It also collects metrics for the evicted edge.
//
// Must be called under lock.
func (s *store) evictHead() {
	front := s.l.Front().Value.(*edge)
	s.evictEdge(front.key)
}

// evictEdge evicts and edge under lock
func (s *store) evictEdgeWithLock(key string) {
	s.mtx.Lock()
	defer s.mtx.Unlock()

	s.evictEdge(key)
}

// evictEdge removes the edge from the store (and map).
// It also collects metrics for the evicted edge.
//
// Must be called under lock.
func (s *store) evictEdge(key string) {
	ele := s.m[key]
	if ele == nil { // it may already have been processed
		return
	}

	edge := ele.Value.(*edge)
	s.evictCallback(edge)

	delete(s.m, key)
	s.l.Remove(ele)
}

// Fetches an edge from the store.
// If the edge doesn't exist, it creates a new one with the default TTL.
func (s *store) upsertEdge(k string, cb storeCallback) (*edge, error) {
	s.mtx.Lock()
	defer s.mtx.Unlock()

	if storedEdge, ok := s.m[k]; ok {
		edge := storedEdge.Value.(*edge)
		cb(edge)
		return edge, nil
	}

	if s.l.Len() >= s.maxItems {
		// todo: try to evict expired items
		return nil, errTooManyItems
	}

	newEdge := newEdge(k, s.ttl)
	ele := s.l.PushBack(newEdge)
	s.m[k] = ele
	cb(newEdge)

	return newEdge, nil
}

// expire evicts all expired items in the store.
func (s *store) expire() {
	s.mtx.RLock()
	if !s.shouldEvictHead() {
		s.mtx.RUnlock()
		return
	}
	s.mtx.RUnlock()

	s.mtx.Lock()
	defer s.mtx.Unlock()

	for s.shouldEvictHead() {
		s.evictHead()
	}
}

'''
'''--- pkg/traces/servicegraphprocessor/store_test.go ---
package servicegraphprocessor

import (
	"fmt"
	"testing"
	"time"

	"github.com/stretchr/testify/assert"
	"github.com/stretchr/testify/require"
)

var noopUpsertCb storeCallback = func(e *edge) {}

func TestStore_upsertEdge(t *testing.T) {
	const keyStr = "key"

	var cbCallCount int
	s := newStore(time.Hour, 1, func(e *edge) {
		cbCallCount++
	})
	assert.Equal(t, 0, s.len())

	_, err := s.upsertEdge(keyStr, func(e *edge) {})
	require.NoError(t, err)
	assert.Equal(t, 1, s.len())
	assert.False(t, s.shouldEvictHead()) // ttl is set to 1h
	assert.Equal(t, 0, cbCallCount)

	e := getEdge(s, keyStr)
	assert.NotNil(t, e)
	assert.Equal(t, keyStr, e.key)

	_, err = s.upsertEdge(keyStr+keyStr, func(e *edge) {})
	assert.Error(t, err)

	_, err = s.upsertEdge(keyStr, func(e *edge) {
		e.clientService = "client"
		e.serverService = "server"
		e.expiration = 0 // expire immediately
	})
	require.NoError(t, err)
	assert.Equal(t, 0, cbCallCount)

	e = getEdge(s, keyStr)
	assert.NotNil(t, e)
	assert.Equal(t, "client", e.clientService)
	assert.Equal(t, "server", e.serverService)
	assert.True(t, s.shouldEvictHead())

	s.evictHead()
	assert.Equal(t, 0, s.len())
	assert.Equal(t, 1, cbCallCount)
}

func TestStore_expire(t *testing.T) {
	keys := map[string]bool{}
	for i := 0; i < 100; i++ {
		keys[fmt.Sprintf("key-%d", i)] = true
	}

	// all new keys are immediately expired.
	s := newStore(-time.Second, 100, func(e *edge) {
		assert.True(t, keys[e.key])
	})

	for key := range keys {
		_, err := s.upsertEdge(key, noopUpsertCb)
		require.NoError(t, err)
	}

	s.expire()
	assert.Equal(t, 0, s.len())
}

func getEdge(s *store, k string) *edge {
	ele, ok := s.m[k]
	if !ok {
		return nil
	}
	return ele.Value.(*edge)
}

'''
'''--- pkg/traces/servicegraphprocessor/testdata/trace-sample.json ---
{
  "resource_spans":[
    {
      "resource":{
        "attributes":[
          {
            "key":"service.name",
            "value":{
              "stringValue":"lb"
            }
          },
          {
            "key":"cluster",
            "value":{
              "stringValue":"tns-demo"
            }
          },
          {
            "key":"namespace",
            "value":{
              "stringValue":"tns-demo"
            }
          },
          {
            "key":"opencensus.exporterversion",
            "value":{
              "stringValue":"Jaeger-Go-2.22.1"
            }
          },
          {
            "key":"host.name",
            "value":{
              "stringValue":"loadgen-6b59dff4c-jdkdk"
            }
          },
          {
            "key":"ip",
            "value":{
              "stringValue":"10.136.11.153"
            }
          },
          {
            "key":"client-uuid",
            "value":{
              "stringValue":"653fad9a76c115ac"
            }
          },
          {
            "key":"container",
            "value":{
              "stringValue":"loadgen"
            }
          },
          {
            "key":"pod",
            "value":{
              "stringValue":"loadgen-6b59dff4c-jdkdk"
            }
          }
        ]
      },
      "instrumentationLibrarySpans":[
        {
          "instrumentationLibrary":{

          },
          "spans":[
            {
              "traceId":"52500773347936975106164071472698",
              "spanId":"9164124892055152",
              "name":"HTTP Client",
              "startTimeUnixNano":"1626717505784699000",
              "endTimeUnixNano":"1626717505833874000",
              "attributes":[
                {
                  "key":"sampler.type",
                  "value":{
                    "stringValue":"const"
                  }
                },
                {
                  "key":"sampler.param",
                  "value":{
                    "boolValue":true
                  }
                }
              ],
              "status":{

              }
            },
            {
              "traceId":"52500773347936975106164071472698",
              "spanId":"3577375869085395",
              "parentSpanId":"9164124892055152",
              "name":"HTTP POST",
              "kind":"SPAN_KIND_CLIENT",
              "startTimeUnixNano":"1626717503329568000",
              "endTimeUnixNano":"1626717505829568000",
              "attributes":[
                {
                  "key":"http.status_code",
                  "value":{
                    "intValue":"302"
                  }
                },
                {
                  "key":"component",
                  "value":{
                    "stringValue":"net/http"
                  }
                },
                {
                  "key":"http.method",
                  "value":{
                    "stringValue":"POST"
                  }
                },
                {
                  "key":"http.url",
                  "value":{
                    "stringValue":"app:80"
                  }
                },
                {
                  "key":"net/http.reused",
                  "value":{
                    "boolValue":false
                  }
                },
                {
                  "key":"net/http.was_idle",
                  "value":{
                    "boolValue":false
                  }
                }
              ],
              "events":[
                {
                  "timeUnixNano":"1626717505784725000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"GetConn"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505784771000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"DNSStart"
                      }
                    },
                    {
                      "key":"host",
                      "value":{
                        "stringValue":"app"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505822812000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"DNSDone"
                      }
                    },
                    {
                      "key":"addr",
                      "value":{
                        "stringValue":"10.188.116.196"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505822821000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"ConnectStart"
                      }
                    },
                    {
                      "key":"network",
                      "value":{
                        "stringValue":"tcp"
                      }
                    },
                    {
                      "key":"addr",
                      "value":{
                        "stringValue":"10.188.116.196:80"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505822983000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"ConnectDone"
                      }
                    },
                    {
                      "key":"network",
                      "value":{
                        "stringValue":"tcp"
                      }
                    },
                    {
                      "key":"addr",
                      "value":{
                        "stringValue":"10.188.116.196:80"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505823035000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"GotConn"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505823116000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"WroteHeaders"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505823121000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"WroteRequest"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505829460000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"GotFirstResponseByte"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505829568000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"ClosedBody"
                      }
                    }
                  ]
                }
              ],
              "status":{
                "code":"STATUS_CODE_ERROR"
              }
            },
            {
              "traceId":"52500773347936975106164071472698",
              "spanId":"3915659542357933",
              "parentSpanId":"9164124892055152",
              "name":"HTTP GET",
              "kind":"SPAN_KIND_CLIENT",
              "startTimeUnixNano":"1626717504533933000",
              "endTimeUnixNano":"1626717505833933000",
              "attributes":[
                {
                  "key":"http.status_code",
                  "value":{
                    "intValue":"404"
                  }
                },
                {
                  "key":"component",
                  "value":{
                    "stringValue":"net/http"
                  }
                },
                {
                  "key":"http.method",
                  "value":{
                    "stringValue":"GET"
                  }
                },
                {
                  "key":"http.url",
                  "value":{
                    "stringValue":"app:80"
                  }
                },
                {
                  "key":"net/http.reused",
                  "value":{
                    "boolValue":false
                  }
                },
                {
                  "key":"net/http.was_idle",
                  "value":{
                    "boolValue":false
                  }
                }
              ],
              "events":[
                {
                  "timeUnixNano":"1626717505829603000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"GetConn"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505829642000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"DNSStart"
                      }
                    },
                    {
                      "key":"host",
                      "value":{
                        "stringValue":"app"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505830180000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"DNSDone"
                      }
                    },
                    {
                      "key":"addr",
                      "value":{
                        "stringValue":"10.188.116.196"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505830186000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"ConnectStart"
                      }
                    },
                    {
                      "key":"network",
                      "value":{
                        "stringValue":"tcp"
                      }
                    },
                    {
                      "key":"addr",
                      "value":{
                        "stringValue":"10.188.116.196:80"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505830301000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"ConnectDone"
                      }
                    },
                    {
                      "key":"network",
                      "value":{
                        "stringValue":"tcp"
                      }
                    },
                    {
                      "key":"addr",
                      "value":{
                        "stringValue":"10.188.116.196:80"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505830332000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"GotConn"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505830372000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"WroteHeaders"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505830373000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"WroteRequest"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505833806000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"GotFirstResponseByte"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505833933000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"ClosedBody"
                      }
                    }
                  ]
                }
              ],
              "status":{

              }
            }
          ]
        }
      ]
    },
    {
      "resource":{
        "attributes":[
          {
            "key":"service.name",
            "value":{
              "stringValue":"app"
            }
          },
          {
            "key":"cluster",
            "value":{
              "stringValue":"tns-demo"
            }
          },
          {
            "key":"namespace",
            "value":{
              "stringValue":"tns-demo"
            }
          },
          {
            "key":"opencensus.exporterversion",
            "value":{
              "stringValue":"Jaeger-Go-2.22.1"
            }
          },
          {
            "key":"host.name",
            "value":{
              "stringValue":"app-7c474df6bc-xpm6j"
            }
          },
          {
            "key":"ip",
            "value":{
              "stringValue":"10.136.11.151"
            }
          },
          {
            "key":"client-uuid",
            "value":{
              "stringValue":"264ce1d77c354156"
            }
          },
          {
            "key":"container",
            "value":{
              "stringValue":"app"
            }
          },
          {
            "key":"pod",
            "value":{
              "stringValue":"app-7c474df6bc-xpm6j"
            }
          }
        ]
      },
      "instrumentationLibrarySpans":[
        {
          "instrumentationLibrary":{

          },
          "spans":[
            {
              "traceId":"52500773347936975106164071472698",
              "spanId":"2272763103718280",
              "parentSpanId":"3577375869085395",
              "name":"HTTP POST - post",
              "kind":"SPAN_KIND_SERVER",
              "startTimeUnixNano":"1626717504829303000",
              "endTimeUnixNano":"1626717505829303000",
              "attributes":[
                {
                  "key":"http.status_code",
                  "value":{
                    "intValue":"302"
                  }
                },
                {
                  "key":"http.method",
                  "value":{
                    "stringValue":"POST"
                  }
                },
                {
                  "key":"http.url",
                  "value":{
                    "stringValue":"/post"
                  }
                },
                {
                  "key":"component",
                  "value":{
                    "stringValue":"net/http"
                  }
                }
              ],
              "status":{

              }
            },
            {
              "traceId":"52500773347936975106164071472698",
              "spanId":"3626796709293884",
              "parentSpanId":"2272763103718280",
              "name":"HTTP Client",
              "startTimeUnixNano":"1626717505823375000",
              "endTimeUnixNano":"1626717505829164000",
              "status":{

              }
            },
            {
              "traceId":"52500773347936975106164071472698",
              "spanId":"8403450133872377",
              "parentSpanId":"3626796709293884",
              "name":"HTTP POST",
              "kind":"SPAN_KIND_CLIENT",
              "startTimeUnixNano":"1626717504929264000",
              "endTimeUnixNano":"1626717505829264000",
              "attributes":[
                {
                  "key":"http.status_code",
                  "value":{
                    "intValue":"208"
                  }
                },
                {
                  "key":"component",
                  "value":{
                    "stringValue":"net/http"
                  }
                },
                {
                  "key":"http.method",
                  "value":{
                    "stringValue":"POST"
                  }
                },
                {
                  "key":"http.url",
                  "value":{
                    "stringValue":"db:80"
                  }
                },
                {
                  "key":"net/http.reused",
                  "value":{
                    "boolValue":false
                  }
                },
                {
                  "key":"net/http.was_idle",
                  "value":{
                    "boolValue":false
                  }
                }
              ],
              "events":[
                {
                  "timeUnixNano":"1626717505823393000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"GetConn"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505823439000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"DNSStart"
                      }
                    },
                    {
                      "key":"host",
                      "value":{
                        "stringValue":"db"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505827663000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"DNSDone"
                      }
                    },
                    {
                      "key":"addr",
                      "value":{
                        "stringValue":"10.188.106.8"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505827673000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"ConnectStart"
                      }
                    },
                    {
                      "key":"network",
                      "value":{
                        "stringValue":"tcp"
                      }
                    },
                    {
                      "key":"addr",
                      "value":{
                        "stringValue":"10.188.106.8:80"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505827797000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"ConnectDone"
                      }
                    },
                    {
                      "key":"network",
                      "value":{
                        "stringValue":"tcp"
                      }
                    },
                    {
                      "key":"addr",
                      "value":{
                        "stringValue":"10.188.106.8:80"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505827824000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"GotConn"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505827896000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"WroteHeaders"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505827901000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"WroteRequest"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505829057000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"GotFirstResponseByte"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505829264000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"ClosedBody"
                      }
                    }
                  ]
                }
              ],
              "status":{

              }
            },
            {
              "traceId":"52500773347936975106164071472698",
              "spanId":"7450148806355154",
              "parentSpanId":"3915659542357933",
              "name":"HTTP GET - root",
              "kind":"SPAN_KIND_SERVER",
              "startTimeUnixNano":"1626717503833939000",
              "endTimeUnixNano":"1626717505833939000",
              "attributes":[
                {
                  "key":"http.status_code",
                  "value":{
                    "intValue":"200"
                  }
                },
                {
                  "key":"http.method",
                  "value":{
                    "stringValue":"GET"
                  }
                },
                {
                  "key":"http.url",
                  "value":{
                    "stringValue":"/"
                  }
                },
                {
                  "key":"component",
                  "value":{
                    "stringValue":"net/http"
                  }
                }
              ],
              "status":{

              }
            },
            {
              "traceId":"52500773347936975106164071472698",
              "spanId":"6032713880928846",
              "parentSpanId":"7450148806355154",
              "name":"HTTP Client",
              "startTimeUnixNano":"1626717505830578000",
              "endTimeUnixNano":"1626717505833516000",
              "status":{

              }
            },
            {
              "traceId":"52500773347936975106164071472698",
              "spanId":"4935730267282470",
              "parentSpanId":"6032713880928846",
              "name":"HTTP GET",
              "kind":"SPAN_KIND_CLIENT",
              "startTimeUnixNano":"1626717504833879000",
              "endTimeUnixNano":"1626717505833879000",
              "attributes":[
                {
                  "key":"http.status_code",
                  "value":{
                    "intValue":"200"
                  }
                },
                {
                  "key":"component",
                  "value":{
                    "stringValue":"net/http"
                  }
                },
                {
                  "key":"http.method",
                  "value":{
                    "stringValue":"GET"
                  }
                },
                {
                  "key":"http.url",
                  "value":{
                    "stringValue":"db:80"
                  }
                },
                {
                  "key":"net/http.reused",
                  "value":{
                    "boolValue":false
                  }
                },
                {
                  "key":"net/http.was_idle",
                  "value":{
                    "boolValue":false
                  }
                }
              ],
              "events":[
                {
                  "timeUnixNano":"1626717505830596000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"GetConn"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505830647000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"DNSStart"
                      }
                    },
                    {
                      "key":"host",
                      "value":{
                        "stringValue":"db"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505832975000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"DNSDone"
                      }
                    },
                    {
                      "key":"addr",
                      "value":{
                        "stringValue":"10.188.106.8"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505832983000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"ConnectStart"
                      }
                    },
                    {
                      "key":"network",
                      "value":{
                        "stringValue":"tcp"
                      }
                    },
                    {
                      "key":"addr",
                      "value":{
                        "stringValue":"10.188.106.8:80"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505833096000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"ConnectDone"
                      }
                    },
                    {
                      "key":"network",
                      "value":{
                        "stringValue":"tcp"
                      }
                    },
                    {
                      "key":"addr",
                      "value":{
                        "stringValue":"10.188.106.8:80"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505833116000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"GotConn"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505833153000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"WroteHeaders"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505833154000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"WroteRequest"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505833460000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"GotFirstResponseByte"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505833880000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"ClosedBody"
                      }
                    }
                  ]
                }
              ],
              "status":{

              }
            }
          ]
        }
      ]
    },
    {
      "resource":{
        "attributes":[
          {
            "key":"service.name",
            "value":{
              "stringValue":"db"
            }
          },
          {
            "key":"cluster",
            "value":{
              "stringValue":"tns-demo"
            }
          },
          {
            "key":"namespace",
            "value":{
              "stringValue":"tns-demo"
            }
          },
          {
            "key":"opencensus.exporterversion",
            "value":{
              "stringValue":"Jaeger-Go-2.22.1"
            }
          },
          {
            "key":"host.name",
            "value":{
              "stringValue":"db-7488656cb4-m8ljw"
            }
          },
          {
            "key":"ip",
            "value":{
              "stringValue":"10.136.11.152"
            }
          },
          {
            "key":"client-uuid",
            "value":{
              "stringValue":"392a5faabe967ba3"
            }
          },
          {
            "key":"container",
            "value":{
              "stringValue":"db"
            }
          },
          {
            "key":"pod",
            "value":{
              "stringValue":"db-7488656cb4-m8ljw"
            }
          }
        ]
      },
      "instrumentationLibrarySpans":[
        {
          "instrumentationLibrary":{

          },
          "spans":[
            {
              "traceId":"52500773347936975106164071472698",
              "spanId":"4608118038743384",
              "parentSpanId":"8403450133872377",
              "name":"HTTP POST - post",
              "kind":"SPAN_KIND_SERVER",
              "startTimeUnixNano":"1626717504328961000",
              "endTimeUnixNano":"1626717505828961000",
              "attributes":[
                {
                  "key":"http.status_code",
                  "value":{
                    "intValue":"208"
                  }
                },
                {
                  "key":"http.method",
                  "value":{
                    "stringValue":"POST"
                  }
                },
                {
                  "key":"http.url",
                  "value":{
                    "stringValue":"/post"
                  }
                },
                {
                  "key":"component",
                  "value":{
                    "stringValue":"net/http"
                  }
                }
              ],
              "status":{

              }
            },
            {
              "traceId":"52500773347936975106164071472698",
              "spanId":"4012344826931146",
              "parentSpanId":"4935730267282470",
              "name":"HTTP GET - root",
              "kind":"SPAN_KIND_SERVER",
              "startTimeUnixNano":"1626717504833394000",
              "endTimeUnixNano":"1626717505833394000",
              "attributes":[
                {
                  "key":"http.status_code",
                  "value":{
                    "intValue":"200"
                  }
                },
                {
                  "key":"http.method",
                  "value":{
                    "stringValue":"GET"
                  }
                },
                {
                  "key":"http.url",
                  "value":{
                    "stringValue":"/"
                  }
                },
                {
                  "key":"component",
                  "value":{
                    "stringValue":"net/http"
                  }
                }
              ],
              "status":{

              }
            }
          ]
        }
      ]
    },
    {
      "resource":{
        "attributes":[
          {
            "key":"service.name",
            "value":{
              "stringValue":"lb"
            }
          },
          {
            "key":"cluster",
            "value":{
              "stringValue":"tns-demo"
            }
          },
          {
            "key":"namespace",
            "value":{
              "stringValue":"tns-demo"
            }
          },
          {
            "key":"opencensus.exporterversion",
            "value":{
              "stringValue":"Jaeger-Go-2.22.1"
            }
          },
          {
            "key":"host.name",
            "value":{
              "stringValue":"loadgen-6b59dff4c-jdkdk"
            }
          },
          {
            "key":"ip",
            "value":{
              "stringValue":"10.136.11.153"
            }
          },
          {
            "key":"client-uuid",
            "value":{
              "stringValue":"653fad9a76c115ac"
            }
          },
          {
            "key":"container",
            "value":{
              "stringValue":"loadgen"
            }
          },
          {
            "key":"pod",
            "value":{
              "stringValue":"loadgen-6b59dff4c-jdkdk"
            }
          }
        ]
      },
      "instrumentationLibrarySpans":[
        {
          "instrumentationLibrary":{

          },
          "spans":[
            {
              "traceId":"35800861220629394970098344564323",
              "spanId":"2879620033827981",
              "name":"HTTP Client",
              "startTimeUnixNano":"1626717505125848000",
              "endTimeUnixNano":"1626717505130325000",
              "attributes":[
                {
                  "key":"sampler.type",
                  "value":{
                    "stringValue":"const"
                  }
                },
                {
                  "key":"sampler.param",
                  "value":{
                    "boolValue":true
                  }
                }
              ],
              "status":{

              }
            },
            {
              "traceId":"35800861220629394970098344564323",
              "spanId":"0447366537724091",
              "parentSpanId":"2879620033827981",
              "name":"HTTP GET",
              "kind":"SPAN_KIND_CLIENT",
              "startTimeUnixNano":"1626717501130383000",
              "endTimeUnixNano":"1626717505130383000",
              "attributes":[
                {
                  "key":"http.status_code",
                  "value":{
                    "intValue":"200"
                  }
                },
                {
                  "key":"component",
                  "value":{
                    "stringValue":"net/http"
                  }
                },
                {
                  "key":"http.method",
                  "value":{
                    "stringValue":"GET"
                  }
                },
                {
                  "key":"http.url",
                  "value":{
                    "stringValue":"app:80"
                  }
                },
                {
                  "key":"net/http.reused",
                  "value":{
                    "boolValue":false
                  }
                },
                {
                  "key":"net/http.was_idle",
                  "value":{
                    "boolValue":false
                  }
                }
              ],
              "events":[
                {
                  "timeUnixNano":"1626717505125868000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"GetConn"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505125909000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"DNSStart"
                      }
                    },
                    {
                      "key":"host",
                      "value":{
                        "stringValue":"app"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505126450000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"DNSDone"
                      }
                    },
                    {
                      "key":"addr",
                      "value":{
                        "stringValue":"10.188.116.196"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505126455000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"ConnectStart"
                      }
                    },
                    {
                      "key":"network",
                      "value":{
                        "stringValue":"tcp"
                      }
                    },
                    {
                      "key":"addr",
                      "value":{
                        "stringValue":"10.188.116.196:80"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505126534000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"ConnectDone"
                      }
                    },
                    {
                      "key":"network",
                      "value":{
                        "stringValue":"tcp"
                      }
                    },
                    {
                      "key":"addr",
                      "value":{
                        "stringValue":"10.188.116.196:80"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505126556000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"GotConn"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505126585000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"WroteHeaders"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505126586000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"WroteRequest"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505130263000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"GotFirstResponseByte"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505130383000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"ClosedBody"
                      }
                    }
                  ]
                }
              ],
              "status":{

              }
            }
          ]
        }
      ]
    },
    {
      "resource":{
        "attributes":[
          {
            "key":"service.name",
            "value":{
              "stringValue":"app"
            }
          },
          {
            "key":"cluster",
            "value":{
              "stringValue":"tns-demo"
            }
          },
          {
            "key":"namespace",
            "value":{
              "stringValue":"tns-demo"
            }
          },
          {
            "key":"opencensus.exporterversion",
            "value":{
              "stringValue":"Jaeger-Go-2.22.1"
            }
          },
          {
            "key":"host.name",
            "value":{
              "stringValue":"app-7c474df6bc-xpm6j"
            }
          },
          {
            "key":"ip",
            "value":{
              "stringValue":"10.136.11.151"
            }
          },
          {
            "key":"client-uuid",
            "value":{
              "stringValue":"264ce1d77c354156"
            }
          },
          {
            "key":"pod",
            "value":{
              "stringValue":"app-7c474df6bc-xpm6j"
            }
          },
          {
            "key":"container",
            "value":{
              "stringValue":"app"
            }
          }
        ]
      },
      "instrumentationLibrarySpans":[
        {
          "instrumentationLibrary":{

          },
          "spans":[
            {
              "traceId":"35800861220629394970098344564323",
              "spanId":"9158319100742391",
              "parentSpanId":"0447366537724091",
              "name":"HTTP GET - root",
              "kind":"SPAN_KIND_SERVER",
              "startTimeUnixNano":"1626717501930340000",
              "endTimeUnixNano":"1626717505130340000",
              "attributes":[
                {
                  "key":"http.status_code",
                  "value":{
                    "intValue":"200"
                  }
                },
                {
                  "key":"http.method",
                  "value":{
                    "stringValue":"GET"
                  }
                },
                {
                  "key":"http.url",
                  "value":{
                    "stringValue":"/"
                  }
                },
                {
                  "key":"component",
                  "value":{
                    "stringValue":"net/http"
                  }
                }
              ],
              "status":{

              }
            },
            {
              "traceId":"35800861220629394970098344564323",
              "spanId":"7640553108230474",
              "parentSpanId":"9158319100742391",
              "name":"HTTP Client",
              "startTimeUnixNano":"1626717505126741000",
              "endTimeUnixNano":"1626717505130038000",
              "status":{

              }
            },
            {
              "traceId":"35800861220629394970098344564323",
              "spanId":"5299662922852552",
              "parentSpanId":"7640553108230474",
              "name":"HTTP GET",
              "kind":"SPAN_KIND_CLIENT",
              "startTimeUnixNano":"1626717502630304000",
              "endTimeUnixNano":"1626717505130304000",
              "attributes":[
                {
                  "key":"http.status_code",
                  "value":{
                    "intValue":"200"
                  }
                },
                {
                  "key":"component",
                  "value":{
                    "stringValue":"net/http"
                  }
                },
                {
                  "key":"http.method",
                  "value":{
                    "stringValue":"GET"
                  }
                },
                {
                  "key":"http.url",
                  "value":{
                    "stringValue":"db:80"
                  }
                },
                {
                  "key":"net/http.reused",
                  "value":{
                    "boolValue":false
                  }
                },
                {
                  "key":"net/http.was_idle",
                  "value":{
                    "boolValue":false
                  }
                }
              ],
              "events":[
                {
                  "timeUnixNano":"1626717505126754000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"GetConn"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505126800000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"DNSStart"
                      }
                    },
                    {
                      "key":"host",
                      "value":{
                        "stringValue":"db"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505129605000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"DNSDone"
                      }
                    },
                    {
                      "key":"addr",
                      "value":{
                        "stringValue":"10.188.106.8"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505129609000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"ConnectStart"
                      }
                    },
                    {
                      "key":"network",
                      "value":{
                        "stringValue":"tcp"
                      }
                    },
                    {
                      "key":"addr",
                      "value":{
                        "stringValue":"10.188.106.8:80"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505129678000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"ConnectDone"
                      }
                    },
                    {
                      "key":"network",
                      "value":{
                        "stringValue":"tcp"
                      }
                    },
                    {
                      "key":"addr",
                      "value":{
                        "stringValue":"10.188.106.8:80"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505129695000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"GotConn"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505129727000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"WroteHeaders"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505129727000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"WroteRequest"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505129965000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"GotFirstResponseByte"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505130303000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"ClosedBody"
                      }
                    }
                  ]
                }
              ],
              "status":{

              }
            }
          ]
        }
      ]
    },
    {
      "resource":{
        "attributes":[
          {
            "key":"service.name",
            "value":{
              "stringValue":"db"
            }
          },
          {
            "key":"cluster",
            "value":{
              "stringValue":"tns-demo"
            }
          },
          {
            "key":"namespace",
            "value":{
              "stringValue":"tns-demo"
            }
          },
          {
            "key":"opencensus.exporterversion",
            "value":{
              "stringValue":"Jaeger-Go-2.22.1"
            }
          },
          {
            "key":"host.name",
            "value":{
              "stringValue":"db-7488656cb4-m8ljw"
            }
          },
          {
            "key":"ip",
            "value":{
              "stringValue":"10.136.11.152"
            }
          },
          {
            "key":"client-uuid",
            "value":{
              "stringValue":"392a5faabe967ba3"
            }
          },
          {
            "key":"container",
            "value":{
              "stringValue":"db"
            }
          },
          {
            "key":"pod",
            "value":{
              "stringValue":"db-7488656cb4-m8ljw"
            }
          }
        ]
      },
      "instrumentationLibrarySpans":[
        {
          "instrumentationLibrary":{

          },
          "spans":[
            {
              "traceId":"35800861220629394970098344564323",
              "spanId":"7696854443843100",
              "parentSpanId":"5299662922852552",
              "name":"HTTP GET - root",
              "kind":"SPAN_KIND_SERVER",
              "startTimeUnixNano":"1626717502629891000",
              "endTimeUnixNano":"1626717505129891000",
              "attributes":[
                {
                  "key":"http.status_code",
                  "value":{
                    "intValue":"200"
                  }
                },
                {
                  "key":"http.method",
                  "value":{
                    "stringValue":"GET"
                  }
                },
                {
                  "key":"http.url",
                  "value":{
                    "stringValue":"/"
                  }
                },
                {
                  "key":"component",
                  "value":{
                    "stringValue":"net/http"
                  }
                }
              ],
              "status":{

              }
            }
          ]
        }
      ]
    }
  ]
}

'''
'''--- pkg/traces/servicegraphprocessor/testdata/unpaired-trace-sample.json ---
{
  "resource_spans":[
    {
      "resource":{
        "attributes":[
          {
            "key":"service.name",
            "value":{
              "stringValue":"lb"
            }
          },
          {
            "key":"cluster",
            "value":{
              "stringValue":"tns-demo"
            }
          },
          {
            "key":"namespace",
            "value":{
              "stringValue":"tns-demo"
            }
          },
          {
            "key":"opencensus.exporterversion",
            "value":{
              "stringValue":"Jaeger-Go-2.22.1"
            }
          },
          {
            "key":"host.name",
            "value":{
              "stringValue":"loadgen-6b59dff4c-jdkdk"
            }
          },
          {
            "key":"ip",
            "value":{
              "stringValue":"10.136.11.153"
            }
          },
          {
            "key":"client-uuid",
            "value":{
              "stringValue":"653fad9a76c115ac"
            }
          },
          {
            "key":"container",
            "value":{
              "stringValue":"loadgen"
            }
          },
          {
            "key":"pod",
            "value":{
              "stringValue":"loadgen-6b59dff4c-jdkdk"
            }
          }
        ]
      },
      "instrumentationLibrarySpans":[
        {
          "instrumentationLibrary":{

          },
          "spans":[
            {
              "traceId":"36902246203382902720382243842825",
              "spanId":"5660545186624696",
              "name":"HTTP Client",
              "startTimeUnixNano":"1626717505784699000",
              "endTimeUnixNano":"1626717505833874000",
              "attributes":[
                {
                  "key":"sampler.type",
                  "value":{
                    "stringValue":"const"
                  }
                },
                {
                  "key":"sampler.param",
                  "value":{
                    "boolValue":true
                  }
                }
              ],
              "status":{

              }
            },
            {
              "traceId":"36902246203382902720382243842825",
              "spanId":"5456342604545149",
              "name":"HTTP POST",
              "kind":"SPAN_KIND_CLIENT",
              "startTimeUnixNano":"1626717503329568000",
              "endTimeUnixNano":"1626717505829568000",
              "attributes":[
                {
                  "key":"http.status_code",
                  "value":{
                    "intValue":"302"
                  }
                },
                {
                  "key":"component",
                  "value":{
                    "stringValue":"net/http"
                  }
                },
                {
                  "key":"http.method",
                  "value":{
                    "stringValue":"POST"
                  }
                },
                {
                  "key":"http.url",
                  "value":{
                    "stringValue":"app:80"
                  }
                },
                {
                  "key":"net/http.reused",
                  "value":{
                    "boolValue":false
                  }
                },
                {
                  "key":"net/http.was_idle",
                  "value":{
                    "boolValue":false
                  }
                }
              ],
              "events":[
                {
                  "timeUnixNano":"1626717505784725000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"GetConn"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505784771000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"DNSStart"
                      }
                    },
                    {
                      "key":"host",
                      "value":{
                        "stringValue":"app"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505822812000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"DNSDone"
                      }
                    },
                    {
                      "key":"addr",
                      "value":{
                        "stringValue":"10.188.116.196"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505822821000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"ConnectStart"
                      }
                    },
                    {
                      "key":"network",
                      "value":{
                        "stringValue":"tcp"
                      }
                    },
                    {
                      "key":"addr",
                      "value":{
                        "stringValue":"10.188.116.196:80"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505822983000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"ConnectDone"
                      }
                    },
                    {
                      "key":"network",
                      "value":{
                        "stringValue":"tcp"
                      }
                    },
                    {
                      "key":"addr",
                      "value":{
                        "stringValue":"10.188.116.196:80"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505823035000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"GotConn"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505823116000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"WroteHeaders"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505823121000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"WroteRequest"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505829460000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"GotFirstResponseByte"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505829568000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"ClosedBody"
                      }
                    }
                  ]
                }
              ],
              "status":{

              }
            },
            {
              "traceId":"36902246203382902720382243842825",
              "spanId":"8322887203696598",
              "name":"HTTP GET",
              "kind":"SPAN_KIND_CLIENT",
              "startTimeUnixNano":"1626717504533933000",
              "endTimeUnixNano":"1626717505833933000",
              "attributes":[
                {
                  "key":"http.status_code",
                  "value":{
                    "intValue":"200"
                  }
                },
                {
                  "key":"component",
                  "value":{
                    "stringValue":"net/http"
                  }
                },
                {
                  "key":"http.method",
                  "value":{
                    "stringValue":"GET"
                  }
                },
                {
                  "key":"http.url",
                  "value":{
                    "stringValue":"app:80"
                  }
                },
                {
                  "key":"net/http.reused",
                  "value":{
                    "boolValue":false
                  }
                },
                {
                  "key":"net/http.was_idle",
                  "value":{
                    "boolValue":false
                  }
                }
              ],
              "events":[
                {
                  "timeUnixNano":"1626717505829603000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"GetConn"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505829642000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"DNSStart"
                      }
                    },
                    {
                      "key":"host",
                      "value":{
                        "stringValue":"app"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505830180000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"DNSDone"
                      }
                    },
                    {
                      "key":"addr",
                      "value":{
                        "stringValue":"10.188.116.196"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505830186000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"ConnectStart"
                      }
                    },
                    {
                      "key":"network",
                      "value":{
                        "stringValue":"tcp"
                      }
                    },
                    {
                      "key":"addr",
                      "value":{
                        "stringValue":"10.188.116.196:80"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505830301000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"ConnectDone"
                      }
                    },
                    {
                      "key":"network",
                      "value":{
                        "stringValue":"tcp"
                      }
                    },
                    {
                      "key":"addr",
                      "value":{
                        "stringValue":"10.188.116.196:80"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505830332000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"GotConn"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505830372000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"WroteHeaders"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505830373000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"WroteRequest"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505833806000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"GotFirstResponseByte"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505833933000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"ClosedBody"
                      }
                    }
                  ]
                }
              ],
              "status":{

              }
            }
          ]
        }
      ]
    },
    {
      "resource":{
        "attributes":[
          {
            "key":"service.name",
            "value":{
              "stringValue":"app"
            }
          },
          {
            "key":"cluster",
            "value":{
              "stringValue":"tns-demo"
            }
          },
          {
            "key":"namespace",
            "value":{
              "stringValue":"tns-demo"
            }
          },
          {
            "key":"opencensus.exporterversion",
            "value":{
              "stringValue":"Jaeger-Go-2.22.1"
            }
          },
          {
            "key":"host.name",
            "value":{
              "stringValue":"app-7c474df6bc-xpm6j"
            }
          },
          {
            "key":"ip",
            "value":{
              "stringValue":"10.136.11.151"
            }
          },
          {
            "key":"client-uuid",
            "value":{
              "stringValue":"264ce1d77c354156"
            }
          },
          {
            "key":"container",
            "value":{
              "stringValue":"app"
            }
          },
          {
            "key":"pod",
            "value":{
              "stringValue":"app-7c474df6bc-xpm6j"
            }
          }
        ]
      },
      "instrumentationLibrarySpans":[
        {
          "instrumentationLibrary":{

          },
          "spans":[
            {
              "traceId":"36902246203382902720382243842825",
              "spanId":"5951100107364269",
              "name":"HTTP POST - post",
              "kind":"SPAN_KIND_SERVER",
              "startTimeUnixNano":"1626717504829303000",
              "endTimeUnixNano":"1626717505829303000",
              "attributes":[
                {
                  "key":"http.status_code",
                  "value":{
                    "intValue":"302"
                  }
                },
                {
                  "key":"http.method",
                  "value":{
                    "stringValue":"POST"
                  }
                },
                {
                  "key":"http.url",
                  "value":{
                    "stringValue":"/post"
                  }
                },
                {
                  "key":"component",
                  "value":{
                    "stringValue":"net/http"
                  }
                }
              ],
              "status":{

              }
            },
            {
              "traceId":"36902246203382902720382243842825",
              "spanId":"5072122083888781",
              "name":"HTTP Client",
              "startTimeUnixNano":"1626717505823375000",
              "endTimeUnixNano":"1626717505829164000",
              "status":{

              }
            },
            {
              "traceId":"36902246203382902720382243842825",
              "spanId":"2764342190725055",
              "name":"HTTP POST",
              "kind":"SPAN_KIND_CLIENT",
              "startTimeUnixNano":"1626717504929264000",
              "endTimeUnixNano":"1626717505829264000",
              "attributes":[
                {
                  "key":"http.status_code",
                  "value":{
                    "intValue":"208"
                  }
                },
                {
                  "key":"component",
                  "value":{
                    "stringValue":"net/http"
                  }
                },
                {
                  "key":"http.method",
                  "value":{
                    "stringValue":"POST"
                  }
                },
                {
                  "key":"http.url",
                  "value":{
                    "stringValue":"db:80"
                  }
                },
                {
                  "key":"net/http.reused",
                  "value":{
                    "boolValue":false
                  }
                },
                {
                  "key":"net/http.was_idle",
                  "value":{
                    "boolValue":false
                  }
                }
              ],
              "events":[
                {
                  "timeUnixNano":"1626717505823393000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"GetConn"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505823439000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"DNSStart"
                      }
                    },
                    {
                      "key":"host",
                      "value":{
                        "stringValue":"db"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505827663000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"DNSDone"
                      }
                    },
                    {
                      "key":"addr",
                      "value":{
                        "stringValue":"10.188.106.8"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505827673000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"ConnectStart"
                      }
                    },
                    {
                      "key":"network",
                      "value":{
                        "stringValue":"tcp"
                      }
                    },
                    {
                      "key":"addr",
                      "value":{
                        "stringValue":"10.188.106.8:80"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505827797000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"ConnectDone"
                      }
                    },
                    {
                      "key":"network",
                      "value":{
                        "stringValue":"tcp"
                      }
                    },
                    {
                      "key":"addr",
                      "value":{
                        "stringValue":"10.188.106.8:80"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505827824000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"GotConn"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505827896000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"WroteHeaders"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505827901000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"WroteRequest"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505829057000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"GotFirstResponseByte"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505829264000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"ClosedBody"
                      }
                    }
                  ]
                }
              ],
              "status":{

              }
            },
            {
              "traceId":"36902246203382902720382243842825",
              "spanId":"3367986519922282",
              "name":"HTTP GET - root",
              "kind":"SPAN_KIND_SERVER",
              "startTimeUnixNano":"1626717503833939000",
              "endTimeUnixNano":"1626717505833939000",
              "attributes":[
                {
                  "key":"http.status_code",
                  "value":{
                    "intValue":"200"
                  }
                },
                {
                  "key":"http.method",
                  "value":{
                    "stringValue":"GET"
                  }
                },
                {
                  "key":"http.url",
                  "value":{
                    "stringValue":"/"
                  }
                },
                {
                  "key":"component",
                  "value":{
                    "stringValue":"net/http"
                  }
                }
              ],
              "status":{

              }
            },
            {
              "traceId":"36902246203382902720382243842825",
              "spanId":"5856608990508121",
              "name":"HTTP Client",
              "startTimeUnixNano":"1626717505830578000",
              "endTimeUnixNano":"1626717505833516000",
              "status":{

              }
            },
            {
              "traceId":"36902246203382902720382243842825",
              "spanId":"4013938741401082",
              "name":"HTTP GET",
              "kind":"SPAN_KIND_CLIENT",
              "startTimeUnixNano":"1626717504833879000",
              "endTimeUnixNano":"1626717505833879000",
              "attributes":[
                {
                  "key":"http.status_code",
                  "value":{
                    "intValue":"200"
                  }
                },
                {
                  "key":"component",
                  "value":{
                    "stringValue":"net/http"
                  }
                },
                {
                  "key":"http.method",
                  "value":{
                    "stringValue":"GET"
                  }
                },
                {
                  "key":"http.url",
                  "value":{
                    "stringValue":"db:80"
                  }
                },
                {
                  "key":"net/http.reused",
                  "value":{
                    "boolValue":false
                  }
                },
                {
                  "key":"net/http.was_idle",
                  "value":{
                    "boolValue":false
                  }
                }
              ],
              "events":[
                {
                  "timeUnixNano":"1626717505830596000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"GetConn"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505830647000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"DNSStart"
                      }
                    },
                    {
                      "key":"host",
                      "value":{
                        "stringValue":"db"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505832975000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"DNSDone"
                      }
                    },
                    {
                      "key":"addr",
                      "value":{
                        "stringValue":"10.188.106.8"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505832983000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"ConnectStart"
                      }
                    },
                    {
                      "key":"network",
                      "value":{
                        "stringValue":"tcp"
                      }
                    },
                    {
                      "key":"addr",
                      "value":{
                        "stringValue":"10.188.106.8:80"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505833096000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"ConnectDone"
                      }
                    },
                    {
                      "key":"network",
                      "value":{
                        "stringValue":"tcp"
                      }
                    },
                    {
                      "key":"addr",
                      "value":{
                        "stringValue":"10.188.106.8:80"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505833116000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"GotConn"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505833153000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"WroteHeaders"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505833154000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"WroteRequest"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505833460000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"GotFirstResponseByte"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505833880000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"ClosedBody"
                      }
                    }
                  ]
                }
              ],
              "status":{

              }
            }
          ]
        }
      ]
    },
    {
      "resource":{
        "attributes":[
          {
            "key":"service.name",
            "value":{
              "stringValue":"db"
            }
          },
          {
            "key":"cluster",
            "value":{
              "stringValue":"tns-demo"
            }
          },
          {
            "key":"namespace",
            "value":{
              "stringValue":"tns-demo"
            }
          },
          {
            "key":"opencensus.exporterversion",
            "value":{
              "stringValue":"Jaeger-Go-2.22.1"
            }
          },
          {
            "key":"host.name",
            "value":{
              "stringValue":"db-7488656cb4-m8ljw"
            }
          },
          {
            "key":"ip",
            "value":{
              "stringValue":"10.136.11.152"
            }
          },
          {
            "key":"client-uuid",
            "value":{
              "stringValue":"392a5faabe967ba3"
            }
          },
          {
            "key":"container",
            "value":{
              "stringValue":"db"
            }
          },
          {
            "key":"pod",
            "value":{
              "stringValue":"db-7488656cb4-m8ljw"
            }
          }
        ]
      },
      "instrumentationLibrarySpans":[
        {
          "instrumentationLibrary":{

          },
          "spans":[
            {
              "traceId":"36902246203382902720382243842825",
              "spanId":"4838352157694212",
              "name":"HTTP POST - post",
              "kind":"SPAN_KIND_SERVER",
              "startTimeUnixNano":"1626717504328961000",
              "endTimeUnixNano":"1626717505828961000",
              "attributes":[
                {
                  "key":"http.status_code",
                  "value":{
                    "intValue":"208"
                  }
                },
                {
                  "key":"http.method",
                  "value":{
                    "stringValue":"POST"
                  }
                },
                {
                  "key":"http.url",
                  "value":{
                    "stringValue":"/post"
                  }
                },
                {
                  "key":"component",
                  "value":{
                    "stringValue":"net/http"
                  }
                }
              ],
              "status":{

              }
            },
            {
              "traceId":"36902246203382902720382243842825",
              "spanId":"9720734159949678",
              "name":"HTTP GET - root",
              "kind":"SPAN_KIND_SERVER",
              "startTimeUnixNano":"1626717504833394000",
              "endTimeUnixNano":"1626717505833394000",
              "attributes":[
                {
                  "key":"http.status_code",
                  "value":{
                    "intValue":"200"
                  }
                },
                {
                  "key":"http.method",
                  "value":{
                    "stringValue":"GET"
                  }
                },
                {
                  "key":"http.url",
                  "value":{
                    "stringValue":"/"
                  }
                },
                {
                  "key":"component",
                  "value":{
                    "stringValue":"net/http"
                  }
                }
              ],
              "status":{

              }
            }
          ]
        }
      ]
    },
    {
      "resource":{
        "attributes":[
          {
            "key":"service.name",
            "value":{
              "stringValue":"lb"
            }
          },
          {
            "key":"cluster",
            "value":{
              "stringValue":"tns-demo"
            }
          },
          {
            "key":"namespace",
            "value":{
              "stringValue":"tns-demo"
            }
          },
          {
            "key":"opencensus.exporterversion",
            "value":{
              "stringValue":"Jaeger-Go-2.22.1"
            }
          },
          {
            "key":"host.name",
            "value":{
              "stringValue":"loadgen-6b59dff4c-jdkdk"
            }
          },
          {
            "key":"ip",
            "value":{
              "stringValue":"10.136.11.153"
            }
          },
          {
            "key":"client-uuid",
            "value":{
              "stringValue":"653fad9a76c115ac"
            }
          },
          {
            "key":"container",
            "value":{
              "stringValue":"loadgen"
            }
          },
          {
            "key":"pod",
            "value":{
              "stringValue":"loadgen-6b59dff4c-jdkdk"
            }
          }
        ]
      },
      "instrumentationLibrarySpans":[
        {
          "instrumentationLibrary":{

          },
          "spans":[
            {
              "traceId":"20208504994066352513559639423186",
              "spanId":"4160455908364640",
              "name":"HTTP Client",
              "startTimeUnixNano":"1626717505125848000",
              "endTimeUnixNano":"1626717505130325000",
              "attributes":[
                {
                  "key":"sampler.type",
                  "value":{
                    "stringValue":"const"
                  }
                },
                {
                  "key":"sampler.param",
                  "value":{
                    "boolValue":true
                  }
                }
              ],
              "status":{

              }
            },
            {
              "traceId":"20208504994066352513559639423186",
              "spanId":"7530837608800278",
              "name":"HTTP GET",
              "kind":"SPAN_KIND_CLIENT",
              "startTimeUnixNano":"1626717501130383000",
              "endTimeUnixNano":"1626717505130383000",
              "attributes":[
                {
                  "key":"http.status_code",
                  "value":{
                    "intValue":"200"
                  }
                },
                {
                  "key":"component",
                  "value":{
                    "stringValue":"net/http"
                  }
                },
                {
                  "key":"http.method",
                  "value":{
                    "stringValue":"GET"
                  }
                },
                {
                  "key":"http.url",
                  "value":{
                    "stringValue":"app:80"
                  }
                },
                {
                  "key":"net/http.reused",
                  "value":{
                    "boolValue":false
                  }
                },
                {
                  "key":"net/http.was_idle",
                  "value":{
                    "boolValue":false
                  }
                }
              ],
              "events":[
                {
                  "timeUnixNano":"1626717505125868000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"GetConn"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505125909000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"DNSStart"
                      }
                    },
                    {
                      "key":"host",
                      "value":{
                        "stringValue":"app"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505126450000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"DNSDone"
                      }
                    },
                    {
                      "key":"addr",
                      "value":{
                        "stringValue":"10.188.116.196"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505126455000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"ConnectStart"
                      }
                    },
                    {
                      "key":"network",
                      "value":{
                        "stringValue":"tcp"
                      }
                    },
                    {
                      "key":"addr",
                      "value":{
                        "stringValue":"10.188.116.196:80"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505126534000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"ConnectDone"
                      }
                    },
                    {
                      "key":"network",
                      "value":{
                        "stringValue":"tcp"
                      }
                    },
                    {
                      "key":"addr",
                      "value":{
                        "stringValue":"10.188.116.196:80"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505126556000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"GotConn"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505126585000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"WroteHeaders"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505126586000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"WroteRequest"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505130263000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"GotFirstResponseByte"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505130383000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"ClosedBody"
                      }
                    }
                  ]
                }
              ],
              "status":{

              }
            }
          ]
        }
      ]
    },
    {
      "resource":{
        "attributes":[
          {
            "key":"service.name",
            "value":{
              "stringValue":"app"
            }
          },
          {
            "key":"cluster",
            "value":{
              "stringValue":"tns-demo"
            }
          },
          {
            "key":"namespace",
            "value":{
              "stringValue":"tns-demo"
            }
          },
          {
            "key":"opencensus.exporterversion",
            "value":{
              "stringValue":"Jaeger-Go-2.22.1"
            }
          },
          {
            "key":"host.name",
            "value":{
              "stringValue":"app-7c474df6bc-xpm6j"
            }
          },
          {
            "key":"ip",
            "value":{
              "stringValue":"10.136.11.151"
            }
          },
          {
            "key":"client-uuid",
            "value":{
              "stringValue":"264ce1d77c354156"
            }
          },
          {
            "key":"pod",
            "value":{
              "stringValue":"app-7c474df6bc-xpm6j"
            }
          },
          {
            "key":"container",
            "value":{
              "stringValue":"app"
            }
          }
        ]
      },
      "instrumentationLibrarySpans":[
        {
          "instrumentationLibrary":{

          },
          "spans":[
            {
              "traceId":"20208504994066352513559639423186",
              "spanId":"3444024849500281",
              "name":"HTTP GET - root",
              "kind":"SPAN_KIND_SERVER",
              "startTimeUnixNano":"1626717501930340000",
              "endTimeUnixNano":"1626717505130340000",
              "attributes":[
                {
                  "key":"http.status_code",
                  "value":{
                    "intValue":"200"
                  }
                },
                {
                  "key":"http.method",
                  "value":{
                    "stringValue":"GET"
                  }
                },
                {
                  "key":"http.url",
                  "value":{
                    "stringValue":"/"
                  }
                },
                {
                  "key":"component",
                  "value":{
                    "stringValue":"net/http"
                  }
                }
              ],
              "status":{

              }
            },
            {
              "traceId":"20208504994066352513559639423186",
              "spanId":"1334625654039117",
              "name":"HTTP Client",
              "startTimeUnixNano":"1626717505126741000",
              "endTimeUnixNano":"1626717505130038000",
              "status":{

              }
            },
            {
              "traceId":"20208504994066352513559639423186",
              "spanId":"6591907790384340",
              "name":"HTTP GET",
              "kind":"SPAN_KIND_CLIENT",
              "startTimeUnixNano":"1626717502630304000",
              "endTimeUnixNano":"1626717505130304000",
              "attributes":[
                {
                  "key":"http.status_code",
                  "value":{
                    "intValue":"200"
                  }
                },
                {
                  "key":"component",
                  "value":{
                    "stringValue":"net/http"
                  }
                },
                {
                  "key":"http.method",
                  "value":{
                    "stringValue":"GET"
                  }
                },
                {
                  "key":"http.url",
                  "value":{
                    "stringValue":"db:80"
                  }
                },
                {
                  "key":"net/http.reused",
                  "value":{
                    "boolValue":false
                  }
                },
                {
                  "key":"net/http.was_idle",
                  "value":{
                    "boolValue":false
                  }
                }
              ],
              "events":[
                {
                  "timeUnixNano":"1626717505126754000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"GetConn"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505126800000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"DNSStart"
                      }
                    },
                    {
                      "key":"host",
                      "value":{
                        "stringValue":"db"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505129605000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"DNSDone"
                      }
                    },
                    {
                      "key":"addr",
                      "value":{
                        "stringValue":"10.188.106.8"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505129609000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"ConnectStart"
                      }
                    },
                    {
                      "key":"network",
                      "value":{
                        "stringValue":"tcp"
                      }
                    },
                    {
                      "key":"addr",
                      "value":{
                        "stringValue":"10.188.106.8:80"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505129678000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"ConnectDone"
                      }
                    },
                    {
                      "key":"network",
                      "value":{
                        "stringValue":"tcp"
                      }
                    },
                    {
                      "key":"addr",
                      "value":{
                        "stringValue":"10.188.106.8:80"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505129695000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"GotConn"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505129727000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"WroteHeaders"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505129727000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"WroteRequest"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505129965000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"GotFirstResponseByte"
                      }
                    }
                  ]
                },
                {
                  "timeUnixNano":"1626717505130303000",
                  "attributes":[
                    {
                      "key":"event",
                      "value":{
                        "stringValue":"ClosedBody"
                      }
                    }
                  ]
                }
              ],
              "status":{

              }
            }
          ]
        }
      ]
    },
    {
      "resource":{
        "attributes":[
          {
            "key":"service.name",
            "value":{
              "stringValue":"db"
            }
          },
          {
            "key":"cluster",
            "value":{
              "stringValue":"tns-demo"
            }
          },
          {
            "key":"namespace",
            "value":{
              "stringValue":"tns-demo"
            }
          },
          {
            "key":"opencensus.exporterversion",
            "value":{
              "stringValue":"Jaeger-Go-2.22.1"
            }
          },
          {
            "key":"host.name",
            "value":{
              "stringValue":"db-7488656cb4-m8ljw"
            }
          },
          {
            "key":"ip",
            "value":{
              "stringValue":"10.136.11.152"
            }
          },
          {
            "key":"client-uuid",
            "value":{
              "stringValue":"392a5faabe967ba3"
            }
          },
          {
            "key":"container",
            "value":{
              "stringValue":"db"
            }
          },
          {
            "key":"pod",
            "value":{
              "stringValue":"db-7488656cb4-m8ljw"
            }
          }
        ]
      },
      "instrumentationLibrarySpans":[
        {
          "instrumentationLibrary":{

          },
          "spans":[
            {
              "traceId":"20208504994066352513559639423186",
              "spanId":"3560101798060843",
              "name":"HTTP GET - root",
              "kind":"SPAN_KIND_SERVER",
              "startTimeUnixNano":"1626717502629891000",
              "endTimeUnixNano":"1626717505129891000",
              "attributes":[
                {
                  "key":"http.status_code",
                  "value":{
                    "intValue":"200"
                  }
                },
                {
                  "key":"http.method",
                  "value":{
                    "stringValue":"GET"
                  }
                },
                {
                  "key":"http.url",
                  "value":{
                    "stringValue":"/"
                  }
                },
                {
                  "key":"component",
                  "value":{
                    "stringValue":"net/http"
                  }
                }
              ],
              "status":{

              }
            }
          ]
        }
      ]
    }
  ]
}
'''
'''--- pkg/traces/traces.go ---
package traces

import (
	"fmt"
	"os"
	"sync"
	"time"

	"contrib.go.opencensus.io/exporter/prometheus"
	"github.com/grafana/agent/pkg/logs"
	"github.com/grafana/agent/pkg/metrics/instance"
	zaplogfmt "github.com/jsternberg/zap-logfmt"
	prom_client "github.com/prometheus/client_golang/prometheus"
	"github.com/sirupsen/logrus"
	"github.com/weaveworks/common/logging"
	"go.opencensus.io/stats/view"
	"go.opentelemetry.io/collector/external/obsreportconfig"
	"go.uber.org/zap"
	"go.uber.org/zap/zapcore"

	"go.opentelemetry.io/collector/config/configtelemetry"
)

// Traces wraps the OpenTelemetry collector to enable tracing pipelines
type Traces struct {
	mut       sync.Mutex
	instances map[string]*Instance

	leveller *logLeveller
	logger   *zap.Logger
	reg      prom_client.Registerer

	promInstanceManager instance.Manager
}

// New creates and starts trace collection.
func New(logsSubsystem *logs.Logs, promInstanceManager instance.Manager, reg prom_client.Registerer, cfg Config, level logrus.Level, fmt logging.Format) (*Traces, error) {
	var leveller logLeveller

	traces := &Traces{
		instances:           make(map[string]*Instance),
		leveller:            &leveller,
		logger:              newLogger(&leveller, fmt),
		reg:                 reg,
		promInstanceManager: promInstanceManager,
	}
	if err := traces.ApplyConfig(logsSubsystem, promInstanceManager, cfg, level); err != nil {
		return nil, err
	}
	return traces, nil
}

// Instance is used to retrieve a named Traces instance
func (t *Traces) Instance(name string) *Instance {
	t.mut.Lock()
	defer t.mut.Unlock()

	return t.instances[name]
}

// ApplyConfig updates Traces with a new Config.
func (t *Traces) ApplyConfig(logsSubsystem *logs.Logs, promInstanceManager instance.Manager, cfg Config, level logrus.Level) error {
	t.mut.Lock()
	defer t.mut.Unlock()

	// Update the log level, if it has changed.
	t.leveller.SetLevel(level)

	newInstances := make(map[string]*Instance, len(cfg.Configs))

	for _, c := range cfg.Configs {
		var (
			instReg = prom_client.WrapRegistererWith(prom_client.Labels{"traces_config": c.Name}, t.reg)
		)

		// If an old instance exists, update it and move it to the new map.
		if old, ok := t.instances[c.Name]; ok {
			err := old.ApplyConfig(logsSubsystem, promInstanceManager, instReg, c)
			if err != nil {
				return err
			}

			newInstances[c.Name] = old
			continue
		}

		var (
			instLogger = t.logger.With(zap.String("traces_config", c.Name))
		)

		inst, err := NewInstance(logsSubsystem, instReg, c, instLogger, t.promInstanceManager)
		if err != nil {
			return fmt.Errorf("failed to create tracing instance %s: %w", c.Name, err)
		}
		newInstances[c.Name] = inst
	}

	// Any instance in l.instances that isn't in newInstances has been removed
	// from the config. Stop them before replacing the map.
	for key, i := range t.instances {
		if _, exist := newInstances[key]; exist {
			continue
		}
		i.Stop()
	}
	t.instances = newInstances

	return nil
}

// Stop stops the OpenTelemetry collector subsystem
func (t *Traces) Stop() {
	t.mut.Lock()
	defer t.mut.Unlock()

	for _, i := range t.instances {
		i.Stop()
	}
}

func newLogger(zapLevel zapcore.LevelEnabler, fmt logging.Format) *zap.Logger {
	config := zap.NewProductionEncoderConfig()
	config.EncodeTime = func(ts time.Time, encoder zapcore.PrimitiveArrayEncoder) {
		encoder.AppendString(ts.UTC().Format(time.RFC3339))
	}

	var encoder zapcore.Encoder
	switch fmt.String() {
	case "logfmt":
		encoder = zaplogfmt.NewEncoder(config)
	case "json":
		encoder = zapcore.NewJSONEncoder(config)
	default:
		encoder = zaplogfmt.NewEncoder(config)
	}

	logger := zap.New(zapcore.NewCore(
		encoder,
		os.Stdout,
		zapLevel,
	), zap.AddCaller())
	logger = logger.With(zap.String("component", "traces"))
	logger.Info("Traces Logger Initialized")

	return logger
}

// logLeveller implements the zapcore.LevelEnabler interface and allows for
// switching out log levels at runtime.
type logLeveller struct {
	mut   sync.RWMutex
	inner zapcore.Level
}

func (l *logLeveller) SetLevel(level logrus.Level) {
	l.mut.Lock()
	defer l.mut.Unlock()

	zapLevel := zapcore.InfoLevel

	switch level {
	case logrus.PanicLevel:
		zapLevel = zapcore.PanicLevel
	case logrus.FatalLevel:
		zapLevel = zapcore.FatalLevel
	case logrus.ErrorLevel:
		zapLevel = zapcore.ErrorLevel
	case logrus.WarnLevel:
		zapLevel = zapcore.WarnLevel
	case logrus.InfoLevel:
		zapLevel = zapcore.InfoLevel
	case logrus.DebugLevel:
	case logrus.TraceLevel:
		zapLevel = zapcore.DebugLevel
	}

	l.inner = zapLevel
}

func (l *logLeveller) Enabled(target zapcore.Level) bool {
	l.mut.RLock()
	defer l.mut.RUnlock()
	return l.inner.Enabled(target)
}

func newMetricViews(reg prom_client.Registerer) ([]*view.View, error) {
	obsMetrics := obsreportconfig.Configure(configtelemetry.LevelBasic)
	err := view.Register(obsMetrics.Views...)
	if err != nil {
		return nil, fmt.Errorf("failed to register views: %w", err)
	}

	pe, err := prometheus.NewExporter(prometheus.Options{
		Namespace:  "traces",
		Registerer: reg,
	})
	if err != nil {
		return nil, fmt.Errorf("failed to create prometheus exporter: %w", err)
	}

	view.RegisterExporter(pe)

	return obsMetrics.Views, nil
}

'''
'''--- pkg/traces/traces_test.go ---
package traces

import (
	"fmt"
	"strings"
	"testing"
	"time"

	"github.com/grafana/agent/pkg/traces/internal/traceutils"
	"github.com/grafana/agent/pkg/util"
	"github.com/opentracing/opentracing-go"
	"github.com/prometheus/client_golang/prometheus"
	"github.com/sirupsen/logrus"
	"github.com/stretchr/testify/require"
	jaegercfg "github.com/uber/jaeger-client-go/config"
	"github.com/weaveworks/common/logging"
	"go.opentelemetry.io/collector/pdata/ptrace"
	"gopkg.in/yaml.v2"
)

func TestTraces(t *testing.T) {
	tracesCh := make(chan ptrace.Traces)
	tracesAddr := traceutils.NewTestServer(t, func(t ptrace.Traces) {
		tracesCh <- t
	})

	tracesCfgText := util.Untab(fmt.Sprintf(`
configs:
- name: default
  receivers:
    jaeger:
      protocols:
        thrift_compact:
  remote_write:
  	- endpoint: %s
      insecure: true
  batch:
    timeout: 100ms
    send_batch_size: 1
	`, tracesAddr))

	var cfg Config
	dec := yaml.NewDecoder(strings.NewReader(tracesCfgText))
	dec.SetStrict(true)
	err := dec.Decode(&cfg)
	require.NoError(t, err)

	var loggingLevel logging.Level
	require.NoError(t, loggingLevel.Set("debug"))

	traces, err := New(nil, nil, prometheus.NewRegistry(), cfg, logrus.InfoLevel, logging.Format{})
	require.NoError(t, err)
	t.Cleanup(traces.Stop)

	tr := testJaegerTracer(t)
	span := tr.StartSpan("test-span")
	span.Finish()

	select {
	case <-time.After(30 * time.Second):
		require.Fail(t, "failed to receive a span after 30 seconds")
	case tr := <-tracesCh:
		require.Equal(t, 1, tr.SpanCount())
		// Nothing to do, send succeeded.
	}
}

func TestTraceWithSpanmetricsConfig(t *testing.T) {
	tracesCfgText := util.Untab(`
configs:
- name: test
  receivers:
    zipkin:
      endpoint: 0.0.0.0:9999
  remote_write:
    - endpoint: 0.0.0.0:5555
      insecure: false
      tls_config:
          insecure_skip_verify: true
  spanmetrics:
    handler_endpoint: 0.0.0.0:9090
    const_labels:
      key1: "value1"
      key2: "value2"
	`)

	var cfg Config
	dec := yaml.NewDecoder(strings.NewReader(tracesCfgText))
	dec.SetStrict(true)
	err := dec.Decode(&cfg)
	require.NoError(t, err)

	var loggingLevel logging.Level
	require.NoError(t, loggingLevel.Set("debug"))

	traces, err := New(nil, nil, prometheus.NewRegistry(), cfg, logrus.InfoLevel, logging.Format{})
	require.NoError(t, err)
	t.Cleanup(traces.Stop)
}

func TestTrace_ApplyConfig(t *testing.T) {
	tracesCh := make(chan ptrace.Traces)
	tracesAddr := traceutils.NewTestServer(t, func(t ptrace.Traces) {
		tracesCh <- t
	})

	tracesCfgText := util.Untab(`
configs:
- name: default
  receivers:
    jaeger:
      protocols:
        thrift_compact:
  remote_write:
  	- endpoint: 127.0.0.1:80 # deliberately the wrong endpoint
  	  insecure: true
  batch:
    timeout: 100ms
    send_batch_size: 1
  service_graphs:
    enabled: true
`)

	var cfg Config
	dec := yaml.NewDecoder(strings.NewReader(tracesCfgText))
	dec.SetStrict(true)
	err := dec.Decode(&cfg)
	require.NoError(t, err)

	traces, err := New(nil, nil, prometheus.NewRegistry(), cfg, logrus.DebugLevel, logging.Format{})
	require.NoError(t, err)
	t.Cleanup(traces.Stop)

	// Fix the config and apply it before sending spans.
	tracesCfgText = util.Untab(fmt.Sprintf(`
configs:
- name: default
  receivers:
    jaeger:
      protocols:
        thrift_compact:
  remote_write:
  	- endpoint: %s
  	  insecure: true
  batch:
    timeout: 100ms
    send_batch_size: 1
	`, tracesAddr))

	var fixedConfig Config
	dec = yaml.NewDecoder(strings.NewReader(tracesCfgText))
	dec.SetStrict(true)
	err = dec.Decode(&fixedConfig)
	require.NoError(t, err)

	err = traces.ApplyConfig(nil, nil, fixedConfig, logrus.DebugLevel)
	require.NoError(t, err)

	tr := testJaegerTracer(t)
	span := tr.StartSpan("test-span")
	span.Finish()

	select {
	case <-time.After(30 * time.Second):
		require.Fail(t, "failed to receive a span after 30 seconds")
	case tr := <-tracesCh:
		require.Equal(t, 1, tr.SpanCount())
		// Nothing to do, send succeeded.
	}
}

func testJaegerTracer(t *testing.T) opentracing.Tracer {
	t.Helper()

	jaegerConfig := jaegercfg.Configuration{
		ServiceName: "TestTraces",
		Sampler: &jaegercfg.SamplerConfig{
			Type:  "const",
			Param: 1,
		},
		Reporter: &jaegercfg.ReporterConfig{
			LocalAgentHostPort: "127.0.0.1:6831",
			LogSpans:           true,
		},
	}
	tr, closer, err := jaegerConfig.NewTracer()
	require.NoError(t, err)
	t.Cleanup(func() {
		require.NoError(t, closer.Close())
	})

	return tr
}

'''
'''--- pkg/usagestats/reporter.go ---
package usagestats

import (
	"context"
	"encoding/json"
	"errors"
	"io/ioutil"
	"math"
	"os"
	"path/filepath"
	"runtime"
	"time"

	"github.com/go-kit/log"
	"github.com/go-kit/log/level"
	"github.com/google/uuid"
	"github.com/grafana/agent/pkg/config"
	"github.com/grafana/dskit/backoff"
	"github.com/grafana/dskit/multierror"
	"github.com/prometheus/common/version"
)

var (
	reportCheckInterval = time.Minute
	reportInterval      = 4 * time.Hour
)

// Reporter holds the agent seed information and sends report of usage
type Reporter struct {
	logger log.Logger
	cfg    *config.Config

	agentSeed  *AgentSeed
	lastReport time.Time
}

// AgentSeed identifies a unique agent
type AgentSeed struct {
	UID       string    `json:"UID"`
	CreatedAt time.Time `json:"created_at"`
	Version   string    `json:"version"`
}

// NewReporter creates a Reporter that will send periodically reports to grafana.com
func NewReporter(logger log.Logger, cfg *config.Config) (*Reporter, error) {
	r := &Reporter{
		logger: logger,
		cfg:    cfg,
	}
	return r, nil
}

func (rep *Reporter) init(ctx context.Context) error {
	path := agentSeedFileName()

	if fileExists(path) {
		seed, err := rep.readSeedFile(path)
		rep.agentSeed = seed
		return err
	}
	rep.agentSeed = &AgentSeed{
		UID:       uuid.NewString(),
		Version:   version.Version,
		CreatedAt: time.Now(),
	}
	return rep.writeSeedFile(*rep.agentSeed, path)
}

func fileExists(path string) bool {
	_, err := os.Stat(path)
	return !errors.Is(err, os.ErrNotExist)
}

// readSeedFile reads the agent seed file
func (rep *Reporter) readSeedFile(path string) (*AgentSeed, error) {
	data, err := ioutil.ReadFile(path)
	if err != nil {
		return nil, err
	}
	seed := &AgentSeed{}
	err = json.Unmarshal(data, seed)
	if err != nil {
		return nil, err
	}
	return seed, nil
}

// writeSeedFile writes the agent seed file
func (rep *Reporter) writeSeedFile(seed AgentSeed, path string) error {
	data, err := json.Marshal(seed)
	if err != nil {
		return err
	}
	return ioutil.WriteFile(path, data, 0644)
}

func agentSeedFileName() string {
	if runtime.GOOS == "windows" {
		return filepath.Join(os.Getenv("APPDATA"), "agent_seed.json")
	}
	// linux/mac
	return "/tmp/agent_seed.json"
}

// Start inits the reporter seed and start sending report for every interval
func (rep *Reporter) Start(ctx context.Context) error {
	level.Info(rep.logger).Log("msg", "running usage stats reporter")
	err := rep.init(ctx)
	if err != nil {
		level.Info(rep.logger).Log("msg", "failed to init seed", "err", err)
		return err
	}

	// check every minute if we should report.
	ticker := time.NewTicker(reportCheckInterval)
	defer ticker.Stop()

	// find  when to send the next report.
	next := nextReport(reportInterval, rep.agentSeed.CreatedAt, time.Now())
	if rep.lastReport.IsZero() {
		// if we never reported assumed it was the last interval.
		rep.lastReport = next.Add(-reportInterval)
	}
	for {
		select {
		case <-ticker.C:
			now := time.Now()
			if !next.Equal(now) && now.Sub(rep.lastReport) < reportInterval {
				continue
			}
			level.Info(rep.logger).Log("msg", "reporting cluster stats", "date", time.Now())
			if err := rep.reportUsage(ctx, next); err != nil {
				level.Info(rep.logger).Log("msg", "failed to report usage", "err", err)
				continue
			}
			rep.lastReport = next
			next = next.Add(reportInterval)
		case <-ctx.Done():
			return ctx.Err()
		}
	}
}

// reportUsage reports the usage to grafana.com.
func (rep *Reporter) reportUsage(ctx context.Context, interval time.Time) error {
	backoff := backoff.New(ctx, backoff.Config{
		MinBackoff: time.Second,
		MaxBackoff: 30 * time.Second,
		MaxRetries: 5,
	})
	var errs multierror.MultiError
	for backoff.Ongoing() {
		if err := sendReport(ctx, rep.agentSeed, interval, rep.getMetrics()); err != nil {
			level.Info(rep.logger).Log("msg", "failed to send usage report", "retries", backoff.NumRetries(), "err", err)
			errs.Add(err)
			backoff.Wait()
			continue
		}
		level.Info(rep.logger).Log("msg", "usage report sent with success")
		return nil
	}
	return errs.Err()
}

func (rep *Reporter) getMetrics() map[string]interface{} {
	return map[string]interface{}{
		"enabled-features": rep.cfg.EnabledFeatures,
	}
}

// nextReport compute the next report time based on the interval.
// The interval is based off the creation of the agent seed to avoid all agents reporting at the same time.
func nextReport(interval time.Duration, createdAt, now time.Time) time.Time {
	duration := math.Ceil(float64(now.Sub(createdAt)) / float64(interval))
	return createdAt.Add(time.Duration(duration) * interval)
}

'''
'''--- pkg/usagestats/reporter_test.go ---
package usagestats

import (
	"context"
	"net/http"
	"net/http/httptest"
	"os"
	"sync"
	"testing"
	"time"

	"github.com/go-kit/log"
	"github.com/grafana/agent/pkg/config"
	jsoniter "github.com/json-iterator/go"
	"github.com/stretchr/testify/require"
)

func Test_ReportLoop(t *testing.T) {
	// stub
	reportCheckInterval = 100 * time.Millisecond
	reportInterval = time.Second

	var (
		mut          sync.Mutex
		totalReports int
		agentIDs     []string
	)

	server := httptest.NewServer(http.HandlerFunc(func(rw http.ResponseWriter, r *http.Request) {
		mut.Lock()
		defer mut.Unlock()

		totalReports++

		var received Report
		require.NoError(t, jsoniter.NewDecoder(r.Body).Decode(&received))
		agentIDs = append(agentIDs, received.UsageStatsID)

		rw.WriteHeader(http.StatusOK)
	}))
	usageStatsURL = server.URL

	r, err := NewReporter(log.NewLogfmtLogger(os.Stdout), &config.Config{EnableUsageReport: true})
	require.NoError(t, err)

	ctx, cancel := context.WithCancel(context.Background())

	go func() {
		<-time.After(6 * time.Second)
		cancel()
	}()
	require.Equal(t, context.Canceled, r.Start(ctx))

	mut.Lock()
	defer mut.Unlock()

	require.GreaterOrEqual(t, totalReports, 5)
	first := agentIDs[0]
	for _, uid := range agentIDs {
		require.Equal(t, first, uid)
	}
	require.Equal(t, first, r.agentSeed.UID)
}

func Test_NextReport(t *testing.T) {
	fixtures := map[string]struct {
		interval  time.Duration
		createdAt time.Time
		now       time.Time

		next time.Time
	}{
		"createdAt aligned with interval and now": {
			interval:  1 * time.Hour,
			createdAt: time.Unix(0, time.Hour.Nanoseconds()),
			now:       time.Unix(0, 2*time.Hour.Nanoseconds()),
			next:      time.Unix(0, 2*time.Hour.Nanoseconds()),
		},
		"createdAt aligned with interval": {
			interval:  1 * time.Hour,
			createdAt: time.Unix(0, time.Hour.Nanoseconds()),
			now:       time.Unix(0, 2*time.Hour.Nanoseconds()+1),
			next:      time.Unix(0, 3*time.Hour.Nanoseconds()),
		},
		"createdAt not aligned": {
			interval:  1 * time.Hour,
			createdAt: time.Unix(0, time.Hour.Nanoseconds()+18*time.Minute.Nanoseconds()+20*time.Millisecond.Nanoseconds()),
			now:       time.Unix(0, 2*time.Hour.Nanoseconds()+1),
			next:      time.Unix(0, 2*time.Hour.Nanoseconds()+18*time.Minute.Nanoseconds()+20*time.Millisecond.Nanoseconds()),
		},
	}
	for name, f := range fixtures {
		t.Run(name, func(t *testing.T) {
			next := nextReport(f.interval, f.createdAt, f.now)
			require.Equal(t, f.next, next)
		})
	}
}

'''
'''--- pkg/usagestats/stats.go ---
package usagestats

import (
	"bytes"
	"context"
	"encoding/json"
	"fmt"
	"io"
	"net/http"
	"runtime"
	"time"

	"github.com/prometheus/common/version"
)

var (
	httpClient    = http.Client{Timeout: 5 * time.Second}
	usageStatsURL = "https://stats.grafana.org/agent-usage-report"
)

// Report is the payload to be sent to stats.grafana.org
type Report struct {
	UsageStatsID string                 `json:"usageStatsId"`
	CreatedAt    time.Time              `json:"createdAt"`
	Interval     time.Time              `json:"interval"`
	Version      string                 `json:"version"`
	Metrics      map[string]interface{} `json:"metrics"`
	Os           string                 `json:"os"`
	Arch         string                 `json:"arch"`
}

func sendReport(ctx context.Context, seed *AgentSeed, interval time.Time, metrics map[string]interface{}) error {
	report := Report{
		UsageStatsID: seed.UID,
		CreatedAt:    seed.CreatedAt,
		Version:      version.Version,
		Os:           runtime.GOOS,
		Arch:         runtime.GOARCH,
		Interval:     interval,
		Metrics:      metrics,
	}
	out, err := json.MarshalIndent(report, "", " ")
	if err != nil {
		return err
	}
	req, err := http.NewRequest(http.MethodPost, usageStatsURL, bytes.NewBuffer(out))
	if err != nil {
		return err
	}
	req.Header.Set("Content-Type", "application/json")

	resp, err := httpClient.Do(req.WithContext(ctx))
	if err != nil {
		return err
	}
	defer resp.Body.Close()
	if resp.StatusCode != http.StatusOK {
		data, err := io.ReadAll(resp.Body)
		if err != nil {
			return err
		}
		return fmt.Errorf("failed to send usage stats: %s  body: %s", resp.Status, string(data))
	}
	return nil
}

'''
'''--- pkg/util/compare_yaml.go ---
package util

import (
	"bytes"

	"gopkg.in/yaml.v2"
)

// CompareYAML marshals a and b to YAML and ensures that their contents are
// equal. If either Marshal fails, CompareYAML returns false.
func CompareYAML(a, b interface{}) bool {
	aBytes, err := yaml.Marshal(a)
	if err != nil {
		return false
	}
	bBytes, err := yaml.Marshal(b)
	if err != nil {
		return false
	}
	return bytes.Equal(aBytes, bBytes)
}

'''
'''--- pkg/util/defaults.go ---
package util

import "flag"

// DefaultConfigFromFlags will load default values into cfg by
// retrieving default values that are registered as flags.
//
// cfg must implement either PrefixedConfigFlags or ConfigFlags.
func DefaultConfigFromFlags(cfg interface{}) interface{} {
	// This function is super ugly but is required for mixing the combination
	// of mechanisms for providing default for config structs that are used
	// across both Prometheus (via UnmarshalYAML and assigning the default object)
	// and Cortex (via RegisterFlags*).
	//
	// The issue stems from default values assigned via RegisterFlags being set
	// at *registration* time, not *flag parse* time. For example, this
	// flag:
	//
	//   fs.BoolVar(&enabled, "enabled", true, "enable everything")
	//
	// Sets enabled to true as soon as fs.BoolVar is called. Normally this is
	// fine, but with how Prometheus implements UnmarshalYAML, these defaults
	// get overridden:
	//
	//   func (c *Config) UnmarshalYAML(unmarshal func(v interface{}) error) error {
	//     *c = DefaultConfig // <-- !! overrides defaults from flags !!
	//     type plain Config
	//     return unmarshal((*plain)(c))
	//   }
	//
	// The solution to this is to make sure that the DefaultConfig object contains
	// the defaults that are set up through registering flags. Unfortunately, the
	// best way to do this is this function that creates a temporary flagset just for
	// the sake of collecting default values.
	//
	// This function should be used like so:
	//
	//   var DefaultConfig = *DefaultConfigFromFlags(&Config{}).(*Config)

	fs := flag.NewFlagSet("DefaultConfigFromFlags", flag.PanicOnError)

	if v, ok := cfg.(PrefixedConfigFlags); ok {
		v.RegisterFlagsWithPrefix("", fs)
	} else if v, ok := cfg.(ConfigFlags); ok {
		v.RegisterFlags(fs)
	} else {
		panic("config does not implement PrefixedConfigFlags or ConfigFlags")
	}

	return cfg
}

// ConfigFlags is an interface that will register flags that can control
// some object.
type ConfigFlags interface {
	RegisterFlags(f *flag.FlagSet)
}

// PrefixedConfigFlags is an interface that, given a prefix for flags
// and a flagset, will register flags that can control some object.
type PrefixedConfigFlags interface {
	RegisterFlagsWithPrefix(prefix string, f *flag.FlagSet)
}

'''
'''--- pkg/util/k8s/k8s.go ---
// Package k8s spins up a Kubernetes cluster for testing.
package k8s

import (
	"context"
	"fmt"
	"os"
	"sort"
	"time"

	docker_types "github.com/docker/docker/api/types"
	docker_nat "github.com/docker/go-connections/nat"
	gragent "github.com/grafana/agent/pkg/operator/apis/monitoring/v1alpha1"
	promop_v1 "github.com/prometheus-operator/prometheus-operator/pkg/apis/monitoring/v1"
	k3d_client "github.com/rancher/k3d/v5/pkg/client"
	config "github.com/rancher/k3d/v5/pkg/config"
	k3d_cfgtypes "github.com/rancher/k3d/v5/pkg/config/types"
	k3d_config "github.com/rancher/k3d/v5/pkg/config/v1alpha3"
	k3d_log "github.com/rancher/k3d/v5/pkg/logger"
	k3d_runtime "github.com/rancher/k3d/v5/pkg/runtimes"
	k3d_docker "github.com/rancher/k3d/v5/pkg/runtimes/docker"
	k3d_types "github.com/rancher/k3d/v5/pkg/types"
	k3d_version "github.com/rancher/k3d/v5/version"
	apiextensions_v1 "k8s.io/apiextensions-apiserver/pkg/apis/apiextensions/v1"
	"k8s.io/apimachinery/pkg/runtime"
	"k8s.io/apimachinery/pkg/util/rand"
	"k8s.io/client-go/kubernetes/scheme"
	"k8s.io/client-go/rest"
	k8s_clientcmd "k8s.io/client-go/tools/clientcmd"
	"sigs.k8s.io/controller-runtime/pkg/client"
)

// Cluster is a Kubernetes cluster that runs inside of a k3s Docker container.
// Call GetConfig to retrieve a Kubernetes *rest.Config to use to connect to
// the cluster.
//
// Cluster also runs an NGINX ingress controller which is exposed to the host.
// Call GetHTTPAddr to get the address for making requests against the server.
//
// Set K8S_USE_DOCKER_NETWORK in your environment variables if you are
// running tests from inside of a Docker container. This environment variable
// configures the k3s Docker container to join the same network as the
// container tests are running in. When this environment variable isn't set,
// the exposed ports on the Docker host are used for cluster communication.
//
// Note that k3s uses containerd as its runtime, which means local Docker
// images are not immediately available for use. To push local images to a
// container, call PushImages. It's recommended that tests use image names that
// are not available on Docker Hub to avoid accidentally testing against the
// wrong image.
//
// Cluster should be stopped by calling Stop, otherwise running Docker
// containers will leak.
type Cluster struct {
	runtime    k3d_runtime.Runtime
	k3dCluster k3d_types.Cluster
	restConfig *rest.Config
	kubeClient client.Client
	nginxAddr  string
}

// Options control creation of a cluster.
type Options struct {
	// Scheme is the Kubernetes scheme used for the generated Kubernetes client.
	// If nil, a generated scheme that contains all known Kubernetes API types
	// will be generated.
	Scheme *runtime.Scheme
}

func (o *Options) applyDefaults() error {
	if o.Scheme == nil {
		o.Scheme = runtime.NewScheme()

		for _, add := range []func(*runtime.Scheme) error{
			scheme.AddToScheme,
			apiextensions_v1.AddToScheme,
			gragent.AddToScheme,
			promop_v1.AddToScheme,
		} {
			if err := add(o.Scheme); err != nil {
				return fmt.Errorf("unable to register scheme: %w", err)
			}
		}
	}
	return nil
}

// NewCluster creates a new Cluster. NewCluster won't return with success until
// the cluster is running, but things like the ingress controller might not be
// running right away. You should never assume that any resource in the cluster
// is running and utilize exponential backoffs to allow time for things to spin
// up.
func NewCluster(ctx context.Context, o Options) (cluster *Cluster, err error) {
	var (
		// We force the Docker runtime so we can create a Docker client for getting
		// the exposed ports for the API server and NGINX.
		runtime = k3d_runtime.Docker

		// Running in docker indicates that we should configure k3s to connect to
		// the same docker network as the current container.
		runningInDocker = os.Getenv("K8S_USE_DOCKER_NETWORK") == "1"
	)

	if err := o.applyDefaults(); err != nil {
		return nil, fmt.Errorf("failed to apply defaults to options: %w", err)
	}

	k3dConfig := k3d_config.SimpleConfig{
		TypeMeta: k3d_cfgtypes.TypeMeta{
			Kind:       "Simple",
			APIVersion: config.DefaultConfigApiVersion,
		},
		Name:    randomClusterName(),
		Servers: 1,
		Ports: []k3d_config.PortWithNodeFilters{{
			// Bind NGINX (container port 80) to 127.0.0.1:0
			Port:        "127.0.0.1:0:80",
			NodeFilters: []string{"loadbalancer"},
		}},
		ExposeAPI: k3d_config.SimpleExposureOpts{
			// Bind API sever to 127.0.0.1:0
			Host:     "127.0.0.1",
			HostIP:   "127.0.0.1",
			HostPort: "0",
		},
		Image: fmt.Sprintf("%s:%s", k3d_types.DefaultK3sImageRepo, k3d_version.K3sVersion),
		Options: k3d_config.SimpleConfigOptions{
			K3dOptions: k3d_config.SimpleConfigOptionsK3d{
				Wait:    true,
				Timeout: time.Minute,
			},
		},
	}
	if runningInDocker {
		err := injectCurrentDockerNetwork(ctx, &k3dConfig)
		if err != nil {
			return nil, fmt.Errorf("could not connect k3d to current docker network: %w", err)
		}
	}

	clusterConfig, err := config.TransformSimpleToClusterConfig(ctx, runtime, k3dConfig)
	if err != nil {
		return nil, fmt.Errorf("failed to generate cluster config: %w", err)
	}

	err = k3d_client.ClusterRun(ctx, runtime, clusterConfig)

	defer func() {
		// We don't want to leak the cluster here, and we can't really be sure how
		// many resources exist, even if ClusterRun fails. If we never set our
		// cluster return argument, we'll delete the k3d cluster. This also
		// gracefully handles panics.
		if cluster == nil {
			_ = k3d_client.ClusterDelete(ctx, runtime, &clusterConfig.Cluster, k3d_types.ClusterDeleteOpts{})
		}
	}()
	if err != nil {
		return nil, fmt.Errorf("failed to run cluster: %w", err)
	}

	var (
		httpAddr      string
		apiServerAddr string
	)

	// If we're currently running inside of Docker, we can connect directly to
	// our container. Otherwise, we have to find what the bound host IPs are.
	if runningInDocker {
		httpAddr, apiServerAddr, err = clusterInternalAddrs(ctx, clusterConfig.Cluster)
	} else {
		httpAddr, apiServerAddr, err = loadBalancerExposedAddrs(ctx, clusterConfig.Cluster)
	}
	if err != nil {
		return nil, fmt.Errorf("failed to discover exposed cluster addresses: %w", err)
	}

	kubeconfig, err := k3d_client.KubeconfigGet(ctx, runtime, &clusterConfig.Cluster)
	if err != nil {
		return nil, fmt.Errorf("failed to retrieve kubeconfig: %w", err)
	}
	if c, ok := kubeconfig.Clusters[kubeconfig.CurrentContext]; ok && c != nil {
		// The generated kubeconfig will set https://127.0.0.1:0 as the address. We
		// need to replace it with the actual exposed port that Docker generated
		// for us.
		c.Server = "https://" + apiServerAddr
	} else {
		return nil, fmt.Errorf("generated kubeconfig missing context set")
	}
	restCfg, err := k8s_clientcmd.NewDefaultClientConfig(*kubeconfig, nil).ClientConfig()
	if err != nil {
		return nil, fmt.Errorf("could not generate k8s REST API config: %w", err)
	}

	kubeClient, err := client.New(restCfg, client.Options{
		Scheme: o.Scheme,
	})
	if err != nil {
		return nil, fmt.Errorf("failed to generate client: %w", err)
	}

	return &Cluster{
		runtime:    runtime,
		k3dCluster: clusterConfig.Cluster,
		restConfig: restCfg,
		nginxAddr:  httpAddr,
		kubeClient: kubeClient,
	}, nil
}

// injectCurrentDockerNetwork reconfigures config to join the Docker network of
// the current container. Fails if the function is not being called from inside
// of a Docker container.
func injectCurrentDockerNetwork(ctx context.Context, config *k3d_config.SimpleConfig) error {
	hostname, err := os.Hostname()
	if err != nil {
		return fmt.Errorf("could not get hostname: %w", err)
	}

	cli, err := k3d_docker.GetDockerClient()
	if err != nil {
		return fmt.Errorf("failed to get docker client: %w", err)
	}
	info, err := cli.ContainerInspect(ctx, hostname)
	if err != nil {
		return fmt.Errorf("failed to find current docker container: %w", err)
	}

	networks := make([]string, 0, len(info.NetworkSettings.Networks))
	for nw := range info.NetworkSettings.Networks {
		networks = append(networks, nw)
	}
	sort.Strings(networks)

	if len(networks) == 0 {
		return fmt.Errorf("no networks")
	}
	config.Network = networks[0]
	return nil
}

func randomClusterName() string {
	return "grafana-agent-e2e-" + rand.String(5)
}

func clusterInternalAddrs(ctx context.Context, cluster k3d_types.Cluster) (httpAddr, serverAddr string, err error) {
	var lb, server *k3d_types.Node
	for _, n := range cluster.Nodes {
		switch n.Role {
		case k3d_types.LoadBalancerRole:
			if lb == nil {
				lb = n
			}
		case k3d_types.ServerRole:
			if server == nil {
				server = n
			}
		}
	}
	if lb == nil {
		return "", "", fmt.Errorf("no loadbalancer node")
	} else if server == nil {
		return "", "", fmt.Errorf("no server node")
	}

	cli, err := k3d_docker.GetDockerClient()
	if err != nil {
		return "", "", fmt.Errorf("failed to get docker client: %w", err)
	}

	lbInfo, err := cli.ContainerInspect(ctx, lb.Name)
	if err != nil {
		return "", "", fmt.Errorf("failed to inspect loadbalancer: %w", err)
	} else if nw, found := lbInfo.NetworkSettings.Networks[cluster.Network.Name]; !found {
		return "", "", fmt.Errorf("loadbalancer not connected to expected network %q", cluster.Network.Name)
	} else {
		httpAddr = fmt.Sprintf("%s:80", nw.IPAddress)
	}

	serverInfo, err := cli.ContainerInspect(ctx, server.Name)
	if err != nil {
		return "", "", fmt.Errorf("failed to inspect worker: %w", err)
	} else if nw, found := serverInfo.NetworkSettings.Networks[cluster.Network.Name]; !found {
		return "", "", fmt.Errorf("worker not connected to expected network %q", cluster.Network.Name)
	} else {
		serverAddr = fmt.Sprintf("%s:6443", nw.IPAddress)
	}

	return httpAddr, serverAddr, nil
}

func loadBalancerExposedAddrs(ctx context.Context, cluster k3d_types.Cluster) (httpAddr, apiServerAddr string, err error) {
	var lb *k3d_types.Node
	for _, n := range cluster.Nodes {
		if n.Role == k3d_types.LoadBalancerRole {
			lb = n
			break
		}
	}
	if lb == nil {
		return "", "", fmt.Errorf("no loadbalancer node")
	}

	cli, err := k3d_docker.GetDockerClient()
	if err != nil {
		return "", "", fmt.Errorf("failed to get docker client: %w", err)
	}
	info, err := cli.ContainerInspect(ctx, lb.Name)
	if err != nil {
		return "", "", fmt.Errorf("failed to inspect loadbalancer: %w", err)
	}

	httpAddr, err = hostBinding(info, 80)
	if err != nil {
		return "", "", fmt.Errorf("failed to discover NGINX HTTP addr: %w", err)
	}
	apiServerAddr, err = hostBinding(info, 6443)
	if err != nil {
		return "", "", fmt.Errorf("failed to discover API server addr: %w", err)
	}
	return httpAddr, apiServerAddr, nil
}

func hostBinding(containerInfo docker_types.ContainerJSON, containerPort int) (string, error) {
	for rawPort, bindings := range containerInfo.NetworkSettings.Ports {
		_, portString := docker_nat.SplitProtoPort(string(rawPort))
		port, _ := docker_nat.ParsePort(portString)
		if port != containerPort {
			continue
		}
		if len(bindings) == 0 {
			return "", fmt.Errorf("no exposed bindings for port %d", containerPort)
		}
		return fmt.Sprintf("%s:%s", bindings[0].HostIP, bindings[0].HostPort), nil
	}

	return "", fmt.Errorf("no container port %d exposed", containerPort)
}

// Client returns the Kubernetes client for this Cluster. Client is handling
// objects registered to the Scheme passed to Options when creating the
// cluster.
func (c *Cluster) Client() client.Client {
	return c.kubeClient
}

// GetConfig returns a *rest.Config that can be used to connect to the
// Kubernetes cluster. The returned Config is a copy and is safe for
// modification.
func (c *Cluster) GetConfig() *rest.Config {
	return rest.CopyConfig(c.restConfig)
}

// GetHTTPAddr returns the host:port address that can be used to connect to the
// cluster's NGINX server.
func (c *Cluster) GetHTTPAddr() string {
	return c.nginxAddr
}

// PushImages push images from the local Docker host into the Cluster. If the
// specified image does not have a tag, `:latest` is assumed.
func (c *Cluster) PushImages(images ...string) error {
	return k3d_client.ImageImportIntoClusterMulti(
		context.Background(),
		c.runtime,
		images,
		&c.k3dCluster,
		k3d_types.ImageImportOpts{},
	)
}

// Stop shuts down and deletes the cluster. Stop must be called to clean up
// created Docker resources.
func (c *Cluster) Stop() {
	err := k3d_client.ClusterDelete(context.Background(), c.runtime, &c.k3dCluster, k3d_types.ClusterDeleteOpts{})
	if err != nil {
		k3d_log.Log().Errorf("failed to shut down cluster, docker containers may have leaked: %s", err)
	}
}

'''
'''--- pkg/util/k8s/k8s_test.go ---
//go:build !nonetwork && !nodocker && !race
// +build !nonetwork,!nodocker,!race

package k8s

import (
	"context"
	"testing"

	"github.com/stretchr/testify/require"
	core "k8s.io/api/core/v1"
	"sigs.k8s.io/controller-runtime/pkg/client"
)

func TestCluster(t *testing.T) {
	ctx := context.Background()

	cluster, err := NewCluster(ctx, Options{})
	require.NoError(t, err)
	defer cluster.Stop()

	cli, err := client.New(cluster.GetConfig(), client.Options{})
	require.NoError(t, err)

	var nss core.NamespaceList
	require.NoError(t, cli.List(ctx, &nss))

	names := make([]string, len(nss.Items))
	for i, ns := range nss.Items {
		names[i] = ns.Name
	}
	require.Contains(t, names, "kube-system")
}

'''
'''--- pkg/util/k8s/objects.go ---
package k8s

import (
	"context"
	"encoding/json"
	"errors"
	"fmt"
	"io"
	"time"

	"github.com/go-kit/log"
	"github.com/go-kit/log/level"
	"github.com/grafana/dskit/backoff"
	"k8s.io/apimachinery/pkg/runtime/serializer"
	"k8s.io/apimachinery/pkg/util/yaml"
	"sigs.k8s.io/controller-runtime/pkg/client"

	apps_v1 "k8s.io/api/apps/v1"
	core_v1 "k8s.io/api/core/v1"
	"k8s.io/apimachinery/pkg/apis/meta/v1/unstructured"
)

// CreateObjects will create the provided set of objects. If any object
// couldn't be created, an error will be returned and created objects will be
// deleted.
func CreateObjects(ctx context.Context, cli client.Client, objs ...client.Object) (err error) {
	// Index offset into objs for objects we managed to create.
	createdOffset := -1

	defer func() {
		if err == nil {
			return
		}
		// Delete the subset of objs we managed to create
		for i := 0; i <= createdOffset; i++ {
			_ = cli.Delete(context.Background(), objs[i])
		}
	}()

	for i, obj := range objs {
		if err := cli.Create(ctx, obj); err != nil {
			return fmt.Errorf("failed to create %s: %w", client.ObjectKeyFromObject(obj), err)
		}
		createdOffset = i
	}
	return nil
}

// ReadObjects will read the set of objects from r and convert them into
// client.Object based on the scheme of the provided Kubernetes client.
//
// The data of r may be YAML or JSON.
func ReadObjects(r io.Reader, cli client.Client) ([]client.Object, error) {
	var (
		objects []client.Object

		scheme     = cli.Scheme()
		rawDecoder = yaml.NewYAMLOrJSONDecoder(r, 4096)
		decoder    = serializer.NewCodecFactory(scheme).UniversalDecoder(scheme.PrioritizedVersionsAllGroups()...)
	)

NextObject:
	for {
		var raw json.RawMessage

		err := rawDecoder.Decode(&raw)
		switch {
		case errors.Is(err, io.EOF):
			break NextObject
		case err != nil:
			return nil, fmt.Errorf("error parsing object: %w", err)
		case len(raw) == 0:
			// Skip over empty objects. This can happen when --- is used at the top
			// of YAML files.
			continue NextObject
		}

		obj, _, err := decoder.Decode(raw, nil, nil)
		if err != nil {
			return nil, fmt.Errorf("failed to decode object: %w", err)
		}
		clientObj, ok := obj.(client.Object)
		if !ok {
			return nil, fmt.Errorf("decoded object %T is not a controller-runtime object", obj)
		}
		objects = append(objects, clientObj)
	}

	return objects, nil
}

// ReadUnstructuredObjects will read the set of objects from r as unstructured
// objects.
func ReadUnstructuredObjects(r io.Reader) ([]*unstructured.Unstructured, error) {
	var (
		objects    []*unstructured.Unstructured
		rawDecoder = yaml.NewYAMLOrJSONDecoder(r, 4096)
	)

NextObject:
	for {
		var raw json.RawMessage

		err := rawDecoder.Decode(&raw)
		switch {
		case errors.Is(err, io.EOF):
			break NextObject
		case err != nil:
			return nil, fmt.Errorf("error parsing object: %w", err)
		case len(raw) == 0:
			// Skip over empty objects. This can happen when --- is used at the top
			// of YAML files.
			continue NextObject
		}

		var us unstructured.Unstructured
		if err := json.Unmarshal(raw, &us); err != nil {
			return nil, fmt.Errorf("failed to decode object: %w", err)
		}
		objects = append(objects, &us)
	}

	return objects, nil
}

// DefaultBackoff is a default backoff config that retries forever until ctx is
// canceled.
var DefaultBackoff = backoff.Config{
	MinBackoff: 100 * time.Millisecond,
	MaxBackoff: 1 * time.Second,
}

// WaitReady will return with no error if obj becomes ready before ctx cancels
// or the backoff fails.
//
// obj may be one of: DaemonSet, StatefulSet, Deployment, Pod. obj must have
// namespace and name set so it can be found. obj will be updated with the
// state of the object in the cluster as WaitReady runs.
//
// The final state of the object will be returned when it is ready.
func WaitReady(ctx context.Context, cli client.Client, obj client.Object, bc backoff.Config) error {
	bo := backoff.New(ctx, bc)

	key := client.ObjectKeyFromObject(obj)

	var readyCheck func() bool
	switch obj := obj.(type) {
	case *apps_v1.DaemonSet:
		readyCheck = func() bool {
			return obj.Status.NumberReady >= obj.Status.UpdatedNumberScheduled
		}
	case *apps_v1.StatefulSet:
		readyCheck = func() bool {
			return obj.Status.ReadyReplicas >= obj.Status.UpdatedReplicas
		}
	case *apps_v1.Deployment:
		readyCheck = func() bool {
			return obj.Status.ReadyReplicas >= obj.Status.UpdatedReplicas
		}
	case *core_v1.Pod:
		readyCheck = func() bool {
			phase := obj.Status.Phase
			return phase == core_v1.PodRunning || phase == core_v1.PodSucceeded
		}
	}

	for bo.Ongoing() {
		err := cli.Get(ctx, key, obj)
		if err == nil && readyCheck() {
			break
		}
		bo.Wait()
	}

	return bo.Err()
}

// Wait calls done until ctx is caneled or check returns nil. Returns an error
// if ctx is canceled.
func Wait(ctx context.Context, l log.Logger, check func() error) error {
	bo := backoff.New(ctx, DefaultBackoff)
	for bo.Ongoing() {
		err := check()
		if err == nil {
			return nil
		}
		level.Error(l).Log("msg", "check failed", "err", err)
		bo.Wait()
	}
	return bo.Err()
}

'''
'''--- pkg/util/k8s/resources.go ---
package k8s

import (
	"context"
	"fmt"
	"io"
	"os"
	"time"

	"github.com/go-kit/log"
	"github.com/go-kit/log/level"
	"sigs.k8s.io/controller-runtime/pkg/client"
)

// ResourceSet deploys a set of temporary objects to a k8s test cluster and
// deletes them when Stop is called.
type ResourceSet struct {
	log        log.Logger
	kubeClient client.Client
	objects    []client.Object
}

// NewResourceSet returns a new resource set.
func NewResourceSet(l log.Logger, cluster *Cluster) *ResourceSet {
	return &ResourceSet{
		log:        l,
		kubeClient: cluster.Client(),
	}
}

// Add will read from r and deploy the resources into the cluster.
func (rs *ResourceSet) Add(ctx context.Context, r io.Reader) error {
	readObjects, err := ReadObjects(r, rs.kubeClient)
	if err != nil {
		return fmt.Errorf("error reading fixture: %w", err)
	}
	err = CreateObjects(ctx, rs.kubeClient, readObjects...)
	if err != nil {
		return err
	}

	rs.objects = append(rs.objects, readObjects...)
	return nil
}

// AddFile will open filename and deploy it into the cluster.
func (rs *ResourceSet) AddFile(ctx context.Context, filename string) error {
	f, err := os.Open(filename)
	if err != nil {
		return fmt.Errorf("failed to open %q: %w", filename, err)
	}
	defer f.Close()
	return rs.Add(ctx, f)
}

// Stop removes deployed resources from the cluster.
func (rs *ResourceSet) Stop() {
	ctx, cancel := context.WithTimeout(context.Background(), time.Minute)
	defer cancel()

	for _, obj := range rs.objects {
		err := rs.kubeClient.Delete(ctx, obj)
		if err != nil {
			level.Error(rs.log).Log("msg", "failed to delete object", "obj", client.ObjectKeyFromObject(obj), "err", err)
		}
	}
}

'''
'''--- pkg/util/strings.go ---
package util

import (
	"regexp"
	"strings"
)

// CamelToSnake is a helper function for converting CamelCase to Snake Case
func CamelToSnake(str string) string {
	var matchFirstCap = regexp.MustCompile("(.)([A-Z][a-z]+)")
	var matchAllCap = regexp.MustCompile("([a-z0-9])([A-Z])")
	snake := matchFirstCap.ReplaceAllString(str, "${1}_${2}")
	snake = matchAllCap.ReplaceAllString(snake, "${1}_${2}")
	return strings.ToLower(snake)
}

'''
'''--- pkg/util/structwalk/structwalk.go ---
// Package structwalk allows you to "walk" the hierarchy of a struct. It is
// very similar to github.com/mitchellh/reflectwalk but allows you to change
// the visitor mid-walk.
package structwalk

import (
	"reflect"

	"github.com/mitchellh/reflectwalk"
)

// Walk traverses the hierarchy of o in depth-first order. It starts by calling
// v.Visit(o). If the visitor w returned by v.Visit(o) is not nil, Walk is
// invoked recursively with visitor w for each of the structs inside of o,
// followed by a call to w.Visit(nil).
//
// o must be non-nil.
func Walk(v Visitor, o interface{}) {
	sw := structWalker{v: v}
	_ = reflectwalk.Walk(o, &sw)
}

// Visitor will have its Visit method invoked for each struct value encountered
// by Walk. If w returned from Visit is non-nil, Walk will then visit each child
// of value with w. The final call after visiting all children will be to
// w.Visit(nil).
type Visitor interface {
	Visit(value interface{}) (w Visitor)
}

type structWalker struct {
	cur interface{}
	v   Visitor
}

// Struct invoke the Visitor for v and its children.
func (sw *structWalker) Struct(v reflect.Value) error {
	// structWalker will walk absolutely all fields, even unexported fields or
	// types. We can only interface exported fields, so we need to abort early
	// for anything that's not supported.
	if !v.CanInterface() {
		return nil
	}

	// Get the interface to the value. reflectwalk will fully derefernce all
	// structs, so if it's possible for us to get address it into a pointer,
	// we will use that for visiting.
	var (
		rawValue = v.Interface()
		ptrValue = rawValue
	)
	if v.Kind() != reflect.Ptr && v.CanAddr() {
		ptrValue = v.Addr().Interface()
	}

	// Struct will recursively call reflectwalk.Walk with a new walker, which
	// means that sw.Struct will be called twice for the same value. We want
	// to ignore calls to Struct with the same value so we don't recurse
	// infinitely.
	if sw.cur != nil && reflect.DeepEqual(rawValue, sw.cur) {
		return nil
	}

	// Visit our struct and create a new walker with the returned Visitor.
	w := sw.v.Visit(ptrValue)
	if w == nil {
		return reflectwalk.SkipEntry
	}
	_ = reflectwalk.Walk(rawValue, &structWalker{cur: rawValue, v: w})
	w.Visit(nil)

	return reflectwalk.SkipEntry
}

func (sw *structWalker) StructField(reflect.StructField, reflect.Value) error {
	return nil
}

'''
'''--- pkg/util/structwalk/structwalk_test.go ---
package structwalk

import (
	"testing"

	"github.com/stretchr/testify/require"
)

type LevelA struct {
	Field1 bool
	Field2 string
	Field3 int
	Nested LevelB
}

type LevelB struct {
	Level1 bool
	Level2 string
	Field3 int
	Nested LevelC
}

type LevelC struct {
	Level1 bool
	Level2 string
	Field3 int
}

func TestWalk(t *testing.T) {
	var (
		iteration int
		fv        FuncVisitor
	)
	fv = func(val interface{}) Visitor {
		iteration++

		// After visiting all 3 structs, should receive a w.Visit(nil) for each level
		if iteration >= 4 {
			require.Nil(t, val)
			return nil
		}

		switch iteration {
		case 1:
			require.IsType(t, LevelA{}, val)
		case 2:
			require.IsType(t, LevelB{}, val)
		case 3:
			require.IsType(t, LevelC{}, val)
		default:
			require.FailNow(t, "unexpected iteration")
		}

		return fv
	}

	var val LevelA
	Walk(fv, val)
}

type FuncVisitor func(v interface{}) Visitor

func (fv FuncVisitor) Visit(v interface{}) Visitor { return fv(v) }

'''
'''--- pkg/util/subset/subset.go ---
// Package subset implements functions to check if one value is a subset of
// another.
package subset

import (
	"fmt"
	"reflect"

	"gopkg.in/yaml.v2"
)

// Assert checks whether target is a subset of source. source and target must
// be the same type. target is a subset of source when:
//
// * If target and source are slices or arrays, then target must have the same
//   number of elements as source. Each element in target must be a subset of
//   the corresponding element from source.
//
// * If target and source are maps, each key in source must exist in target.
//   The value for each element in target must be a subset of the corresponding
//   element from source.
//
// * Otherwise, target and source must be deeply equal.
//
// An instance of Error will be returned when target is not a subset of source.
//
// Subset checking is primarily useful when doing things like YAML assertions,
// where you only want to ensure that a subset of YAML is defined as expected.
func Assert(source, target interface{}) error {
	return assert(reflect.ValueOf(source), reflect.ValueOf(target))
}

func assert(source, target reflect.Value) error {
	// Deference interface/pointers for direct comparison
	for canElem(source) {
		source = source.Elem()
	}
	for canElem(target) {
		target = target.Elem()
	}

	if source.Type() != target.Type() {
		return &Error{Message: fmt.Sprintf("type mismatch: %T != %T", source.Interface(), target.Interface())}
	}

	switch source.Kind() {
	case reflect.Slice, reflect.Array:
		if source.Len() != target.Len() {
			return &Error{Message: fmt.Sprintf("length mismatch: %d != %d", source.Len(), target.Len())}
		}
		for i := 0; i < source.Len(); i++ {
			if err := assert(source.Index(i), target.Index(i)); err != nil {
				return &Error{
					Message: fmt.Sprintf("element %d", i),
					Inner:   err,
				}
			}
		}
		return nil

	case reflect.Map:
		iter := source.MapRange()
		for iter.Next() {
			var (
				sourceElement = iter.Value()
				targetElement = target.MapIndex(iter.Key())
			)
			if !targetElement.IsValid() {
				return &Error{Message: fmt.Sprintf("missing key %v", iter.Key().Interface())}
			}
			if err := assert(sourceElement, targetElement); err != nil {
				return &Error{
					Message: fmt.Sprintf("%v", iter.Key().Interface()),
					Inner:   err,
				}
			}
		}
		return nil

	default:
		if !reflect.DeepEqual(source.Interface(), target.Interface()) {
			return &Error{Message: fmt.Sprintf("%v != %v", source, target)}
		}
		return nil
	}
}

func canElem(v reflect.Value) bool {
	return v.Kind() == reflect.Interface || v.Kind() == reflect.Ptr
}

// Error is a subset assertion error.
type Error struct {
	Message string // Message of the error
	Inner   error  // Optional inner error
}

// Error implements error.
func (e *Error) Error() string {
	if e.Inner == nil {
		return e.Message
	}
	return fmt.Sprintf("%s: %s", e.Message, e.Inner)
}

// Unwrap returns the inner error, if set.
func (e *Error) Unwrap() error { return e.Inner }

// YAMLAssert is like Assert but accepts YAML bytes as input.
func YAMLAssert(source, target []byte) error {
	var sourceValue interface{}
	if err := yaml.Unmarshal(source, &sourceValue); err != nil {
		return err
	}
	var targetValue interface{}
	if err := yaml.Unmarshal(target, &targetValue); err != nil {
		return err
	}
	return Assert(sourceValue, targetValue)
}

'''
'''--- pkg/util/subset/subset_test.go ---
package subset

import (
	"testing"

	"github.com/stretchr/testify/require"
)

func TestAssert(t *testing.T) {
	tt := []struct {
		name           string
		source, target string
		expect         string
	}{
		// Plain values
		{
			name:   "values match",
			source: `true`,
			target: `true`,
			expect: "",
		},
		{
			name:   "values mismatch",
			source: `true`,
			target: `false`,
			expect: "true != false",
		},
		{
			name:   "type mismatch",
			source: `true`,
			target: `5`,
			expect: "type mismatch: bool != int",
		},

		// Arrays
		{
			name:   "arrays match",
			source: `[1, 2, 3]`,
			target: `[1, 2, 3]`,
			expect: "",
		},
		{
			name:   "arrays mismatch",
			source: `[1, 2, 3]`,
			target: `[1, 2, 4]`,
			expect: "element 2: 3 != 4",
		},
		{
			name:   "array element type mismatch",
			source: `[1, 2, 3]`,
			target: `[1, 2, true]`,
			expect: "element 2: type mismatch: int != bool",
		},

		// Maps
		{
			name:   "maps match",
			source: `{"hello": "world"}`,
			target: `{"hello": "world"}`,
			expect: "",
		},
		{
			name:   "maps mismatch",
			source: `{"hello": "world", "year": 2000}`,
			target: `{"hello": "world", "year": 2001}`,
			expect: "year: 2000 != 2001",
		},
		{
			name:   "maps subset",
			source: `{"hello": "world"}`,
			target: `{"hello": "world", "year": 2001}`,
			expect: "",
		},
		{
			name:   "maps type mismatch",
			source: `{"hello": "world", "year": 2000}`,
			target: `{"hello": "world", "year": "yes"}`,
			expect: "year: type mismatch: int != string",
		},
	}

	for _, tc := range tt {
		t.Run(tc.name, func(t *testing.T) {
			err := YAMLAssert([]byte(tc.source), []byte(tc.target))
			if tc.expect == "" {
				require.NoError(t, err)
			} else {
				require.EqualError(t, err, tc.expect)
			}
		})
	}
}

'''
'''--- pkg/util/test_logger.go ---
package util

import (
	"os"
	"testing"
	"time"

	"github.com/go-kit/log"
)

// TestLogger generates a logger for a test.
func TestLogger(t *testing.T) log.Logger {
	t.Helper()

	l := log.NewSyncLogger(log.NewLogfmtLogger(os.Stderr))
	l = log.WithPrefix(l,
		"test", t.Name(),
		"ts", log.Valuer(testTimestamp),
	)

	return l
}

// testTimestamp is a log.Valuer that returns the timestamp
// without the date or timezone, reducing the noise in the test.
func testTimestamp() interface{} {
	t := time.Now().UTC()
	return t.Format("15:04:05.000")
}

'''
'''--- pkg/util/trigger.go ---
package util

import (
	"context"
	"sync"
	"time"

	"go.uber.org/atomic"
)

// WaitTrigger allows for waiting for a specific condition to be met.
// Useful for tests.
type WaitTrigger struct {
	completed atomic.Bool
	mut       *sync.Mutex
	cond      *sync.Cond
}

// NewWaitTrigger creates a new WaitTrigger.
func NewWaitTrigger() *WaitTrigger {
	var mut sync.Mutex
	cond := sync.NewCond(&mut)
	return &WaitTrigger{mut: &mut, cond: cond}
}

// Trigger completes the trigger and alerts all waiting. Calling Trigger again
// after the first invocation is a no-op.
func (wt *WaitTrigger) Trigger() {
	wt.mut.Lock()
	defer wt.mut.Unlock()
	wt.completed.Store(true)
	wt.cond.Broadcast()
}

// Wait waits for trigger to complete up to the specified timeout. Returns an
// error if the timeout expires.
func (wt *WaitTrigger) Wait(timeout time.Duration) error {
	ctx, cancel := context.WithTimeout(context.Background(), timeout)
	defer cancel()
	return wt.WaitContext(ctx)
}

// WaitContext waits for trigger to complete or for the context to cancel.
// Returns an error if ctx gets canceled.
func (wt *WaitTrigger) WaitContext(ctx context.Context) error {
	parentCtx := ctx

	ctx, cancel := context.WithCancel(parentCtx)
	defer cancel()

	go func() {
		<-ctx.Done()

		// Ignore cancellations from our child context.
		if parentCtx.Err() != nil {
			wt.cond.Broadcast()
		}
	}()

	wt.mut.Lock()
	for ctx.Err() == nil && !wt.completed.Load() {
		wt.cond.Wait()
	}
	err := parentCtx.Err()
	wt.mut.Unlock()
	return err
}

'''
'''--- pkg/util/trigger_test.go ---
package util

import (
	"context"
	"testing"
	"time"

	"github.com/stretchr/testify/require"
)

func TestWaitTrigger(t *testing.T) {
	t.Run("timeout", func(t *testing.T) {
		wt := NewWaitTrigger()
		err := wt.Wait(time.Millisecond * 100)
		require.ErrorIs(t, err, context.DeadlineExceeded)
	})

	t.Run("no timeout", func(t *testing.T) {
		wt := NewWaitTrigger()

		go func() {
			<-time.After(100 * time.Millisecond)
			wt.Trigger()
		}()

		err := wt.Wait(time.Second)
		require.NoError(t, err)
	})
}

'''
'''--- pkg/util/unregisterer.go ---
package util

import "github.com/prometheus/client_golang/prometheus"

// Unregisterer is a Prometheus Registerer that can unregister all collectors
// passed to it.
type Unregisterer struct {
	wrap prometheus.Registerer
	cs   map[prometheus.Collector]struct{}
}

// WrapWithUnregisterer wraps a prometheus Registerer with capabilities to
// unregister all collectors.
func WrapWithUnregisterer(reg prometheus.Registerer) *Unregisterer {
	return &Unregisterer{
		wrap: reg,
		cs:   make(map[prometheus.Collector]struct{}),
	}
}

// Register implements prometheus.Registerer.
func (u *Unregisterer) Register(c prometheus.Collector) error {
	if u.wrap == nil {
		return nil
	}

	err := u.wrap.Register(c)
	if err != nil {
		return err
	}
	u.cs[c] = struct{}{}
	return nil
}

// MustRegister implements prometheus.Registerer.
func (u *Unregisterer) MustRegister(cs ...prometheus.Collector) {
	for _, c := range cs {
		if err := u.Register(c); err != nil {
			panic(err)
		}
	}
}

// Unregister implements prometheus.Registerer.
func (u *Unregisterer) Unregister(c prometheus.Collector) bool {
	if u.wrap != nil && u.wrap.Unregister(c) {
		delete(u.cs, c)
		return true
	}
	return false
}

// UnregisterAll unregisters all collectors that were registered through the
// Reigsterer.
func (u *Unregisterer) UnregisterAll() bool {
	success := true
	for c := range u.cs {
		if !u.Unregister(c) {
			success = false
		}
	}
	return success
}

'''
'''--- pkg/util/untab.go ---
package util

import "strings"

// Untab is a utility function for tests to make it easier
// to write YAML tests, where some editors will insert tabs
// into strings by default.
func Untab(s string) string {
	return strings.ReplaceAll(s, "\t", "  ")
}

'''
'''--- pkg/util/yaml.go ---
package util

import (
	"errors"
	"regexp"
	"sort"

	"gopkg.in/yaml.v2"
)

// RawYAML is similar to json.RawMessage and allows for deferred YAML decoding.
type RawYAML []byte

// UnmarshalYAML implements yaml.Unmarshaler.
func (r *RawYAML) UnmarshalYAML(unmarshal func(interface{}) error) error {
	var ms yaml.MapSlice
	if err := unmarshal(&ms); err != nil {
		return err
	}
	bb, err := yaml.Marshal(ms)
	if err != nil {
		return err
	}
	*r = bb
	return nil
}

// MarshalYAML implements yaml.Marshaler.
func (r RawYAML) MarshalYAML() (interface{}, error) {
	return r.Map()
}

// Map converts the raw YAML into a yaml.MapSlice.
func (r RawYAML) Map() (yaml.MapSlice, error) {
	var ms yaml.MapSlice
	if err := yaml.Unmarshal(r, &ms); err != nil {
		return nil, err
	}
	return ms, nil
}

// MarshalYAMLMerged marshals all values from vv into a single object.
func MarshalYAMLMerged(vv ...interface{}) ([]byte, error) {
	var full yaml.MapSlice
	for _, v := range vv {
		bb, err := yaml.Marshal(v)
		if err != nil {
			return nil, err
		}
		ms, err := RawYAML(bb).Map()
		if err != nil {
			return nil, err
		}
		full = append(full, ms...)
	}
	return yaml.Marshal(full)
}

// UnmarshalYAMLMerged performs a strict unmarshal of bb into all values from
// vv.
func UnmarshalYAMLMerged(bb []byte, vv ...interface{}) error {
	var typeErrors []yaml.TypeError

	for _, v := range vv {
		// Perform a strict unmarshal. This is likely to fail with type errors for
		// missing fields that may have been consumed by another object in vv.
		var te *yaml.TypeError
		if err := yaml.UnmarshalStrict(bb, v); errors.As(err, &te) {
			typeErrors = append(typeErrors, *te)
		} else if err != nil {
			return err
		}

		// It's common for custom yaml.Unmarshaler implementations to use
		// UnmarshalYAML to apply default values both before and after calling the
		// unmarshal method passed to them.
		//
		// We *must* do a second non-strict unmarshal *after* the strict unmarshal
		// to ensure that every v was able to complete its unmarshal to completion,
		// ignoring type errors from unrecognized fields.
		if err := yaml.Unmarshal(bb, v); err != nil {
			return err
		}
	}

	var (
		addedErrors    = map[string]struct{}{}
		notFoundErrors = map[string]int{}
	)

	// Do an initial pass over our errors, separating errors for not found fields.
	// Other errors are "real" and should be returned.
	for _, te := range typeErrors {
		for _, msg := range te.Errors {
			notFound := notFoundErrRegex.FindStringSubmatch(msg)
			if notFound != nil {
				// Track the invalid field error. Use the first capture group which
				// excludes the type, which will be unique per v.
				notFoundErrors[notFound[1]]++
				continue
			}
			addedErrors[msg] = struct{}{}
		}
	}

	// Iterate over our errors for not found fields. The field truly isn't defined
	// if it was reported len(vv) times (i.e., no v consumed it).
	for msg, count := range notFoundErrors {
		if count == len(vv) {
			addedErrors[msg] = struct{}{}
		}
	}

	if len(addedErrors) > 0 {
		realErrors := make([]string, 0, len(addedErrors))
		for msg := range addedErrors {
			realErrors = append(realErrors, msg)
		}
		sort.Strings(realErrors)
		return &yaml.TypeError{Errors: realErrors}
	}
	return nil
}

var notFoundErrRegex = regexp.MustCompile(`^(line \d+: field .* not found) in type .*$`)

'''
'''--- pkg/util/yaml_test.go ---
package util

import (
	"testing"

	"github.com/stretchr/testify/require"
)

// TestUnmarshalYAMLMerged_CustomUnmarshal checks to see that
// UnmarshalYAMLMerged works with merging types that have custom unmarshal
// methods which do extra checks after calling unmarshal.
func TestUnmarshalYAMLMerged_CustomUnmarshal(t *testing.T) {
	in := `
  fieldA: foo
  fieldB: bar
  `

	var (
		val1 typeOne
		val2 typeTwo
	)

	err := UnmarshalYAMLMerged([]byte(in), &val1, &val2)
	require.NoError(t, err)

	require.Equal(t, "foo", val1.FieldA)
	require.Equal(t, "bar", val2.FieldB)
	require.True(t, val2.Unmarshaled)
}

type typeOne struct {
	FieldA string `yaml:"fieldA"`
}

type typeTwo struct {
	FieldB      string `yaml:"fieldB"`
	Unmarshaled bool   `yaml:"-"`
}

func (t *typeTwo) UnmarshalYAML(unmarshal func(interface{}) error) error {
	type rawType typeTwo
	if err := unmarshal((*rawType)(t)); err != nil {
		return err
	}
	t.Unmarshaled = true
	return nil
}

'''
'''--- production/grafana-agent-mixin/jsonnetfile.json ---
{
  "dependencies": [
    {
      "name": "grafana-builder",
      "source": {
        "git": {
          "remote": "https://github.com/grafana/jsonnet-libs",
          "subdir": "grafana-builder"
        }
      },
      "version": "master"
    },
    {
      "name": "grafonnet",
      "source": {
        "git": {
          "remote": "https://github.com/grafana/grafonnet-lib",
          "subdir": "grafonnet"
        }
      },
      "version": "master"
    }
  ]
}

'''
'''--- production/grafanacloud-install.ps1 ---
# Script to install Grafana agen for Windows
param ($GCLOUD_STACK_ID, $GCLOUD_API_KEY, $GCLOUD_API_URL)

Write-Host "Setting up Grafana agent"

if ( -Not [bool](([System.Security.Principal.WindowsIdentity]::GetCurrent()).groups -match "S-1-5-32-544") ) {
	Write-Host "ERROR: The script needs to be run with Administrator privileges"
	exit
}

# Check if required parameters are present
if ($GCLOUD_STACK_ID -eq "") {
	Write-Host "ERROR: Required argument GCLOUD_STACK_ID missing"
	exit
}

if ($GCLOUD_API_KEY -eq "") {
	Write-Host "ERROR:  Required argument GCLOUD_API_KEY missing"
	exit
}

if ($GCLOUD_API_URL -eq "") {
	Write-Host "ERROR: Required argument GCLOUD_API_URL missing"
	exit
}

Write-Host "GCLOUD_STACK_ID:" $GCLOUD_STACK_ID
Write-Host "GCLOUD_API_KEY:" $GCLOUD_API_KEY
Write-Host "GCLOUD_API_URL:" $GCLOUD_API_URL

# Install Module Powershell-yaml required to convert agent config from json to yaml
Write-Host "Checking and installing required Powershell-yaml module"
Install-Module PowerShell-yaml

Write-Host "Downloading Grafana agent Windows Installer"
$DOWLOAD_URL = "https://github.com/grafana/agent/releases/latest/download/grafana-agent-installer.exe"
$OUTPUT_FILE = ".\grafana-agent-installer.exe"
Invoke-WebRequest -Uri $DOWLOAD_URL -OutFile $OUTPUT_FILE

# Install Grafana agent in silent mode
Write-Host "Installing Grafana agent for Windows"
.\grafana-agent-installer.exe /S

Write-Host "Retrieving and updating Grafana agent config"
$CONFIG_URI = "$GCLOUD_API_URL/stacks/$GCLOUD_STACK_ID/agent_config?platforms=windows"
$AUTH_TOKEN = "Bearer $GCLOUD_API_KEY"

$headers = @{
    Authorization = $AUTH_TOKEN
}

$response = Invoke-WebRequest $CONFIG_URI -Method 'GET' -Headers $headers

$jsonObj = $response | ConvertFrom-Json
if ($jsonObj.status -eq "success") {
	$config_file = ".\agent-config.yaml"
	Write-Host "Saving and updating agent configuration file"
	$yamlConfig = $jsonObj.data | ConvertTo-Yaml
	Set-Content -Path $config_file -Value ($yamlConfig)
    # Append APPDATA path to bookmark files
    $line = Get-Content $config_file | Select-String bookmark_path | Select-Object -ExpandProperty Line
    if ($line -ne $null) {
        $content = Get-Content $config_file
        $line | ForEach-Object {  
            $split_line = $_ -split ": "
            $prefix = $split_line[0]
            $bookmark_filename = $split_line[1] -replace "./",""
            $content = $content -replace $_,"$($prefix): $($env:APPDATA)\$($bookmark_filename)"
        }
        $content | Set-Content $config_file
    }
    Move-Item $config_file "C:\Program Files\Grafana Agent\agent-config.yaml" -force

	# Wait for service to initialize after first install
	Write-Host "Wait for Grafana service to initialize"
	Start-Sleep -s 5

	# Restart Grafana agent to load new configuration
	Write-Host "Restarting Grafana agent service"
	Stop-Service "Grafana Agent"
	Start-Service "Grafana Agent"

	# Wait for service to startup after restart
	Write-Host "Wait for Grafana service to initialize after restart"
	Start-Sleep -s 10

	# Show Grafana agent service status
	Get-Service "Grafana Agent"
} else {
	Write-Host "Failed to retrieve config"
}

'''
'''--- production/grafanacloud-install.sh ---
#!/usr/bin/env sh
# shellcheck shell=dash
# This script should run in all POSIX environments and Dash is POSIX compliant.

# grafanacloud-install.sh installs the Grafana Agent on supported
# Linux systems for Grafana Cloud users. Those who aren't users of Grafana Cloud
# or need to install the Agent on a different architecture or platform should
# try another installation method.
#
# grafanacloud-install.sh has a hard dependency on being run on a supported
# Linux system. Currently only systems that can install deb or rpm packages
# are supported. The target system will try to be detected, but if it cannot,
# PACKAGE_SYSTEM can be passed as an environment variable with either rpm or
# deb.
set -eu
trap "exit 1" TERM
MY_PID=$$

log() {
  echo "$@" >&2
}

fatal() {
  log "$@"
  kill -s TERM "$MY_PID"
}

#
# REQUIRED environment variables.
#
GCLOUD_STACK_ID=${GCLOUD_STACK_ID:=} # Stack ID where integrations are installed
GCLOUD_API_KEY=${GCLOUD_API_KEY:=}   # API key to authenticate against Grafana Cloud's API with
GCLOUD_API_URL=${GCLOUD_API_URL:=}   # Grafana Cloud's API url

[ -z "$GCLOUD_STACK_ID" ] && fatal "Required environment variable \$GCLOUD_STACK_ID not set."
[ -z "$GCLOUD_API_KEY" ]  && fatal "Required environment variable \$GCLOUD_API_KEY not set."

#
# OPTIONAL environment variables.
#

# Architecture to install.
ARCH=${ARCH:=amd64}

# Package system to install the Agent with. If not empty, MUST be either rpm or
# deb. If empty, the script will try to detect the host OS and the appropriate
# package system to use.
PACKAGE_SYSTEM=${PACKAGE_SYSTEM:=}

#
# Global constants.
#
RELEASE_VERSION="0.26.1"

RELEASE_URL="https://github.com/grafana/agent/releases/download/v${RELEASE_VERSION}"
DEB_URL="${RELEASE_URL}/grafana-agent-${RELEASE_VERSION}-1.${ARCH}.deb"
RPM_URL="${RELEASE_URL}/grafana-agent-${RELEASE_VERSION}-1.${ARCH}.rpm"

main() {
  if [ -z "$PACKAGE_SYSTEM" ]; then
    PACKAGE_SYSTEM=$(detect_package_system)
  fi
  log "--- Using package system $PACKAGE_SYSTEM. Downloading and installing package for ${ARCH}"

  case "$PACKAGE_SYSTEM" in
    deb)
      install_deb
      ;;
    rpm)
      install_rpm
      ;;
    *)
      fatal "Unsupported PACKAGE_SYSTEM value $PACKAGE_SYSTEM. Must be either rpm or deb".
      ;;
  esac

  log '--- Retrieving config and placing in /etc/grafana-agent.yaml'
  retrieve_config | sudo tee /etc/grafana-agent.yaml

  log '--- Enabling and starting grafana-agent.service'
  sudo systemctl enable grafana-agent.service
  sudo systemctl start grafana-agent.service

  # Add some empty newlines to give some visual whitespace before printing the
  # success message.
  log ''
  log ''
  log 'Grafana Agent is now running! To check the status of your Agent, run:'
  log '   sudo systemctl status grafana-agent.service'
}

# detect_package_system tries to detect the host distribution to determine if
# deb or rpm should be used for installing the Agent. Prints out either "deb"
# or "rpm". Calls fatal if the host OS is not supported.
detect_package_system() {
  command -v dpkg >/dev/null 2>&1 && { echo "deb"; return; }
  command -v rpm  >/dev/null 2>&1 && { echo "rpm"; return; }

  case "$(uname)" in
    Darwin)
      fatal 'macOS not supported'
      ;;
    *)
      fatal "Unknown unsupported OS: $(uname)"
      ;;
  esac
}

# install_deb downloads and installs the deb package of the Grafana Agent.
install_deb() {
  curl -fL# "${DEB_URL}" -o /tmp/grafana-agent.deb || fatal 'Failed to download package'
  sudo dpkg -i /tmp/grafana-agent.deb
  rm /tmp/grafana-agent.deb
}

# install_rpm downloads and installs the deb package of the Grafana Agent.
install_rpm() {
  sudo rpm --reinstall "${RPM_URL}"
}

# retrieve_config downloads the config file for the Agent and prints out its
# contents to stdout.
retrieve_config() {
  if ! grafana-agentctl cloud-config -u "${GCLOUD_STACK_ID}" -p "${GCLOUD_API_KEY}" -e "${GCLOUD_API_URL}" 2>/dev/null; then
    fatal "Failed to retrieve config"
  fi
}

main

'''
'''--- production/kubernetes/README.md ---
# Kubernetes Config

This directory contains Kubernetes manifest templates for rolling out the Agent.

Manifests:

- Metric collection (StatefulSet): [`agent-bare.yaml`](./agent-bare.yaml)
- Log collection (DaemonSet): [`agent-loki.yaml`](./agent-loki.yaml)
- Trace collection (Deployment): [`agent-traces.yaml`](./agent-traces.yaml)

  **These manifests do not include the Agent's configuration (ConfigMaps)**,
which are necessary to run the Agent.

For sample configurations and detailed installation instructions, please head to:

- [Grafana Agent Metrics Kubernetes Quickstart](https://grafana.com/docs/grafana-cloud/quickstart/agent-k8s/k8s_agent_metrics/)
- [Grafana Agent Logs Kubernetes Quickstart](https://grafana.com/docs/grafana-cloud/quickstart/agent-k8s/k8s_agent_logs/)
- [Grafana Agent Traces Kubernetes Quickstart](https://grafana.com/docs/grafana-cloud/quickstart/agent-k8s/k8s_agent_traces/)

## Manually Applying

Since the manifest files are just templates, note that they are *not* ready for
applying out of the box and you will have to manually perform the following steps:

1. Download the manifest as `manifest.yaml`

2. Modify your copy of the manifest, replacing relevant variables with the appropriate values

3. Apply the modified manifest file: `kubectl -ndefault apply -f manifest.yaml`.

This directory also contains an `install-bare.sh` script that is used inside of
Grafana Cloud instructions. If using the Grafana Agent outside of Grafana Cloud,
it is recommended to follow the steps above instead of calling this script
directly.

## Rebuilding the manifests

The manifests provided are created using Grafana Labs' production
[Tanka configs](../tanka/grafana-agent) with some default values. If you want to
build the YAML file with some custom values, you will need the following pieces
of software installed:

1. [Tanka](https://github.com/grafana/tanka) >= v0.8
2. [`jsonnet-bundler`](https://github.com/jsonnet-bundler/jsonnet-bundler) >= v0.2.1

See the [`template` Tanka environment](./build/templates) for the current
settings that initialize the Grafana Agent Tanka configs.

To build the YAML files, execute the `./build/build.sh` script or run `make example-kubernetes`
from the project's root directory.

'''
'''--- production/kubernetes/build/build.sh ---
#!/usr/bin/env bash
# shellcheck shell=bash

set +e

DIRNAME=$(dirname "$0")

pushd "${DIRNAME}" || exit 1
# Make sure dependencies are up to date
jb install
tk show --dangerous-allow-redirect ./templates/bare > "${PWD}/../agent-bare.yaml"
tk show --dangerous-allow-redirect ./templates/loki > "${PWD}/../agent-loki.yaml"
tk show --dangerous-allow-redirect ./templates/traces > "${PWD}/../agent-traces.yaml"
tk show --dangerous-allow-redirect ./templates/operator > "${PWD}/../../operator/templates/agent-operator.yaml"
popd || exit 1

'''
'''--- production/kubernetes/build/jsonnetfile.json ---
{
  "version": 1,
  "dependencies": [
    {
      "source": {
        "git": {
          "remote": "https://github.com/grafana/jsonnet-libs.git",
          "subdir": "ksonnet-util"
        }
      },
      "version": "master"
    },
    {
      "source": {
        "git": {
          "remote": "https://github.com/jsonnet-libs/k8s-libsonnet.git",
          "subdir": "1.21"
        }
      },
      "version": "main"
    },
    {
      "source": {
        "git": {
          "remote": "https://github.com/kubernetes/kube-state-metrics.git",
          "subdir": "jsonnet/kube-state-metrics"
        }
      },
      "version": "v2.5.0"
    },
    {
      "source": {
        "local": {
          "directory": "../../tanka/grafana-agent"
        }
      },
      "version": ""
    },
    {
      "source": {
        "local": {
          "directory": "../../tanka/grafana-agent-operator"
        }
      },
      "version": ""
    }
  ],
  "legacyImports": true
}

'''
'''--- production/kubernetes/build/jsonnetfile.lock.json ---
{
  "version": 1,
  "dependencies": [
    {
      "source": {
        "git": {
          "remote": "https://github.com/grafana/jsonnet-libs.git",
          "subdir": "ksonnet-util"
        }
      },
      "version": "28a9c400acbc02994ea8b08494571c7b476096b6",
      "sum": "OxgtIWL4hjvG0xkMwUzZ7Yjs52zUhLhaVQpwHCbqf8A="
    },
    {
      "source": {
        "git": {
          "remote": "https://github.com/jsonnet-libs/grafana-agent-libsonnet.git",
          "subdir": "0.26"
        }
      },
      "version": "4763fb9dd69acd7c32ea34a708328ad7d1984100",
      "sum": "AcBuxWZhGRgcfHFUxYRUOhAnQ9FnEP37fVl68jAQNc8=",
      "name": "agent-operator-gen"
    },
    {
      "source": {
        "git": {
          "remote": "https://github.com/jsonnet-libs/k8s-libsonnet.git",
          "subdir": "1.21"
        }
      },
      "version": "f8efa81cf15257bd151b97e31599e20b2ba5311b",
      "sum": "FYub7WxElJkqjjXA++DemsKHwsPqUFW945BTgpVop6Q="
    },
    {
      "source": {
        "git": {
          "remote": "https://github.com/jsonnet-libs/prometheus-operator-libsonnet.git",
          "subdir": "0.57"
        }
      },
      "version": "daddbdd13374107f78a2489301f7c23ae1eb0b16",
      "sum": "8+yZ7FalORuq5ZGpqSnSa+/4YQcPa7x9rClXcjgGCq0=",
      "name": "prom-operator-gen"
    },
    {
      "source": {
        "git": {
          "remote": "https://github.com/kubernetes/kube-state-metrics.git",
          "subdir": "jsonnet/kube-state-metrics"
        }
      },
      "version": "0567e1e1b981755e563d2244fa1659563f2cddbc",
      "sum": "P0dCnbzyPScQGNXwXRcwiPkMLeTq0IPNbSTysDbySnM="
    },
    {
      "source": {
        "local": {
          "directory": "../../tanka/grafana-agent"
        }
      },
      "version": ""
    },
    {
      "source": {
        "local": {
          "directory": "../../tanka/grafana-agent-operator"
        }
      },
      "version": ""
    }
  ],
  "legacyImports": false
}

'''
'''--- production/kubernetes/build/templates/bare/spec.json ---
{
  "apiVersion": "tanka.dev/v1alpha1",
  "kind": "Environment",
  "metadata": {
    "name": "template"
  },
  "spec": {
    "apiServer": "",
    "namespace": ""
  }
}

'''
'''--- production/kubernetes/build/templates/base-sigv4/spec.json ---
{
  "apiVersion": "tanka.dev/v1alpha1",
  "kind": "Environment",
  "metadata": {
    "name": "template"
  },
  "spec": {
    "apiServer": "",
    "namespace": ""
  }
}

'''
'''--- production/kubernetes/build/templates/base/spec.json ---
{
  "apiVersion": "tanka.dev/v1alpha1",
  "kind": "Environment",
  "metadata": {
    "name": "template"
  },
  "spec": {
    "apiServer": "",
    "namespace": ""
  }
}

'''
'''--- production/kubernetes/build/templates/loki/spec.json ---
{
  "apiVersion": "tanka.dev/v1alpha1",
  "kind": "Environment",
  "metadata": {
    "name": "template"
  },
  "spec": {
    "apiServer": "",
    "namespace": ""
  }
}

'''
'''--- production/kubernetes/build/templates/operator/spec.json ---
{
  "apiVersion": "tanka.dev/v1alpha1",
  "kind": "Environment",
  "metadata": {
    "name": "template"
  },
  "spec": {
    "apiServer": "",
    "namespace": ""
  }
}

'''
'''--- production/kubernetes/build/templates/traces/spec.json ---
{
  "apiVersion": "tanka.dev/v1alpha1",
  "kind": "Environment",
  "metadata": {
    "name": "template"
  },
  "spec": {
    "apiServer": "",
    "namespace": ""
  }
}

'''
'''--- production/kubernetes/install-bare.sh ---
#!/usr/bin/env bash
# shellcheck shell=bash

#
# install-bare.sh is an installer for the Agent without a ConfigMap. It is
# used during the Grafana Cloud integrations wizard and is not recommended
# to be used directly. Instead of calling this script directly, please
# make a copy of ./agent-bare.yaml and modify it for your needs.
#
# Note that agent-bare.yaml does not have a ConfigMap, so the Grafana Agent
# will not launch until one is created. For more information on setting up
# a ConfigMap, please refer to:
#
# Metrics quickstart: https://grafana.com/docs/grafana-cloud/quickstart/agent-k8s/k8s_agent_metrics/
# Logs quickstart: https://grafana.com/docs/grafana-cloud/quickstart/agent-k8s/k8s_agent_logs/
#

check_installed() {
  if ! type "$1" >/dev/null 2>&1; then
    echo "error: $1 not installed" >&2
    exit 1
  fi
}

check_installed curl
check_installed envsubst

MANIFEST_BRANCH=v0.26.1
MANIFEST_URL=${MANIFEST_URL:-https://raw.githubusercontent.com/grafana/agent/${MANIFEST_BRANCH}/production/kubernetes/agent-bare.yaml}
NAMESPACE=${NAMESPACE:-default}

export NAMESPACE

curl -fsSL "$MANIFEST_URL" | envsubst

'''
'''--- production/tanka/grafana-agent-operator/jsonnetfile.json ---
{
    "dependencies": [
        {
            "name": "ksonnet-util",
            "source": {
                "git": {
                    "remote": "https://github.com/grafana/jsonnet-libs",
                    "subdir": "ksonnet-util"
                }
            },
            "version": "master"
        },
        {
            "name": "agent-operator-gen",
            "source": {
              "git": {
                "remote": "https://github.com/jsonnet-libs/grafana-agent-libsonnet.git",
                "subdir": "0.26"
              }
            },
            "version": "main"
          },
          {
            "name": "prom-operator-gen",
            "source": {
              "git": {
                "remote": "https://github.com/jsonnet-libs/prometheus-operator-libsonnet.git",
                "subdir": "0.57"
              }
            },
            "version": "main"
          }
    ]
}

'''
'''--- production/tanka/grafana-agent/jsonnetfile.json ---
{
    "dependencies": [
        {
            "name": "ksonnet-util",
            "source": {
                "git": {
                    "remote": "https://github.com/grafana/jsonnet-libs",
                    "subdir": "ksonnet-util"
                }
            },
            "version": "master"
        }
    ]
}

'''
'''--- production/tanka/grafana-agent/v1/README.md ---
# Tanka Configs

**STATUS**: Abandoned. Use v0 (parent directory) or v2 instead.

This directory contains the Tanka configs that we use to deploy the Grafana
Agent. It is marked as `v1` and is incompatible with the `v0` configs
found in the [parent directory](../).

This library is currently a work in progress and backwards-incompatible changes
may occur. Once the library is considered complete, no further backwards
incompatible changes will be made.

## Capabilities

This library is significantly more flexible than its `v0` counterpart. It tries
to allow to deploy and configure the Agent in a feature matrix:

| Mechanism        | Metrics | Logs      | Traces | Integrations |
| ---------------- | ------- | --------- | ------ | ------------ |
| DaemonSet        | Yes     | Yes       | Yes    | Yes          |
| Deployment       | Yes     | No        | No     | No           |
| Scraping Service | Yes     | No        | No     | No           |

The library can be invoked multiple times to get full coverage. For example, you
may wish to deploy a scraping service for scalable metrics collection, and a
DaemonSet with just Loki Logs for log collection.

Trying to use the library in incompatible ways will generate errors. For
example, you may not deploy a scraping service with Loki logs collection.

## API

## Generate Agent Deployment

- `new(name, namespace)`: Create a new DaemonSet. This is the default mode to
  deploy the Agent.  Enables host filtering.
- `newDeployment(name, namespace)`: Create a new single-replica Deployment.
  Disables host filtering.
- `newScrapingService(name, namespace, replicas)`: (Not yet available). Create a
  scalable deployment of clustered Agents. Requires being given a KV store such as Redis or ETCD.

## Configure Metrics

- `withMetricsConfig(config)`: Creates a metrics config block.
- `defaultMetricsConfig`: Default metrics config block.
- `withMetricsInstances(instances)`: Creates a metrics instance config to
  tell the Agent what to scrape.
- `withRemoteWrite(remote_writes)`: Configures locations to remote write metrics
   to. Controls remote writes globally.
- `scrapeInstanceKubernetes`: Default metrics instance config to scrape from
  Kubernetes.

## Configure Logs

- `withLogsConfig(config)`: Creates a Logs config block to pass to the Agent.
- `newLogsClient(client_config)`: Creates a new client configuration to pass
  to `withLogsClients`.
- `withLogsClients(clients)`: Add a set of clients to a Logs config block.
- `scrapeKubernetesLogs`: Default Logs config that collects logs from Kubernetes
  pods.

## Configure Traces

- `withTracesConfig(config)`: Creates a Traces config block to pass to the Agent.
- `withTracesRemoteWrite(remote_write)`: Configures one or multiple locations to push spans to.
- `withTracesSamplingStrategies(strategies)`: Configures strategies for trace collection.
- `withTracesScrapeConfigs(scrape_configs)`: Configures scrape configs to attach
   labels to incoming spans.
- `tracesScrapeKubernetes`: Default scrape configs to collect meta information
   from pods. Aligns with the labels from `scrapeInstanceKubernetes` and
   `scrapeKubernetesLogs` so logs, metrics, and traces all use the same set of
   labels.

## General

- `withImages(images)`: Use custom images.
- `withConfigHash(include=true)`: Whether to include a config hash annotation.
- `withPortsMixin(ports)`: Mixin ports from `k.core.v1.containerPort` against
   the container and service.

'''
'''--- production/tanka/grafana-agent/v2/README.md ---
# Tanka Configs

**STATUS**: Work in progress, use of these configs is not recommended for production.

This directory contains the Tanka configs that we use to deploy the Grafana
Agent. It is marked as `v2` and is incompatible previous versions of the library
located in other directories.

This library is currently a work in progress and backwards-incompatible changes
may occur. Once the library is considered complete, no further backwards
incompatible changes will be made.

## Capabilities

This library is significantly simplified over the `v0` and `v1` counterparts.
Since there are many ways to combine the various functionalities of the Grafana
Agent, the `v2` library aims to stay out of your way and provide optional composible
helpers that may be useful for some people.

Users of the library will pick a controller for their deployment. They are
expected to know what feature are compatible with which controller:

| Controller       | Metrics              | Logs      | Traces | Integrations |
| ---------------- | -------------------  | --------- | ------ | ------------ |
| DaemonSet        | If host filtering    | Yes       | Yes    | No           |
| Deployment       | Yes                  | No        | No     | Yes          |
| StatefulSet      | Yes                  | No        | No     | Yes          |

Creating an incompatible deployment will cause runtime issues when running the
Agent (for example, if configuring Logs with a StatefulSet, you will only get
logs from the node the pods are running on).

To get full coverage of features, you must create multiple deployments of the
library. You may wish to combine a StatefulSet for metrics and integrations, a
Deployment for Traces, and a DaemonSet for logs.

## API

## Generate Agent Deployment

- `new(name='grafana-agent', namespace='')`: Create a new Agent without a
   controller.
- `withDeploymentController(replicas=1)`: Attach a Deployment as the Agent
  controller. Number of replicas may optionally be given.
- `withDaemonSetController()`: Attach a DaemonSet as the Agent controller.
- `withStatefulSetController(replicas=1, volumeClaims=[])`: Attach a StatefulSet
  as the Agent controller. Number of replicas and a set of volume claim
  templates may be given.

## Generate Scraping Service Syncer

The Scraping Service Syncer is used to sync metrics instance configs against the
scraping service config management API.

- `newSyncer(name='grafana-agent-sycner', namespace='', config={})`

## General

- `withAgentConfig(config)`: Provide a custom Agent config.
- `withArgsMixin(config)`: Pass a map of additional flags to set.
- `withMetricsPort(port)`: Value for the `http-metrics` port (default 80)
- `withImagesMixin(images)`: Use custom images instead of the defaults.
- `withConfigHash(include=true)`: Whether to include a config hash annotation.
- `withPortsMixin(ports=[])`: Mixin ports from `k.core.v1.containerPort` against
   the container and service.
- `withVolumesMixin(volumes=[])`: Volume to attach to the pod.
- `withVolumeMountsMixin(mounts=[])`: Volume mounts to attach to the container.

## Helpers

- `newKubernetesMetrics(config={})`: Creates a set of metrics scrape_configs for
  collecting metrics from Kubernetes pods.
- `newKubernetesLogs(config={})`: Creates a set of logs scrape_configs for
  collecting logs from Kubernetes pods.
- `newKubernetesTraces(config={})`: Creates a set of traces scrape_configs for
  associating spans with metadata from discovered Kubernetes pods.
- `withLogVolumeMounts(config={})`: Adds volume mounts to the controller for collecting
  logs.
- `withLogPermissions(config={})`: Runs the container as privileged and as the root user
  so logs can be collected properly.
- `withService(config)`: Add a service for the deployment, statefulset, or daemonset.
  Note that this must be called after any ports are added via `withPortsMixin`.

'''
'''--- tools/crow/README.md ---
# Crow

Crow is a tool similar to Tempo Vulture and Loki Canary that is used to smoke test Grafana Agent. Crow works by generating metrics, then validating them against Prometheus. Crow uses two endpoints; the traditional `/metrics` and then `/validate` that generates the results of Crow checking for successful samples.

Note: The `/validate` endpoint should only be checked by the Grafana Agent instance that is configured to remote_write. 
'''
'''--- tools/crow/main.go ---
// Comand grafana-agent-crow is a correctness checker tool that validates that
// scraped metrics are delivered to a remote_write endpoint. Inspired by Loki
// Canary and Cortex test-exporter.
package main

import (
	"context"
	"flag"
	"fmt"
	"os"

	// Adds version information
	_ "github.com/grafana/agent/pkg/build"
	"github.com/grafana/agent/pkg/server"

	"github.com/go-kit/log/level"
	"github.com/grafana/agent/pkg/crow"
	"github.com/prometheus/client_golang/prometheus"
	"github.com/prometheus/client_golang/prometheus/promhttp"
	"github.com/prometheus/common/version"
)

func init() {
	prometheus.MustRegister(version.NewCollector("grafana_agent_crow"))
}

func main() {
	var (
		fs = flag.NewFlagSet(os.Args[0], flag.ExitOnError)

		serverCfg   = server.DefaultConfig
		serverFlags = server.DefaultFlags

		crowCfg     = crow.DefaultConfig
		showVersion bool
	)

	serverFlags.RegisterFlags(fs)
	crowCfg.RegisterFlagsWithPrefix(fs, "crow.")
	fs.BoolVar(&showVersion, "version", false, "show version")

	if err := fs.Parse(os.Args[1:]); err != nil {
		fmt.Fprintln(os.Stderr, "failed to parse flags", err)
		os.Exit(1)
	}
	if showVersion {
		fmt.Println(version.Print(os.Args[0]))
		os.Exit(0)
	}

	l := server.NewLogger(&serverCfg)
	crowCfg.Log = l

	s, err := server.New(l, prometheus.DefaultRegisterer, prometheus.DefaultGatherer, serverCfg, serverFlags)
	if err != nil {
		level.Error(l).Log("msg", "failed to initialize server", "err", err)
		os.Exit(1)
	}

	c, err := crow.New(crowCfg)
	if err != nil {
		level.Error(l).Log("msg", "failed to initialize crow", "err", err)
		os.Exit(1)
	}
	defer c.Stop()

	// The server comes with a /metrics endpoint by default using s.Registerer.
	// Create a /validate endpoint to handle our validation metrics.
	validator := prometheus.NewRegistry()
	s.HTTP.Handle("/validate", promhttp.HandlerFor(validator, promhttp.HandlerOpts{
		EnableOpenMetrics: true,
	}))

	// Register crow's metrics to /metrics and /validate respectively.
	prometheus.DefaultRegisterer.MustRegister(c.StateMetrics())
	validator.MustRegister(c.TestMetrics())

	ctx, cancel := server.SignalContext(context.Background(), l)
	defer cancel()

	if err := s.Run(ctx); err != nil {
		level.Error(l).Log("msg", "server exited with error", "err", err)
		os.Exit(1)
	}
}

'''
'''--- tools/release-note.md ---
This is release `${RELEASE_TAG}` of the Grafana Agent.

### Upgrading
Read the [upgrade guide](https://grafana.com/docs/agent/${RELEASE_DOC_TAG}/upgrade-guide) for specific instructions on upgrading from older versions.

### Notable changes:
:warning: **ADD RELEASE NOTES HERE** :warning:

### Installation:
Grafana Agent is currently distributed in plain binary form, Docker container images, a Windows installer, and a Kubernetes install script. Choose whichever fits your use-case best.

#### Kubernetes 

Install directions [here.](https://grafana.com/docs/grafana-cloud/quickstart/agent-k8s/)

#### Docker container:

* https://hub.docker.com/r/grafana/agent

```bash
docker pull "grafana/agent:${RELEASE_TAG}"
```

#### Windows installer

The Windows installer is provided as a [release asset](https://github.com/grafana/agent/releases/download/${RELEASE_TAG}/grafana-agent-installer.exe) for x64 machines.

#### Binary

We provide precompiled binary executables for the most common operating systems. Choose from the assets below for your matching operating system. 

Note: ppc64le builds are currently considered secondary release targets and do not have the same level of support and testing as other platforms.

Example for the `linux` operating system on `amd64`:

```bash
# download the binary
curl -O -L "https://github.com/grafana/agent/releases/download/${RELEASE_TAG}/agent-linux-amd64.zip"

# extract the binary
unzip "agent-linux-amd64.zip"

# make sure it is executable
chmod a+x "agent-linux-amd64"
```

#### `agentctl`

`agentctl`, a tool for helping you interact with the Agent, is available as a Docker image:

```bash
docker pull "grafana/agentctl:${RELEASE_TAG}"
```

Or as a binary. Like before, choose the assets below that matches your operating system. For example, with `linux` on `amd64`:

```bash
# download the binary
curl -O -L "https://github.com/grafana/agent/releases/download/${RELEASE_TAG}/agentctl-linux-amd64.zip"

# extract the binary
unzip "agentctl-linux-amd64.zip"

# make sure it is executable
chmod a+x "agentctl-linux-amd64"
```

#### `agent-operator`

`agent-operator`, a Kubernetes Operator for the Grafana Agent, is available only as a Docker image:

```bash
docker pull "grafana/agent-operator:${RELEASE_TAG}"
```

'''
'''--- tools/rivereval/main.go ---
// Command rivereval reads a River file from disk, evaluates it as an
// expression, and prints the result as a River value.
package main

import (
	"fmt"
	"os"

	"github.com/grafana/agent/pkg/river/parser"
	"github.com/grafana/agent/pkg/river/token/builder"
	"github.com/grafana/agent/pkg/river/vm"
)

func main() {
	if err := run(); err != nil {
		fmt.Fprintln(os.Stderr, err)
	}
}

func run() error {
	args := os.Args[1:]

	if len(args) != 1 {
		return fmt.Errorf("usage: rivereval [file]")
	}

	contents, err := os.ReadFile(args[0])
	if err != nil {
		return err
	}

	// We currently can't support parsing entire files since eval.Evaluate
	// assumes you'll pass a block with a struct schema to it. This might be a
	// restriction we can loosen in the future.
	node, err := parser.ParseExpression(string(contents))
	if err != nil {
		return err
	}
	eval := vm.New(node)

	var v interface{}
	if err := eval.Evaluate(nil, &v); err != nil {
		return err
	}

	expr := builder.NewExpr()
	expr.SetValue(v)

	_, _ = expr.WriteTo(os.Stdout)
	fmt.Println() // Write an extra newline at the end
	return nil
}

'''
'''--- tools/riverfmt/main.go ---
package main

import (
	"bytes"
	"errors"
	"flag"
	"fmt"
	"io"
	"os"

	"github.com/grafana/agent/pkg/river/diag"
	"github.com/grafana/agent/pkg/river/parser"
	"github.com/grafana/agent/pkg/river/printer"
)

func main() {
	err := run()

	var diags diag.Diagnostics
	if errors.As(err, &diags) {
		for _, diag := range diags {
			fmt.Fprintln(os.Stderr, diag)
		}
		os.Exit(1)
	} else if err != nil {
		fmt.Fprintf(os.Stderr, "error: %s\n", err)
		os.Exit(1)
	}
}

func run() error {
	var (
		write bool
	)

	fs := flag.NewFlagSet("riverfmt", flag.ExitOnError)
	fs.BoolVar(&write, "w", write, "write result to (source) file instead of stdout")

	if err := fs.Parse(os.Args[1:]); err != nil {
		return err
	}

	args := fs.Args()
	switch len(args) {
	case 0:
		if write {
			return fmt.Errorf("cannot use -w with standard input")
		}
		return format("<stdin>", nil, os.Stdin, write)

	case 1:
		fi, err := os.Stat(args[0])
		if err != nil {
			return err
		}
		if fi.IsDir() {
			return fmt.Errorf("cannot format a directory")
		}
		f, err := os.Open(args[0])
		if err != nil {
			return err
		}
		defer f.Close()
		return format(args[0], fi, f, write)

	default:
		return fmt.Errorf("can only format one file")
	}
}

func format(filename string, fi os.FileInfo, r io.Reader, write bool) error {
	bb, err := io.ReadAll(r)
	if err != nil {
		return err
	}

	f, err := parser.ParseFile(filename, bb)
	if err != nil {
		return err
	}

	var buf bytes.Buffer
	if err := printer.Fprint(&buf, f); err != nil {
		return err
	}

	// Add a newline at the endi
	_, _ = buf.Write([]byte{'\n'})

	if !write {
		_, err := io.Copy(os.Stdout, &buf)
		return err
	}

	wf, err := os.OpenFile(filename, os.O_WRONLY|os.O_TRUNC|os.O_CREATE, fi.Mode().Perm())
	if err != nil {
		return err
	}
	defer wf.Close()

	_, err = io.Copy(wf, &buf)
	return err
}

'''
'''--- tools/smoke/internal/smoke.go ---
package smoke

import (
	"context"
	"flag"
	"fmt"
	"math/rand"
	"net/http"
	"time"

	"github.com/go-kit/log"
	"github.com/go-kit/log/level"
	"github.com/oklog/run"
	"k8s.io/client-go/kubernetes"
	"k8s.io/client-go/tools/clientcmd"
)

// Smoke is the top level object for a smoke test.
type Smoke struct {
	cfg    *Config
	logger log.Logger
	tasks  []repeatingTask

	fakeRemoteWriteHandler http.HandlerFunc
}

// Config struct to pass configuration to the Smoke constructor.
type Config struct {
	Kubeconfig        string
	Namespace         string
	PodPrefix         string
	FakeRemoteWrite   bool
	SimulateErrors    bool
	ErrorPercentage   float64
	ChaosFrequency    time.Duration
	MutationFrequency time.Duration
}

// RegisterFlags registers flags for the config to the given FlagSet.
func (c *Config) RegisterFlags(f *flag.FlagSet) {
	f.StringVar(&c.Namespace, "namespace", DefaultConfig.Namespace, "namespace smoke test should run in")
	f.StringVar(&c.Kubeconfig, "kubeconfig", DefaultConfig.Kubeconfig, "absolute path to the kubeconfig file")
	f.StringVar(&c.PodPrefix, "pod-prefix", DefaultConfig.PodPrefix, "prefix for grafana agent pods")
	f.BoolVar(&c.FakeRemoteWrite, "fake-remote-write", DefaultConfig.FakeRemoteWrite, "remote write endpoint for series which are discarded, useful for testing and not storing metrics")
	f.BoolVar(&c.SimulateErrors, "simulate-errors", DefaultConfig.SimulateErrors, "remote write endpoint will return a 500 error response randomly")
	f.Float64Var(&c.ErrorPercentage, "simulate-errors-percentage", DefaultConfig.ErrorPercentage, "percentage chance a request will result in an error")
	f.DurationVar(&c.ChaosFrequency, "chaos-frequency", DefaultConfig.ChaosFrequency, "chaos frequency duration")
	f.DurationVar(&c.MutationFrequency, "mutation-frequency", DefaultConfig.MutationFrequency, "mutation frequency duration")
}

// DefaultConfig holds defaults for Smoke settings.
var DefaultConfig = Config{
	Kubeconfig:        "",
	Namespace:         "default",
	PodPrefix:         "grafana-agent",
	FakeRemoteWrite:   false,
	SimulateErrors:    false,
	ErrorPercentage:   0.01,
	ChaosFrequency:    30 * time.Minute,
	MutationFrequency: 5 * time.Minute,
}

// New is the constructor for a Smoke object.
func New(logger log.Logger, cfg Config) (*Smoke, error) {
	s := &Smoke{
		cfg:    &cfg,
		logger: logger,
	}
	if s.logger == nil {
		s.logger = log.NewNopLogger()
	}

	// use the current context in kubeconfig. this falls back to in-cluster config if kubeconfig is empty
	config, err := clientcmd.BuildConfigFromFlags("", cfg.Kubeconfig)
	if err != nil {
		return nil, err
	}
	// creates the clientset
	clientset, err := kubernetes.NewForConfig(config)
	if err != nil {
		return nil, err
	}

	if cfg.FakeRemoteWrite {
		s.fakeRemoteWriteHandler = func(w http.ResponseWriter, _ *http.Request) {
			w.WriteHeader(http.StatusOK)
		}
		if cfg.SimulateErrors {
			rand.Seed(time.Now().UnixNano())
			s.fakeRemoteWriteHandler = func(w http.ResponseWriter, _ *http.Request) {
				if rnd := rand.Float64(); cfg.ErrorPercentage > rnd {
					w.WriteHeader(http.StatusInternalServerError)
					return
				}
				w.WriteHeader(http.StatusOK)
			}
		}
	}

	// add default tasks
	s.tasks = append(s.tasks,
		repeatingTask{
			Task: &deletePodTask{
				logger:    log.With(s.logger, "task", "delete_pod", "pod", "grafana-agent-0"),
				clientset: clientset,
				namespace: cfg.Namespace,
				pod:       fmt.Sprintf("%s-0", cfg.PodPrefix),
			},
			frequency: cfg.ChaosFrequency,
		},
		repeatingTask{
			Task: &deletePodBySelectorTask{
				logger:    log.With(s.logger, "task", "delete_pod_by_selector"),
				clientset: clientset,
				namespace: cfg.Namespace,
				selector:  fmt.Sprintf("name=%s-cluster", cfg.PodPrefix),
			},
			frequency: cfg.ChaosFrequency,
		},
		repeatingTask{
			Task: &scaleDeploymentTask{
				logger:      log.With(s.logger, "task", "scale_deployment", "deployment", "avalanche"),
				clientset:   clientset,
				namespace:   cfg.Namespace,
				deployment:  "avalanche",
				maxReplicas: 11,
				minReplicas: 2,
			},
			frequency: cfg.MutationFrequency,
		})

	return s, nil
}

func (s *Smoke) ServeHTTP(w http.ResponseWriter, r *http.Request) {
	s.fakeRemoteWriteHandler(w, r)
}

// Run starts the smoke test and runs the tasks concurrently.
func (s *Smoke) Run(ctx context.Context) error {
	var g run.Group
	ctx, cancel := context.WithCancel(ctx)
	defer cancel()
	taskFn := func(t repeatingTask) func() error {
		return func() error {
			tick := time.NewTicker(t.frequency)
			defer tick.Stop()
			for {
				select {
				case <-tick.C:
					if err := t.Run(ctx); err != nil {
						return err
					}
				case <-ctx.Done():
					return nil
				}
			}
		}
	}
	for _, task := range s.tasks {
		g.Add(taskFn(task), func(_ error) {
			cancel()
		})
	}

	if s.cfg.FakeRemoteWrite && s.fakeRemoteWriteHandler != nil {
		level.Info(s.logger).Log("msg", "serving fake remote-write endpoint on :19090")
		g.Add(func() error {
			return http.ListenAndServe(":19090", s)
		}, func(_ error) {
			cancel()
		})
	}

	return g.Run()
}

'''
'''--- tools/smoke/internal/tasks.go ---
package smoke

import (
	"context"
	"math/rand"
	"time"

	"github.com/go-kit/log"
	"github.com/go-kit/log/level"
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
	"k8s.io/client-go/kubernetes"
	"k8s.io/utils/pointer"
)

// The Task interface represents some unit of work performed concurrently.
type Task interface {
	Run(context.Context) error
}

type repeatingTask struct {
	Task
	frequency time.Duration
}

type deletePodTask struct {
	logger    log.Logger
	clientset kubernetes.Interface
	namespace string
	pod       string
}

func (t *deletePodTask) Run(ctx context.Context) error {
	level.Debug(t.logger).Log("msg", "deleting pod")
	if err := t.clientset.CoreV1().Pods(t.namespace).Delete(ctx, t.pod, metav1.DeleteOptions{
		GracePeriodSeconds: pointer.Int64(0),
	}); err != nil {
		level.Error(t.logger).Log("msg", "failed to delete pod", "err", err)
	}
	return nil
}

type scaleDeploymentTask struct {
	logger      log.Logger
	clientset   kubernetes.Interface
	namespace   string
	deployment  string
	maxReplicas int
	minReplicas int
}

func (t *scaleDeploymentTask) Run(ctx context.Context) error {
	newReplicas := rand.Intn(t.maxReplicas-t.minReplicas) + t.minReplicas
	level.Debug(t.logger).Log("msg", "scaling replicas", "replicas", newReplicas)

	scale, err := t.clientset.AppsV1().Deployments(t.namespace).
		GetScale(ctx, t.deployment, metav1.GetOptions{})
	if err != nil {
		level.Error(t.logger).Log("msg", "failed to get autoscalingv1.Scale object", "err", err)
		return nil
	}

	sc := *scale
	sc.Spec.Replicas = int32(newReplicas)
	_, err = t.clientset.AppsV1().Deployments(t.namespace).
		UpdateScale(ctx, t.deployment, &sc, metav1.UpdateOptions{})
	if err != nil {
		level.Error(t.logger).Log("msg", "failed to scale deployment", "err", err)
	}
	return nil
}

type deletePodBySelectorTask struct {
	logger    log.Logger
	clientset kubernetes.Interface
	namespace string
	selector  string
}

func (t *deletePodBySelectorTask) Run(ctx context.Context) error {
	list, err := t.clientset.CoreV1().Pods(t.namespace).List(ctx, metav1.ListOptions{
		LabelSelector: t.selector,
	})
	if err != nil {
		level.Error(t.logger).Log("msg", "failed to list pods", "err", err)
		return nil
	}

	l := len(list.Items)
	if l > 0 {
		i := rand.Intn(l)
		pod := list.Items[i].Name
		level.Debug(t.logger).Log("msg", "deleting pod", "pod", pod)
		if err := t.clientset.CoreV1().Pods(t.namespace).Delete(ctx, pod, metav1.DeleteOptions{
			GracePeriodSeconds: pointer.Int64(0),
		}); err != nil {
			level.Error(t.logger).Log("msg", "failed to delete pod", "pod", pod, "err", err)
		}
	}

	return nil
}

'''
'''--- tools/smoke/internal/tasks_test.go ---
package smoke

import (
	"context"
	"testing"

	"github.com/go-kit/log"
	"k8s.io/client-go/kubernetes"
	"k8s.io/client-go/kubernetes/fake"
)

// Note: these tests are mostly worthless at this point
// but would allow easy debugging of tasks as they become more
// complex. Using https://pkg.go.dev/k8s.io/client-go/testing#ObjectTracker
// to mock responses from the fake client is also possible.

func Test_deletePodBySelectorTask_Run(t1 *testing.T) {
	type fields struct {
		logger    log.Logger
		clientset kubernetes.Interface
		namespace string
		selector  string
	}
	type args struct {
		ctx context.Context
	}
	tests := []struct {
		name    string
		fields  fields
		args    args
		wantErr bool
	}{
		{
			name: "deletePodBySelectorTask",
			fields: fields{
				logger:    log.NewNopLogger(),
				clientset: fake.NewSimpleClientset(),
				namespace: "foo",
				selector:  "foo=bar",
			},
		},
	}
	for _, tt := range tests {
		t1.Run(tt.name, func(t1 *testing.T) {
			t := &deletePodBySelectorTask{
				logger:    tt.fields.logger,
				clientset: tt.fields.clientset,
				namespace: tt.fields.namespace,
				selector:  tt.fields.selector,
			}
			if err := t.Run(tt.args.ctx); (err != nil) != tt.wantErr {
				t1.Errorf("Run() error = %v, wantErr %v", err, tt.wantErr)
			}
		})
	}
}

func Test_deletePodTask_Run(t1 *testing.T) {
	type fields struct {
		logger    log.Logger
		clientset kubernetes.Interface
		namespace string
		pod       string
	}
	type args struct {
		ctx context.Context
	}
	tests := []struct {
		name    string
		fields  fields
		args    args
		wantErr bool
	}{
		{
			name: "deletePodTask",
			fields: fields{
				logger:    log.NewNopLogger(),
				clientset: fake.NewSimpleClientset(),
				namespace: "foo",
				pod:       "bar",
			},
		},
	}
	for _, tt := range tests {
		t1.Run(tt.name, func(t1 *testing.T) {
			t := &deletePodTask{
				logger:    tt.fields.logger,
				clientset: tt.fields.clientset,
				namespace: tt.fields.namespace,
				pod:       tt.fields.pod,
			}
			if err := t.Run(tt.args.ctx); (err != nil) != tt.wantErr {
				t1.Errorf("Run() error = %v, wantErr %v", err, tt.wantErr)
			}
		})
	}
}

func Test_scaleDeploymentTask_Run(t1 *testing.T) {
	type fields struct {
		logger      log.Logger
		clientset   kubernetes.Interface
		namespace   string
		deployment  string
		maxReplicas int
		minReplicas int
	}
	type args struct {
		ctx context.Context
	}
	tests := []struct {
		name    string
		fields  fields
		args    args
		wantErr bool
	}{
		{
			name: "scaleDeploymentTask",
			fields: fields{
				logger:      log.NewNopLogger(),
				clientset:   fake.NewSimpleClientset(),
				namespace:   "foo",
				deployment:  "bar",
				maxReplicas: 11,
				minReplicas: 2,
			},
		},
	}
	for _, tt := range tests {
		t1.Run(tt.name, func(t1 *testing.T) {
			t := &scaleDeploymentTask{
				logger:      tt.fields.logger,
				clientset:   tt.fields.clientset,
				namespace:   tt.fields.namespace,
				deployment:  tt.fields.deployment,
				maxReplicas: tt.fields.maxReplicas,
				minReplicas: tt.fields.minReplicas,
			}
			if err := t.Run(tt.args.ctx); (err != nil) != tt.wantErr {
				t1.Errorf("Run() error = %v, wantErr %v", err, tt.wantErr)
			}
		})
	}
}

'''
'''--- tools/smoke/main.go ---
package main

import (
	"context"
	"flag"
	"os"
	"time"

	"github.com/go-kit/log/level"
	"github.com/grafana/agent/pkg/server"
	smoke "github.com/grafana/agent/tools/smoke/internal"
	"github.com/weaveworks/common/logging"
)

func main() {
	var (
		cfg         smoke.Config
		logLevel    logging.Level
		logFormat   logging.Format
		withTimeout time.Duration
	)

	cfg.RegisterFlags(flag.CommandLine)
	logLevel.RegisterFlags(flag.CommandLine)
	logFormat.RegisterFlags(flag.CommandLine)
	flag.DurationVar(&withTimeout, "duration", time.Duration(0), "test duration")
	flag.Parse()

	logger := server.NewLoggerFromLevel(logLevel, logFormat)

	ctx := context.Background()
	if withTimeout > 0 {
		var cancel context.CancelFunc
		ctx, cancel = context.WithTimeout(ctx, withTimeout)
		defer cancel()
		level.Debug(logger).Log("msg", "running with duration", "duration", withTimeout.String())
	}

	level.Info(logger).Log("msg", "starting smoke test")
	smokeTest, err := smoke.New(logger, cfg)
	if err != nil {
		level.Error(logger).Log("msg", "error constructing smoke test", "err", err)
		os.Exit(1)
	}
	if err := smokeTest.Run(ctx); err != nil {
		level.Error(logger).Log("msg", "smoke test run failure", "err", err)
		os.Exit(1)
	}
}

'''