*GitHub Repository "NEAR-Edu/rust-playground"*

'''--- .github/ISSUE_TEMPLATE/crate-addition-or-update.md ---
---
name: Crate addition or update
about: Suggest a new or updated crate for the playground
title: Please add/update [cratename]
labels: wontfix
assignees: ''

---

Please read [our crate policy][policy]. Any issue opened for a new or updated crate version will be closed with a reference to the same policy.

[policy]: https://github.com/integer32llc/rust-playground/blob/master/CRATE_POLICY.md

'''
'''--- .github/workflows/ci.yml ---
# This file was generated by ci/generate and should not be modified by hand
---
name: Validate everything
'on':
  push:
    branches:
    - master
  pull_request_target:
    types:
    - labeled
    branches:
    - master
env:
  DOCKER_HUB_USERNAME: shepmaster
  GH_CONTAINER_REGISTRY_USERNAME: shepmaster
  AWS_ACCESS_KEY_ID: AKIAWESVHZ3JQAY5NM5K
jobs:
  build_compiler_containers:
    name: Build ${{ matrix.channel }} compiler container
    runs-on: ubuntu-latest
    strategy:
      matrix:
        channel:
        - stable
        - beta
        - nightly
    if: 'github.event_name == ''push'' || contains(github.event.pull_request.labels.*.name, ''CI: approved'')'
    env:
      IMAGE_NAME: ghcr.io/integer32llc/rust-playground-ci-rust-${{ matrix.channel }}
    steps:
    - name: Checkout code
      uses: actions/checkout@v2
      with:
        ref: "${{ github.event.pull_request.head.sha }}"
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v1
      with:
        driver-opts: image=moby/buildkit:master
    - name: Login to GitHub Container Registry
      uses: docker/login-action@v1
      with:
        registry: ghcr.io
        username: "${{ env.GH_CONTAINER_REGISTRY_USERNAME }}"
        password: "${{ secrets.GH_CONTAINER_REGISTRY_TOKEN }}"
    - name: Build and push 'toolchain' container
      env:
        TAG_PREFIX: "${{ env.IMAGE_NAME }}:toolchain"
      uses: docker/build-push-action@v2
      with:
        context: compiler/base/
        file: compiler/base/Dockerfile
        build-args: channel=${{ matrix.channel }}
        target: toolchain
        pull: true
        push: true
        tags: "${{ env.TAG_PREFIX }}--${{ github.run_id }}"
        cache-from: |-
          ${{ env.TAG_PREFIX }}--${{ github.run_id }}
          ${{ env.TAG_PREFIX }}--latest
        cache-to: type=inline
    - name: Build and push 'bare-sources' container
      env:
        TAG_PREFIX: "${{ env.IMAGE_NAME }}:bare-sources"
      uses: docker/build-push-action@v2
      with:
        context: compiler/base/
        file: compiler/base/Dockerfile
        build-args: channel=${{ matrix.channel }}
        target: bare-sources
        pull: true
        push: true
        tags: "${{ env.TAG_PREFIX }}--${{ github.run_id }}"
        cache-from: |-
          ${{ env.TAG_PREFIX }}--${{ github.run_id }}
          ${{ env.TAG_PREFIX }}--latest
        cache-to: type=inline
    - name: Build and push 'munge' container
      env:
        TAG_PREFIX: "${{ env.IMAGE_NAME }}:munge"
      uses: docker/build-push-action@v2
      with:
        context: compiler/base/
        file: compiler/base/Dockerfile
        build-args: channel=${{ matrix.channel }}
        target: munge
        pull: true
        push: true
        tags: "${{ env.TAG_PREFIX }}--${{ github.run_id }}"
        cache-from: |-
          ${{ env.TAG_PREFIX }}--${{ github.run_id }}
          ${{ env.TAG_PREFIX }}--latest
        cache-to: type=inline
    - name: Build and push 'sources' container
      env:
        TAG_PREFIX: "${{ env.IMAGE_NAME }}:sources"
      uses: docker/build-push-action@v2
      with:
        context: compiler/base/
        file: compiler/base/Dockerfile
        build-args: channel=${{ matrix.channel }}
        target: sources
        pull: true
        push: true
        tags: "${{ env.TAG_PREFIX }}--${{ github.run_id }}"
        cache-from: |-
          ${{ env.TAG_PREFIX }}--${{ github.run_id }}
          ${{ env.TAG_PREFIX }}--latest
        cache-to: type=inline
    - name: Build and push container
      uses: docker/build-push-action@v2
      with:
        context: compiler/base/
        file: compiler/base/Dockerfile
        build-args: channel=${{ matrix.channel }}
        pull: true
        push: true
        tags: "${{ env.IMAGE_NAME }}:${{ github.run_id }}"
        cache-from: |-
          ${{ env.IMAGE_NAME }}:${{ github.run_id }}
          ${{ env.IMAGE_NAME }}:latest
        cache-to: type=inline
  build_tool_containers:
    name: Build ${{ matrix.tool }} tool container
    runs-on: ubuntu-latest
    needs: build_compiler_containers
    strategy:
      matrix:
        tool:
        - clippy
        - miri
        - rustfmt
    if: 'github.event_name == ''push'' || contains(github.event.pull_request.labels.*.name, ''CI: approved'')'
    env:
      IMAGE_NAME: ghcr.io/integer32llc/rust-playground-ci-tool-${{ matrix.tool }}
    steps:
    - name: Checkout code
      uses: actions/checkout@v2
      with:
        ref: "${{ github.event.pull_request.head.sha }}"
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v1
      with:
        driver-opts: image=moby/buildkit:master
    - name: Login to GitHub Container Registry
      uses: docker/login-action@v1
      with:
        registry: ghcr.io
        username: "${{ env.GH_CONTAINER_REGISTRY_USERNAME }}"
        password: "${{ secrets.GH_CONTAINER_REGISTRY_TOKEN }}"
    - name: Build and push container
      uses: docker/build-push-action@v2
      with:
        context: compiler/${{ matrix.tool }}/
        file: compiler/${{ matrix.tool }}/Dockerfile
        build-args: base_image=ghcr.io/integer32llc/rust-playground-ci-rust-nightly:sources--${{ github.run_id }}
        pull: true
        push: true
        tags: "${{ env.IMAGE_NAME }}:${{ github.run_id }}"
        cache-from: |-
          ${{ env.IMAGE_NAME }}:${{ github.run_id }}
          ${{ env.IMAGE_NAME }}:latest
        cache-to: type=inline
  build_backend:
    name: Build backend
    runs-on: ubuntu-latest
    if: 'github.event_name == ''push'' || contains(github.event.pull_request.labels.*.name, ''CI: approved'')'
    steps:
    - name: Checkout code
      uses: actions/checkout@v2
      with:
        ref: "${{ github.event.pull_request.head.sha }}"
    - name: Cache Cargo intermediate products
      uses: actions/cache@v2
      with:
        path: |-
          ~/.cargo/registry
          ~/.cargo/git
          ui/target
        key: "${{ runner.os }}-cargo-${{ hashFiles('ui/**/Cargo.lock') }}-2"
    - name: Build backend
      run: |-
        mkdir -p ui/target; docker run --rm -v $PWD/ui:/ui -v ~/.cargo/git:/home/rust/.cargo/git -v ~/.cargo/registry:/home/rust/.cargo/registry --workdir /ui ekidd/rust-musl-builder:stable bash -c '
          sudo chown -R rust:rust /home/rust/.cargo /ui/target;
          cargo build --locked --target=x86_64-unknown-linux-musl --release
        '
    - name: Restore permissions
      run: sudo chown -R runner:docker ~/.cargo/ ui/target
    - name: Save backend artifact
      uses: actions/upload-artifact@v2
      with:
        name: backend
        path: ui/target/x86_64-unknown-linux-musl/release/ui
  build_frontend:
    name: Build frontend
    runs-on: ubuntu-latest
    if: 'github.event_name == ''push'' || contains(github.event.pull_request.labels.*.name, ''CI: approved'')'
    steps:
    - name: Checkout code
      uses: actions/checkout@v2
      with:
        ref: "${{ github.event.pull_request.head.sha }}"
    - name: Get yarn cache directory path
      id: yarn-cache-dir-path
      run: echo "::set-output name=dir::$(yarn cache dir)"
    - name: Cache yarn intermediate products
      uses: actions/cache@v2
      with:
        path: "${{ steps.yarn-cache-dir-path.outputs.dir }}"
        key: "${{ runner.os }}-yarn-${{ hashFiles('**/yarn.lock') }}"
        restore-keys: "${{ runner.os }}-yarn-"
    - name: Configure node
      uses: actions/setup-node@v1
      with:
        node-version: 14.15
    - name: Install dependencies
      run: yarn --cwd ui/frontend/
    - name: Run tests
      run: yarn --cwd ui/frontend/ test
    - name: Lint
      run: yarn --cwd ui/frontend/ test:lint
    - name: Build frontend
      run: yarn --cwd ui/frontend/ run build:production
    - name: Save frontend artifact
      uses: actions/upload-artifact@v2
      with:
        name: frontend
        path: ui/frontend/build
  run_integration_tests:
    name: Running integration tests
    runs-on: ubuntu-latest
    if: 'github.event_name == ''push'' || contains(github.event.pull_request.labels.*.name, ''CI: approved'')'
    needs:
    - build_compiler_containers
    - build_tool_containers
    - build_backend
    - build_frontend
    defaults:
      run:
        working-directory: tests
    steps:
    - name: Checkout code
      uses: actions/checkout@v2
      with:
        ref: "${{ github.event.pull_request.head.sha }}"
    - name: Configure Ruby
      uses: actions/setup-ruby@v1
      with:
        ruby-version: '2.7'
    - name: Cache bundler intermediate products
      uses: actions/cache@v2
      with:
        path: tests/vendor/bundle
        key: "${{ runner.os }}-gems-${{ hashFiles('tests/**/Gemfile.lock') }}"
        restore-keys: "${{ runner.os }}-gems-"
    - name: Install gems
      run: |-
        gem install bundler
        bundle config path vendor/bundle
        bundle install --jobs 4 --retry 3
    - name: Pull containers
      run: echo ghcr.io/integer32llc/rust-playground-ci-{rust-{stable,beta,nightly},tool-{clippy,rustfmt,miri}}:${{ github.run_id }} | xargs -n1 docker pull
    - name: Rename containers
      run: |-
        for c in stable beta nightly; do
          docker tag ghcr.io/integer32llc/rust-playground-ci-rust-$c:${{ github.run_id }} ghcr.io/integer32llc/rust-playground-ci-rust-$c
          docker tag ghcr.io/integer32llc/rust-playground-ci-rust-$c:${{ github.run_id }} shepmaster/rust-$c
          docker tag ghcr.io/integer32llc/rust-playground-ci-rust-$c:${{ github.run_id }} rust-$c
        done
        for t in clippy miri rustfmt; do
          docker tag ghcr.io/integer32llc/rust-playground-ci-tool-$t:${{ github.run_id }} ghcr.io/integer32llc/rust-playground-ci-tool-$t
          docker tag ghcr.io/integer32llc/rust-playground-ci-tool-$t:${{ github.run_id }} shepmaster/$t
          docker tag ghcr.io/integer32llc/rust-playground-ci-tool-$t:${{ github.run_id }} $t
        done
    - name: Download backend
      uses: actions/download-artifact@v2
      with:
        name: backend
        path: tests/server/
    - name: Download frontend
      uses: actions/download-artifact@v2
      with:
        name: frontend
        path: tests/server/build/
    - name: Run tests
      env:
        PLAYGROUND_UI_ROOT: server/build/
        PLAYGROUND_CORS_ENABLED: true
        PLAYGROUND_GITHUB_TOKEN: "${{ secrets.PLAYGROUND_GITHUB_TOKEN }}"
      run: |-
        chmod +x ./server/ui && ./server/ui &
        bundle exec rspec
    - name: Preserve screenshots
      if: "${{ failure() }}"
      uses: actions/upload-artifact@v2
      with:
        name: test-failures
        path: tests/test-failures
  release_artifacts:
    name: Release artifacts
    runs-on: ubuntu-latest
    needs:
    - run_integration_tests
    if: github.event_name == 'push' && github.event.ref == 'refs/heads/master'
    steps:
    - name: Login to GitHub Container Registry
      uses: docker/login-action@v1
      with:
        registry: ghcr.io
        username: "${{ env.GH_CONTAINER_REGISTRY_USERNAME }}"
        password: "${{ secrets.GH_CONTAINER_REGISTRY_TOKEN }}"
    - name: Login to Docker Hub
      uses: docker/login-action@v1
      with:
        username: "${{ env.DOCKER_HUB_USERNAME }}"
        password: "${{ secrets.DOCKER_HUB_TOKEN }}"
    - name: Login to AWS
      uses: aws-actions/configure-aws-credentials@v1
      with:
        aws-access-key-id: "${{ env.AWS_ACCESS_KEY_ID }}"
        aws-secret-access-key: "${{ secrets.AWS_SECRET_ACCESS_KEY }}"
        aws-region: us-east-2
    - name: Pull containers
      run: echo ghcr.io/integer32llc/rust-playground-ci-{rust-{stable,beta,nightly},tool-{clippy,rustfmt,miri}}:${{ github.run_id }} | xargs -n1 docker pull
    - name: Rename containers
      run: |-
        for c in stable beta nightly; do
          docker tag ghcr.io/integer32llc/rust-playground-ci-rust-$c:${{ github.run_id }} ghcr.io/integer32llc/rust-playground-ci-rust-$c
          docker tag ghcr.io/integer32llc/rust-playground-ci-rust-$c:${{ github.run_id }} shepmaster/rust-$c
          docker tag ghcr.io/integer32llc/rust-playground-ci-rust-$c:${{ github.run_id }} rust-$c
        done
        for t in clippy miri rustfmt; do
          docker tag ghcr.io/integer32llc/rust-playground-ci-tool-$t:${{ github.run_id }} ghcr.io/integer32llc/rust-playground-ci-tool-$t
          docker tag ghcr.io/integer32llc/rust-playground-ci-tool-$t:${{ github.run_id }} shepmaster/$t
          docker tag ghcr.io/integer32llc/rust-playground-ci-tool-$t:${{ github.run_id }} $t
        done
    - name: Push containers
      run: |-
        for c in stable beta nightly; do
          docker push ghcr.io/integer32llc/rust-playground-ci-rust-$c
          docker push shepmaster/rust-$c
        done
        for t in clippy miri rustfmt; do
          docker push ghcr.io/integer32llc/rust-playground-ci-tool-$t
          docker push shepmaster/$t
        done
    - name: Download backend
      uses: actions/download-artifact@v2
      with:
        name: backend
        path: server/
    - name: Download frontend
      uses: actions/download-artifact@v2
      with:
        name: frontend
        path: server/build/
    - name: Push backend
      run: aws s3 cp server/ui s3://playground-artifacts-i32
    - name: Push frontend
      run: aws s3 sync server/build/ s3://playground-artifacts-i32/build

'''
'''--- .github/workflows/cron.yml ---
# This file was generated by ci/generate and should not be modified by hand
---
name: Scheduled rebuild
'on':
  workflow_dispatch:
  schedule:
  - cron: 7 2 * * *
env:
  DOCKER_HUB_USERNAME: shepmaster
  GH_CONTAINER_REGISTRY_USERNAME: shepmaster
  AWS_ACCESS_KEY_ID: AKIAWESVHZ3JQAY5NM5K
jobs:
  build_compiler_containers:
    name: Build ${{ matrix.channel }} compiler container
    runs-on: ubuntu-latest
    strategy:
      matrix:
        channel:
        - stable
        - beta
        - nightly
    env:
      IMAGE_NAME: ghcr.io/integer32llc/rust-playground-ci-rust-${{ matrix.channel }}
      DOCKER_HUB_IMAGE_NAME: shepmaster/rust-${{ matrix.channel }}
    continue-on-error: true
    steps:
    - name: Checkout code
      uses: actions/checkout@v2
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v1
      with:
        driver-opts: image=moby/buildkit:master
    - name: Login to GitHub Container Registry
      uses: docker/login-action@v1
      with:
        registry: ghcr.io
        username: "${{ env.GH_CONTAINER_REGISTRY_USERNAME }}"
        password: "${{ secrets.GH_CONTAINER_REGISTRY_TOKEN }}"
    - name: Login to Docker Hub
      uses: docker/login-action@v1
      with:
        username: "${{ env.DOCKER_HUB_USERNAME }}"
        password: "${{ secrets.DOCKER_HUB_TOKEN }}"
    - name: Build and push 'toolchain' container
      env:
        TAG_PREFIX: "${{ env.IMAGE_NAME }}:toolchain"
      uses: docker/build-push-action@v2
      with:
        context: compiler/base/
        file: compiler/base/Dockerfile
        build-args: channel=${{ matrix.channel }}
        target: toolchain
        pull: true
        push: true
        tags: "${{ env.TAG_PREFIX }}--${{ github.run_id }}"
        cache-from: |-
          ${{ env.TAG_PREFIX }}--${{ github.run_id }}
          ${{ env.TAG_PREFIX }}--latest
        cache-to: type=inline
    - name: Build and push 'bare-sources' container
      env:
        TAG_PREFIX: "${{ env.IMAGE_NAME }}:bare-sources"
      uses: docker/build-push-action@v2
      with:
        context: compiler/base/
        file: compiler/base/Dockerfile
        build-args: channel=${{ matrix.channel }}
        target: bare-sources
        pull: true
        push: true
        tags: "${{ env.TAG_PREFIX }}--${{ github.run_id }}"
        cache-from: |-
          ${{ env.TAG_PREFIX }}--${{ github.run_id }}
          ${{ env.TAG_PREFIX }}--latest
        cache-to: type=inline
    - name: Build and push 'munge' container
      env:
        TAG_PREFIX: "${{ env.IMAGE_NAME }}:munge"
      uses: docker/build-push-action@v2
      with:
        context: compiler/base/
        file: compiler/base/Dockerfile
        build-args: channel=${{ matrix.channel }}
        target: munge
        pull: true
        push: true
        tags: "${{ env.TAG_PREFIX }}--${{ github.run_id }}"
        cache-from: |-
          ${{ env.TAG_PREFIX }}--${{ github.run_id }}
          ${{ env.TAG_PREFIX }}--latest
        cache-to: type=inline
    - name: Build and push 'sources' container
      env:
        TAG_PREFIX: "${{ env.IMAGE_NAME }}:sources"
      uses: docker/build-push-action@v2
      with:
        context: compiler/base/
        file: compiler/base/Dockerfile
        build-args: channel=${{ matrix.channel }}
        target: sources
        pull: true
        push: true
        tags: "${{ env.TAG_PREFIX }}--${{ github.run_id }}"
        cache-from: |-
          ${{ env.TAG_PREFIX }}--${{ github.run_id }}
          ${{ env.TAG_PREFIX }}--latest
        cache-to: type=inline
    - name: Build and push container
      uses: docker/build-push-action@v2
      with:
        context: compiler/base/
        file: compiler/base/Dockerfile
        build-args: channel=${{ matrix.channel }}
        pull: true
        push: true
        tags: "${{ env.IMAGE_NAME }}:${{ github.run_id }}"
        cache-from: |-
          ${{ env.IMAGE_NAME }}:${{ github.run_id }}
          ${{ env.IMAGE_NAME }}:latest
        cache-to: type=inline
    - name: Pull container
      run: docker pull ${{ env.IMAGE_NAME }}:${{ github.run_id }}
    - name: Rename container
      run: |-
        docker tag ${{ env.IMAGE_NAME }}:${{ github.run_id }} ${{ env.IMAGE_NAME }}
        docker tag ${{ env.IMAGE_NAME }}:${{ github.run_id }} ${{ env.DOCKER_HUB_IMAGE_NAME }}
    - name: Push container
      run: |-
        docker push ${{ env.IMAGE_NAME }}
        docker push ${{ env.DOCKER_HUB_IMAGE_NAME }}
  build_tool_containers:
    name: Build ${{ matrix.tool }} tool container
    runs-on: ubuntu-latest
    needs: build_compiler_containers
    strategy:
      matrix:
        tool:
        - clippy
        - miri
        - rustfmt
    env:
      IMAGE_NAME: ghcr.io/integer32llc/rust-playground-ci-tool-${{ matrix.tool }}
      DOCKER_HUB_IMAGE_NAME: shepmaster/${{ matrix.tool }}
    continue-on-error: true
    steps:
    - name: Checkout code
      uses: actions/checkout@v2
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v1
      with:
        driver-opts: image=moby/buildkit:master
    - name: Login to GitHub Container Registry
      uses: docker/login-action@v1
      with:
        registry: ghcr.io
        username: "${{ env.GH_CONTAINER_REGISTRY_USERNAME }}"
        password: "${{ secrets.GH_CONTAINER_REGISTRY_TOKEN }}"
    - name: Login to Docker Hub
      uses: docker/login-action@v1
      with:
        username: "${{ env.DOCKER_HUB_USERNAME }}"
        password: "${{ secrets.DOCKER_HUB_TOKEN }}"
    - name: Build and push container
      uses: docker/build-push-action@v2
      with:
        context: compiler/${{ matrix.tool }}/
        file: compiler/${{ matrix.tool }}/Dockerfile
        build-args: base_image=ghcr.io/integer32llc/rust-playground-ci-rust-nightly:sources--${{ github.run_id }}
        pull: true
        push: true
        tags: "${{ env.IMAGE_NAME }}:${{ github.run_id }}"
        cache-from: |-
          ${{ env.IMAGE_NAME }}:${{ github.run_id }}
          ${{ env.IMAGE_NAME }}:latest
        cache-to: type=inline
    - name: Pull container
      run: docker pull ${{ env.IMAGE_NAME }}:${{ github.run_id }}
    - name: Rename container
      run: |-
        docker tag ${{ env.IMAGE_NAME }}:${{ github.run_id }} ${{ env.IMAGE_NAME }}
        docker tag ${{ env.IMAGE_NAME }}:${{ github.run_id }} ${{ env.DOCKER_HUB_IMAGE_NAME }}
    - name: Push container
      run: |-
        docker push ${{ env.IMAGE_NAME }}
        docker push ${{ env.DOCKER_HUB_IMAGE_NAME }}

'''
'''--- CRATE_POLICY.md ---
# Playground crate inclusion policy

The playground selects a number of root crates to include:

- The top 100 crates based on [all time downloads][]
- Crates from the [Rust cookbook][]

The latest stable version of these crates are available, as well as
whatever dependencies these crates require.

## Why is there a policy?

The number of crates must be restricted because time and space are
limited resources and the playground is a volunteer-supported open source
project. It would be infeasible to provide every possible crate.

This inclusion policy is used to avoid "playing favorites" for which
crates are available. Hand-picking crates will lead to resentment
about which crates were not included between the playground
maintainers and crate authors or even the broader Rust community. 
Neither of these outcomes is desired.

## Exclusion policy

Occasionally, some crates that would otherwise meet the above criteria
will not be available on the playground. A non-exhaustive list of
reasons is:

- Does not compile on Linux
- Does not compile on the stable release channel
- Does not compile due to invalid feature flag selection

In these cases, we will temporarily exclude the crate to allow the
playground to continue to be updated. We usually also notify the crate
maintainers so they can adjust their crates and be re-included.

## I don't like the current system!

We are open to well-reasoned [alternate algorithms][], but be aware
that any proposal would likely be expected to also provide the
majority of implementation work.

[all time downloads]: https://crates.io/crates?sort=downloads
[Rust cookbook]: https://rust-lang-nursery.github.io/rust-cookbook/
[alternate algorithms]: https://github.com/integer32llc/rust-playground/issues/101
'''
'''--- README.md ---
# Rust Playground

This is the home of the [Rust Playground][real],
also [hosted by Integer 32][us].

[real]: https://play.rust-lang.org/
[us]: https://play.integer32.com/

## What's it do?

The playground allows you to experiment with Rust before you install
it locally, or in any other case where you might not have the compiler
available.

It has a number of features, including:

1. A nice, unobtrusive editor with syntax highlighting.
1. The ability to compile in debug or release mode against the current
   stable, beta, or nightly version of Rust.
1. The top 100 popular crates (ranked by all-time downloads), crates
   that are part of the [Rust Cookbook][] and all of their
   dependencies are available for use!
1. The ability to quickly load and save your code to a
   GitHub [Gist][gist] and share it with your friends.
1. [rustfmt][] and [Clippy][clippy] can be run against the source code.
1. The ability to see the LLVM IR, assembly, or Rust MIR for the
   source code.

[Rust Cookbook]: https://rust-lang-nursery.github.io/rust-cookbook/
[gist]: https://gist.github.com/
[rustfmt]: https://github.com/rust-lang/rustfmt
[clippy]: https://github.com/rust-lang/rust-clippy

## Architecture

A [React][react] frontend communicates with an [Iron][iron]
backend. [Docker][docker] containers are used to provide the various
compilers and tools as well as to help isolate them.

We hope that this frontend and backend stack is comfortable to
potential contributors! If you are interested in contributing, please
feel free to ask a question and we might even be able to point out
some useful resources.

[react]: https://reactjs.org/
[iron]: https://github.com/iron/iron
[docker]: https://www.docker.com/

## Resource Limits

### Network

There is no network connection between the compiler container and the
outside world.

### Memory

The amount of memory the compiler and resulting executable use is
limited by the container.

### Execution Time

The total compilation and execution time is limited by the container.

### Disk

This sandbox **does not** provide any disk space limits. It is
suggested to run the server such that the temp directory is a
space-limited. One bad actor may fill up this shared space, but it
should be cleaned when that request ends.

## Security Hall of Fame

A large set of thanks go to those individuals who have helped by
reporting security holes or other attack vectors against the
Playground. Each report helps us make the Playground better!

* Preliminary sandbox testing (PID limit) by Stefan O'Rear.

If you'd like to perform tests that you think might disrupt service of
the Playground, get in touch and we can create an isolated clone to
perform tests on! Once fixed, you can choose to be credited here.

## Development

### Build the UI
```
cd ui/frontend
yarn
yarn run watch # Will rebuild and watch for changes
```

If you don't need the backend running because you are only making
basic HTML/CSS/JS changes, directly open in your browser the built
`ui/frontend/build/index.html`.

### Build and run the server

Configure your `.env` file as described in the [ui README](./ui/README.md).

```
cd ui
cargo run
```

### Build or download the containers
```
cd compiler
./build.sh # If you want to test changes to the containers
./fetch.sh # If you just want the current playground
```

## Deployment

* [Amazon EC2 (Ubuntu)](deployment/ubuntu.md)

## License

Licensed under either of
 * Apache License, Version 2.0 ([LICENSE-APACHE](LICENSE-APACHE) or http://www.apache.org/licenses/LICENSE-2.0)
 * MIT license ([LICENSE-MIT](LICENSE-MIT) or http://opensource.org/licenses/MIT)
at your option.

'''
'''--- ci/workflows.yml ---
components:
  - global_env: &global_env
      env:
        DOCKER_HUB_USERNAME: shepmaster
        GH_CONTAINER_REGISTRY_USERNAME: shepmaster
        AWS_ACCESS_KEY_ID: AKIAWESVHZ3JQAY5NM5K

  - checkout: &checkout
      name: "Checkout code"
      uses: actions/checkout@v2

  # This should only be used when we know that the code being tested
  # doesn't make use of our secrets or elevated GitHub token.
  - checkout_pr: &checkout_pr
      name: "Checkout code"
      uses: actions/checkout@v2
      with:
        ref: ${{ github.event.pull_request.head.sha }}

  - docker_buildx: &docker_buildx
      name: "Set up Docker Buildx"
      uses: docker/setup-buildx-action@v1
      with:
        driver-opts: >-
          image=moby/buildkit:master

  - login_ghcr: &login_ghcr
      name: "Login to GitHub Container Registry"
      uses: docker/login-action@v1
      with:
        registry: ghcr.io
        username: ${{ env.GH_CONTAINER_REGISTRY_USERNAME }}
        password: ${{ secrets.GH_CONTAINER_REGISTRY_TOKEN }}

  - login_docker_hub: &login_docker_hub
      name: "Login to Docker Hub"
      uses: docker/login-action@v1
      with:
        username: ${{ env.DOCKER_HUB_USERNAME }}
        password: ${{ secrets.DOCKER_HUB_TOKEN }}

  - build_compiler_containers_job: &build_compiler_containers_job
      name: "Build ${{ matrix.channel }} compiler container"
      runs-on: ubuntu-latest

      strategy:
        matrix:
          channel: [stable, beta, nightly]

  - build_compiler_containers_job_env: &build_compiler_containers_job_env
      IMAGE_NAME: ghcr.io/integer32llc/rust-playground-ci-rust-${{ matrix.channel }}

  - build_compiler_containers_toolchain: &build_compiler_containers_toolchain
      name: "Build and push 'toolchain' container"
      env:
        TAG_PREFIX: ${{ env.IMAGE_NAME }}:toolchain
      uses: docker/build-push-action@v2
      with:
        context: compiler/base/
        file: compiler/base/Dockerfile
        build-args: |-
          channel=${{ matrix.channel }}
        target: toolchain
        pull: true
        push: true
        tags: |-
          ${{ env.TAG_PREFIX }}--${{ github.run_id }}
        cache-from: |-
          ${{ env.TAG_PREFIX }}--${{ github.run_id }}
          ${{ env.TAG_PREFIX }}--latest
        cache-to: type=inline

  - build_compiler_containers_bare_sources: &build_compiler_containers_bare_sources
      name: "Build and push 'bare-sources' container"
      env:
        TAG_PREFIX: ${{ env.IMAGE_NAME }}:bare-sources
      uses: docker/build-push-action@v2
      with:
        context: compiler/base/
        file: compiler/base/Dockerfile
        build-args: |-
          channel=${{ matrix.channel }}
        target: bare-sources
        pull: true
        push: true
        tags: |-
          ${{ env.TAG_PREFIX }}--${{ github.run_id }}
        cache-from: |-
          ${{ env.TAG_PREFIX }}--${{ github.run_id }}
          ${{ env.TAG_PREFIX }}--latest
        cache-to: type=inline

  - build_compiler_containers_munge: &build_compiler_containers_munge
      name: "Build and push 'munge' container"
      env:
        TAG_PREFIX: ${{ env.IMAGE_NAME }}:munge
      uses: docker/build-push-action@v2
      with:
        context: compiler/base/
        file: compiler/base/Dockerfile
        build-args: |-
          channel=${{ matrix.channel }}
        target: munge
        pull: true
        push: true
        tags: |-
          ${{ env.TAG_PREFIX }}--${{ github.run_id }}
        cache-from: |-
          ${{ env.TAG_PREFIX }}--${{ github.run_id }}
          ${{ env.TAG_PREFIX }}--latest
        cache-to: type=inline

  - build_compiler_containers_sources: &build_compiler_containers_sources
      name: "Build and push 'sources' container"
      env:
        TAG_PREFIX: ${{ env.IMAGE_NAME }}:sources
      uses: docker/build-push-action@v2
      with:
        context: compiler/base/
        file: compiler/base/Dockerfile
        build-args: |-
          channel=${{ matrix.channel }}
        target: sources
        pull: true
        push: true
        tags: |-
          ${{ env.TAG_PREFIX }}--${{ github.run_id }}
        cache-from: |-
          ${{ env.TAG_PREFIX }}--${{ github.run_id }}
          ${{ env.TAG_PREFIX }}--latest
        cache-to: type=inline

  - build_compiler_containers_final: &build_compiler_containers_final
      name: "Build and push container"
      uses: docker/build-push-action@v2
      with:
        context: compiler/base/
        file: compiler/base/Dockerfile
        build-args: |-
          channel=${{ matrix.channel }}
        pull: true
        push: true
        tags: |-
          ${{ env.IMAGE_NAME }}:${{ github.run_id }}
        cache-from: |-
          ${{ env.IMAGE_NAME }}:${{ github.run_id }}
          ${{ env.IMAGE_NAME }}:latest
        cache-to: type=inline

  - build_tool_containers_job: &build_tool_containers_job
      name: "Build ${{ matrix.tool }} tool container"
      runs-on: ubuntu-latest
      needs: build_compiler_containers

      strategy:
        matrix:
          tool: [clippy, miri, rustfmt]

  - build_tool_containers_job_env: &build_tool_containers_job_env
      IMAGE_NAME: ghcr.io/integer32llc/rust-playground-ci-tool-${{ matrix.tool }}

  - build_tool_containers_final: &build_tool_containers_final
      name: "Build and push container"
      uses: docker/build-push-action@v2
      with:
        context: compiler/${{ matrix.tool }}/
        file: compiler/${{ matrix.tool }}/Dockerfile
        build-args: |-
          base_image=ghcr.io/integer32llc/rust-playground-ci-rust-nightly:sources--${{ github.run_id }}
        pull: true
        push: true
        tags: |-
          ${{ env.IMAGE_NAME }}:${{ github.run_id }}
        cache-from: |-
          ${{ env.IMAGE_NAME }}:${{ github.run_id }}
          ${{ env.IMAGE_NAME }}:latest
        cache-to: type=inline

  - pull_containers: &pull_containers
      name: "Pull containers"
      run: |-
        echo ghcr.io/integer32llc/rust-playground-ci-{rust-{stable,beta,nightly},tool-{clippy,rustfmt,miri}}:${{ github.run_id }} | xargs -n1 docker pull

  - rename_all_containers: &rename_all_containers
      name: "Rename containers"
      run: |-
        for c in stable beta nightly; do
          docker tag ghcr.io/integer32llc/rust-playground-ci-rust-$c:${{ github.run_id }} ghcr.io/integer32llc/rust-playground-ci-rust-$c
          docker tag ghcr.io/integer32llc/rust-playground-ci-rust-$c:${{ github.run_id }} shepmaster/rust-$c
          docker tag ghcr.io/integer32llc/rust-playground-ci-rust-$c:${{ github.run_id }} rust-$c
        done
        for t in clippy miri rustfmt; do
          docker tag ghcr.io/integer32llc/rust-playground-ci-tool-$t:${{ github.run_id }} ghcr.io/integer32llc/rust-playground-ci-tool-$t
          docker tag ghcr.io/integer32llc/rust-playground-ci-tool-$t:${{ github.run_id }} shepmaster/$t
          docker tag ghcr.io/integer32llc/rust-playground-ci-tool-$t:${{ github.run_id }} $t
        done

  - pull_current_container: &pull_current_container
      name: "Pull container"
      run: |-
        docker pull ${{ env.IMAGE_NAME }}:${{ github.run_id }}

  - rename_current_container: &rename_current_container
      name: "Rename container"
      run: |-
        docker tag ${{ env.IMAGE_NAME }}:${{ github.run_id }} ${{ env.IMAGE_NAME }}
        docker tag ${{ env.IMAGE_NAME }}:${{ github.run_id }} ${{ env.DOCKER_HUB_IMAGE_NAME }}

  - push_current_container: &push_current_container
      name: "Push container"
      run: |-
        docker push ${{ env.IMAGE_NAME }}
        docker push ${{ env.DOCKER_HUB_IMAGE_NAME }}

workflows:
  ci:
    name: "Validate everything"

    'on':
      push:
        branches:
          - master
      pull_request_target:
        types: [labeled]
        branches:
          - master

    <<: *global_env

    jobs:
      build_compiler_containers:
        <<: *build_compiler_containers_job
        if: "github.event_name == 'push' || contains(github.event.pull_request.labels.*.name, 'CI: approved')"
        env:
          <<: *build_compiler_containers_job_env

        steps:
          - *checkout_pr
          - *docker_buildx
          - *login_ghcr
          - *build_compiler_containers_toolchain
          - *build_compiler_containers_bare_sources
          - *build_compiler_containers_munge
          - *build_compiler_containers_sources
          - *build_compiler_containers_final

      build_tool_containers:
        <<: *build_tool_containers_job
        if: "github.event_name == 'push' || contains(github.event.pull_request.labels.*.name, 'CI: approved')"
        env:
          <<: *build_tool_containers_job_env

        steps:
          - *checkout_pr
          - *docker_buildx
          - *login_ghcr
          - *build_tool_containers_final

      build_backend:
        name: "Build backend"
        runs-on: ubuntu-latest
        if: "github.event_name == 'push' || contains(github.event.pull_request.labels.*.name, 'CI: approved')"

        steps:
          - *checkout_pr

          - name: "Cache Cargo intermediate products"
            uses: actions/cache@v2
            with:
              path: |-
                ~/.cargo/registry
                ~/.cargo/git
                ui/target
              key: ${{ runner.os }}-cargo-${{ hashFiles('ui/**/Cargo.lock') }}-2

          - name: "Build backend"
            run: >-
                mkdir -p ui/target;
                docker
                run
                --rm
                -v $PWD/ui:/ui
                -v ~/.cargo/git:/home/rust/.cargo/git
                -v ~/.cargo/registry:/home/rust/.cargo/registry
                --workdir /ui
                ekidd/rust-musl-builder:stable
                bash -c '
                  sudo chown -R rust:rust /home/rust/.cargo /ui/target;
                  cargo build --locked --target=x86_64-unknown-linux-musl --release
                '

          - name: "Restore permissions"
            run: >-
              sudo chown -R runner:docker ~/.cargo/ ui/target

          - name: "Save backend artifact"
            uses: actions/upload-artifact@v2
            with:
              name: backend
              path: ui/target/x86_64-unknown-linux-musl/release/ui

      build_frontend:
        name: "Build frontend"
        runs-on: ubuntu-latest
        if: "github.event_name == 'push' || contains(github.event.pull_request.labels.*.name, 'CI: approved')"

        steps:
          - *checkout_pr

          - name: "Get yarn cache directory path"
            id: yarn-cache-dir-path
            run: echo "::set-output name=dir::$(yarn cache dir)"

          - name: "Cache yarn intermediate products"
            uses: actions/cache@v2
            with:
              path: ${{ steps.yarn-cache-dir-path.outputs.dir }}
              key: ${{ runner.os }}-yarn-${{ hashFiles('**/yarn.lock') }}
              restore-keys: |-
                ${{ runner.os }}-yarn-

          - name: "Configure node"
            uses: actions/setup-node@v1
            with:
              node-version: 14.15

          - name: "Install dependencies"
            run: >-
              yarn --cwd ui/frontend/

          - name: "Run tests"
            run: >-
              yarn --cwd ui/frontend/ test

          - name: "Lint"
            run: >-
              yarn --cwd ui/frontend/ test:lint

          - name: "Style"
            run: >-
              yarn --cwd ui/frontend/ test:style

          - name: "Build frontend"
            run: >-
              yarn --cwd ui/frontend/ run build:production

          - name: "Save frontend artifact"
            uses: actions/upload-artifact@v2
            with:
              name: frontend
              path: ui/frontend/build

      run_integration_tests:
        name: "Running integration tests"
        runs-on: ubuntu-latest
        if: "github.event_name == 'push' || contains(github.event.pull_request.labels.*.name, 'CI: approved')"
        needs:
          - build_compiler_containers
          - build_tool_containers
          - build_backend
          - build_frontend

        defaults:
          run:
            working-directory: tests

        steps:
          - *checkout_pr

          - name: "Configure Ruby"
            uses: actions/setup-ruby@v1
            with:
              ruby-version: '2.7'

          - name: "Cache bundler intermediate products"
            uses: actions/cache@v2
            with:
              path: tests/vendor/bundle
              key: ${{ runner.os }}-gems-${{ hashFiles('tests/**/Gemfile.lock') }}
              restore-keys: |-
                ${{ runner.os }}-gems-

          - name: "Install gems"
            run: |-
              gem install bundler
              bundle config path vendor/bundle
              bundle install --jobs 4 --retry 3

          - *pull_containers
          - *rename_all_containers

          - name: "Download backend"
            uses: actions/download-artifact@v2
            with:
              name: backend
              path: tests/server/

          - name: "Download frontend"
            uses: actions/download-artifact@v2
            with:
              name: frontend
              path: tests/server/build/

          - name: "Run tests"
            env:
              PLAYGROUND_UI_ROOT: server/build/
              PLAYGROUND_CORS_ENABLED: true
              PLAYGROUND_GITHUB_TOKEN: ${{ secrets.PLAYGROUND_GITHUB_TOKEN }}
            run: |-
              chmod +x ./server/ui && ./server/ui &
              bundle exec rspec

          - name: "Preserve screenshots"
            if: ${{ failure() }}
            uses: actions/upload-artifact@v2
            with:
              name: test-failures
              path: tests/test-failures

      release_artifacts:
        name: "Release artifacts"
        runs-on: ubuntu-latest
        needs:
          - run_integration_tests
        if: github.event_name == 'push' && github.event.ref == 'refs/heads/master'

        steps:
          - *login_ghcr

          - name: "Login to Docker Hub"
            uses: docker/login-action@v1
            with:
              username: ${{ env.DOCKER_HUB_USERNAME }}
              password: ${{ secrets.DOCKER_HUB_TOKEN }}

          - name: "Login to AWS"
            uses: aws-actions/configure-aws-credentials@v1
            with:
              aws-access-key-id: ${{ env.AWS_ACCESS_KEY_ID }}
              aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
              aws-region: us-east-2

          - *pull_containers
          - *rename_all_containers

          - name: "Push containers"
            run: |-
              for c in stable beta nightly; do
                docker push ghcr.io/integer32llc/rust-playground-ci-rust-$c
                docker push shepmaster/rust-$c
              done
              for t in clippy miri rustfmt; do
                docker push ghcr.io/integer32llc/rust-playground-ci-tool-$t
                docker push shepmaster/$t
              done

          - name: "Download backend"
            uses: actions/download-artifact@v2
            with:
              name: backend
              path: server/

          - name: "Download frontend"
            uses: actions/download-artifact@v2
            with:
              name: frontend
              path: server/build/

          - name: "Push backend"
            run: |-
              aws s3 cp server/ui s3://playground-artifacts-i32

          - name: "Push frontend"
            run: |-
              aws s3 sync server/build/ s3://playground-artifacts-i32/build

  cron:
    name: "Scheduled rebuild"

    'on':
      workflow_dispatch:
      schedule:
        # Nightlies are available ~1am UTC, should definitely be out by 2am
        - cron:  '7 2 * * *'

    <<: *global_env

    jobs:
      build_compiler_containers:
        <<: *build_compiler_containers_job
        env:
          <<: *build_compiler_containers_job_env
          DOCKER_HUB_IMAGE_NAME: shepmaster/rust-${{ matrix.channel }}
        continue-on-error: true

        steps:
          - *checkout
          - *docker_buildx
          - *login_ghcr
          - *login_docker_hub
          - *build_compiler_containers_toolchain
          - *build_compiler_containers_bare_sources
          - *build_compiler_containers_munge
          - *build_compiler_containers_sources
          - *build_compiler_containers_final

          - *pull_current_container
          - *rename_current_container
          - *push_current_container

      build_tool_containers:
        <<: *build_tool_containers_job
        env:
          <<: *build_tool_containers_job_env
          DOCKER_HUB_IMAGE_NAME: shepmaster/${{ matrix.tool }}
        continue-on-error: true

        steps:
          - *checkout
          - *docker_buildx
          - *login_ghcr
          - *login_docker_hub
          - *build_tool_containers_final

          - *pull_current_container
          - *rename_current_container
          - *push_current_container

'''
'''--- compiler/base/Cargo.toml ---
[package]
name = "playground"
version = "0.0.1"
authors = ["The Rust Playground"]
resolver = "2"
[profile.dev]
codegen-units = 1
incremental = false

[profile.release]
codegen-units = 1
incremental = false
[dependencies.addr2line]
package = "addr2line"
version = "=0.15.2"

[dependencies.adler]
package = "adler"
version = "=1.0.2"

[dependencies.adler32]
package = "adler32"
version = "=1.2.0"

[dependencies.ahash]
package = "ahash"
version = "=0.7.4"

[dependencies.aho_corasick]
package = "aho-corasick"
version = "=0.7.18"

[dependencies.ansi_term]
package = "ansi_term"
version = "=0.12.1"

[dependencies.ansi_term_0_11_0]
package = "ansi_term"
version = "=0.11.0"

[dependencies.anyhow]
package = "anyhow"
version = "=1.0.41"

[dependencies.approx]
package = "approx"
version = "=0.5.0"

[dependencies.arc_swap]
package = "arc-swap"
version = "=0.4.8"

[dependencies.arrayvec]
package = "arrayvec"
version = "=0.7.1"

[dependencies.async_recursion]
package = "async-recursion"
version = "=0.3.2"

[dependencies.atty]
package = "atty"
version = "=0.2.14"

[dependencies.autocfg]
package = "autocfg"
version = "=1.0.1"

[dependencies.backtrace]
package = "backtrace"
version = "=0.3.60"

[dependencies.base64]
package = "base64"
version = "=0.13.0"

[dependencies.bit_set]
package = "bit-set"
version = "=0.5.2"

[dependencies.bit_vec]
package = "bit-vec"
version = "=0.6.3"

[dependencies.bitflags]
package = "bitflags"
version = "=1.2.1"

[dependencies.block_buffer]
package = "block-buffer"
version = "=0.9.0"

[dependencies.bstr]
package = "bstr"
version = "=0.2.16"

[dependencies.bytemuck]
package = "bytemuck"
version = "=1.7.0"
features = ["derive", "extern_crate_alloc", "extern_crate_std", "min_const_generics", "zeroable_maybe_uninit"]

[dependencies.byteorder]
package = "byteorder"
version = "=1.4.3"

[dependencies.bytes]
package = "bytes"
version = "=1.0.1"

[dependencies.cc]
package = "cc"
version = "=1.0.68"

[dependencies.cfg_if]
package = "cfg-if"
version = "=1.0.0"

[dependencies.cfg_if_0_1_10]
package = "cfg-if"
version = "=0.1.10"

[dependencies.chrono]
package = "chrono"
version = "=0.4.19"
features = ["serde"]

[dependencies.clap]
package = "clap"
version = "=2.33.3"

[dependencies.color_quant]
package = "color_quant"
version = "=1.1.0"

[dependencies.const_fn]
package = "const_fn"
version = "=0.4.8"

[dependencies.cpufeatures]
package = "cpufeatures"
version = "=0.1.5"

[dependencies.crc32fast]
package = "crc32fast"
version = "=1.2.1"

[dependencies.crossbeam]
package = "crossbeam"
version = "=0.8.1"

[dependencies.crossbeam_channel]
package = "crossbeam-channel"
version = "=0.5.1"

[dependencies.crossbeam_deque]
package = "crossbeam-deque"
version = "=0.8.0"

[dependencies.crossbeam_epoch]
package = "crossbeam-epoch"
version = "=0.9.5"

[dependencies.crossbeam_queue]
package = "crossbeam-queue"
version = "=0.3.2"

[dependencies.crossbeam_utils]
package = "crossbeam-utils"
version = "=0.8.5"

[dependencies.crypto_mac]
package = "crypto-mac"
version = "=0.10.0"

[dependencies.csv]
package = "csv"
version = "=1.1.6"

[dependencies.csv_core]
package = "csv-core"
version = "=0.1.10"

[dependencies.data_encoding]
package = "data-encoding"
version = "=2.3.2"

[dependencies.debug_unreachable]
package = "new_debug_unreachable"
version = "=1.0.4"

[dependencies.deflate]
package = "deflate"
version = "=0.8.6"

[dependencies.derivative]
package = "derivative"
version = "=2.2.0"

[dependencies.digest]
package = "digest"
version = "=0.9.0"

[dependencies.dtoa]
package = "dtoa"
version = "=0.4.8"

[dependencies.either]
package = "either"
version = "=1.6.1"

[dependencies.encoding_rs]
package = "encoding_rs"
version = "=0.8.28"

[dependencies.env_logger]
package = "env_logger"
version = "=0.8.4"

[dependencies.error_chain]
package = "error-chain"
version = "=0.12.4"

[dependencies.fallible_iterator]
package = "fallible-iterator"
version = "=0.2.0"

[dependencies.fallible_streaming_iterator]
package = "fallible-streaming-iterator"
version = "=0.1.9"

[dependencies.filetime]
package = "filetime"
version = "=0.2.14"

[dependencies.fixedbitset]
package = "fixedbitset"
version = "=0.2.0"

[dependencies.flate2]
package = "flate2"
version = "=1.0.20"

[dependencies.fnv]
package = "fnv"
version = "=1.0.7"

[dependencies.foreign_types]
package = "foreign-types"
version = "=0.3.2"

[dependencies.foreign_types_shared]
package = "foreign-types-shared"
version = "=0.1.1"

[dependencies.form_urlencoded]
package = "form_urlencoded"
version = "=1.0.1"

[dependencies.futf]
package = "futf"
version = "=0.1.4"

[dependencies.futures]
package = "futures"
version = "=0.3.15"
features = ["compat", "io-compat", "thread-pool"]

[dependencies.futures_channel]
package = "futures-channel"
version = "=0.3.15"

[dependencies.futures_core]
package = "futures-core"
version = "=0.3.15"

[dependencies.futures_executor]
package = "futures-executor"
version = "=0.3.15"

[dependencies.futures_io]
package = "futures-io"
version = "=0.3.15"

[dependencies.futures_macro]
package = "futures-macro"
version = "=0.3.15"

[dependencies.futures_sink]
package = "futures-sink"
version = "=0.3.15"

[dependencies.futures_task]
package = "futures-task"
version = "=0.3.15"

[dependencies.futures_util]
package = "futures-util"
version = "=0.3.15"

[dependencies.generic_array]
package = "generic-array"
version = "=0.14.4"

[dependencies.getrandom]
package = "getrandom"
version = "=0.2.3"

[dependencies.getrandom_0_1_16]
package = "getrandom"
version = "=0.1.16"

[dependencies.gif]
package = "gif"
version = "=0.11.2"

[dependencies.gimli]
package = "gimli"
version = "=0.24.0"

[dependencies.glob]
package = "glob"
version = "=0.3.0"

[dependencies.h2]
package = "h2"
version = "=0.3.3"

[dependencies.hashbrown]
package = "hashbrown"
version = "=0.11.2"

[dependencies.hashbrown_0_9_1]
package = "hashbrown"
version = "=0.9.1"

[dependencies.hashlink]
package = "hashlink"
version = "=0.7.0"

[dependencies.hmac]
package = "hmac"
version = "=0.10.1"

[dependencies.html5ever]
package = "html5ever"
version = "=0.25.1"

[dependencies.http]
package = "http"
version = "=0.2.4"

[dependencies.http_body]
package = "http-body"
version = "=0.4.2"

[dependencies.httparse]
package = "httparse"
version = "=1.4.1"

[dependencies.httpdate]
package = "httpdate"
version = "=1.0.1"

[dependencies.humantime]
package = "humantime"
version = "=2.1.0"

[dependencies.hyper]
package = "hyper"
version = "=0.14.9"
features = ["full"]

[dependencies.hyper_tls]
package = "hyper-tls"
version = "=0.5.0"

[dependencies.idna]
package = "idna"
version = "=0.2.3"

[dependencies.image]
package = "image"
version = "=0.23.14"

[dependencies.indexmap]
package = "indexmap"
version = "=1.6.2"

[dependencies.instant]
package = "instant"
version = "=0.1.9"

[dependencies.iovec]
package = "iovec"
version = "=0.1.4"

[dependencies.ipnet]
package = "ipnet"
version = "=2.3.1"

[dependencies.itertools]
package = "itertools"
version = "=0.10.1"

[dependencies.itoa]
package = "itoa"
version = "=0.4.7"

[dependencies.jpeg_decoder]
package = "jpeg-decoder"
version = "=0.1.22"

[dependencies.lazy_static]
package = "lazy_static"
version = "=1.4.0"

[dependencies.libc]
package = "libc"
version = "=0.2.97"

[dependencies.libm]
package = "libm"
version = "=0.2.1"

[dependencies.libsqlite3_sys]
package = "libsqlite3-sys"
version = "=0.22.2"

[dependencies.linked_hash_map]
package = "linked-hash-map"
version = "=0.5.4"

[dependencies.lock_api]
package = "lock_api"
version = "=0.4.4"

[dependencies.log]
package = "log"
version = "=0.4.14"

[dependencies.log4rs]
package = "log4rs"
version = "=1.0.0"

[dependencies.log_mdc]
package = "log-mdc"
version = "=0.1.0"

[dependencies.mac]
package = "mac"
version = "=0.1.1"

[dependencies.markup5ever]
package = "markup5ever"
version = "=0.10.1"

[dependencies.markup5ever_rcdom]
package = "markup5ever_rcdom"
version = "=0.1.0"

[dependencies.matches]
package = "matches"
version = "=0.1.8"

[dependencies.matrixmultiply]
package = "matrixmultiply"
version = "=0.3.1"

[dependencies.md5]
package = "md-5"
version = "=0.9.1"

[dependencies.memchr]
package = "memchr"
version = "=2.4.0"

[dependencies.memmap]
package = "memmap"
version = "=0.7.0"

[dependencies.memoffset]
package = "memoffset"
version = "=0.6.4"

[dependencies.mime]
package = "mime"
version = "=0.3.16"

[dependencies.miniz_oxide]
package = "miniz_oxide"
version = "=0.4.4"

[dependencies.miniz_oxide_0_3_7]
package = "miniz_oxide"
version = "=0.3.7"

[dependencies.mio]
package = "mio"
version = "=0.7.13"
features = ["net", "os-ext", "os-poll"]

[dependencies.nalgebra]
package = "nalgebra"
version = "=0.27.1"

[dependencies.nalgebra_macros]
package = "nalgebra-macros"
version = "=0.1.0"

[dependencies.native_tls]
package = "native-tls"
version = "=0.2.7"

[dependencies.ndarray]
package = "ndarray"
version = "=0.15.3"

[dependencies.net2]
package = "net2"
version = "=0.2.37"

[dependencies.num]
package = "num"
version = "=0.4.0"

[dependencies.num_bigint]
package = "num-bigint"
version = "=0.4.0"

[dependencies.num_complex]
package = "num-complex"
version = "=0.4.0"

[dependencies.num_cpus]
package = "num_cpus"
version = "=1.13.0"

[dependencies.num_integer]
package = "num-integer"
version = "=0.1.44"

[dependencies.num_iter]
package = "num-iter"
version = "=0.1.42"

[dependencies.num_rational]
package = "num-rational"
version = "=0.4.0"

[dependencies.num_rational_0_3_2]
package = "num-rational"
version = "=0.3.2"

[dependencies.num_traits]
package = "num-traits"
version = "=0.2.14"

[dependencies.object]
package = "object"
version = "=0.25.3"

[dependencies.once_cell]
package = "once_cell"
version = "=1.8.0"

[dependencies.opaque_debug]
package = "opaque-debug"
version = "=0.3.0"

[dependencies.openssl]
package = "openssl"
version = "=0.10.35"

[dependencies.openssl_probe]
package = "openssl-probe"
version = "=0.1.4"

[dependencies.openssl_sys]
package = "openssl-sys"
version = "=0.9.65"

[dependencies.ordered_float]
package = "ordered-float"
version = "=2.5.1"

[dependencies.parking_lot]
package = "parking_lot"
version = "=0.11.1"

[dependencies.parking_lot_core]
package = "parking_lot_core"
version = "=0.8.3"

[dependencies.paste]
package = "paste"
version = "=1.0.5"

[dependencies.percent_encoding]
package = "percent-encoding"
version = "=2.1.0"

[dependencies.pest]
package = "pest"
version = "=2.1.3"

[dependencies.petgraph]
package = "petgraph"
version = "=0.5.1"

[dependencies.phf]
package = "phf"
version = "=0.8.0"

[dependencies.phf_codegen]
package = "phf_codegen"
version = "=0.8.0"

[dependencies.phf_generator]
package = "phf_generator"
version = "=0.8.0"

[dependencies.phf_shared]
package = "phf_shared"
version = "=0.8.0"

[dependencies.pin_project]
package = "pin-project"
version = "=1.0.7"

[dependencies.pin_project_internal]
package = "pin-project-internal"
version = "=1.0.7"

[dependencies.pin_project_lite]
package = "pin-project-lite"
version = "=0.2.6"

[dependencies.pin_utils]
package = "pin-utils"
version = "=0.1.0"

[dependencies.pkg_config]
package = "pkg-config"
version = "=0.3.19"

[dependencies.png]
package = "png"
version = "=0.16.8"

[dependencies.postgres]
package = "postgres"
version = "=0.19.1"

[dependencies.postgres_protocol]
package = "postgres-protocol"
version = "=0.6.1"

[dependencies.postgres_types]
package = "postgres-types"
version = "=0.2.1"

[dependencies.ppv_lite86]
package = "ppv-lite86"
version = "=0.2.10"

[dependencies.precomputed_hash]
package = "precomputed-hash"
version = "=0.1.1"

[dependencies.proc_macro2]
package = "proc-macro2"
version = "=1.0.27"
features = ["span-locations"]

[dependencies.proc_macro_hack]
package = "proc-macro-hack"
version = "=0.5.19"

[dependencies.proc_macro_nested]
package = "proc-macro-nested"
version = "=0.1.7"

[dependencies.quick_error]
package = "quick-error"
version = "=2.0.1"

[dependencies.quote]
package = "quote"
version = "=1.0.9"

[dependencies.rand]
package = "rand"
version = "=0.8.4"
features = ["serde1", "small_rng"]

[dependencies.rand_0_7_3]
package = "rand"
version = "=0.7.3"

[dependencies.rand_chacha]
package = "rand_chacha"
version = "=0.3.1"

[dependencies.rand_chacha_0_2_2]
package = "rand_chacha"
version = "=0.2.2"

[dependencies.rand_core]
package = "rand_core"
version = "=0.6.3"
features = ["alloc", "getrandom", "serde", "serde1", "std"]

[dependencies.rand_core_0_5_1]
package = "rand_core"
version = "=0.5.1"

[dependencies.rand_distr]
package = "rand_distr"
version = "=0.4.1"

[dependencies.rand_hc]
package = "rand_hc"
version = "=0.3.1"

[dependencies.rand_pcg]
package = "rand_pcg"
version = "=0.2.1"

[dependencies.rawpointer]
package = "rawpointer"
version = "=0.2.1"

[dependencies.rayon]
package = "rayon"
version = "=1.5.1"

[dependencies.rayon_core]
package = "rayon-core"
version = "=1.9.1"

[dependencies.regex]
package = "regex"
version = "=1.5.4"

[dependencies.regex_automata]
package = "regex-automata"
version = "=0.1.10"

[dependencies.regex_syntax]
package = "regex-syntax"
version = "=0.6.25"

[dependencies.remove_dir_all]
package = "remove_dir_all"
version = "=0.5.3"

[dependencies.reqwest]
package = "reqwest"
version = "=0.11.4"
features = ["blocking", "cookies", "json", "multipart"]

[dependencies.ring]
package = "ring"
version = "=0.16.20"

[dependencies.rusqlite]
package = "rusqlite"
version = "=0.25.3"
features = ["bundled-full"]

[dependencies.rustc_demangle]
package = "rustc-demangle"
version = "=0.1.20"

[dependencies.rustc_version]
package = "rustc_version"
version = "=0.4.0"

[dependencies.ryu]
package = "ryu"
version = "=1.0.5"

[dependencies.same_file]
package = "same-file"
version = "=1.0.6"

[dependencies.scoped_threadpool]
package = "scoped_threadpool"
version = "=0.1.9"

[dependencies.scopeguard]
package = "scopeguard"
version = "=1.1.0"

[dependencies.select]
package = "select"
version = "=0.5.0"

[dependencies.semver]
package = "semver"
version = "=1.0.3"

[dependencies.semver_parser]
package = "semver-parser"
version = "=0.10.2"

[dependencies.serde]
package = "serde"
version = "1"
features = ["derive"]

[dependencies.serde_json]
package = "serde_json"
version = "=1.0.64"
features = ["raw_value"]

[dependencies.serde_urlencoded]
package = "serde_urlencoded"
version = "=0.7.0"

[dependencies.serde_value]
package = "serde-value"
version = "=0.7.0"

[dependencies.serde_yaml]
package = "serde_yaml"
version = "=0.8.17"

[dependencies.sha2]
package = "sha2"
version = "=0.9.5"

[dependencies.simba]
package = "simba"
version = "=0.5.1"

[dependencies.siphasher]
package = "siphasher"
version = "=0.3.5"

[dependencies.slab]
package = "slab"
version = "=0.4.3"

[dependencies.smallvec]
package = "smallvec"
version = "=1.6.1"

[dependencies.smawk]
package = "smawk"
version = "=0.3.1"

[dependencies.socket2]
package = "socket2"
version = "=0.4.0"
features = ["all"]

[dependencies.spin]
package = "spin"
version = "=0.5.2"

[dependencies.standback]
package = "standback"
version = "=0.2.17"

[dependencies.string_cache]
package = "string_cache"
version = "=0.8.1"

[dependencies.string_cache_codegen]
package = "string_cache_codegen"
version = "=0.5.1"

[dependencies.stringprep]
package = "stringprep"
version = "=0.1.2"

[dependencies.strsim]
package = "strsim"
version = "=0.10.0"

[dependencies.strsim_0_8_0]
package = "strsim"
version = "=0.8.0"

[dependencies.subtle]
package = "subtle"
version = "=2.4.0"

[dependencies.syn]
package = "syn"
version = "=1.0.57"
features = ["extra-traits", "fold", "full", "visit", "visit-mut"]

[dependencies.tar]
package = "tar"
version = "=0.4.35"

[dependencies.tempfile]
package = "tempfile"
version = "=3.2.0"

[dependencies.tendril]
package = "tendril"
version = "=0.4.2"

[dependencies.termcolor]
package = "termcolor"
version = "=1.1.2"

[dependencies.textwrap]
package = "textwrap"
version = "=0.14.0"

[dependencies.textwrap_0_11_0]
package = "textwrap"
version = "=0.11.0"

[dependencies.thiserror]
package = "thiserror"
version = "=1.0.25"

[dependencies.thiserror_impl]
package = "thiserror-impl"
version = "=1.0.25"

[dependencies.thread_id]
package = "thread-id"
version = "=3.3.0"

[dependencies.thread_local]
package = "thread_local"
version = "=1.1.3"

[dependencies.threadpool]
package = "threadpool"
version = "=1.8.1"

[dependencies.tiff]
package = "tiff"
version = "=0.6.1"

[dependencies.time]
package = "time"
version = "=0.2.27"

[dependencies.time_0_1_44]
package = "time"
version = "=0.1.44"

[dependencies.time_macros]
package = "time-macros"
version = "=0.1.1"

[dependencies.time_macros_impl]
package = "time-macros-impl"
version = "=0.1.2"

[dependencies.tinyvec]
package = "tinyvec"
version = "=1.2.0"
features = ["alloc", "grab_spare_slice", "rustc_1_40", "serde"]

[dependencies.tinyvec_macros]
package = "tinyvec_macros"
version = "=0.1.0"

[dependencies.tokio]
package = "tokio"
version = "=1.7.1"
features = ["full", "test-util"]

[dependencies.tokio_native_tls]
package = "tokio-native-tls"
version = "=0.3.0"

[dependencies.tokio_postgres]
package = "tokio-postgres"
version = "=0.7.2"

[dependencies.tokio_util]
package = "tokio-util"
version = "=0.6.7"

[dependencies.toml]
package = "toml"
version = "=0.5.8"

[dependencies.tower_service]
package = "tower-service"
version = "=0.3.1"

[dependencies.tracing]
package = "tracing"
version = "=0.1.26"

[dependencies.tracing_core]
package = "tracing-core"
version = "=0.1.18"

[dependencies.traitobject]
package = "traitobject"
version = "=0.1.0"

[dependencies.try_lock]
package = "try-lock"
version = "=0.2.3"

[dependencies.typemap]
package = "typemap"
version = "=0.3.3"

[dependencies.typenum]
package = "typenum"
version = "=1.13.0"

[dependencies.ucd_trie]
package = "ucd-trie"
version = "=0.1.3"

[dependencies.unicase]
package = "unicase"
version = "=2.6.0"

[dependencies.unicode_bidi]
package = "unicode-bidi"
version = "=0.3.5"

[dependencies.unicode_linebreak]
package = "unicode-linebreak"
version = "=0.1.1"

[dependencies.unicode_normalization]
package = "unicode-normalization"
version = "=0.1.19"

[dependencies.unicode_segmentation]
package = "unicode-segmentation"
version = "=1.7.1"

[dependencies.unicode_width]
package = "unicode-width"
version = "=0.1.8"

[dependencies.unicode_xid]
package = "unicode-xid"
version = "=0.2.2"

[dependencies.unsafe_any]
package = "unsafe-any"
version = "=0.4.2"

[dependencies.untrusted]
package = "untrusted"
version = "=0.7.1"

[dependencies.url]
package = "url"
version = "=2.2.2"

[dependencies.utf8]
package = "utf-8"
version = "=0.7.6"

[dependencies.vec_map]
package = "vec_map"
version = "=0.8.2"

[dependencies.version_check]
package = "version_check"
version = "=0.9.3"

[dependencies.walkdir]
package = "walkdir"
version = "=2.3.2"

[dependencies.want]
package = "want"
version = "=0.3.0"

[dependencies.weezl]
package = "weezl"
version = "=0.1.5"

[dependencies.winapi]
package = "winapi"
version = "=0.3.9"

[dependencies.xattr]
package = "xattr"
version = "=0.2.2"

[dependencies.xml5ever]
package = "xml5ever"
version = "=0.16.1"

[dependencies.yaml_rust]
package = "yaml-rust"
version = "=0.4.5"

[dependencies.near_sdk_macros]
package = "near-sdk-macros"
version = "=3.1.0"

[dependencies.near_sdk]
package = "near-sdk"
version = "=3.1.0"

'''
'''--- compiler/base/crate-information.json ---
[
  {
    "name": "addr2line",
    "version": "0.15.2",
    "id": "addr2line"
  },
  {
    "name": "adler",
    "version": "1.0.2",
    "id": "adler"
  },
  {
    "name": "adler32",
    "version": "1.2.0",
    "id": "adler32"
  },
  {
    "name": "ahash",
    "version": "0.7.4",
    "id": "ahash"
  },
  {
    "name": "aho-corasick",
    "version": "0.7.18",
    "id": "aho_corasick"
  },
  {
    "name": "ansi_term",
    "version": "0.12.1",
    "id": "ansi_term"
  },
  {
    "name": "ansi_term",
    "version": "0.11.0",
    "id": "ansi_term_0_11_0"
  },
  {
    "name": "anyhow",
    "version": "1.0.41",
    "id": "anyhow"
  },
  {
    "name": "approx",
    "version": "0.5.0",
    "id": "approx"
  },
  {
    "name": "arc-swap",
    "version": "0.4.8",
    "id": "arc_swap"
  },
  {
    "name": "arrayvec",
    "version": "0.7.1",
    "id": "arrayvec"
  },
  {
    "name": "async-recursion",
    "version": "0.3.2",
    "id": "async_recursion"
  },
  {
    "name": "async-trait",
    "version": "0.1.50",
    "id": "async_trait"
  },
  {
    "name": "atty",
    "version": "0.2.14",
    "id": "atty"
  },
  {
    "name": "autocfg",
    "version": "1.0.1",
    "id": "autocfg"
  },
  {
    "name": "backtrace",
    "version": "0.3.60",
    "id": "backtrace"
  },
  {
    "name": "base64",
    "version": "0.13.0",
    "id": "base64"
  },
  {
    "name": "bit-set",
    "version": "0.5.2",
    "id": "bit_set"
  },
  {
    "name": "bit-vec",
    "version": "0.6.3",
    "id": "bit_vec"
  },
  {
    "name": "bitflags",
    "version": "1.2.1",
    "id": "bitflags"
  },
  {
    "name": "block-buffer",
    "version": "0.9.0",
    "id": "block_buffer"
  },
  {
    "name": "bstr",
    "version": "0.2.16",
    "id": "bstr"
  },
  {
    "name": "bytemuck",
    "version": "1.7.0",
    "id": "bytemuck"
  },
  {
    "name": "byteorder",
    "version": "1.4.3",
    "id": "byteorder"
  },
  {
    "name": "bytes",
    "version": "1.0.1",
    "id": "bytes"
  },
  {
    "name": "cc",
    "version": "1.0.68",
    "id": "cc"
  },
  {
    "name": "cfg-if",
    "version": "1.0.0",
    "id": "cfg_if"
  },
  {
    "name": "cfg-if",
    "version": "0.1.10",
    "id": "cfg_if_0_1_10"
  },
  {
    "name": "chrono",
    "version": "0.4.19",
    "id": "chrono"
  },
  {
    "name": "clap",
    "version": "2.33.3",
    "id": "clap"
  },
  {
    "name": "color_quant",
    "version": "1.1.0",
    "id": "color_quant"
  },
  {
    "name": "const_fn",
    "version": "0.4.8",
    "id": "const_fn"
  },
  {
    "name": "cpufeatures",
    "version": "0.1.5",
    "id": "cpufeatures"
  },
  {
    "name": "crc32fast",
    "version": "1.2.1",
    "id": "crc32fast"
  },
  {
    "name": "crossbeam",
    "version": "0.8.1",
    "id": "crossbeam"
  },
  {
    "name": "crossbeam-channel",
    "version": "0.5.1",
    "id": "crossbeam_channel"
  },
  {
    "name": "crossbeam-deque",
    "version": "0.8.0",
    "id": "crossbeam_deque"
  },
  {
    "name": "crossbeam-epoch",
    "version": "0.9.5",
    "id": "crossbeam_epoch"
  },
  {
    "name": "crossbeam-queue",
    "version": "0.3.2",
    "id": "crossbeam_queue"
  },
  {
    "name": "crossbeam-utils",
    "version": "0.8.5",
    "id": "crossbeam_utils"
  },
  {
    "name": "crypto-mac",
    "version": "0.10.0",
    "id": "crypto_mac"
  },
  {
    "name": "csv",
    "version": "1.1.6",
    "id": "csv"
  },
  {
    "name": "csv-core",
    "version": "0.1.10",
    "id": "csv_core"
  },
  {
    "name": "data-encoding",
    "version": "2.3.2",
    "id": "data_encoding"
  },
  {
    "name": "deflate",
    "version": "0.8.6",
    "id": "deflate"
  },
  {
    "name": "derivative",
    "version": "2.2.0",
    "id": "derivative"
  },
  {
    "name": "digest",
    "version": "0.9.0",
    "id": "digest"
  },
  {
    "name": "dtoa",
    "version": "0.4.8",
    "id": "dtoa"
  },
  {
    "name": "either",
    "version": "1.6.1",
    "id": "either"
  },
  {
    "name": "encoding_rs",
    "version": "0.8.28",
    "id": "encoding_rs"
  },
  {
    "name": "env_logger",
    "version": "0.8.4",
    "id": "env_logger"
  },
  {
    "name": "error-chain",
    "version": "0.12.4",
    "id": "error_chain"
  },
  {
    "name": "fallible-iterator",
    "version": "0.2.0",
    "id": "fallible_iterator"
  },
  {
    "name": "fallible-streaming-iterator",
    "version": "0.1.9",
    "id": "fallible_streaming_iterator"
  },
  {
    "name": "filetime",
    "version": "0.2.14",
    "id": "filetime"
  },
  {
    "name": "fixedbitset",
    "version": "0.2.0",
    "id": "fixedbitset"
  },
  {
    "name": "flate2",
    "version": "1.0.20",
    "id": "flate2"
  },
  {
    "name": "fnv",
    "version": "1.0.7",
    "id": "fnv"
  },
  {
    "name": "foreign-types",
    "version": "0.3.2",
    "id": "foreign_types"
  },
  {
    "name": "foreign-types-shared",
    "version": "0.1.1",
    "id": "foreign_types_shared"
  },
  {
    "name": "form_urlencoded",
    "version": "1.0.1",
    "id": "form_urlencoded"
  },
  {
    "name": "futf",
    "version": "0.1.4",
    "id": "futf"
  },
  {
    "name": "futures",
    "version": "0.3.15",
    "id": "futures"
  },
  {
    "name": "futures-channel",
    "version": "0.3.15",
    "id": "futures_channel"
  },
  {
    "name": "futures-core",
    "version": "0.3.15",
    "id": "futures_core"
  },
  {
    "name": "futures-executor",
    "version": "0.3.15",
    "id": "futures_executor"
  },
  {
    "name": "futures-io",
    "version": "0.3.15",
    "id": "futures_io"
  },
  {
    "name": "futures-macro",
    "version": "0.3.15",
    "id": "futures_macro"
  },
  {
    "name": "futures-sink",
    "version": "0.3.15",
    "id": "futures_sink"
  },
  {
    "name": "futures-task",
    "version": "0.3.15",
    "id": "futures_task"
  },
  {
    "name": "futures-util",
    "version": "0.3.15",
    "id": "futures_util"
  },
  {
    "name": "generic-array",
    "version": "0.14.4",
    "id": "generic_array"
  },
  {
    "name": "getrandom",
    "version": "0.2.3",
    "id": "getrandom"
  },
  {
    "name": "getrandom",
    "version": "0.1.16",
    "id": "getrandom_0_1_16"
  },
  {
    "name": "gif",
    "version": "0.11.2",
    "id": "gif"
  },
  {
    "name": "gimli",
    "version": "0.24.0",
    "id": "gimli"
  },
  {
    "name": "glob",
    "version": "0.3.0",
    "id": "glob"
  },
  {
    "name": "h2",
    "version": "0.3.3",
    "id": "h2"
  },
  {
    "name": "hashbrown",
    "version": "0.11.2",
    "id": "hashbrown"
  },
  {
    "name": "hashbrown",
    "version": "0.9.1",
    "id": "hashbrown_0_9_1"
  },
  {
    "name": "hashlink",
    "version": "0.7.0",
    "id": "hashlink"
  },
  {
    "name": "hmac",
    "version": "0.10.1",
    "id": "hmac"
  },
  {
    "name": "html5ever",
    "version": "0.25.1",
    "id": "html5ever"
  },
  {
    "name": "http",
    "version": "0.2.4",
    "id": "http"
  },
  {
    "name": "http-body",
    "version": "0.4.2",
    "id": "http_body"
  },
  {
    "name": "httparse",
    "version": "1.4.1",
    "id": "httparse"
  },
  {
    "name": "httpdate",
    "version": "1.0.1",
    "id": "httpdate"
  },
  {
    "name": "humantime",
    "version": "2.1.0",
    "id": "humantime"
  },
  {
    "name": "hyper",
    "version": "0.14.9",
    "id": "hyper"
  },
  {
    "name": "hyper-tls",
    "version": "0.5.0",
    "id": "hyper_tls"
  },
  {
    "name": "idna",
    "version": "0.2.3",
    "id": "idna"
  },
  {
    "name": "image",
    "version": "0.23.14",
    "id": "image"
  },
  {
    "name": "indexmap",
    "version": "1.6.2",
    "id": "indexmap"
  },
  {
    "name": "instant",
    "version": "0.1.9",
    "id": "instant"
  },
  {
    "name": "iovec",
    "version": "0.1.4",
    "id": "iovec"
  },
  {
    "name": "ipnet",
    "version": "2.3.1",
    "id": "ipnet"
  },
  {
    "name": "itertools",
    "version": "0.10.1",
    "id": "itertools"
  },
  {
    "name": "itoa",
    "version": "0.4.7",
    "id": "itoa"
  },
  {
    "name": "jpeg-decoder",
    "version": "0.1.22",
    "id": "jpeg_decoder"
  },
  {
    "name": "lazy_static",
    "version": "1.4.0",
    "id": "lazy_static"
  },
  {
    "name": "libc",
    "version": "0.2.97",
    "id": "libc"
  },
  {
    "name": "libm",
    "version": "0.2.1",
    "id": "libm"
  },
  {
    "name": "libsqlite3-sys",
    "version": "0.22.2",
    "id": "libsqlite3_sys"
  },
  {
    "name": "linked-hash-map",
    "version": "0.5.4",
    "id": "linked_hash_map"
  },
  {
    "name": "lock_api",
    "version": "0.4.4",
    "id": "lock_api"
  },
  {
    "name": "log",
    "version": "0.4.14",
    "id": "log"
  },
  {
    "name": "log-mdc",
    "version": "0.1.0",
    "id": "log_mdc"
  },
  {
    "name": "log4rs",
    "version": "1.0.0",
    "id": "log4rs"
  },
  {
    "name": "mac",
    "version": "0.1.1",
    "id": "mac"
  },
  {
    "name": "markup5ever",
    "version": "0.10.1",
    "id": "markup5ever"
  },
  {
    "name": "markup5ever_rcdom",
    "version": "0.1.0",
    "id": "markup5ever_rcdom"
  },
  {
    "name": "matches",
    "version": "0.1.8",
    "id": "matches"
  },
  {
    "name": "matrixmultiply",
    "version": "0.3.1",
    "id": "matrixmultiply"
  },
  {
    "name": "md-5",
    "version": "0.9.1",
    "id": "md5"
  },
  {
    "name": "memchr",
    "version": "2.4.0",
    "id": "memchr"
  },
  {
    "name": "memmap",
    "version": "0.7.0",
    "id": "memmap"
  },
  {
    "name": "memoffset",
    "version": "0.6.4",
    "id": "memoffset"
  },
  {
    "name": "mime",
    "version": "0.3.16",
    "id": "mime"
  },
  {
    "name": "miniz_oxide",
    "version": "0.4.4",
    "id": "miniz_oxide"
  },
  {
    "name": "miniz_oxide",
    "version": "0.3.7",
    "id": "miniz_oxide_0_3_7"
  },
  {
    "name": "mio",
    "version": "0.7.13",
    "id": "mio"
  },
  {
    "name": "nalgebra",
    "version": "0.27.1",
    "id": "nalgebra"
  },
  {
    "name": "nalgebra-macros",
    "version": "0.1.0",
    "id": "nalgebra_macros"
  },
  {
    "name": "native-tls",
    "version": "0.2.7",
    "id": "native_tls"
  },
  {
    "name": "ndarray",
    "version": "0.15.3",
    "id": "ndarray"
  },
  {
    "name": "net2",
    "version": "0.2.37",
    "id": "net2"
  },
  {
    "name": "new_debug_unreachable",
    "version": "1.0.4",
    "id": "debug_unreachable"
  },
  {
    "name": "num",
    "version": "0.4.0",
    "id": "num"
  },
  {
    "name": "num-bigint",
    "version": "0.4.0",
    "id": "num_bigint"
  },
  {
    "name": "num-complex",
    "version": "0.4.0",
    "id": "num_complex"
  },
  {
    "name": "num-integer",
    "version": "0.1.44",
    "id": "num_integer"
  },
  {
    "name": "num-iter",
    "version": "0.1.42",
    "id": "num_iter"
  },
  {
    "name": "num-rational",
    "version": "0.4.0",
    "id": "num_rational"
  },
  {
    "name": "num-rational",
    "version": "0.3.2",
    "id": "num_rational_0_3_2"
  },
  {
    "name": "num-traits",
    "version": "0.2.14",
    "id": "num_traits"
  },
  {
    "name": "num_cpus",
    "version": "1.13.0",
    "id": "num_cpus"
  },
  {
    "name": "object",
    "version": "0.25.3",
    "id": "object"
  },
  {
    "name": "once_cell",
    "version": "1.8.0",
    "id": "once_cell"
  },
  {
    "name": "opaque-debug",
    "version": "0.3.0",
    "id": "opaque_debug"
  },
  {
    "name": "openssl",
    "version": "0.10.35",
    "id": "openssl"
  },
  {
    "name": "openssl-probe",
    "version": "0.1.4",
    "id": "openssl_probe"
  },
  {
    "name": "openssl-sys",
    "version": "0.9.65",
    "id": "openssl_sys"
  },
  {
    "name": "ordered-float",
    "version": "2.5.1",
    "id": "ordered_float"
  },
  {
    "name": "parking_lot",
    "version": "0.11.1",
    "id": "parking_lot"
  },
  {
    "name": "parking_lot_core",
    "version": "0.8.3",
    "id": "parking_lot_core"
  },
  {
    "name": "paste",
    "version": "1.0.5",
    "id": "paste"
  },
  {
    "name": "percent-encoding",
    "version": "2.1.0",
    "id": "percent_encoding"
  },
  {
    "name": "pest",
    "version": "2.1.3",
    "id": "pest"
  },
  {
    "name": "petgraph",
    "version": "0.5.1",
    "id": "petgraph"
  },
  {
    "name": "phf",
    "version": "0.8.0",
    "id": "phf"
  },
  {
    "name": "phf_codegen",
    "version": "0.8.0",
    "id": "phf_codegen"
  },
  {
    "name": "phf_generator",
    "version": "0.8.0",
    "id": "phf_generator"
  },
  {
    "name": "phf_shared",
    "version": "0.8.0",
    "id": "phf_shared"
  },
  {
    "name": "pin-project",
    "version": "1.0.7",
    "id": "pin_project"
  },
  {
    "name": "pin-project-internal",
    "version": "1.0.7",
    "id": "pin_project_internal"
  },
  {
    "name": "pin-project-lite",
    "version": "0.2.6",
    "id": "pin_project_lite"
  },
  {
    "name": "pin-utils",
    "version": "0.1.0",
    "id": "pin_utils"
  },
  {
    "name": "pkg-config",
    "version": "0.3.19",
    "id": "pkg_config"
  },
  {
    "name": "png",
    "version": "0.16.8",
    "id": "png"
  },
  {
    "name": "postgres",
    "version": "0.19.1",
    "id": "postgres"
  },
  {
    "name": "postgres-protocol",
    "version": "0.6.1",
    "id": "postgres_protocol"
  },
  {
    "name": "postgres-types",
    "version": "0.2.1",
    "id": "postgres_types"
  },
  {
    "name": "ppv-lite86",
    "version": "0.2.10",
    "id": "ppv_lite86"
  },
  {
    "name": "precomputed-hash",
    "version": "0.1.1",
    "id": "precomputed_hash"
  },
  {
    "name": "proc-macro-hack",
    "version": "0.5.19",
    "id": "proc_macro_hack"
  },
  {
    "name": "proc-macro-nested",
    "version": "0.1.7",
    "id": "proc_macro_nested"
  },
  {
    "name": "proc-macro2",
    "version": "1.0.27",
    "id": "proc_macro2"
  },
  {
    "name": "quick-error",
    "version": "2.0.1",
    "id": "quick_error"
  },
  {
    "name": "quote",
    "version": "1.0.9",
    "id": "quote"
  },
  {
    "name": "rand",
    "version": "0.8.4",
    "id": "rand"
  },
  {
    "name": "rand",
    "version": "0.7.3",
    "id": "rand_0_7_3"
  },
  {
    "name": "rand_chacha",
    "version": "0.3.1",
    "id": "rand_chacha"
  },
  {
    "name": "rand_chacha",
    "version": "0.2.2",
    "id": "rand_chacha_0_2_2"
  },
  {
    "name": "rand_core",
    "version": "0.6.3",
    "id": "rand_core"
  },
  {
    "name": "rand_core",
    "version": "0.5.1",
    "id": "rand_core_0_5_1"
  },
  {
    "name": "rand_distr",
    "version": "0.4.1",
    "id": "rand_distr"
  },
  {
    "name": "rand_hc",
    "version": "0.3.1",
    "id": "rand_hc"
  },
  {
    "name": "rand_pcg",
    "version": "0.2.1",
    "id": "rand_pcg"
  },
  {
    "name": "rawpointer",
    "version": "0.2.1",
    "id": "rawpointer"
  },
  {
    "name": "rayon",
    "version": "1.5.1",
    "id": "rayon"
  },
  {
    "name": "rayon-core",
    "version": "1.9.1",
    "id": "rayon_core"
  },
  {
    "name": "regex",
    "version": "1.5.4",
    "id": "regex"
  },
  {
    "name": "regex-automata",
    "version": "0.1.10",
    "id": "regex_automata"
  },
  {
    "name": "regex-syntax",
    "version": "0.6.25",
    "id": "regex_syntax"
  },
  {
    "name": "remove_dir_all",
    "version": "0.5.3",
    "id": "remove_dir_all"
  },
  {
    "name": "reqwest",
    "version": "0.11.4",
    "id": "reqwest"
  },
  {
    "name": "ring",
    "version": "0.16.20",
    "id": "ring"
  },
  {
    "name": "rusqlite",
    "version": "0.25.3",
    "id": "rusqlite"
  },
  {
    "name": "rustc-demangle",
    "version": "0.1.20",
    "id": "rustc_demangle"
  },
  {
    "name": "rustc_version",
    "version": "0.4.0",
    "id": "rustc_version"
  },
  {
    "name": "ryu",
    "version": "1.0.5",
    "id": "ryu"
  },
  {
    "name": "same-file",
    "version": "1.0.6",
    "id": "same_file"
  },
  {
    "name": "scoped_threadpool",
    "version": "0.1.9",
    "id": "scoped_threadpool"
  },
  {
    "name": "scopeguard",
    "version": "1.1.0",
    "id": "scopeguard"
  },
  {
    "name": "select",
    "version": "0.5.0",
    "id": "select"
  },
  {
    "name": "semver",
    "version": "1.0.3",
    "id": "semver"
  },
  {
    "name": "semver-parser",
    "version": "0.10.2",
    "id": "semver_parser"
  },
  {
    "name": "serde",
    "version": "1.0.126",
    "id": "serde"
  },
  {
    "name": "serde-value",
    "version": "0.7.0",
    "id": "serde_value"
  },
  {
    "name": "serde_derive",
    "version": "1.0.126",
    "id": "serde_derive"
  },
  {
    "name": "serde_json",
    "version": "1.0.64",
    "id": "serde_json"
  },
  {
    "name": "serde_urlencoded",
    "version": "0.7.0",
    "id": "serde_urlencoded"
  },
  {
    "name": "serde_yaml",
    "version": "0.8.17",
    "id": "serde_yaml"
  },
  {
    "name": "sha2",
    "version": "0.9.5",
    "id": "sha2"
  },
  {
    "name": "simba",
    "version": "0.5.1",
    "id": "simba"
  },
  {
    "name": "siphasher",
    "version": "0.3.5",
    "id": "siphasher"
  },
  {
    "name": "slab",
    "version": "0.4.3",
    "id": "slab"
  },
  {
    "name": "smallvec",
    "version": "1.6.1",
    "id": "smallvec"
  },
  {
    "name": "smawk",
    "version": "0.3.1",
    "id": "smawk"
  },
  {
    "name": "socket2",
    "version": "0.4.0",
    "id": "socket2"
  },
  {
    "name": "spin",
    "version": "0.5.2",
    "id": "spin"
  },
  {
    "name": "standback",
    "version": "0.2.17",
    "id": "standback"
  },
  {
    "name": "string_cache",
    "version": "0.8.1",
    "id": "string_cache"
  },
  {
    "name": "string_cache_codegen",
    "version": "0.5.1",
    "id": "string_cache_codegen"
  },
  {
    "name": "stringprep",
    "version": "0.1.2",
    "id": "stringprep"
  },
  {
    "name": "strsim",
    "version": "0.10.0",
    "id": "strsim"
  },
  {
    "name": "strsim",
    "version": "0.8.0",
    "id": "strsim_0_8_0"
  },
  {
    "name": "subtle",
    "version": "2.4.0",
    "id": "subtle"
  },
  {
    "name": "syn",
    "version": "1.0.73",
    "id": "syn"
  },
  {
    "name": "tar",
    "version": "0.4.35",
    "id": "tar"
  },
  {
    "name": "tempfile",
    "version": "3.2.0",
    "id": "tempfile"
  },
  {
    "name": "tendril",
    "version": "0.4.2",
    "id": "tendril"
  },
  {
    "name": "termcolor",
    "version": "1.1.2",
    "id": "termcolor"
  },
  {
    "name": "textwrap",
    "version": "0.14.0",
    "id": "textwrap"
  },
  {
    "name": "textwrap",
    "version": "0.11.0",
    "id": "textwrap_0_11_0"
  },
  {
    "name": "thiserror",
    "version": "1.0.25",
    "id": "thiserror"
  },
  {
    "name": "thiserror-impl",
    "version": "1.0.25",
    "id": "thiserror_impl"
  },
  {
    "name": "thread-id",
    "version": "3.3.0",
    "id": "thread_id"
  },
  {
    "name": "thread_local",
    "version": "1.1.3",
    "id": "thread_local"
  },
  {
    "name": "threadpool",
    "version": "1.8.1",
    "id": "threadpool"
  },
  {
    "name": "tiff",
    "version": "0.6.1",
    "id": "tiff"
  },
  {
    "name": "time",
    "version": "0.2.27",
    "id": "time"
  },
  {
    "name": "time",
    "version": "0.1.44",
    "id": "time_0_1_44"
  },
  {
    "name": "time-macros",
    "version": "0.1.1",
    "id": "time_macros"
  },
  {
    "name": "time-macros-impl",
    "version": "0.1.2",
    "id": "time_macros_impl"
  },
  {
    "name": "tinyvec",
    "version": "1.2.0",
    "id": "tinyvec"
  },
  {
    "name": "tinyvec_macros",
    "version": "0.1.0",
    "id": "tinyvec_macros"
  },
  {
    "name": "tokio",
    "version": "1.7.1",
    "id": "tokio"
  },
  {
    "name": "tokio-native-tls",
    "version": "0.3.0",
    "id": "tokio_native_tls"
  },
  {
    "name": "tokio-postgres",
    "version": "0.7.2",
    "id": "tokio_postgres"
  },
  {
    "name": "tokio-util",
    "version": "0.6.7",
    "id": "tokio_util"
  },
  {
    "name": "toml",
    "version": "0.5.8",
    "id": "toml"
  },
  {
    "name": "tower-service",
    "version": "0.3.1",
    "id": "tower_service"
  },
  {
    "name": "tracing",
    "version": "0.1.26",
    "id": "tracing"
  },
  {
    "name": "tracing-core",
    "version": "0.1.18",
    "id": "tracing_core"
  },
  {
    "name": "traitobject",
    "version": "0.1.0",
    "id": "traitobject"
  },
  {
    "name": "try-lock",
    "version": "0.2.3",
    "id": "try_lock"
  },
  {
    "name": "typemap",
    "version": "0.3.3",
    "id": "typemap"
  },
  {
    "name": "typenum",
    "version": "1.13.0",
    "id": "typenum"
  },
  {
    "name": "ucd-trie",
    "version": "0.1.3",
    "id": "ucd_trie"
  },
  {
    "name": "unicase",
    "version": "2.6.0",
    "id": "unicase"
  },
  {
    "name": "unicode-bidi",
    "version": "0.3.5",
    "id": "unicode_bidi"
  },
  {
    "name": "unicode-linebreak",
    "version": "0.1.1",
    "id": "unicode_linebreak"
  },
  {
    "name": "unicode-normalization",
    "version": "0.1.19",
    "id": "unicode_normalization"
  },
  {
    "name": "unicode-segmentation",
    "version": "1.7.1",
    "id": "unicode_segmentation"
  },
  {
    "name": "unicode-width",
    "version": "0.1.8",
    "id": "unicode_width"
  },
  {
    "name": "unicode-xid",
    "version": "0.2.2",
    "id": "unicode_xid"
  },
  {
    "name": "unsafe-any",
    "version": "0.4.2",
    "id": "unsafe_any"
  },
  {
    "name": "untrusted",
    "version": "0.7.1",
    "id": "untrusted"
  },
  {
    "name": "url",
    "version": "2.2.2",
    "id": "url"
  },
  {
    "name": "utf-8",
    "version": "0.7.6",
    "id": "utf8"
  },
  {
    "name": "vec_map",
    "version": "0.8.2",
    "id": "vec_map"
  },
  {
    "name": "version_check",
    "version": "0.9.3",
    "id": "version_check"
  },
  {
    "name": "walkdir",
    "version": "2.3.2",
    "id": "walkdir"
  },
  {
    "name": "want",
    "version": "0.3.0",
    "id": "want"
  },
  {
    "name": "weezl",
    "version": "0.1.5",
    "id": "weezl"
  },
  {
    "name": "winapi",
    "version": "0.3.9",
    "id": "winapi"
  },
  {
    "name": "xattr",
    "version": "0.2.2",
    "id": "xattr"
  },
  {
    "name": "xml5ever",
    "version": "0.16.1",
    "id": "xml5ever"
  },
  {
    "name": "yaml-rust",
    "version": "0.4.5",
    "id": "yaml_rust"
  }
]
'''
'''--- compiler/base/entrypoint.sh ---
#!/bin/bash

set -eu

timeout=${PLAYGROUND_TIMEOUT:-10}

modify-cargo-toml

# Don't use `exec` here. The shell is what prints out the useful
# "Killed" message
timeout --signal=KILL ${timeout} "$@"

'''
'''--- compiler/base/modify-cargo-toml/Cargo.toml ---
[package]
name = "modify-cargo-toml"
version = "0.1.0"
authors = ["Jake Goulding <jake.goulding@gmail.com>"]

[dependencies]
serde = "1.0.78"
toml = "0.5.1"
serde_derive = "1.0.78"

'''
'''--- compiler/base/modify-cargo-toml/src/main.rs ---
extern crate serde;
#[macro_use]
extern crate serde_derive;
extern crate toml;

use std::{collections::BTreeMap, env, ffi::OsString, fs, path::PathBuf};
use toml::Value;

fn main() {
    let mut args = env::args_os().skip(1).fuse();

    let input_filename = args.next().unwrap_or_else(|| OsString::from("Cargo.toml"));
    let output_filename = args.next().unwrap_or_else(|| input_filename.clone());

    let input_filename = PathBuf::from(input_filename);
    let output_filename = PathBuf::from(output_filename);

    let input = fs::read_to_string(&input_filename)
        .unwrap_or_else(|e| panic!("Cannot read {}: {}", input_filename.display(), e));
    let mut cargo_toml: Value = toml::from_str(&input)
        .unwrap_or_else(|e| panic!("Cannot parse {} as TOML: {}", input_filename.display(), e));

    if env::var_os("PLAYGROUND_FEATURE_EDITION2021").is_some() {
        cargo_toml = set_feature_edition2021(cargo_toml);
    }

    if let Ok(edition) = env::var("PLAYGROUND_EDITION") {
        cargo_toml = set_edition(cargo_toml, &edition);
    }

    if env::var_os("PLAYGROUND_NO_DEPENDENCIES").is_some() {
        cargo_toml = remove_dependencies(cargo_toml);
    }

    if let Ok(crate_type) = env::var("PLAYGROUND_CRATE_TYPE") {
        cargo_toml = set_crate_type(cargo_toml, &crate_type);
    }

    if let Ok(lto) = env::var("PLAYGROUND_RELEASE_LTO") {
        cargo_toml = set_release_lto(cargo_toml, lto == "true");
    }

    let output = toml::to_string(&cargo_toml).expect("Cannot convert back to TOML");

    fs::write(&output_filename, output)
        .unwrap_or_else(|e| panic!("Cannot write to {}: {}", output_filename.display(), e));
}

type Other = BTreeMap<String, Value>;

fn modify<F, T>(cargo_toml: Value, f: F) -> Value
where
    F: FnOnce(T) -> T,
    T: serde::Serialize + for<'de> serde::Deserialize<'de>,
{
    let cargo_toml = cargo_toml.try_into().unwrap();

    let cargo_toml = f(cargo_toml);

    Value::try_from(cargo_toml).unwrap()
}

fn ensure_string_in_vec(values: &mut Vec<String>, val: &str) {
    if !values.iter().any(|f| f == val) {
        values.push(val.into());
    }
}

fn set_feature_edition2021(cargo_toml: Value) -> Value {
    #[derive(Debug, Serialize, Deserialize)]
    #[serde(rename_all = "kebab-case")]
    struct CargoToml {
        #[serde(default)]
        cargo_features: Vec<String>,
        #[serde(flatten)]
        other: Other,
    }

    modify(cargo_toml, |mut cargo_toml: CargoToml| {
        ensure_string_in_vec(&mut cargo_toml.cargo_features, "edition2021");
        cargo_toml
    })
}

fn set_edition(cargo_toml: Value, edition: &str) -> Value {
    #[derive(Debug, Serialize, Deserialize)]
    #[serde(rename_all = "kebab-case")]
    struct CargoToml {
        package: Package,
        #[serde(flatten)]
        other: Other,
    }

    #[derive(Debug, Serialize, Deserialize)]
    #[serde(rename_all = "kebab-case")]
    struct Package {
        #[serde(default)]
        edition: String,
        #[serde(flatten)]
        other: Other,
    }

    modify(cargo_toml, |mut cargo_toml: CargoToml| {
        cargo_toml.package.edition = edition.into();
        cargo_toml
    })
}

fn remove_dependencies(cargo_toml: Value) -> Value {
    #[derive(Debug, Serialize, Deserialize)]
    #[serde(rename_all = "kebab-case")]
    struct CargoToml {
        dependencies: BTreeMap<String, Value>,
        #[serde(flatten)]
        other: Other,
    }

    modify(cargo_toml, |mut cargo_toml: CargoToml| {
        cargo_toml.dependencies.clear();
        cargo_toml
    })
}

fn set_crate_type(cargo_toml: Value, crate_type: &str) -> Value {
    #[derive(Debug, Serialize, Deserialize)]
    #[serde(rename_all = "kebab-case")]
    struct CargoToml {
        #[serde(default)]
        lib: Lib,
        #[serde(flatten)]
        other: Other,
    }

    #[derive(Debug, Default, Serialize, Deserialize)]
    #[serde(rename_all = "kebab-case")]
    struct Lib {
        #[serde(default)]
        crate_type: Vec<String>,
        #[serde(flatten)]
        other: Other,
    }

    modify(cargo_toml, |mut cargo_toml: CargoToml| {
        ensure_string_in_vec(&mut cargo_toml.lib.crate_type, crate_type);
        cargo_toml
    })
}

fn set_release_lto(cargo_toml: Value, lto: bool) -> Value {
    #[derive(Debug, Serialize, Deserialize)]
    #[serde(rename_all = "kebab-case")]
    struct CargoToml {
        #[serde(default)]
        profile: Profiles,
        #[serde(flatten)]
        other: Other,
    }

    #[derive(Debug, Default, Serialize, Deserialize)]
    #[serde(rename_all = "kebab-case")]
    struct Profiles {
        #[serde(default)]
        release: Profile,
        #[serde(flatten)]
        other: Other,
    }

    #[derive(Debug, Default, Serialize, Deserialize)]
    #[serde(rename_all = "kebab-case")]
    struct Profile {
        #[serde(default)]
        lto: bool,
        #[serde(flatten)]
        other: Other,
    }

    modify(cargo_toml, |mut cargo_toml: CargoToml| {
        cargo_toml.profile.release.lto = lto;
        cargo_toml
    })
}

'''
'''--- compiler/base/postinstall.sh ---
#!/usr/bin/env bash

set -eu

function install_wasm_target() {
    rustup target add wasm32-unknown-unknown
}

function install_wasm2wat() {
    cd /tmp
    git clone https://github.com/WebAssembly/wabt
    cd /tmp/wabt/
    cmake -DBUILD_TESTS=OFF -DCMAKE_BUILD_TYPE=Release
    make wasm2wat
    cp ./wasm2wat $HOME/.cargo/bin
    rm -rf /tmp/wabt/
}

function install_wasm_gc() {
    cargo install wasm-gc
}

if [[ $1 == "nightly" ]]; then
    (install_wasm_target)
    (install_wasm2wat)
    (install_wasm_gc)
fi

'''
'''--- compiler/build.sh ---
#!/bin/bash

set -euv -o pipefail

channels_to_build="${CHANNELS_TO_BUILD-stable}"
tools_to_build="${TOOLS_TO_BUILD-rustfmt clippy miri}"
perform_push="${PERFORM_PUSH-false}"

repository=shepmaster

for channel in $channels_to_build; do
    cd "base"

    image_name="rust-${channel}"
    full_name="${repository}/${image_name}"

    docker pull "${full_name}" || true
    docker pull "${full_name}:munge" || true

    # Prevent building the tool multiple times
    # https://github.com/moby/moby/issues/34715
    docker build -t "${full_name}:munge" \
           --target munge \
           --cache-from "${full_name}" \
           --cache-from "${full_name}:munge" \
           --build-arg channel="${channel}" \
           .

    docker build -t "${full_name}:sources" \
           --target sources \
           --cache-from "${full_name}" \
           --cache-from "${full_name}:munge" \
           --build-arg channel="${channel}" \
           .

    docker build -t "${full_name}" \
           --cache-from "${full_name}" \
           --cache-from "${full_name}:munge" \
           --build-arg channel="${channel}" \
           .

    docker tag "${full_name}" "${image_name}"

    if [[ "${perform_push}" == 'true' ]]; then
        docker push "${full_name}:munge"
        docker push "${full_name}:sources"
        docker push "${full_name}"
    fi

    cd ..
done

crate_api_base=https://crates.io/api/v1/crates

for tool in $tools_to_build; do
    cd "${tool}"

    image_name="${tool}"
    full_name="${repository}/${image_name}"

    docker pull "${full_name}" || true
    docker build -t "${full_name}" \
           .

    docker tag "${full_name}" "${image_name}"

    if [[ "${perform_push}" == 'true' ]]; then
        docker push "${full_name}"
    fi

    cd ..
done

'''
'''--- compiler/fetch.sh ---
#!/bin/bash

set -euv -o pipefail

repository=shepmaster

for image in rust-stable rust-beta rust-nightly rustfmt clippy miri; do
    docker pull "${repository}/${image}"
    # The backend expects images without a repository prefix
    docker tag "${repository}/${image}" "${image}"
done

'''
'''--- deployment/ubuntu.md ---
### Amazon EC2 (Ubuntu)

Here's an example session. This could definitely be improved and
automated.

#### Dependencies (as root)

```
apt-get update
apt-get upgrade -y
apt-get install git awscli nginx

# Install Docker CE
# Configure apt-get per instructions
# https://docs.docker.com/engine/installation/linux/docker-ce/ubuntu/
apt-get install docker-ce

# Use a production-quality storage driver that doesn't leak disk space
cat >>/etc/docker/daemon.json <<EOF
{
    "storage-driver": "overlay2"
}
EOF

# Ensure Docker can control the PID limit
mount | grep cgroup/pids

# Ensure Docker can control swap limit
# https://docs.docker.com/engine/installation/linux/linux-postinstall/#your-kernel-does-not-support-cgroup-swap-limit-capabilities

service docker restart
usermod -a -G docker ubuntu # user needs to log out and in again

fallocate -l 1G /swap.fs
chmod 0600 /swap.fs
mkswap /swap.fs
```

#### Set aside disk space (as root)
```
fallocate -l 512M /playground.fs
device=$(losetup -f --show /playground.fs)
mkfs -t ext3 -m 1 -v $device
mkdir /mnt/playground
```

#### Configure disk mountpoints (as root)
```
cat >>/etc/fstab <<EOF
/swap.fs        none            swap   sw       0   0
/playground.fs /mnt/playground  ext3   loop     0   0
EOF
```

Reboot the instance at this point.

#### Get the code
```
git clone https://github.com/integer32llc/rust-playground.git
cd rust-playground
```

#### Set a crontab to update the assets, binary, and docker containers

```
crontab -e
```

Review the [example crontab](crontab) in this repo. It calls [`update.sh`](update.sh) also in this repo.

#### Install the SystemD service

[playground.service](playground.service)

```
cp playground.service /etc/systemd/system/playground.service
service playground start
systemctl enable playground.service
```

#### Install the Nginx reverse proxy

[playground-reverse-proxy](playground-reverse-proxy)

```
cp playground-reverse-proxy /etc/nginx/sites-enabled
service nginx reload
```

#### Configure SSL

'''
'''--- deployment/update.sh ---
#!/bin/bash

set -euv -o pipefail

root=/home/ubuntu
binary_path=$root/playground-artifacts/ui

# Get new docker images
$root/rust-playground/compiler/fetch.sh

# Clean old docker images
docker system prune -f || true

# Get the binary's hash so we know if it has changed
previous_binary_hash=""
if [[ -f "${binary_path}" ]]; then
    previous_binary_hash=$(md5sum "${binary_path}")
fi

# Get new artifacts
aws s3 sync --region=us-east-2 s3://playground-artifacts-i32 $root/playground-artifacts
# These artifacts don't change names and might stay the same size
# https://github.com/aws/aws-cli/issues/1074
aws s3 sync \
    --region=us-east-2 \
    --exclude='*' \
    --include=ui \
    --include=build/index.html \
    --include=build/index.html.gz \
    --include=build/robots.txt \
    --exact-timestamps \
    s3://playground-artifacts-i32 $root/playground-artifacts
chmod +x "${binary_path}"

# Restart to get new server binary
if [[ -z "${previous_binary_hash}" ]] || ! md5sum -c <(echo "${previous_binary_hash}") --status; then
    sudo service playground stop || true
    sudo service playground start
fi

'''
'''--- tests/spec/features/assistance_spec.rb ---
require 'spec_helper'
require 'support/editor'
require 'support/playground_actions'

RSpec.feature "Editor assistance for common code modifications", type: :feature, js: true do
  include PlaygroundActions

  before { visit '/' }

  scenario "building code without a main method offers adding one" do
    editor.set <<~EOF
      fn example() {}
    EOF
    click_on("Build")

    within(:output, :warning) do
      click_on("add a main function")
    end

    expect(editor).to have_line 'println!("Hello, world!")'
  end

  scenario "using an unstable feature offers adding the feature flag" do
    in_channel_menu { click_on("Nightly") }
    editor.set <<~EOF
      extern "avr-interrupt" fn dummy() {}
    EOF
    click_on("Build")

    within(:output, :stderr) do
      click_on("add `#![feature(abi_avr_interrupt)]`")
    end

    expect(editor).to have_line '#![feature(abi_avr_interrupt)]'
  end

  scenario "using a type that hasn't been imported offers importing it" do
    editor.set <<~EOF
      fn example(_: HashMap) {}
    EOF
    click_on("Build")

    within(:output, :stderr) do
      click_on("use std::collections::HashMap;")
    end

    expect(editor).to have_line 'use std::collections::HashMap;'
  end

  scenario "triggering a panic offers enabling backtraces" do
    editor.set <<~EOF
      fn main() {
          panic!("Oops");
      }
    EOF
    click_on("Run")

    within(:output, :stderr) do
      click_on("run with `RUST_BACKTRACE=1` environment variable to display a backtrace")
    end

    within(:output, :stderr) do
      expect(page).to have_content("stack backtrace:")
    end
  end

  private

  def editor
    Editor.new(page)
  end
end

'''
'''--- tests/spec/features/automatic_primary_action_spec.rb ---
require 'spec_helper'
require 'support/editor'

RSpec.feature "Automatically selecting the primary action", type: :feature, js: true do
  before { visit '/' }

  scenario "when the crate is a binary" do
    editor.set <<~EOF
      #![crate_type="bin"]
      fn main() {
          println!("Hello, world");
      }
    EOF
    click_on("Run")

    within(:output, :stdout) do
      expect(page).to have_content 'Hello, world'
    end
  end

  scenario "when the crate is a library" do
    editor.set <<~EOF
      #![crate_type="lib"]
      fn main() {
          println!("Hello, world");
      }
    EOF
    click_on("Build")

    within(:output, :stderr) do
      expect(page).to have_content 'function is never used: `main`'
    end
  end

  scenario "when the crate is a library with tests" do
    editor.set <<~EOF
      #![crate_type="lib"]

      #[test]
      fn test() {
          assert_eq!(1 + 2, 3);
      }

      fn main() {
          println!("Hello, world");
      }
    EOF
    click_on("Build")

    within(:output, :stderr) do
      expect(page).to have_content 'function is never used: `main`'
    end
  end

  scenario "when tests are present" do
    editor.set <<~EOF
      #[test]
      fn awesome() {}
    EOF
    click_on("Test")

    within(:output, :stdout) do
      expect(page).to have_content 'running 1 test'
      expect(page).to have_content 'test awesome ... ok'
      expect(page).to have_content 'test result: ok'
      expect(page).to have_content '1 passed'
      expect(page).to have_content '0 failed'
    end
  end

  scenario "when tests and a main method are present" do
    editor.set <<~EOF
      #[test]
      fn awesome() {}

      fn main() {
          println!("Running in main");
      }
    EOF
    click_on("Test")

    within(:output, :stdout) do
      expect(page).to have_content 'running 1 test'
      expect(page).to_not have_content 'Running in main'
    end
  end

  scenario "when a main method is present" do
    editor.set <<~EOF
      fn main() {
          println!("Running in main");
      }
    EOF
    click_on("Run")

    within(:output, :stdout) do
      expect(page).to have_content 'Running in main'
    end
  end

  scenario "when neither tests nor a main method are present" do
    editor.set <<~EOF
      fn arbitrary_code() {
          println!("I am code");
      }
    EOF
    click_on("Build")

    within(:output, :stderr) do
      expect(page).to have_content 'function is never used: `arbitrary_code`'
    end
  end

  private

  def editor
    Editor.new(page)
  end
end

'''
'''--- tests/spec/features/backtrace_spec.rb ---
require 'spec_helper'
require 'support/editor'
require 'support/playground_actions'

RSpec.feature "A backtrace is shown for certain errors", type: :feature, js: true do
  include PlaygroundActions

  before do
    visit '/'
    editor.set(code)
  end

  context "backtraces are enabled" do
    before do
      in_advanced_options_menu { choose 'enabled' }
      within(:header) { click_on("Run") }
    end

    scenario "a backtrace is shown" do
      within(:output, :stderr) do
        expect(page).to have_content 'stack backtrace:'
        expect(page).to have_content 'rust_begin_unwind'
      end
    end

    scenario "filenames link to that line of code" do
      within(:output, :stderr) do
        expect(page).to have_link('main.rs:2')
        expect(page).to have_link('main.rs:6')
      end
    end
  end

  context "backtraces are disabled" do
    before do
      within(:header) { click_on("Run") }
    end

    scenario "the backtrace suggestion is a link" do
      within(:output, :stderr) do
        expect(page).to have_link(text: /Run with .* a backtrace/i)
      end
    end
  end

  def editor
    Editor.new(page)
  end

  def code
    <<~EOF
    fn trigger_the_problem() {
        None::<u8>.unwrap();
    }

    fn main() {
        trigger_the_problem()
    }
    EOF
  end
end

'''
'''--- tests/spec/features/compilation_modes_spec.rb ---
require 'spec_helper'
require 'support/editor'
require 'support/playground_actions'

RSpec.feature "Compiling in different modes", type: :feature, js: true do
  include PlaygroundActions

  before do
    visit '/'
    editor.set(compilation_mode_code)
  end

  scenario "compiling in debug mode" do
    in_mode_menu { click_on("Debug") }
    click_on("Run")

    within(:output, :stdout) do
      expect(page).to have_content 'Compiling in debug mode'
      expect(page).to_not have_content 'Compiling in release mode'
    end
  end

  scenario "compiling in release mode" do
    in_mode_menu { click_on("Release") }
    click_on("Run")

    within(:output, :stdout) do
      expect(page).to_not have_content 'Compiling in debug mode'
      expect(page).to have_content 'Compiling in release mode'
    end
  end

  def editor
    Editor.new(page)
  end

  def compilation_mode_code
    <<~EOF
    #[cfg(debug_assertions)]
    fn main() {
        println!("Compiling in debug mode");
    }

    #[cfg(not(debug_assertions))]
    fn main() {
        println!("Compiling in release mode");
    }
    EOF
  end
end

'''
'''--- tests/spec/features/compilation_targets_spec.rb ---
require 'spec_helper'
require 'support/editor'
require 'support/playground_actions'

RSpec.feature "Compiling to different formats", type: :feature, js: true do
  include PlaygroundActions

  before do
    visit '/'
    editor.set(code)
  end

  context "ignoring automatic primary actions" do
    before do
      code = <<~EOF
        #[test]
        fn a_test() { assert!(false); }
        fn main() { println!("Hello, world!"); }
      EOF
      editor.set(code)
    end

    scenario "choosing to run the code" do
      in_build_menu { click_on(build_button: "Run") }
      within(:output, :stdout) do
        expect(page).to have_content 'Hello, world!'
      end
    end

    scenario "choosing to build the code" do
      in_build_menu { click_on(build_button: "Build") }
      within(:output, :stderr) do
        expect(page).to have_content 'function is never used: `main`'
      end
    end

    scenario "choosing to test the code" do
      in_build_menu { click_on(build_button: "Test") }
      within(:output, :stdout) do
        expect(page).to have_content "panicked at 'assertion failed: false'"
      end
    end
  end

  context "when AT&T syntax is selected" do
    before do
      in_config_menu { choose("AT&T") }
    end

    scenario "compiling to assembly" do
      in_build_menu { click_on("assembly") }

      within(:output, :code) do
        # We demangle the symbols
        expect(page).to have_content 'playground::main:'

        expect(page).to have_content 'movq %rdi, %rax'
      end
    end
  end

  context "when Intel syntax is selected" do
    before do
      in_config_menu { choose("Intel") }
    end

    scenario "compiling to assembly" do
      in_build_menu { click_on("assembly") }

      within(:output, :code) do
        # We demangle the symbols
        expect(page).to have_content 'playground::main:'

        expect(page).to have_content 'mov rax, rdi'
      end
    end
  end

  scenario "compiling to LLVM IR" do
    in_build_menu { click_on("LLVM IR") }

    within(:output, :code) do
      expect(page).to have_content 'ModuleID'
      expect(page).to have_content 'target datalayout'
      expect(page).to have_content 'target triple'
    end
  end

  scenario "compiling to MIR" do
    in_build_menu { click_on("MIR") }

    within(:output, :result) do
      expect(page).to have_content 'bb0: {'
    end
  end

  scenario "compiling to HIR" do
    editor.set <<~EOF
      fn demo() -> impl std::fmt::Display { 42 }
    EOF

    in_build_menu { click_on("HIR") }

    within(:output, :result) do
      expect(page).to have_content 'fn demo() -> /*impl Trait*/ { 42 }'
    end
  end

  scenario "compiling to WebAssembly" do
    in_build_menu { click_on("WASM") }

    within(:output, :code) do
      expect(page).to have_content '(module'
      expect(page).to have_content '(block'
    end
  end

  context "when the code doesn't compile" do
    before { editor.set("fn main() {") }

    scenario "it shows the compilation error" do
      in_build_menu { click_on("MIR") }

      within(:output, :stderr) do
        expect(page).to have_content 'an unclosed delimiter'
      end
    end
  end

  def editor
    Editor.new(page)
  end

  def code
    <<~EOF
    fn main() {
        println!("Hello, world!");
    }
    EOF
  end
end

'''
'''--- tests/spec/features/editions_spec.rb ---
require 'spec_helper'
require 'support/editor'
require 'support/playground_actions'

RSpec.feature "Multiple Rust editions", type: :feature, js: true do
  include PlaygroundActions

  before do
    visit '/'
    editor.set(rust_edition_code)
  end

  scenario "using the 2015 edition" do
    in_advanced_options_menu { select '2015' }
    click_on("Run")

    within(:output, :stderr) do
      expect(page).to have_content 'cannot find struct, variant or union type `async` in this scope'
    end
  end

  scenario "using the 2018 edition" do
    in_advanced_options_menu { select '2018' }
    click_on("Run")

    within(:output, :stderr) do
      expect(page).to have_content "thread 'main' panicked at 'Box<Any>'"
    end
  end

  scenario "using the 2021 edition" do
    in_advanced_options_menu { select '2021' }
    click_on("Run")

    within(:output, :stderr) do
      expect(page).to have_content 'format argument must be a string literal', wait: 10
    end
  end

  def editor
    Editor.new(page)
  end

  def rust_edition_code
    <<~EOF
    #![allow(non_fmt_panic)]
    fn main() {
        panic!(async {})
    }
    EOF
  end
end

'''
'''--- tests/spec/features/editor_types_spec.rb ---
require 'spec_helper'
require 'support/playground_actions'

RSpec.feature "Editing in different editors", type: :feature, js: true do
  include PlaygroundActions

  before { visit '/' }

  scenario "using the simple editor" do
    in_config_menu { choose("simple") }

    fill_in('editor-simple', with: simple_editor_code)

    click_on("Run")

    within(:output, :stdout) do
      expect(page).to have_content 'simple editor'
    end
  end

  def simple_editor_code
    <<~EOF
    fn main() {
        println!("Using the simple editor");
    }
    EOF
  end
end

'''
'''--- tests/spec/features/highlighting_error_output_spec.rb ---
require 'spec_helper'
require 'support/editor'

RSpec.feature "Highlighting the output", type: :feature, js: true do
  before do
    visit '/'
    editor.set(code)
    within(:header) { click_on("Run") }
  end

  scenario "errors are highlighted" do
    within(:output, :stderr) do
      expect(page).to have_css '.error', text: '1 type argument but 2 type arguments were supplied'
      expect(page).to have_css '.error', text: 'aborting due to 2 previous errors'
      expect(page).to have_css '.error', text: /Could not compile `playground`/i
    end
  end

  scenario "error locations are links" do
    within(:output, :stderr) do
      expect(page).to have_link('src/main.rs')
    end
  end

  scenario "github see-issues are links" do
    within(:output, :stderr) do
      expect(page).to have_link('see issue #23416 <https://github.com/rust-lang/rust/issues/23416>', href: 'https://github.com/rust-lang/rust/issues/23416')
    end
  end

  scenario "error codes link to the error page" do
    within(:output, :stderr) do
      expect(page).to have_link('E0107', href: /error-index.html#E0107/)
    end
  end

  def editor
    Editor.new(page)
  end

  def code
    <<~EOF
    fn main() {
        drop::<u8, u8>(1);

        42: u64;
    }
    EOF
  end
end

'''
'''--- tests/spec/features/highlighting_mir_output_spec.rb ---
require 'spec_helper'
require 'support/editor'
require 'support/playground_actions'

RSpec.feature "Highlighting MIR output", type: :feature, js: true do
  include PlaygroundActions

  before do
    visit '/'
    editor.set(code)
    in_build_menu { click_on("MIR") }
  end

  scenario "error locations are links" do
    within(:output, :mir) do
      click_link('src/main.rs:4:14: 4:19', match: :first)
    end
    expect(editor).to have_highlighted_text('a + b')
  end

  def editor
    Editor.new(page)
  end

  def code
    <<~EOF
    fn main() {
        let a = 1;
        let b = 2;
        let _c = a + b;
    }
    EOF
  end
end

'''
'''--- tests/spec/features/multiple_channels_spec.rb ---
require 'spec_helper'
require 'support/editor'
require 'support/playground_actions'

RSpec.feature "Multiple Rust versions", type: :feature, js: true do
  include PlaygroundActions

  before do
    visit '/'
    editor.set(version_code)
  end

  scenario "using stable Rust" do
    in_channel_menu { click_on("Stable") }
    click_on("Run")

    within(:output, :stdout) do
      expect(page).to have_content 'rustc'
      expect(page).to_not have_content 'beta'
      expect(page).to_not have_content 'nightly'
    end
  end

  scenario "using beta Rust" do
    in_channel_menu { click_on("Beta") }
    click_on("Run")

    within(:output, :stdout) do
      expect(page).to have_content 'rustc'
      expect(page).to have_content 'beta'
      expect(page).to_not have_content 'nightly'
    end
  end

  scenario "using nightly Rust" do
    in_channel_menu { click_on("Nightly") }
    click_on("Run")

    within(:output, :stdout) do
      expect(page).to have_content 'rustc'
      expect(page).to_not have_content 'beta'
      expect(page).to have_content 'nightly'
    end
  end

  def editor
    Editor.new(page)
  end

  def version_code
    <<~EOF
    use std::process::Command;

    fn main() {
        let output = Command::new("rustc").arg("--version").output().unwrap();
        let output = String::from_utf8(output.stdout).unwrap();
        println!("{}", output);
    }
    EOF
  end
end

'''
'''--- tests/spec/features/navigation_spec.rb ---
require 'spec_helper'
require 'support/editor'
require 'support/playground_actions'

RSpec.feature "Navigating between pages", type: :feature, js: true do
  include PlaygroundActions

  RSpec::Matchers.define :be_at_url do |path, query = {}|
    match do |page|
      uri = URI::parse(page.current_url)
      expect(uri.path).to eql(path)

      query = query.map { |k, v| [k.to_s, Array(v).map(&:to_s)] }.to_h
      query_hash = CGI::parse(uri.query || '')
      expect(query_hash).to include(query)
    end

    failure_message do |page|
      "expected that #{page.current_url} would be #{path} with the query parameters #{query}"
    end
  end

  # This is kind of a test of the router library too, so if that ever
  # gets extracted, a chunk of these tests can be removed.

  scenario "Mode and channel buttons update the URL" do
    visit '/'
    expect(page).to have_content('RUN')

    editor.set("dummy")
    expect(page).to be_at_url('/')

    in_mode_menu { click_on('Release') }
    expect(page).to be_at_url('/', version: 'stable', mode: 'release')

    go_back
    expect(page).to be_at_url('/')

    in_mode_menu { click_on('Release') }
    in_channel_menu { click_on('Beta') }
    expect(page).to be_at_url('/', version: 'beta', mode: 'release')

    go_back
    expect(page).to be_at_url('/')
  end

  scenario "Navigating to help changes the URL" do
    visit '/'
    expect(page).to have_content('RUN')

    click_on 'View help'
    expect(page).to be_at_url('/help')
    expect(page).to have_content('The Rust Playground')

    go_back
    expect(page).to be_at_url('/')
    expect(page).to have_content('RUN')

    go_forward
    expect(page).to be_at_url('/help')
    expect(page).to have_content('The Rust Playground')

    click_on "Return to the playground"
    expect(page).to be_at_url('/')
    expect(page).to have_content('RUN')
  end

  scenario "Navigating from help changes the URL" do
    visit '/help'
    expect(page).to have_content('The Rust Playground')

    click_on "Return to the playground"
    expect(page).to be_at_url('/')
    expect(page).to have_content('RUN')
  end

  def editor
    Editor.new(page)
  end

  # It probably would be worth figuring out why
  # `page.go_{back,forward}` doesn't work... :-(
  # Maybe https://github.com/teampoltergeist/poltergeist/issues/624
  def go_back
    page.execute_script('window.history.go(-1);')
  end

  def go_forward
    page.execute_script('window.history.go(1);')
  end
end

'''
'''--- tests/spec/features/sharing_with_others_spec.rb ---
require 'spec_helper'
require 'support/editor'
require 'support/playground_actions'

RSpec.feature "Sharing the code with others", type: :feature, js: true do
  include PlaygroundActions

  before { visit '/' }

  # This test does more than one thing so we can avoid sending too
  # many requests to GitHub
  scenario "saving to a Gist" do
    editor.set(code)

    in_channel_menu { click_on("Nightly") }
    in_mode_menu { click_on("Release") }
    in_advanced_options_menu { select("2018") }

    within(:header) { click_on 'Share' }

    # Save the links before we navigate away
    perma_link = find_link("Permalink to the playground")[:href]
    direct_link = find_link("Direct link to the gist")[:href]
    urlo_link = find_link("Open a new thread in the Rust user forum")[:href]

    # Navigate away so we can tell that we go back to the same page
    visit 'about:blank'

    visit perma_link
    expect(page).to have_link("Permalink to the playground")
    expect(editor).to have_line 'automated test'
    expect(perma_link).to match(/mode=release/)
    expect(perma_link).to match(/version=nightly/)
    expect(perma_link).to match(/edition=2018/)

    visit direct_link
    expect(page).to have_content 'All gists'
    expect(page).to have_content 'GitHub, Inc.'

    # Need to be logged in to URLO for this link to work
    expect(urlo_link).to match(%r{https://users.rust-lang.org/new-topic})
    expect(urlo_link).to match(%{automated%20test})
  end

  def editor
    Editor.new(page)
  end

  def code
    <<~EOF
      // This code was saved by an automated test for the Rust Playground
    EOF
  end
end

'''
'''--- tests/spec/features/tools_spec.rb ---
# coding: utf-8

require 'spec_helper'
require 'support/editor'
require 'support/playground_actions'

RSpec.feature "Using third-party Rust tools", type: :feature, js: true do
  include PlaygroundActions

  before { visit '/' }

  scenario "formatting code" do
    editor.set 'fn main() { [1,2,3,4]; }'
    in_tools_menu { click_on("Rustfmt") }

    expect(editor).to have_line '[1, 2, 3, 4];'
  end

  scenario "linting code with Clippy" do
    editor.set code_with_lint_warnings
    in_tools_menu { click_on("Clippy") }

    within(:output, :stderr) do
      expect(page).to have_content 'deny(clippy::eq_op)'
      expect(page).to have_content 'warn(clippy::zero_divided_by_zero)'
    end
  end

  def code_with_lint_warnings
    <<~EOF
    use itertools::Itertools;

    fn example() {
        let a = 0.0 / 0.0;
        println!("NaN is {}", a);
    }
    EOF
  end

  scenario "sanitize code with Miri" do
    editor.set code_with_undefined_behavior
    in_tools_menu { click_on("Miri") }

    within(:output, :stderr) do
      expect(page).to have_content %r{pointer must be in-bounds at offset 1, but is outside bounds of alloc\d+ which has size 0}, wait: 10

    end
  end

  def code_with_undefined_behavior
    <<~EOF
    fn main() {
        let mut a: [u8; 0] = [];
        unsafe { *a.get_unchecked_mut(1) = 1; }
    }
    EOF
  end

  scenario "expand macros with the nightly compiler" do
    editor.set code_that_uses_macros
    in_tools_menu { click_on("Expand macros") }

    within(:output, :stdout) do
      # First-party
      expect(page).to have_content('core::fmt::Arguments::new_v1')

      # Third-party procedural macro
      expect(page).to have_content('block_on(async')

      # User-specified declarative macro
      expect(page).to have_content('fn created_by_macro() -> i32 { 42 }')
    end
  end

  def code_that_uses_macros
    <<~EOF
    macro_rules! demo {
        ($name:ident) => {
            fn $name() -> i32 { 42 }
        }
    }

    demo!(created_by_macro);

    #[tokio::main]
    async fn example() {
        println!("a value: {}", created_by_macro());
    }
    EOF
  end

  def editor
    Editor.new(page)
  end
end

'''
'''--- tests/spec/features/url_parameters_spec.rb ---
# coding: utf-8

require 'spec_helper'
require 'support/editor'
require 'support/playground_actions'

RSpec.feature "Configuration by URL parameters", type: :feature, js: true do
  include PlaygroundActions

  RSpec::Matchers.define :have_mode do |expected|
    match do |actual|
      within actual.find_button("Mode  Choose the optimization level") do |page|
        expect(page).to have_text(expected)
      end
    end
  end

  RSpec::Matchers.define :have_channel do |expected|
    match do |actual|
      within actual.find_button("Channel  Choose the Rust version") do |page|
        expect(page).to have_text(expected)
      end
    end
  end

  RSpec::Matchers.define :have_edition do |expected|
    match do |actual|
      in_advanced_options_menu do
        expect(page).to have_select(selected: expected)
      end
    end
  end

  scenario "loading from a Gist" do
    visit '/?gist=20fb1e0475f890d0fdb7864e3ad0820c'

    expect(editor).to have_line 'This source code came from a Gist'
  end

  scenario "loading from a Gist preserves the links" do
    visit '/?gist=20fb1e0475f890d0fdb7864e3ad0820c'

    within(:output) { click_on 'Share' }
    expect(page).to have_link("Permalink to the playground", href: /gist=20fb1e0475f890d0fdb7864e3ad0820c/)
  end

  scenario "loading from a Gist with a channel preserves the channel" do
    visit '/?gist=20fb1e0475f890d0fdb7864e3ad0820c&version=beta'

    expect(page).to have_channel('Beta')
    expect(page).to have_link("Permalink to the playground", href: /version=beta/)
  end

  scenario "loading from a Gist with a mode preserves the mode" do
    visit '/?gist=20fb1e0475f890d0fdb7864e3ad0820c&mode=release'

    expect(page).to have_mode('Release')
    expect(page).to have_link("Permalink to the playground", href: /mode=release/)
  end

  scenario "loading from a Gist with an edition preserves the edition" do
    visit '/?gist=20fb1e0475f890d0fdb7864e3ad0820c&edition=2018'

    expect(page).to have_edition('2018')
    expect(page).to have_link("Permalink to the playground", href: /edition=2018/)
  end

  scenario "loading from a Gist without an edition selects Rust 2015" do
    visit '/?gist=20fb1e0475f890d0fdb7864e3ad0820c'

    expect(page).to have_edition('2015')
    expect(page).to have_link("Permalink to the playground", href: /edition=2015/)
  end

  scenario "loading code directly from a parameter" do
    visit '/?code=fn%20main()%20%7B%0A%20%20%20%20println!(%22Hello%2C%20world!%22)%3B%0A%7D'

    expect(editor).to have_line 'println!("Hello, world!")'
  end

  scenario "loading code directly from a parameter without an edition selects Rust 2015" do
    visit '/?code=fn%20main()%20%7B%0A%20%20%20%20println!(%22Hello%2C%20world!%22)%3B%0A%7D'

    expect(page).to have_edition('2015')
  end

  scenario "loading with a channel" do
    visit '/?version=nightly'

    expect(page).to have_channel('Nightly')
  end

  scenario "loading with a mode" do
    visit '/?mode=release'

    expect(page).to have_mode('Release')
  end

  scenario "loading with an edition" do
    visit '/?edition=2018'

    expect(page).to have_edition('2018')
  end

  scenario "loading without code or an edition" do
    visit '/'
    expect(page).to have_edition('2018')
  end

  def editor
    Editor.new(page)
  end
end

'''
'''--- tests/spec/requests/caching_spec.rb ---
require 'net/http'
require 'spec_helper'

RSpec.feature "Caching headers are provided for assets ", type: :request do
  let(:index_uri) { URI(Capybara.app_host) }

  describe "the index page" do
    let(:one_day_s) { 24 * 60 * 60 }

    it "is cached for one day" do
      Net::HTTP.start(index_uri.host, index_uri.port) do |http|
        request = Net::HTTP::Get.new(index_uri)
        response = http.request(request)

        expect(response['cache-control']).to match(/public.*max-age.*=.*#{one_day_s}/)
        expect(response['last-modified']).to_not be_nil
      end
    end
  end

  describe "an asset" do
    let(:index_body) { Net::HTTP.get(index_uri) }
    let(:index_page) { Capybara.string(index_body) }
    let(:asset_path) { index_page.first('head script', visible: false)[:src] }
    let(:asset_uri) { URI.join(index_uri, asset_path) }
    let(:one_year_s) { 365 * 24 * 60 * 60 }

    it 'is cached for one year' do
      Net::HTTP.start(asset_uri.host, asset_uri.port) do |http|
        request = Net::HTTP::Get.new(asset_uri)
        response = http.request(request)
        expect(response['cache-control']).to match(/public.*max-age.*=.*#{one_year_s}/)
        expect(response['last-modified']).to_not be_nil
      end
    end
  end
end

'''
'''--- tests/spec/requests/cors_spec.rb ---

require 'net/http'
require 'spec_helper'

RSpec.feature "Cross-origin requests", :cors, type: :request do
  let(:evaluate_json_uri) { URI.join(Capybara.app_host, '/evaluate.json') }

  it "allows preflight requests for POSTing to evaluate.json" do
    Net::HTTP.start(evaluate_json_uri.host, evaluate_json_uri.port) do |http|
      request = Net::HTTP::Options.new(evaluate_json_uri)
      request['origin'] = 'https://rust-lang.org'
      request['access-control-request-headers'] = 'content-type'
      request['access-control-request-method'] = 'POST'

      response = http.request(request)

      expect(response['access-control-allow-headers']).to match(/content-type/i)
      expect(response['access-control-allow-methods'].split(',').map(&:strip)).to match_array([/GET/i, /POST/i])
      expect(response['access-control-allow-origin']).to eq('*')
      expect(response['access-control-max-age']).to eq('3600')
      expect(response['vary'].split(',').map(&:strip)).to match_array([/origin/i, /access-control-request-method/i, /access-control-request-headers/i])
    end
  end
end

'''
'''--- tests/spec/requests/evaluate_spec.rb ---
# coding: utf-8

require 'net/http'
require 'spec_helper'

RSpec.feature "evaluate.json endpoint", type: :request do
  let(:evaluate_json_uri) { URI.join(Capybara.app_host, '/evaluate.json') }

  let(:code) {
    <<~EOF
    fn main() {
        let greetings = ["Hello", "Hola", "Bonjour",
                         "Ciao", "", "",
                         "Cze", "Ol", "",
                         "Cho bn", "", "Hallo",
                         "Hej", "Ahoj", "",""];

        for (num, greeting) in greetings.iter().enumerate() {
            print!("{} : ", greeting);
            match num {
                0 =>  println!("This code is editable and runnable!"),
                1 =>  println!("Este cdigo es editable y ejecutable!"),
                2 =>  println!("Ce code est modifiable et excutable !"),
                3 =>  println!("Questo codice  modificabile ed eseguibile!"),
                4 =>  println!(""),
                5 =>  println!("     !"),
                6 =>  println!("Ten kod mona edytowa oraz uruchomi!"),
                7 =>  println!("Este cdigo  editvel e executvel!"),
                8 =>  println!("     !"),
                9 =>  println!("Bn c th edit v run code trc tip!"),
                10 => println!(""),
                11 => println!("Dieser Code kann bearbeitet und ausgefhrt werden!"),
                12 => println!("Den hr koden kan redigeras och kras!"),
                13 => println!("Tento kd mete upravit a spustit"),
                14 => println!("      !"),
                15 => println!(""),
                _ =>  {},
            }
        }
    }
    EOF
  }
  let(:request) {{ 'version': 'beta', 'optimize': '0', 'code': code } }
  let(:body) { JSON.generate(request) }

  it "allows evaluating compilation requests from the Rust home page" do
    Net::HTTP.start(evaluate_json_uri.host, evaluate_json_uri.port) do |http|
      request = Net::HTTP::Post.new(evaluate_json_uri)
      request.body = body

      response = http.request(request)

      body = response.body.force_encoding('UTF-8')
      expect(body).to match('Hello : This code is editable and runnable')
      expect(body).to match(' : ')
      expect(body).to match(' : ')
    end
  end
end

'''
'''--- tests/spec/spec_helper.rb ---
RSpec.configure do |config|
  config.expect_with :rspec do |expectations|
    expectations.include_chain_clauses_in_custom_matcher_descriptions = true
  end

  config.mock_with :rspec do |mocks|
    mocks.verify_partial_doubles = true
  end

  config.disable_monkey_patching!

  # We aren't really testing Ruby code, so let's assume the Ruby code
  # of the tests is good enough
  config.warnings = false

  if config.files_to_run.one?
    config.default_formatter = 'doc'
  end

  config.order = :random

  Kernel.srand config.seed
end

require 'capybara/rspec'
require 'webdrivers'
require 'capybara-screenshot/rspec'

ADDRESS = ENV.fetch('PLAYGROUND_UI_ADDRESS', '127.0.0.1')
PORT = ENV.fetch('PLAYGROUND_UI_PORT', '5000')

Capybara.register_driver :firefox do |app|
  Capybara::Selenium::Driver.load_selenium

  capture_js_log = ENV.fetch('CAPTURE_JS_LOG', 'false').casecmp?('true')
  Selenium::WebDriver.logger.level = :debug if capture_js_log

  options = {}
  options[:log_level] = :trace if capture_js_log

  browser_options = ::Selenium::WebDriver::Firefox::Options.new(options)
  browser_options.headless! if ENV.fetch('HEADLESS', 'true').casecmp?('true')
  browser_options.add_preference('devtools.console.stdout.content', true) if capture_js_log

  Capybara::Selenium::Driver.new(
    app,
    browser: :firefox,
    options: browser_options,
    clear_local_storage: true,
    clear_session_storage: true,
  )
end

Capybara.default_driver = Capybara.javascript_driver = :firefox
Capybara.app_host = "http://#{ADDRESS}:#{PORT}"
Capybara.run_server = false
Capybara.default_max_wait_time = 5
Capybara.automatic_label_click = true

Capybara::Screenshot.register_driver(:firefox) do |driver, path|
  driver.browser.save_screenshot(path)
end
Capybara.save_path = "./test-failures"

Capybara.modify_selector(:link_or_button) do
  expression_filter(:build_button) {|xpath, name| xpath[XPath.css('[data-test-id="button-menu-item__name"]').contains(name)] }
end

Capybara.add_selector(:header) do
  css { |_id| "[data-test-id = 'header']" }
end

Capybara.add_selector(:output) do
  css do |id|
    id_s = 'output'
    id_s += "-#{id}" if id
    "[data-test-id = '#{id_s}']"
  end
end

'''
'''--- tests/spec/support/editor.rb ---
class Editor
  attr_reader :page
  def initialize(page)
    @page = page
  end

  def set(text)
    page.within('.ace_text-input', visible: :any) do
      page.execute_script <<~JS
        window.rustPlayground.setCode(#{text.to_json});
      JS
    end
  end

  def has_line?(text)
    page.has_css? '.ace_line', text: text
  end

  def has_highlighted_text?(text)
    page.within('.ace_text-input', visible: :any) do
      selected = page.evaluate_script <<~JS
        (() => {
          const editor = document.querySelector('.ace_editor').env.editor;
          return editor.getSelectedText();
        })()
      JS

      selected == text
    end
  end
end

'''
'''--- tests/spec/support/playground_actions.rb ---
# coding: utf-8

module PlaygroundActions
  def in_build_menu(&block)
    in_menu("Select what to build", &block)
  end

  def in_mode_menu(&block)
    in_menu("Mode  Choose the optimization level", &block)
  end

  def in_channel_menu(&block)
    in_menu("Channel  Choose the Rust version", &block)
  end

  def in_advanced_options_menu(&block)
    in_menu("Advanced compilation flags", &block)
  end

  def in_tools_menu(&block)
    in_menu("Tools", &block)
  end

  def in_config_menu(&block)
    in_menu("Config", close: true, &block)
  end

  private

  def in_menu(button_locator, close: false)
    click_on(button_locator)
    yield
  ensure
    click_on(button_locator) if close
  end
end

'''
'''--- top-crates/Cargo.toml ---
[package]
authors = ["Jake Goulding <jake.goulding@integer32.com>"]
name = "top-crates"
version = "0.1.0"
edition = "2018"

[dependencies]
cargo = "0.54.0"
itertools = "0.10.0"
lazy_static = "1.0.0"
reqwest = { version = "0.11.0", features = ["blocking"] }
serde = "1.0.1"
serde_derive = "1.0.1"
serde_json = "1.0.0"
toml = "0.5.0"

'''
'''--- top-crates/crate-modifications.toml ---
exclusions = []

additions = [
    # Crates that the compiler recommends
    # rg 'https://crates.io/crates/[a-z_-]+' --glob '*.stderr' --only-matching --no-line-number --no-filename | sort | uniq | cut -d '/' -f 5
    "async-trait",
    "async-recursion",
]

'''
'''--- top-crates/src/main.rs ---
#![deny(rust_2018_idioms)]

use cargo::{
    core::{
        compiler::{CompileKind, CompileTarget, TargetInfo},
        package::PackageSet,
        registry::PackageRegistry,
        resolver::{self, features::RequestedFeatures, ResolveOpts},
        source::SourceMap,
        Dependency, Package, Source, SourceId, TargetKind,
    },
    sources::RegistrySource,
    util::Config,
};
use itertools::Itertools;
use lazy_static::lazy_static;
use serde::{Deserialize, Serialize};
use std::{
    collections::{BTreeMap, BTreeSet, HashSet},
    fs::File,
    io::{Read, Write},
};

const PLAYGROUND_TARGET_PLATFORM: &str = "x86_64-unknown-linux-gnu";

/// The list of crates from crates.io
#[derive(Debug, Deserialize)]
struct TopCrates {
    crates: Vec<Crate>,
}

/// A single crate from crates.io
#[derive(Debug, Deserialize)]
struct OneCrate {
    #[serde(rename = "crate")]
    krate: Crate,
}

/// The shared description of a crate
#[derive(Debug, Deserialize)]
struct Crate {
    #[serde(rename = "id")]
    name: String,
}

/// A Cargo.toml file.
#[derive(Serialize)]
struct TomlManifest {
    package: TomlPackage,
    profile: Profiles,
    #[serde(serialize_with = "toml::ser::tables_last")]
    dependencies: BTreeMap<String, DependencySpec>,
}

/// Header of Cargo.toml file.
#[derive(Serialize)]
struct TomlPackage {
    name: String,
    version: String,
    authors: Vec<String>,
    resolver: String,
}

/// A mapping of a crates name to its identifier used in source code
#[derive(Debug, Serialize)]
struct CrateInformation {
    name: String,
    version: String,
    id: String,
}

/// Hand-curated changes to the crate list
#[derive(Debug, Deserialize)]
struct Modifications {
    #[serde(default)]
    exclusions: Vec<String>,
    #[serde(default)]
    additions: BTreeSet<String>,
}

/// A profile section in a Cargo.toml file
#[derive(Serialize)]
#[serde(rename_all = "kebab-case")]
struct Profile {
    codegen_units: u32,
    incremental: bool,
}

/// Available profile types
#[derive(Serialize)]
struct Profiles {
    dev: Profile,
    release: Profile,
}

#[derive(Debug, Serialize, Clone)]
#[serde(rename_all = "kebab-case")]
struct DependencySpec {
    #[serde(skip_serializing_if = "String::is_empty")]
    package: String,
    #[serde(serialize_with = "exact_version")]
    version: String,
    #[serde(skip_serializing_if = "Vec::is_empty")]
    features: Vec<String>,
    #[serde(skip_serializing_if = "is_true")]
    default_features: bool,
}

fn exact_version<S>(version: &String, serializer: S) -> Result<S::Ok, S::Error>
where
    S: serde::Serializer,
{
    format!("={}", version).serialize(serializer)
}

fn is_true(b: &bool) -> bool {
    *b
}

impl Modifications {
    fn excluded(&self, name: &str) -> bool {
        self.exclusions.iter().any(|n| n == name)
    }
}

lazy_static! {
    static ref MODIFICATIONS: Modifications = {
        let mut f = File::open("crate-modifications.toml")
            .expect("unable to open crate modifications file");

        let mut d = Vec::new();
        f.read_to_end(&mut d)
            .expect("unable to read crate modifications file");

        toml::from_slice(&d).expect("unable to parse crate modifications file")
    };
}

fn simple_get(url: &str) -> reqwest::Result<reqwest::blocking::Response> {
    reqwest::blocking::ClientBuilder::new()
        .user_agent("Rust Playground - Top Crates Utility")
        .build()?
        .get(url)
        .send()
}

impl TopCrates {
    /// List top 100 crates by number of downloads on crates.io.
    fn download() -> TopCrates {
        let resp =
            simple_get("https://crates.io/api/v1/crates?page=1&per_page=100&sort=downloads")
                .expect("Could not fetch top crates");
        assert!(resp.status().is_success(), "Could not download top crates; HTTP status was {}", resp.status());

        serde_json::from_reader(resp).expect("Invalid JSON")
    }

    fn add_rust_cookbook_crates(&mut self) {
        let mut resp = simple_get(
            "https://raw.githubusercontent.com/rust-lang-nursery/rust-cookbook/master/Cargo.toml",
        )
        .expect("Could not fetch cookbook manifest");
        assert!(resp.status().is_success(), "Could not download cookbook; HTTP status was {}", resp.status());

        let mut content = String::new();
        resp.read_to_string(&mut content)
            .expect("could not read cookbook manifest");

        let manifest = content
            .parse::<toml::Value>()
            .expect("could not parse cookbook manifest");

        let dependencies = manifest["dependencies"]
            .as_table()
            .expect("no dependencies found for cookbook manifest");
        self.crates.extend({
            dependencies.iter().map(|(name, _)| Crate {
                name: name.to_string(),
            })
        })
    }

    /// Add crates that have been hand-picked
    fn add_curated_crates(&mut self) {
        self.crates.extend({
            MODIFICATIONS
                .additions
                .iter()
                .cloned()
                .map(|name| Crate { name })
        });
    }
}

/// Finds the features specified by the custom metadata of `pkg`.
///
/// Our custom metadata format looks like:
///
///     [package.metadata.playground]
///     default-features = true
///     features = ["std", "extra-traits"]
///     all-features = false
///
/// All fields are optional.
fn playground_metadata_features(pkg: &Package) -> Option<(Vec<String>, bool)> {
    let custom_metadata = pkg.manifest().custom_metadata()?;
    let playground_metadata = custom_metadata.get("playground")?;

    #[derive(Deserialize)]
    #[serde(default, rename_all = "kebab-case")]
    struct Metadata {
        features: Vec<String>,
        default_features: bool,
        all_features: bool,
    }

    impl Default for Metadata {
        fn default() -> Self {
            Metadata {
                features: Vec::new(),
                default_features: true,
                all_features: false,
            }
        }
    }

    let metadata = match playground_metadata.clone().try_into::<Metadata>() {
        Ok(metadata) => metadata,
        Err(err) => {
            eprintln!(
                "Failed to parse custom metadata for {} {}: {}",
                pkg.name(),
                pkg.version(),
                err
            );
            return None;
        }
    };

    // If `all-features` is set then we ignore `features`.
    let summary = pkg.summary();
    let mut enabled_features: BTreeSet<String> = if metadata.all_features {
        summary.features().keys().map(ToString::to_string).collect()
    } else {
        metadata.features.into_iter().collect()
    };

    // If not opting out of default features, remove default features from the
    // explicit features list. This avoids ongoing spurious diffs in our
    // generated Cargo.toml as default features are added to a library.
    if metadata.default_features {
        if let Some(default_feature_names) = summary.features().get("default") {
            enabled_features.remove("default");
            for feature in default_feature_names {
                enabled_features.remove(&feature.to_string());
            }
        }
    }

    if !enabled_features.is_empty() || !metadata.default_features {
        Some((
            enabled_features.into_iter().collect(),
            metadata.default_features,
        ))
    } else {
        None
    }
}

fn write_manifest(manifest: TomlManifest, path: &str) {
    let mut f = File::create(path).expect("Unable to create Cargo.toml");
    let content = toml::to_vec(&manifest).expect("Couldn't serialize TOML");
    f.write_all(&content).expect("Couldn't write Cargo.toml");
}

fn main() {
    // Setup to interact with cargo.
    let config = Config::default().expect("Unable to create default Cargo config");
    let _lock = config.acquire_package_cache_lock();
    let crates_io = SourceId::crates_io(&config).expect("Unable to create crates.io source ID");
    let mut source = RegistrySource::remote(crates_io, &HashSet::new(), &config);
    source.update().expect("Unable to update registry");

    let mut top = TopCrates::download();
    top.add_rust_cookbook_crates();
    top.add_curated_crates();

    // Find the newest (non-prerelease, non-yanked) versions of all
    // the interesting crates.
    let mut summaries = Vec::new();
    for Crate { name } in &top.crates {
        if MODIFICATIONS.excluded(name) {
            continue;
        }

        // Query the registry for a summary of this crate.
        // Usefully, this doesn't seem to include yanked versions
        let dep = Dependency::parse_no_deprecated(name, None, crates_io)
            .unwrap_or_else(|e| panic!("Unable to parse dependency for {}: {}", name, e));

        let matches = source.query_vec(&dep).unwrap_or_else(|e| {
            panic!("Unable to query registry for {}: {}", name, e);
        });

        // Find the newest non-prelease version
        let summary = matches
            .into_iter()
            .filter(|summary| !summary.version().is_prerelease())
            .max_by_key(|summary| summary.version().clone())
            .unwrap_or_else(|| panic!("Registry has no viable versions of {}", name));

        // Add a dependency on this crate.
        summaries.push((
            summary,
            ResolveOpts {
                dev_deps: false,
                features: RequestedFeatures::DepFeatures {
                    features: Default::default(),
                    uses_default_features: true,
                },
            },
        ));
    }

    // Resolve transitive dependencies.
    let mut registry = PackageRegistry::new(&config).expect("Unable to create package registry");
    registry.lock_patches();
    let try_to_use = HashSet::new();
    let resolve = resolver::resolve(&summaries, &[], &mut registry, &try_to_use, None, true)
        .expect("Unable to resolve dependencies");

    // Find crates incompatible with the playground's platform
    let mut valid_for_our_platform: BTreeSet<_> = summaries.iter().map(|(s, _)| s.package_id()).collect();

    let ct = CompileTarget::new(PLAYGROUND_TARGET_PLATFORM).expect("Unable to create a CompileTarget");
    let ck = CompileKind::Target(ct);
    let rustc = config.load_global_rustc(None).expect("Unable to load the global rustc");

    let ti = TargetInfo::new(&config, &[ck], &rustc, ck).expect("Unable to create a TargetInfo");
    let cc = ti.cfg();

    let mut to_visit = valid_for_our_platform.clone();

    while !to_visit.is_empty() {
        let mut visit_next = BTreeSet::new();

        for package_id in to_visit {
            for (dep_pkg, deps) in resolve.deps(package_id) {

                let for_this_platform = deps.iter().any(|dep| {
                    dep.platform().map_or(true, |platform| platform.matches(PLAYGROUND_TARGET_PLATFORM, cc))
                });

                if for_this_platform {
                    valid_for_our_platform.insert(dep_pkg);
                    visit_next.insert(dep_pkg);
                }
            }
        }

        to_visit = visit_next;
    }

    // Remove invalid and excluded packages that have been added due to resolution
    let package_ids: Vec<_> = resolve
        .iter()
        .filter(|pkg| valid_for_our_platform.contains(pkg))
        .filter(|pkg| !MODIFICATIONS.excluded(pkg.name().as_str()))
        .collect();

    let mut sources = SourceMap::new();
    sources.insert(Box::new(source));

    let package_set =
        PackageSet::new(&package_ids, sources, &config).expect("Unable to create a PackageSet");

    let mut packages = package_set
        .get_many(package_set.package_ids())
        .expect("Unable to download packages");

    // Sort all packages by name then version (descending), so that
    // when we group them we know we get all the same crates together
    // and the newest version first.
    packages.sort_by(|a, b| {
        a.name()
            .cmp(&b.name())
            .then(a.version().cmp(&b.version()).reverse())
    });

    let mut dependencies = BTreeMap::new();
    let mut infos = Vec::new();

    for (name, pkgs) in &packages.into_iter().group_by(|pkg| pkg.name()) {
        let mut first = true;

        for pkg in pkgs {
            let version = pkg.version();

            let crate_name = pkg
                .targets()
                .iter()
                .flat_map(|target| match target.kind() {
                    TargetKind::Lib(_) => Some(target.crate_name()),
                    _ => None,
                })
                .next()
                .unwrap_or_else(|| panic!("{} did not have a library", name));

            // We see the newest version first. Any subsequent
            // versions will have their version appended so that they
            // are uniquely named
            let exposed_name = if first {
                crate_name.clone()
            } else {
                format!(
                    "{}_{}_{}_{}",
                    crate_name, version.major, version.minor, version.patch
                )
            };

            let (features, default_features) =
                playground_metadata_features(&pkg).unwrap_or_else(|| (Vec::new(), true));

            dependencies.insert(
                exposed_name.clone(),
                DependencySpec {
                    package: name.to_string(),
                    version: version.to_string(),
                    features,
                    default_features,
                },
            );

            infos.push(CrateInformation {
                name: name.to_string(),
                version: version.to_string(),
                id: exposed_name,
            });

            first = false;
        }
    }

    // Construct playground's Cargo.toml.
    let manifest = TomlManifest {
        package: TomlPackage {
            name: "playground".to_owned(),
            version: "0.0.1".to_owned(),
            authors: vec!["The Rust Playground".to_owned()],
            resolver: "2".to_owned(),
        },
        profile: Profiles {
            dev: Profile {
                codegen_units: 1,
                incremental: false,
            },
            release: Profile {
                codegen_units: 1,
                incremental: false,
            },
        },
        dependencies,
    };

    // Write manifest file.
    let cargo_toml = "../compiler/base/Cargo.toml";
    write_manifest(manifest, cargo_toml);
    println!("wrote {}", cargo_toml);

    let path = "../compiler/base/crate-information.json";
    let mut f = File::create(path).unwrap_or_else(|e| panic!("Unable to create {}: {}", path, e));
    serde_json::to_writer_pretty(&mut f, &infos)
        .unwrap_or_else(|e| panic!("Unable to write {}: {}", path, e));
    println!("Wrote {}", path);
}

'''
'''--- ui/Cargo.toml ---
[package]
authors = ["Jake Goulding <jake.goulding@integer32.com>"]
name = "ui"
version = "0.1.0"
edition = "2018"

[features]
default = ['fork-bomb-prevention']
fork-bomb-prevention = []

[dependencies]
bodyparser = "0.8.0"
corsware = "0.2.0"
env_logger = "0.8.2"
iron = "0.6.0"
lazy_static = "1.0.0"
log = "0.4.0"
tempdir = "0.3.7"
mount = "0.4.0"
petgraph = "0.5.0"
regex = "1.0.0"
rustc-demangle = "0.1.5"
serde = "1.0"
serde_derive = "1.0"
serde_json = "1.0"
hubcaps = "0.6.0"
tokio = { version = "0.2.9", features = ["macros", "time", "process", "rt-threaded"] }
router = "0.6.0"
openssl-probe = "0.1.2"
dotenv = "0.15.0"
snafu = "0.6.0"
prometheus = "0.12.0"
strum = { version = "0.20.0", features = ["derive"] }

[dependencies.playground-middleware]
git = "https://github.com/integer32llc/playground-middleware"

'''
'''--- ui/README.md ---
## Configuration

When developing, you can place these in a [`.env`][dotenv] file on
disk in this directory.

In production, these should be set according to your deployment method
of choice.

| Key                        | Required   | Default Value     | Description                                                               |
| -------------------------- | ---------- | ----------------- | ------------------------------------------------------------------------- |
| `PLAYGROUND_UI_ROOT`       | **Yes**    |                   | The path to the HTML, CSS, and Javascript files                           |
| `PLAYGROUND_GITHUB_TOKEN`  | **Yes**    |                   | The [GitHub API token][gist] to read and write Gists                      |
| `PLAYGROUND_UI_ADDRESS`    | No         | 127.0.0.1         | The address to listen on                                                  |
| `PLAYGROUND_UI_PORT`       | No         | 5000              | The port to listen on                                                     |
| `PLAYGROUND_LOG_FILE`      | No         | access-log.csv    | The file to record accesses                                               |
| `PLAYGROUND_METRICS_TOKEN` | No         |                   | If set, will require authentication for the metrics endpoint              |
| `PLAYGROUND_CORS_ENABLED`  | No         |                   | If set, will enable CORS support                                          |
| `TMPDIR`                   | No         | system-provided   | Where compilation artifacts will be saved. Must be accessible to Docker   |

[dotenv]: https://crates.io/crates/dotenv
[gist]: https://developer.github.com/v3/gists/#authentication

### Troubleshooting

#### macOS

After launching `ui`, when you try to do any action (ex. `build`, `rustfmt`, `run` and so on), you get errors from Docker about "Mounts denied":

```
docker: Error response from daemon: Mounts denied:
The paths /var/folders/dx/l5pn75zx5v9_cwstvgwc5qyc0000gn/T/playground.6gEHdGUM6XPU/output and /var/folders/dx/l5pn75zx5v9_cwstvgwc5qyc0000gn/T/playground.6gEHdGUM6XPU/input.rs
are not shared from OS X and are not known to Docker.
You can configure shared paths from Docker -> Preferences... -> File Sharing.
See https://docs.docker.com/docker-for-mac/osxfs/#namespaces for more info.
.
time="2099-12-31T00:00:00+00:00" level=error msg="error waiting for container: context canceled"
```

To fix this issue, set the `TMPDIR` environment variable to a path that Docker can mount:

```
mkdir tmp
TMPDIR=$PWD/tmp cargo run
```

(Note: This was reported at [#480](https://github.com/integer32llc/rust-playground/issues/480))

'''
'''--- ui/frontend/.eslintrc.js ---
module.exports = {
  parser: '@typescript-eslint/parser',
  plugins: [
    '@typescript-eslint',
    'react',
    'react-hooks',
  ],
  settings: {
    react: {
      version: 'detect',
    },
  },
  extends: [
    'plugin:@typescript-eslint/recommended',
    'plugin:react/recommended',
  ],
  rules:  {
    'comma-dangle': ['error', 'always-multiline'],
    'max-len': ['error', {
      'code': 120,
    }],
    'quotes': ['error', 'single'],

    '@typescript-eslint/explicit-function-return-type': 'off',
    '@typescript-eslint/indent': ['error', 2],
    '@typescript-eslint/no-explicit-any': 'off',
    '@typescript-eslint/no-unused-vars': ['error', {
      varsIgnorePattern: "^_",
      argsIgnorePattern: "^_",
    }],
    '@typescript-eslint/no-use-before-define': ['error', {
      functions: false,
      variables: false,
    }],

    'react/jsx-boolean-value': ['error', 'never'],
    'react/jsx-tag-spacing': ['error', {
      "beforeClosing": "never",
    }],
    'react/prop-types': 'off',

    'react-hooks/rules-of-hooks': 'error',
    'react-hooks/exhaustive-deps': 'warn',

    // Temporariliy disabled to upgrade
    '@typescript-eslint/ban-types': 'off',
    '@typescript-eslint/explicit-module-boundary-types': 'off',
  },
};

'''
'''--- ui/frontend/.prettierrc.json ---
{
  "singleQuote": true
}

'''
'''--- ui/frontend/.stylelintrc.json ---
{
  "extends": [
    "stylelint-config-standard",
    "stylelint-config-css-modules",
    "stylelint-config-idiomatic-order"
  ],
  "rules": {
    "value-keyword-case": ["lower", {
      "ignoreProperties": [
        "composes"
      ]
    }]
  }
}

'''
'''--- ui/frontend/BuildMenu.module.css ---
.code {
  padding: 0 0.25em;
  background: #eee;
}

'''
'''--- ui/frontend/ButtonMenuItem.module.css ---
.container {
  composes: -menuItemFullButton from './shared.module.css';

  &:hover {
    color: var(--header-tint);
  }
}

.name {
  composes: -menuItemTitle from './shared.module.css';
  margin: 0;
}

.description {
  margin: 0;
}

'''
'''--- ui/frontend/ChannelMenu.module.css ---
.description {
  margin: 0;
}

'''
'''--- ui/frontend/ConfigElement.module.css ---
.container {
  display: flex;
  align-items: center;
}

.name {
  flex: 1;
  font-size: 13px;
}

.notDefault {
  composes: name;
  color: var(--header-tint);
  font-weight: 600;
}

.value {
  flex: 1;
}

.select {
  width: 100%;
}

.toggle {
  display: flex;

  & label {
    $border: 1px solid #bbb;

    flex: 1;
    padding: 0 1em;
    border: $border;
    border-right-width: 0;
    border-bottom-left-radius: var(--header-border-radius);
    border-top-left-radius: var(--header-border-radius);
    color: #777;
    cursor: pointer;
    font-size: 11px;
    font-weight: 600;
    text-align: center;
    text-transform: uppercase;

    & ~ label {
      border-right-width: 1px;
      border-left: $border;
      border-radius: 0 var(--header-border-radius) var(--header-border-radius) 0;
    }

    &:hover {
      background: hsla(208, 100%, 43%, 0.1);
    }
  }

  & input {
    display: none;

    &:checked + label {
      border-color: var(--header-tint);
      background: var(--header-tint);
      color: #fff;

      & ~ label {
        border-left-width: 0;
      }
    }
  }
}

'''
'''--- ui/frontend/Editor.module.css ---
.container {
  composes: -autoSize from './shared.module.css';
  position: relative;
}

.advanced {
  composes: -bodyMonospace -autoSize from './shared.module.css';
  position: absolute;
}

.simple {
  composes: advanced;
  border: none;
}

'''
'''--- ui/frontend/Header.module.css ---
.container {
  display: flex;
  padding: 1.25em 0;
  font-size: 12px;

  & button:enabled {
    cursor: pointer;
  }
}

.set {
  margin-right: 0.5em;

  &:last-child {
    margin-right: 0;
  }
}

.setChannelMode {
  margin-right: auto;
}

'''
'''--- ui/frontend/HeaderButton.module.css ---
.container {
  display: flex;
  height: 3em;
  align-items: center;
  padding: 0 1.25em;
  font-weight: 600;
  text-decoration: none;
  text-transform: uppercase;
  white-space: nowrap;
}

.bold {
  font-weight: 700;
}

.expandable {
  composes: container;
  padding-right: 1em;
}

.hasLeftIcon {
  composes: container;
  padding-left: 1em;
}

.hasRightIcon {
  composes: container;
  padding-right: 1em;
}

.iconOnly {
  composes: container;
  padding: 0 0.75em;
}

.leftIcon {
  margin-right: 0.5em;
}

.iconOnly .leftIcon {
  margin-right: 0;
}

.drop {
  margin-left: 0.75em;
}

.rightIcon {
  margin-left: 0.75em;
}

'''
'''--- ui/frontend/Help.module.css ---
.container {
  max-width: 800px;
  padding: 1em;
  margin: 1em auto;
  background-color: #fff;
  line-height: 1.5;
}

.code {
  padding: 0 0.25em;
  background: #eee;
}

.logo {
  text-align: center;
}

.header {
  &:hover::after {
    content: ' ';
  }
}

.headerLink {
  color: black;
  text-decoration: none;

  &:hover {
    text-decoration: underline;
  }
}

'''
'''--- ui/frontend/HelpExample.module.css ---
.container {
  position: relative;
}

.loadExample {
  position: absolute;
  top: 0;
  right: 0;
  border: none;
  background: rgba(255, 255, 255, 0.8);
  border-bottom-left-radius: 0.5em;
  cursor: pointer;
  opacity: 0;
  transition: all 0.5s;
  visibility: hidden;
}

.container:hover .loadExample {
  opacity: 1;
  visibility: visible;
}

'''
'''--- ui/frontend/Icon.module.css ---
.icon {
  display: block;
  fill: currentColor;
}

'''
'''--- ui/frontend/Loader.module.css ---
@keyframes loader-fade {
  0% {
    opacity: 0;
  }

  75% {
    opacity: 1;
  }
}

.dot {
  animation: loader-fade 1s;
  animation-iteration-count: infinite;
  opacity: 0;

  &:nth-child(2) {
    animation-delay: 0.2s;
  }

  &:nth-child(3) {
    animation-delay: 0.4s;
  }
}

'''
'''--- ui/frontend/MenuAside.module.css ---
.aside {
  margin: 0.25em 0 0 0;
  color: #888;
}

'''
'''--- ui/frontend/MenuGroup.module.css ---
.container {
  width: 27em;
  padding: 0.75em 1em 0 1em;
  line-height: normal;

  &:last-child {
    padding-bottom: 0.75em;
  }
}

.title {
  padding-bottom: 10px;
  border-bottom: 1px solid var(--header-main-border);
  margin: 0;
  font-size: 11px;
  font-weight: 700;
  text-transform: uppercase;
}

.content {
  padding: 1em 0.25em;
}

'''
'''--- ui/frontend/MenuItem.module.css ---
.container {
  margin-bottom: 1em;

  &:last-child {
    margin-bottom: 0;
  }
}

'''
'''--- ui/frontend/Notifications.module.css ---
$buffer: 0.5em;
$space: 0.25em;

.container {
  position: absolute;
  z-index: 10;
  right: $buffer;
  bottom: $buffer;
  left: $buffer;
  max-width: 50em;
  border: 2px solid #428bca;
  margin-right: auto;
  margin-left: auto;
  background: white;
}

.notification {
  display: flex;
}

.notificationContent {
  padding: $space 0 $space $space;
}

.close {
  composes: -buttonReset from './shared.module.css';
  padding: $space;
  background: #e1e1db;
  cursor: pointer;
}

'''
'''--- ui/frontend/Output.module.css ---
$current-tab: #f9ffff;
$background-tab: #fcfcfc; /* desaturate($current-tab, 100%); */

.container {
  display: flex;
  width: 100%;
  height: 100%;
  flex-direction: column;
}

.tabs {
  display: flex;
}

.tab {
  flex: 1 1 auto;
  border: var(--border);
  border-right: none;
  background-color: $background-tab;
  cursor: pointer;
  line-height: 1.5em;

  &:last-of-type {
    border-right: var(--border);
  }
}

.tabSelected {
  composes: tab;
  border-bottom: none;
  background-color: $current-tab;
  cursor: default;

  &:focus {
    outline: none;
  }
}

.tabClose {
  composes: tab;
  flex: 0 0 auto;
}

.body {
  overflow: scroll;
  height: 100%;
  padding: 0.5em;
  border: var(--border);
  border-top: none;
  background-color: $current-tab;
}

'''
'''--- ui/frontend/Output/Execute.module.css ---
.addMain {
  composes: -buttonAsLink from '../shared.module.css';
}

'''
'''--- ui/frontend/Output/Gist.module.css ---
$copied-duration: 1s ease-in-out;

.container {
  display: flex;
}

.button {
  composes: -buttonReset from '../shared.module.css';
  margin: 0 0.25em 0 0.5em;
  cursor: pointer;
  transition: color $copied-duration;
}

.text {
  opacity: 0;
  transition:
    visibility $copied-duration,
    opacity $copied-duration,
    color $copied-duration;
  visibility: hidden;
}

.active {
  composes: container;

  & .button {
    color: green;
    transition: color 0s;
  }

  & .text {
    color: green;
    opacity: 1;
    transition: visibility 0s, opacity 0s, color 0s;
    visibility: visible;
  }
}

'''
'''--- ui/frontend/Output/Header.module.css ---
.container {
  display: flex;
  color: var(--border-color);
  white-space: nowrap;

  &::before,
  &::after {
    flex: 1 1 auto;
    border-top: var(--border);
    margin: auto;
    content: '';
  }

  &::before {
    margin-right: 2%;
  }

  &::after {
    margin-left: 2%;
  }
}

'''
'''--- ui/frontend/Output/OutputPrism.module.css ---
.container {
  composes: -bodyMonospace from '../shared.module.css';
}

'''
'''--- ui/frontend/Output/Section.module.css ---
.code {
  composes: -bodyMonospace from '../shared.module.css';
}

'''
'''--- ui/frontend/Playground.module.css ---
.container {
  display: flex;
  height: 100vh;
  flex-direction: column;
  padding-bottom: 1em;
}

.-parent {
  composes: -autoSize from './shared.module.css';
  display: grid;
}

$plainPrimaryDimension: 1fr auto;

.plainRows {
  composes: -parent;
  grid-template-rows: $plainPrimaryDimension;
}

.plainColumns {
  composes: -parent;
  grid-template-columns: $plainPrimaryDimension;
}

.-gutter {
  display: flex;
  align-items: center;
  justify-content: center;
}

$splitPrimaryDimension: 1fr 12px 1fr;
$splitSecondaryDimension: 1fr;

.splitRows {
  composes: -parent;
  grid-template-columns: $splitSecondaryDimension;
  grid-template-rows: $splitPrimaryDimension;
}

.splitRowsGutter {
  composes: -gutter;
  cursor: row-resize;
}

.splitRowsGutterHandle {
  pointer-events: none;
  transform: rotate(90deg);
}

.splitColumns {
  composes: -parent;
  grid-template-columns: $splitPrimaryDimension;
  grid-template-rows: $splitSecondaryDimension;
}

.splitColumnsGutter {
  composes: -gutter;
  cursor: col-resize;
}

.editor {
  composes: -autoSize from './shared.module.css';
  border: 4px solid var(--border-color);
  border-radius: 4px;
}

.output {
  composes: -autoSize from './shared.module.css';
}

'''
'''--- ui/frontend/PopButton.module.css ---
$fg-color: #222;
$bg-color: white;
$arrow-size: 10px;
$vertical-border-color: #cacaca;

.container {
  z-index: 10;

  /* Prevents the popper from shifting when adding it to the DOM
   * triggers showing the scrollbars.
   * https://github.com/FezVrasta/popper.js/issues/457#issuecomment-367692177
   */
  top: 0;
  font-size: 12px;

  button:enabled {
    cursor: pointer;
  }
}

.arrow {
  border: $arrow-size solid transparent;
}

.container[data-placement^='bottom'] .arrow {
  border-top-width: 0;
  border-bottom-color: $bg-color;
  margin-top: 0;
}

.content {
  border-right: 1px solid $vertical-border-color;
  border-bottom: 1px solid var(--header-accent-border);
  border-left: 1px solid $vertical-border-color;
  margin: $arrow-size;
  background: $bg-color;
  border-radius: var(--header-border-radius);
  box-shadow: 0 1px 4px -2px rgba(0, 0, 0, 0.6), inset 0 1px 0 white;
  color: $fg-color;
}

'''
'''--- ui/frontend/SegmentedButton.module.css ---
$bg-light: #fff;
$bg-dark: #f9f9f9;

.container {
  display: flex;
  align-items: center;
  border-radius: var(--header-border-radius);
  box-shadow: 0 2px 4px -2px rgba(0, 0, 0, 0.4), inset 0 1px 0 white;
}

.button {
  composes: -buttonReset from './shared.module.css';
  border: 1px solid var(--header-main-border);
  background: linear-gradient($bg-light, $bg-dark);
  background-color: $bg-light;
  color: #444;

  &:first-child {
    border-bottom-left-radius: var(--header-border-radius);
    border-top-left-radius: var(--header-border-radius);
  }

  &:last-child {
    border-bottom-right-radius: var(--header-border-radius);
    border-top-right-radius: var(--header-border-radius);
  }

  &:not(:first-child) {
    border-left: none;
  }

  &:not(:last-child) {
    border-right: 1px solid var(--header-main-border);
  }

  &:hover {
    background: linear-gradient($bg-light, #f3f3f3);
    color: #333;
  }

  &:active {
    border-top-color: #bababa;
    border-bottom-color: #d6d6d6;
    background: linear-gradient($bg-dark, #ededed);
    box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.2);
  }
}

.buttonBuild {
  composes: button;
  border-color: hsl(15, 66.7%, 32%);
  background: var(--rust);
  color: white;

  &:not(:last-child) {
    /* Silly specificity */
    border-right-width: 0;
  }

  &:hover {
    background: var(--rust-dark);
    color: white;
  }

  &:active {
    border-top-color: var(--rust-dark);
    border-bottom-color: var(--rust-dark);
    background: var(--rust-dark);
  }
}

'''
'''--- ui/frontend/SelectableMenuItem.module.css ---
.container {
  composes: -menuItemFullButton from './shared.module.css';

  &:hover {
    color: var(--header-tint);
  }
}

.selected {
  composes: container;
  color: var(--header-tint);
  font-weight: 600;
}

.header {
  display: flex;
  align-items: center;
}

.name {
  composes: -menuItemTitle from './shared.module.css';
}

.description {
  padding-left: 2em;
}

.checkmark {
  margin-right: 0.5em;
  opacity: 0;
  transition: opacity 0.15s ease-in-out;
}

.selected .checkmark,
.selected:hover .checkmark {
  opacity: 1;
}

.container:hover .checkmark {
  color: var(--header-tint);
  opacity: 0.5;
}

'''
'''--- ui/frontend/actions.ts ---

import fetch from 'isomorphic-fetch';
import { ThunkAction as ReduxThunkAction } from 'redux-thunk';
import url from 'url';

import {
  clippyRequestSelector,
  formatRequestSelector,
  getCrateType,
  isAutoBuildSelector,
  runAsTest,
} from './selectors';
import State from './state';
import {
  AssemblyFlavor,
  Backtrace,
  Channel,
  DemangleAssembly,
  Edition,
  Editor,
  Focus,
  Mode,
  Notification,
  Orientation,
  Page,
  PairCharacters,
  PrimaryAction,
  PrimaryActionAuto,
  PrimaryActionCore,
  ProcessAssembly,
  Position,
  makePosition,
} from './types';

const routes = {
  compile: { pathname: '/compile' },
  execute: { pathname: '/execute' },
  format: { pathname: '/format' },
  clippy: { pathname: '/clippy' },
  miri: { pathname: '/miri' },
  macroExpansion: { pathname: '/macro-expansion' },
  meta: {
    crates: { pathname: '/meta/crates' },
    version: {
      stable: '/meta/version/stable',
      beta: '/meta/version/beta',
      nightly: '/meta/version/nightly',
      rustfmt: '/meta/version/rustfmt',
      clippy: '/meta/version/clippy',
      miri: '/meta/version/miri',
    },
    gist: { pathname: '/meta/gist/' },
  },
};

type ThunkAction<T = void> = ReduxThunkAction<T, State, {}, Action>;

const createAction = <T extends string, P extends {}>(type: T, props?: P) => (
  Object.assign({ type }, props)
);

export enum ActionType {
  SetPage = 'SET_PAGE',
  ChangeEditor = 'CHANGE_EDITOR',
  ChangeKeybinding = 'CHANGE_KEYBINDING',
  ChangeTheme = 'CHANGE_THEME',
  ChangePairCharacters = 'CHANGE_PAIR_CHARACTERS',
  ChangeOrientation = 'CHANGE_ORIENTATION',
  ChangeAssemblyFlavor = 'CHANGE_ASSEMBLY_FLAVOR',
  ChangePrimaryAction = 'CHANGE_PRIMARY_ACTION',
  ChangeChannel = 'CHANGE_CHANNEL',
  ChangeDemangleAssembly = 'CHANGE_DEMANGLE_ASSEMBLY',
  ChangeProcessAssembly = 'CHANGE_PROCESS_ASSEMBLY',
  ChangeMode = 'CHANGE_MODE',
  ChangeEdition = 'CHANGE_EDITION',
  ChangeBacktrace = 'CHANGE_BACKTRACE',
  ChangeFocus = 'CHANGE_FOCUS',
  ExecuteRequest = 'EXECUTE_REQUEST',
  ExecuteSucceeded = 'EXECUTE_SUCCEEDED',
  ExecuteFailed = 'EXECUTE_FAILED',
  CompileAssemblyRequest = 'COMPILE_ASSEMBLY_REQUEST',
  CompileAssemblySucceeded = 'COMPILE_ASSEMBLY_SUCCEEDED',
  CompileAssemblyFailed = 'COMPILE_ASSEMBLY_FAILED',
  CompileLlvmIrRequest = 'COMPILE_LLVM_IR_REQUEST',
  CompileLlvmIrSucceeded = 'COMPILE_LLVM_IR_SUCCEEDED',
  CompileLlvmIrFailed = 'COMPILE_LLVM_IR_FAILED',
  CompileHirRequest = 'COMPILE_HIR_REQUEST',
  CompileHirSucceeded = 'COMPILE_HIR_SUCCEEDED',
  CompileHirFailed = 'COMPILE_HIR_FAILED',
  CompileMirRequest = 'COMPILE_MIR_REQUEST',
  CompileMirSucceeded = 'COMPILE_MIR_SUCCEEDED',
  CompileMirFailed = 'COMPILE_MIR_FAILED',
  CompileWasmRequest = 'COMPILE_WASM_REQUEST',
  CompileWasmSucceeded = 'COMPILE_WASM_SUCCEEDED',
  CompileWasmFailed = 'COMPILE_WASM_FAILED',
  EditCode = 'EDIT_CODE',
  AddMainFunction = 'ADD_MAIN_FUNCTION',
  AddImport = 'ADD_IMPORT',
  EnableFeatureGate = 'ENABLE_FEATURE_GATE',
  GotoPosition = 'GOTO_POSITION',
  SelectText = 'SELECT_TEXT',
  RequestFormat = 'REQUEST_FORMAT',
  FormatSucceeded = 'FORMAT_SUCCEEDED',
  FormatFailed = 'FORMAT_FAILED',
  RequestClippy = 'REQUEST_CLIPPY',
  ClippySucceeded = 'CLIPPY_SUCCEEDED',
  ClippyFailed = 'CLIPPY_FAILED',
  RequestMiri = 'REQUEST_MIRI',
  MiriSucceeded = 'MIRI_SUCCEEDED',
  MiriFailed = 'MIRI_FAILED',
  RequestMacroExpansion = 'REQUEST_MACRO_EXPANSION',
  MacroExpansionSucceeded = 'MACRO_EXPANSION_SUCCEEDED',
  MacroExpansionFailed = 'MACRO_EXPANSION_FAILED',
  RequestGistLoad = 'REQUEST_GIST_LOAD',
  GistLoadSucceeded = 'GIST_LOAD_SUCCEEDED',
  GistLoadFailed = 'GIST_LOAD_FAILED',
  RequestGistSave = 'REQUEST_GIST_SAVE',
  GistSaveSucceeded = 'GIST_SAVE_SUCCEEDED',
  GistSaveFailed = 'GIST_SAVE_FAILED',
  RequestCratesLoad = 'REQUEST_CRATES_LOAD',
  CratesLoadSucceeded = 'CRATES_LOAD_SUCCEEDED',
  RequestVersionsLoad = 'REQUEST_VERSIONS_LOAD',
  VersionsLoadSucceeded = 'VERSIONS_LOAD_SUCCEEDED',
  NotificationSeen = 'NOTIFICATION_SEEN',
  BrowserWidthChanged = 'BROWSER_WIDTH_CHANGED',
  SplitRatioChanged = 'SPLIT_RATIO_CHANGED',
}

const setPage = (page: Page) =>
  createAction(ActionType.SetPage, { page });

export const navigateToIndex = () => setPage('index');
export const navigateToHelp = () => setPage('help');

export const changeEditor = (editor: Editor) =>
  createAction(ActionType.ChangeEditor, { editor });

export const changeKeybinding = (keybinding: string) =>
  createAction(ActionType.ChangeKeybinding, { keybinding });

export const changeTheme = (theme: string) =>
  createAction(ActionType.ChangeTheme, { theme });

export const changePairCharacters = (pairCharacters: PairCharacters) =>
  createAction(ActionType.ChangePairCharacters, { pairCharacters });

export const changeOrientation = (orientation: Orientation) =>
  createAction(ActionType.ChangeOrientation, { orientation });

export const changeAssemblyFlavor = (assemblyFlavor: AssemblyFlavor) =>
  createAction(ActionType.ChangeAssemblyFlavor, { assemblyFlavor });

export const changeDemangleAssembly = (demangleAssembly: DemangleAssembly) =>
  createAction(ActionType.ChangeDemangleAssembly, { demangleAssembly });

export const changeProcessAssembly = (processAssembly: ProcessAssembly) =>
  createAction(ActionType.ChangeProcessAssembly, { processAssembly });

const changePrimaryAction = (primaryAction: PrimaryAction) =>
  createAction(ActionType.ChangePrimaryAction, { primaryAction });

export const changeChannel = (channel: Channel) =>
  createAction(ActionType.ChangeChannel, { channel });

export const changeMode = (mode: Mode) =>
  createAction(ActionType.ChangeMode, { mode });

const changeEditionRaw = (edition: Edition) =>
  createAction(ActionType.ChangeEdition, { edition });

export const changeEdition = (edition: Edition): ThunkAction => dispatch => {
  if (edition == Edition.Rust2021) {
    dispatch(changeChannel(Channel.Nightly));
  }
  dispatch(changeEditionRaw(edition));
}

export const changeBacktrace = (backtrace: Backtrace) =>
  createAction(ActionType.ChangeBacktrace, { backtrace });

export const reExecuteWithBacktrace = (): ThunkAction => dispatch => {
  dispatch(changeBacktrace(Backtrace.Enabled));
  dispatch(performExecuteOnly());
};

export const changeFocus = (focus: Focus) =>
  createAction(ActionType.ChangeFocus, { focus });

const requestExecute = () =>
  createAction(ActionType.ExecuteRequest);

const receiveExecuteSuccess = ({ stdout, stderr, isAutoBuild }) =>
  createAction(ActionType.ExecuteSucceeded, { stdout, stderr, isAutoBuild });

const receiveExecuteFailure = ({ error, isAutoBuild }) =>
  createAction(ActionType.ExecuteFailed, { error, isAutoBuild });

function jsonGet(urlObj) {
  const urlStr = url.format(urlObj);

  return fetchJson(urlStr, {
    method: 'get',
  });
}

function jsonPost(urlObj, body) {
  const urlStr = url.format(urlObj);

  return fetchJson(urlStr, {
    method: 'post',
    body: JSON.stringify(body),
  });
}

async function fetchJson(url, args) {
  const { headers = {} } = args;
  headers['Content-Type'] = 'application/json';

  let response;
  try {
    response = await fetch(url, { ...args, headers });
  } catch (networkError) {
    // e.g. server unreachable
    throw ({
      error: `Network error: ${networkError.toString()}`,
    });
  }

  let body;
  try {
    body = await response.json();
  } catch (convertError) {
    throw ({
      error: `Response was not JSON: ${convertError.toString()}`,
    });
  }

  if (response.ok) {
    // HTTP 2xx
    return body;
  } else {
    // HTTP 4xx, 5xx (e.g. malformed JSON request)
    throw body;
  }
}

interface ExecuteRequestBody {
  channel: string;
  mode: string;
  crateType: string;
  tests: boolean;
  code: string;
  edition: string;
  backtrace: boolean;
}

const performCommonExecute = (crateType, tests): ThunkAction => (dispatch, getState) => {
  dispatch(requestExecute());

  const state = getState();
  const { code, configuration: { channel, mode, edition } } = state;
  const backtrace = state.configuration.backtrace === Backtrace.Enabled;
  const isAutoBuild = isAutoBuildSelector(state);

  const body: ExecuteRequestBody = { channel, mode, edition, crateType, tests, code, backtrace };

  return jsonPost(routes.execute, body)
    .then(json => dispatch(receiveExecuteSuccess({ ...json, isAutoBuild })))
    .catch(json => dispatch(receiveExecuteFailure({ ...json, isAutoBuild })));
};

function performAutoOnly(): ThunkAction {
  return function(dispatch, getState) {
    const state = getState();
    const crateType = getCrateType(state);
    const tests = runAsTest(state);

    return dispatch(performCommonExecute(crateType, tests));
  };
}

const performExecuteOnly = (): ThunkAction => performCommonExecute('bin', false);
const performCompileOnly = (): ThunkAction => performCommonExecute('lib', false);
const performTestOnly = (): ThunkAction => performCommonExecute('lib', true);

interface CompileRequestBody extends ExecuteRequestBody {
  target: string;
  assemblyFlavor: string;
  demangleAssembly: string;
  processAssembly: string;
}

function performCompileShow(target, { request, success, failure }): ThunkAction {
  // TODO: Check a cache
  return function(dispatch, getState) {
    dispatch(request());

    const state = getState();
    const { code, configuration: {
      channel,
      mode,
      edition,
      assemblyFlavor,
      demangleAssembly,
      processAssembly,
    } } = state;
    const crateType = getCrateType(state);
    const tests = runAsTest(state);
    const backtrace = state.configuration.backtrace === Backtrace.Enabled;
    const body: CompileRequestBody = {
      channel,
      mode,
      edition,
      crateType,
      tests,
      code,
      target,
      assemblyFlavor,
      demangleAssembly,
      processAssembly,
      backtrace,
    };

    return jsonPost(routes.compile, body)
      .then(json => dispatch(success(json)))
      .catch(json => dispatch(failure(json)));
  };
}

const requestCompileAssembly = () =>
  createAction(ActionType.CompileAssemblyRequest);

const receiveCompileAssemblySuccess = ({ code, stdout, stderr }) =>
  createAction(ActionType.CompileAssemblySucceeded, { code, stdout, stderr });

const receiveCompileAssemblyFailure = ({ error }) =>
  createAction(ActionType.CompileAssemblyFailed, { error });

const performCompileToAssemblyOnly = () =>
  performCompileShow('asm', {
    request: requestCompileAssembly,
    success: receiveCompileAssemblySuccess,
    failure: receiveCompileAssemblyFailure,
  });

const requestCompileLlvmIr = () =>
  createAction(ActionType.CompileLlvmIrRequest);

const receiveCompileLlvmIrSuccess = ({ code, stdout, stderr }) =>
  createAction(ActionType.CompileLlvmIrSucceeded, { code, stdout, stderr });

const receiveCompileLlvmIrFailure = ({ error }) =>
  createAction(ActionType.CompileLlvmIrFailed, { error });

const performCompileToLLVMOnly = () =>
  performCompileShow('llvm-ir', {
    request: requestCompileLlvmIr,
    success: receiveCompileLlvmIrSuccess,
    failure: receiveCompileLlvmIrFailure,
  });

const requestCompileHir = () =>
  createAction(ActionType.CompileHirRequest);

const receiveCompileHirSuccess = ({ code, stdout, stderr }) =>
  createAction(ActionType.CompileHirSucceeded, { code, stdout, stderr });

const receiveCompileHirFailure = ({ error }) =>
  createAction(ActionType.CompileHirFailed, { error });

const performCompileToHirOnly = () =>
  performCompileShow('hir', {
    request: requestCompileHir,
    success: receiveCompileHirSuccess,
    failure: receiveCompileHirFailure,
  });

const performCompileToNightlyHirOnly = (): ThunkAction => dispatch => {
  dispatch(changeChannel(Channel.Nightly));
  dispatch(performCompileToHirOnly());
};

const requestCompileMir = () =>
  createAction(ActionType.CompileMirRequest);

const receiveCompileMirSuccess = ({ code, stdout, stderr }) =>
  createAction(ActionType.CompileMirSucceeded, { code, stdout, stderr });

const receiveCompileMirFailure = ({ error }) =>
  createAction(ActionType.CompileMirFailed, { error });

const performCompileToMirOnly = () =>
  performCompileShow('mir', {
    request: requestCompileMir,
    success: receiveCompileMirSuccess,
    failure: receiveCompileMirFailure,
  });

const requestCompileWasm = () =>
  createAction(ActionType.CompileWasmRequest);

const receiveCompileWasmSuccess = ({ code, stdout, stderr }) =>
  createAction(ActionType.CompileWasmSucceeded, { code, stdout, stderr });

const receiveCompileWasmFailure = ({ error }) =>
  createAction(ActionType.CompileWasmFailed, { error });

const performCompileToWasm = () =>
  performCompileShow('wasm', {
    request: requestCompileWasm,
    success: receiveCompileWasmSuccess,
    failure: receiveCompileWasmFailure,
  });

const performCompileToNightlyWasmOnly = (): ThunkAction => dispatch => {
  dispatch(changeChannel(Channel.Nightly));
  dispatch(performCompileToWasm());
};

const PRIMARY_ACTIONS: { [index in PrimaryAction]: () => ThunkAction } = {
  [PrimaryActionCore.Asm]: performCompileToAssemblyOnly,
  [PrimaryActionCore.Compile]: performCompileOnly,
  [PrimaryActionCore.Execute]: performExecuteOnly,
  [PrimaryActionCore.Test]: performTestOnly,
  [PrimaryActionAuto.Auto]: performAutoOnly,
  [PrimaryActionCore.LlvmIr]: performCompileToLLVMOnly,
  [PrimaryActionCore.Hir]: performCompileToHirOnly,
  [PrimaryActionCore.Mir]: performCompileToMirOnly,
  [PrimaryActionCore.Wasm]: performCompileToNightlyWasmOnly,
};

export const performPrimaryAction = (): ThunkAction => (dispatch, getState) => {
  const state = getState();
  const primaryAction = PRIMARY_ACTIONS[state.configuration.primaryAction];
  dispatch(primaryAction());
};

const performAndSwitchPrimaryAction = (inner: () => ThunkAction, id: PrimaryAction) => (): ThunkAction => dispatch => {
  dispatch(changePrimaryAction(id));
  dispatch(inner());
};

export const performExecute =
  performAndSwitchPrimaryAction(performExecuteOnly, PrimaryActionCore.Execute);
export const performCompile =
  performAndSwitchPrimaryAction(performCompileOnly, PrimaryActionCore.Compile);
export const performTest =
  performAndSwitchPrimaryAction(performTestOnly, PrimaryActionCore.Test);
export const performCompileToAssembly =
  performAndSwitchPrimaryAction(performCompileToAssemblyOnly, PrimaryActionCore.Asm);
export const performCompileToLLVM =
  performAndSwitchPrimaryAction(performCompileToLLVMOnly, PrimaryActionCore.LlvmIr);
export const performCompileToMir =
  performAndSwitchPrimaryAction(performCompileToMirOnly, PrimaryActionCore.Mir);
export const performCompileToNightlyHir =
  performAndSwitchPrimaryAction(performCompileToNightlyHirOnly, PrimaryActionCore.Hir);
export const performCompileToNightlyWasm =
  performAndSwitchPrimaryAction(performCompileToNightlyWasmOnly, PrimaryActionCore.Wasm);

export const editCode = (code: string) =>
  createAction(ActionType.EditCode, { code });

export const addMainFunction = () =>
  createAction(ActionType.AddMainFunction);

export const addImport = (code: string) =>
  createAction(ActionType.AddImport, { code });

export const enableFeatureGate = (featureGate: string) =>
  createAction(ActionType.EnableFeatureGate, { featureGate });

export const gotoPosition = (line: string | number, column: string | number) =>
  createAction(ActionType.GotoPosition, makePosition(line, column));

export const selectText = (start: Position, end: Position) =>
  createAction(ActionType.SelectText, { start, end });

const requestFormat = () =>
  createAction(ActionType.RequestFormat);

interface FormatRequestBody {
  code: string;
  edition: string;
}

interface FormatResponseBody {
  code: string;
  stdout: string;
  stderr: string;
  error: string;
}

const receiveFormatSuccess = (body: FormatResponseBody) =>
  createAction(ActionType.FormatSucceeded, body);

const receiveFormatFailure = (body: FormatResponseBody) =>
  createAction(ActionType.FormatFailed, body);

export function performFormat(): ThunkAction {
  // TODO: Check a cache
  return function(dispatch, getState) {
    dispatch(requestFormat());

    const body: FormatRequestBody = formatRequestSelector(getState());

    return jsonPost(routes.format, body)
      .then(json => {
        if (json.success) {
          dispatch(receiveFormatSuccess(json));
        } else {
          dispatch(receiveFormatFailure(json));
        }
      })
      .catch(json => dispatch(receiveFormatFailure(json)));
  };
}

const requestClippy = () =>
  createAction(ActionType.RequestClippy);

interface ClippyRequestBody {
  code: string;
  edition: string;
  crateType: string;
}

const receiveClippySuccess = ({ stdout, stderr }) =>
  createAction(ActionType.ClippySucceeded, { stdout, stderr });

const receiveClippyFailure = ({ error }) =>
  createAction(ActionType.ClippyFailed, { error });

export function performClippy(): ThunkAction {
  // TODO: Check a cache
  return function(dispatch, getState) {
    dispatch(requestClippy());

    const body: ClippyRequestBody = clippyRequestSelector(getState());

    return jsonPost(routes.clippy, body)
      .then(json => dispatch(receiveClippySuccess(json)))
      .catch(json => dispatch(receiveClippyFailure(json)));
  };
}

const requestMiri = () =>
  createAction(ActionType.RequestMiri);

interface MiriRequestBody {
  code: string;
  edition: string;
}

const receiveMiriSuccess = ({ stdout, stderr }) =>
  createAction(ActionType.MiriSucceeded, { stdout, stderr });

const receiveMiriFailure = ({ error }) =>
  createAction(ActionType.MiriFailed, { error });

export function performMiri(): ThunkAction {
  // TODO: Check a cache
  return function(dispatch, getState) {
    dispatch(requestMiri());

    const { code, configuration: {
      edition,
    } } = getState();
    const body: MiriRequestBody = { code, edition };

    return jsonPost(routes.miri, body)
      .then(json => dispatch(receiveMiriSuccess(json)))
      .catch(json => dispatch(receiveMiriFailure(json)));
  };
}

const requestMacroExpansion = () =>
  createAction(ActionType.RequestMacroExpansion);

interface MacroExpansionRequestBody {
  code: string;
  edition: string;
}

const receiveMacroExpansionSuccess = ({ stdout, stderr }) =>
  createAction(ActionType.MacroExpansionSucceeded, { stdout, stderr });

const receiveMacroExpansionFailure = ({ error }) =>
  createAction(ActionType.MacroExpansionFailed, { error });

export function performMacroExpansion(): ThunkAction {
  // TODO: Check a cache
  return function(dispatch, getState) {
    dispatch(requestMacroExpansion());

    const { code, configuration: {
      edition,
    } } = getState();
    const body: MacroExpansionRequestBody = { code, edition };

    return jsonPost(routes.macroExpansion, body)
      .then(json => dispatch(receiveMacroExpansionSuccess(json)))
      .catch(json => dispatch(receiveMacroExpansionFailure(json)));
  };
}

interface GistSuccessProps {
  id: string;
  url: string;
  code: string;
  stdout: string;
  stderr: string;
  channel: Channel;
  mode: Mode;
  edition: Edition;
}

const requestGistLoad = () =>
  createAction(ActionType.RequestGistLoad);

const receiveGistLoadSuccess = (props: GistSuccessProps) =>
  createAction(ActionType.GistLoadSucceeded, props);

const receiveGistLoadFailure = () => // eslint-disable-line no-unused-vars
  createAction(ActionType.GistLoadFailed);

type PerformGistLoadProps =
  Pick<GistSuccessProps, Exclude<keyof GistSuccessProps, 'url' | 'code' | 'stdout' | 'stderr'>>;

export function performGistLoad({ id, channel, mode, edition }: PerformGistLoadProps): ThunkAction {
  return function(dispatch, _getState) {
    dispatch(requestGistLoad());
    const u = url.resolve(routes.meta.gist.pathname, id);
    jsonGet(u)
      .then(gist => dispatch(receiveGistLoadSuccess({ channel, mode, edition, ...gist })));
    // TODO: Failure case
  };
}

const requestGistSave = () =>
  createAction(ActionType.RequestGistSave);

const receiveGistSaveSuccess = (props: GistSuccessProps) =>
  createAction(ActionType.GistSaveSucceeded, props);

const receiveGistSaveFailure = ({ error }) => // eslint-disable-line no-unused-vars
  createAction(ActionType.GistSaveFailed, { error });

export function performGistSave(): ThunkAction {
  return function(dispatch, getState) {
    dispatch(requestGistSave());

    const { code, configuration: { channel, mode, edition }, output: { execute: { stdout, stderr } } } = getState();

    return jsonPost(routes.meta.gist, { code })
      .then(json => dispatch(receiveGistSaveSuccess({ ...json, code, stdout, stderr, channel, mode, edition })));
    // TODO: Failure case
  };
}

const requestCratesLoad = () =>
  createAction(ActionType.RequestCratesLoad);

const receiveCratesLoadSuccess = ({ crates }) =>
  createAction(ActionType.CratesLoadSucceeded, { crates });

export function performCratesLoad(): ThunkAction {
  return function(dispatch) {
    dispatch(requestCratesLoad());

    return jsonGet(routes.meta.crates)
      .then(json => dispatch(receiveCratesLoadSuccess(json)));
    // TODO: Failure case
  };
}

const requestVersionsLoad = () =>
  createAction(ActionType.RequestVersionsLoad);

const receiveVersionsLoadSuccess = ({ stable, beta, nightly, rustfmt, clippy, miri }) =>
  createAction(ActionType.VersionsLoadSucceeded, { stable, beta, nightly, rustfmt, clippy, miri });

export function performVersionsLoad(): ThunkAction {
  return function(dispatch) {
    dispatch(requestVersionsLoad());

    const stable = jsonGet(routes.meta.version.stable);
    const beta = jsonGet(routes.meta.version.beta);
    const nightly = jsonGet(routes.meta.version.nightly);
    const rustfmt = jsonGet(routes.meta.version.rustfmt);
    const clippy = jsonGet(routes.meta.version.clippy);
    const miri = jsonGet(routes.meta.version.miri);

    const all = Promise.all([stable, beta, nightly, rustfmt, clippy, miri]);

    return all
      .then(([stable, beta, nightly, rustfmt, clippy, miri]) => dispatch(receiveVersionsLoadSuccess({
        stable,
        beta,
        nightly,
        rustfmt,
        clippy,
        miri,
      })));
    // TODO: Failure case
  };
}

const notificationSeen = (notification: Notification) =>
  createAction(ActionType.NotificationSeen, { notification });

export const seenRustSurvey2020 = () => notificationSeen(Notification.RustSurvey2020);

export const browserWidthChanged = (isSmall: boolean) =>
  createAction(ActionType.BrowserWidthChanged, { isSmall });

export const splitRatioChanged = () =>
  createAction(ActionType.SplitRatioChanged);

function parseChannel(s: string): Channel | null {
  switch (s) {
    case 'stable':
      return Channel.Stable;
    case 'beta':
      return Channel.Beta;
    case 'nightly':
      return Channel.Nightly;
    default:
      return null;
  }
}

function parseMode(s: string): Mode | null {
  switch (s) {
    case 'debug':
      return Mode.Debug;
    case 'release':
      return Mode.Release;
    default:
      return null;
  }
}

function parseEdition(s: string): Edition | null {
  switch (s) {
    case '2015':
      return Edition.Rust2015;
    case '2018':
      return Edition.Rust2018;
    case '2021':
      return Edition.Rust2021;
    default:
      return null;
  }
}

export function indexPageLoad({
  code,
  gist,
  version = 'stable',
  mode: modeString = 'debug',
  edition: editionString,
}): ThunkAction {
  return function(dispatch) {
    const channel = parseChannel(version);
    const mode = parseMode(modeString);
    let edition = parseEdition(editionString);

    dispatch(navigateToIndex());

    if (code || gist) {
      // We need to ensure that any links that predate the existence
      // of editions will *forever* pick 2015. However, if we aren't
      // loading code, then allow the edition to remain the default.
      if (!edition) {
        edition = Edition.Rust2015;
      }
    }

    if (code) {
      dispatch(editCode(code));
    } else if (gist) {
      dispatch(performGistLoad({ id: gist, channel, mode, edition }));
    }

    if (channel) {
      dispatch(changeChannel(channel));
    }

    if (mode) {
      dispatch(changeMode(mode));
    }

    if (edition) {
      dispatch(changeEdition(edition));
    }
  };
}

export function helpPageLoad() {
  return navigateToHelp();
}

export function showExample(code): ThunkAction {
  return function(dispatch) {
    dispatch(navigateToIndex());
    dispatch(editCode(code));
  };
}

export type Action =
  | ReturnType<typeof setPage>
  | ReturnType<typeof changePairCharacters>
  | ReturnType<typeof changeAssemblyFlavor>
  | ReturnType<typeof changeBacktrace>
  | ReturnType<typeof changeChannel>
  | ReturnType<typeof changeDemangleAssembly>
  | ReturnType<typeof changeEditionRaw>
  | ReturnType<typeof changeEditor>
  | ReturnType<typeof changeFocus>
  | ReturnType<typeof changeKeybinding>
  | ReturnType<typeof changeMode>
  | ReturnType<typeof changeOrientation>
  | ReturnType<typeof changePrimaryAction>
  | ReturnType<typeof changeProcessAssembly>
  | ReturnType<typeof changeTheme>
  | ReturnType<typeof requestExecute>
  | ReturnType<typeof receiveExecuteSuccess>
  | ReturnType<typeof receiveExecuteFailure>
  | ReturnType<typeof requestCompileAssembly>
  | ReturnType<typeof receiveCompileAssemblySuccess>
  | ReturnType<typeof receiveCompileAssemblyFailure>
  | ReturnType<typeof requestCompileLlvmIr>
  | ReturnType<typeof receiveCompileLlvmIrSuccess>
  | ReturnType<typeof receiveCompileLlvmIrFailure>
  | ReturnType<typeof requestCompileMir>
  | ReturnType<typeof receiveCompileMirSuccess>
  | ReturnType<typeof receiveCompileMirFailure>
  | ReturnType<typeof requestCompileHir>
  | ReturnType<typeof receiveCompileHirSuccess>
  | ReturnType<typeof receiveCompileHirFailure>
  | ReturnType<typeof requestCompileWasm>
  | ReturnType<typeof receiveCompileWasmSuccess>
  | ReturnType<typeof receiveCompileWasmFailure>
  | ReturnType<typeof editCode>
  | ReturnType<typeof addMainFunction>
  | ReturnType<typeof addImport>
  | ReturnType<typeof enableFeatureGate>
  | ReturnType<typeof gotoPosition>
  | ReturnType<typeof selectText>
  | ReturnType<typeof requestFormat>
  | ReturnType<typeof receiveFormatSuccess>
  | ReturnType<typeof receiveFormatFailure>
  | ReturnType<typeof requestClippy>
  | ReturnType<typeof receiveClippySuccess>
  | ReturnType<typeof receiveClippyFailure>
  | ReturnType<typeof requestMiri>
  | ReturnType<typeof receiveMiriSuccess>
  | ReturnType<typeof receiveMiriFailure>
  | ReturnType<typeof requestMacroExpansion>
  | ReturnType<typeof receiveMacroExpansionSuccess>
  | ReturnType<typeof receiveMacroExpansionFailure>
  | ReturnType<typeof requestGistLoad>
  | ReturnType<typeof receiveGistLoadSuccess>
  | ReturnType<typeof receiveGistLoadFailure>
  | ReturnType<typeof requestGistSave>
  | ReturnType<typeof receiveGistSaveSuccess>
  | ReturnType<typeof receiveGistSaveFailure>
  | ReturnType<typeof requestCratesLoad>
  | ReturnType<typeof receiveCratesLoadSuccess>
  | ReturnType<typeof requestVersionsLoad>
  | ReturnType<typeof receiveVersionsLoadSuccess>
  | ReturnType<typeof notificationSeen>
  | ReturnType<typeof browserWidthChanged>
  | ReturnType<typeof splitRatioChanged>
  ;

'''
'''--- ui/frontend/advanced-editor.ts ---
/// This file will be a separate bundle and loaded async.

import ace from 'ace-builds';
import 'ace-builds/src-noconflict/ext-language_tools';
import 'ace-builds/src-noconflict/ext-searchbox';
import 'ace-builds/src-noconflict/mode-rust';

export default { ace };

'''
'''--- ui/frontend/assets/integer32-logo.svg ---
<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<svg xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#" xmlns="http://www.w3.org/2000/svg" enable-background="new 0 0 960 560" xml:space="preserve" viewBox="0 0 289.20001 48.700001" height="48.7" width="289.2" version="1.1" y="0px" x="0px" xmlns:cc="http://creativecommons.org/ns#" xmlns:dc="http://purl.org/dc/elements/1.1/"><metadata><rdf:RDF><cc:Work rdf:about=""><dc:format>image/svg+xml</dc:format><dc:type rdf:resource="http://purl.org/dc/dcmitype/StillImage"/></cc:Work></rdf:RDF></metadata><polygon points="336.6 257 376.7 257 376.7 292.3 356.6 300.7 336.6 292.3" fill="#354c9f" transform="translate(-334.9,-255.6)"/><polygon points="356.2 300.7 362.9 298.1 361.9 284.9 355.2 266.7 348.1 257.8 337.3 258.4 337.8 276.4 342.6 294.8" fill="#a7d2ee" transform="translate(-334.9,-255.6)"/><path fill="#fff" d="m38.8 1.3h-7.7c-5.1 2.8-10.5 11.9-10.5 11.9l3.3 6.6c0.2-0.4 0.3 1 0.5 0.6l2.9 10.3c5-14.2 13.9-16.6 13.9-16.6l0.3-10.7c-0.8 0.4-1.9-2.5-2.7-2.1z"/><path fill="#354c9f" d="m8.4 38.7h-2.4c0-11.9-5.5-16.9-5.6-17l1.6-1.8c0.3 0.2 6.4 5.9 6.4 18.8z"/><path fill="#354d9f" d="m0 0v38.1l21.7 9.2 21.7-9.2v-38.1h-43.4zm26.7 41.5-4 1.7c0.6-20.1-10.4-33.9-16.3-39.8h5c2.6 2.6 7.8 8.4 11.4 17.1 2.5 5.7 4.1 12.8 3.9 21zm-23.3-37.8c5.2 4.7 17.5 18.2 16.7 39.2l-4.6-1.9c-0.1-17.7-8.6-27.2-12.1-30.4v-6.9zm26.6-0.3h7.3c-6.6 4.7-10.9 10.6-13 14.1-0.8-1.7-1.6-3.3-2.4-4.8 0.5-1.3 2.7-5.5 8.1-9.3zm-9.7 6.7c-1.9-2.9-3.8-5.1-5.3-6.8h10.9c-3.1 2.6-4.7 5.1-5.6 6.8zm5.2 10.2c1.1-2.1 5.6-10 14.6-15.9v8c-6.4 4.4-10.6 11.1-12.6 14.9-0.5-2.6-1.2-4.9-2-7zm-22.1-6.2c3.6 3.9 9.3 12.2 9.6 25.9l-9.6-4.1v-21.8zm25.2 26.6c0.2-3.3 0-6.4-0.3-9.4 0-0.1 4.1-10 11.9-16v20.5l-11.6 4.9z"/><g transform="translate(-334.9,-255.6)"><g fill="#3e4555"><path d="m394.2 261.7c-0.7-0.7-1-1.5-1-2.5s0.3-1.8 1-2.5 1.5-1 2.5-1 1.8 0.3 2.5 1 1 1.5 1 2.5-0.3 1.8-1 2.5-1.5 1-2.5 1-1.8-0.3-2.5-1zm5.2 31.8h-5.6v-26.5h5.6v26.5z"/><path d="m411.5 279.2v14.4h-5.6v-26.6h5.6v4.8c0.9-1.6 2.1-2.9 3.7-3.8s3.3-1.4 5.1-1.4c3 0 5.4 0.9 7.3 2.7 1.8 1.8 2.8 4.5 2.8 7.9v16.3h-5.6v-14.5c0-4.9-2-7.3-6.1-7.3-1.9 0-3.6 0.6-5 1.9-1.5 1.2-2.2 3.1-2.2 5.6z"/><path d="m442.2 271.5v13.5c0 1.3 0.3 2.3 1 3s1.6 1.1 2.8 1.1 2.3-0.6 3.4-1.7l2.3 3.9c-2 1.8-4.1 2.6-6.5 2.6s-4.4-0.8-6.1-2.5c-1.7-1.6-2.5-3.9-2.5-6.7v-13.3h-3.3v-4.4h3.3v-8.3h5.6v8.3h7v4.5h-7z"/><path d="m479.3 282.7h-20.8c0.1 1.9 1 3.5 2.6 4.7s3.5 1.8 5.6 1.8c3.3 0 5.9-1 7.6-3.1l3.2 3.5c-2.9 3-6.6 4.4-11.2 4.4-3.7 0-6.9-1.2-9.5-3.7s-3.9-5.8-3.9-10 1.3-7.5 4-10 5.8-3.7 9.4-3.7 6.7 1.1 9.2 3.3 3.8 5.2 3.8 9v3.8zm-20.8-4.4h15.2c0-2.2-0.7-3.9-2.1-5.1s-3.1-1.8-5.2-1.8c-2 0-3.9 0.6-5.5 1.9-1.6 1.2-2.4 2.9-2.4 5z"/><path d="m508.7 267v23.2c0 4.7-1.3 8.2-3.8 10.6s-5.8 3.5-9.8 3.5-7.6-1.2-10.8-3.7l2.6-4.2c2.6 2 5.2 2.9 7.9 2.9s4.7-0.7 6.3-2c1.5-1.4 2.3-3.5 2.3-6.5v-3.4c-0.8 1.6-2 2.8-3.6 3.7s-3.3 1.4-5.2 1.4c-3.5 0-6.4-1.2-8.7-3.7s-3.4-5.5-3.4-9.2 1.1-6.7 3.4-9.2 5.2-3.7 8.7-3.7 6.4 1.4 8.6 4.3v-4h5.5zm-20.7 12.2c0 2.2 0.7 4.1 2 5.6 1.3 1.6 3.2 2.4 5.4 2.4 2.3 0 4.1-0.8 5.5-2.3s2.1-3.4 2.1-5.7-0.7-4.2-2.1-5.8-3.3-2.4-5.5-2.4c-2.3 0-4.1 0.8-5.4 2.4-1.3 1.7-2 3.7-2 5.8z"/><path d="m538.8 282.7h-20.8c0.1 1.9 1 3.5 2.6 4.7s3.5 1.8 5.6 1.8c3.3 0 5.9-1 7.6-3.1l3.2 3.5c-2.9 3-6.6 4.4-11.2 4.4-3.7 0-6.9-1.2-9.5-3.7s-3.9-5.8-3.9-10 1.3-7.5 4-10 5.8-3.7 9.4-3.7 6.7 1.1 9.2 3.3 3.8 5.2 3.8 9v3.8zm-20.8-4.4h15.2c0-2.2-0.7-3.9-2.1-5.1s-3.1-1.8-5.2-1.8c-2 0-3.9 0.6-5.5 1.9-1.6 1.2-2.4 2.9-2.4 5z"/><path d="m557 272.2c-2.8 0-4.8 0.9-6.2 2.7s-2.1 4.2-2.1 7.2v11.4h-5.6v-26.5h5.6v5.3c0.9-1.7 2.1-3 3.7-4.1s3.2-1.6 4.9-1.6l0.1 5.6h-0.4z"/><path d="m574 263.9v-5.2h20.4v4.6l-8.4 9.4c3.2 0.1 5.7 1.1 7.5 3s2.7 4.2 2.7 6.9c0 3.6-1.2 6.4-3.6 8.4s-5.5 3-9.3 3-7.5-1.2-11.1-3.6l2.5-4.7c2.9 2 5.9 3 9 3 2 0 3.7-0.5 5-1.4s2-2.3 2-4.1-0.7-3.2-2.2-4.3-3.5-1.6-6.1-1.6c-1.3 0-2.5 0.2-3.7 0.5v-4.5l8.1-9.4h-12.8z"/><path d="m615.7 272.3c1-1.4 1.5-2.7 1.5-4.1s-0.5-2.6-1.6-3.6-2.4-1.5-4-1.5c-2.9 0-5.2 1.5-7.1 4.4l-4.7-2.7c1.5-2.3 3.2-4 5.1-5.2 1.8-1.2 4.2-1.7 7.1-1.7s5.5 0.9 7.7 2.8c2.2 1.8 3.3 4.4 3.3 7.6 0 1.8-0.5 3.5-1.4 5.1s-2.6 3.7-5.1 6.3l-8.2 8.3h15.8v5.6h-23.9v-5l10.6-10.6c2.2-2.5 3.9-4.4 4.9-5.7z"/></g></g></svg>

'''
'''--- ui/frontend/declarations.d.ts ---
declare module '*.module.css' {
  const classes: { [key: string]: string };
  export default classes;
}

declare module 'prismjs/themes/*.css' {
  const content: string;
  export default content;
}

declare module '*.svg' {
  const content: string;
  export default content;
}

declare const ACE_KEYBINDINGS: string[];
declare const ACE_THEMES: string[];

interface Window {
  __REDUX_DEVTOOLS_EXTENSION_COMPOSE__: any;
  rustPlayground: {
    setCode(code: string): void;
  };
}

'''
'''--- ui/frontend/highlighting.ts ---
import Prism from 'prismjs';
import { makePosition } from './types';

export function configureRustErrors({
  enableFeatureGate,
  getChannel,
  gotoPosition,
  selectText,
  addImport,
  reExecuteWithBacktrace,
}) {
  Prism.languages.rust_errors = {
    'warning': {
      pattern: /^warning(\[E\d+\])?:.*$/m,
      inside: {
        'error-explanation': /\[E\d+\]/,
      },
    },
    'error': {
      pattern: /^error(\[E\d+\])?:.*$/m,
      inside: {
        'error-explanation': /\[E\d+\]/,
      },
    },
    'note': {
      pattern: /^\s*=\s*note:.*$/m,
      inside: {
        'see-issue': /see .*rust-lang\/rust\/issues\/\d+>/,
      },
    },
    'error-location': /-->\s+(\/playground\/)?src\/.*\n/,
    'import-suggestion-outer': {
      pattern: /\|\s+use\s+([^;]+);/,
      inside: {
        'import-suggestion': /use\s+.*/,
      },
    },
    'rust-errors-help': {
      pattern: /help:.*\n/,
      inside: {
        'feature-gate': /add `#\!\[feature\(.+?\)\]`/,
      },
    },
    'backtrace': {
      pattern: /at \.\/src\/.*\n/,
      inside: {
        'backtrace-location': /src\/main.rs:(\d+)/,
      },
    },
    'backtrace-enable': /Run with `RUST_BACKTRACE=1` environment variable to display a backtrace/i,
  };

  Prism.languages.rust_mir = {
    'mir-source': /src\/[A-Za-z0-9_.\-]+\.rs:\d+:\d+: \d+:\d+/,
  }

  Prism.hooks.add('wrap', env => {
    if (env.type === 'error-explanation') {
      const errorMatch = /E\d+/.exec(env.content);
      const [errorCode] = errorMatch;
      env.tag = 'a';
      env.attributes.href = `https://doc.rust-lang.org/${getChannel()}/error-index.html#${errorCode}`;
      env.attributes.target = '_blank';
    }
    if (env.type === 'see-issue') {
      const errorMatch = /\d+/.exec(env.content);
      const [errorCode] = errorMatch;
      env.tag = 'a';
      env.attributes.href = `https://github.com/rust-lang/rust/issues/${errorCode}`;
      env.attributes.target = '_blank';
    }
    if (env.type === 'error-location') {
      let line;
      let col;
      const errorMatchFull = /(\d+):(\d+)/.exec(env.content);
      if (errorMatchFull) {
        line = errorMatchFull[1];
        col = errorMatchFull[2];
      } else {
        const errorMatchShort = /:(\d+)/.exec(env.content);
        line = errorMatchShort[1];
        col = '1';
      }
      env.tag = 'a';
      env.attributes.href = '#';
      env.attributes['data-line'] = line;
      env.attributes['data-col'] = col;
    }
    if (env.type === 'import-suggestion') {
      env.tag = 'a';
      env.attributes.href = '#';
      env.attributes['data-suggestion'] = env.content;
    }
    if (env.type === 'feature-gate') {
      const [_, featureGate] = /feature\((.*?)\)/.exec(env.content);
      env.tag = 'a';
      env.attributes.href = '#';
      env.attributes['data-feature-gate'] = featureGate;
    }
    if (env.type === 'backtrace-enable') {
      env.tag = 'a';
      env.attributes.href = '#';
      env.attributes['data-backtrace-enable'] = 'true';
    }
    if (env.type === 'backtrace-location') {
      const errorMatch = /:(\d+)/.exec(env.content);
      const [_, line] = errorMatch;
      env.tag = 'a';
      env.attributes.href = '#';
      env.attributes['data-line'] = line;
      env.attributes['data-col'] = '1';
    }
    if (env.type === 'mir-source') {
      const lineMatch = /(\d+):(\d+): (\d+):(\d+)/.exec(env.content);
      const [_, startLine, startCol, endLine, endCol] = lineMatch;
      env.tag = 'a';
      env.attributes.href = '#';
      env.attributes['data-start-line'] = startLine;
      env.attributes['data-start-col'] = startCol;
      env.attributes['data-end-line'] = endLine;
      env.attributes['data-end-col'] = endCol;
    }
  });

  Prism.hooks.add('after-highlight', env => {
    const links = env.element.querySelectorAll('.error-location, .backtrace-location');
    Array.from(links).forEach((link: HTMLAnchorElement) => {
      const { line, col } = link.dataset;
      link.onclick = e => {
        e.preventDefault();
        gotoPosition(line, col);
      };
    });

    const importSuggestions = env.element.querySelectorAll('.import-suggestion');
    Array.from(importSuggestions).forEach((link: HTMLAnchorElement) => {
      const { suggestion } = link.dataset;
      link.onclick = (e) => {
        e.preventDefault();
        addImport(suggestion + '\n');
      };
    });

    const featureGateEnablers = env.element.querySelectorAll('.feature-gate');
    Array.from(featureGateEnablers).forEach((link: HTMLAnchorElement) => {
      link.onclick = e => {
        e.preventDefault();
        enableFeatureGate(link.dataset.featureGate);
        gotoPosition(1, 1);
      };
    });

    const backtraceEnablers = env.element.querySelectorAll('.backtrace-enable');
    Array.from(backtraceEnablers).forEach((link: HTMLAnchorElement) => {
      link.onclick = e => {
        e.preventDefault();
        reExecuteWithBacktrace();
      };
    });

    const mirSourceLinks = env.element.querySelectorAll('.mir-source');
    Array.from(mirSourceLinks).forEach((link: HTMLAnchorElement) => {
      const { startLine, startCol, endLine, endCol } = link.dataset;
      const start = makePosition(startLine, startCol);
      const end = makePosition(endLine, endCol);

      link.onclick = e => {
        e.preventDefault();
        selectText(start, end);
      };
    });
  });
}

'''
'''--- ui/frontend/index.module.css ---
:root {
  --primary-font: 'Open Sans', sans-serif;
  --rust: #a42;
  --rust-dark: #80331a;
  --border-color: #bbb;
  --border: 1px solid var(--border-color);
  --header-main-border: #dedede;
  --header-transition: 0.2s ease-in-out;
  --header-tint: #428bca;
  --header-border-radius: 4px;
  --header-accent-border: #bdbdbd;
}

/* Modify normalized styles */
button,
input,
optgroup,
select,
textarea {
  font-family: var(--primary-font);
}

html {
  box-sizing: border-box;
}

*,
*::before,
*::after {
  box-sizing: inherit;
}

body {
  padding: 0 1em;
  background-color: #e1e1db;
  font-family: var(--primary-font);
}

:global(.language-rust_errors) {
  & :global(.warning) {
    color: #f79a06;
  }

  & :global(.error) {
    color: #bf1b1b;
  }
}

'''
'''--- ui/frontend/local_storage.spec.ts ---
import { deserialize } from './local_storage';

describe('restoring saved state', () => {
  const easyDeserialize = (state: any) => {
    if (typeof state === 'string' || state === undefined) {
      return deserialize(state);
    } else {
      state.version = 1;
      return deserialize(JSON.stringify(state));
    }
  };

  test('undefined state stays that way', () => {
    expect(easyDeserialize(undefined)).toBeUndefined();
  });

  test('unknown serialized version resets to defaults', () => {
    expect(easyDeserialize('{"version":42}')).toBeUndefined();
  });

  test('serialized data is kept', () => {
    const parsed = easyDeserialize({
      configuration: { theme: 'xcode' },
      code: 'not default code',
      notifications: { seenRustSurvey2018: true },
    });

    expect(parsed.configuration.theme).toEqual('xcode');
    expect(parsed.code).toEqual('not default code');
    expect(parsed.notifications.seenRustSurvey2018).toBe(true);
  });
});

'''
'''--- ui/frontend/local_storage.ts ---
// This is used to store "long-term" values; those which we want to be
// preserved between completely independent sessions of the
// playground.

import State from './state';
import storage from './storage';

const CURRENT_VERSION = 1;

export function serialize(state: State) {
  return JSON.stringify({
    version: CURRENT_VERSION,
    configuration: {
      editor: state.configuration.editor,
      keybinding: state.configuration.keybinding,
      theme: state.configuration.theme,
      pairCharacters: state.configuration.pairCharacters,
      orientation: state.configuration.orientation,
      assemblyFlavor: state.configuration.assemblyFlavor,
      demangleAssembly: state.configuration.demangleAssembly,
      processAssembly: state.configuration.processAssembly,
    },
    code: state.code,
    notifications: state.notifications,
  });
}

export function deserialize(savedState) {
  if (!savedState) { return undefined; }
  const parsedState = JSON.parse(savedState);
  if (!parsedState) { return undefined; }
  if (parsedState.version !== CURRENT_VERSION) { return undefined; }

  // This assumes that the keys we serialize with match the keys in the
  // live state. If that's no longer true, an additional renaming step
  // needs to be added.
  delete parsedState.version;
  return parsedState;
}

export default storage({
  storageFactory: () => localStorage,
  serialize,
  deserialize,
});

'''
'''--- ui/frontend/package.json ---
{
  "name": "ui",
  "version": "0.0.1",
  "description": "UI for the Rust playground",
  "main": "index.js",
  "dependencies": {
    "@popperjs/core": "^2.4.0",
    "ace-builds": "^1.4.4",
    "common-tags": "^1.8.0",
    "core-js": "^3.1.3",
    "history": "^4.6.0",
    "isomorphic-fetch": "^3.0.0",
    "lodash": "^4.17.0",
    "prismjs": "^1.6.0",
    "qs": "^6.4.0",
    "react": "^17.0.1",
    "react-copy-to-clipboard": "^5.0.1",
    "react-dom": "^17.0.1",
    "react-popper": "^2.0.0",
    "react-portal": "^4.1.4",
    "react-prism": "^4.0.0",
    "react-redux": "^7.0.0",
    "react-shadow": "^19.0.2",
    "react-split-grid": "^1.0.3",
    "redux": "^4.0.0",
    "redux-thunk": "^2.1.0",
    "regenerator-runtime": "^0.13.2",
    "reselect": "^4.0.0",
    "route-parser": "^0.0.5",
    "url": "^0.11.0"
  },
  "devDependencies": {
    "@babel/core": "^7.0.0",
    "@babel/plugin-proposal-class-properties": "^7.0.0",
    "@babel/plugin-proposal-object-rest-spread": "^7.0.0",
    "@babel/plugin-syntax-dynamic-import": "^7.0.0",
    "@babel/preset-env": "^7.0.0",
    "@babel/preset-react": "^7.0.0",
    "@types/jest": "^26.0.0",
    "@types/lodash": "^4.14.118",
    "@types/react": "^17.0.2",
    "@types/react-dom": "^17.0.1",
    "@types/react-redux": "^7.1.2",
    "@typescript-eslint/eslint-plugin": "^4.16.1",
    "@typescript-eslint/parser": "^4.16.1",
    "autoprefixer": "^10.2.4",
    "babel-loader": "^8.0.0",
    "babel-plugin-lodash": "^3.3.4",
    "basename": "^0.1.2",
    "compression-webpack-plugin": "^7.1.2",
    "copy-webpack-plugin": "^8.0.0",
    "css-loader": "^5.1.1",
    "eslint": "^7.4.0",
    "eslint-plugin-react": "^7.14.3",
    "eslint-plugin-react-hooks": "^4.0.0",
    "glob": "^7.0.5",
    "html-webpack-plugin": "^5.2.0",
    "jest": "^26.0.0",
    "json-loader": "^0.5.4",
    "mini-css-extract-plugin": "^1.3.9",
    "normalize.css": "^8.0.0",
    "postcss": "^8.2.7",
    "postcss-loader": "^5.0.0",
    "postcss-nesting": "^7.0.1",
    "postcss-simple-vars": "^6.0.3",
    "prettier": "2.2.1",
    "style-loader": "^2.0.0",
    "stylelint": "^13.12.0",
    "stylelint-config-css-modules": "^2.2.0",
    "stylelint-config-idiomatic-order": "^8.1.0",
    "stylelint-config-standard": "^21.0.0",
    "ts-jest": "^26.0.0",
    "ts-loader": "^8.0.0",
    "typescript": "^4.2.2",
    "typescript-plugin-css-modules": "^3.2.0",
    "webpack": "^5.24.3",
    "webpack-cli": "^4.5.0"
  },
  "engines": {
    "node": "^14.15.1"
  },
  "scripts": {
    "test": "jest",
    "test:lint": "eslint '**/*.tsx' '**/*.ts'",
    "test:lint:fix": "eslint --fix '**/*.tsx' '**/*.ts'",
    "test:style": "yarn run test:style:prettier && yarn run test:style:stylelint",
    "test:style:fix": "yarn run test:style:prettier:fix && yarn run test:style:stylelint:fix",
    "test:style:prettier": "prettier --check .",
    "test:style:prettier:fix": "prettier --write .",
    "test:style:stylelint": "stylelint '**/*.css'",
    "test:style:stylelint:fix": "stylelint --fix '**/*.css'",
    "build": "webpack --progress --color --mode development",
    "build:production": "webpack --progress --color --mode production",
    "watch": "yarn run build --watch"
  },
  "jest": {
    "transform": {
      "^.+\\.tsx?$": "ts-jest"
    },
    "testRegex": "(\\.|/)(test|spec)\\.tsx?$",
    "moduleFileExtensions": [
      "ts",
      "tsx",
      "js",
      "jsx"
    ]
  },
  "author": "",
  "license": "MIT"
}

'''
'''--- ui/frontend/postcss.config.js ---
module.exports = {
  plugins: [
    require('postcss-simple-vars'),
    require('postcss-nesting'),
    require('autoprefixer')(),
  ]
};

'''
'''--- ui/frontend/reducers/browser.ts ---
import { Action, ActionType } from '../actions';

const DEFAULT: State = {
  isSmall: true,
  ratioGeneration: 0,
};

export type State = {
  isSmall: boolean;
  ratioGeneration: number;
};

export default function code(state = DEFAULT, action: Action): State {
  switch (action.type) {
    case ActionType.BrowserWidthChanged:
      return { ...state, isSmall: action.isSmall };
    case ActionType.SplitRatioChanged: {
      let { ratioGeneration } = state;
      ratioGeneration++;
      return { ...state, ratioGeneration };
    }

    default:
      return state;
  }
}

'''
'''--- ui/frontend/reducers/code.ts ---
import { Action, ActionType } from '../actions';

const DEFAULT: State = `fn main() {
    println!("Hello, world!");
}`;

export type State = string;

export default function code(state = DEFAULT, action: Action): State {
  switch (action.type) {
    case ActionType.RequestGistLoad:
      return '';
    case ActionType.GistLoadSucceeded:
      return action.code;

    case ActionType.EditCode:
      return action.code;

    case ActionType.AddMainFunction:
      return `${state}\n\n${DEFAULT}`;

    case ActionType.AddImport:
      return action.code + state;

    case ActionType.EnableFeatureGate:
      return `#![feature(${action.featureGate})]\n${state}`;

    case ActionType.FormatSucceeded:
      return action.code;

    default:
      return state;
  }
}

'''
'''--- ui/frontend/reducers/configuration.ts ---
import { Action, ActionType } from '../actions';
import {
  AssemblyFlavor,
  Backtrace,
  Channel,
  DemangleAssembly,
  Edition,
  Editor,
  Mode,
  Orientation,
  PairCharacters,
  PrimaryAction,
  PrimaryActionAuto,
  ProcessAssembly,
} from '../types';

export interface State {
  editor: Editor;
  keybinding: string;
  theme: string;
  pairCharacters: PairCharacters;
  orientation: Orientation;
  assemblyFlavor: AssemblyFlavor;
  demangleAssembly: DemangleAssembly;
  processAssembly: ProcessAssembly;
  primaryAction: PrimaryAction;
  channel: Channel;
  mode: Mode;
  edition: Edition;
  backtrace: Backtrace;
}

const DEFAULT: State = {
  editor: Editor.Advanced,
  keybinding: 'ace',
  theme: 'github',
  pairCharacters: PairCharacters.Enabled,
  orientation: Orientation.Automatic,
  assemblyFlavor: AssemblyFlavor.Att,
  demangleAssembly: DemangleAssembly.Demangle,
  processAssembly: ProcessAssembly.Filter,
  primaryAction: PrimaryActionAuto.Auto,
  channel: Channel.Stable,
  mode: Mode.Debug,
  edition: Edition.Rust2018,
  backtrace: Backtrace.Disabled,
};

export default function configuration(state = DEFAULT, action: Action): State {
  switch (action.type) {
    case ActionType.ChangeEditor:
      return { ...state, editor: action.editor };
    case ActionType.ChangeKeybinding:
      return { ...state, keybinding: action.keybinding };
    case ActionType.ChangeTheme:
      return { ...state, theme: action.theme };
    case ActionType.ChangePairCharacters:
      return { ...state, pairCharacters: action.pairCharacters };
    case ActionType.ChangeOrientation:
      return { ...state, orientation: action.orientation };
    case ActionType.ChangeAssemblyFlavor:
      return { ...state, assemblyFlavor: action.assemblyFlavor };
    case ActionType.ChangeDemangleAssembly:
      return { ...state, demangleAssembly: action.demangleAssembly };
    case ActionType.ChangeProcessAssembly:
      return { ...state, processAssembly: action.processAssembly };
    case ActionType.ChangePrimaryAction:
      return { ...state, primaryAction: action.primaryAction };
    case ActionType.ChangeChannel: {
      return { ...state, channel: action.channel };
    }
    case ActionType.ChangeMode:
      return { ...state, mode: action.mode };
    case ActionType.ChangeEdition: {
      return { ...state, edition: action.edition };
    }
    case ActionType.ChangeBacktrace:
      return { ...state, backtrace: action.backtrace };
    default:
      return state;
  }
}

'''
'''--- ui/frontend/reducers/crates.ts ---
import { sortBy } from 'lodash';

import { Action, ActionType } from '../actions';
import { Crate } from '../types';

const DEFAULT: State = [];

export type State = Crate[];

export default function crates(state = DEFAULT, action: Action) {
  switch (action.type) {
    case ActionType.CratesLoadSucceeded:
      return sortBy(action.crates, c => c.name);
    default:
      return state;
  }
}

'''
'''--- ui/frontend/reducers/globalConfiguration.ts ---
import { Action } from '../actions';

export interface State {
  baseUrl: string;
}

const DEFAULT: State = {
  baseUrl: '',
};

export default function globalConfiguration(state = DEFAULT, _action: Action): State {
  return state;
}

'''
'''--- ui/frontend/reducers/index.ts ---
import { combineReducers } from 'redux';

import browser from './browser';
import code from './code';
import configuration from './configuration';
import crates from './crates';
import globalConfiguration from './globalConfiguration';
import notifications from './notifications';
import output from './output';
import page from './page';
import position from './position';
import selection from './selection';
import versions from './versions';

const playgroundApp = combineReducers({
  browser,
  code,
  configuration,
  crates,
  globalConfiguration,
  notifications,
  output,
  page,
  position,
  selection,
  versions,
});

export type State = ReturnType<typeof playgroundApp>;

export default playgroundApp;

'''
'''--- ui/frontend/reducers/notifications.ts ---
import { Action, ActionType } from '../actions';
import { Notification } from '../types';

interface State {
  seenRustSurvey2018: boolean; // expired
  seenRust2018IsDefault: boolean; // expired
  seenRustSurvey2020: boolean;
}

const DEFAULT: State = {
  seenRustSurvey2018: true,
  seenRust2018IsDefault: true,
  seenRustSurvey2020: false,
};

export default function notifications(state = DEFAULT, action: Action): State {
  switch (action.type) {
    case ActionType.NotificationSeen: {
      switch (action.notification) {
        case Notification.RustSurvey2020: {
          return { ...state, seenRustSurvey2020: true };
        }
      }
    }
    default:
      return state;
  }
}

'''
'''--- ui/frontend/reducers/output/assembly.ts ---
import { Action, ActionType } from '../../actions';
import { finish, start } from './sharedStateManagement';

const DEFAULT: State = {
  requestsInProgress: 0,
  code: null,
  stdout: null,
  stderr: null,
  error: null,
};

interface State {
  requestsInProgress: number;
  code?: string;
  stdout?: string;
  stderr?: string;
  error?: string;
}

export default function assembly(state = DEFAULT, action: Action) {
  switch (action.type) {
    case ActionType.CompileAssemblyRequest:
      return start(DEFAULT, state);
    case ActionType.CompileAssemblySucceeded: {
      const { code = '', stdout = '', stderr = '' } = action;
      return finish(state, { code, stdout, stderr });
    }
    case ActionType.CompileAssemblyFailed:
      return finish(state, { error: action.error });
    default:
      return state;
  }
}

'''
'''--- ui/frontend/reducers/output/clippy.ts ---
import { Action, ActionType } from '../../actions';
import { finish, start } from './sharedStateManagement';

const DEFAULT: State = {
  requestsInProgress: 0,
  stdout: null,
  stderr: null,
  error: null,
};

interface State {
  requestsInProgress: number;
  stdout?: string;
  stderr?: string;
  error?: string;
}

export default function clippy(state = DEFAULT, action: Action) {
  switch (action.type) {
    case ActionType.RequestClippy:
      return start(DEFAULT, state);
    case ActionType.ClippySucceeded: {
      const { stdout = '', stderr = '' } = action;
      return finish(state, { stdout, stderr });
    }
    case ActionType.ClippyFailed:
      return finish(state, { error: action.error });
    default:
      return state;
  }
}

'''
'''--- ui/frontend/reducers/output/execute.ts ---
import { Action, ActionType } from '../../actions';
import { finish, start } from './sharedStateManagement';

const DEFAULT: State = {
  requestsInProgress: 0,
  stdout: null,
  stderr: null,
  error: null,
  isAutoBuild: false,
};

interface State {
  requestsInProgress: number;
  stdout?: string;
  stderr?: string;
  error?: string;
  isAutoBuild: boolean;
}

export default function execute(state = DEFAULT, action: Action) {
  switch (action.type) {
    case ActionType.ExecuteRequest:
      return start(DEFAULT, state);
    case ActionType.ExecuteSucceeded: {
      const { stdout = '', stderr = '', isAutoBuild } = action;
      return finish(state, { stdout, stderr, isAutoBuild });
    }
    case ActionType.ExecuteFailed: {
      const { error, isAutoBuild } = action;
      return finish(state, { error, isAutoBuild });
    }
    default:
      return state;
  }
}

'''
'''--- ui/frontend/reducers/output/format.ts ---
import { Action, ActionType } from '../../actions';
import { finish, start } from './sharedStateManagement';

const DEFAULT: State = {
  requestsInProgress: 0,
  stdout: null,
  stderr: null,
  error: null,
};

interface State {
  requestsInProgress: number;
  stdout?: string;
  stderr?: string;
  error?: string;
}

export default function format(state = DEFAULT, action: Action): State {
  switch (action.type) {
    case ActionType.RequestFormat:
      return start(DEFAULT, state);
    case ActionType.FormatSucceeded:
      return finish(state);
    case ActionType.FormatFailed: {
      const { stdout = '', stderr = '', error = '' } = action;
      return finish(state, { stdout, stderr, error });
    }
    default:
      return state;
  }
}

'''
'''--- ui/frontend/reducers/output/gist.ts ---
import { Action, ActionType } from '../../actions';
import { Channel, Edition, Mode } from '../../types';
import { finish, RequestsInProgress, start } from './sharedStateManagement';

const DEFAULT: State = {
  requestsInProgress: 0,
  id: null,
  url: null,
  code: null,
  stdout: null,
  stderr: null,
  channel: null,
  mode: null,
  edition: null,
  error: null,
};

interface State extends RequestsInProgress {
  id?: string;
  url?: string;
  code?: string;
  stdout?: string;
  stderr?: string;
  channel?: Channel;
  mode?: Mode;
  edition?: Edition;
  error?: string;
}

export default function gist(state = DEFAULT, action: Action): State {
  switch (action.type) {
    case ActionType.RequestGistLoad:
    case ActionType.RequestGistSave:
      return start(DEFAULT, state);

    case ActionType.GistLoadSucceeded:
    case ActionType.GistSaveSucceeded: {
      const { id, url, code, stdout, stderr, channel, mode, edition } = action;
      return finish(state, { id, url, code, stdout, stderr, channel, mode, edition });
    }

    case ActionType.GistLoadFailed:
    case ActionType.GistSaveFailed:
      return finish(state, { error: 'Some kind of error' });

    default:
      return state;
  }
}

'''
'''--- ui/frontend/reducers/output/hir.ts ---
import { Action, ActionType } from '../../actions';
import { finish, start } from './sharedStateManagement';

const DEFAULT: State = {
  requestsInProgress: 0,
  code: null,
  stdout: null,
  stderr: null,
  error: null,
};

interface State {
  requestsInProgress: number;
  code?: string;
  stdout?: string;
  stderr?: string;
  error?: string;
}

export default function hir(state = DEFAULT, action: Action) {
  switch (action.type) {
    case ActionType.CompileHirRequest:
      return start(DEFAULT, state);
    case ActionType.CompileHirSucceeded: {
      const { code = '', stdout = '', stderr = '' } = action;
      return finish(state, { code, stdout, stderr });
    }
    case ActionType.CompileHirFailed:
      return finish(state, { error: action.error });
    default:
      return state;
  }
}

'''
'''--- ui/frontend/reducers/output/index.ts ---
import { combineReducers } from 'redux';

import assembly from './assembly';
import clippy from './clippy';
import execute from './execute';
import format from './format';
import gist from './gist';
import hir from './hir';
import llvmIr from './llvmIr';
import macroExpansion from './macroExpansion';
import meta from './meta';
import mir from './mir';
import miri from './miri';
import wasm from './wasm';

const output = combineReducers({
  meta,
  format,
  clippy,
  miri,
  macroExpansion,
  assembly,
  llvmIr,
  mir,
  hir,
  wasm,
  execute,
  gist,
});

export type State = ReturnType<typeof output>;

export default output;

'''
'''--- ui/frontend/reducers/output/llvmIr.ts ---
import { Action, ActionType } from '../../actions';
import { finish, start } from './sharedStateManagement';

const DEFAULT: State = {
  requestsInProgress: 0,
  code: null,
  stdout: null,
  stderr: null,
  error: null,
};

interface State {
  requestsInProgress: number;
  code?: string;
  stdout?: string;
  stderr?: string;
  error?: string;
}

export default function llvmIr(state = DEFAULT, action: Action) {
  switch (action.type) {
    case ActionType.CompileLlvmIrRequest:
      return start(DEFAULT, state);
    case ActionType.CompileLlvmIrSucceeded: {
      const { code = '', stdout = '', stderr = '' } = action;
      return finish(state, { code, stdout, stderr });
    }
    case ActionType.CompileLlvmIrFailed:
      return finish(state, { error: action.error });
    default:
      return state;
  }
}

'''
'''--- ui/frontend/reducers/output/macroExpansion.ts ---
import { Action, ActionType } from '../../actions';
import { finish, start } from './sharedStateManagement';

const DEFAULT: State = {
  requestsInProgress: 0,
  stdout: null,
  stderr: null,
  error: null,
};

interface State {
  requestsInProgress: number;
  stdout?: string;
  stderr?: string;
  error?: string;
}

export default function macroExpansion(state = DEFAULT, action: Action) {
  switch (action.type) {
    case ActionType.RequestMacroExpansion:
      return start(DEFAULT, state);
    case ActionType.MacroExpansionSucceeded: {
      const { stdout = '', stderr = '' } = action;
      return finish(state, { stdout, stderr });
    }
    case ActionType.MacroExpansionFailed:
      return finish(state, { error: action.error });
    default:
      return state;
  }
}

'''
'''--- ui/frontend/reducers/output/meta.ts ---
import { Action, ActionType } from '../../actions';
import { Focus } from '../../types';

const DEFAULT: State = {
  focus: null,
};

interface State {
  focus?: Focus;
}

export default function meta(state = DEFAULT, action: Action) {
  switch (action.type) {
    case ActionType.ChangeFocus:
      return { ...state, focus: action.focus };

    case ActionType.RequestClippy:
      return { ...state, focus: Focus.Clippy };

    case ActionType.RequestMiri:
      return { ...state, focus: Focus.Miri };

    case ActionType.RequestMacroExpansion:
      return { ...state, focus: Focus.MacroExpansion };

    case ActionType.CompileLlvmIrRequest:
      return { ...state, focus: Focus.LlvmIr };

    case ActionType.CompileMirRequest:
      return { ...state, focus: Focus.Mir };

    case ActionType.CompileHirRequest:
      return { ...state, focus: Focus.Hir };

    case ActionType.CompileWasmRequest:
      return { ...state, focus: Focus.Wasm };

    case ActionType.CompileAssemblyRequest:
      return { ...state, focus: Focus.Asm };

    case ActionType.ExecuteRequest:
      return { ...state, focus: Focus.Execute };

    case ActionType.RequestFormat:
      return { ...state, focus: Focus.Format };
    case ActionType.FormatSucceeded:
      return { ...state, focus: null };

    case ActionType.RequestGistLoad:
    case ActionType.RequestGistSave:
      return { ...state, focus: Focus.Gist };

    default:
      return state;
  }
}

'''
'''--- ui/frontend/reducers/output/mir.ts ---
import { Action, ActionType } from '../../actions';
import { finish, start } from './sharedStateManagement';

const DEFAULT: State = {
  requestsInProgress: 0,
  code: null,
  stdout: null,
  stderr: null,
  error: null,
};

interface State {
  requestsInProgress: number;
  code?: string;
  stdout?: string;
  stderr?: string;
  error?: string;
}

export default function mir(state = DEFAULT, action: Action) {
  switch (action.type) {
    case ActionType.CompileMirRequest:
      return start(DEFAULT, state);
    case ActionType.CompileMirSucceeded: {
      const { code = '', stdout = '', stderr = '' } = action;
      return finish(state, { code, stdout, stderr });
    }
    case ActionType.CompileMirFailed:
      return finish(state, { error: action.error });
    default:
      return state;
  }
}

'''
'''--- ui/frontend/reducers/output/miri.ts ---
import { Action, ActionType } from '../../actions';
import { finish, start } from './sharedStateManagement';

const DEFAULT: State = {
  requestsInProgress: 0,
  stdout: null,
  stderr: null,
  error: null,
};

interface State {
  requestsInProgress: number;
  stdout?: string;
  stderr?: string;
  error?: string;
}

export default function miri(state = DEFAULT, action: Action) {
  switch (action.type) {
    case ActionType.RequestMiri:
      return start(DEFAULT, state);
    case ActionType.MiriSucceeded: {
      const { stdout = '', stderr = '' } = action;
      return finish(state, { stdout, stderr });
    }
    case ActionType.MiriFailed:
      return finish(state, { error: action.error });
    default:
      return state;
  }
}

'''
'''--- ui/frontend/reducers/output/sharedStateManagement.ts ---
export interface RequestsInProgress {
  requestsInProgress: number;
}

type WithoutRequests<S> = Pick<S, Exclude<keyof S, keyof RequestsInProgress>>;

export function start<S extends RequestsInProgress>(
  zeroState: S,
  state: S,
): S {
  const { requestsInProgress = 0 } = state;
  return Object.assign({}, zeroState, { requestsInProgress: requestsInProgress + 1 });
}

export function finish<S extends RequestsInProgress>(
  state: S,
  newState?: WithoutRequests<S>,
): S {
  const { requestsInProgress = 0 } = state;
  return Object.assign({}, state, newState, { requestsInProgress: requestsInProgress - 1 });
}

'''
'''--- ui/frontend/reducers/output/wasm.ts ---
import { Action, ActionType } from '../../actions';
import { finish, start } from './sharedStateManagement';

const DEFAULT: State = {
  requestsInProgress: 0,
  code: null,
  stdout: null,
  stderr: null,
  error: null,
};

interface State {
  requestsInProgress: number;
  code?: string;
  stdout?: string;
  stderr?: string;
  error?: string;
}

export default function wasm(state = DEFAULT, action: Action) {
  switch (action.type) {
    case ActionType.CompileWasmRequest:
      return start(DEFAULT, state);
    case ActionType.CompileWasmSucceeded: {
      const { code = '', stdout = '', stderr = '' } = action;
      return finish(state, { code, stdout, stderr });
    }
    case ActionType.CompileWasmFailed:
      return finish(state, { error: action.error });
    default:
      return state;
  }
}

'''
'''--- ui/frontend/reducers/page.ts ---
import { Action, ActionType } from '../actions';
import { Page } from '../types';

export type State = Page;

export default function page(state: State = 'index', action: Action) {
  switch (action.type) {
    case ActionType.SetPage:
      return action.page;
    default:
      return state;
  }
}

'''
'''--- ui/frontend/reducers/position.ts ---
import { Action, ActionType } from '../actions';
import { Position } from '../types';

const DEFAULT: Position = {
  line: 0,
  column: 0,
};

export type State = Position;

export default function position(state = DEFAULT, action: Action) {
  switch (action.type) {
    case ActionType.GotoPosition: {
      const { line, column } = action;
      return { ...state, line, column };
    }
    default:
      return state;
  }
}

'''
'''--- ui/frontend/reducers/selection.ts ---
import { Action, ActionType } from '../actions';
import { Selection } from '../types';

const DEFAULT: Selection = {
  start: null,
  end: null,
};

export default function position(state = DEFAULT, action: Action) {
  switch (action.type) {
    case ActionType.SelectText: {
      const { start, end } = action;
      return { ...state, start, end };
    }
    default:
      return state;
  }
}

'''
'''--- ui/frontend/reducers/versions.ts ---
import { Action, ActionType } from '../actions';
import { Version } from '../types';

const DEFAULT: State = {
  stable: null,
  beta: null,
  nightly: null,
  rustfmt: null,
  clippy: null,
  miri: null,
};

export interface State {
  stable?: Version;
  beta?: Version;
  nightly?: Version;
  rustfmt?: Version;
  clippy?: Version;
  miri?: Version;
}

export default function crates(state = DEFAULT, action: Action) {
  switch (action.type) {
    case ActionType.VersionsLoadSucceeded: {
      const { stable, beta, nightly, rustfmt, clippy, miri } = action;
      return { stable, beta, nightly, rustfmt, clippy, miri };
    }
    default:
      return state;
  }
}

'''
'''--- ui/frontend/robots.txt ---
User-Agent: *
Disallow:

'''
'''--- ui/frontend/selectors/index.spec.ts ---
import reducer from '../reducers';

import { hasMainFunctionSelector } from './index';

const buildState = code => {
  const state = reducer(undefined, { type: '__test_init' });
  state.code = code;
  return state;
};

describe('checking for a main function', () => {
  test('empty code has no main', () => {
    expect(hasMainFunctionSelector(buildState(''))).toBe(false);
  });

  test('a plain main counts', () => {
    expect(hasMainFunctionSelector(buildState('fn main()'))).toBe(true);
  });

  test('a public main counts', () => {
    expect(hasMainFunctionSelector(buildState('pub fn main()'))).toBe(true);
  });

  test('an async main counts', () => {
    expect(hasMainFunctionSelector(buildState('async fn main()'))).toBe(true);
  });

  test('a public async main counts', () => {
    expect(hasMainFunctionSelector(buildState('pub async fn main()'))).toBe(true);
  });

  test('a const main counts', () => {
    expect(hasMainFunctionSelector(buildState('const fn main()'))).toBe(true);
  });

  test('a public const main counts', () => {
    expect(hasMainFunctionSelector(buildState('pub const fn main()'))).toBe(true);
  });

  test('a public const async main counts', () => {
    expect(hasMainFunctionSelector(buildState('pub const async fn main()'))).toBe(true);
  });

  test('leading indentation is ignored', () => {
    expect(hasMainFunctionSelector(buildState('\t fn main()'))).toBe(true);
  });

  test('extra space everywhere is ignored', () => {
    expect(hasMainFunctionSelector(buildState('  pub async   fn  main  (  )'))).toBe(true);
  });

  test('a commented-out main does not count', () => {
    expect(hasMainFunctionSelector(buildState('// fn main()'))).toBe(false);
    expect(hasMainFunctionSelector(buildState('/* fn main()'))).toBe(false);
  });

  test('a function with the substring main does not count', () => {
    expect(hasMainFunctionSelector(buildState('fn mainly()'))).toBe(false);
  });
});

'''
'''--- ui/frontend/selectors/index.ts ---
import { source } from 'common-tags';
import { createSelector } from 'reselect';
import * as url from 'url';

import { State } from '../reducers';
import { Backtrace, Channel, Edition, Orientation, PrimaryActionAuto, PrimaryActionCore, AceResizeKey } from '../types';

const codeSelector = (state: State) => state.code;

const HAS_TESTS_RE = /^\s*#\s*\[\s*test\s*([^"]*)]/m;
export const hasTestsSelector = createSelector(codeSelector, code => !!code.match(HAS_TESTS_RE));

const HAS_MAIN_FUNCTION_RE = /^\s*(pub\s+)?\s*(const\s+)?\s*(async\s+)?\s*fn\s+main\s*\(\s*\)/m;
export const hasMainFunctionSelector = createSelector(codeSelector, code => !!code.match(HAS_MAIN_FUNCTION_RE));

const CRATE_TYPE_RE = /^\s*#!\s*\[\s*crate_type\s*=\s*"([^"]*)"\s*]/m;
export const crateTypeSelector = createSelector(codeSelector, code => (code.match(CRATE_TYPE_RE) || [])[1]);

const autoPrimaryActionSelector = createSelector(
  crateTypeSelector,
  hasTestsSelector,
  hasMainFunctionSelector,
  (crateType, hasTests, hasMainFunction) => {
    if (crateType) {
      if (crateType === 'bin') {
        return PrimaryActionCore.Execute;
      } else {
        return PrimaryActionCore.Compile;
      }
    } else {
      if (hasTests) {
        return PrimaryActionCore.Test;
      } else if (hasMainFunction) {
        return PrimaryActionCore.Execute;
      } else {
        return PrimaryActionCore.Compile;
      }
    }
  },
);

export const runAsTest = createSelector(
  autoPrimaryActionSelector,
  primaryAction => primaryAction === PrimaryActionCore.Test,
);
export const getCrateType = createSelector(
  autoPrimaryActionSelector,
  primaryAction => primaryAction === PrimaryActionCore.Execute ? 'bin' : 'lib',
);

const rawPrimaryActionSelector = (state: State) => state.configuration.primaryAction;

export const isAutoBuildSelector = createSelector(
  rawPrimaryActionSelector,
  autoPrimaryActionSelector,
  (primaryAction, autoPrimaryAction) => (
    primaryAction === PrimaryActionAuto.Auto && autoPrimaryAction === PrimaryActionCore.Compile
  ),
);

const primaryActionSelector = createSelector(
  rawPrimaryActionSelector,
  autoPrimaryActionSelector,
  (primaryAction, autoPrimaryAction): PrimaryActionCore => (
    primaryAction === PrimaryActionAuto.Auto ? autoPrimaryAction : primaryAction
  ),
);

const LABELS: { [index in PrimaryActionCore]: string } = {
  [PrimaryActionCore.Asm]: 'Show Assembly',
  [PrimaryActionCore.Compile]: 'Build',
  [PrimaryActionCore.Execute]: 'Run',
  [PrimaryActionCore.LlvmIr]: 'Show LLVM IR',
  [PrimaryActionCore.Hir]: 'Show HIR',
  [PrimaryActionCore.Mir]: 'Show MIR',
  [PrimaryActionCore.Test]: 'Test',
  [PrimaryActionCore.Wasm]: 'Show WASM',
};

export const getExecutionLabel = createSelector(primaryActionSelector, primaryAction => LABELS[primaryAction]);

const getStable = (state: State) => state.versions && state.versions.stable;
const getBeta = (state: State) => state.versions && state.versions.beta;
const getNightly = (state: State) => state.versions && state.versions.nightly;
const getRustfmt = (state: State) => state.versions && state.versions.rustfmt;
const getClippy = (state: State) => state.versions && state.versions.clippy;
const getMiri = (state: State) => state.versions && state.versions.miri;

const versionNumber = v => v ? v.version : '';
export const stableVersionText = createSelector([getStable], versionNumber);
export const betaVersionText = createSelector([getBeta], versionNumber);
export const nightlyVersionText = createSelector([getNightly], versionNumber);
export const clippyVersionText = createSelector([getClippy], versionNumber);
export const rustfmtVersionText = createSelector([getRustfmt], versionNumber);
export const miriVersionText = createSelector([getMiri], versionNumber);

const versionDetails = v => v ? `${v.date} ${v.hash.slice(0, 20)}` : '';
export const betaVersionDetailsText = createSelector([getBeta], versionDetails);
export const nightlyVersionDetailsText = createSelector([getNightly], versionDetails);
export const clippyVersionDetailsText = createSelector([getClippy], versionDetails);
export const rustfmtVersionDetailsText = createSelector([getRustfmt], versionDetails);
export const miriVersionDetailsText = createSelector([getMiri], versionDetails);

const editionSelector = (state: State) => state.configuration.edition;

export const isNightlyChannel = (state: State) => (
  state.configuration.channel === Channel.Nightly
);
export const isWasmAvailable = isNightlyChannel;
export const isHirAvailable = isNightlyChannel;
export const isRust2021Available = isNightlyChannel;

export const getModeLabel = (state: State) => {
  const { configuration: { mode } } = state;
  return `${mode}`;
};

export const getChannelLabel = (state: State) => {
  const { configuration: { channel } } = state;
  return `${channel}`;
};

export const isEditionDefault = createSelector(
  editionSelector,
  edition => edition == Edition.Rust2018,
);

export const getBacktraceSet = (state: State) => (
  state.configuration.backtrace !== Backtrace.Disabled
);

export const getAdvancedOptionsSet = createSelector(
  isEditionDefault, getBacktraceSet,
  (editionDefault, backtraceSet) => (
    !editionDefault || backtraceSet
  ),
);

export const hasProperties = obj => Object.values(obj).some(val => !!val);

const getOutputs = (state: State) => [
  state.output.assembly,
  state.output.clippy,
  state.output.execute,
  state.output.format,
  state.output.gist,
  state.output.llvmIr,
  state.output.mir,
  state.output.hir,
  state.output.miri,
  state.output.macroExpansion,
  state.output.wasm,
];

export const getSomethingToShow = createSelector(
  getOutputs,
  a => a.some(hasProperties),
);

const baseUrlSelector = (state: State) =>
  state.globalConfiguration.baseUrl;

const gistSelector = (state: State) =>
  state.output.gist;

// Selects url.query of build configs.
const urlQuerySelector = createSelector(
  gistSelector,
  gist => ({
    version: gist.channel,
    mode: gist.mode,
    edition: gist.edition,
  }),
);

export const showGistLoaderSelector = createSelector(
  gistSelector,
  gist => gist.requestsInProgress > 0,
);

export const permalinkSelector = createSelector(
  baseUrlSelector, urlQuerySelector, gistSelector,
  (baseUrl, query, gist) => {
    const u = url.parse(baseUrl, true);
    u.query = { ...query, gist: gist.id };
    return url.format(u);
  },
);

const codeBlock = (code: string, language = '') =>
  '```' + language + `\n${code}\n` + '```';

const maybeOutput = (code: string, whenPresent: (_: string) => void) => {
  const val = (code || '').trim();
  if (val.length !== 0) { whenPresent(code); }
};

const snippetSelector = createSelector(
  gistSelector, permalinkSelector,
  (gist, permalink) => {
    let snippet =
      source`
        ${codeBlock(gist.code, 'rust')}

        ([Playground](${permalink}))
      `;

    maybeOutput(gist.stdout, stdout => {
      snippet += '\n\n';
      snippet +=
        source`
          Output:

          ${codeBlock(stdout)}
        `;
    });

    maybeOutput(gist.stderr, stderr => {
      snippet += '\n\n';
      snippet +=
        source`
          Errors:

          ${codeBlock(stderr)}
        `;
    });

    return snippet;
  },
);

export const urloUrlSelector = createSelector(
  snippetSelector,
  snippet => {
    const newUsersPostUrl = url.parse('https://users.rust-lang.org/new-topic', true);
    newUsersPostUrl.query = { body: snippet };
    return url.format(newUsersPostUrl);
  },
);

export const codeUrlSelector = createSelector(
  baseUrlSelector, urlQuerySelector, gistSelector,
  (baseUrl, query, gist) => {
    const u = url.parse(baseUrl, true);
    u.query = { ...query, code: gist.code };
    return url.format(u);
  },
);

const notificationsSelector = (state: State) => state.notifications;

const NOW = new Date();
const RUST_SURVEY_2020_END = new Date('2020-09-24T23:59:59Z');
const RUST_SURVEY_2020_OPEN = NOW <= RUST_SURVEY_2020_END;
export const showRustSurvey2020Selector = createSelector(
  notificationsSelector,
  notifications => RUST_SURVEY_2020_OPEN && !notifications.seenRustSurvey2020,
);

export const anyNotificationsToShowSelector = createSelector(
  showRustSurvey2020Selector,
  allNotifications => allNotifications,
);

export const clippyRequestSelector = createSelector(
  codeSelector,
  editionSelector,
  getCrateType,
  (code, edition, crateType) => ({ code, edition, crateType }),
);

export const formatRequestSelector = createSelector(
  codeSelector,
  editionSelector,
  (code, edition) => ({ code, edition }),
);

const focus = (state: State) => state.output.meta.focus;
export const isOutputFocused = createSelector(
  focus,
  (focus) => !!focus,
);

const orientationConfig = (state: State) => state.configuration.orientation;
const browserWidthIsSmall = (state: State) => state.browser.isSmall;

export const orientation = createSelector(
  orientationConfig,
  browserWidthIsSmall,
  (orientation, widthIsSmall) => {
    if (orientation == Orientation.Automatic) {
      if (widthIsSmall) { return Orientation.Horizontal } else { return Orientation.Vertical }
    } else {
      return orientation;
    }
  }
)

const ratioGeneration = (state: State) => state.browser.ratioGeneration;

export const aceResizeKey = createSelector(
  focus,
  ratioGeneration,
  (focus, ratioGeneration): AceResizeKey => [focus, ratioGeneration],
)

export const offerCrateAutocompleteOnUse = createSelector(
  editionSelector,
  (edition) => edition !== Edition.Rust2015,
);

'''
'''--- ui/frontend/session_storage.ts ---
// This is used to store "short-term" values; those which we want to
// be preserved between the same sessions of the playground, such as
// when we reopen a closed tab.

import { State } from './reducers';
import storage from './storage';

const CURRENT_VERSION = 1;

export function serialize(state: State): string {
  return JSON.stringify({
    version: CURRENT_VERSION,
    configuration: {
      primaryAction: state.configuration.primaryAction,
    },
    code: state.code,
  });
}

export function deserialize(savedState: string): Partial<State> {
  if (!savedState) { return undefined; }
  const parsedState = JSON.parse(savedState);
  if (!parsedState) { return undefined; }
  if (parsedState.version !== CURRENT_VERSION) { return undefined; }

  // This assumes that the keys we serialize with match the keys in the
  // live state. If that's no longer true, an additional renaming step
  // needs to be added.
  delete parsedState.version;
  return parsedState;
}

export default storage({
  storageFactory: () => sessionStorage,
  serialize,
  deserialize,
});

'''
'''--- ui/frontend/shared.module.css ---
.-bodyMonospace {
  /* http://code.stephenmorley.org/html-and-css/fixing-browsers-broken-monospace-font-handling/
   * ACE uses Monaco, Menlo, "Ubuntu Mono", Consolas, source-code-pro, monospace;
   */
  font-family: 'Source Code Pro', monospace;
  font-size: 0.9em;
}

.-autoSize {
  width: 100%;
  min-width: 0;
  height: 100%;
  min-height: 0;
}

.-buttonReset {
  padding: 0;
  border: none;
  background: inherit;
  background-color: transparent; /* IE 11 */
  font: inherit;
  line-height: inherit;
  text-align: inherit;
}

.-buttonAsLink {
  composes: -buttonReset;
  color: #00e;
  cursor: pointer;
  text-decoration: underline;
  user-select: text;
}

.-menuItemTitle {
  font-size: 13px;
  font-weight: 600;
}

.-menuItemFullButton {
  composes: -buttonReset;
  width: 100%;
  transition: color var(--header-transition);
  user-select: text;
}

'''
'''--- ui/frontend/state.ts ---
import { State } from './reducers';

export default State;

'''
'''--- ui/frontend/storage.spec.ts ---
import { createStore } from 'redux';

import storage, { InMemoryStorage } from './storage';

const identityReducer = <S>() => (s: S, _a: any): S => s;
const serialize = JSON.stringify;
const deserialize = JSON.parse;

describe('restoring saved state', () => {
  test('partially serialized data is merged with initial state', () => {
    const testStorage = new InMemoryStorage();
    testStorage.setItem('redux', serialize({ config: { alpha: true } }));

    const initialState = {
      config: { alpha: false, beta: 42 },
    };

    const enhancer = storage({ storageFactory: () => testStorage, serialize, deserialize });
    const store = createStore(identityReducer<typeof initialState>(), initialState, enhancer);

    const state = store.getState();

    expect(state.config.alpha).toEqual(true);
    expect(state.config.beta).toEqual(42);
  });
});

'''
'''--- ui/frontend/storage.ts ---
import { merge } from 'lodash';
import { StoreEnhancer, StoreEnhancerStoreCreator } from 'redux';

type SimpleStorage = Pick<Storage, 'getItem' | 'setItem'>;

interface Config<S> {
  storageFactory: () => SimpleStorage;
  serialize: (state: S) => string;
  deserialize: (state: string) => S;
}

export class InMemoryStorage {
  private data = {};

  public getItem(name: string): string {
    return this.data[name];
  }

  public setItem(name: string, value: string) {
    this.data[name] = value;
  }
}

const key = 'redux';

const storage = <St>(config: Config<St>): StoreEnhancer =>
  (createStore: StoreEnhancerStoreCreator<{}, St>) =>
    (reducer, preloadedState) => {
      const { storageFactory, serialize, deserialize } = config;

      let storage: SimpleStorage;

      try {
        // Attempt to use the storage to see if security settings are preventing it.
        storage = storageFactory();
        const current = storage.getItem(key);
        storage.setItem(key, current);
      } catch (e) {
        console.warn('Unable to store configuration, falling back to non-persistent in-memory storage');
        storage = new InMemoryStorage();
      }

      const serializedState = storage.getItem(key);
      const persistedState = deserialize(serializedState);
      const mergedPreloadedState = merge(preloadedState, persistedState);
      const theStore = createStore(reducer, mergedPreloadedState);

      theStore.subscribe(() => {
        const state = theStore.getState();
        const serializedState = serialize(state);
        storage.setItem(key, serializedState);
      });

      return theStore;
    };

export default storage;

'''
'''--- ui/frontend/tsconfig.json ---
{
  "exclude": [
    "build",
  ],
  "compilerOptions": {
    "moduleResolution": "node",
    "allowSyntheticDefaultImports": true,
    "alwaysStrict": true,
    "target": "ES2017",
    "module": "esnext",
    "sourceMap": true,
    "jsx": "preserve",
    "plugins": [{ "name": "typescript-plugin-css-modules" }],
  }
}

'''
'''--- ui/frontend/tsfmt.json ---
{
  "indentSize": 2,
  "tabSize": 2
}

'''
'''--- ui/frontend/types.ts ---
export type Page = 'index' | 'help';

export interface Position {
  line: number;
  column: number;
}

export const makePosition = (line: string | number, column: string | number): Position =>
  ({ line: +line, column: +column });

export interface Selection {
  start?: Position;
  end?: Position;
}

export interface Crate {
  id: string;
  name: string;
  version: string;
}

export interface Version {
  version: string;
  hash: string;
  date: string;
}

export interface CommonEditorProps {
  code: string;
  execute: () => any;
  onEditCode: (_: string) => any;
  position: Position;
  selection: Selection;
  crates: Crate[];
}

export enum Editor {
  Simple = 'simple',
  Advanced = 'advanced',
}

export enum PairCharacters {
  Enabled = 'enabled',
  Disabled = 'disabled',
}

export enum Orientation {
  Automatic = 'automatic',
  Horizontal = 'horizontal',
  Vertical = 'vertical',
}

export enum AssemblyFlavor {
  Att = 'att',
  Intel = 'intel',
}

export enum DemangleAssembly {
  Demangle = 'demangle',
  Mangle = 'mangle',
}

export enum ProcessAssembly {
  Filter = 'filter',
  Raw = 'raw',
}

export enum PrimaryActionAuto {
  Auto = 'auto',
}

export enum PrimaryActionCore {
  Asm = 'asm',
  Compile = 'compile',
  Execute = 'execute',
  LlvmIr = 'llvm-ir',
  Hir = 'hir',
  Mir = 'mir',
  Test = 'test',
  Wasm = 'wasm',
}

export type PrimaryAction = PrimaryActionCore | PrimaryActionAuto;

export enum Channel {
  Stable = 'stable',
  Beta = 'beta',
  Nightly = 'nightly',
}

export enum Mode {
  Debug = 'debug',
  Release = 'release',
}

export enum Edition {
  Rust2015 = '2015',
  Rust2018 = '2018',
  Rust2021 = '2021',
}

export enum Backtrace {
  Disabled = 'disabled',
  Enabled = 'enabled',
}

export enum Focus {
  Clippy = 'clippy',
  Miri = 'miri',
  MacroExpansion = 'macro-expansion',
  LlvmIr = 'llvm-ir',
  Mir = 'mir',
  Hir = 'hir',
  Wasm = 'wasm',
  Asm = 'asm',
  Execute = 'execute',
  Format = 'format',
  Gist = 'gist',
}

export enum Notification {
  RustSurvey2020 = 'rust-survey-2020',
}

export type AceResizeKey = [Focus, number];

'''
'''--- ui/frontend/types/react-prism.d.ts ---
declare module 'react-prism' {
  export const PrismCode: any;
}

'''
'''--- ui/frontend/uss-router/index.ts ---
import { isEqual } from 'lodash';
import { createStore } from 'redux';

export function createRouter({
  store,
  reducer,
  history,
  stateSelector,
  stateToLocation,
  locationToAction,
}) {
  let doingUpdateFromBrowser = false; // Avoid immediately PUSHing the state again
  let interestingPrevState;

  // Watch changes to the Redux state
  store.subscribe(() => {
    if (doingUpdateFromBrowser) { return; }

    const nextState = store.getState();
    const interestingNextState = stateSelector(nextState);

    if (!isEqual(interestingNextState, interestingPrevState)) {
      const nextLocation = stateToLocation(nextState);

      history.push(nextLocation);

      interestingPrevState = interestingNextState;
    }
  });

  const dispatchBrowserLocationChange = nextLocation => {
    const action = locationToAction(nextLocation);
    if (action) {
      doingUpdateFromBrowser = true;
      store.dispatch(action);
      doingUpdateFromBrowser = false;
    }
  };

  // Watch changes to the browser state
  history.listen((nextLocation, historyAction) => {
    if (historyAction === 'POP') {
      dispatchBrowserLocationChange(nextLocation);
    }
  });

  // Load initial browser state
  dispatchBrowserLocationChange(history.location);

  // Now that we've set up any initial state, we keep it so we can
  // tell when the location needs to change.
  interestingPrevState = stateSelector(store.getState());

  return {
    provisionalLocation: action => {
      const state = store.getState();
      const tempStore = createStore(reducer, state);
      const a = action();
      tempStore.dispatch(a);
      const maybeState = tempStore.getState();
      return stateToLocation(maybeState);
    },
  };
}

'''
'''--- ui/frontend/webpack.config.js ---
/* global process:false, __dirname:false */

const webpack = require('webpack');
const HtmlPlugin = require('html-webpack-plugin');
const CopyPlugin = require('copy-webpack-plugin');
const MiniCssExtractPlugin = require("mini-css-extract-plugin");
const CompressionPlugin = require("compression-webpack-plugin");
const glob = require('glob');
const basename = require('basename');

const thisPackage = require('./package.json');
const devDependencies = Object.keys(thisPackage.devDependencies);

const allKeybindingNames =
      glob.sync('./node_modules/ace-builds/src-noconflict/keybinding-*.js')
      .map(basename)
      .map(n => n.replace(/^keybinding-/, ''));
const allThemeNames =
      glob.sync('./node_modules/ace-builds/src-noconflict/theme-*.js')
      .map(basename)
      .map(n => n.replace(/^theme-/, ''));

// There's a builtin/default keybinding that we call `ace`.
const allKeybindings = allKeybindingNames.concat(['ace']).sort();
const allThemes = allThemeNames;

// The name is nicer to debug with, but changing names breaks long-term-caching
const developmentFilenameTemplate = '[name]-[chunkhash]';
const productionFilenameTemplate = '[chunkhash]';

module.exports = function(_, argv) {
  const isProduction = argv.mode === 'production';
  const filenameTemplate =
        isProduction ?
        productionFilenameTemplate :
        developmentFilenameTemplate;

  const devtool =
        isProduction ?
        false :
        'inline-source-map';

  const localIdentName = isProduction ?
         "[hash:base64]" :
         "[path][name]__[local]--[hash:base64]";

  return {
    entry: './index.tsx',

    devtool,

    cache: {
      type: 'filesystem',

      buildDependencies: {
        config: [__filename],
      },
    },

    output: {
      publicPath: 'assets/',
      path: `${__dirname}/build/assets`,
      filename: `${filenameTemplate}.js`,
      chunkFilename: `${filenameTemplate}.js`,
    },

    resolve: {
      extensions: ['.js', '.jsx', '.ts', '.tsx'],
    },

    module: {
      rules: [
        {
          test: [/\.js$/, /\.jsx$/],
          exclude: /node_modules/,
          use: 'babel-loader',
        },
        {
          test: [/\.ts$/, /\.tsx$/],
          exclude: /node_modules/,
          use: ['babel-loader', 'ts-loader'],
        },
        {
          test: /prismjs\/themes\/.*css$/,
          type: 'asset/resource',
        },
        {
          test: /\.css$/,
          include: /node_modules/,
          use: [
            MiniCssExtractPlugin.loader,
            "css-loader",
            "postcss-loader",
          ],
        },
        {
          test: /\.module.css$/,
          exclude: /node_modules/,
          use: [
            MiniCssExtractPlugin.loader,
            {
              loader: "css-loader",
              options: {
                modules: {
                  localIdentName,
                },
              },
            },
            "postcss-loader",
          ],
        },
        {
          test: /\.svg$/,
          type: 'asset/inline',
        },
      ],
    },

    plugins: [
      new webpack.DefinePlugin({
        ACE_KEYBINDINGS: JSON.stringify(allKeybindings),
        ACE_THEMES: JSON.stringify(allThemes),
      }),
      new HtmlPlugin({
        title: "Rust Playground",
        template: 'index.ejs',
        filename: '../index.html',
      }),
      new CopyPlugin({
        patterns: [
          { from: 'robots.txt', to: '..' },
        ],
      }),
      new MiniCssExtractPlugin({
        filename: `${filenameTemplate}.css`,
        chunkFilename: `${filenameTemplate}.css`,
      }),
      ...(isProduction ? [new CompressionPlugin()] : []),
    ],

    optimization: {
      splitChunks: {
        chunks: "all",
      },
    },
  };
};

'''
'''--- ui/src/asm_cleanup.rs ---
// Thanks to Matt Godbolt for creating the amazing Compiler Explorer https://www.godbolt.org
// This aims to provide similar assembly cleanup to what Godbolt does

use lazy_static::lazy_static;
use petgraph::prelude::*;
use regex::{Captures, Regex};
use rustc_demangle::demangle;
use std::collections::HashSet;

pub fn demangle_asm(block: &str) -> String {
    lazy_static! {
        static ref DEMANGLE_REGEX: Regex = Regex::new(r"_[a-zA-Z0-9._$]*").unwrap();
    }

    DEMANGLE_REGEX.replace_all(block, |caps: &Captures<'_>| {
        format!("{:#}", demangle(caps.get(0).map_or("", |m| m.as_str())))
    }).to_string()
}

enum LineType<'a> {
    Opcode,
    LabelDecl(&'a str),
    Data(&'a str),
    FunctionDecl,
    Directive,
    Blank,
    Misc,
}

// Removes unused labels and directives from assembly
pub fn filter_asm(block: &str) -> String {

    use self::LineType::*;

    lazy_static! {
        // Example:    mov rax, rdx
        // Always inlude in results
        static ref OPCODE_REGEX: Regex = Regex::new(r"^\s+[a-zA-Z]+.*[^:]$").unwrap();
    }
    lazy_static! {
        // Example:.Lfunc_end7:
        // Finds label declarations
        // Include in results only if it is referenced by an opcode, or is a function
        static ref LABEL_DECL_REGEX: Regex = Regex::new(r"^([a-zA-Z_.<][a-zA-Z0-9$&_.,<>\[\]{}:' ]*):(\s+#.*)?$").unwrap();
    }
    lazy_static! {
        // Example:    mov lea rdi, [rip + str.0] // str.0 is the referenced label
        // Find labels used as operands for an opcode
        static ref LABEL_REF_REGEX: Regex = Regex::new(r"([a-zA-Z_.][a-zA-Z0-9$_.]*)").unwrap();
    }
    lazy_static! {
        // Example:    .string "Hello, world!"
        // Note: this is a type of directive
        // Include in results if it is part of a used label, may contain label references
        static ref DATA_REGEX: Regex = Regex::new(r"^\s+\.(string|asciz|ascii|[1248]?byte|short|word|long|quad|value|zero)").unwrap();
    }
    lazy_static! {
        // Example:    .type main,@function
        // Note: this is a type of directive
        // Never include in results, but is used to find and include functions
        static ref FUNCTION_REGEX: Regex = Regex::new(r"^\s+\.type\s*(.*),@function$").unwrap();
    }
    lazy_static! {
        // Example:    .p2align 4, 0x90
        // Note: this will also match entries found by DATA_REGEX and FUNCTION_REGEX
        // Never include in results
        static ref DIRECTIVE_REGEX: Regex = Regex::new(r"^\s+\..*[^:]$").unwrap();
    }
    lazy_static! {
        // Never include in results
        static ref BLANK_REGEX: Regex = Regex::new(r"^\s*$").unwrap();
    }

    let mut current_label = "";
    let mut line_info = Vec::new();
    let mut labels = HashSet::new();
    let mut opcode_operands = HashSet::new();
    let mut label_graph = DiGraphMap::new();

    // Note the type of data held on each line of the block
    for line in block.lines() {
        if OPCODE_REGEX.is_match(line) {
            line_info.push(Opcode);
            // Skip the opcode, just add operands
            for label_ref_cap in LABEL_REF_REGEX.captures_iter(line).skip(1).filter_map(|cap| cap.get(1)) {
                opcode_operands.insert(label_ref_cap.as_str());
            }
        } else if let Some(label_decl_cap) = LABEL_DECL_REGEX.captures(line).and_then(|cap| cap.get(1)) {
            line_info.push(LabelDecl(label_decl_cap.as_str()));
            labels.insert(label_decl_cap.as_str());
            current_label = label_decl_cap.as_str();
        } else if DATA_REGEX.is_match(line) && current_label != "" {
            line_info.push(Data(current_label));
            // These will be checked for references to other labels later on
            // Skip the data type, just capture its reference
            for label_ref_cap in LABEL_REF_REGEX.captures_iter(line).skip(1).filter_map(|cap| cap.get(1)) {
                // Create a graph of how data labels reference each other
                label_graph.add_edge(current_label, label_ref_cap.as_str(), 1);
            }
        } else if let Some(function_cap) = FUNCTION_REGEX.captures(line).and_then(|cap| cap.get(1)) {
            line_info.push(FunctionDecl);
            opcode_operands.insert(function_cap.as_str());
        // DIRECTIVE_REGEX must be checked after FUNCTION_REGEX and DATA_REGEX, matches them too
        } else if DIRECTIVE_REGEX.is_match(line) {
            line_info.push(Directive);
        } else if BLANK_REGEX.is_match(line) {
            line_info.push(Blank);
        // If no matches are found then include line in output
        } else {
            line_info.push(Misc);
        }
    }

    let mut data_labels = Vec::new();
    let mut used_labels: HashSet<_> = labels.intersection(&opcode_operands).collect();

    // We only include labels ref'd by data dirs if directly or indirectly used by an opcode
    for label in &used_labels {
        if label_graph.contains_node(label) {
            let mut label_search = Dfs::new(&label_graph, label);
            while let Some(next_label) = label_search.next(&label_graph) {
                data_labels.push(next_label);
            }
        }
    }

    used_labels.extend(&data_labels);

    let mut filtered_asm = String::new();
    for (line, line_type) in block.lines().zip(&line_info) {
        match *line_type {
            Opcode | Misc => {
                filtered_asm.push_str(line);
                filtered_asm.push('\n');
            },
            Data(data) if used_labels.contains(&data) => {
                filtered_asm.push_str(line);
                filtered_asm.push('\n');
            },
            LabelDecl(label) if used_labels.contains(&label) => {
                filtered_asm.push('\n');
                filtered_asm.push_str(line);
                filtered_asm.push('\n');
            },
            _ => (),
        }
    }

    filtered_asm
}

#[cfg(test)]
mod test {
    #[test]
    fn demangles() {
        assert_eq!(
            super::demangle_asm("_ZN4core3fmt9Arguments6new_v117h3c6f806acbe1ddabE"),
            "core::fmt::Arguments::new_v1");
        }

    #[test]
    fn many_demangles() {
        assert_eq!(
            super::demangle_asm(".section.text._ZN4core3fmt9Arguments6new_v117h3c6f806acbe1ddabE,\"ax\",@progbits\n .p2align4, 0x90\n .type_ZN4core3fmt9Arguments6new_v117h3c6f806acbe1ddabE,@function"),
            ".section.text.core::fmt::Arguments::new_v1,\"ax\",@progbits\n .p2align4, 0x90\n .typecore::fmt::Arguments::new_v1,@function");
        }

    #[test]
    fn demangle_pass_through() {
        assert_eq!(
            super::demangle_asm("push rbp\n mov rbp, rsp"),
            "push rbp\n mov rbp, rsp");
    }

    #[test]
    fn one_directive_removed() {
        assert_eq!(
            super::filter_asm("  .filesystem1 \"<println macros>\"\n  movq%rsp, %rbp\n"),
            "  movq%rsp, %rbp\n");
    }

    #[test]
    fn many_directives_removed() {
        assert_eq!(
            super::filter_asm(" .cfi_def_cfa_register %rbp\n subq$80, %rsp\n .text\n"),
            " subq$80, %rsp\n");
    }

    #[test]
    fn used_label_kept() {
        assert_eq!(
            super::filter_asm(".Lcfi0:\n  callq    .Lcfi0\n"),
            "\n.Lcfi0:\n  callq    .Lcfi0\n");
    }

    #[test]
    fn unused_label_removed() {
        assert_eq!(
        super::filter_asm("addq    $16, %rsp\n    popq    %rbp\n    retq\n.Lfunc_end31:\nstr.0:\n"),
        "addq    $16, %rsp\n    popq    %rbp\n    retq\n");
    }

    #[test]
    fn used_data_kept() {
        assert_eq!(super::filter_asm("ref.2:\n  .quad 1\n  jmp ref.2\n"),
        "\nref.2:\n  .quad 1\n  jmp ref.2\n")
    }

    #[test]
    fn unused_data_removed() {
        assert_eq!(super::filter_asm("str.0:\n  .ascii \"Hello, world\"\n  pop rbp\n"),
        "  pop rbp\n");
    }

    #[test]
    fn blank_lines_removed() {
        assert_eq!(super::filter_asm("  mov rbp, rsp\nmain:\n  jmp core::fmt::Arguments\n  \n"),
        "  mov rbp, rsp\n  jmp core::fmt::Arguments\n")
    }

    #[test]
    fn functions_kept() {
        assert_eq!(super::filter_asm("  .type main,@function\nmain:\n  pushq %rax\n"),
        "\nmain:\n  pushq %rax\n");
    }
    #[test]
    fn used_data_ref_label_kept() {
        assert_eq!(super::filter_asm(".Lcfi0:\n  .quad .Lcfi1\n  mov .Lcfi0\n.Lcfi1:\n  addq $16, %rsp\n"),
        "\n.Lcfi0:\n  .quad .Lcfi1\n  mov .Lcfi0\n\n.Lcfi1:\n  addq $16, %rsp\n");
    }
    #[test]
    fn unused_data_ref_label_removed() {
        assert_eq!(super::filter_asm(".Lcfi0:\n  .quad 1\n  mov .Lcfi0\n.Lcfi1:\n  addq $16, %rsp\n"),
        "\n.Lcfi0:\n  .quad 1\n  mov .Lcfi0\n  addq $16, %rsp\n");
    }
    #[test]
    fn used_data_ref_label_graph_walk() {
        assert_eq!(super::filter_asm("main:\n  .quad ref.1\n  mov main\nref.1:\n  .quad ref.2\nref.2:\n  .quad 1"),
        "\nmain:\n  .quad ref.1\n  mov main\n\nref.1:\n  .quad ref.2\n\nref.2:\n  .quad 1\n");
    }
    #[test]
    fn label_with_comment_recognized() {
        assert_eq!(super::filter_asm(".LBB6_10:  # =>Comment\n movq %r15, %rsi\n movq %rbx, %rdx\n ja .LBB6_10\n"),
        "\n.LBB6_10:  # =>Comment\n movq %r15, %rsi\n movq %rbx, %rdx\n ja .LBB6_10\n");
    }
    #[test]
    fn comment_retained() {
        assert_eq!(super::filter_asm("# %bb.0:\n subq $24, %rsp\n"),
        "# %bb.0:\n subq $24, %rsp\n")
    }
}

'''
'''--- ui/src/gist.rs ---
use hubcaps::{
    self,
    gists::{self, Content, GistOptions},
    Credentials, Github,
};
use std::collections::HashMap;

const FILENAME: &str = "playground.rs";
const DESCRIPTION: &str = "Code shared from the Rust Playground";

pub struct Gist {
    pub id: String,
    pub url: String,
    pub code: String,
}

impl From<gists::Gist> for Gist {
    fn from(other: gists::Gist) -> Self {
        let mut files: Vec<_> = other.files
            .into_iter()
            .map(|(name, file)| (name, file.content.unwrap_or_default()))
            .collect();

        files.sort_by(|(name1, _), (name2, _)| name1.cmp(name2));

        let code = match files.len() {
            0 | 1 => files.into_iter().map(|(_, content)| content).collect(),
            _ => {
                files
                    .into_iter()
                    .map(|(name, content)| format!("// {}\n{}\n\n", name, content))
                    .collect()
            }
        };

        Gist {
            id: other.id,
            url: other.html_url,
            code: code,
        }
    }
}

#[tokio::main]
pub async fn create(token: String, code: String) -> Gist {
    create_future(token, code)
        .await
        .expect("Unable to create gist")
    // TODO: Better reporting of failures
}

pub async fn create_future(token: String, code: String) -> hubcaps::Result<Gist> {
    let github = github(token)?;

    let file = Content {
        filename: None,
        content: code,
    };

    let mut files = HashMap::new();
    files.insert(FILENAME.into(), file);

    let options = GistOptions {
        description: Some(DESCRIPTION.into()),
        public: Some(false),
        files,
    };

    github
        .gists()
        .create(&options)
        .await
        .map(Into::into)
}

#[tokio::main]
pub async fn load(token: String, id: &str) -> Gist {
    load_future(token, id).await
        .expect("Unable to load gist")
    // TODO: Better reporting of a 404
}

pub async fn load_future(token: String, id: &str) -> hubcaps::Result<Gist> {
    let github = github(token)?;

    github
        .gists()
        .get(id)
        .await
        .map(Into::into)
}

fn github(token: String) -> hubcaps::Result<Github> {
    Github::new("The Rust Playground", Credentials::Token(token))
}

'''
'''--- ui/src/main.rs ---
#![deny(rust_2018_idioms)]

use corsware::{AllowedOrigins, CorsMiddleware, UniCase};
use iron::{
    headers::ContentType,
    method::Method::{Get, Post},
    modifiers::Header,
    prelude::*,
    status,
};
use lazy_static::lazy_static;
use mount::Mount;
use playground_middleware::{
    Cache, FileLogger, GuessContentType, ModifyWith, Prefix, Rewrite, Staticfile, StatisticLogger,
};
use prometheus::{Encoder, TextEncoder};
use router::Router;
use serde::{de::DeserializeOwned, Serialize, Deserialize};
use snafu::{ResultExt, Snafu};
use std::{
    any::Any,
    convert::{TryFrom, TryInto},
    env,
    path::PathBuf,
    sync::{Arc, Mutex},
    time::{Duration, Instant},
};

use crate::metrics::{track_metric, track_metric_force_endpoint, track_metric_no_request};
use crate::sandbox::Sandbox;

const DEFAULT_ADDRESS: &str = "127.0.0.1";
const DEFAULT_PORT: u16 = 5000;
const DEFAULT_LOG_FILE: &str = "access-log.csv";

mod asm_cleanup;
mod gist;
mod sandbox;

const ONE_HOUR_IN_SECONDS: u32 = 60 * 60;
const ONE_DAY_IN_SECONDS: u64 = 60 * 60 * 24;
const ONE_YEAR_IN_SECONDS: u64 = 60 * 60 * 24 * 365;

const SANDBOX_CACHE_TIME_TO_LIVE_IN_SECONDS: u64 = ONE_HOUR_IN_SECONDS as u64;

fn main() {
    // Dotenv may be unable to load environment variables, but that's ok in production
    let _ = dotenv::dotenv();
    openssl_probe::init_ssl_cert_env_vars();
    env_logger::init();

    let root: PathBuf = env::var_os("PLAYGROUND_UI_ROOT").expect("Must specify PLAYGROUND_UI_ROOT").into();
    let gh_token = env::var("PLAYGROUND_GITHUB_TOKEN").expect("Must specify PLAYGROUND_GITHUB_TOKEN");

    let address = env::var("PLAYGROUND_UI_ADDRESS").unwrap_or_else(|_| DEFAULT_ADDRESS.to_string());
    let port = env::var("PLAYGROUND_UI_PORT").ok().and_then(|p| p.parse().ok()).unwrap_or(DEFAULT_PORT);
    let logfile = env::var("PLAYGROUND_LOG_FILE").unwrap_or_else(|_| DEFAULT_LOG_FILE.to_string());
    let cors_enabled = env::var_os("PLAYGROUND_CORS_ENABLED").is_some();
    let metrics_token = env::var("PLAYGROUND_METRICS_TOKEN").ok();

    let files = Staticfile::new(&root).expect("Unable to open root directory");
    let mut files = Chain::new(files);
    let one_day = Duration::new(ONE_DAY_IN_SECONDS, 0);
    let one_year = Duration::new(ONE_YEAR_IN_SECONDS, 0);

    files.link_after(ModifyWith::new(Cache::new(one_day)));
    files.link_after(Prefix::new(&["assets"], Cache::new(one_year)));
    files.link_after(GuessContentType::new(ContentType::html().0));

    let mut gist_router = Router::new();
    gist_router.post("/", meta_gist_create, "gist_create");
    gist_router.get("/:id", meta_gist_get, "gist_get");

    let mut mount = Mount::new();
    mount.mount("/", files);
    mount.mount("/compile", compile);
    mount.mount("/execute", execute);
    mount.mount("/format", format);
    mount.mount("/clippy", clippy);
    mount.mount("/miri", miri);
    mount.mount("/macro-expansion", macro_expansion);
    mount.mount("/meta/crates", meta_crates);
    mount.mount("/meta/version/stable", meta_version_stable);
    mount.mount("/meta/version/beta", meta_version_beta);
    mount.mount("/meta/version/nightly", meta_version_nightly);
    mount.mount("/meta/version/rustfmt", meta_version_rustfmt);
    mount.mount("/meta/version/clippy", meta_version_clippy);
    mount.mount("/meta/version/miri", meta_version_miri);
    mount.mount("/meta/gist", gist_router);
    mount.mount("/evaluate.json", evaluate);

    mount.mount("/metrics", metrics);

    let mut chain = Chain::new(mount);
    let file_logger = FileLogger::new(logfile).expect("Unable to create file logger");
    let logger = StatisticLogger::new(file_logger);
    let rewrite = Rewrite::new(vec![vec!["help".into()]], "/index.html".into());
    let gh_token = GhToken::new(gh_token);

    chain.link_around(logger);
    chain.link_before(rewrite);
    chain.link_before(gh_token);

    if let Some(metrics_token) = metrics_token {
        let metrics_token = MetricsToken::new(metrics_token);
        chain.link_before(metrics_token);
    }

    if cors_enabled {
        chain.link_around(CorsMiddleware {
            // A null origin occurs when you make a request from a
            // page hosted on a filesystem, such as when you read the
            // Rust book locally
            allowed_origins: AllowedOrigins::Any { allow_null: true },
            allowed_headers: vec![UniCase("Content-Type".to_owned())],
            allowed_methods: vec![Get, Post],
            exposed_headers: vec![],
            allow_credentials: false,
            max_age_seconds: ONE_HOUR_IN_SECONDS,
            prefer_wildcard: true,
        });
    }

    log::info!("Starting the server on http://{}:{}", address, port);
    Iron::new(chain).http((&*address, port)).expect("Unable to start server");
}

#[derive(Debug, Clone)]
struct GhToken(Arc<String>);

impl GhToken {
    fn new(token: String) -> Self {
        GhToken(Arc::new(token))
    }
}

impl iron::BeforeMiddleware for GhToken {
    fn before(&self, req: &mut Request<'_, '_>) -> IronResult<()> {
        req.extensions.insert::<Self>(self.clone());
        Ok(())
    }
}

impl iron::typemap::Key for GhToken {
    type Value = Self;
}

#[derive(Debug, Clone)]
struct MetricsToken(Arc<String>);

impl MetricsToken {
    fn new(token: String) -> Self {
        MetricsToken(Arc::new(token))
    }
}

impl iron::BeforeMiddleware for MetricsToken {
    fn before(&self, req: &mut Request<'_, '_>) -> IronResult<()> {
        req.extensions.insert::<Self>(self.clone());
        Ok(())
    }
}

impl iron::typemap::Key for MetricsToken {
    type Value = Self;
}

fn compile(req: &mut Request<'_, '_>) -> IronResult<Response> {
    with_sandbox(req, |sandbox, req: CompileRequest| {
        let req = req.try_into()?;
        track_metric(req, |req| sandbox.compile(&req))
            .map(CompileResponse::from)
            .context(Compilation)
    })
}

fn execute(req: &mut Request<'_, '_>) -> IronResult<Response> {
    with_sandbox(req, |sandbox, req: ExecuteRequest| {
        let req = req.try_into()?;
        track_metric(req, |req| sandbox.execute(&req))
            .map(ExecuteResponse::from)
            .context(Execution)
    })
}

fn format(req: &mut Request<'_, '_>) -> IronResult<Response> {
    with_sandbox(req, |sandbox, req: FormatRequest| {
        let req = req.try_into()?;
        track_metric(req, |req| sandbox.format(&req))
            .map(FormatResponse::from)
            .context(Formatting)
    })
}

fn clippy(req: &mut Request<'_, '_>) -> IronResult<Response> {
    with_sandbox(req, |sandbox, req: ClippyRequest| {
        let req = req.try_into()?;
        track_metric(req, |req| sandbox.clippy(&req))
            .map(ClippyResponse::from)
            .context(Linting)
    })
}

fn miri(req: &mut Request<'_, '_>) -> IronResult<Response> {
    with_sandbox(req, |sandbox, req: MiriRequest| {
        let req = req.try_into()?;
        track_metric(req, |req| sandbox.miri(&req))
            .map(MiriResponse::from)
            .context(Interpreting)
    })
}

fn macro_expansion(req: &mut Request<'_, '_>) -> IronResult<Response> {
    with_sandbox(req, |sandbox, req: MacroExpansionRequest| {
        let req = req.try_into()?;
        track_metric(req, |req| sandbox.macro_expansion(&req))
            .map(MacroExpansionResponse::from)
            .context(Expansion)
    })
}

fn meta_crates(_req: &mut Request<'_, '_>) -> IronResult<Response> {
    with_sandbox_no_request(|sandbox| {
        track_metric_no_request(metrics::Endpoint::MetaCrates, || cached(sandbox).crates())
            .map(MetaCratesResponse::from)
    })
}

fn meta_version_stable(_req: &mut Request<'_, '_>) -> IronResult<Response> {
    with_sandbox_no_request(|sandbox| {
        track_metric_no_request(metrics::Endpoint::MetaVersionStable, || {
            cached(sandbox).version_stable()
        })
        .map(MetaVersionResponse::from)
    })
}

fn meta_version_beta(_req: &mut Request<'_, '_>) -> IronResult<Response> {
    with_sandbox_no_request(|sandbox| {
        track_metric_no_request(metrics::Endpoint::MetaVersionBeta, || {
            cached(sandbox).version_beta()
        })
        .map(MetaVersionResponse::from)
    })
}

fn meta_version_nightly(_req: &mut Request<'_, '_>) -> IronResult<Response> {
    with_sandbox_no_request(|sandbox| {
        track_metric_no_request(metrics::Endpoint::MetaVersionNightly, || {
            cached(sandbox).version_nightly()
        })
        .map(MetaVersionResponse::from)
    })
}

fn meta_version_rustfmt(_req: &mut Request<'_, '_>) -> IronResult<Response> {
    with_sandbox_no_request(|sandbox| {
        track_metric_no_request(metrics::Endpoint::MetaVersionRustfmt, || {
            cached(sandbox).version_rustfmt()
        })
        .map(MetaVersionResponse::from)
    })
}

fn meta_version_clippy(_req: &mut Request<'_, '_>) -> IronResult<Response> {
    with_sandbox_no_request(|sandbox| {
        track_metric_no_request(metrics::Endpoint::MetaVersionClippy, || {
            cached(sandbox).version_clippy()
        })
        .map(MetaVersionResponse::from)
    })
}

fn meta_version_miri(_req: &mut Request<'_, '_>) -> IronResult<Response> {
    with_sandbox_no_request(|sandbox| {
        track_metric_no_request(metrics::Endpoint::MetaVersionMiri, || {
            cached(sandbox).version_miri()
        })
        .map(MetaVersionResponse::from)
    })
}

fn meta_gist_create(req: &mut Request<'_, '_>) -> IronResult<Response> {
    let token = req.extensions.get::<GhToken>().unwrap().0.as_ref().clone();
    serialize_to_response(deserialize_from_request(req, |r: MetaGistCreateRequest| {
        let gist = gist::create(token, r.code);
        Ok(MetaGistResponse::from(gist))
    }))
}

fn meta_gist_get(req: &mut Request<'_, '_>) -> IronResult<Response> {
    match req.extensions.get::<Router>().unwrap().find("id") {
        Some(id) => {
            let token = req.extensions.get::<GhToken>().unwrap().0.as_ref().clone();
            let gist = gist::load(token, id);
            serialize_to_response(Ok(MetaGistResponse::from(gist)))
        }
        None => {
            Ok(Response::with(status::UnprocessableEntity))
        }
    }
}

// This is a backwards compatibilty shim. The Rust homepage and the
// documentation use this to run code in place.
fn evaluate(req: &mut Request<'_, '_>) -> IronResult<Response> {
    with_sandbox(req, |sandbox, req: EvaluateRequest| {
        let req = req.try_into()?;
        track_metric_force_endpoint(req, metrics::Endpoint::Evaluate, |req| {
            sandbox.execute(&req)
        })
        .map(EvaluateResponse::from)
        .context(Evaluation)
    })
}

fn with_sandbox<Req, Resp, F>(req: &mut Request<'_, '_>, f: F) -> IronResult<Response>
where
    F: FnOnce(Sandbox, Req) -> Result<Resp>,
    Req: DeserializeOwned + Clone + Any + 'static,
    Resp: Serialize,
{
    serialize_to_response(run_handler(req, f))
}

fn with_sandbox_no_request<Resp, F>(f: F) -> IronResult<Response>
where
    F: FnOnce(Sandbox) -> Result<Resp>,
    Resp: Serialize,
{
    serialize_to_response(run_handler_no_request(f))
}

fn run_handler<Req, Resp, F>(req: &mut Request<'_, '_>, f: F) -> Result<Resp>
where
    F: FnOnce(Sandbox, Req) -> Result<Resp>,
    Req: DeserializeOwned + Clone + Any + 'static,
{
    deserialize_from_request(req, |req| {
        let sandbox = Sandbox::new().context(SandboxCreation)?;
        f(sandbox, req)
    })
}

fn deserialize_from_request<Req, Resp, F>(req: &mut Request<'_, '_>, f: F) -> Result<Resp>
where
    F: FnOnce(Req) -> Result<Resp>,
    Req: DeserializeOwned + Clone + Any + 'static,
{
    let body = req.get::<bodyparser::Struct<Req>>()
        .context(Deserialization)?;

    let req = body.ok_or(Error::RequestMissing)?;

    let resp = f(req)?;

    Ok(resp)
}

fn run_handler_no_request<Resp, F>(f: F) -> Result<Resp>
where
    F: FnOnce(Sandbox) -> Result<Resp>,
{
    let sandbox = Sandbox::new().context(SandboxCreation)?;
    let resp = f(sandbox)?;
    Ok(resp)
}

fn serialize_to_response<Resp>(response: Result<Resp>) -> IronResult<Response>
where
    Resp: Serialize,
{
    let response = response.and_then(|resp| {
        let resp = serde_json::ser::to_string(&resp).context(Serialization)?;
        Ok(resp)
    });

    match response {
        Ok(body) => Ok(Response::with((status::Ok, Header(ContentType::json()), body))),
        Err(err) => {
            let err = ErrorJson { error: err.to_string() };
            match serde_json::ser::to_string(&err) {
                Ok(error_str) => Ok(Response::with((status::InternalServerError, Header(ContentType::json()), error_str))),
                Err(_) => Ok(Response::with((status::InternalServerError, Header(ContentType::json()), FATAL_ERROR_JSON))),
            }
        },
    }
}

#[derive(Debug, Clone)]
struct SandboxCacheInfo<T> {
    value: T,
    time: Instant,
}

/// Caches the success value of a single operation
#[derive(Debug)]
struct SandboxCacheOne<T>(Mutex<Option<SandboxCacheInfo<T>>>);

impl<T> Default for SandboxCacheOne<T> {
    fn default() -> Self { SandboxCacheOne(Mutex::default()) }
}

impl<T> SandboxCacheOne<T>
where
    T: Clone
{
    fn clone_or_populate<F>(&self, populator: F) -> Result<T>
    where
        F: FnOnce() -> sandbox::Result<T>
    {
        let mut cache = self.0.lock().map_err(|_| Error::CachePoisoned)?;

        match cache.clone() {
            Some(cached) => {
                if cached.time.elapsed() > Duration::from_secs(SANDBOX_CACHE_TIME_TO_LIVE_IN_SECONDS) {
                    SandboxCacheOne::populate(&mut *cache, populator)
                } else {
                    Ok(cached.value)
                }
            },
            None => {
                SandboxCacheOne::populate(&mut *cache, populator)
            }
        }
    }

    fn populate<F>(cache: &mut Option<SandboxCacheInfo<T>>, populator: F) -> Result<T>
    where
        F: FnOnce() -> sandbox::Result<T>
    {
        let value = populator().context(Caching)?;
        *cache = Some(SandboxCacheInfo {
            value: value.clone(),
            time: Instant::now(),
        });
        Ok(value)
    }
}

/// Caches the successful results of all sandbox operations that make
/// sense to cache.
#[derive(Debug, Default)]
struct SandboxCache {
    crates: SandboxCacheOne<Vec<sandbox::CrateInformation>>,
    version_stable: SandboxCacheOne<sandbox::Version>,
    version_beta: SandboxCacheOne<sandbox::Version>,
    version_nightly: SandboxCacheOne<sandbox::Version>,
    version_clippy: SandboxCacheOne<sandbox::Version>,
    version_rustfmt: SandboxCacheOne<sandbox::Version>,
    version_miri: SandboxCacheOne<sandbox::Version>,
}

/// Provides a similar API to the Sandbox that caches the successful results.
struct CachedSandbox<'a> {
    sandbox: Sandbox,
    cache: &'a SandboxCache,
}

impl<'a> CachedSandbox<'a> {
    fn crates(&self) -> Result<Vec<sandbox::CrateInformation>> {
        self.cache.crates.clone_or_populate(|| self.sandbox.crates())
    }

    fn version_stable(&self) -> Result<sandbox::Version> {
        self.cache.version_stable.clone_or_populate(|| {
            self.sandbox.version(sandbox::Channel::Stable)
        })
    }

    fn version_beta(&self) -> Result<sandbox::Version> {
        self.cache.version_beta.clone_or_populate(|| {
            self.sandbox.version(sandbox::Channel::Beta)
        })
    }

    fn version_nightly(&self) -> Result<sandbox::Version> {
        self.cache.version_nightly.clone_or_populate(|| {
            self.sandbox.version(sandbox::Channel::Nightly)
        })
    }

    fn version_clippy(&self) -> Result<sandbox::Version> {
        self.cache.version_clippy.clone_or_populate(|| {
            self.sandbox.version_clippy()
        })
    }

    fn version_rustfmt(&self) -> Result<sandbox::Version> {
        self.cache.version_rustfmt.clone_or_populate(|| {
            self.sandbox.version_rustfmt()
        })
    }

    fn version_miri(&self) -> Result<sandbox::Version> {
        self.cache.version_miri.clone_or_populate(|| {
            self.sandbox.version_miri()
        })
    }
}

/// A convenience constructor
fn cached(sandbox: Sandbox) -> CachedSandbox<'static> {
    lazy_static! {
        static ref SANDBOX_CACHE: SandboxCache = Default::default();
    }

    CachedSandbox {
        sandbox,
        cache: &SANDBOX_CACHE,
    }
}

mod metrics {
    use lazy_static::lazy_static;
    use prometheus::{self, register_histogram_vec, HistogramVec};
    use regex::Regex;
    use std::time::Instant;

    use crate::sandbox::{self, Channel, CompileTarget, CrateType, Edition, Mode};

    lazy_static! {
        pub(crate) static ref REQUESTS: HistogramVec = register_histogram_vec!(
            "playground_request_duration_seconds",
            "Number of requests made",
            Labels::LABELS,
            vec![0.1, 1.0, 2.5, 5.0, 10.0, 15.0]
        )
        .unwrap();
    }

    #[derive(Debug, Copy, Clone, strum::IntoStaticStr)]
    pub(crate) enum Endpoint {
        Compile,
        Execute,
        Format,
        Miri,
        Clippy,
        MacroExpansion,
        MetaCrates,
        MetaVersionStable,
        MetaVersionBeta,
        MetaVersionNightly,
        MetaVersionRustfmt,
        MetaVersionClippy,
        MetaVersionMiri,
        Evaluate,
    }

    #[derive(Debug, Copy, Clone, strum::IntoStaticStr)]
    pub(crate) enum Outcome {
        Success,
        ErrorServer,
        ErrorTimeoutSoft,
        ErrorTimeoutHard,
        ErrorUserCode,
    }

    #[derive(Debug, Copy, Clone)]
    pub(crate) struct Labels {
        endpoint: Endpoint,
        outcome: Outcome,

        target: Option<CompileTarget>,
        channel: Option<Channel>,
        mode: Option<Mode>,
        edition: Option<Option<Edition>>,
        crate_type: Option<CrateType>,
        tests: Option<bool>,
        backtrace: Option<bool>,
    }

    impl Labels {
        const COUNT: usize = 9;

        const LABELS: &'static [&'static str; Self::COUNT] = &[
            "endpoint",
            "outcome",
            "target",
            "channel",
            "mode",
            "edition",
            "crate_type",
            "tests",
            "backtrace",
        ];

        fn to_values(&self) -> [&'static str; Self::COUNT] {
            let Self {
                endpoint,
                outcome,
                target,
                channel,
                mode,
                edition,
                crate_type,
                tests,
                backtrace,
            } = *self;

            fn b(v: Option<bool>) -> &'static str {
                v.map_or("", |v| if v { "true" } else { "false" })
            }

            let target = target.map_or("", Into::into);
            let channel = channel.map_or("", Into::into);
            let mode = mode.map_or("", Into::into);
            let edition = match edition {
                None => "",
                Some(None) => "Unspecified",
                Some(Some(v)) => v.into(),
            };
            let crate_type = crate_type.map_or("", Into::into);
            let tests = b(tests);
            let backtrace = b(backtrace);

            [
                endpoint.into(),
                outcome.into(),
                target,
                channel,
                mode,
                edition,
                crate_type,
                tests,
                backtrace,
            ]
        }
    }

    pub(crate) trait GenerateLabels {
        fn generate_labels(&self, outcome: Outcome) -> Labels;
    }

    impl<T> GenerateLabels for &'_ T
    where
        T: GenerateLabels,
    {
        fn generate_labels(&self, outcome: Outcome) -> Labels {
            T::generate_labels(self, outcome)
        }
    }

    impl GenerateLabels for sandbox::CompileRequest {
        fn generate_labels(&self, outcome: Outcome) -> Labels {
            let Self {
                target,
                channel,
                crate_type,
                mode,
                edition,
                tests,
                backtrace,
                code: _,
            } = *self;

            Labels {
                endpoint: Endpoint::Compile,
                outcome,

                target: Some(target),
                channel: Some(channel),
                mode: Some(mode),
                edition: Some(edition),
                crate_type: Some(crate_type),
                tests: Some(tests),
                backtrace: Some(backtrace),
            }
        }
    }

    impl GenerateLabels for sandbox::ExecuteRequest {
        fn generate_labels(&self, outcome: Outcome) -> Labels {
            let Self {
                channel,
                mode,
                edition,
                crate_type,
                tests,
                backtrace,
                code: _,
            } = *self;

            Labels {
                endpoint: Endpoint::Execute,
                outcome,

                target: None,
                channel: Some(channel),
                mode: Some(mode),
                edition: Some(edition),
                crate_type: Some(crate_type),
                tests: Some(tests),
                backtrace: Some(backtrace),
            }
        }
    }

    impl GenerateLabels for sandbox::FormatRequest {
        fn generate_labels(&self, outcome: Outcome) -> Labels {
            let Self { edition, code: _ } = *self;

            Labels {
                endpoint: Endpoint::Format,
                outcome,

                target: None,
                channel: None,
                mode: None,
                edition: Some(edition),
                crate_type: None,
                tests: None,
                backtrace: None,
            }
        }
    }

    impl GenerateLabels for sandbox::ClippyRequest {
        fn generate_labels(&self, outcome: Outcome) -> Labels {
            let Self {
                code: _,
                edition,
                crate_type,
            } = *self;

            Labels {
                endpoint: Endpoint::Clippy,
                outcome,

                target: None,
                channel: None,
                mode: None,
                edition: Some(edition),
                crate_type: Some(crate_type),
                tests: None,
                backtrace: None,
            }
        }
    }

    impl GenerateLabels for sandbox::MiriRequest {
        fn generate_labels(&self, outcome: Outcome) -> Labels {
            let Self { code: _, edition } = *self;

            Labels {
                endpoint: Endpoint::Miri,
                outcome,

                target: None,
                channel: None,
                mode: None,
                edition: Some(edition),
                crate_type: None,
                tests: None,
                backtrace: None,
            }
        }
    }

    impl GenerateLabels for sandbox::MacroExpansionRequest {
        fn generate_labels(&self, outcome: Outcome) -> Labels {
            let Self { code: _, edition } = *self;

            Labels {
                endpoint: Endpoint::MacroExpansion,
                outcome,

                target: None,
                channel: None,
                mode: None,
                edition: Some(edition),
                crate_type: None,
                tests: None,
                backtrace: None,
            }
        }
    }

    pub(crate) trait SuccessDetails: Sized {
        fn success_details(&self) -> Outcome;

        fn for_sandbox_result(r: &Result<Self, sandbox::Error>) -> Outcome {
            use sandbox::Error::*;

            match r {
                Ok(v) => v.success_details(),
                Err(CompilerExecutionTimedOut { .. }) => Outcome::ErrorTimeoutHard,
                Err(_) => Outcome::ErrorServer,
            }
        }
    }

    fn common_success_details(success: bool, stderr: &str) -> Outcome {
        lazy_static! {
            // Memory allocation failures are "Aborted"
            static ref SOFT_TIMEOUT_REGEX: Regex = Regex::new("entrypoint.sh.*Killed.*timeout").unwrap();
        }

        match success {
            true => Outcome::Success,
            false => {
                if stderr
                    .lines()
                    .next_back()
                    .map_or(false, |l| SOFT_TIMEOUT_REGEX.is_match(l))
                {
                    Outcome::ErrorTimeoutSoft
                } else {
                    Outcome::ErrorUserCode
                }
            }
        }
    }

    impl SuccessDetails for sandbox::CompileResponse {
        fn success_details(&self) -> Outcome {
            common_success_details(self.success, &self.stderr)
        }
    }

    impl SuccessDetails for sandbox::ExecuteResponse {
        fn success_details(&self) -> Outcome {
            common_success_details(self.success, &self.stderr)
        }
    }

    impl SuccessDetails for sandbox::FormatResponse {
        fn success_details(&self) -> Outcome {
            common_success_details(self.success, &self.stderr)
        }
    }

    impl SuccessDetails for sandbox::ClippyResponse {
        fn success_details(&self) -> Outcome {
            common_success_details(self.success, &self.stderr)
        }
    }

    impl SuccessDetails for sandbox::MiriResponse {
        fn success_details(&self) -> Outcome {
            common_success_details(self.success, &self.stderr)
        }
    }

    impl SuccessDetails for sandbox::MacroExpansionResponse {
        fn success_details(&self) -> Outcome {
            common_success_details(self.success, &self.stderr)
        }
    }

    impl SuccessDetails for Vec<sandbox::CrateInformation> {
        fn success_details(&self) -> Outcome {
            Outcome::Success
        }
    }

    impl SuccessDetails for sandbox::Version {
        fn success_details(&self) -> Outcome {
            Outcome::Success
        }
    }

    pub(crate) fn track_metric<Req, B, Resp>(request: Req, body: B) -> sandbox::Result<Resp>
    where
        Req: GenerateLabels,
        B: FnOnce(&Req) -> sandbox::Result<Resp>,
        Resp: SuccessDetails,
    {
        track_metric_common(request, body, |_| {})
    }

    pub(crate) fn track_metric_force_endpoint<Req, B, Resp>(
        request: Req,
        endpoint: Endpoint,
        body: B,
    ) -> sandbox::Result<Resp>
    where
        Req: GenerateLabels,
        B: FnOnce(&Req) -> sandbox::Result<Resp>,
        Resp: SuccessDetails,
    {
        track_metric_common(request, body, |labels| labels.endpoint = endpoint)
    }

    fn track_metric_common<Req, B, Resp, F>(request: Req, body: B, f: F) -> sandbox::Result<Resp>
    where
        Req: GenerateLabels,
        B: FnOnce(&Req) -> sandbox::Result<Resp>,
        Resp: SuccessDetails,
        F: FnOnce(&mut Labels),
    {
        let start = Instant::now();
        let response = body(&request);
        let elapsed = start.elapsed();

        let outcome = SuccessDetails::for_sandbox_result(&response);
        let mut labels = request.generate_labels(outcome);
        f(&mut labels);
        let values = &labels.to_values();

        let histogram = REQUESTS.with_label_values(values);

        histogram.observe(elapsed.as_secs_f64());

        response
    }

    pub(crate) fn track_metric_no_request<B, Resp>(
        endpoint: Endpoint,
        body: B,
    ) -> crate::Result<Resp>
    where
        B: FnOnce() -> crate::Result<Resp>,
    {
        let start = Instant::now();
        let response = body();
        let elapsed = start.elapsed();

        let outcome = if response.is_ok() {
            Outcome::Success
        } else {
            Outcome::ErrorServer
        };
        let labels = Labels {
            endpoint,
            outcome,
            target: None,
            channel: None,
            mode: None,
            edition: None,
            crate_type: None,
            tests: None,
            backtrace: None,
        };
        let values = &labels.to_values();
        let histogram = REQUESTS.with_label_values(values);

        histogram.observe(elapsed.as_secs_f64());

        response
    }
}

fn authorized_for_metrics(req: &mut Request<'_, '_>) -> bool {
    use iron::headers::{Authorization, Bearer};

    // If not configured, allow it to be public
    let token = match req.extensions.get::<MetricsToken>() {
        Some(token) => token,
        None => return true,
    };

    let authorization = match req.headers.get::<Authorization<Bearer>>() {
        Some(a) => a,
        None => return false,
    };

    authorization.0.token.as_str() == token.0.as_str()
}

fn metrics(req: &mut Request<'_, '_>) -> IronResult<Response> {
    if !authorized_for_metrics(req) {
        return Ok(Response::with((status::Unauthorized, "Unauthorized")));
    }

    let metric_families = prometheus::gather();
    let encoder = TextEncoder::new();
    let mut buffer = Vec::new();

    encoder.encode(&metric_families, &mut buffer).unwrap();

    Ok(Response::with((status::Ok, buffer)))
}

#[derive(Debug, Snafu)]
pub enum Error {
    #[snafu(display("Sandbox creation failed: {}", source))]
    SandboxCreation { source: sandbox::Error },
    #[snafu(display("Compilation operation failed: {}", source))]
    Compilation { source: sandbox::Error },
    #[snafu(display("Execution operation failed: {}", source))]
    Execution { source: sandbox::Error },
    #[snafu(display("Evaluation operation failed: {}", source))]
    Evaluation { source: sandbox::Error },
    #[snafu(display("Linting operation failed: {}", source))]
    Linting { source: sandbox::Error },
    #[snafu(display("Expansion operation failed: {}", source))]
    Expansion { source: sandbox::Error },
    #[snafu(display("Formatting operation failed: {}", source))]
    Formatting { source: sandbox::Error },
    #[snafu(display("Interpreting operation failed: {}", source))]
    Interpreting { source: sandbox::Error },
    #[snafu(display("Caching operation failed: {}", source))]
    Caching { source: sandbox::Error },
    #[snafu(display("Unable to serialize response: {}", source))]
    Serialization { source: serde_json::Error },
    #[snafu(display("Unable to deserialize request: {}", source))]
    Deserialization { source: bodyparser::BodyError },
    #[snafu(display("The value {:?} is not a valid target", value))]
    InvalidTarget { value: String },
    #[snafu(display("The value {:?} is not a valid assembly flavor", value))]
    InvalidAssemblyFlavor { value: String },
    #[snafu(display("The value {:?} is not a valid demangle option", value))]
    InvalidDemangleAssembly { value: String },
    #[snafu(display("The value {:?} is not a valid assembly processing option", value))]
    InvalidProcessAssembly { value: String },
    #[snafu(display("The value {:?} is not a valid channel", value,))]
    InvalidChannel { value: String },
    #[snafu(display("The value {:?} is not a valid mode", value))]
    InvalidMode { value: String },
    #[snafu(display("The value {:?} is not a valid edition", value))]
    InvalidEdition { value: String },
    #[snafu(display("The value {:?} is not a valid crate type", value))]
    InvalidCrateType { value: String },
    #[snafu(display("No request was provided"))]
    RequestMissing,
    #[snafu(display("The cache has been poisoned"))]
    CachePoisoned,
}

type Result<T, E = Error> = ::std::result::Result<T, E>;

const FATAL_ERROR_JSON: &str =
    r#"{"error": "Multiple cascading errors occurred, abandon all hope"}"#;

#[derive(Debug, Clone, Serialize)]
struct ErrorJson {
    error: String,
}

#[derive(Debug, Clone, Deserialize)]
struct CompileRequest {
    target: String,
    #[serde(rename = "assemblyFlavor")]
    assembly_flavor: Option<String>,
    #[serde(rename = "demangleAssembly")]
    demangle_assembly: Option<String>,
    #[serde(rename = "processAssembly")]
    process_assembly: Option<String>,
    channel: String,
    mode: String,
    #[serde(default)]
    edition: String,
    #[serde(rename = "crateType")]
    crate_type: String,
    tests: bool,
    #[serde(default)]
    backtrace: bool,
    code: String,
}

#[derive(Debug, Clone, Serialize)]
struct CompileResponse {
    success: bool,
    code: String,
    stdout: String,
    stderr: String,
}

#[derive(Debug, Clone, Deserialize)]
struct ExecuteRequest {
    channel: String,
    mode: String,
    #[serde(default)]
    edition: String,
    #[serde(rename = "crateType")]
    crate_type: String,
    tests: bool,
    #[serde(default)]
    backtrace: bool,
    code: String,
}

#[derive(Debug, Clone, Serialize)]
struct ExecuteResponse {
    success: bool,
    stdout: String,
    stderr: String,
}

#[derive(Debug, Clone, Deserialize)]
struct FormatRequest {
    code: String,
    #[serde(default)]
    edition: String,
}

#[derive(Debug, Clone, Serialize)]
struct FormatResponse {
    success: bool,
    code: String,
    stdout: String,
    stderr: String,
}

#[derive(Debug, Clone, Deserialize)]
struct ClippyRequest {
    code: String,
    #[serde(default)]
    edition: String,
    #[serde(default = "default_crate_type", rename = "crateType")]
    crate_type: String,
}

#[derive(Debug, Clone, Serialize)]
struct ClippyResponse {
    success: bool,
    stdout: String,
    stderr: String,
}

#[derive(Debug, Clone, Deserialize)]
struct MiriRequest {
    code: String,
    #[serde(default)]
    edition: String,
}

#[derive(Debug, Clone, Serialize)]
struct MiriResponse {
    success: bool,
    stdout: String,
    stderr: String,
}

#[derive(Debug, Clone, Deserialize)]
struct MacroExpansionRequest {
    code: String,
    #[serde(default)]
    edition: String,
}

#[derive(Debug, Clone, Serialize)]
struct MacroExpansionResponse {
    success: bool,
    stdout: String,
    stderr: String,
}

#[derive(Debug, Clone, Serialize)]
struct CrateInformation {
    name: String,
    version: String,
    id: String,
}

#[derive(Debug, Clone, Serialize)]
struct MetaCratesResponse {
    crates: Vec<CrateInformation>,
}

#[derive(Debug, Clone, Serialize)]
struct MetaVersionResponse {
    version: String,
    hash: String,
    date: String,
}

#[derive(Debug, Clone, Deserialize)]
struct MetaGistCreateRequest {
    code: String,
}

#[derive(Debug, Clone, Serialize)]
struct MetaGistResponse {
    id: String,
    url: String,
    code: String,
}

#[derive(Debug, Clone, Deserialize)]
struct EvaluateRequest {
    version: String,
    optimize: String,
    code: String,
    #[serde(default)]
    edition: String,
    #[serde(default)]
    tests: bool,
}

#[derive(Debug, Clone, Serialize)]
struct EvaluateResponse {
    result: String,
    error: Option<String>,
}

impl TryFrom<CompileRequest> for sandbox::CompileRequest {
    type Error = Error;

    fn try_from(me: CompileRequest) -> Result<Self> {
        let target = parse_target(&me.target)?;
        let assembly_flavor = match me.assembly_flavor {
            Some(f) => Some(parse_assembly_flavor(&f)?),
            None => None,
        };

        let demangle = match me.demangle_assembly {
            Some(f) => Some(parse_demangle_assembly(&f)?),
            None => None,
        };

        let process_assembly = match me.process_assembly {
            Some(f) => Some(parse_process_assembly(&f)?),
            None => None,
        };

        let target = match (target, assembly_flavor, demangle, process_assembly) {
            (sandbox::CompileTarget::Assembly(_, _, _), Some(flavor), Some(demangle), Some(process)) =>
                sandbox::CompileTarget::Assembly(flavor, demangle, process),
            _ => target,
        };

        Ok(sandbox::CompileRequest {
            target,
            channel: parse_channel(&me.channel)?,
            mode: parse_mode(&me.mode)?,
            edition: parse_edition(&me.edition)?,
            crate_type: parse_crate_type(&me.crate_type)?,
            tests: me.tests,
            backtrace: me.backtrace,
            code: me.code,
        })
    }
}

impl From<sandbox::CompileResponse> for CompileResponse {
    fn from(me: sandbox::CompileResponse) -> Self {
        CompileResponse {
            success: me.success,
            code: me.code,
            stdout: me.stdout,
            stderr: me.stderr,
        }
    }
}

impl TryFrom<ExecuteRequest> for sandbox::ExecuteRequest {
    type Error = Error;

    fn try_from(me: ExecuteRequest) -> Result<Self> {
        Ok(sandbox::ExecuteRequest {
            channel: parse_channel(&me.channel)?,
            mode: parse_mode(&me.mode)?,
            edition: parse_edition(&me.edition)?,
            crate_type: parse_crate_type(&me.crate_type)?,
            tests: me.tests,
            backtrace: me.backtrace,
            code: me.code,
        })
    }
}

impl From<sandbox::ExecuteResponse> for ExecuteResponse {
    fn from(me: sandbox::ExecuteResponse) -> Self {
        ExecuteResponse {
            success: me.success,
            stdout: me.stdout,
            stderr: me.stderr,
        }
    }
}

impl TryFrom<FormatRequest> for sandbox::FormatRequest {
    type Error = Error;

    fn try_from(me: FormatRequest) -> Result<Self> {
        Ok(sandbox::FormatRequest {
            code: me.code,
            edition: parse_edition(&me.edition)?,
        })
    }
}

impl From<sandbox::FormatResponse> for FormatResponse {
    fn from(me: sandbox::FormatResponse) -> Self {
        FormatResponse {
            success: me.success,
            code: me.code,
            stdout: me.stdout,
            stderr: me.stderr,
        }
    }
}

impl TryFrom<ClippyRequest> for sandbox::ClippyRequest {
    type Error = Error;

    fn try_from(me: ClippyRequest) -> Result<Self> {
        Ok(sandbox::ClippyRequest {
            code: me.code,
            crate_type: parse_crate_type(&me.crate_type)?,
            edition: parse_edition(&me.edition)?,
        })
    }
}

impl From<sandbox::ClippyResponse> for ClippyResponse {
    fn from(me: sandbox::ClippyResponse) -> Self {
        ClippyResponse {
            success: me.success,
            stdout: me.stdout,
            stderr: me.stderr,
        }
    }
}

impl TryFrom<MiriRequest> for sandbox::MiriRequest {
    type Error = Error;

    fn try_from(me: MiriRequest) -> Result<Self> {
        Ok(sandbox::MiriRequest {
            code: me.code,
            edition: parse_edition(&me.edition)?,
        })
    }
}

impl From<sandbox::MiriResponse> for MiriResponse {
    fn from(me: sandbox::MiriResponse) -> Self {
        MiriResponse {
            success: me.success,
            stdout: me.stdout,
            stderr: me.stderr,
        }
    }
}

impl TryFrom<MacroExpansionRequest> for sandbox::MacroExpansionRequest {
    type Error = Error;

    fn try_from(me: MacroExpansionRequest) -> Result<Self> {
        Ok(sandbox::MacroExpansionRequest {
            code: me.code,
            edition: parse_edition(&me.edition)?,
        })
    }
}

impl From<sandbox::MacroExpansionResponse> for MacroExpansionResponse {
    fn from(me: sandbox::MacroExpansionResponse) -> Self {
        MacroExpansionResponse {
            success: me.success,
            stdout: me.stdout,
            stderr: me.stderr,
        }
    }
}

impl From<Vec<sandbox::CrateInformation>> for MetaCratesResponse {
    fn from(me: Vec<sandbox::CrateInformation>) -> Self {
        let crates = me.into_iter()
            .map(|cv| CrateInformation { name: cv.name, version: cv.version, id: cv.id })
            .collect();

        MetaCratesResponse {
            crates,
        }
    }
}

impl From<sandbox::Version> for MetaVersionResponse {
    fn from(me: sandbox::Version) -> Self {
        MetaVersionResponse {
            version: me.release,
            hash: me.commit_hash,
            date: me.commit_date,
        }
    }
}

impl From<gist::Gist> for MetaGistResponse {
    fn from(me: gist::Gist) -> Self {
        MetaGistResponse {
            id: me.id,
            url: me.url,
            code: me.code,
        }
    }
}

impl TryFrom<EvaluateRequest> for sandbox::ExecuteRequest {
    type Error = Error;

    fn try_from(me: EvaluateRequest) -> Result<Self> {
        Ok(sandbox::ExecuteRequest {
            channel: parse_channel(&me.version)?,
            mode: if me.optimize != "0" { sandbox::Mode::Release } else { sandbox::Mode::Debug },
            edition: parse_edition(&me.edition)?,
            crate_type: sandbox::CrateType::Binary,
            tests: me.tests,
            backtrace: false,
            code: me.code,
        })
    }
}

impl From<sandbox::ExecuteResponse> for EvaluateResponse {
    fn from(me: sandbox::ExecuteResponse) -> Self {
        // The old playground didn't use Cargo, so it never had the
        // Cargo output ("Compiling playground...") which is printed
        // to stderr. Since this endpoint is used to inline results on
        // the page, don't include the stderr unless an error
        // occurred.
        if me.success {
            EvaluateResponse {
                result: me.stdout,
                error: None,
            }
        } else {
            // When an error occurs, *some* consumers check for an
            // `error` key, others assume that the error is crammed in
            // the `result` field and then they string search for
            // `error:` or `warning:`. Ew. We can put it in both.
            let result = me.stderr + &me.stdout;
            EvaluateResponse {
                result: result.clone(),
                error: Some(result),
            }
        }
    }
}

fn parse_target(s: &str) -> Result<sandbox::CompileTarget> {
    Ok(match s {
        "asm" => sandbox::CompileTarget::Assembly(sandbox::AssemblyFlavor::Att,
                                                  sandbox::DemangleAssembly::Demangle,
                                                  sandbox::ProcessAssembly::Filter),
        "llvm-ir" => sandbox::CompileTarget::LlvmIr,
        "mir" => sandbox::CompileTarget::Mir,
        "hir" => sandbox::CompileTarget::Hir,
        "wasm" => sandbox::CompileTarget::Wasm,
        value => InvalidTarget { value }.fail()?,
    })
}

fn parse_assembly_flavor(s: &str) -> Result<sandbox::AssemblyFlavor> {
    Ok(match s {
        "att" => sandbox::AssemblyFlavor::Att,
        "intel" => sandbox::AssemblyFlavor::Intel,
        value => InvalidAssemblyFlavor { value }.fail()?
    })
}

fn parse_demangle_assembly(s: &str) -> Result<sandbox::DemangleAssembly> {
    Ok(match s {
        "demangle" => sandbox::DemangleAssembly::Demangle,
        "mangle" => sandbox::DemangleAssembly::Mangle,
        value => InvalidDemangleAssembly { value }.fail()?,
    })
}

fn parse_process_assembly(s: &str) -> Result<sandbox::ProcessAssembly> {
    Ok(match s {
        "filter" => sandbox::ProcessAssembly::Filter,
        "raw" => sandbox::ProcessAssembly::Raw,
        value => InvalidProcessAssembly { value }.fail()?
    })
}

fn parse_channel(s: &str) -> Result<sandbox::Channel> {
    Ok(match s {
        "stable" => sandbox::Channel::Stable,
        "beta" => sandbox::Channel::Beta,
        "nightly" => sandbox::Channel::Nightly,
        value => InvalidChannel { value }.fail()?,
    })
}

fn parse_mode(s: &str) -> Result<sandbox::Mode> {
    Ok(match s {
        "debug" => sandbox::Mode::Debug,
        "release" => sandbox::Mode::Release,
        value => InvalidMode { value }.fail()?,
    })
}

fn parse_edition(s: &str) -> Result<Option<sandbox::Edition>> {
    Ok(match s {
        "" => None,
        "2015" => Some(sandbox::Edition::Rust2015),
        "2018" => Some(sandbox::Edition::Rust2018),
        "2021" => Some(sandbox::Edition::Rust2021),
        value => InvalidEdition { value }.fail()?,
    })
}

fn parse_crate_type(s: &str) -> Result<sandbox::CrateType> {
    use crate::sandbox::{CrateType::*, LibraryType::*};
    Ok(match s {
        "bin" => Binary,
        "lib" => Library(Lib),
        "dylib" => Library(Dylib),
        "rlib" => Library(Rlib),
        "staticlib" => Library(Staticlib),
        "cdylib" => Library(Cdylib),
        "proc-macro" => Library(ProcMacro),
        value => InvalidCrateType { value }.fail()?,
    })
}

fn default_crate_type() -> String {
    "bin".into()
}

'''
'''--- ui/src/sandbox.rs ---
use serde_derive::Deserialize;
use snafu::{OptionExt, ResultExt, Snafu};
use std::{
    collections::BTreeMap,
    ffi::OsStr,
    fmt,
    fs::{self, File},
    io::{self, prelude::*, BufReader, ErrorKind},
    os::unix::fs::PermissionsExt,
    path::{Path, PathBuf},
    string,
    time::Duration,
};
use tempdir::TempDir;
use tokio::process::Command;

const DOCKER_PROCESS_TIMEOUT_SOFT: Duration = Duration::from_secs(10);
const DOCKER_PROCESS_TIMEOUT_HARD: Duration = Duration::from_secs(12);

#[derive(Debug, Deserialize)]
struct CrateInformationInner {
    name: String,
    version: String,
    id: String,
}

#[derive(Debug, Clone)]
pub struct CrateInformation {
    pub name: String,
    pub version: String,
    pub id: String,
}

impl From<CrateInformationInner> for CrateInformation {
    fn from(me: CrateInformationInner) -> Self {
        let CrateInformationInner { name, version, id } = me;
        Self { name, version, id }
    }
}

#[derive(Debug, Clone)]
pub struct Version {
    pub release: String,
    pub commit_hash: String,
    pub commit_date: String,
}

#[derive(Debug, Snafu)]
pub enum Error {
    #[snafu(display("Unable to create temporary directory: {}", source))]
    UnableToCreateTempDir { source: io::Error },
    #[snafu(display("Unable to create output directory: {}", source))]
    UnableToCreateOutputDir { source: io::Error },
    #[snafu(display("Unable to set permissions for output directory: {}", source))]
    UnableToSetOutputPermissions { source: io::Error },
    #[snafu(display("Unable to create source file: {}", source))]
    UnableToCreateSourceFile { source: io::Error },
    #[snafu(display("Unable to set permissions for source file: {}", source))]
    UnableToSetSourcePermissions { source: io::Error },

    #[snafu(display("Unable to start the compiler: {}", source))]
    UnableToStartCompiler { source: io::Error },
    #[snafu(display("Unable to find the compiler ID"))]
    MissingCompilerId,
    #[snafu(display("Unable to wait for the compiler: {}", source))]
    UnableToWaitForCompiler { source: io::Error },
    #[snafu(display("Unable to get output from the compiler: {}", source))]
    UnableToGetOutputFromCompiler { source: io::Error },
    #[snafu(display("Unable to remove the compiler: {}", source))]
    UnableToRemoveCompiler { source: io::Error },
    #[snafu(display("Compiler execution took longer than {} ms", timeout.as_millis()))]
    CompilerExecutionTimedOut { source: tokio::time::Elapsed, timeout: Duration },

    #[snafu(display("Unable to read output file: {}", source))]
    UnableToReadOutput { source: io::Error },
    #[snafu(display("Unable to read crate information: {}", source))]
    UnableToParseCrateInformation { source: ::serde_json::Error },
    #[snafu(display("Output was not valid UTF-8: {}", source))]
    OutputNotUtf8 { source: string::FromUtf8Error },
    #[snafu(display("Output was missing"))]
    OutputMissing,
    #[snafu(display("Release was missing from the version output"))]
    VersionReleaseMissing,
    #[snafu(display("Commit hash was missing from the version output"))]
    VersionHashMissing,
    #[snafu(display("Commit date was missing from the version output"))]
    VersionDateMissing,
}

pub type Result<T, E = Error> = ::std::result::Result<T, E>;

pub struct Sandbox {
    #[allow(dead_code)]
    scratch: TempDir,
    input_file: PathBuf,
    output_dir: PathBuf,
}

fn vec_to_str(v: Vec<u8>) -> Result<String> {
    String::from_utf8(v).context(OutputNotUtf8)
}

// We must create a world-writable files (rustfmt) and directories
// (LLVM IR) so that the process inside the Docker container can write
// into it.
//
// This problem does *not* occur when using the indirection of
// docker-machine.
fn wide_open_permissions() -> std::fs::Permissions {
    PermissionsExt::from_mode(0o777)
}

impl Sandbox {
    pub fn new() -> Result<Self> {
        let scratch = TempDir::new("playground").context(UnableToCreateTempDir)?;
        let input_file = scratch.path().join("input.rs");
        let output_dir = scratch.path().join("output");

        fs::create_dir(&output_dir).context(UnableToCreateOutputDir)?;
        fs::set_permissions(&output_dir, wide_open_permissions()).context(UnableToSetOutputPermissions)?;

        Ok(Sandbox {
            scratch,
            input_file,
            output_dir,
        })
    }

    pub fn compile(&self, req: &CompileRequest) -> Result<CompileResponse> {
        self.write_source_code(&req.code)?;

        let command = self.compile_command(req.target, req.channel, req.mode, req.tests, req);

        let output = run_command_with_timeout(command)?;

        // The compiler writes the file to a name like
        // `compilation-3b75174cac3d47fb.ll`, so we just find the
        // first with the right extension.
        let file =
            fs::read_dir(&self.output_dir)
            .context(UnableToReadOutput)?
            .flat_map(|entry| entry)
            .map(|entry| entry.path())
            .find(|path| path.extension() == Some(req.target.extension()));

        let stdout = vec_to_str(output.stdout)?;
        let mut stderr = vec_to_str(output.stderr)?;

        let mut code = match file {
            Some(file) => read(&file)?.unwrap_or_else(String::new),
            None => {
                // If we didn't find the file, it's *most* likely that
                // the user's code was invalid. Tack on our own error
                // to the compiler's error instead of failing the
                // request.
                use self::fmt::Write;
                write!(&mut stderr, "\nUnable to locate file for {} output", req.target)
                    .expect("Unable to write to a string");
                String::new()
            }
        };

        if let CompileTarget::Assembly(_, demangle, process) = req.target {

            if demangle == DemangleAssembly::Demangle {
                code = super::asm_cleanup::demangle_asm(&code);
            }

            if process == ProcessAssembly::Filter {
                code = super::asm_cleanup::filter_asm(&code);
            }
        } else if CompileTarget::Hir == req.target {
            // TODO: Run rustfmt on the generated HIR.
        }

        Ok(CompileResponse {
            success: output.status.success(),
            code,
            stdout,
            stderr,
        })
    }

    pub fn execute(&self, req: &ExecuteRequest) -> Result<ExecuteResponse> {
        self.write_source_code(&req.code)?;
        let command = self.execute_command(req.channel, req.mode, req.tests, req);

        let output = run_command_with_timeout(command)?;

        Ok(ExecuteResponse {
            success: output.status.success(),
            stdout: vec_to_str(output.stdout)?,
            stderr: vec_to_str(output.stderr)?,
        })
    }

    pub fn format(&self, req: &FormatRequest) -> Result<FormatResponse> {
        self.write_source_code(&req.code)?;
        let command = self.format_command(req);

        let output = run_command_with_timeout(command)?;

        Ok(FormatResponse {
            success: output.status.success(),
            code: read(self.input_file.as_ref())?.ok_or(Error::OutputMissing)?,
            stdout: vec_to_str(output.stdout)?,
            stderr: vec_to_str(output.stderr)?,
        })
    }

    pub fn clippy(&self, req: &ClippyRequest) -> Result<ClippyResponse> {
        self.write_source_code(&req.code)?;
        let command = self.clippy_command(req);

        let output = run_command_with_timeout(command)?;

        Ok(ClippyResponse {
            success: output.status.success(),
            stdout: vec_to_str(output.stdout)?,
            stderr: vec_to_str(output.stderr)?,
        })
    }

    pub fn miri(&self, req: &MiriRequest) -> Result<MiriResponse> {
        self.write_source_code(&req.code)?;
        let command = self.miri_command(req);

        let output = run_command_with_timeout(command)?;

        Ok(MiriResponse {
            success: output.status.success(),
            stdout: vec_to_str(output.stdout)?,
            stderr: vec_to_str(output.stderr)?,
        })
    }

    pub fn macro_expansion(&self, req: &MacroExpansionRequest) -> Result<MacroExpansionResponse> {
        self.write_source_code(&req.code)?;
        let command = self.macro_expansion_command(req);

        let output = run_command_with_timeout(command)?;

        Ok(MacroExpansionResponse {
            success: output.status.success(),
            stdout: vec_to_str(output.stdout)?,
            stderr: vec_to_str(output.stderr)?,
        })
    }

    pub fn crates(&self) -> Result<Vec<CrateInformation>> {
        let mut command = basic_secure_docker_command();
        command.args(&[Channel::Stable.container_name()]);
        command.args(&["cat", "crate-information.json"]);

        let output = run_command_with_timeout(command)?;

        let crate_info: Vec<CrateInformationInner> = ::serde_json::from_slice(&output.stdout).context(UnableToParseCrateInformation)?;

        let crates = crate_info.into_iter()
            .map(Into::into)
            .collect();

        Ok(crates)
    }

    pub fn version(&self, channel: Channel) -> Result<Version> {
        let mut command = basic_secure_docker_command();
        command.args(&[channel.container_name()]);
        command.args(&["rustc", "--version", "--verbose"]);

        let output = run_command_with_timeout(command)?;
        let version_output = vec_to_str(output.stdout)?;

        let mut info: BTreeMap<String, String> = version_output.lines().skip(1).filter_map(|line| {
            let mut pieces = line.splitn(2, ':').fuse();
            match (pieces.next(), pieces.next()) {
                (Some(name), Some(value)) => Some((name.trim().into(), value.trim().into())),
                _ => None
            }
        }).collect();

        let release = info.remove("release").ok_or(Error::VersionReleaseMissing)?;
        let commit_hash = info.remove("commit-hash").ok_or(Error::VersionHashMissing)?;
        let commit_date = info.remove("commit-date").ok_or(Error::VersionDateMissing)?;

        Ok(Version { release, commit_hash, commit_date })
    }

    pub fn version_rustfmt(&self) -> Result<Version> {
        let mut command = basic_secure_docker_command();
        command.args(&["rustfmt", "cargo", "fmt", "--version"]);
        self.cargo_tool_version(command)
    }

    pub fn version_clippy(&self) -> Result<Version> {
        let mut command = basic_secure_docker_command();
        command.args(&["clippy", "cargo", "clippy", "--version"]);
        self.cargo_tool_version(command)
    }

    pub fn version_miri(&self) -> Result<Version> {
        let mut command = basic_secure_docker_command();
        command.args(&["miri", "cargo", "miri", "--version"]);
        self.cargo_tool_version(command)
    }

    // Parses versions of the shape `toolname 0.0.0 (0000000 0000-00-00)`
    fn cargo_tool_version(&self, command: Command) -> Result<Version> {
        let output = run_command_with_timeout(command)?;
        let version_output = vec_to_str(output.stdout)?;
        let mut parts = version_output.split_whitespace().fuse().skip(1);

        let release = parts.next().unwrap_or("").into();
        let commit_hash = parts.next().unwrap_or("").trim_start_matches('(').into();
        let commit_date = parts.next().unwrap_or("").trim_end_matches(')').into();

        Ok(Version { release, commit_hash, commit_date })
    }

    fn write_source_code(&self, code: &str) -> Result<()> {
        fs::write(&self.input_file, code).context(UnableToCreateSourceFile)?;
        fs::set_permissions(&self.input_file, wide_open_permissions()).context(UnableToSetSourcePermissions)?;

        log::debug!("Wrote {} bytes of source to {}", code.len(), self.input_file.display());
        Ok(())
    }

    fn compile_command(&self, target: CompileTarget, channel: Channel, mode: Mode, tests: bool, req: impl CrateTypeRequest + EditionRequest + BacktraceRequest) -> Command {
        let mut cmd = self.docker_command(Some(req.crate_type()));
        set_execution_environment(&mut cmd, Some(target), &req);

        let execution_cmd = build_execution_command(Some(target), channel, mode, &req, tests);

        cmd.arg(&channel.container_name()).args(&execution_cmd);

        log::debug!("Compilation command is {:?}", cmd);

        cmd
    }

    fn execute_command(&self, channel: Channel, mode: Mode, tests: bool, req: impl CrateTypeRequest + EditionRequest + BacktraceRequest) -> Command {
        let mut cmd = self.docker_command(Some(req.crate_type()));
        set_execution_environment(&mut cmd, None, &req);

        let execution_cmd = build_execution_command(None, channel, mode, &req, tests);

        cmd.arg(&channel.container_name()).args(&execution_cmd);

        log::debug!("Execution command is {:?}", cmd);

        cmd
    }

    fn format_command(&self, req: impl EditionRequest) -> Command {
        let crate_type = CrateType::Binary;

        let mut cmd = self.docker_command(Some(crate_type));

        cmd.apply_edition(req);

        cmd.arg("rustfmt").args(&["cargo", "fmt"]);

        log::debug!("Formatting command is {:?}", cmd);

        cmd
    }

    fn clippy_command(&self, req: impl CrateTypeRequest + EditionRequest) -> Command {
        let mut cmd = self.docker_command(Some(req.crate_type()));

        cmd.apply_crate_type(&req);
        cmd.apply_edition(&req);

        cmd.arg("clippy").args(&["cargo", "clippy"]);

        log::debug!("Clippy command is {:?}", cmd);

        cmd
    }

    fn miri_command(&self, req: impl EditionRequest) -> Command {
        let mut cmd = self.docker_command(None);
        cmd.apply_edition(req);

        cmd.arg("miri").args(&["cargo", "miri-playground"]);

        log::debug!("Miri command is {:?}", cmd);

        cmd
    }

    fn macro_expansion_command(&self, req: impl EditionRequest) -> Command {
        let mut cmd = self.docker_command(None);
        cmd.apply_edition(req);

        cmd.arg(&Channel::Nightly.container_name()).args(&[
            "cargo",
            "rustc",
            "--",
            "-Zunpretty=expanded",
        ]);

        log::debug!("Macro expansion command is {:?}", cmd);

        cmd
    }

    fn docker_command(&self, crate_type: Option<CrateType>) -> Command {
        let crate_type = crate_type.unwrap_or(CrateType::Binary);

        let mut mount_input_file = self.input_file.as_os_str().to_os_string();
        mount_input_file.push(":");
        mount_input_file.push("/playground/");
        mount_input_file.push(crate_type.file_name());

        let mut mount_output_dir = self.output_dir.as_os_str().to_os_string();
        mount_output_dir.push(":");
        mount_output_dir.push("/playground-result");

        let mut cmd = basic_secure_docker_command();

        cmd
            .arg("--volume").arg(&mount_input_file)
            .arg("--volume").arg(&mount_output_dir);

        cmd
    }
}

macro_rules! docker_command {
    ($($arg:expr),* $(,)?) => ({
        let mut cmd = Command::new("docker");
        $( cmd.arg($arg); )*
        cmd
    });
}

fn basic_secure_docker_command() -> Command {
    let mut cmd = docker_command!(
        "run",
        "--detach",
        "--cap-drop=ALL",
        // Needed to allow overwriting the file
        "--cap-add=DAC_OVERRIDE",
        "--security-opt=no-new-privileges",
        "--workdir", "/playground",
        "--net", "none",
        "--memory", "512m",
        "--memory-swap", "640m",
        "--env", format!("PLAYGROUND_TIMEOUT={}", DOCKER_PROCESS_TIMEOUT_SOFT.as_secs()),
    );

    if cfg!(feature = "fork-bomb-prevention") {
        cmd.args(&["--pids-limit", "512"]);
    }

    cmd.kill_on_drop(true);

    cmd
}

fn build_execution_command(target: Option<CompileTarget>, channel: Channel, mode: Mode, req: impl CrateTypeRequest, tests: bool) -> Vec<&'static str> {
    use self::CompileTarget::*;
    use self::CrateType::*;
    use self::Mode::*;

    let mut cmd = vec!["cargo"];

    match (target, req.crate_type(), tests) {
        (Some(Wasm), _, _) => cmd.push("wasm"),
        (Some(_), _, _)    => cmd.push("rustc"),
        (_, _, true)       => cmd.push("test"),
        (_, Library(_), _) => cmd.push("build"),
        (_, _, _)          => cmd.push("run"),
    }

    if mode == Release {
        cmd.push("--release");
    }

    if let Some(target) = target {
        cmd.extend(&["--", "-o"]);
        if target == Hir {
            // -Zunpretty=hir only emits the HIR, not the binary itself
            cmd.push("/playground-result/compilation.hir");
        } else {
            cmd.push("/playground-result/compilation");
        }

        match target {
            Assembly(flavor, _, _) => {
                use self::AssemblyFlavor::*;

                cmd.push("--emit=asm");

                // Enable extra assembly comments for nightly builds
                if let Channel::Nightly = channel {
                    cmd.push("-Z");
                    cmd.push("asm-comments");
                }

                cmd.push("-C");
                match flavor {
                    Att => cmd.push("llvm-args=-x86-asm-syntax=att"),
                    Intel => cmd.push("llvm-args=-x86-asm-syntax=intel"),
                }
            },
            LlvmIr => cmd.push("--emit=llvm-ir"),
            Mir => cmd.push("--emit=mir"),
            Hir => cmd.push("-Zunpretty=hir"),
            Wasm => { /* handled by cargo-wasm wrapper */ },
         }
    }

    cmd
}

fn set_execution_environment(cmd: &mut Command, target: Option<CompileTarget>, req: impl CrateTypeRequest + EditionRequest + BacktraceRequest) {
    use self::CompileTarget::*;

    if let Some(Wasm) = target {
        cmd.args(&["--env", "PLAYGROUND_NO_DEPENDENCIES=true"]);
        cmd.args(&["--env", "PLAYGROUND_RELEASE_LTO=true"]);
    }

    cmd.apply_crate_type(&req);
    cmd.apply_edition(&req);
    cmd.apply_backtrace(&req);
}

fn read(path: &Path) -> Result<Option<String>> {
    let f = match File::open(path) {
        Ok(f) => f,
        Err(ref e) if e.kind() == ErrorKind::NotFound => return Ok(None),
        e => e.context(UnableToReadOutput)?,
    };
    let mut f = BufReader::new(f);

    let mut s = String::new();
    f.read_to_string(&mut s).context(UnableToReadOutput)?;
    Ok(Some(s))
}

#[tokio::main]
async fn run_command_with_timeout(mut command: Command) -> Result<std::process::Output> {
    use std::os::unix::process::ExitStatusExt;

    let timeout = DOCKER_PROCESS_TIMEOUT_HARD;

    let output = command.output()
        .await
        .context(UnableToStartCompiler)?;

    // Exit early, in case we don't have the container
    if !output.status.success() {
        return Ok(output);
    }

    let output = String::from_utf8_lossy(&output.stdout);
    let id = output.lines().next().context(MissingCompilerId)?.trim();

    // ----------

    let mut command = docker_command!("wait", id);

    let timed_out = match tokio::time::timeout(timeout, command.output()).await {
        Ok(Ok(o)) => {
            // Didn't time out, didn't fail to run
            let o = String::from_utf8_lossy(&o.stdout);
            let code = o.lines().next().unwrap_or("").trim().parse().unwrap_or(i32::MAX);
            Ok(ExitStatusExt::from_raw(code))
        }
        Ok(e) => return e.context(UnableToWaitForCompiler), // Failed to run
        Err(e) => Err(e), // Timed out
    };

    // ----------

    let mut command = docker_command!("logs", id);
    let mut output = command.output().await.context(UnableToGetOutputFromCompiler)?;

    // ----------

    let mut command = docker_command!(
        "rm",
        // Kills container if still running
        "--force",
        id
    );
    command.stdout(std::process::Stdio::null());
    command.status().await.context(UnableToRemoveCompiler)?;

    let code = timed_out.context(CompilerExecutionTimedOut { timeout })?;

    output.status = code;

    Ok(output)
}

#[derive(Debug, Copy, Clone, PartialEq, Eq)]
pub enum AssemblyFlavor {
    Att,
    Intel,
}

#[derive(Debug, Copy, Clone, PartialEq, Eq)]
pub enum DemangleAssembly {
    Demangle,
    Mangle,
}

#[derive(Debug, Copy, Clone, PartialEq, Eq)]
pub enum ProcessAssembly {
    Filter,
    Raw,
}

#[derive(Debug, Copy, Clone, PartialEq, Eq, strum::IntoStaticStr)]
pub enum CompileTarget {
    Assembly(AssemblyFlavor, DemangleAssembly, ProcessAssembly),
    LlvmIr,
    Mir,
    Hir,
    Wasm,
}

impl CompileTarget {
    fn extension(&self) -> &'static OsStr {
        let ext = match *self {
            CompileTarget::Assembly(_, _, _) => "s",
            CompileTarget::LlvmIr            => "ll",
            CompileTarget::Mir               => "mir",
            CompileTarget::Hir               => "hir",
            CompileTarget::Wasm              => "wat",
        };
        OsStr::new(ext)
    }
}

impl fmt::Display for CompileTarget {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        use self::CompileTarget::*;

        match *self {
            Assembly(_, _, _) => "assembly".fmt(f),
            LlvmIr            => "LLVM IR".fmt(f),
            Mir               => "Rust MIR".fmt(f),
            Hir               => "Rust HIR".fmt(f),
            Wasm              => "WebAssembly".fmt(f),
        }
    }
}

#[derive(Debug, Copy, Clone, PartialEq, Eq, strum::IntoStaticStr)]
pub enum Channel {
    Stable,
    Beta,
    Nightly,
}

impl Channel {
    fn container_name(&self) -> &'static str {
        use self::Channel::*;

        match *self {
            Stable => "rust-stable",
            Beta => "rust-beta",
            Nightly => "rust-nightly",
        }
    }
}

#[derive(Debug, Copy, Clone, PartialEq, Eq, strum::IntoStaticStr)]
pub enum Mode {
    Debug,
    Release,
}

#[derive(Debug, Copy, Clone, PartialEq, Eq, strum::IntoStaticStr)]
pub enum Edition {
    Rust2015,
    Rust2018,
    Rust2021, // TODO - add parallel tests for 2021
}

impl Edition {
    fn cargo_ident(&self) -> &'static str {
        use self::Edition::*;

        match *self {
            Rust2015 => "2015",
            Rust2018 => "2018",
            Rust2021 => "2021",
        }
    }
}

#[derive(Debug, Copy, Clone, PartialEq, Eq, strum::IntoStaticStr)]
pub enum CrateType {
    Binary,
    Library(LibraryType),
}

impl CrateType {
    fn file_name(&self) -> &'static str {
        use self::CrateType::*;

        match *self {
            Binary => "src/main.rs",
            Library(_) => "src/lib.rs",
        }
    }
}

#[derive(Debug, Copy, Clone, PartialEq, Eq, strum::IntoStaticStr)]
pub enum LibraryType {
    Lib,
    Dylib,
    Rlib,
    Staticlib,
    Cdylib,
    ProcMacro
}

impl LibraryType {
    fn cargo_ident(&self) -> &'static str {
        use self::LibraryType::*;

        match *self {
            Lib => "lib",
            Dylib => "dylib",
            Rlib => "rlib",
            Staticlib => "staticlib",
            Cdylib => "cdylib",
            ProcMacro => "proc-macro",
        }
    }
}

trait DockerCommandExt {
    fn apply_crate_type(&mut self, req: impl CrateTypeRequest);
    fn apply_edition(&mut self, req: impl EditionRequest);
    fn apply_backtrace(&mut self, req: impl BacktraceRequest);
}

impl DockerCommandExt for Command {
    fn apply_crate_type(&mut self, req: impl CrateTypeRequest) {
        if let CrateType::Library(lib) = req.crate_type() {
            self.args(&["--env", &format!("PLAYGROUND_CRATE_TYPE={}", lib.cargo_ident())]);
        }
    }

    fn apply_edition(&mut self, req: impl EditionRequest) {
        if let Some(edition) = req.edition() {
            if edition == Edition::Rust2021 {
                self.args(&["--env", &format!("PLAYGROUND_FEATURE_EDITION2021=true")]);
            }

            self.args(&["--env", &format!("PLAYGROUND_EDITION={}", edition.cargo_ident())]);
        }
    }

    fn apply_backtrace(&mut self, req: impl BacktraceRequest) {
        if req.backtrace() {
            self.args(&["--env", "RUST_BACKTRACE=1"]);
        }
    }
}

trait CrateTypeRequest {
    fn crate_type(&self) -> CrateType;
}

impl<R: CrateTypeRequest> CrateTypeRequest for &'_ R {
    fn crate_type(&self) -> CrateType { (*self).crate_type() }
}

trait EditionRequest {
    fn edition(&self) -> Option<Edition>;
}

impl<R: EditionRequest> EditionRequest for &'_ R {
    fn edition(&self) -> Option<Edition> { (*self).edition() }
}

trait BacktraceRequest {
    fn backtrace(&self) -> bool;
}

impl<R: BacktraceRequest> BacktraceRequest for &'_ R {
    fn backtrace(&self) -> bool { (*self).backtrace() }
}

#[derive(Debug, Clone)]
pub struct CompileRequest {
    pub target: CompileTarget,
    pub channel: Channel,
    pub crate_type: CrateType,
    pub mode: Mode,
    pub edition: Option<Edition>,
    pub tests: bool,
    pub backtrace: bool,
    pub code: String,
}

impl CrateTypeRequest for CompileRequest {
    fn crate_type(&self) -> CrateType { self.crate_type }
}

impl EditionRequest for CompileRequest {
    fn edition(&self) -> Option<Edition> { self.edition }
}

impl BacktraceRequest for CompileRequest {
    fn backtrace(&self) -> bool { self.backtrace }
}

#[derive(Debug, Clone)]
pub struct CompileResponse {
    pub success: bool,
    pub code: String,
    pub stdout: String,
    pub stderr: String,
}

#[derive(Debug, Clone)]
pub struct ExecuteRequest {
    pub channel: Channel,
    pub mode: Mode,
    pub edition: Option<Edition>,
    pub crate_type: CrateType,
    pub tests: bool,
    pub backtrace: bool,
    pub code: String,
}

impl CrateTypeRequest for ExecuteRequest {
    fn crate_type(&self) -> CrateType { self.crate_type }
}

impl EditionRequest for ExecuteRequest {
    fn edition(&self) -> Option<Edition> { self.edition }
}

impl BacktraceRequest for ExecuteRequest {
    fn backtrace(&self) -> bool { self.backtrace }
}

#[derive(Debug, Clone)]
pub struct ExecuteResponse {
    pub success: bool,
    pub stdout: String,
    pub stderr: String,
}

#[derive(Debug, Clone)]
pub struct FormatRequest {
    pub code: String,
    pub edition: Option<Edition>,
}

impl EditionRequest for FormatRequest {
    fn edition(&self) -> Option<Edition> { self.edition }
}

#[derive(Debug, Clone)]
pub struct FormatResponse {
    pub success: bool,
    pub code: String,
    pub stdout: String,
    pub stderr: String,
}

#[derive(Debug, Clone)]
pub struct ClippyRequest {
    pub code: String,
    pub edition: Option<Edition>,
    pub crate_type: CrateType,
}

impl CrateTypeRequest for ClippyRequest {
    fn crate_type(&self) -> CrateType { self.crate_type }
}

impl EditionRequest for ClippyRequest {
    fn edition(&self) -> Option<Edition> { self.edition }
}

#[derive(Debug, Clone)]
pub struct ClippyResponse {
    pub success: bool,
    pub stdout: String,
    pub stderr: String,
}

#[derive(Debug, Clone)]
pub struct MiriRequest {
    pub code: String,
    pub edition: Option<Edition>,
}

impl EditionRequest for MiriRequest {
    fn edition(&self) -> Option<Edition> { self.edition }
}

#[derive(Debug, Clone)]
pub struct MiriResponse {
    pub success: bool,
    pub stdout: String,
    pub stderr: String,
}

#[derive(Debug, Clone)]
pub struct MacroExpansionRequest {
    pub code: String,
    pub edition: Option<Edition>,
}

impl EditionRequest for MacroExpansionRequest {
    fn edition(&self) -> Option<Edition> {
        self.edition
    }
}

#[derive(Debug, Clone)]
pub struct MacroExpansionResponse {
    pub success: bool,
    pub stdout: String,
    pub stderr: String,
}

#[cfg(test)]
mod test {
    use super::*;

    // Running the tests completely in parallel causes spurious
    // failures due to my resource-limited Docker
    // environment. Additionally, we have some tests that *require*
    // that no other Docker processes are running.
    fn one_test_at_a_time() -> impl Drop {
        use lazy_static::lazy_static;
        use std::sync::Mutex;

        lazy_static! {
            static ref DOCKER_SINGLETON: Mutex<()> = Default::default();
        }

        // We can't poison the empty tuple
        DOCKER_SINGLETON.lock().unwrap_or_else(|e| e.into_inner())
    }

    const HELLO_WORLD_CODE: &'static str = r#"
    fn main() {
        println!("Hello, world!");
    }
    "#;

    impl Default for ExecuteRequest {
        fn default() -> Self {
            ExecuteRequest {
                channel: Channel::Stable,
                crate_type: CrateType::Binary,
                mode: Mode::Debug,
                tests: false,
                code: HELLO_WORLD_CODE.to_string(),
                edition: None,
                backtrace: false,
            }
        }
    }

    impl Default for CompileRequest {
        fn default() -> Self {
            CompileRequest {
                target: CompileTarget::LlvmIr,
                channel: Channel::Stable,
                crate_type: CrateType::Binary,
                mode: Mode::Debug,
                tests: false,
                code: HELLO_WORLD_CODE.to_string(),
                edition: None,
                backtrace: false,
            }
        }
    }

    impl Default for ClippyRequest {
        fn default() -> Self {
            ClippyRequest {
                code: HELLO_WORLD_CODE.to_string(),
                crate_type: CrateType::Binary,
                edition: None,
            }
        }
    }

    #[test]
    fn basic_functionality() {
        let _singleton = one_test_at_a_time();
        let req = ExecuteRequest::default();

        let sb = Sandbox::new().expect("Unable to create sandbox");
        let resp = sb.execute(&req).expect("Unable to execute code");

        assert!(resp.stdout.contains("Hello, world!"));
    }

    const COMPILATION_MODE_CODE: &'static str = r#"
    #[cfg(debug_assertions)]
    fn main() {
        println!("Compiling in debug mode");
    }

    #[cfg(not(debug_assertions))]
    fn main() {
        println!("Compiling in release mode");
    }
    "#;

    #[test]
    fn debug_mode() {
        let _singleton = one_test_at_a_time();
        let req = ExecuteRequest {
            code: COMPILATION_MODE_CODE.to_string(),
            ..ExecuteRequest::default()
        };

        let sb = Sandbox::new().expect("Unable to create sandbox");
        let resp = sb.execute(&req).expect("Unable to execute code");

        assert!(resp.stdout.contains("debug mode"));
    }

    #[test]
    fn release_mode() {
        let _singleton = one_test_at_a_time();
        let req = ExecuteRequest {
            mode: Mode::Release,
            code: COMPILATION_MODE_CODE.to_string(),
            ..ExecuteRequest::default()
        };

        let sb = Sandbox::new().expect("Unable to create sandbox");
        let resp = sb.execute(&req).expect("Unable to execute code");

        assert!(resp.stdout.contains("release mode"));
    }

    static VERSION_CODE: &'static str = r#"
    use std::process::Command;

    fn main() {
        let output = Command::new("rustc").arg("--version").output().unwrap();
        let output = String::from_utf8(output.stdout).unwrap();
        println!("{}", output);
    }
    "#;

    #[test]
    fn stable_channel() {
        let _singleton = one_test_at_a_time();
        let req = ExecuteRequest {
            channel: Channel::Stable,
            code: VERSION_CODE.to_string(),
            ..ExecuteRequest::default()
        };

        let sb = Sandbox::new().expect("Unable to create sandbox");
        let resp = sb.execute(&req).expect("Unable to execute code");

        assert!(resp.stdout.contains("rustc"));
        assert!(!resp.stdout.contains("beta"));
        assert!(!resp.stdout.contains("nightly"));
    }

    #[test]
    fn beta_channel() {
        let _singleton = one_test_at_a_time();
        let req = ExecuteRequest {
            channel: Channel::Beta,
            code: VERSION_CODE.to_string(),
            ..ExecuteRequest::default()
        };

        let sb = Sandbox::new().expect("Unable to create sandbox");
        let resp = sb.execute(&req).expect("Unable to execute code");

        assert!(resp.stdout.contains("rustc"));
        assert!(resp.stdout.contains("beta"));
        assert!(!resp.stdout.contains("nightly"));
    }

    #[test]
    fn nightly_channel() {
        let _singleton = one_test_at_a_time();
        let req = ExecuteRequest {
            channel: Channel::Nightly,
            code: VERSION_CODE.to_string(),
            ..ExecuteRequest::default()
        };

        let sb = Sandbox::new().expect("Unable to create sandbox");
        let resp = sb.execute(&req).expect("Unable to execute code");

        assert!(resp.stdout.contains("rustc"));
        assert!(!resp.stdout.contains("beta"));
        assert!(resp.stdout.contains("nightly"));
    }

    // Code that will only work in Rust 2015
    const EDITION_CODE: &str = r#"
    fn main() {
        let async = true;
    }
    "#;

    const EDITION_ERROR: &str = "found keyword `async`";

    #[test]
    fn rust_edition_default() -> Result<()> {
        let _singleton = one_test_at_a_time();
        let req = ExecuteRequest {
            channel: Channel::Nightly,
            code: EDITION_CODE.to_string(),
            ..ExecuteRequest::default()
        };

        let resp = Sandbox::new()?.execute(&req)?;

        assert!(!resp.stderr.contains(EDITION_ERROR), "was: {}", resp.stderr);
        Ok(())
    }

    #[test]
    fn rust_edition_2015() -> Result<()> {
        let _singleton = one_test_at_a_time();
        let req = ExecuteRequest {
            channel: Channel::Nightly,
            code: EDITION_CODE.to_string(),
            edition: Some(Edition::Rust2015),
            ..ExecuteRequest::default()
        };

        let resp = Sandbox::new()?.execute(&req)?;

        assert!(!resp.stderr.contains(EDITION_ERROR), "was: {}", resp.stderr);
        Ok(())
    }

    #[test]
    fn rust_edition_2018() -> Result<()> {
        let _singleton = one_test_at_a_time();
        let req = ExecuteRequest {
            channel: Channel::Nightly,
            code: EDITION_CODE.to_string(),
            edition: Some(Edition::Rust2018),
            ..ExecuteRequest::default()
        };

        let resp = Sandbox::new()?.execute(&req)?;

        assert!(resp.stderr.contains(EDITION_ERROR), "was: {}", resp.stderr);
        Ok(())
    }

    const BACKTRACE_CODE: &str = r#"
    fn trigger_the_problem() {
        None::<u8>.unwrap();
    }

    fn main() {
        trigger_the_problem()
    }
    "#;

    const BACKTRACE_NOTE: &str = "run with `RUST_BACKTRACE=1` environment variable to display a backtrace";

    #[test]
    fn backtrace_disabled() -> Result<()> {
        let _singleton = one_test_at_a_time();
        let req = ExecuteRequest {
            code: BACKTRACE_CODE.to_string(),
            backtrace: false,
            ..ExecuteRequest::default()
        };

        let sb = Sandbox::new()?;
        let resp = sb.execute(&req)?;

        assert!(resp.stderr.contains(BACKTRACE_NOTE), "Was: {}", resp.stderr);
        assert!(!resp.stderr.contains("stack backtrace:"), "Was: {}", resp.stderr);

        Ok(())
    }

    #[test]
    fn backtrace_enabled() -> Result<()> {
        let _singleton = one_test_at_a_time();
        let req = ExecuteRequest {
            code: BACKTRACE_CODE.to_string(),
            backtrace: true,
            ..ExecuteRequest::default()
        };

        let sb = Sandbox::new()?;
        let resp = sb.execute(&req)?;

        assert!(!resp.stderr.contains(BACKTRACE_NOTE), "Was: {}", resp.stderr);
        assert!(resp.stderr.contains("stack backtrace:"), "Was: {}", resp.stderr);

        Ok(())
    }

    #[test]
    fn output_llvm_ir() {
        let _singleton = one_test_at_a_time();
        let req = CompileRequest {
            target: CompileTarget::LlvmIr,
            ..CompileRequest::default()
        };

        let sb = Sandbox::new().expect("Unable to create sandbox");
        let resp = sb.compile(&req).expect("Unable to compile code");

        assert!(resp.code.contains("ModuleID"));
        assert!(resp.code.contains("target datalayout"));
        assert!(resp.code.contains("target triple"));
    }

    #[test]
    fn output_assembly() {
        let _singleton = one_test_at_a_time();
        let req = CompileRequest {
            target: CompileTarget::Assembly(AssemblyFlavor::Att, DemangleAssembly::Mangle, ProcessAssembly::Raw),
            ..CompileRequest::default()
        };

        let sb = Sandbox::new().expect("Unable to create sandbox");
        let resp = sb.compile(&req).expect("Unable to compile code");

        assert!(resp.code.contains(".text"));
        assert!(resp.code.contains(".file"));
        assert!(resp.code.contains(".section"));
        assert!(resp.code.contains(".p2align"));
    }

    #[test]
    fn output_demangled_assembly() {
        let _singleton = one_test_at_a_time();
        let req = CompileRequest {
            target: CompileTarget::Assembly(AssemblyFlavor::Att, DemangleAssembly::Demangle, ProcessAssembly::Raw),
            ..CompileRequest::default()
        };

        let sb = Sandbox::new().expect("Unable to create sandbox");
        let resp = sb.compile(&req).expect("Unable to compile code");

        assert!(resp.code.contains("core::fmt::Arguments::new_v1"));
        assert!(resp.code.contains("std::io::stdio::_print@GOTPCREL"));
    }

    #[test]
    #[should_panic]
    fn output_filtered_assembly() {
        let _singleton = one_test_at_a_time();
        let req = CompileRequest {
            target: CompileTarget::Assembly(AssemblyFlavor::Att, DemangleAssembly::Mangle, ProcessAssembly::Filter),
            ..CompileRequest::default()
        };

        let sb = Sandbox::new().expect("Unable to create sandbox");
        let resp = sb.compile(&req).expect("Unable to compile code");

        assert!(resp.code.contains(".text"));
        assert!(resp.code.contains(".file"));
    }

    #[test]
    fn formatting_code() {
        let _singleton = one_test_at_a_time();
        let req = FormatRequest {
            code: "fn foo () { method_call(); }".to_string(),
            edition: None,
        };

        let sb = Sandbox::new().expect("Unable to create sandbox");
        let resp = sb.format(&req).expect("Unable to format code");

        let lines: Vec<_> = resp.code.lines().collect();

        assert_eq!(lines[0], "fn foo() {");
        assert_eq!(lines[1], "    method_call();");
        assert_eq!(lines[2], "}");
    }

    // Code that is only syntactically valid in Rust 2018
    const FORMAT_IN_EDITION_2018: &str = r#"fn main() { use std::num::ParseIntError; let result: Result<i32, ParseIntError> = try { "1".parse::<i32>()? + "2".parse::<i32>()? + "3".parse::<i32>()? }; assert_eq!(result, Ok(6)); }"#;

    const FORMAT_ERROR: &str = r#"error: expected identifier, found `"1"`"#;

    #[test]
    fn formatting_code_edition_2015() -> Result<()> {
        let _singleton = one_test_at_a_time();
        let req = FormatRequest {
            code: FORMAT_IN_EDITION_2018.to_string(),
            edition: Some(Edition::Rust2015),
        };

        let resp = Sandbox::new()?.format(&req)?;

        assert!(resp.stderr.contains(FORMAT_ERROR));
        Ok(())
    }

    #[test]
    fn formatting_code_edition_2018() -> Result<()> {
        let _singleton = one_test_at_a_time();
        let req = FormatRequest {
            code: FORMAT_IN_EDITION_2018.to_string(),
            edition: Some(Edition::Rust2018),
        };

        let resp = Sandbox::new()?.format(&req)?;
        assert!(!resp.stderr.contains(FORMAT_ERROR));

        let lines: Vec<_> = resp.code.lines().collect();
        assert_eq!(lines[0], r#"fn main() {"#);
        assert_eq!(lines[1], r#"    use std::num::ParseIntError;"#);
        assert_eq!(lines[2], r#"    let result: Result<i32, ParseIntError> ="#);
        assert_eq!(lines[3], r#"        try { "1".parse::<i32>()? + "2".parse::<i32>()? + "3".parse::<i32>()? };"#);
        assert_eq!(lines[4], r#"    assert_eq!(result, Ok(6));"#);
        assert_eq!(lines[5], r#"}"#);
        Ok(())
    }

    #[test]
    fn linting_code() {
        let _singleton = one_test_at_a_time();
        let code = r#"
        fn main() {
            let a = 0.0 / 0.0;
            println!("NaN is {}", a);
        }
        "#;

        let req = ClippyRequest {
            code: code.to_string(),
            ..ClippyRequest::default()
        };

        let sb = Sandbox::new().expect("Unable to create sandbox");
        let resp = sb.clippy(&req).expect("Unable to lint code");

        assert!(resp.stderr.contains("deny(clippy::eq_op)"));
        assert!(resp.stderr.contains("warn(clippy::zero_divided_by_zero)"));
    }

    #[test]
    fn linting_code_options() {
        let _singleton = one_test_at_a_time();
        let code = r#"
        use itertools::Itertools; // Edition 2018 feature

        fn example() {
            let a = 0.0 / 0.0;
            println!("NaN is {}", a);
        }
        "#;

        let req = ClippyRequest {
            code: code.to_string(),
            crate_type: CrateType::Library(LibraryType::Rlib),
            edition: Some(Edition::Rust2018),
        };

        let sb = Sandbox::new().expect("Unable to create sandbox");
        let resp = sb.clippy(&req).expect("Unable to lint code");

        assert!(resp.stderr.contains("deny(clippy::eq_op)"));
        assert!(resp.stderr.contains("warn(clippy::zero_divided_by_zero)"));
    }

    #[test]
    fn interpreting_code() -> Result<()> {
        let _singleton = one_test_at_a_time();
        let code = r#"
        fn main() {
            let mut a: [u8; 0] = [];
            unsafe { *a.get_unchecked_mut(1) = 1; }
        }
        "#;

        let req = MiriRequest {
            code: code.to_string(),
            edition: None,
        };

        let sb = Sandbox::new()?;
        let resp = sb.miri(&req)?;

        assert!(resp.stderr.contains("pointer must be in-bounds at offset 1"), "was: {}", resp.stderr);
        assert!(resp.stderr.contains("outside bounds of alloc"), "was: {}", resp.stderr);
        assert!(resp.stderr.contains("which has size 0"), "was: {}", resp.stderr);
        Ok(())
    }

    #[test]
    fn network_connections_are_disabled() {
        let _singleton = one_test_at_a_time();
        let code = r#"
            fn main() {
                match ::std::net::TcpStream::connect("google.com:80") {
                    Ok(_) => println!("Able to connect to the outside world"),
                    Err(e) => println!("Failed to connect {}, {:?}", e, e),
                }
            }
        "#;

        let req = ExecuteRequest {
            code: code.to_string(),
            ..ExecuteRequest::default()
        };

        let sb = Sandbox::new().expect("Unable to create sandbox");
        let resp = sb.execute(&req).expect("Unable to execute code");

        assert!(resp.stdout.contains("Failed to connect"));
    }

    #[test]
    fn memory_usage_is_limited() {
        let _singleton = one_test_at_a_time();
        let code = r#"
            fn main() {
                let megabyte = 1024 * 1024;
                let mut big = vec![0u8; 384 * megabyte];
                for i in &mut big { *i += 1; }
            }
        "#;

        let req = ExecuteRequest {
            code: code.to_string(),
            ..ExecuteRequest::default()
        };

        let sb = Sandbox::new().expect("Unable to create sandbox");
        let resp = sb.execute(&req).expect("Unable to execute code");

        assert!(resp.stderr.contains("Killed"));
    }

    #[test]
    fn wallclock_time_is_limited() {
        let _singleton = one_test_at_a_time();
        let code = r#"
            fn main() {
                let a_long_time = std::time::Duration::from_secs(20);
                std::thread::sleep(a_long_time);
            }
        "#;

        let req = ExecuteRequest {
            code: code.to_string(),
            ..ExecuteRequest::default()
        };

        let sb = Sandbox::new().expect("Unable to create sandbox");
        let resp = sb.execute(&req).expect("Unable to execute code");

        assert!(resp.stderr.contains("Killed"));
    }

    #[test]
    fn wallclock_time_is_limited_from_outside() {
        let _singleton = one_test_at_a_time();
        let code = r##"
            use std::{process::Command, thread, time::Duration};

            fn main() {
                let output = Command::new("pgrep").args(&["timeout"]).output().unwrap();
                assert!(output.status.success());

                let out = String::from_utf8(output.stdout).expect("Unable to parse output");
                let timeout_pid: u32 = out.trim().parse().expect("Unable to find timeout PID");

                let output = Command::new("sh")
                    .args(&["-c", &format!("kill -s STOP {}", timeout_pid)])
                    .output()
                    .unwrap();
                assert!(output.status.success());

                for _ in 0.. {
                    thread::sleep(Duration::from_secs(1));
                }
            }
        "##;

        #[tokio::main]
        async fn docker_process_count() -> usize {
            let mut cmd = docker_command!("ps", "-a");
            let output = cmd.output().await.expect("Unable to get process count");
            let output = String::from_utf8_lossy(&output.stdout);
            // Skip one line of header
            output.lines().skip(1).count()
        }

        assert_eq!(0, docker_process_count(), "There must be no running docker processes");

        let req = ExecuteRequest {
            code: code.to_string(),
            ..ExecuteRequest::default()
        };

        let sb = Sandbox::new().expect("Unable to create sandbox");
        match sb.execute(&req) {
            Ok(_) => panic!("Expected an error"),
            Err(Error::CompilerExecutionTimedOut{..}) => {/* Ok */}
            Err(e) => panic!("Got the wrong error: {}", e),
        }

        assert_eq!(0, docker_process_count(), "A docker process continues to run");
    }

    #[test]
    fn number_of_pids_is_limited() {
        let _singleton = one_test_at_a_time();
        let forkbomb = r##"
            fn main() {
                ::std::process::Command::new("sh").arg("-c").arg(r#"
                    z() {
                        z&
                        z
                    }
                    z
                "#).status().unwrap();
            }
        "##;

        let req = ExecuteRequest {
            code: forkbomb.to_string(),
            ..ExecuteRequest::default()
        };

        let sb = Sandbox::new().expect("Unable to create sandbox");
        let resp = sb.execute(&req).expect("Unable to execute code");

        assert!(resp.stderr.contains("Cannot fork"));
    }
}

'''