*GitHub Repository "MetricsDAO/near_dbt"*

'''--- .github/workflows/.dbt/profiles.yml ---
near:
  target: prod
  outputs:
    dev:
      type: snowflake
      account: "{{ env_var('ACCOUNT') }}"
      role: "{{ env_var('ROLE') }}"
      user: "{{ env_var('USER') }}"
      password: "{{ env_var('PASSWORD') }}"
      region: "{{ env_var('REGION') }}"
      database: "{{ env_var('DATABASE') }}"
      warehouse: "{{ env_var('WAREHOUSE') }}"
      schema: SILVER
      threads: 4
      client_session_keep_alive: False
    prod:
      type: snowflake
      account: "{{ env_var('ACCOUNT') }}"
      role: "{{ env_var('ROLE') }}"
      user: "{{ env_var('USER') }}"
      password: "{{ env_var('PASSWORD') }}"
      region: "{{ env_var('REGION') }}"
      database: "{{ env_var('DATABASE') }}"
      warehouse: "{{ env_var('WAREHOUSE') }}"
      schema: silver
      threads: 4
      client_session_keep_alive: False

'''
'''--- .github/workflows/dbt_docs_update.yml ---
name: docs_update

on:
  workflow_call:

env:
  USE_VARS: "${{ vars.USE_VARS }}"
  DBT_PROFILES_DIR: "${{ vars.DBT_PROFILES_DIR }}"
  DBT_VERSION: "${{ vars.DBT_VERSION }}"
  ACCOUNT: "${{ vars.ACCOUNT }}"
  ROLE: "${{ vars.ROLE }}"
  USER: "${{ vars.USER }}"
  PASSWORD: "${{ secrets.PASSWORD }}"
  REGION: "${{ vars.REGION }}"
  DATABASE: "${{ vars.DATABASE }}"
  WAREHOUSE: "${{ vars.WAREHOUSE }}"
  SCHEMA: "${{ vars.SCHEMA }}"

jobs:
  scheduled_run:
    name: docs_update
    runs-on: ubuntu-latest
    environment:
      name: workflow_prod

    steps:
      - uses: actions/checkout@v3

      - uses: actions/setup-python@v4
        with:
          python-version: "3.10"
          cache: "pip"

      - name: overwrite env vars
        if: ${{ env.USE_VARS == 'TRUE' }}
        run: |
          echo "DBT_VERSION=${{ vars.DBT_VERSION }}" >> $GITHUB_ENV
          echo "DBT_PROFILES_DIR=${{ vars.DBT_PROFILES_DIR }}" >> $GITHUB_ENV
          echo "ACCOUNT=${{ vars.ACCOUNT }}" >> $GITHUB_ENV
          echo "ROLE=${{ vars.ROLE }}" >> $GITHUB_ENV
          echo "USER=${{ vars.USER }}" >> $GITHUB_ENV
          echo "REGION=${{ vars.REGION }}" >> $GITHUB_ENV
          echo "DATABASE=${{ vars.DATABASE }}" >> $GITHUB_ENV
          echo "SCHEMA=${{ vars.SCHEMA }}" >> $GITHUB_ENV

      - name: install dependencies
        run: |
          pip install dbt-snowflake==${{ vars.DBT_VERSION }}
          dbt deps

      - name: refresh ddl for datashare
        run: |
          cnt=$(dbt ls -m fsc_utils.datashare._datashare___create_gold | wc -l ); if [ $cnt -eq 1 ]; then dbt run -m fsc_utils.datashare._datashare___create_gold; fi;

      - name: checkout docs branch
        run: |
          git checkout -B docs origin/main

      - name: generate dbt docs
        run: dbt docs generate -t prod

      - name: move files to docs directory
        run: |
          mkdir -p ./docs
          cp target/{catalog.json,manifest.json,index.html} docs/
      - name: clean up target directory
        run: dbt clean

      - name: check for changes
        run: git status

      - name: stage changed files
        run: git add .

      - name: commit changed files
        run: |
          git config user.email "abc@xyz"
          git config user.name "github-actions"
          git commit -am "Auto-update docs"
      - name: push changes to docs
        run: |
          git push -f --set-upstream origin docs

'''
'''--- .github/workflows/dbt_run_adhoc.yml ---
name: dbt_run_adhoc
run-name: ${{ inputs.dbt_command }}

on:
  workflow_dispatch:
    branches:
      - "main"
    inputs:
      environment:
        type: choice
        description: DBT Run Environment
        required: true
        options:
          - dev
          - prod
        default: dev
      warehouse:
        type: choice
        description: Snowflake warehouse
        required: true
        options:
          - DBT
          - DBT_CLOUD
          - DBT_EMERGENCY
        default: DBT
      dbt_command:
        type: string
        description: "DBT Run Command"
        required: true

env:
  USE_VARS: "${{ vars.USE_VARS }}"
  DBT_PROFILES_DIR: "${{ vars.DBT_PROFILES_DIR }}"
  DBT_VERSION: "${{ vars.DBT_VERSION }}"
  ACCOUNT: "${{ vars.ACCOUNT }}"
  ROLE: "${{ vars.ROLE }}"
  USER: "${{ vars.USER }}"
  PASSWORD: "${{ secrets.PASSWORD }}"
  REGION: "${{ vars.REGION }}"
  DATABASE: "${{ vars.DATABASE }}"
  WAREHOUSE: "${{ inputs.warehouse }}"
  SCHEMA: "${{ vars.SCHEMA }}"

concurrency:
  group: ${{ github.workflow }}

jobs:
  run_dbt_jobs:
    runs-on: ubuntu-latest
    environment:
      name: workflow_${{ inputs.environment }}

    steps:
      - uses: actions/checkout@v3

      - uses: actions/setup-python@v4
        with:
          python-version: "3.10"

      - name: install dependencies
        run: |
          pip install -r requirements.txt
          dbt deps
      - name: Run DBT Jobs
        run: |
          ${{ inputs.dbt_command }}

'''
'''--- .github/workflows/dbt_run_atlas.yml ---
name: dbt_run_atlas
run-name: dbt_run_atlas

on:
  workflow_dispatch:
  schedule:
    # Runs once per day at 0 UTC
    - cron: "0 0 * * *"

env:
  USE_VARS: "${{ vars.USE_VARS }}"
  DBT_PROFILES_DIR: "${{ vars.DBT_PROFILES_DIR }}"
  DBT_VERSION: "${{ vars.DBT_VERSION }}"
  ACCOUNT: "${{ vars.ACCOUNT }}"
  ROLE: "${{ vars.ROLE }}"
  USER: "${{ vars.USER }}"
  PASSWORD: "${{ secrets.PASSWORD }}"
  REGION: "${{ vars.REGION }}"
  DATABASE: "${{ vars.DATABASE }}"
  WAREHOUSE: "${{ vars.WAREHOUSE }}"
  SCHEMA: "${{ vars.SCHEMA }}"

concurrency:
  group: ${{ github.workflow }}

jobs:
  dbt:
    runs-on: ubuntu-latest
    environment:
      name: workflow_prod
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-python@v4
        with:
          python-version: "3.10"
          cache: "pip"

      - name: install dependencies
        run: |
          pip install -r requirements.txt
          dbt deps

      - name: Run DBT Jobs
        run: |
          dbt run -s tag:atlas

      - name: Store logs
        uses: actions/upload-artifact@v3
        with:
          name: dbt-logs
          path: |
            logs
            target

'''
'''--- .github/workflows/dbt_run_daily_refresh.yml ---
name: dbt_run_daily_refresh
run-name: dbt_run_daily_refresh

on:
  workflow_dispatch:
  schedule:
    # Runs 0900 daily (see https://crontab.guru)
    - cron: "0 9 * * *"

env:
  USE_VARS: "${{ vars.USE_VARS }}"
  DBT_PROFILES_DIR: "${{ vars.DBT_PROFILES_DIR }}"
  DBT_VERSION: "${{ vars.DBT_VERSION }}"
  ACCOUNT: "${{ vars.ACCOUNT }}"
  ROLE: "${{ vars.ROLE }}"
  USER: "${{ vars.USER }}"
  PASSWORD: "${{ secrets.PASSWORD }}"
  REGION: "${{ vars.REGION }}"
  DATABASE: "${{ vars.DATABASE }}"
  WAREHOUSE: "${{ vars.WAREHOUSE }}"
  SCHEMA: "${{ vars.SCHEMA }}"

concurrency:
  group: ${{ github.workflow }}

jobs:
  dbt:
    runs-on: ubuntu-latest
    environment:
      name: workflow_prod
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-python@v4
        with:
          python-version: "3.10"
          cache: "pip"

      - name: install dependencies
        run: |
          pip install -r requirements.txt
          dbt deps

      - name: Run DBT Jobs
        run: |
          dbt run -s models/gold

      - name: Store logs
        uses: actions/upload-artifact@v3
        with:
          name: dbt-logs
          path: |
            logs
            target

'''
'''--- .github/workflows/dbt_run_deployment.yml ---
name: dbt_run_deployment
run-name: dbt_run_deployment

on:
  workflow_dispatch:
    branches:
      - "main"
    inputs:
      warehouse:
        type: choice
        description: Snowflake warehouse
        required: true
        options:
          - DBT
          - DBT_CLOUD
          - DBT_EMERGENCY
        default: DBT
      dbt_command:
        type: string
        description: "DBT Run Command"
        required: true

env:
  USE_VARS: "${{ vars.USE_VARS }}"
  DBT_PROFILES_DIR: "${{ vars.DBT_PROFILES_DIR }}"
  DBT_VERSION: "${{ vars.DBT_VERSION }}"
  ACCOUNT: "${{ vars.ACCOUNT }}"
  ROLE: "${{ vars.ROLE }}"
  USER: "${{ vars.USER }}"
  PASSWORD: "${{ secrets.PASSWORD }}"
  REGION: "${{ vars.REGION }}"
  DATABASE: "${{ vars.DATABASE }}"
  WAREHOUSE: "${{ inputs.WAREHOUSE }}"
  SCHEMA: "${{ vars.SCHEMA }}"

concurrency:
  group: ${{ github.workflow }}

jobs:
  dbt:
    runs-on: ubuntu-latest
    environment:
      name: workflow_prod
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-python@v4
        with:
          python-version: "3.10"
          cache: "pip"

      - name: install dependencies
        run: |
          pip install -r requirements.txt
          dbt deps

      - name: Run DBT Jobs
        run: |
          ${{ inputs.dbt_command }}

      - name: Run datashare model
        run: |
          cnt=$(dbt ls -m fsc_utils.datashare._datashare___create_gold | wc -l ); if [ $cnt -gt 0 ]; then dbt run -m fsc_utils.datashare._datashare___create_gold; fi; 
          dbt run-operation run_query --args "{sql: call admin.datashare.sp_grant_share_permissions('${{ env.DATABASE }}')}"

      - name: Store logs
        uses: actions/upload-artifact@v3
        with:
          name: dbt-logs
          path: |
            logs
            target

'''
'''--- .github/workflows/dbt_run_dev_refresh.yml ---
name: dbt_run_dev_refresh
run-name: dbt_run_dev_refresh

on:
  workflow_dispatch:
  schedule:
    # Runs 0800 daily (see https://crontab.guru)
    - cron: "* 8 * * *"

env:
  USE_VARS: "${{ vars.USE_VARS }}"
  DBT_PROFILES_DIR: "${{ vars.DBT_PROFILES_DIR }}"
  DBT_VERSION: "${{ vars.DBT_VERSION }}"
  ACCOUNT: "${{ vars.ACCOUNT }}"
  ROLE: "${{ vars.ROLE }}"
  USER: "${{ vars.USER }}"
  PASSWORD: "${{ secrets.PASSWORD }}"
  REGION: "${{ vars.REGION }}"
  DATABASE: "${{ vars.DATABASE }}"
  WAREHOUSE: "${{ vars.WAREHOUSE }}"
  SCHEMA: "${{ vars.SCHEMA }}"

concurrency:
  group: ${{ github.workflow }}

jobs:
  dbt:
    runs-on: ubuntu-latest
    environment:
      name: workflow_prod
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-python@v4
        with:
          python-version: "3.10"
          cache: "pip"

      - name: install dependencies
        run: |
          pip install -r requirements.txt
          dbt deps

      - name: Run DBT Jobs
        run: |
          dbt run-operation run_sp_create_prod_clone;

      - name: Store logs
        uses: actions/upload-artifact@v3
        with:
          name: dbt-logs
          path: |
            logs
            target

'''
'''--- .github/workflows/dbt_run_full_observability.yml ---
name: dbt_run_full_observability
run-name: dbt_run_full_observability

on:
  workflow_dispatch:
  schedule:
    # Runs ‚ÄúAt 00:00 on day-of-month 1.‚Äù (see https://crontab.guru)
    - cron: "0 0 1 * *"

env:
  USE_VARS: "${{ vars.USE_VARS }}"
  DBT_PROFILES_DIR: "${{ vars.DBT_PROFILES_DIR }}"
  DBT_VERSION: "${{ vars.DBT_VERSION }}"
  ACCOUNT: "${{ vars.ACCOUNT }}"
  ROLE: "${{ vars.ROLE }}"
  USER: "${{ vars.USER }}"
  PASSWORD: "${{ secrets.PASSWORD }}"
  REGION: "${{ vars.REGION }}"
  DATABASE: "${{ vars.DATABASE }}"
  WAREHOUSE: "${{ vars.WAREHOUSE }}"
  SCHEMA: "${{ vars.SCHEMA }}"

concurrency:
  group: ${{ github.workflow }}

jobs:
  run_dbt_jobs:
    runs-on: ubuntu-latest
    environment:
      name: workflow_prod

    steps:
      - uses: actions/checkout@v3

      - uses: actions/setup-python@v4
        with:
          python-version: "3.10"

      - name: install dependencies

        run: |
          pip install -r requirements.txt
          dbt deps

      - name: Run DBT Jobs
        run: |
          dbt run --threads 2 --vars '{"OBSERV_FULL_TEST":True}' -m tag:observability

'''
'''--- .github/workflows/dbt_run_livequery_scheduled.yml ---
name: dbt_run_livequery_scheduled
run-name: dbt_run_livequery_scheduled

on:
  workflow_dispatch:
  schedule:
    # Runs hourly (see https://crontab.guru)
    - cron: '0 * * * *'

env:
  USE_VARS: "${{ vars.USE_VARS }}"
  DBT_PROFILES_DIR: "${{ vars.DBT_PROFILES_DIR }}"
  DBT_VERSION: "${{ vars.DBT_VERSION }}"
  ACCOUNT: "${{ vars.ACCOUNT }}"
  ROLE: "${{ vars.ROLE }}"
  USER: "${{ vars.USER }}"
  PASSWORD: "${{ secrets.PASSWORD }}"
  REGION: "${{ vars.REGION }}"
  DATABASE: "${{ vars.DATABASE }}"
  WAREHOUSE: "${{ vars.WAREHOUSE }}"
  SCHEMA: "${{ vars.SCHEMA }}"
  PAGODA_API_KEY: "${{ secrets.PAGODA_API_KEY }}"
  PAGODA_SQL_LIMIT: "${{ vars.PAGODA_SQL_LIMIT }}"

concurrency:
  group: ${{ github.workflow }}
  
jobs:
  dbt:
    runs-on: ubuntu-latest
    environment:
      name: workflow_prod
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-python@v4
        with:
          python-version: "3.10"
          cache: "pip"

      - name: install dependencies
        run: |
          pip install -r requirements.txt
          dbt deps

      - name: Run LiveQuery Model(s)
        run: |
          dbt run -s tag:pagoda --vars '{"PAGODA_API_KEY": ${{ secrets.PAGODA_API_KEY }}, "SQL_LIMIT": ${{ vars.PAGODA_SQL_LIMIT }}}' 

      - name: Store logs
        uses: actions/upload-artifact@v3
        with:
          name: dbt-logs
          path: |
            logs
            target

'''
'''--- .github/workflows/dbt_run_livequery_weekly.yml ---
name: dbt_run_livequery_weekly
run-name: dbt_run_livequery_weekly

on:
  workflow_dispatch:
  schedule:
    # Runs weekly at 0 UTC on Mondays (see https://crontab.guru)
    - cron: "0 0 * * 1"

env:
  USE_VARS: "${{ vars.USE_VARS }}"
  DBT_PROFILES_DIR: "${{ vars.DBT_PROFILES_DIR }}"
  DBT_VERSION: "${{ vars.DBT_VERSION }}"
  ACCOUNT: "${{ vars.ACCOUNT }}"
  ROLE: "${{ vars.ROLE }}"
  USER: "${{ vars.USER }}"
  PASSWORD: "${{ secrets.PASSWORD }}"
  REGION: "${{ vars.REGION }}"
  DATABASE: "${{ vars.DATABASE }}"
  WAREHOUSE: "${{ vars.WAREHOUSE }}"
  SCHEMA: "${{ vars.SCHEMA }}"

concurrency:
  group: ${{ github.workflow }}

jobs:
  dbt:
    runs-on: ubuntu-latest
    environment:
      name: workflow_prod
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-python@v4
        with:
          python-version: "3.10"
          cache: "pip"

      - name: install dependencies
        run: |
          pip install -r requirements.txt
          dbt deps

      - name: Run DBT Jobs
        run: |
          dbt run -s tag:nearblocks tag:activity

      - name: Store logs
        uses: actions/upload-artifact@v3
        with:
          name: dbt-logs
          path: |
            logs
            target

'''
'''--- .github/workflows/dbt_run_nearblocks_api.yml ---
name: dbt_run_nearblocks_api
run-name: dbt_run_nearblocks_api

on:
  workflow_dispatch:
  # Disabling schedule
  # schedule:
  # Runs 0100 UTC daily (see https://crontab.guru)
  # - cron: '0 1 * * *'

env:
  USE_VARS: "${{ vars.USE_VARS }}"
  DBT_PROFILES_DIR: "${{ vars.DBT_PROFILES_DIR }}"
  DBT_VERSION: "${{ vars.DBT_VERSION }}"
  ACCOUNT: "${{ vars.ACCOUNT }}"
  ROLE: "${{ vars.ROLE }}"
  USER: "${{ vars.USER }}"
  PASSWORD: "${{ secrets.PASSWORD }}"
  REGION: "${{ vars.REGION }}"
  DATABASE: "${{ vars.DATABASE }}"
  WAREHOUSE: "${{ vars.WAREHOUSE }}"
  SCHEMA: "${{ vars.SCHEMA }}"

concurrency:
  group: ${{ github.workflow }}

jobs:
  dbt:
    runs-on: ubuntu-latest
    environment:
      name: workflow_prod
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-python@v4
        with:
          python-version: "3.10"
          cache: "pip"

      - name: install dependencies
        run: |
          pip install -r requirements.txt
          dbt deps

      - name: Run DBT Jobs
        run: |
          dbt run-operation get_nearblocks_fts

      - name: Store logs
        uses: actions/upload-artifact@v3
        with:
          name: dbt-logs
          path: |
            logs
            target

'''
'''--- .github/workflows/dbt_run_observability.yml ---
name: dbt_run_observability
run-name: dbt_run_observability

on:
  workflow_dispatch:
  schedule:
    # Runs "2 times per day" (see https://crontab.guru)
    - cron: "0 6,18 * * *"

env:
  USE_VARS: "${{ vars.USE_VARS }}"
  DBT_PROFILES_DIR: "${{ vars.DBT_PROFILES_DIR }}"
  DBT_VERSION: "${{ vars.DBT_VERSION }}"
  ACCOUNT: "${{ vars.ACCOUNT }}"
  ROLE: "${{ vars.ROLE }}"
  USER: "${{ vars.USER }}"
  PASSWORD: "${{ secrets.PASSWORD }}"
  REGION: "${{ vars.REGION }}"
  DATABASE: "${{ vars.DATABASE }}"
  WAREHOUSE: "${{ vars.WAREHOUSE }}"
  SCHEMA: "${{ vars.SCHEMA }}"

concurrency:
  group: ${{ github.workflow }}

jobs:
  run_dbt_jobs:
    runs-on: ubuntu-latest
    environment:
      name: workflow_prod

    steps:
      - uses: actions/checkout@v3

      - uses: actions/setup-python@v4
        with:
          python-version: "3.10"

      - name: install dependencies

        run: |
          pip install -r requirements.txt
          dbt deps
      - name: Run DBT Jobs
        run: |
          dbt run --threads 2 --vars '{"OBSERV_FULL_TEST":False}' -m tag:observability

'''
'''--- .github/workflows/dbt_run_scheduled.yml ---
name: dbt_run_scheduled
run-name: dbt_run_scheduled

on:
  workflow_dispatch:
  schedule:
    # Runs "every hour" (see https://crontab.guru)
    - cron: "30 * * * *"

env:
  USE_VARS: "${{ vars.USE_VARS }}"
  DBT_PROFILES_DIR: "${{ vars.DBT_PROFILES_DIR }}"
  DBT_VERSION: "${{ vars.DBT_VERSION }}"
  ACCOUNT: "${{ vars.ACCOUNT }}"
  ROLE: "${{ vars.ROLE }}"
  USER: "${{ vars.USER }}"
  PASSWORD: "${{ secrets.PASSWORD }}"
  REGION: "${{ vars.REGION }}"
  DATABASE: "${{ vars.DATABASE }}"
  WAREHOUSE: "${{ vars.WAREHOUSE }}"
  SCHEMA: "${{ vars.SCHEMA }}"

concurrency:
  group: ${{ github.workflow }}

jobs:
  dbt:
    runs-on: ubuntu-latest
    environment:
      name: workflow_prod
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-python@v4
        with:
          python-version: "3.10"
          cache: "pip"

      - name: install dependencies
        run: |
          pip install -r requirements.txt
          dbt deps

      - name: Run DBT Jobs
        run: |
          dbt run-operation dispatch_github_workflow --args "{'repo_name': 'streamline-snowflake', 'workflow_name': 'dbt_run_near_external_table_update', 'gb_id': '${{ secrets.GB_ID}}'}";
          dbt seed; dbt run -s models/bronze tag:helper tag:load+ tag:labels+ tag:scheduled_non_core --exclude streamline__s3_sync tag:livequery tag:atlas tag:exclude_from_schedule

      - name: Store logs
        uses: actions/upload-artifact@v3
        with:
          name: dbt-logs
          path: |
            logs
            target

'''
'''--- .github/workflows/dbt_test.yml ---
name: dbt_test_scheduled
run-name: dbt_test_scheduled

on:
  workflow_dispatch:
  schedule:
    # Run at 1245 UTC daily (see https://crontab.guru)
    - cron: "45 12 * * *"
env:
  USE_VARS: "${{ vars.USE_VARS }}"
  DBT_PROFILES_DIR: "${{ vars.DBT_PROFILES_DIR }}"
  DBT_VERSION: "${{ vars.DBT_VERSION }}"
  ACCOUNT: "${{ vars.ACCOUNT }}"
  ROLE: "${{ vars.ROLE }}"
  USER: "${{ vars.USER }}"
  PASSWORD: "${{ secrets.PASSWORD }}"
  REGION: "${{ vars.REGION }}"
  DATABASE: "${{ vars.DATABASE }}"
  WAREHOUSE: "${{ vars.TEST_WAREHOUSE }}"
  SCHEMA: "${{ vars.SCHEMA }}"
  SLACK_WEBHOOK_URL: "${{ secrets.SLACK_WEBHOOK_URL }}"

concurrency:
  group: ${{ github.workflow }}

jobs:
  run_dbt_jobs:
    runs-on: ubuntu-latest
    environment:
      name: workflow_prod

    steps:
      - uses: actions/checkout@v3

      - uses: actions/setup-python@v4
        with:
          python-version: "3.10"

      - name: install dependencies
        run: |
          pip install -r requirements.txt
          dbt deps
      - name: Run DBT Jobs
        run: |
          dbt test -s models/gold
        continue-on-error: true

      - name: Log test results
        run: |
          python python_scripts/test_alert/dbt_test_alert.py

'''
'''--- README.md ---
# Near DBT Project

Curated SQL Views and Metrics for the Near Blockchain.

What's Near? Learn more [here](https://near.org/)

## Variables

To control which external table environment a model references, as well as, whether a Stream is invoked at runtime using control variables:
* STREAMLINE_INVOKE_STREAMS
When True, invokes streamline on model run as normal
When False, NO-OP
* STREAMLINE_USE_DEV_FOR_EXTERNAL_TABLES
When True, uses DEV schema Streamline. Ethereum_DEV
When False, uses PROD schema Streamline. Ethereum

Default values are False

* Usage:
 `dbt run --var '{"STREAMLINE_USE_DEV_FOR_EXTERNAL_TABLES": True, "STREAMLINE_INVOKE_STREAMS": True}'  -m ...`

To control the creation of UDF or SP macros with dbt run:
* UPDATE_UDFS_AND_SPS
When True, executes all macros included in the on-run-start hooks within dbt_project.yml on model run as normal
When False, none of the on-run-start macros are executed on model run

Default values are False

* Usage:
 `dbt run --var '{"UPDATE_UDFS_AND_SPS": True}'  -m ...`

## Applying Model Tags

### Database / Schema level tags

Database and schema tags are applied via the `add_database_or_schema_tags` macro.  These tags are inherited by their downstream objects.  To add/modify tags call the appropriate tag set function within the macro.

```
{{ set_database_tag_value('SOME_DATABASE_TAG_KEY','SOME_DATABASE_TAG_VALUE') }}
{{ set_schema_tag_value('SOME_SCHEMA_TAG_KEY','SOME_SCHEMA_TAG_VALUE') }}
```

### Model tags

To add/update a model's snowflake tags, add/modify the `meta` model property under `config`.  Only table level tags are supported at this time via DBT.

```
{{ config(
    ...,
    meta={
        'database_tags':{
            'table': {
                'PURPOSE': 'SOME_PURPOSE'
            }
        }
    },
    ...
) }}
```

By default, model tags are pushed to Snowflake on each DBT run. You can disable this by setting the `UPDATE_SNOWFLAKE_TAGS` project variable to `False` during a run.

```
dbt run --var '{"UPDATE_SNOWFLAKE_TAGS":False}' -s models/core/core__ez_dex_swaps.sql
```

### Querying for existing tags on a model in snowflake

```
select *
from table(near.information_schema.tag_references('near.core.ez_dex_swaps', 'table'));
```

## Branching / PRs

When conducting work please branch off of main with a description branch name and generate a pull request. At least one other individual must review the PR before it can be merged into main. Once merged into main DBT Cloud will run the new models and output the results into the `PROD` schema.

When creating a PR please include the following details in the PR description:

1. List of Tables Created or Modified
2. Description of changes.
3. Implication of changes (if any).

## Fixing Data Issues

### Manual Batch Refresh

If data needs to be re-run for some reason, partitions of data can be re-reun through the models by utilizing the column `_partition_by_block_number` and passing environment variables.

Any data refresh will need to be done in a batch due to the nature of the receipt <> tx hash mapping. The view `silver__receipt_tx_hash_mapping` is a recursive AncestryTree that follows linked receipt outcome ids to map all receipts generated in a transaction back to the primary hash. Receipts can be generated many blocks after the transaction occurs, so a generous buffer is required to ensure all receipts are captured.
  
The fix makes use of [project variables](https://docs.getdbt.com/docs/build/project-variables#defining-variables-on-the-command-line) to pass the following parameters:
 - MANUAL_FIX (required): This will run the models with the specified range, rather than the standard incremental logic. `False` by default.
 - RANGE_START (required): The start of the block partition range (nearest 10,000) to run.
 - RANGE_END (required): The end of the block partition range (nearest 10,000) to run.
 - FRONT_BUFFER (optional): The number of partitions to add to the front of the range. 1 by default, not likely to need changing.
 - END_BUFFER (optional): The number of partitions to add to the end of the range. 1 by default, not likely to need changing.

`FRONT_BUFFER` and `END_BUFFER` are set to 1 by default and indicate how many partitions (10k blocks) should be added on to the front or end of the range.
 - Flatten receipts is set to look back 1 partition to grab receipts that may have occurred prior to the start of the range.
 - Receipt tx hash mapping is set to look back 1 partition to grab receipts that may have occurred prior to the start of the range.
 - Receipts final does not buffer the range to only map receipts that occurred within the range to a tx hash (but the lookback is necessary in case the tree is truncated by the partition break).
 - Transactions final does not add a buffer when grabbing transactions from the int txs model, but does add an end buffer when selecting from receipts final to include mapped receipts that may have occurred after the end of the range.

```
dbt run -s [tags] --vars [variables]
```

#### dbt Model Tags

To help with targeted refreshes, a number of tags have been applied to the models. These are defined below:

| Tag | Description | View Models |
| --- | --- | --- | 
| load | Runs models that load data into Snowflake from S3. The 2 `load_X` models are staging tables for data, which is then parsed and transformed up until the final txs/receipts models. | [link](https://flipsidecrypto.github.io/near-models/#!/overview?g_v=1&g_i=tag:load) |
| load_shards | Just the `load` models that touch shards | [link](https://flipsidecrypto.github.io/near-models/#!/overview?g_v=1&g_i=tag:load_shards) |
| load_blocks | Just the `load` models that touch blocks | [link](https://flipsidecrypto.github.io/near-models/#!/overview?g_v=1&g_i=tag:load_blocks) |
| receipt_map | Runs the receipt-mapping models that must use a partition. This set of models cannot simply run with incremental logic due to the recursive tree used to map receipt IDs to Tx Hashes. | [link](https://flipsidecrypto.github.io/near-models/#!/overview?g_v=1&g_i=tag:receipt_map) |
| actions | Just the 3 action events models, an important set of intermediary models before curated activity. Note: These are also tagged with `s3_curated`. | [link](https://flipsidecrypto.github.io/near-models/#!/overview?g_v=1&g_i=tag:actions) |
| curated | Models that are used to generate the curated tables | [link](https://flipsidecrypto.github.io/near-models/#!/overview?g_v=1&g_i=tag:curated) |
| core | All public views are tagged with core, regardless of schema. At this time, that includes `core` and `social`. | [link](https://flipsidecrypto.github.io/near-models/#!/overview?g_v=1&g_i=tag:core) |

Note: there are other tags that are currently not used. All legacy models are tagged with something that includes `rpc`, but all are presently disabled to avoid an accidental run.  
You can visualize these tags by using the DAG Explorer in the [docs](https://flipsidecrypto.github.io/near-models/#!/overview?g_v=1&g_i=tag:load).  

#### Load Missing Blocks or Shards
[Blocks](models/silver/streamline/silver__load_blocks.sql) and [shards](models/silver/streamline/silver__load_shards.sql) can be re-loaded using the load tag(s).
 - `load` will run both blocks and shards models, landing data in `silver__streamline_blocks`, `silver__streamline_receipts`, `silver__streamline_receipt_chunks`, and `silver__streamline_transactions`.
 - `load_blocks` will run just the blocks models, landing data in `silver__streamline_blocks`.
 - `load_shards` will run just the shards models, landing data in `silver__streamline_receipts`, `silver__streamline_receipt_chunks`, and `silver__streamline_transactions`.

The logic in the load_x models will only check the external table for blocks and shards known to be missing. It will query the sequence gap test table(s), thus the partition range is not required for this step, as it will take that from the test table.

```
dbt run -s tag:load --vars '{"MANUAL_FIX": True}'
```

#### Map Tx Hash <> Receipt Hash
The middle step is to map receipt IDs to transaction hashes. This is done in 3 models, which are tagged with `receipt_map`. 2 of these models are helper views that recursively map out the receipt->parent receipt->...->transaction, thus linking all receipts to a transaction. This step is computationally intensive, and requires a tight partition range. For present blocks with more activity, <250k is recommended. 

The following will read a range of receipts from `silver__streamline_receipts` and link receipts to the corresponding tx hash, saving the result to `silver__streamline_receipts_final`. It will then insert receipt data into the `tx` object in `silver__streamline_transactions_final`.

```
dbt run -s tag:receipt_map --vars '{"MANUAL_FIX": True, "RANGE_START": X, "RANGE_END": Y}'
```

If the range being mapped is the same range as the block/shard re-walk, then the tag can simply be appended to the load job and the receipts will be mapped after ingestion.
```
dbt run -s tag:load tag:receipt_map --vars '{"MANUAL_FIX": True, "RANGE_START": X, "RANGE_END": Y}'
```

The end result of this run will be `streamline__receipts_final` and `streamline__transactions_final` ([link](https://flipsidecrypto.github.io/near-models/#!/overview?g_v=1&g_i=tag:load%20tag:receipt_map)).

#### Update curated models
 Actions and curated models include the conditional based on target name so the tags `actions` and `curated` can be included to re-run the fixed data in downstream silver models. If missing data is loaded in new, this should not be necessary as `_load_timestamp` will be set to when the data hits snowflake and will flow through the standard incremental logic in the curated models. However, the range can be run with the curated tag:

 ```
dbt run -s tag:curated --vars '{"MANUAL_FIX": True, "RANGE_START": X, "RANGE_END": Y}'
```
Or
```
dbt run -s tag:load tag:receipt_map tag:curated --vars '{"MANUAL_FIX": True, "RANGE_START": X, "RANGE_END": Y}'
```

### Incremental Load Strategy
Because data must be run in batches to properly map receipts to a transaction hash, a conditional is added to curated models using jinja. This should be present on everything after the mapping process.
Most data will have no issue running with a standard incremental load. This filter is required for the above commands in the **Manual Batch Refresh** section.

Include the following conditional, as targeted runs of block partitions may be required:
```
        {% if var("MANUAL_FIX") %}
            {{ partition_load_manual('no_buffer') }}
        {% else %}
            {{ incremental_load_filter('_inserted_timestamp') }}
        {% endif %}
```
## More DBT Resources:

* Learn more about dbt [in the docs](https://docs.getdbt.com/docs/introduction)
* Check out [Discourse](https://discourse.getdbt.com/) for commonly asked questions and answers
* Check out [the blog](https://blog.getdbt.com/) for the latest news on dbt's development and best practices
'''
'''--- dbt_project.yml ---
# Name your project! Project names should contain only lowercase characters
# and underscores. A good package name should reflect your organization's
# name or the intended use of these models
name: "near"
version: "1.2.0"
config-version: 2

# This setting configures which "profile" dbt uses for this project.
profile: "near"
require-dbt-version: ">=1.7.0"

# These configurations specify where dbt should look for different types of files.
# The `source-paths` config, for example, states that models in this project can be
# found in the "models/" directory. You probably won't need to change these!
model-paths: ["models"]
analysis-paths: ["analysis"]
test-paths: ["tests"]
seed-paths: ["data"]
macro-paths: ["macros"]
snapshot-paths: ["snapshots"]

target-path: "target" # directory which will store compiled SQL files
clean-targets: # directories to be removed by `dbt clean`
  - "target"
  - "dbt_modules"
  - "dbt_packages"

on-run-start:
  - "{{ create_udfs() }}"
  - "{{create_sps()}}"
  - "{{create_get_nearblocks_fts()}}"

on-run-end:
  - "{{ apply_meta_as_tags(results) }}"

# Configuring models
# Full documentation: https://docs.getdbt.com/docs/configuring-models

# In this example config, we tell dbt to build all models in the example/ directory
# as tables. These settings can be overridden in the individual model files
# using the `{{ config(...) }}` macro.
models:
  +copy_grants: True
  +persist_docs:
    relation: True
    columns: True
  +on_schema_change: "append_new_columns"

tests:
  near:
    silver:
      +error_if: ">100" # only raise as error if >100, otherwise warn
  +store_failures: True # all tests

vars:
  "dbt_date:time_zone": GMT
  STREAMLINE_INVOKE_STREAMS: False
  STREAMLINE_USE_DEV_FOR_EXTERNAL_TABLES: False
  UPDATE_UDFS_AND_SPS: False
  UPDATE_SNOWFLAKE_TAGS: True
  MANUAL_FIX: False
  OBSERV_FULL_TEST: False
  DBT_FULL_TEST: False
  STREAMLINE_LOAD_LOOKBACK_HOURS: 3
  RECEIPT_MAP_LOOKBACK_HOURS: 6
  IS_MIGRATION: False

dispatch:
  - macro_namespace: dbt
    search_order:
      - near-models
      - dbt_snowflake_query_tags
      - dbt

query-comment:
  comment: "{{ dbt_snowflake_query_tags.get_query_comment(node) }}"
  append: true # Snowflake removes prefixed comments.

'''
'''--- docker-compose.yml ---
version: "3.4"

services:
  dbt_console:
    build: .
    volumes:
      - .:/near
    env_file: 
      - .env

'''
'''--- docs/vercel.json ---
{
    "github": {
        "silent": true
    }
}
'''
'''--- docs/vercel.sh ---
#!/bin/bash

echo "VERCEL_ENV: $VERCEL_ENV"

if [[ "$VERCEL_ENV" == "production" ]] ; then
  # Proceed with the build
  echo "‚úÖ - Build can proceed"
  exit 1;

else
  # Don't build
  echo "üõë - Build cancelled"
  exit 0;
fi

'''
'''--- macros/api_udf/create_get_nearblocks_fts.sql ---
{# Deprecated 9/25/2023 #}
{% macro create_get_nearblocks_fts() %}
  {% set create_table %}
  CREATE schema if NOT EXISTS {{ target.database }}.bronze_api;
CREATE TABLE if NOT EXISTS {{ target.database }}.bronze_api.nearblocks_fts(
    token_name STRING,
    token_contract STRING,
    token_data variant,
    provider STRING,
    _inserted_timestamp timestamp_ntz,
    _res_id STRING
  );
{% endset %}
  {% do run_query(create_table) %}
  {% set query %}
  {% set max_loops = 20 %}
  CREATE
  OR REPLACE PROCEDURE {{ target.database }}.bronze_api.get_nearblocks_fts() returns variant LANGUAGE SQL AS $$
BEGIN
  let counter:= 1;
  let number_of_iterations:= 0;
REPEAT 
number_of_iterations:= number_of_iterations + 1;
let page:= counter;
CREATE
  OR REPLACE temporary TABLE response_data AS WITH api_call AS (
    SELECT
      ethereum.streamline.udf_api(
        'GET',
        'https://api.nearblocks.io/v1/fts',
        {},
        { 
          'page': :page,
          'per_page': 50,
          'sort': 'name',
          'order': 'asc' 
        }
      ) AS res,
      ARRAY_SIZE(
        res :data :tokens
      ) AS token_count,
      CURRENT_TIMESTAMP AS _request_timestamp
  ),
  flatten_res AS (
    SELECT
      VALUE :name :: STRING AS token_name,
      VALUE :contract :: STRING AS token_contract,
      VALUE AS token_data,
      'nearblocks' AS provider,
      _request_timestamp AS _inserted_timestamp,
      concat_ws('-', DATE_PART(epoch_second, _request_timestamp), token_contract) AS _res_id
    FROM
      api_call,
      LATERAL FLATTEN(
        input => res :data :tokens
      )
  )
SELECT
  token_name,
  token_contract,
  token_data,
  provider,
  _inserted_timestamp,
  _res_id
FROM
  flatten_res;
INSERT INTO
  bronze_api.nearblocks_fts(
    token_name,
    token_contract,
    token_data,
    provider,
    _inserted_timestamp,
    _res_id
  )
SELECT
  token_name,
  token_contract,
  token_data,
  provider,
  _inserted_timestamp,
  _res_id
FROM
  response_data;
counter:= counter + 1;
until (
    counter = {{ max_loops }}
    OR (
      SELECT
        COUNT(1) = 0
      FROM
        response_data
    )
  )
END REPEAT;
RETURN number_of_iterations;
END;$$ 
{% endset %}
{% do run_query(query) %}
{% endmacro %}

'''
'''--- macros/api_udf/get_nearblocks_fts.sql ---
{# Deprecated 9/25/2023 #}

{% macro get_nearblocks_fts() %}
{% set sql %}

CALL {{ target.database }}.bronze_api.get_nearblocks_fts()

{% endset %}
{% do run_query(sql) %}
{% endmacro%}

'''
'''--- macros/create_procedure_get_chainhead.sql ---
{% macro create_PROCEDURE_GET_CHAINHEAD() %}
    {% set sql %}
        CREATE OR REPLACE PROCEDURE {{ target.database }}.STREAMLINE.GET_CHAINHEAD(
        ) RETURNS STRING
        LANGUAGE JAVASCRIPT
        EXECUTE AS CALLER
        AS
        $$
        let resultFound = false;
        let blockId = 0;
        while (!resultFound) {
            var stmt = snowflake.createStatement({
                sqlText: `SELECT {{ target.database }}.live.udf_api(
                        'POST',
                        'https://rpc.mainnet.near.org',
                        { 
                            'Content-Type': 'application/json' 
                        },
                        { 
                            'jsonrpc': '2.0',
                            'id': 'dontcare',
                            'method' :'status',
                            'params':{
                                'finality': 'final' 
                                }
                        }
                ) :data :result :sync_info :latest_block_height :: INT AS block_id;`
            });
            var result = stmt.execute();
            result.next();
            res_temp = result.getColumnValue(1); 
            if (res_temp != null) {
                res = res_temp;
                resultFound = true;
            }
        }
        return res;
        $$;
    {% endset %}
    {% do run_query(sql) %}
{% endmacro %}

'''
'''--- macros/create_sps.sql ---
{% macro create_sps() %}
    {% if target.database == 'NEAR' %}
        CREATE schema IF NOT EXISTS _internal;
{{ sp_create_prod_clone('_internal') }};
    {% endif %}
{% endmacro %}

'''
'''--- macros/create_udfs.sql ---
{% macro create_udfs() %}
    {% if var("UPDATE_UDFS_AND_SPS") %}
        {% if target.database != "NEAR_COMMUNITY_DEV" %}
            {% set sql %}
                CREATE schema if NOT EXISTS silver;
                CREATE schema if NOT EXISTS streamline;
                {{ create_udf_introspect() }}
                {{ create_udf_s3_list_directories() }}
                {{ create_udf_s3_list_objects() }}
                {{ create_udf_s3_copy_objects() }}
                {{ create_udf_s3_copy_objects_overwrite() }}
                {{ create_UDTF_CALL_CONTRACT_FUNCTION() }}
                {{ create_UDTF_CALL_CONTRACT_FUNCTION_BY_HEIGHT() }}
                {{ create_UDF_GET_CHAINHEAD() }}
            {% endset %}
            {% do run_query(sql) %}
        {{- fsc_utils.create_udfs() -}}
        {% endif %}
    {% endif %}
{% endmacro %}

'''
'''--- macros/custom_naming_macros.sql ---
{% macro generate_schema_name(
        custom_schema_name = none,
        node = none
    ) -%}
    {% set node_name = node.name %}
    {% set split_name = node_name.split('__') %}
    {{ split_name [0] | trim }}
{%- endmacro %}

{% macro generate_alias_name(
        custom_alias_name = none,
        node = none
    ) -%}
    {% set node_name = node.name %}
    {% set split_name = node_name.split('__') %}
    {{ split_name [1] | trim }}
{%- endmacro %}

'''
'''--- macros/helpers/helpers.sql ---
{% macro dispatch_github_workflow(repo_name, workflow_name, gb_id) %}
    {% set context_query %}
        SET LIVEQUERY_CONTEXT = '{"userId":"{{ gb_id }}"}';
    {% endset %}
    {% do run_query(context_query) %}
    {% set query %}
        SELECT github_actions.workflow_dispatches('FlipsideCrypto', '{{ repo_name }}', '{{ workflow_name }}.yml', NULL)
    {% endset %}
    {% do run_query(query) %}
{% endmacro %}
'''
'''--- macros/incremental_utils.sql ---
{% macro incremental_load_filter(time_col) -%}

{% if is_incremental() %}
{{ time_col }} >= (
  SELECT
    MAX(
      {{ time_col }}
    )
  FROM
    {{ this }}
)
{%- else -%}
  TRUE
{% endif %}
{%- endmacro %}

{% macro incremental_last_x_days(
    time_col,
    time_in_days
  ) -%}

{% if is_incremental() %}
{{ time_col }} :: DATE >= SYSDATE() - INTERVAL '{{ time_in_days }}'
{% else %}
  TRUE
{% endif %}
{%- endmacro %}

{% macro incremental_pad_x_minutes(
    time_col,
    time_in_minutes
  ) -%}

{% if is_incremental() %}
{{ time_col }} >= (
  SELECT
    MAX(
      {{ time_col }}
    )
  FROM
    {{ this }}
) - INTERVAL '{{ time_in_minutes }} minutes'
{% else %}
  TRUE
{% endif %}
{%- endmacro %}

'''
'''--- macros/manual_batch_refresh.sql ---
{% macro partition_load_manual(
        scope = 'no_buffer'
    ) %}
    {# if range_start and range_end not set in cli, default to earliest rpc data #}
    {% set range_start = var(
        'RANGE_START',
        46700000
    ) %}
    {% set range_end = var(
        'RANGE_END',
        47000000
    ) %}
    {% set front_buffer = var(
        'FRONT_BUFFER',
        1
    ) %}
    {% set end_buffer = var(
        'END_BUFFER',
        1
    ) %}
    {% if scope == 'front' %}
        _partition_by_block_number BETWEEN {{ range_start }} - (
            10000 * {{ front_buffer }}
        )
        AND {{ range_end }}

        {% elif scope == 'end' %}
        _partition_by_block_number BETWEEN {{ range_start }}
        AND {{ range_end }} + (
            10000 * {{ end_buffer }}
        ) {% elif scope == 'no_buffer' %}
        _partition_by_block_number BETWEEN {{ range_start }}
        AND {{ range_end }}
    {% else %}
        TRUE
    {% endif %}
{%- endmacro %}

'''
'''--- macros/partition_batch_load.sql ---
{% macro partition_batch_load(batch_size) %}

{% if is_incremental() %}
_partition_by_block_number BETWEEN (
    SELECT
        MAX(_partition_by_block_number)
    FROM
        {{ this }}
)
AND (
    (
        SELECT
            MAX(_partition_by_block_number)
        FROM
            {{ this }}
    ) + {{ batch_size }}
)
{%- else -%}
    _partition_by_block_number BETWEEN 9820000
    AND 10000000
{% endif %}
{%- endmacro %}

{% macro partition_incremental_load(
        batch_size,
        front_buffer = 0,
        end_buffer = 0
    ) %}

{% if is_incremental() %}
_partition_by_block_number BETWEEN (
    SELECT
        MAX(_partition_by_block_number) - {{ front_buffer }}
    FROM
        {{ this }}
)
AND (
    (
        SELECT
            MAX(_partition_by_block_number)
        FROM
            {{ this }}
    ) + {{ batch_size }} + {{ end_buffer }}
)
{%- else -%}
    TRUE
{% endif %}
{%- endmacro %}

'''
'''--- macros/run_sp_create_prod_clone.sql ---
{% macro run_sp_create_prod_clone() %}
    {% set clone_query %}
    call near._internal.create_prod_clone(
        'near',
        'near_dev',
        'internal_dev'
    );
{% endset %}
    {% do run_query(clone_query) %}
{% endmacro %}

'''
'''--- macros/run_sp_create_prod_community_clone.sql ---
{% macro run_sp_create_prod_community_clone() %}
{% set clone_query %}
call near._internal.create_prod_clone('near', 'near_community_dev', 'flipside_community_curator');
{% endset %}

{% do run_query(clone_query) %}
{% endmacro %}
'''
'''--- macros/sp_create_prod_clone.sql ---
{% macro sp_create_prod_clone(target_schema) -%}

create or replace procedure {{ target_schema }}.create_prod_clone(source_db_name string, destination_db_name string, role_name string)
returns boolean 
language javascript
execute as caller
as
$$
    snowflake.execute({sqlText: `BEGIN TRANSACTION;`});
    try {
        snowflake.execute({sqlText: `CREATE OR REPLACE DATABASE ${DESTINATION_DB_NAME} CLONE ${SOURCE_DB_NAME}`});
        snowflake.execute({sqlText: `DROP SCHEMA IF EXISTS ${DESTINATION_DB_NAME}._INTERNAL`}); /* this only needs to be in prod */
        snowflake.execute({sqlText: `GRANT USAGE ON DATABASE ${DESTINATION_DB_NAME} TO AWS_LAMBDA_ETHEREUM_API`}); 

        snowflake.execute({sqlText: `GRANT OWNERSHIP ON ALL SCHEMAS IN DATABASE ${DESTINATION_DB_NAME} TO ROLE ${ROLE_NAME} COPY CURRENT GRANTS;`}); 
        snowflake.execute({sqlText: `GRANT OWNERSHIP ON ALL FUNCTIONS IN DATABASE ${DESTINATION_DB_NAME} TO ROLE ${ROLE_NAME} COPY CURRENT GRANTS;`}); 
        snowflake.execute({sqlText: `GRANT OWNERSHIP ON ALL PROCEDURES IN DATABASE ${DESTINATION_DB_NAME} TO ROLE ${ROLE_NAME} COPY CURRENT GRANTS;`}); 
        snowflake.execute({sqlText: `GRANT OWNERSHIP ON ALL VIEWS IN DATABASE ${DESTINATION_DB_NAME} TO ROLE ${ROLE_NAME} COPY CURRENT GRANTS;`}); 
        snowflake.execute({sqlText: `GRANT OWNERSHIP ON ALL STAGES IN DATABASE ${DESTINATION_DB_NAME} TO ROLE ${ROLE_NAME} COPY CURRENT GRANTS;`}); 
        snowflake.execute({sqlText: `GRANT OWNERSHIP ON ALL TABLES IN DATABASE ${DESTINATION_DB_NAME} TO ROLE ${ROLE_NAME} COPY CURRENT GRANTS;`}); 
        snowflake.execute({sqlText: `GRANT OWNERSHIP ON FUTURE FUNCTIONS IN DATABASE ${DESTINATION_DB_NAME} TO ROLE ${ROLE_NAME};`}); 
        snowflake.execute({sqlText: `GRANT OWNERSHIP ON FUTURE PROCEDURES IN DATABASE ${DESTINATION_DB_NAME} TO ROLE ${ROLE_NAME};`}); 
        snowflake.execute({sqlText: `GRANT OWNERSHIP ON FUTURE VIEWS IN DATABASE ${DESTINATION_DB_NAME} TO ROLE ${ROLE_NAME};`}); 
        snowflake.execute({sqlText: `GRANT OWNERSHIP ON FUTURE STAGES IN DATABASE ${DESTINATION_DB_NAME} TO ROLE ${ROLE_NAME};`}); 
        snowflake.execute({sqlText: `GRANT OWNERSHIP ON FUTURE TABLES IN DATABASE ${DESTINATION_DB_NAME} TO ROLE ${ROLE_NAME};`}); 
        snowflake.execute({sqlText: `GRANT USAGE ON ALL STAGES IN DATABASE ${DESTINATION_DB_NAME} TO ROLE AWS_LAMBDA_ETHEREUM_API;`}); 

        snowflake.execute({sqlText: `GRANT OWNERSHIP ON DATABASE ${DESTINATION_DB_NAME} TO ROLE ${ROLE_NAME} COPY CURRENT GRANTS;`})

        var existing_tags = snowflake.execute({sqlText: `SHOW TAGS IN DATABASE ${DESTINATION_DB_NAME};`});
        while (existing_tags.next()) {
            var schema = existing_tags.getColumnValue(4);
            var tag_name = existing_tags.getColumnValue(2)
            snowflake.execute({sqlText: `GRANT OWNERSHIP ON TAG ${DESTINATION_DB_NAME}.${schema}.${tag_name} TO ROLE ${ROLE_NAME} COPY CURRENT GRANTS;`});
        }

        snowflake.execute({sqlText: `COMMIT;`});
    } catch (err) {
        snowflake.execute({sqlText: `ROLLBACK;`});
        throw(err);
    }

    return true
$$

{%- endmacro %}
'''
'''--- macros/streamline_udfs.sql ---
{% macro create_udf_introspect() %}
    CREATE
    OR REPLACE EXTERNAL FUNCTION streamline.udf_introspect(
        echo STRING
    ) returns text api_integration = aws_stg_us_east_1_api AS {% if target.name == "prod" %}
        'https://jfqhk99kj1.execute-api.us-east-1.amazonaws.com/stg/s3/introspect'
    {% else %}
        'https://jfqhk99kj1.execute-api.us-east-1.amazonaws.com/stg/s3/introspect'
    {%- endif %};
{% endmacro %}

{% macro create_udf_s3_list_directories() %}
    CREATE
    OR REPLACE EXTERNAL FUNCTION streamline.udf_s3_list_directories(
        path STRING
    ) returns ARRAY api_integration = aws_stg_us_east_1_api max_batch_rows = 15 AS {% if target.name == "prod" %}
        'https://jfqhk99kj1.execute-api.us-east-1.amazonaws.com/stg/s3/list_directories'
    {% else %}
        'https://jfqhk99kj1.execute-api.us-east-1.amazonaws.com/stg/s3/list_directories'
    {%- endif %};
{% endmacro %}

{% macro create_udf_s3_list_objects() %}
    CREATE
    OR REPLACE EXTERNAL FUNCTION streamline.udf_s3_list_objects(
        path STRING
    ) returns ARRAY api_integration = aws_stg_us_east_1_api max_batch_rows = 15 AS {% if target.name == "prod" %}
        'https://jfqhk99kj1.execute-api.us-east-1.amazonaws.com/stg/s3/list_objects'
    {% else %}
        'https://jfqhk99kj1.execute-api.us-east-1.amazonaws.com/stg/s3/list_objects'
    {%- endif %};
{% endmacro %}

{% macro create_udf_s3_copy_objects() %}
    CREATE
    OR REPLACE EXTERNAL FUNCTION streamline.udf_s3_copy_objects(
        paths ARRAY,
        source STRING,
        target STRING
    ) returns ARRAY api_integration = aws_stg_us_east_1_api headers = (
        'overwrite' = '1'
    ) max_batch_rows = 3 AS {% if target.name == "prod" %}
        'https://jfqhk99kj1.execute-api.us-east-1.amazonaws.com/stg/s3/copy_objects'
    {% else %}
        'https://jfqhk99kj1.execute-api.us-east-1.amazonaws.com/stg/s3/copy_objects'
    {%- endif %};
{% endmacro %}

{% macro create_udf_s3_copy_objects_overwrite() %}
    CREATE
    OR REPLACE EXTERNAL FUNCTION streamline.udf_s3_objects_overwrite(
        paths ARRAY,
        source STRING,
        target STRING
    ) returns ARRAY api_integration = aws_stg_us_east_1_api headers = (
        'overwrite' = '1'
    ) max_batch_rows = 3 AS {% if target.name == "prod" %}
        'https://jfqhk99kj1.execute-api.us-east-1.amazonaws.com/stg/s3/copy_objects'
    {% else %}
        'https://jfqhk99kj1.execute-api.us-east-1.amazonaws.com/stg/s3/copy_objects'
    {%- endif %};
{% endmacro %}

'''
'''--- macros/tags/add_database_or_schema_tags.sql ---
{% macro add_database_or_schema_tags() %}
    {{ set_database_tag_value('BLOCKCHAIN_NAME','NEAR') }}
{% endmacro %}

'''
'''--- macros/tags/snowflake_tagging.sql ---
{% macro apply_meta_as_tags(results) %}
    {% if var("UPDATE_SNOWFLAKE_TAGS") %}
        {{ log('apply_meta_as_tags', info=False) }}
        {{ log(results, info=False) }}
        {% if execute %}

            {%- set tags_by_schema = {} -%}
            {% for res in results -%}
                {% if res.node.meta.database_tags %}

                    {%- set model_database = res.node.database -%}
                    {%- set model_schema = res.node.schema -%}
                    {%- set model_schema_full = model_database+'.'+model_schema -%}
                    {%- set model_alias = res.node.alias -%}

                    {% if model_schema_full not in tags_by_schema.keys() %}
                        {{ log('need to fetch tags for schema '+model_schema_full, info=False) }}
                        {%- call statement('main', fetch_result=True) -%}
                            show tags in {{model_database}}.{{model_schema}}
                        {%- endcall -%}
                        {%- set _ = tags_by_schema.update({model_schema_full: load_result('main')['table'].columns.get('name').values()|list}) -%}
                        {{ log('Added tags to cache', info=False) }}
                    {% else %}
                        {{ log('already have tag info for schema', info=False) }}
                    {% endif %}

                    {%- set current_tags_in_schema = tags_by_schema[model_schema_full] -%}
                    {{ log('current_tags_in_schema:', info=False) }}
                    {{ log(current_tags_in_schema, info=False) }}
                    {{ log("========== Processing tags for "+model_schema_full+"."+model_alias+" ==========", info=False) }}

                    {% set line -%}
                        node: {{ res.node.unique_id }}; status: {{ res.status }} (message: {{ res.message }})
                        node full: {{ res.node}}
                        meta: {{ res.node.meta}}
                        materialized: {{ res.node.config.materialized }}
                    {%- endset %}
                    {{ log(line, info=False) }}

                    {%- call statement('main', fetch_result=True) -%}
                        select LEVEL,UPPER(TAG_NAME) as TAG_NAME,TAG_VALUE from table(information_schema.tag_references_all_columns('{{model_schema}}.{{model_alias}}', 'table'))
                    {%- endcall -%}
                    {%- set existing_tags_for_table = load_result('main')['data'] -%}
                    {{ log('Existing tags for table:', info=False) }}
                    {{ log(existing_tags_for_table, info=False) }}

                    {{ log('--', info=False) }}
                    {% for table_tag in res.node.meta.database_tags.table %}

                        {{ create_tag_if_missing(current_tags_in_schema,table_tag|upper) }}
                        {% set desired_tag_value = res.node.meta.database_tags.table[table_tag] %}

                        {{set_table_tag_value_if_different(model_schema,model_alias,table_tag,desired_tag_value,existing_tags_for_table)}}
                    {% endfor %}
                    {{ log("========== Finished processing tags for "+model_alias+" ==========", info=False) }}
                {% endif %}
            {% endfor %}
        {% endif %}
    {% endif %}
{% endmacro %}

{% macro create_tag_if_missing(all_tag_names,table_tag) %}
	{% if table_tag not in all_tag_names %}
		{{ log('Creating missing tag '+table_tag, info=False) }}
        {%- call statement('main', fetch_result=True) -%}
            create tag if not exists silver.{{table_tag}}
        {%- endcall -%}
		{{ log(load_result('main').data, info=False) }}
	{% else %}
		{{ log('Tag already exists: '+table_tag, info=False) }}
	{% endif %}
{% endmacro %}

{% macro set_table_tag_value_if_different(model_schema,table_name,tag_name,desired_tag_value,existing_tags) %}
    {{ log('Ensuring tag '+tag_name+' has value '+desired_tag_value+' at table level', info=False) }}
    {%- set existing_tag_for_table = existing_tags|selectattr('0','equalto','TABLE')|selectattr('1','equalto',tag_name|upper)|list -%}
    {{ log('Filtered tags for table:', info=False) }}
    {{ log(existing_tag_for_table[0], info=False) }}
    {% if existing_tag_for_table|length > 0 and existing_tag_for_table[0][2]==desired_tag_value %}
        {{ log('Correct tag value already exists', info=False) }}
    {% else %}
        {{ log('Setting tag value for '+tag_name+' to value '+desired_tag_value, info=False) }}
        {%- call statement('main', fetch_result=True) -%}
            alter table {{model_schema}}.{{table_name}} set tag {{tag_name}} = '{{desired_tag_value}}'
        {%- endcall -%}
        {{ log(load_result('main').data, info=False) }}
    {% endif %}
{% endmacro %}

{% macro set_column_tag_value_if_different(table_name,column_name,tag_name,desired_tag_value,existing_tags) %}
    {{ log('Ensuring tag '+tag_name+' has value '+desired_tag_value+' at column level', info=False) }}
    {%- set existing_tag_for_column = existing_tags|selectattr('0','equalto','COLUMN')|selectattr('1','equalto',tag_name|upper)|list -%}
    {{ log('Filtered tags for column:', info=False) }}
    {{ log(existing_tag_for_column[0], info=False) }}
    {% if existing_tag_for_column|length > 0 and existing_tag_for_column[0][2]==desired_tag_value %}
        {{ log('Correct tag value already exists', info=False) }}
    {% else %}
        {{ log('Setting tag value for '+tag_name+' to value '+desired_tag_value, info=False) }}
        {%- call statement('main', fetch_result=True) -%}
            alter table {{table_name}} modify column {{column_name}} set tag {{tag_name}} = '{{desired_tag_value}}'
        {%- endcall -%}
        {{ log(load_result('main').data, info=False) }}
    {% endif %}
{% endmacro %}

{% macro set_database_tag_value(tag_name,tag_value) %}
    {% set query %}
        create tag if not exists silver.{{tag_name}}
    {% endset %}
    {% do run_query(query) %}
    {% set query %}
        alter database {{target.database}} set tag {{target.database}}.silver.{{tag_name}} = '{{tag_value}}'
    {% endset %}
    {% do run_query(query) %}
{% endmacro %}

{% macro set_schema_tag_value(target_schema,tag_name,tag_value) %}
    {% set query %}
        create tag if not exists silver.{{tag_name}}
    {% endset %}
    {% do run_query(query) %}
    {% set query %}
        alter schema {{target.database}}.{{target_schema}} set tag {{target.database}}.silver.{{tag_name}} = '{{tag_value}}'
    {% endset %}
    {% do run_query(query) %}
{% endmacro %}

'''
'''--- macros/tests/sequence_gaps.sql ---
{% test sequence_gaps(
    model,
    partition_by,
    column_name
) %}
{%- set partition_sql = partition_by | join(", ") -%}
{%- set previous_column = "prev_" ~ column_name -%}
WITH source AS (
    SELECT
        {{ partition_sql + "," if partition_sql }}
        {{ column_name }},
        LAG(
            {{ column_name }},
            1
        ) over (
            {{ "PARTITION BY " ~ partition_sql if partition_sql }}
            ORDER BY
                {{ column_name }} ASC
        ) AS {{ previous_column }}
    FROM
        {{ model }}
)
SELECT
    {{ partition_sql + "," if partition_sql }}
    {{ previous_column }},
    {{ column_name }},
    {{ column_name }} - {{ previous_column }}
    - 1 AS gap
FROM
    source
WHERE
    {{ column_name }} - {{ previous_column }} <> 1
ORDER BY
    gap DESC {% endtest %}

'''
'''--- macros/tests/tx_gaps.sql ---
{% test tx_gaps(
    model,
    column_name,
    column_block,
    column_tx_count
) %}
WITH block_base AS (
    SELECT
        {{ column_block }},
        {{ column_tx_count }}
    FROM
        {{ ref('silver__blocks') }}
),
model_name AS (
    SELECT
        {{ column_block }},
        COUNT(
            DISTINCT {{ column_name }}
        ) AS model_tx_count
    FROM
        {{ model }}
    GROUP BY
        {{ column_block }}
)
SELECT
    block_base.{{ column_block }} as b_block_id,
    {{ column_tx_count }},
    model_name.{{ column_block }} as t_block_id,
    model_tx_count
FROM
    block_base
    LEFT JOIN model_name
    ON block_base.{{ column_block }} = model_name.{{ column_block }}
WHERE
    {{ column_tx_count }} <> model_tx_count {% endtest %}

'''
'''--- macros/udfs/create_udf_get_chainhead.sql ---
{% macro create_UDF_GET_CHAINHEAD() %}
    {% set sql %}
        CREATE
        OR REPLACE FUNCTION {{ target.database }}.STREAMLINE.UDF_GET_CHAINHEAD(
        ) returns INTEGER 
        AS $$ 
            SELECT
                {{ target.database }}.live.udf_api(
                    'POST',
                    'https://rpc.mainnet.near.org',
                    { 
                        'Content-Type': 'application/json' 
                    },
                    { 
                        'jsonrpc': '2.0',
                        'id': 'dontcare',
                        'method' :'status',
                        'params':{
                            'finality': 'final' 
                            }
                    }
            ) :data :result :sync_info :latest_block_height :: INT AS block_id
        
        $$ 
     {% endset %}
    {% do run_query(sql) %}
{% endmacro %}
'''
'''--- macros/udfs/create_udtf_call_contract_block_height.sql ---
{% macro create_UDTF_CALL_CONTRACT_FUNCTION_BY_HEIGHT() %}
{% set sql %}
{# 
    Execute a method on a contract at a specific block height.
    This function is equivalent to the one defined in macro create_UDTF_CALL_CONTRACT_FUNCTION, except for the block height input parameter.
    Signature STRING, STRING, OBJECT, NUMBER 
 #}
CREATE OR REPLACE FUNCTION
    {{ target.database }}.STREAMLINE.UDTF_CALL_CONTRACT_FUNCTION(
        contract_address STRING,
        method_name STRING,
        args OBJECT,
        block_id NUMBER
    )
RETURNS TABLE (
    BLOCK_HEIGHT NUMBER,
    DATA VARIANT,
    DECODED_RESULT VARIANT,
    ERROR VARIANT
)
AS
$$
WITH params AS (
    SELECT
        lower(contract_address) AS contract_address,
        lower(method_name) AS method,
        block_id,
        BASE64_ENCODE(args::STRING) AS arg_base64
),
call_function AS (
    SELECT
        block_id,
        {{ target.database }}.live.udf_api(
            'POST',
            'https://archival-rpc.mainnet.near.org',
            { 
                'Content-Type': 'application/json' 
            },
            { 
                'jsonrpc': '2.0',
                'id': 'dontcare',
                'method' :'query',
                'params':{
                    'request_type': 'call_function',
                    'block_id': block_id,
                    'account_id': contract_address,
                    'method_name': method_name,
                    'args_base64': arg_base64 }
                    }
        ) AS res
    FROM
        params p
),
response AS (
    SELECT
        block_id,
        res,
        res :data ::VARIANT as data,
        res :data :result :result :: ARRAY AS res_array,
        TRY_PARSE_JSON(
            COALESCE(
                res :data :result :error :: STRING,
                res :data :error :: STRING
            )
        ) AS error
    FROM
        call_function
),
try_decode_hex AS (
    SELECT
        block_id,
        b.value AS raw,
        b.index,
        LPAD(TRIM(to_char(b.value :: INT, 'XXXXXXX')) :: STRING, 2, '0') AS hex
    FROM
        response A,
        TABLE(FLATTEN(res_array, recursive => TRUE)) b
    WHERE
        IS_ARRAY(res_array) = TRUE
    ORDER BY
        1,
        3
),
decoded_response AS (
    SELECT
        block_id,
        ARRAY_TO_STRING(ARRAY_AGG(hex) within GROUP (
    ORDER BY
        INDEX ASC), '') AS decoded_response
    FROM
        try_decode_hex
    GROUP BY
        1
)
select
    r.block_id,
    r.DATA,
    TRY_PARSE_JSON(livequery.utils.udf_hex_to_string(decoded_response)) as decoded_result,
    r.error
from response r
LEFT JOIN decoded_response d using (block_id)
$$

{% endset %}
{% do run_query(sql) %}
{% endmacro %}

'''
'''--- macros/udfs/create_udtf_call_contract_block_height.yml ---
version: 2

macros:
  - name: create_UDTF_CALL_CONTRACT_FUNCTION_BY_HEIGHT
    description: >
      Creates the Snowflake function `UDTF_CALL_CONTRACT_FUNCTION` with a height parameter input to  
      call a contract method via the [public NEAR RPC endpoint](https://docs.near.org/api/rpc/setup), modeled after the official documentation, [here](https://docs.near.org/api/rpc/contracts#call-a-contract-function).  
      See examples on the main docs landing page.
    arguments:
      - name: CONTRACT_ADDRESS
        type: string
        description: The contract address to call a function on, also called `account_id` in the Near docs.
      - name: METHOD_NAME
        type: string
        description: The method to call, refer to the deployed contract or Nearblocks.io
      - name: ARGS
        type: object
        description: The parameters to pass to the method call.
      - name: BLOCK_ID
        type: number
        description: The block height at which to call the method.
 
'''
'''--- macros/udfs/create_udtf_call_contract_finality.sql ---
{% macro create_UDTF_CALL_CONTRACT_FUNCTION() %}
    {% set sql %}
    {#
    EXECUTE A method
    ON A deployed near smart contract USING THE `finality` block PARAMETER BY DEFAULT.signature STRING,
    STRING,
    OBJECT #}
    CREATE
    OR REPLACE FUNCTION {{ target.database }}.STREAMLINE.UDTF_CALL_CONTRACT_FUNCTION(
        contract_address STRING,
        method_name STRING,
        args OBJECT
    ) returns TABLE (
        block_height NUMBER,
        DATA variant,
        decoded_result variant,
        error VARIANT
    ) AS $$ WITH params AS (
        SELECT
            LOWER(contract_address) AS contract_address,
            LOWER(method_name) AS method,
            'final' AS finality,
            BASE64_ENCODE(
                args :: STRING
            ) AS arg_base64
    ),
    call_function AS (
        SELECT
        {{ target.database }}.live.udf_api(
            'POST',
            'https://rpc.mainnet.near.org',
            { 
                'Content-Type': 'application/json' 
            },
            { 
                'jsonrpc': '2.0',
                'id': 'dontcare',
                'method' :'query',
                'params':{
                    'request_type': 'call_function',
                    'finality': finality,
                    'account_id': contract_address,
                    'method_name': method_name,
                    'args_base64': arg_base64 }
                    }
        ) AS res
        FROM
            params p
    ),
    response AS (
        SELECT
            res,
            res :data :: variant AS DATA,
            res :data :result :block_height :: NUMBER AS block_height,
            res :data :result :result :: ARRAY AS res_array,
            TRY_PARSE_JSON(
                COALESCE(
                    res :data :result :error :: STRING,
                    res :data :error :: STRING
                )
            ) AS error
        FROM
            call_function
    ),
    try_decode_hex AS (
        SELECT
            block_height,
            b.value AS raw,
            b.index,
            LPAD(TRIM(to_char(b.value :: INT, 'XXXXXXX')) :: STRING, 2, '0') AS hex
        FROM
            response A,
            TABLE(FLATTEN(res_array, recursive => TRUE)) b
        WHERE
            IS_ARRAY(res_array) = TRUE
        ORDER BY
            1,
            3
    ),
    decoded_response AS (
        SELECT
            block_height,
            ARRAY_TO_STRING(ARRAY_AGG(hex) within GROUP (
        ORDER BY
            INDEX ASC), '') AS decoded_response
        FROM
            try_decode_hex
        GROUP BY
            1
    )
SELECT
    r.block_height,
    r.data,
    TRY_PARSE_JSON(
        livequery.utils.udf_hex_to_string(decoded_response)
    ) AS decoded_result,
    r.error
FROM
    response r
    LEFT JOIN decoded_response d USING (block_height) $$ {% endset %}
    {% do run_query(sql) %}
{% endmacro %}

'''
'''--- macros/udfs/create_udtf_call_contract_finality.yml ---
version: 2

macros:
  - name: create_UDTF_CALL_CONTRACT_FUNCTION
    description: >
      Creates the Snowflake function `UDTF_CALL_CONTRACT_FUNCTION` to
      call a contract method via the [public NEAR RPC endpoint](https://docs.near.org/api/rpc/setup), modeled after the official documentation, [here](https://docs.near.org/api/rpc/contracts#call-a-contract-function).  
      See examples on the main docs landing page.
    arguments:
      - name: CONTRACT_ADDRESS
        type: string
        description: The contract address to call a function on, also called `account_id` in the Near docs.
      - name: METHOD_NAME
        type: string
        description: The method to call, refer to the deployed contract or Nearblocks.io
      - name: ARGS
        type: object
        description: The parameters to pass to the method call.

'''
'''--- models/bronze/bronze__address_labels.sql ---
{{ config(
    materialized = 'view'
) }}

SELECT
    system_created_at,
    blockchain,
    address,
    creator,
    label_type,
    label_subtype,
    address_name,
    project_name,
    insert_date as _inserted_timestamp,
    modified_timestamp AS _modified_timestamp,
    _is_deleted,
    labels_combined_id
FROM
    {{ source(
        'crosschain_silver',
        'labels_combined'
    ) }}
WHERE
    blockchain = 'near'

'''
'''--- models/bronze/bronze__dates.sql ---
{{ config(
    materialized = 'view'
) }}

SELECT
    date_day,
    prior_date_day,
    next_date_day,
    prior_year_date_day,
    prior_year_over_year_date_day,
    day_of_week,
    day_of_week_iso,
    day_of_week_name,
    day_of_week_name_short,
    day_of_month,
    day_of_year,
    week_start_date,
    week_end_date,
    prior_year_week_start_date,
    prior_year_week_end_date,
    week_of_year,
    iso_week_start_date,
    iso_week_end_date,
    prior_year_iso_week_start_date,
    prior_year_iso_week_end_date,
    iso_week_of_year,
    prior_year_week_of_year,
    prior_year_iso_week_of_year,
    month_of_year,
    month_name,
    month_name_short,
    month_start_date,
    month_end_date,
    prior_year_month_start_date,
    prior_year_month_end_date,
    quarter_of_year,
    quarter_start_date,
    quarter_end_date,
    year_number,
    year_start_date,
    year_end_date
FROM
    {{ source(
        'crosschain',
        'dim_dates'
    ) }}

'''
'''--- models/bronze/prices/bronze__complete_native_asset_metadata.sql ---
{{ config (
    materialized = 'view'
) }}

SELECT
    asset_id,
    symbol,
    NAME,
    decimals,
    blockchain,
    is_deprecated,
    provider,
    source,
    _inserted_timestamp,
    inserted_timestamp,
    modified_timestamp,
    complete_native_asset_metadata_id,
    _invocation_id
FROM
    {{ source(
        'crosschain_silver',
        'complete_native_asset_metadata'
    ) }}
WHERE
    blockchain = 'near protocol'
    AND symbol = 'NEAR'

'''
'''--- models/bronze/prices/bronze__complete_native_prices.sql ---
{{ config (
    materialized = 'view'
) }}

SELECT
    HOUR,
    asset_id,
    symbol,
    NAME,
    decimals,
    price,
    blockchain,
    is_imputed,
    is_deprecated,
    provider,
    source,
    _inserted_timestamp,
    inserted_timestamp,
    modified_timestamp,
    complete_native_prices_id,
    _invocation_id
FROM
    {{ source(
        'crosschain_silver',
        'complete_native_prices'
    ) }}
WHERE
    blockchain = 'near protocol'
    AND symbol = 'NEAR'

'''
'''--- models/bronze/prices/bronze__complete_provider_asset_metadata.sql ---
{{ config (
    materialized = 'view'
) }}

SELECT
    asset_id,
    token_address,
    NAME,
    symbol,
    platform,
    platform_id,
    provider,
    source,
    _inserted_timestamp,
    inserted_timestamp,
    modified_timestamp,
    complete_provider_asset_metadata_id,
    _invocation_id
FROM
    {{ source(
        'crosschain_silver',
        'complete_provider_asset_metadata'
    ) }}
WHERE
    platform IN (
        'NEAR Protocol',
        'Near',
        'near-protocol'
    )

'''
'''--- models/bronze/prices/bronze__complete_provider_prices.sql ---
{{ config (
    materialized = 'view'
) }}

SELECT
    asset_id,
    recorded_hour,
    OPEN,
    high,
    low,
    CLOSE,
    provider,
    source,
    _inserted_timestamp,
    inserted_timestamp,
    modified_timestamp,
    complete_provider_prices_id,
    _invocation_id
FROM
    {{ source(
        'crosschain_silver',
        'complete_provider_prices'
    ) }}
-- prices for all ids

'''
'''--- models/bronze/prices/bronze__complete_token_asset_metadata.sql ---
{{ config (
    materialized = 'view'
) }}

SELECT
    token_address,
    asset_id,
    symbol,
    NAME,
    decimals,
    blockchain,
    blockchain_name,
    blockchain_id,
    is_deprecated,
    provider,
    source,
    _inserted_timestamp,
    inserted_timestamp,
    modified_timestamp,
    complete_token_asset_metadata_id,
    _invocation_id
FROM
    {{ source(
        'crosschain_silver',
        'complete_token_asset_metadata'
    ) }}
WHERE
    blockchain IN (
        'near',
        'near protocol'
    )

'''
'''--- models/bronze/prices/bronze__complete_token_prices.sql ---
{{ config (
    materialized = 'view'
) }}

SELECT
    HOUR,
    token_address,
    asset_id,
    symbol,
    NAME,
    decimals,
    price,
    blockchain,
    blockchain_name,
    blockchain_id,
    is_imputed,
    is_deprecated,
    provider,
    source,
    _inserted_timestamp,
    inserted_timestamp,
    modified_timestamp,
    complete_token_prices_id,
    _invocation_id
FROM
    {{ source(
        'crosschain_silver',
        'complete_token_prices'
    ) }}
WHERE
    blockchain IN (
        'near',
        'near protocol'
    )

'''
'''--- models/descriptions/__overview__.md ---
{% docs __overview__ %}

# Welcome to the Flipside Crypto NEAR Models Documentation

## **What does this documentation cover?**

The documentation included here details the design of the NEAR
tables and views available via [Flipside Crypto.](https://flipsidecrypto.xyz/) For more information on how these models are built, please see [the github repository.](https://github.com/flipsideCrypto/near-models/)

## **How do I use these docs?**

The easiest way to navigate this documentation is to use the Quick Links below. These links will take you to the documentation for each table, which contains a description, a list of the columns, and other helpful information.

If you are experienced with dbt docs, feel free to use the sidebar to navigate the documentation, as well as explore the relationships between tables and the logic building them.

There is more information on how to use dbt docs in the last section of this document.

## **Quick Links to Table Documentation**

**Click on the links below to jump to the documentation for each schema.**

### Core Tables (`NEAR`.`CORE`.`<table_name>`)

**Dimension Tables:**

- [dim_address_labels](#!/model/model.near.core__dim_address_labels)
- [dim_token_labels](#!/model/model.near.core__dim_token_labels)

**Fact Tables:**

- [fact_actions_events_function_call](#!/model/model.near.core__fact_actions_events_function_call)
- [fact_actions_events](#!/model/model.near.core__fact_actions_events)
- [fact_blocks](#!/model/model.near.core__fact_blocks)
- [fact_logs](#!/model/model.near.core__fact_logs)
- [fact_receipts](#!/model/model.near.core__fact_receipts)
- [fact_token_metadata](#!/model/model.near.core__fact_token_metadata)
- [fact_transactions](#!/model/model.near.core__fact_transactions)
- [fact_transfers](#!/model/model.near.core__fact_transfers)

### DeFi Tables (`NEAR`.`DEFI`.`<table_name>`)

- [fact_dex_swaps](#!/model/model.near.defi__fact_dex_swaps)

### Governance Tables (`NEAR`.`GOV`.`<table_name>`)

- [dim_staking_pools](#!/model/model.near.gov__dim_staking_pools)
- [fact_lockup_actions](#!/model/model.near.gov__fact_lockup_actions)
- [fact_staking_actions](#!/model/model.near.gov__fact_staking_actions)
- [fact_staking_pool_balances](#!/model/model.near.gov__fact_staking_pool_balances)
- [fact_staking_pool_daily_balances](#!/model/model.near.gov__fact_staking_pool_daily_balances)

### NFT Tables (`NEAR`.`NFT`.`<table_name>`)

- [fact_nft_mints](#!/model/model.near.nft__fact_nft_mints)
- [fact_nft_transfers](#!/model/model.near.nft__fact_nft_transfers)
- [ez_nft_sales](#!/model/model.near.nft__ez_nft_sales)

### Price Tables (`NEAR`.`PRICE`.`<table_name>`)

- [fact_prices](#!/model/model.near.price__fact_prices)

### Social Tables (`NEAR`.`SOCIAL`.`<table_name>`)

- [fact_addkey_events](#!/model/model.near.social__fact_addkey_events)
- [fact_decoded_actions](#!/model/model.near.social__fact_decoded_actions)
- [fact_profile_changes](#!/model/model.near.social__fact_profile_changes)
- [fact_posts](#!/model/model.near.social__fact_posts)
- [fact_widget_deployments](#!/model/model.near.social__fact_widget_deployments)

### Beta Tables (`NEAR`.`BETA`.`<table_name>`)

- [github_activity](https://github.com/forgxyz/developer_report_near)

### Custom Functions

- [udtf_call_contract_function](#!/macro/macro.near.create_UDTF_CALL_CONTRACT_FUNCTION_BY_HEIGHT)

Call a contract method via the [public NEAR RPC endpoint](https://docs.near.org/api/rpc/setup), modeled after the official documentation, [here](https://docs.near.org/api/rpc/contracts#call-a-contract-function).

This function accepts 3 or 4 parameters:

- `account_id` STR (required)
- This is the deployed contract_address you want to call.

- `method_name` STR (required)
- This is the method on the contract to call.

- `args` OBJ (required)
- Any requred or optional input parameters that the contract method accepts.
- For best results, this should be formed by using the Snowflake function [`OBJECT_CONSTRUCT()`](https://docs.snowflake.com/en/sql-reference/functions/object_construct)

- `block_id` INT (optional)
- Pass a block height (note - hash not accepted) to call the method at a certain block in time.
- If nothing is passed, the default behavior is `final` per the explanation [here](https://docs.near.org/api/rpc/setup#using-finality-param).
- Note - when passing in a block id parameter, the archive node is called which may be considerably slower than the primary access node.

**Important Note** - this is the public access endpoint, use responsibly.

#### Examples

Return 25 accounts that have authorized the contract `social.near`.

```sql
SELECT
    *
FROM
    TABLE(
        near.streamline.udtf_call_contract_function(
            'social.near',
            'get_accounts',
            OBJECT_CONSTRUCT(
                'from_index',
                0,
                'limit',
                25
            )
        )
    );

```

Get the staked balance of 100 addresses on the pool `staked.poolv1.near` at block `85,000,000`.

```sql
SELECT
    DATA :result :block_height :: NUMBER AS block_height,
    VALUE :account_id :: STRING AS account_id,
    VALUE :can_withdraw :: BOOLEAN AS can_withdraw,
    VALUE :staked_balance :: NUMBER / pow(
        10,
        24
    ) AS staked_balance,
    VALUE :unstaked_balance :: NUMBER / pow(
        10,
        24
    ) AS unstaked_balance
FROM
    TABLE(
        near.streamline.udtf_call_contract_function(
            'staked.poolv1.near',
            'get_accounts',
            {
                'from_index': 0,
                'limit': 100
            },
            85000000
        )
    ),
    LATERAL FLATTEN(decoded_result)
```

- [udf_get_chainhead](#!/macro/macro.near.create_UDF_GET_CHAINHEAD)

Calls the `status` method on Near RPC and returns the block height of chainhead.

```sql
SELECT
    NEAR.STREAMLINE.UDF_GET_CHAINHEAD()
```

## **Data Model Overview**

The NEAR
models are built a few different ways, but the core fact tables are built using three layers of sql models: **bronze, silver, and gold (or core).**

- Bronze: Data is loaded in from the source as a view
- Silver: All necessary parsing, filtering, de-duping, and other transformations are done here
- Gold (or core): Final views and tables that are available publicly

The dimension tables are sourced from a variety of on-chain and off-chain sources.

Convenience views (denoted ez\_) are a combination of different fact and dimension tables. These views are built to make it easier to query the data.

## **Using dbt docs**

### Navigation

You can use the `Project` and `Database` navigation tabs on the left side of the window to explore the models in the project.

### Database Tab

This view shows relations (tables and views) grouped into database schemas. Note that ephemeral models are _not_ shown in this interface, as they do not exist in the database.

### Graph Exploration

You can click the blue icon on the bottom-right corner of the page to view the lineage graph of your models.

On model pages, you'll see the immediate parents and children of the model you're exploring. By clicking the Expand button at the top-right of this lineage pane, you'll be able to see all of the models that are used to build, or are built from, the model you're exploring.

Once expanded, you'll be able to use the `--models` and `--exclude` model selection syntax to filter the models in the graph. For more information on model selection, check out the [dbt docs](https://docs.getdbt.com/docs/model-selection-syntax).

Note that you can also right-click on models to interactively filter and explore the graph.

### **More information**

- [Flipside](https://flipsidecrypto.xyz/)
- [Velocity](https://app.flipsidecrypto.com/velocity?nav=Discover)
- [Tutorials](https://docs.flipsidecrypto.com/our-data/tutorials)
- [Github](https://github.com/FlipsideCrypto/near-models)
- [What is dbt?](https://docs.getdbt.com/docs/introduction)

{% enddocs %}

'''
'''--- models/descriptions/_epoch_id.md ---
{% docs _epoch_id %}

An internal identifier for the epoch. This is a hashed representation of the pool_id and epoch number.

{% enddocs %}

'''
'''--- models/descriptions/_ingested_at.md ---
{% docs _ingested_at %}

The timestamp for when the block was ingested.

{% enddocs %}

'''
'''--- models/descriptions/_inserted_timestamp.md ---
{% docs _inserted_timestamp %}

The timestamp for when the block was inserted into the data warehouse by the Chainwalker.

{% enddocs %}

'''
'''--- models/descriptions/_log_signer_id_match.md ---
{% docs _log_signer_id_match %}

A boolean indicating whether the signer_id of the log matches the signer_id of the transaction. Internal / silver column only.

{% enddocs %}

'''
'''--- models/descriptions/_modified_timestamp.md ---
{% docs _modified_timestamp %}

The timestamp at which the underlying record was last modified by an internal process.
This is used for incrementally loading based on when the source data was last modified.

{% enddocs %}

'''
'''--- models/descriptions/_partition_by_block_number.md ---
{% docs _partition_by_block_number %}

Block number grouping for ingestion partition

{% enddocs %}
'''
'''--- models/descriptions/_request_timestamp.md ---
{% docs _request_timestamp %}

Time (in UTC) when an API call was made.

{% enddocs %}

'''
'''--- models/descriptions/_res_id.md ---
{% docs _res_id %}

The response ID which is a concatenation between the epoch timestamp and an identifier relevant to the data ingested, such as contract.

{% enddocs %}

'''
'''--- models/descriptions/_source.md ---
{% docs _source %}

An internal column denoting the source of the data.

{% enddocs %}

'''
'''--- models/descriptions/_source_data.md ---
{% docs _source_data %}

A silver-level column with the fulll (unparsed) Widget object.

{% enddocs %}
'''
'''--- models/descriptions/action.md ---
{% docs action %}

The action that the user is taking.
Deposit: user is depositing funds to be used for lending
Withdraw: user has changed their mind and are no longer willing to lend, so they withdraw their asset

{% enddocs %}

'''
'''--- models/descriptions/action_data.md ---
{% docs action_data %}

A JSON object containing the argument data that was called by the `action_event`, if any.

{% enddocs %}

'''
'''--- models/descriptions/action_id.md ---
{% docs action_id %}

The `action_id` is a concatenation of `receipt_id `and the index of the action within a receipt. This is unique for each record. The primary hash depends on the source of the action, as both a transaction and a receipt can process actions.

{% enddocs %}

'''
'''--- models/descriptions/action_id_profile.md ---
{% docs action_id_profile %}

A unique ID for profile changes within Near social. This ID is one step further than action_id_social as it includes the profile segment being updated.

{% enddocs %}
'''
'''--- models/descriptions/action_id_social.md ---
{% docs action_id_social %}

A unique action ID for Near Social events, as a concatenation of the action id and the Social module.

{% enddocs %}
'''
'''--- models/descriptions/action_index.md ---
{% docs action_index %}

The index of the current `action_name` and `action_data` in the order in which it appeared in the transaction.

{% enddocs %}

'''
'''--- models/descriptions/action_name.md ---
{% docs action_name %}

The name of the action performed.

{% enddocs %}

'''
'''--- models/descriptions/action_source.md ---
{% docs action_source %}

The source object of the executed action, transaction or receipt.

{% enddocs %}
'''
'''--- models/descriptions/actions.md ---
{% docs actions %}

The actions executed during the receipt or transaction processing.

{% enddocs %}
'''
'''--- models/descriptions/active_day.md ---
{% docs active_day %}

Date of activity.

{% enddocs %}

'''
'''--- models/descriptions/address.md ---
{% docs address %}

The NEAR address that corresponds with a label.

{% enddocs %}
'''
'''--- models/descriptions/address_name.md ---
{% docs address_name %}

The name attributed to the address.

{% enddocs %}

'''
'''--- models/descriptions/all_transfers.md ---
{% docs all_transfers %}

"The total count of 'nft_transfer' transactions."

{% enddocs %}

'''
'''--- models/descriptions/allowance.md ---
{% docs allowance %}

Amount of NEAR approved for use in unadjusted format (10^24). NULL if permission is FullAccess.

{% enddocs %}

'''
'''--- models/descriptions/amount.md ---
{% docs amount %}

The amount of tokens transferred
If in the ez_ view, this number is decimal adjusted to actual amount. If in silver level or a fact_ view, the raw amount is presented

{% enddocs %}

'''
'''--- models/descriptions/amount_adj.md ---
{% docs amount_adj %}

A decimal adjusted amount (of tokens, price, etc.). 

{% enddocs %}

'''
'''--- models/descriptions/amount_in.md ---
{% docs amount_in %}

The amount of tokens put into the swap.

{% enddocs %}

'''
'''--- models/descriptions/amount_in_raw.md ---
{% docs amount_in_raw %}

Amount in, in a swap or transfer, in adjusted form.

{% enddocs %}

'''
'''--- models/descriptions/amount_out.md ---
{% docs amount_out %}

The amount of tokens taken out of or received from the swap.

{% enddocs %}

'''
'''--- models/descriptions/amount_out_raw.md ---
{% docs amount_out_raw %}

Amount out, in a swap or transfer, in adjusted form.

{% enddocs %}

'''
'''--- models/descriptions/amount_raw.md ---
{% docs amount_raw %}

An unadjusted amount (of tokens, price, etc.) for the relevant record. This is the number as it appears on chain and is not decimal adjusted.

{% enddocs %}

'''
'''--- models/descriptions/amount_usd.md ---
{% docs amount_usd %}

Token amount for the record decimal adjusted and multiplied by a price in USD, if available.

{% enddocs %}

'''
'''--- models/descriptions/args.md ---
{% docs args %}

Decoded (where possible) arguments passed alongside the `method_name`.  If decoding failed, the table will contain the raw message.

{% enddocs %}

'''
'''--- models/descriptions/attached_gas.md ---
{% docs attached_gas %}

Units of gas (figure is not decimal adjusted, 10^12) attached to the transaction (this is often higher than 'Gas Used').

{% enddocs %}

'''
'''--- models/descriptions/author.md ---
{% docs author %}

The author of the block, chunk or shard.

{% enddocs %}
'''
'''--- models/descriptions/avg_gas_price.md ---
{% docs avg_gas_price %}

The average gas price in transactions. Not decimal adjusted; units in yoctoNEAR (10^-24 NEAR)

{% enddocs %}

'''
'''--- models/descriptions/balance.md ---
{% docs balance %}

The balance of a pool or address at a given block.

{% enddocs %}

'''
'''--- models/descriptions/base_uri.md ---
{% docs base_uri %}

The URI associated with the token or NFT, set by the deployer or creator.

{% enddocs %}

'''
'''--- models/descriptions/block_author.md ---
{% docs block_author %}

The `block_author` taken from block headers. Validators of the blockchain.

{% enddocs %}

'''
'''--- models/descriptions/block_challenges_result.md ---
{% docs block_challenges_result %}

The block_challenges_result taken from block headers.

{% enddocs %}

'''
'''--- models/descriptions/block_challenges_root.md ---
{% docs block_challenges_root %}

The block_challenges_root taken from block headers.

{% enddocs %}

'''
'''--- models/descriptions/block_hash.md ---
{% docs block_hash %}

Unique identifier (hash) of this block.

{% enddocs %}

'''
'''--- models/descriptions/block_height.md ---
{% docs block_height %}

The block height is a sequential number of the most recent block in the blockchain.

{% enddocs %}

'''
'''--- models/descriptions/block_id.md ---
{% docs block_id %}

The height of the chain this block corresponds with.

{% enddocs %}

'''
'''--- models/descriptions/block_producers.md ---
{% docs block_producers %}

Number of block producers in this epoch.

{% enddocs %}

'''
'''--- models/descriptions/block_timestamp.md ---
{% docs block_timestamp %}

The date and time at which the block began.

{% enddocs %}

'''
'''--- models/descriptions/blockchain.md ---
{% docs blockchain %}

The name of the blockchain.

{% enddocs %}
'''
'''--- models/descriptions/blocks.md ---
{% docs blocks %}

Number of blocks included in the epoch.

{% enddocs %}

'''
'''--- models/descriptions/blocks_impacted_array.md ---
{% docs blocks_impacted_array %}

An array of the impacted blocks during the observability run.

{% enddocs %}

'''
'''--- models/descriptions/blocks_impacted_count.md ---
{% docs blocks_impacted_count %}

The number of blocks impacted during the observability run.  
Impacted is defined as missing or having bad data.

{% enddocs %}

'''
'''--- models/descriptions/blocks_tested.md ---
{% docs blocks_tested %}

The number of blocks tested in the observability run.

{% enddocs %}

'''
'''--- models/descriptions/branch.md ---
{% docs branch %}

The branch, if any, of the widget module. May be null.

{% enddocs %}
'''
'''--- models/descriptions/chain_id.md ---
{% docs chain_id %}

Chain ID as defined by the corresponding bridge.

Wormhole Portal Bridge https://docs.wormhole.com/wormhole/reference/constants

Multichain Bridge https://docs.multichain.org/getting-started/introduction/supported-chains

Allbridge Classic https://github.com/allbridge-io/allbridge-contract-docs?tab=readme-ov-file#blockchain-ids

{% enddocs %}

'''
'''--- models/descriptions/chunk.md ---
{% docs chunk %}

A single chunk from the shard. Chunk is an aggregation of transactions and receipts which are executed within a particular shard.

{% enddocs %}

'''
'''--- models/descriptions/chunk_hash.md ---
{% docs chunk_hash %}

The identifier for the chunk.

{% enddocs %}
'''
'''--- models/descriptions/chunk_headers_root.md ---
{% docs chunk_headers_root %}

The chunk_headers_root taken from block headers.

{% enddocs %}

'''
'''--- models/descriptions/chunk_mask.md ---
{% docs chunk_mask %}

The chunk_mask taken from block headers.

{% enddocs %}

'''
'''--- models/descriptions/chunk_receipts_root.md ---
{% docs chunk_receipts_root %}

The chunk_receipts_root taken from block headers.

{% enddocs %}

'''
'''--- models/descriptions/chunk_transactions.md ---
{% docs chunk_transactions %}

The transactions object from the chunks.

{% enddocs %}
'''
'''--- models/descriptions/chunk_tx_root.md ---
{% docs chunk_tx_root %}

The chunk_tx_root taken from block headers.

{% enddocs %}

'''
'''--- models/descriptions/chunks.md ---
{% docs chunks %}

The chunks taken from block headers. Chunk is an aggregation of transactions which are executed within a particular shard.

{% enddocs %}

'''
'''--- models/descriptions/chunks_included.md ---
{% docs chunks_included %}

The chunks_included taken from block headers.

{% enddocs %}

'''
'''--- models/descriptions/circulating_supply.md ---
{% docs circulating_supply %}

Total supply less locked supply.

{% enddocs %}

'''
'''--- models/descriptions/clean_log.md ---
{% docs clean_log %}

The logs linked to the transaction.

{% enddocs %}

'''
'''--- models/descriptions/contract_address.md ---
{% docs contract_address %}

The address of the deployed contract for the token, nft, or other smart contract.

{% enddocs %}

'''
'''--- models/descriptions/contract_metadata.md ---
{% docs contract_metadata %}

Token contract metadata from the Pagoda API. Should correspond with the metadata provided by the Nearblocks API.

{% enddocs %}

'''
'''--- models/descriptions/daily_active_contracts.md ---
{% docs daily_active_contracts %}

The daily number of active contracts.

{% enddocs %}

'''
'''--- models/descriptions/daily_active_wallets.md ---
{% docs daily_active_wallets %}

The daily number of active wallets.

{% enddocs %}

'''
'''--- models/descriptions/daily_gas_used.md ---
{% docs daily_gas_used %}

The total daily gas used in transactions. Not decimal adjusted; gas units (10^-12 Tgas)

{% enddocs %}

'''
'''--- models/descriptions/daily_transactions.md ---
{% docs daily_transactions %}

The daily number of transactions.

{% enddocs %}

'''
'''--- models/descriptions/data.md ---
{% docs data %}

A JSON object representing the response from an API.

{% enddocs %}

'''
'''--- models/descriptions/date.md ---
{% docs date %}

The date (day).

{% enddocs %}

'''
'''--- models/descriptions/decimals.md ---
{% docs decimals %}

The number of decimals a raw number should be divided by to decimal adjust. For example, bridged tokens from Ethereum typically use 18 decimals so a raw (unadjusted chain number) of 1000000000000000000 represents 1.

{% enddocs %}

'''
'''--- models/descriptions/deposit.md ---
{% docs deposit %}

Sum of all NEAR tokens transferred from the signing account to the receiver account during receipt processing. This includes tokens sent in a Transfer action(s), and tokens sent in a FunctionCall action(s) with a deposit attached.

In raw number format with 24 decimal places, to adjust divide by POW(10,24) or multiply by 1e-24.

{% enddocs %}

'''
'''--- models/descriptions/deposit_timestamp.md ---
{% docs deposit_timestamp %}

Block timestamp of the initial deposit.

{% enddocs %}

'''
'''--- models/descriptions/destination_address.md ---
{% docs destination_address %}

The address tokens are being sent to, in a transfer or bridge transaction.

{% enddocs %}

'''
'''--- models/descriptions/destination_chain.md ---
{% docs destination_chain %}

The recipient blockchain in a bridge transaction.

{% enddocs %}

'''
'''--- models/descriptions/direction.md ---
{% docs direction %}

Direction of funds through a bridge. Inbound = tokens bridged to Near ecosystem.

Note - for the Rainbow bridge, inbound means Near or Aurora as tokens pass through Near to get to Aurora.

{% enddocs %}

'''
'''--- models/descriptions/end_time.md ---
{% docs end_time %}

Block timestamp associated with max block id.

{% enddocs %}

'''
'''--- models/descriptions/epoch_id.md ---
{% docs epoch_id %}

The epoch_id taken from block headers.

{% enddocs %}

'''
'''--- models/descriptions/epoch_num.md ---
{% docs epoch_num %}

Ordinal number of the epoch.

{% enddocs %}

'''
'''--- models/descriptions/epoch_number.md ---
{% docs epoch_number %}

The epoch number for this staking reward payout. Epoch increment in order every 43,200 blocks.

{% enddocs %}

'''
'''--- models/descriptions/epoch_sync_data_hash.md ---
{% docs epoch_sync_data_hash %}

The epoch_sync_data_hash taken from block headers, if available.

{% enddocs %}

'''
'''--- models/descriptions/error_message.md ---
{% docs error_message %}

The error message, if any, associated with the failure.

{% enddocs %}

'''
'''--- models/descriptions/error_type_0.md ---
{% docs error_type_0 %}

The top-level error type, which likely pertains to the type of object that failed. For example `ActionError` when a action failed to execute for some reason.

{% enddocs %}
'''
'''--- models/descriptions/error_type_1.md ---
{% docs error_type_1 %}

The second level of error type when a receipt has failed. This pertains to the scope in which the error occurred, such as `FunctionCallError`.

{% enddocs %}
'''
'''--- models/descriptions/error_type_2.md ---
{% docs error_type_2 %}

The third level of error type which actually pertains to the type of failure. This is commonly `ExecutionError`.

{% enddocs %}
'''
'''--- models/descriptions/event.md ---
{% docs event %}

The specific event of the transaction.
f_transfer - mainly contains swap transactions involving usn.
ft_mint - event that indicates when a new usn token is created.
ft_burn - event that indicates when usn is burnt.

{% enddocs %}

'''
'''--- models/descriptions/events.md ---
{% docs events %}

The events taken from block headers.

{% enddocs %}

'''
'''--- models/descriptions/execution_outcome.md ---
{% docs execution_outcome %}

The outcome of the transaction, action, or receipt that was executed in the shard.

{% enddocs %}
'''
'''--- models/descriptions/from_address.md ---
{% docs from_address %}

The address the sends the token.

{% enddocs %}

'''
'''--- models/descriptions/gas_burnt.md ---
{% docs gas_burnt %}

The gas used in the object, whether it be the transaction, action or receipt. In the case of a curated model where this column is included alongside a transaction fee, this is the gas burnt during the individual action or receipt.

In raw number format with 16 decimal places, to adjust divide by POW(10,16) or multiply by 1e-16.

{% enddocs %}

'''
'''--- models/descriptions/gas_price.md ---
{% docs gas_price %}

The gas_price taken from block headers, number is not decimal adjusted.

{% enddocs %}

'''
'''--- models/descriptions/gas_used.md ---
{% docs gas_used %}

Units of gas required to execute this transaction. In raw number format, to adjust divide by POW(10,12)

{% enddocs %}

'''
'''--- models/descriptions/header.md ---
{% docs header %}

A json column containing header information from the object: block or chunk.

{% enddocs %}

'''
'''--- models/descriptions/height_created.md ---
{% docs height_created %}

The block height at which the chunk was created, may not be the same as the height for when the chunk is included depending on processing time.

{% enddocs %}
'''
'''--- models/descriptions/height_included.md ---
{% docs height_included %}

The block height at which the chunk is finalized and included, formally appending the outcome to the chain.

{% enddocs %}
'''
'''--- models/descriptions/icon.md ---
{% docs icon %}

A base64 encoded image for the token or NFT's icon.

{% enddocs %}

'''
'''--- models/descriptions/id.md ---
{% docs id %}

A unique identifier for the record.

{% enddocs %}

'''
'''--- models/descriptions/implied_price.md ---
{% docs implied_price %}

The implied price of the NFT is calculated by dividing the deposit by the number of mint events.

{% enddocs %}

'''
'''--- models/descriptions/index.md ---
{% docs index %}

The positon index for the record in question, if it was stored in a particular order.

{% enddocs %}

'''
'''--- models/descriptions/inserted_timestamp.md ---
{% docs inserted_timestamp %}

The timestamp at which the record was initially created and inserted into this table.

{% enddocs %}

'''
'''--- models/descriptions/invocation_id.md ---
{% docs invocation_id %}

A job ID to identify the run that last modified a record.

{% enddocs %}

'''
'''--- models/descriptions/is_standard.md ---
{% docs is_standard %}

A boolean value indicating whether it is a standardized log or not.

{% enddocs %}

'''
'''--- models/descriptions/l1_label.md ---
{% docs l1_label %}

Deprecating soon. This is the same column label type, but is being kept for compatibility until 3/1/2023. TODO - deprecate.

{% enddocs %}
'''
'''--- models/descriptions/l2_label.md ---
{% docs l2_label %}

Deprecating soon. This is the same column label subtype, but is being kept for compatibility until 3/1/2023. TODO - deprecate.

{% enddocs %}
'''
'''--- models/descriptions/label_subtype.md ---
{% docs label_subtype %}

A sub-category nested within label type providing further detail.

{% enddocs %}
'''
'''--- models/descriptions/label_type.md ---
{% docs label_type %}

A high-level category describing the addresses main function or ownership.

{% enddocs %}
'''
'''--- models/descriptions/last_ds_final_block.md ---
{% docs last_ds_final_block %}

The last_ds_final_block taken from block headers.

{% enddocs %}

'''
'''--- models/descriptions/last_final_block.md ---
{% docs last_final_block %}

The last_final_block taken from block headers.

{% enddocs %}

'''
'''--- models/descriptions/latest_protocol_version.md ---
{% docs latest_protocol_version %}

The latest_protocol_version taken from block headers.

{% enddocs %}

'''
'''--- models/descriptions/liquid_supply.md ---
{% docs liquid_supply %}

Nonlocked and nonstaked NEAR.

{% enddocs %}

'''
'''--- models/descriptions/locked_amount.md ---
{% docs locked_amount %}

Amount of NEAR still locked.

{% enddocs %}

'''
'''--- models/descriptions/lockup_account_id.md ---
{% docs lockup_account_id %}

A vault created by the lockup action that holds the distributed NEAR tokens until the end of the lockup duration.

{% enddocs %}
'''
'''--- models/descriptions/lockup_amount.md ---
{% docs lockup_amount %}

The amount, in NEAR, of the initial lockup.

{% enddocs %}

'''
'''--- models/descriptions/lockup_duration.md ---
{% docs lockup_duration %}

The duration of the lockup period.

{% enddocs %}

'''
'''--- models/descriptions/lockup_end_timestamp.md ---
{% docs lockup_end_timestamp %}

When the lockup period ends, per the lockup config on chain.

{% enddocs %}

'''
'''--- models/descriptions/lockup_index.md ---
{% docs lockup_index %}

An ordinal representation of the lockup account, in block_timestamp order.

{% enddocs %}

'''
'''--- models/descriptions/lockup_time_left_ns.md ---
{% docs lockup_time_left_ns %}

Time left in the lockup, for the date of record at 00:00 UTC.

{% enddocs %}

'''
'''--- models/descriptions/lockup_timestamp.md ---
{% docs lockup_timestamp %}

The initial lockup timestamp, in epoch time.

{% enddocs %}

'''
'''--- models/descriptions/lockup_timestamp_ntz.md ---
{% docs lockup_timestamp_ntz %}

Timestamp of the start of the lockup period, converted to UTC time.

{% enddocs %}

'''
'''--- models/descriptions/log.md ---
{% docs log %}

A single log extracted from a receipt.

{% enddocs %}

'''
'''--- models/descriptions/log_id.md ---
{% docs log_id %}

Concatenation between receipt id and index of the log.

{% enddocs %}

'''
'''--- models/descriptions/log_signer_id.md ---
{% docs log_signer_id %}

The NEAR address indicated in the log.

{% enddocs %}

'''
'''--- models/descriptions/logs.md ---
{% docs logs %}

Logs (array) for this receipt.

{% enddocs %}

'''
'''--- models/descriptions/maa.md ---
{% docs maa %}

Monthly Active Accounts (wallets), as determined by transaction signers.

{% enddocs %}

'''
'''--- models/descriptions/max_block.md ---
{% docs max_block %}

The maximum block tested in the range of the observability test run.

{% enddocs %}

'''
'''--- models/descriptions/max_block_id.md ---
{% docs max_block_id %}

The end block for the epoch, or max block thus far if the epoch is current.

{% enddocs %}

'''
'''--- models/descriptions/max_block_timestamp.md ---
{% docs max_block_timestamp %}

The block timestamp of the max block tested in the observability run.

{% enddocs %}

'''
'''--- models/descriptions/memo.md ---
{% docs memo %}

Memo: The log message within Near now includes an optional dictionary.

{% enddocs %}

'''
'''--- models/descriptions/metadata.md ---
{% docs metadata %}

Metadata (object) for this transaction. May be null, especially for Near Social Widgets.

{% enddocs %}

'''
'''--- models/descriptions/metadata_id.md ---
{% docs metadata_id %}

A MD5 Hash of an NFT contract and series ID, providing an unique indicator for collecting NFT Series Metadata.

{% enddocs %}

'''
'''--- models/descriptions/method_name.md ---
{% docs method_name %}

Name of the method(s) approved for use. NULL if permission is FullAccess.

{% enddocs %}

'''
'''--- models/descriptions/method_names.md ---
{% docs method_names %}

The function that is being called for the transaction
can be ft_transfer_call, ft_transfer or withdraw

{% enddocs %}

'''
'''--- models/descriptions/min_block.md ---
{% docs min_block %}

The minimum block tested in the range of the observability test run.

{% enddocs %}

'''
'''--- models/descriptions/min_block_id.md ---
{% docs min_block_id %}

The starting block for the epoch.

{% enddocs %}

'''
'''--- models/descriptions/min_block_timestamp.md ---
{% docs min_block_timestamp %}

The block timestamp of the min block tested in the observability run.

{% enddocs %}

'''
'''--- models/descriptions/mint_action_id.md ---
{% docs mint_action_id %}

Unique id for each standar mint event

{% enddocs %}

'''
'''--- models/descriptions/mint_per_tx.md ---
{% docs mint_per_tx %}

Number of NFTs minted per `nft_mint` event called.

{% enddocs %}

'''
'''--- models/descriptions/mints_count.md ---
{% docs mint_count %}

"The count of transactions where the method_name indicates a minting event rather than a transfer."

{% enddocs %}

'''
'''--- models/descriptions/modified_timestamp.md ---
{% docs modified_timestamp %}

The timestamp at which this record was last modified by an internal process.

{% enddocs %}

'''
'''--- models/descriptions/monthly_active_contracts.md ---
{% docs monthly_active_contracts %}

The number of active contracts for the month of the date.

{% enddocs %}

'''
'''--- models/descriptions/name.md ---
{% docs name %}

The name of the asset.

{% enddocs %}

'''
'''--- models/descriptions/network.md ---
{% docs network %}

The blockchain network. (i.e. mainnet, testnet, etc.)

{% enddocs %}

'''
'''--- models/descriptions/new_maas.md ---
{% docs new_maas %}

Monthly Active Users, whose first tranaction occurred in the preceding 30 days.

{% enddocs %}

'''
'''--- models/descriptions/next_bp_hash.md ---
{% docs next_bp_hash %}

The next_bp_hash taken from block headers.

{% enddocs %}

'''
'''--- models/descriptions/next_epoch_id.md ---
{% docs next_epoch_id %}

The next_epoch_id taken from block headers.

{% enddocs %}

'''
'''--- models/descriptions/nft_address.md ---
{% docs nft_address %}

The contract address of the NFT.

{% enddocs %}
'''
'''--- models/descriptions/nft_id.md ---
{% docs nft_id %}

The token_series_id for the NFT contract.

{% enddocs %}
'''
'''--- models/descriptions/nft_project_name.md ---
{% docs nft_project_name %}

The project_name is the name of the collection in the NFT exchange platform

{% enddocs %}
'''
'''--- models/descriptions/nft_token_id.md ---
{% docs nft_token_id %}

The token ID for this NFT contract. 

{% enddocs %}
'''
'''--- models/descriptions/node.md ---
{% docs node %}

A branch of the data object. 

In the case of NEAR Social schema, node is being used to denote the top-level key of the data object. 

{% enddocs %}

'''
'''--- models/descriptions/node_data.md ---
{% docs node_data %}

The data object that the top level node contains.

{% enddocs %}
'''
'''--- models/descriptions/non_staked_locked_supply.md ---
{% docs non_staked_locked_supply %}

NEAR supply that is locked via a lockup but not staked.

{% enddocs %}

'''
'''--- models/descriptions/nonce.md ---
{% docs nonce %}

Nonce for transactions.

{% enddocs %}

'''
'''--- models/descriptions/nonliquid_supply.md ---
{% docs nonliquid_supply %}

Total supply, less liquid supply.

{% enddocs %}

'''
'''--- models/descriptions/nonstaked_circulating_supply.md ---
{% docs nonstaked_circulating_supply %}

NEAR supply that is neither locked nor staked.

{% enddocs %}

'''
'''--- models/descriptions/offset_id.md ---
{% docs offset_id %}

Synonmous with block_id for Near.

{% enddocs %}

'''
'''--- models/descriptions/outcome.md ---
{% docs outcome %}

The outcome of the transaction, action, or receipt that was executed in the shard.

{% enddocs %}
'''
'''--- models/descriptions/outcome_root.md ---
{% docs outcome_root %}

The outcome_root taken from block headers.

{% enddocs %}

'''
'''--- models/descriptions/owner.md ---
{% docs owner %}

The owner of the token, which is the signer_id for minting events and the receiver_id for transfers.

{% enddocs %}

'''
'''--- models/descriptions/owner_account_id.md ---
{% docs owner_account_id %}

The wallet address of the owner for the locked tokens, per the initial distribution.

{% enddocs %}

'''
'''--- models/descriptions/owner_count.md ---
{% docs owner_count %}

"The count of distinct owners that have interacted with the receiver's tokens."

{% enddocs %}

'''
'''--- models/descriptions/owner_id.md ---
{% docs owner_id %}

Owner of the minted NFT

{% enddocs %}

'''
'''--- models/descriptions/owner_per_tx.md ---
{% docs owner_per_tx %}

Number of different owners batch minting, `data` array's len in the LOG message

{% enddocs %}

'''
'''--- models/descriptions/perc_circulating_supply.md ---
{% docs perc_circulating_supply %}

Percentage of NEAR circulating.
circulating_supply / total_supply

{% enddocs %}

'''
'''--- models/descriptions/perc_locked_supply.md ---
{% docs perc_locked_supply %}

Percentage of supply locked.  
total_locked_supply / total_supply

{% enddocs %}

'''
'''--- models/descriptions/perc_staked_circulating.md ---
{% docs perc_staked_circulating %}

Percentage of supply staked and not locked, of circulating supply.
nonlocked_and_staked_supply / circulating_supply

{% enddocs %}

'''
'''--- models/descriptions/perc_staked_locked.md ---
{% docs perc_staked_locked %}

Percentage of supply both staked and locked, out of all locked supply.  
locked_and_staked_supply / total_locked_supply

{% enddocs %}

'''
'''--- models/descriptions/permission.md ---
{% docs permission %}

Permissions granted to the contract by the signer.

{% enddocs %}

'''
'''--- models/descriptions/platform.md ---
{% docs platform %}

The protocol utilized for the operation, likely a swap or bridge.

{% enddocs %}

'''
'''--- models/descriptions/pool_address.md ---
{% docs pool_address %}

The NEAR address of the staking pool.

{% enddocs %}

'''
'''--- models/descriptions/pool_id.md ---
{% docs pool_id %}

The unique id for the pool involved in the swap.

{% enddocs %}

'''
'''--- models/descriptions/post_image.md ---
{% docs post_image %}

The IPFS hash of the image included in the post, if any. This field may be null if the post does not contain an image.

{% enddocs %}
'''
'''--- models/descriptions/post_text.md ---
{% docs post_text %}

The text content, in markdown, of the post. This field could be null if the post contains only an image.

{% enddocs %}
'''
'''--- models/descriptions/post_type.md ---
{% docs post_type %}
The type of post, seemingly determined by media. As of march 2023, only type md (markdown) exists.
{% enddocs %}
'''
'''--- models/descriptions/predecessor_id.md ---
{% docs predecessor_id %}

This is the account that was the immediate caller to the smart contract. If this is a simple transaction (no cross-contract calls) from alice.near to banana.near, the smart contract at banana.near considers Alice the predecessor. In this case, Alice would also be the signer.  
  
Source: https://docs.near.org/tutorials/crosswords/beginner/actions#predecessor-signer-and-current-account

{% enddocs %}

'''
'''--- models/descriptions/prev_hash.md ---
{% docs prev_hash %}

The prev_hash taken from block headers.

{% enddocs %}

'''
'''--- models/descriptions/prev_height.md ---
{% docs prev_height %}

The prev_height taken from block headers.

{% enddocs %}

'''
'''--- models/descriptions/prev_state_root.md ---
{% docs prev_state_root %}

The prev_state_root taken from block headers.

{% enddocs %}

'''
'''--- models/descriptions/price_usd.md ---
{% docs price_usd %}

The asset price, in US Dollars.

{% enddocs %}

'''
'''--- models/descriptions/prices/prices.md ---
{% docs prices_dim_asset_metadata_table_doc %}

A comprehensive dimensional table holding asset metadata and other relevant details pertaining to each id, from multiple providers. This data set includes raw, non-transformed data coming directly from the provider APIs and rows are not intended to be unique. As a result, there may be data quality issues persisting in the APIs that flow through to this dimensional model. If you are interested in using a curated data set instead, please utilize ez_asset_metadata.

{% enddocs %}

{% docs prices_ez_asset_metadata_table_doc %}

A convenience table holding prioritized asset metadata and other relevant details pertaining to each token_address and native asset. This data set is highly curated and contains metadata for one unique asset per blockchain.

{% enddocs %}

{% docs prices_fact_prices_ohlc_hourly_table_doc %}

A comprehensive fact table holding id and provider specific open, high, low, close hourly prices, from multiple providers. This data set includes raw, non-transformed data coming directly from the provider APIs and rows are not intended to be unique. As a result, there may be data quality issues persisting in the APIs that flow through to this fact based model. If you are interested in using a curated data set instead, please utilize ez_prices_hourly.

{% enddocs %}

{% docs prices_ez_prices_hourly_table_doc %}

A convenience table for determining token prices by address and blockchain, and native asset prices by symbol and blockchain. This data set is highly curated and contains metadata for one price per hour per unique asset and blockchain.

{% enddocs %}

{% docs prices_provider %}

The provider or source of the data.

{% enddocs %}

{% docs prices_asset_id %}

The unique identifier representing the asset.

{% enddocs %}

{% docs prices_name %}

The name of asset.

{% enddocs %}

{% docs prices_symbol %}

The symbol of asset.

{% enddocs %}

{% docs prices_token_address %}

The specific address representing the asset on a specific platform. This will be NULL if referring to a native asset.

{% enddocs %}

{% docs prices_blockchain %}

The Blockchain, Network, or Platform for this asset.

{% enddocs %}

{% docs prices_blockchain_id %}

The unique identifier of the Blockchain, Network, or Platform for this asset.

{% enddocs %}

{% docs prices_decimals %}

The number of decimals for the asset. May be NULL.

{% enddocs %}

{% docs prices_is_native %}

A flag indicating assets native to the respective blockchain.

{% enddocs %}

{% docs prices_is_deprecated %}

A flag indicating if the asset is deprecated or no longer supported by the provider.

{% enddocs %}

{% docs prices_id_deprecation %}

Deprecating soon! Please use the `asset_id` column instead.

{% enddocs %}

{% docs prices_decimals_deprecation %}

Deprecating soon! Please use the decimals column in `ez_asset_metadata` or join in `dim_contracts` instead.

{% enddocs %}

{% docs prices_hour %}

Hour that the price was recorded at.

{% enddocs %}

{% docs prices_price %}

Closing price of the recorded hour in USD.

{% enddocs %}

{% docs prices_is_imputed %}

A flag indicating if the price was imputed, or derived, from the last arriving record. This is generally used for tokens with low-liquidity or inconsistent reporting.

{% enddocs %}

{% docs prices_open %}

Opening price of the recorded hour in USD.

{% enddocs %}

{% docs prices_high %}

Highest price of the recorded hour in USD

{% enddocs %}

{% docs prices_low %}

Lowest price of the recorded hour in USD

{% enddocs %}

{% docs prices_close %}

Closing price of the recorded hour in USD

{% enddocs %}
'''
'''--- models/descriptions/profile_data.md ---
{% docs profile_data %}

The data being updated for the profile section in the transaction. Nested JSON data may require use of the function TRY_PARSE_JSON(<column>).

{% enddocs %}
'''
'''--- models/descriptions/profile_section.md ---
{% docs profile_section %}

The section of the profile that is being edited in the transaction.

{% enddocs %}

'''
'''--- models/descriptions/project_name.md ---
{% docs project_name %}

The associated project, if applicable.

{% enddocs %}
'''
'''--- models/descriptions/proof.md ---
{% docs proof %}

Proof (array) for this transaction.

{% enddocs %}

'''
'''--- models/descriptions/provider.md ---
{% docs provider %}

The source or provider of the data in the record.

{% enddocs %}

'''
'''--- models/descriptions/public_key.md ---
{% docs public_key %}

The public key of an AccessKey which was used to sign the original transaction. In case of a deposit refund, the public key is empty (all bytes are 0).

{% enddocs %}

'''
'''--- models/descriptions/random_value.md ---
{% docs random_value %}

The random_value taken from block headers.

{% enddocs %}

'''
'''--- models/descriptions/raw_price.md ---
{% docs raw_price %}
The unadjusted price as reported by the source. This should be decimal adjusted to get the real value.
{% enddocs %}
'''
'''--- models/descriptions/receipt.md ---
{% docs receipt %}

A single receipt produced as a byproduct of the actions taken within a transaction.

{% enddocs %}
'''
'''--- models/descriptions/receipt_execution_outcome_id.md ---
{% docs receipt_execution_outcome_id %}

A unique identifier for objects within the receipt_execution_outcomes array, which is a concatenation of shard_id and its index in the array.

{% enddocs %}
'''
'''--- models/descriptions/receipt_execution_outcomes.md ---
{% docs receipt_execution_outcomes %}

The outcome of the execution of a receipt. This is the result of the execution of the receipt on the shard. It contains the status of the execution, the logs, and the result of the execution.

{% enddocs %}
'''
'''--- models/descriptions/receipt_id.md ---
{% docs receipt_id %}

The identifying hash for a receipt.

{% enddocs %}
'''
'''--- models/descriptions/receipt_index.md ---
{% docs receipt_index %}

Deprecation notice! Please note this column will be removed from the receipts tables. For more context on NEAR Receipts, please see the announcement in Discord here: https://discord.com/channels/784442203187314689/992655061517881385/1098015182103523408

{% enddocs %}

'''
'''--- models/descriptions/receipt_object_id.md ---
{% docs receipt_object_id %}

Unique identifier of the receipt object for this transaction.

{% enddocs %}

'''
'''--- models/descriptions/receipt_outcome_execution_index.md ---
{% docs receipt_outcome_execution_index %}

The index for the receipt_outcome_execution from the array contained in the shard.

{% enddocs %}
'''
'''--- models/descriptions/receipt_outcome_id.md ---
{% docs receipt_outcome_id %}

Unique identifier(s) (array) of the remaining receipt outcomes for this transaction. This list will not include the record's own receipt id, but will list the subsequent receipts within the transaction.

{% enddocs %}

'''
'''--- models/descriptions/receipt_succeeded.md ---
{% docs receipt_succeeded %}

A boolean indicating whether the receipt was successfully processed, based on the presence of a Failure message.

{% enddocs %}
'''
'''--- models/descriptions/receipt_type.md ---
{% docs receipt_type %}

The type of receipt, as taken from the actions executed during the receipt. Options, presently, are Action or Data.

{% enddocs %}

'''
'''--- models/descriptions/receipts.md ---
{% docs receipts %}

An array of receipts included in the chunk or exection outcome.

{% enddocs %}
'''
'''--- models/descriptions/receiver_id.md ---
{% docs receiver_id %}

The address of the NEAR account that the receipt was executed on.
Note, this differs from `tx_receiver` and is associated with the receipt within a transaction. It is often a contract on which a method is executed by the `signer_id`.

{% enddocs %}

'''
'''--- models/descriptions/record_id.md ---
{% docs record_id %}

A unique id for the record generated by Chainwalkers.

{% enddocs %}

'''
'''--- models/descriptions/release_duration.md ---
{% docs release_duration %}

The duration until the locked tokens can be released.

{% enddocs %}

'''
'''--- models/descriptions/rent_paid.md ---
{% docs rent_paid %}

The rent_paid taken from block headers.

{% enddocs %}

'''
'''--- models/descriptions/returning_maas.md ---
{% docs returning_maas %}

Monthly active accounts, who are not defined as new.

{% enddocs %}

'''
'''--- models/descriptions/reward_tokens.md ---
{% docs reward_tokens %}

The total amount of tokens rewarded to the validator for this staking reward payout. Number is presented raw and not decimal adjusted in the fact table.

{% enddocs %}

'''
'''--- models/descriptions/rolling_30day_active_wallets.md ---
{% docs rolling_30day_active_wallets %}

The number of active wallets in the last 30 days.

{% enddocs %}

'''
'''--- models/descriptions/rolling_7day_active_wallets.md ---
{% docs rolling_7day_active_wallets %}

The number of active wallets in the last 7 days.

{% enddocs %}

'''
'''--- models/descriptions/sender_id.md ---
{% docs sender_id %}

The id, or wallet address, of the sender from the receipt action.

{% enddocs %}

'''
'''--- models/descriptions/series_id.md ---
{% docs series_id %}

The series, or collection, id for a NFT project. Many platforms issues NFT collections from a marketplace contract. For example, the contract `x.paras.near` is the Paras NFT Marketplace and mints NFTs from this master-contract. A token ID 1234:123 indicates that the NFT is token `123` within series `1234`.

{% enddocs %}

'''
'''--- models/descriptions/series_title.md ---
{% docs series_title %}

Title of the NFT series.

{% enddocs %}

'''
'''--- models/descriptions/shard_id.md ---
{% docs shard_id %}

The id for this shard, which is block_id plus shard number

{% enddocs %}
'''
'''--- models/descriptions/shard_number.md ---
{% docs shard_number %}

The numeric identifier for this shard, indexed at 0.

{% enddocs %}
'''
'''--- models/descriptions/signature.md ---
{% docs signature %}

The signature taken from block headers.

{% enddocs %}

'''
'''--- models/descriptions/signer_id.md ---
{% docs signer_id %}

The signer is the account that originally signed the transaction that began the blockchain activity, which may or may not include cross-contract calls. If a function calls results in several cross-contract calls, think of the signer as the account that pushed over the first domino in that chain reaction.

{% enddocs %}
'''
'''--- models/descriptions/source.md ---
{% docs source %}

The source of the information presented in the record.

{% enddocs %}

'''
'''--- models/descriptions/source_address.md ---
{% docs source_address %}

The originating address from which tokens are being sent, in a transfer or bridge transaction.  

This addressed is ascertained as best as possible, but may be null depending on the available information.  

Example 1 - tx CzPRdoiU74bo9yqqt9fCP5Xdab2mPVqxr9gU5xeaQA4a stores just "signer_public_key 0x0x1589‚Ä¶f694" on chain.  

Example 2 - tx FA7tQeGQnhminbas28YgaizwmT4vnEUiCr3vdXmN3Xjn does not log any signing address at all.  

{% enddocs %}

'''
'''--- models/descriptions/source_chain.md ---
{% docs source_chain %}

The originating blockchain in a bridge transaction.

{% enddocs %}

'''
'''--- models/descriptions/source_code.md ---
{% docs source_code %}

The source code for the widget, in JavaScript.

{% enddocs %}
'''
'''--- models/descriptions/source_object.md ---
{% docs source_object %}

The source of the object. For example, receipts can be found in the chunk and in the receipt_execution_outcome of a shard.

{% enddocs %}
'''
'''--- models/descriptions/staked_balance.md ---
{% docs staked_balance %}

Gross balance of staked NEAR for the record, whether date or account.

{% enddocs %}

'''
'''--- models/descriptions/staked_circulating_supply.md ---
{% docs staked_circulating_supply %}

Non-locked (from a lockup.near disbursement) and staked to a node.

{% enddocs %}

'''
'''--- models/descriptions/staked_locked_supply.md ---
{% docs staked_locked_supply %}

NEAR supply that is locked via a lockup and staked to a node.

{% enddocs %}

'''
'''--- models/descriptions/staking_action.md ---
{% docs staking_action %}

The staking action performed in this transaction. Can be `"Stake"` or `"Unstake"` if in the deprecating `dim_staking_actions` table, or `staking`, `unstaking`, `deposited`, `withdrawing` if in the new `fact_staking_actions` table. These method names are taken directly from the log in which they occur.

{% enddocs %}

'''
'''--- models/descriptions/staking_pool_address.md ---
{% docs staking_pool_address %}

The pool address delegated into.

{% enddocs %}

'''
'''--- models/descriptions/staking_pool_owner.md ---
{% docs staking_pool_owner %}

The account of the staking pool owner.

{% enddocs %}

'''
'''--- models/descriptions/staking_pool_reward_fee_fraction.md ---
{% docs staking_pool_reward_fee_fraction %}

An object representing the fraction of the reward fee taken by the staking pool.

{% enddocs %}

'''
'''--- models/descriptions/staking_pool_tx_type.md ---
{% docs staking_pool_tx_type %}

The type of transaction involving this staking pool.
Either `"Create"` for staking pool creation or `"Update"` for `reward_fee_fraction` updates.

{% enddocs %}

'''
'''--- models/descriptions/staking_stake_amount.md ---
{% docs staking_stake_amount %}

The amount staked or delegated toward securing the NEAR network.

{% enddocs %}

'''
'''--- models/descriptions/start_time.md ---
{% docs start_time %}

Block timestamp associated with min block id.

{% enddocs %}

'''
'''--- models/descriptions/state_changes.md ---
{% docs state_changes %}

Account and access key updates to contracts as recorded in the block shard.

{% enddocs %}
'''
'''--- models/descriptions/stats_core.md ---
{% docs ez_core_metrics_hourly_table_doc %}

A convenience table that aggregates block and transaction related metrics using various aggregate functions such as SUM, COUNT, MIN and MAX from the fact_transactions table, on an hourly basis. Stats for the current hour will be updated as new data arrives.

{% enddocs %}

{% docs block_timestamp_hour %}

The hour of the timestamp of the block.

{% enddocs %}

{% docs block_number_min %}

The minimum block number in the hour.

{% enddocs %}

{% docs block_number_max %}

The maximum block number in the hour.

{% enddocs %}

{% docs block_count %}

The number of blocks in the hour.

{% enddocs %}

{% docs transaction_count %}

The number of transactions in the hour.

{% enddocs %}

{% docs transaction_count_success %}

The number of successful transactions in the hour.

{% enddocs %}

{% docs transaction_count_failed %}

The number of failed transactions in the hour.

{% enddocs %}

{% docs unique_from_count %}

The number of unique origin from addresses in the hour.

{% enddocs %}

{% docs unique_to_count %}

The number of unique origin to addresses in the hour.

{% enddocs %}

{% docs total_fees_native %}

The sum of all fees in the hour, in the native fee currency.

{% enddocs %}

{% docs total_fees_usd %}

The sum of all fees in the hour, in USD.

{% enddocs %}

'''
'''--- models/descriptions/status.md ---
{% docs status %}

Boolean representing the success or failure of the event.
For transfers, both the tx and receipt must have succeeded for STATUS to be TRUE. 

NOTE - it is possible for a transaction to successfully execute while one of its receipts fails. A transaction can also be a failure with successful receipts. It is possible the approach taken to determine a successful transfer is incorrect, so both tx and receipt success fields are available.

{% enddocs %}

'''
'''--- models/descriptions/status_value.md ---
{% docs status_value %}

Status information (object) for this transaction.

{% enddocs %}

'''
'''--- models/descriptions/swap_id.md ---
{% docs swap_id %}

A unique id comprised of the transaction hash combined with the swap index.

{% enddocs %}

'''
'''--- models/descriptions/swap_index.md ---
{% docs swap_index %}

The index number of the swap indicating its order of execution in the transaction.

{% enddocs %}

'''
'''--- models/descriptions/swap_input_data.md ---
{% docs swap_input_data %}

JSON of input data for the swap, taken from the FunctionCall JSON.
Note, directional keys such as in and out are determined by the pool.

{% enddocs %}

'''
'''--- models/descriptions/symbol.md ---
{% docs symbol %}

The shorthand symbol for the token, as used by common price feeds and exchanges.

{% enddocs %}

'''
'''--- models/descriptions/system_created_at.md ---
{% docs system_created_at %}

The timestamp for when the label was created by the Flipside label tool.

{% enddocs %}
'''
'''--- models/descriptions/table_dim_labels.md ---
{% docs table_dim_labels %}

The labels table is a store of one-to-one address identifiers, or an address name. Labels are broken out into a "type" (such as cex, dex, dapp, games, etc.) and a "subtype" (ex: contract_deployer, hot_wallet, token_contract, etc.) in order to help classify each address name into similar groups. Our labels are sourced from many different places, but can primarily be grouped into two categories: automatic and manual. Automatic labels are continuously labeled based on certain criteria, such as a known contract deploying another contract, behavior based algorithms for finding deposit wallets, and consistent data pulls of custom protocol APIs. Manual labels are done periodically to find addresses that cannot be found programatically such as finding new protocol addresses, centralized exchange hot wallets, or trending addresses. Labels can also be added by our community by using our add-a-label tool (https://science.flipsidecrypto.xyz/add-a-label/) or on-chain with near (https://near.social/lord1.near/widget/Form) and are reviewed by our labels team. A label can be removed by our labels team if it is found to be incorrect or no longer relevant; this generally will only happen for mislabeled deposit wallets.

{% enddocs %}

'''
'''--- models/descriptions/terminate_vesting_timestamp.md ---
{% docs terminate_vesting_timestamp %}

Timestamp of when the vesting is to be terminated, if applicable.

{% enddocs %}

'''
'''--- models/descriptions/termination_unvested_amount.md ---
{% docs termination_unvested_amount %}

Unvested amount upon termination of lockup, if applicable.

{% enddocs %}

'''
'''--- models/descriptions/termination_withdrawn_amount.md ---
{% docs termination_withdrawn_amount %}

Amount, in NEAR, withdrawn at termination of the vesting period, if applicable.

{% enddocs %}

'''
'''--- models/descriptions/test_name.md ---
{% docs test_name %}

The name of the test for observability models.

{% enddocs %}

'''
'''--- models/descriptions/test_timestamp.md ---
{% docs test_timestamp %}

The timestamp of the observability test run.

{% enddocs %}

'''
'''--- models/descriptions/timestamp.md ---
{% docs timestamp %}

The date and time for the record.

{% enddocs %}

'''
'''--- models/descriptions/to_address.md ---
{% docs to_address %}

The receiver of usn token.

{% enddocs %}

'''
'''--- models/descriptions/token.md ---
{% docs token %}

The long-form name of the token.

{% enddocs %}

'''
'''--- models/descriptions/token_contract.md ---
{% docs token_contract %}

The contract address corresponding to the token, view details of the contract by following this address on the chain explorer.

{% enddocs %}

'''
'''--- models/descriptions/token_data.md ---
{% docs token_data %}

A JSON dictionary containing metadata about the token, such as past 24h volume and transfers, number of holders, etc.

{% enddocs %}

'''
'''--- models/descriptions/token_id.md ---
{% docs token_id %}

The identifier of the token being transferred or minted.

{% enddocs %}

'''
'''--- models/descriptions/token_in.md ---
{% docs token_in %}

The address of the token sent for swap.

{% enddocs %}

'''
'''--- models/descriptions/token_metadata.md ---
{% docs token_metadata %}

NFT token-level metadata for a NFT series / collection.

{% enddocs %}

'''
'''--- models/descriptions/token_out.md ---
{% docs token_out %}

The address of the token being swapped to.

{% enddocs %}

'''
'''--- models/descriptions/tokens.md ---
{% docs tokens %}

Count of tokens issued by the NFT Contract.

{% enddocs %}

'''
'''--- models/descriptions/tokens_count.md ---
{% docs tokens_count %}

"The count of unique tokens that have been received by the receiver_id."

{% enddocs %}

'''
'''--- models/descriptions/total_locked_supply.md ---
{% docs total_locked_supply %}

Total NEAR locked by lockup.near disbursements.

{% enddocs %}

'''
'''--- models/descriptions/total_near_supply.md ---
{% docs total_near_supply %}

Total supply of NEAR, per the block header, at this epoch.

{% enddocs %}

'''
'''--- models/descriptions/total_nonstaked_supply.md ---
{% docs total_nonstaked_supply %}

Total supply less total staked supply of NEAR.

{% enddocs %}

'''
'''--- models/descriptions/total_staked_balance.md ---
{% docs total_staked_balance %}

The total staked NEAR at the time of the reward payout. Number is presented raw and not decimal adjusted in the fact table.

{% enddocs %}

'''
'''--- models/descriptions/total_staked_supply.md ---
{% docs total_staked_supply %}

Gross staked supply of NEAR.

{% enddocs %}

'''
'''--- models/descriptions/total_staking_shares.md ---
{% docs total_staking_shares %}

Total staking shares that comprise the staked balance of the pool. Number is presented raw and not decimal adjusted in the fact table.

{% enddocs %}

'''
'''--- models/descriptions/total_supply.md ---
{% docs total_supply %}

The total_supply taken from block headers.

{% enddocs %}

'''
'''--- models/descriptions/total_wallets.md ---
{% docs total_wallets %}

Total number of wallets created

{% enddocs %}

'''
'''--- models/descriptions/trader.md ---
{% docs trader %}

The address who initiated the swap.

{% enddocs %}

'''
'''--- models/descriptions/transaction_fee.md ---
{% docs transaction_fee %}

Total fee paid in NEAR to execute this transaction, which is a summation of all fees paid for actions and receipts within the transaction.

In raw number format, to adjust divide by POW(10,24)

{% enddocs %}

'''
'''--- models/descriptions/transfer_type.md ---
{% docs transfer_type %}

Nature of the transfer

{% enddocs %}

'''
'''--- models/descriptions/transfers_information.md ---
{% docs transfers_information %}

A dictionary of information about the parameters allowing or limiting transfers of the locked NEAR.

{% enddocs %}

'''
'''--- models/descriptions/tx.md ---
{% docs tx %}

The transaction's information.

{% enddocs %}

'''
'''--- models/descriptions/tx_block_index.md ---
{% docs tx_block_index %}

The index of the transaction within the block. Starts at 0.

{% enddocs %}

'''
'''--- models/descriptions/tx_count.md ---
{% docs tx_count %}

The `tx_count` taken from block headers. The number of transactions included in the block.

{% enddocs %}

'''
'''--- models/descriptions/tx_hash.md ---
{% docs tx_hash %}

Unique identifier (hash) of this transaction.

{% enddocs %}

'''
'''--- models/descriptions/tx_id.md ---
{% docs tx_id %}

Synonmous with transaction hash, a unique on chain identifier for the transaction

{% enddocs %}

'''
'''--- models/descriptions/tx_outcome.md ---
{% docs tx_outcome %}

The transaction outcome.

{% enddocs %}

'''
'''--- models/descriptions/tx_receipt.md ---
{% docs tx_receipt %}

The transaction receipt.

{% enddocs %}

'''
'''--- models/descriptions/tx_receiver.md ---
{% docs tx_receiver %}

The transaction receiver.

{% enddocs %}

'''
'''--- models/descriptions/tx_signer.md ---
{% docs tx_signer %}

The transaction signer.

{% enddocs %}

'''
'''--- models/descriptions/tx_status.md ---
{% docs tx_status %}

/// DEPRECATION WARNING /// Indicates whether the transaction failed or succeeded. This will be get deprecated in the future. Please use `tx_succeeded` instead.

{% enddocs %}

'''
'''--- models/descriptions/tx_succeeded.md ---
{% docs tx_succeeded %}

Indicates whether the transaction failed or succeeded.

{% enddocs %}

'''
'''--- models/descriptions/txn_hash.md ---
{% docs txn_hash %}

Unique identifier (hash) of this transaction.

{% enddocs %}

'''
'''--- models/descriptions/unlocked_amount_today.md ---
{% docs unlocked_amount_today %}

Amount of NEAR unlocked on the date of record.

{% enddocs %}

'''
'''--- models/descriptions/unreleased_amount.md ---
{% docs unreleased_amount %}

Amount of NEAR yet to be unlocked, as of the date of record.

{% enddocs %}

'''
'''--- models/descriptions/unvested_amount.md ---
{% docs unvested_amount %}

Unvested NEAR at time of record.

{% enddocs %}

'''
'''--- models/descriptions/utc_date.md ---
{% docs utc_date %}

Datestamp, assuming UTC-0, of the record.

{% enddocs %}

'''
'''--- models/descriptions/validator_proposals.md ---
{% docs validator_proposals %}

The validator_proposals taken from block headers.

{% enddocs %}

'''
'''--- models/descriptions/validator_reward.md ---
{% docs validator_reward %}

The validator_reward taken from block headers.

{% enddocs %}

'''
'''--- models/descriptions/vesting_cliff_timestamp.md ---
{% docs vesting_cliff_timestamp %}

Timestamp for a cliff-style unlock of NEAR, if applicable to this lockup.

{% enddocs %}

'''
'''--- models/descriptions/vesting_end_timestamp.md ---
{% docs vesting_end_timestamp %}

End of the vesting period, if applicable.

{% enddocs %}

'''
'''--- models/descriptions/vesting_schedule.md ---
{% docs vesting_schedule %}

Legacy/no longer used. The vesting schedule for the locked tokens.

{% enddocs %}

'''
'''--- models/descriptions/vesting_start_timestamp.md ---
{% docs vesting_start_timestamp %}

The start of the vesting period.

{% enddocs %}

'''
'''--- models/descriptions/vesting_time_left_ns.md ---
{% docs vesting_time_left_ns %}

Time left, in ns, until the lockup is fully vested, if applicable.

{% enddocs %}

'''
'''--- models/descriptions/vesting_total_time_ns.md ---
{% docs vesting_total_time_ns %}

The total amount of time, in ns, of the vesting period, if applicable.

{% enddocs %}

'''
'''--- models/descriptions/wallets_created.md ---
{% docs wallets_created %}

Number of wallets created.

{% enddocs %}

'''
'''--- models/descriptions/weekly_active_contracts.md ---
{% docs weekly_active_contracts %}

The number of active contracts for the week of the date.

{% enddocs %}

'''
'''--- models/descriptions/widget_modules_used.md ---
{% docs widget_modules_used %}

References any other widgets used in the targeted widget/Near Social app. May be null.

{% enddocs %}
'''
'''--- models/descriptions/widget_name.md ---
{% docs widget_name %}

The name of the widget as saved on Near Social. There is no unique identifier for widgets, so if the name is changed by the developer the next transaction record will reflect the new name.

{% enddocs %}
'''
'''--- models/descriptions/widget_url.md ---
{% docs widget_url %}

A direct link to the widget. Note, if the name was later changed, this URL will be an invalid link.

{% enddocs %}
'''
'''--- models/gold/atlas/atlas__ez_nft_contract_metrics.sql ---
{{ config(
    materialized = 'view',
    secure = false,
    meta={
    'database_tags':{
        'table': {
            'PURPOSE': 'ATLAS'
            }
        }
    },
    tags = ['atlas']
) }}

WITH nft_data AS (

    SELECT
        atlas_nft_table_id AS ez_nft_contract_metrics_id,
        receiver_id,
        tokens,
        transfers_24h,
        transfers_3d,
        all_transfers,
        owners,
        transactions,
        mints,
        COALESCE(inserted_timestamp, '2000-01-01' :: TIMESTAMP_NTZ) AS inserted_timestamp,
        COALESCE(modified_timestamp, '2000-01-01' :: TIMESTAMP_NTZ) AS modified_timestamp
    FROM
        {{ ref('silver__atlas_nft_table') }}
)
SELECT
    *
FROM
    nft_data

'''
'''--- models/gold/atlas/atlas__ez_nft_contract_metrics.yml ---
version: 2

models:
  - name: atlas__ez_nft_contract_metrics
    description: |-
      NFT transaction activities by receiver_id. It includes counts of unique tokens, transfers within the last 24 hours and 3 days, all transfers, unique owners, total transactions, and minting events.
    tests:
      - dbt_utils.recency:
          datepart: days
          field: inserted_timestamp
          interval: 1

    columns:
      - name: EZ_NFT_CONTRACT_METRICS_ID
        description: "{ { doc('id')}}"
        tests:
          - unique:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'
          - not_null:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'

      - name: RECEIVER_ID
        description: "{ { doc('receiver_id')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - STRING
                - VARCHAR

      - name: TOKENS
        description: "{{ doc('tokens_count')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - NUMBER
                - INTEGER

      - name: TRANSFERS_24H
        description: "The count of 'nft_transfer' transactions that occurred in the last 24 hours."
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - NUMBER
                - INTEGER

      - name: TRANSFERS_3D
        description: "The count of 'nft_transfer' transactions that occurred in the last 3 days."
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - NUMBER
                - INTEGER

      - name: ALL_TRANSFERS
        description: "{{ doc('all_transfers')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - NUMBER
                - INTEGER

      - name: OWNERS
        description: "{{ doc('owner_count')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - NUMBER
                - INTEGER

      - name: TRANSACTIONS
        description: "{{ doc('tx_count')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - NUMBER
                - INTEGER

      - name: MINTS
        description: "{{ doc('mint_count')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - NUMBER
                - INTEGER

      - name: INSERTED_TIMESTAMP
        description: "{{ doc('inserted_timestamp')}}"

      - name: MODIFIED_TIMESTAMP
        description: "{{ doc('modified_timestamp')}}"

'''
'''--- models/gold/atlas/atlas__ez_nft_contract_metrics_daily.sql ---
{{ config(
    materialized = 'view',
    secure = false,
    meta={
    'database_tags':{
        'table': {
            'PURPOSE': 'ATLAS'
            }
        }
    },
    tags = ['atlas']
) }}

WITH nft_detailed AS (

    SELECT
        atlas_nft_detailed_id AS ez_nft_contract_metrics_daily_id,
        DAY,
        receiver_id,
        tokens,
        all_transfers,
        owners,
        transactions,
        mints,
        COALESCE(inserted_timestamp, '2000-01-01' :: TIMESTAMP_NTZ) AS inserted_timestamp,
        COALESCE(modified_timestamp, '2000-01-01' :: TIMESTAMP_NTZ) AS modified_timestamp
    FROM
        {{ ref('silver__atlas_nft_detailed') }}
)
SELECT
    *
FROM
    nft_detailed

'''
'''--- models/gold/atlas/atlas__ez_nft_contract_metrics_daily.yml ---
version: 2

models:
  - name: atlas__ez_nft_contract_metrics_daily
    description: |-
      Overview of NFT transactions in NEAR.
    tests:
      - dbt_utils.recency:
          datepart: days
          field: inserted_timestamp
          interval: 1

columns:
  - name: EZ_NFT_CONTRACT_METRICS_DAILY_ID
    description: "{{ doc('id')}}"
    tests:
      - unique:
          where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'
      - not_null:
          where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'

  - name: DAY
    description: "{{ doc('date')}}"
    tests:
      - not_null

  - name: RECEIVER_ID
    description: "{{ doc('tx_receiver')}}"
    tests:
      - not_null
      - dbt_expectations.expect_column_values_to_be_in_type_list:
          column_type_list:
            - STRING
            - VARCHAR

  - name: TOKENS
    description: "{{ doc('tokens_count')}}"
    tests:
      - not_null
      - dbt_expectations.expect_column_values_to_be_in_type_list:
          column_type_list:
            - NUMBER
            - INTEGER

  - name: ALL_TRANSFERS
    description: "{{ doc('all_transfers')}}"
    tests:
      - not_null
      - dbt_expectations.expect_column_values_to_be_in_type_list:
          column_type_list:
            - NUMBER
            - INTEGER

  - name: OWNERS
    description: "{{ doc('owner_count')}}"
    tests:
      - not_null
      - dbt_expectations.expect_column_values_to_be_in_type_list:
          column_type_list:
            - NUMBER
            - INTEGER

  - name: TRANSACTIONS
    description: "{{ doc('tx_count')}}"
    tests:
      - not_null
      - dbt_expectations.expect_column_values_to_be_in_type_list:
          column_type_list:
            - NUMBER
            - INTEGER

  - name: MINTS
    description: "{{ doc('mint_count')}}"
    tests:
      - not_null
      - dbt_expectations.expect_column_values_to_be_in_type_list:
          column_type_list:
            - NUMBER
            - INTEGER

  - name: INSERTED_TIMESTAMP
    description: "{{ doc('inserted_timestamp')}}"

  - name: MODIFIED_TIMESTAMP
    description: "{{ doc('modified_timestamp')}}"

'''
'''--- models/gold/atlas/atlas__ez_supply.sql ---
{{ config(
    materialized = 'view',
    secure = false,
    meta={
    'database_tags':{
        'table': {
            'PURPOSE': 'ATLAS'
            }
        }
    },
    tags = ['atlas']
) }}

WITH supply AS (

    SELECT
        utc_date,
        total_supply,
        total_staked_supply,
        total_nonstaked_supply,
        circulating_supply,
        total_locked_supply,
        liquid_supply,
        nonliquid_supply,
        staked_locked_supply,
        non_staked_locked_supply,
        staked_circulating_supply,
        nonstaked_circulating_supply,
        perc_locked_supply,
        perc_circulating_supply,
        perc_staked_locked,
        perc_staked_circulating,
        atlas_supply_id AS ez_supply_id,
        COALESCE(inserted_timestamp, '2000-01-01' :: TIMESTAMP_NTZ) AS inserted_timestamp,
        COALESCE(modified_timestamp, '2000-01-01' :: TIMESTAMP_NTZ) AS modified_timestamp
    FROM
        {{ ref('silver__atlas_supply') }}
)
SELECT
    *
FROM
    supply

'''
'''--- models/gold/atlas/atlas__ez_supply.yml ---
version: 2

models:
  - name: atlas__ez_supply
    description: |-
      A table represeting calculations for the supply of NEAR across various categories, such as staked and locked.
    tests:
      - dbt_utils.recency:
          datepart: days
          field: inserted_timestamp
          interval: 1
    
    columns:
      - name: UTC_DATE
        description: "{{ doc('utc_date') }}"
        tests:
          - not_null
      - name: TOTAL_SUPPLY
        description: "{{ doc('total_supply') }}"
        tests:
          - not_null
      - name: TOTAL_STAKED_SUPPLY
        description: "{{ doc('total_staked_supply') }}"
        tests:
          - not_null
      - name: TOTAL_NONSTAKED_SUPPLY
        description: "{{ doc('total_nonstaked_supply') }}"
        tests:
          - not_null
      - name: CIRCULATING_SUPPLY
        description: "{{ doc('circulating_supply') }}"
        tests:
          - not_null
      - name: TOTAL_LOCKED_SUPPLY
        description: "{{ doc('total_locked_supply') }}"
        tests:
          - not_null
      - name: LIQUID_SUPPLY
        description: "{{ doc('liquid_supply') }}"
        tests:
          - not_null
      - name: NONLIQUID_SUPPLY
        description: "{{ doc('nonliquid_supply') }}"
        tests:
          - not_null
      - name: STAKED_LOCKED_SUPPLY
        description: "{{ doc('staked_locked_supply') }}"
        tests:
          - not_null
      - name: NON_STAKED_LOCKED_SUPPLY
        description: "{{ doc('non_staked_locked_supply') }}"
        tests:
          - not_null
      - name: STAKED_CIRCULATING_SUPPLY
        description: "{{ doc('staked_circulating_supply') }}"
        tests:
          - not_null
      - name: NONSTAKED_CIRCULATING_SUPPLY
        description: "{{ doc('nonstaked_circulating_supply') }}"
        tests:
          - not_null
      - name: PERC_LOCKED_SUPPLY
        description: "{{ doc('perc_locked_supply') }}"
        tests:
          - not_null
      - name: PERC_CIRCULATING_SUPPLY
        description: "{{ doc('perc_circulating_supply') }}"
        tests:
          - not_null
      - name: PERC_STAKED_LOCKED
        description: "{{ doc('perc_staked_locked') }}"
        tests:
          - not_null
      - name: PERC_STAKED_CIRCULATING
        description: "{{ doc('perc_staked_circulating') }}"
        tests:
          - not_null
      - name: EZ_SUPPLY_ID
        description: "{{ doc('id') }}"
        tests:
          - not_null
          - unique
      - name: INSERTED_TIMESTAMP
        description: "{{ doc('inserted_timestamp') }}"

      - name: MODIFIED_TIMESTAMP
        description: "{{ doc('modified_timestamp') }}"

'''
'''--- models/gold/atlas/atlas__fact_accounts_created.sql ---
{{ config(
    materialized = 'view',
    secure = false,
    meta={
    'database_tags':{
        'table': {
            'PURPOSE': 'ATLAS'
            }
        }
    },
    tags = ['atlas']
) }}

SELECT
    atlas_account_created_id AS fact_accounts_created_id,
    DAY,
    wallets_created,
    inserted_timestamp,
    modified_timestamp
FROM
    {{ ref('silver__atlas_accounts_created') }}

'''
'''--- models/gold/atlas/atlas__fact_accounts_created.yml ---
version: 2

models:
  - name: atlas__fact_accounts_created
    description: |-
      Daily count of accounts created on NEAR.
    tests:
      - dbt_utils.recency:
          datepart: days
          field: inserted_timestamp
          interval: 1

    columns:
      - name: FACT_ACCOUNTS_CREATED_ID
        description: "{ { doc('id')}}"
        tests:
          - unique:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'
          - not_null:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'

      - name: DAY
        description: "{{ doc('date')}}"
        tests:
          - not_null

      - name: WALLETS_CREATED
        description: "{{ doc('wallets_created')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - NUMBER
                - INTEGER

      - name: INSERTED_TIMESTAMP
        description: "{{doc('inserted_timestamp')}}"

      - name: MODIFIED_TIMESTAMP
        description: "{{doc('modified_timestamp')}}"

      - name: INVOCATION_ID
        description: "{{doc('invocation_id')}}"

'''
'''--- models/gold/atlas/atlas__fact_maas.sql ---
{{ config(
    materialized = 'view',
    meta={
    'database_tags':{
        'table': {
            'PURPOSE': 'ATLAS'
            }
        }
    },
    tags = ['atlas']
) }}

SELECT
    atlas_maa_id AS fact_maas_id,
    day,
    maa,
    new_maas,
    returning_maas,
    COALESCE(inserted_timestamp, '2000-01-01' :: TIMESTAMP_NTZ) AS inserted_timestamp,
    COALESCE(modified_timestamp, '2000-01-01' :: TIMESTAMP_NTZ) AS modified_timestamp
FROM
    {{ ref('silver__atlas_maa') }}

'''
'''--- models/gold/atlas/atlas__fact_maas.yml ---
version: 2

models:
  - name: atlas__fact_maas
    description: |-
      Monthly Active Accounts (wallets) on NEAR, including new and returning wallets, calculated over a rolling 30 day window. An active account, here, is defined as the signing of at least one transaction.
    tests:
      - dbt_utils.recency:
          datepart: days
          field: inserted_timestamp
          interval: 1

    columns:
      - name: fact_maas_id
        description: "{{ doc('id') }}"
        tests:
          - not_null:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'
          - unique:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'

      - name: day
        description: "{{ doc('active_day') }}"
        tests:
          - not_null
          - unique

      - name: maa
        description: "{{ doc('maa')}}"
        tests:
          - not_null

      - name: new_maas
        description: "{{ doc('new_maas') }}"
        tests:
          - not_null

      - name: returning_maas
        description: "{{ doc('returning_maas') }}"
        tests:
          - not_null

      - name: inserted_timestamp
        description: "{{ doc('inserted_timestamp') }}"

      - name: modified_timestamp
        description: "{{ doc('modified_timestamp') }}"

'''
'''--- models/gold/atlas/atlas__fact_nft_monthly_txs.sql ---
{{ config(
    materialized = 'view',
    secure = false,
    meta={
    'database_tags':{
        'table': {
            'PURPOSE': 'ATLAS'
            }
        }
    },
    tags = ['atlas']
) }}

WITH TRAILING AS (

    SELECT
        atlas_nft_30_trailing_id AS fact_nft_monthly_txs_id,
        DAY,
        txns,
        COALESCE(inserted_timestamp, '2000-01-01' :: TIMESTAMP_NTZ) AS inserted_timestamp,
        COALESCE(modified_timestamp, '2000-01-01' :: TIMESTAMP_NTZ) AS modified_timestamp
    FROM
        {{ ref('silver__atlas_nft_30_trailing') }}
)
SELECT
    *
FROM
    TRAILING

'''
'''--- models/gold/atlas/atlas__fact_nft_monthly_txs.yml ---
version: 2

models:
  - name: atlas__fact_nft_monthly_txs
    description: |-
      Summary of NFT transactions from the 'silver__atlas_nft_transactions' table. It provides a daily count of transactions, accounting for a 29-day lookback period for each day within the specified date range.
    tests:
      - dbt_utils.recency:
          datepart: days
          field: inserted_timestamp
          interval: 1

    columns:
      - name: FACT_NFT_MONTHLY_TXS_ID
        description: "{{ doc('id')}}"
        tests:
          - unique:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'
          - not_null:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'

      - name: DAY
        description: "{{ doc('date')}}"
        tests:
          - not_null

      - name: TXNS
        description: "{{ doc('tx_count')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - NUMBER
                - INTEGER
                
      - name: INSERTED_TIMESTAMP
        description: "{{ doc('inserted_timestamp')}}"

      - name: MODIFIED_TIMESTAMP
        description: "{{ doc('modified_timestamp')}}"

'''
'''--- models/gold/core/core__dim_address_labels.sql ---
{{ config(
    materialized = 'view',
    secure = false,
    tags = ['core']
) }}

WITH flipside_labels AS (

    SELECT
        system_created_at,
        blockchain,
        address,
        address_name,
        project_name,
        label_type,
        label_subtype,
        l1_label,
        l2_label,
        creator,
        address_labels_id AS dim_address_labels_id,
        inserted_timestamp,
        modified_timestamp
    FROM
        {{ ref('silver__address_labels') }}
)
SELECT
    *
FROM
    flipside_labels

'''
'''--- models/gold/core/core__dim_address_labels.yml ---
version: 2

models:
  - name: core__dim_address_labels
    description: |-
      "{{doc('table_dim_labels')}}"

    columns:
      - name: SYSTEM_CREATED_AT
        description: "{{ doc('system_created_at')}}"

      - name: BLOCKCHAIN
        description: "{{ doc('symbol')}}"

      - name: ADDRESS
        description: "{{ doc('address')}}"

      - name: ADDRESS_NAME
        description: "{{ doc('address_name')}}"

      - name: PROJECT_NAME
        description: "{{ doc('project_name')}}"

      - name: LABEL_TYPE
        description: "{{ doc('label_type')}}"

      - name: LABEL_SUBTYPE
        description: "{{ doc('label_subtype')}}"

      - name: L1_LABEL
        description: "{{ doc('l1_label')}}"

      - name: L2_LABEL
        description: "{{ doc('l2_label')}}"

      - name: DIM_ADDRESS_LABELS_ID
        description: "{{doc('id')}}"
        tests:
          - not_null
          - unique:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'

      - name: INSERTED_TIMESTAMP
        description: "{{doc('inserted_timestamp')}}"

      - name: MODIFIED_TIMESTAMP
        description: "{{doc('modified_timestamp')}}"

'''
'''--- models/gold/core/core__dim_ft_contract_metadata.sql ---
{{ config(
    materialized = 'view',
    tags = ['core', 'livequery', 'nearblocks']
) }}

WITH ft_contract_metadata AS (

    SELECT
        *
    FROM
        {{ ref('silver__ft_contract_metadata') }}
)
SELECT
    contract_address,
    NAME,
    symbol,
    decimals,
    icon,
    COALESCE(
        ft_contract_metadata_id,
        {{ dbt_utils.generate_surrogate_key(
            ['contract_address']
        ) }}
    ) AS dim_ft_contract_metadata_id,
    COALESCE(inserted_timestamp, _inserted_timestamp, '2000-01-01' :: TIMESTAMP_NTZ) AS inserted_timestamp,
    COALESCE(modified_timestamp, _inserted_timestamp, '2000-01-01' :: TIMESTAMP_NTZ) AS modified_timestamp
FROM
    ft_contract_metadata

'''
'''--- models/gold/core/core__dim_ft_contract_metadata.yml ---
version: 2

models:
  - name: core__dim_ft_contract_metadata
    description: |-
      Fungible Token contract metadata provided by the Nearblocks NFT endpoint.

    columns:
      - name: CONTRACT_ADDRESS
        description: "{{ doc('contract_address')}}"
        tests:
          - not_null

      - name: NAME
        description: "{{ doc('name')}}"
        tests: 
          - not_null

      - name: SYMBOL
        description: "{{ doc('symbol')}}"
        tests: 
          - not_null

      - name: DECIMALS
        description: "{{ doc('decimals')}}"
        tests: 
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - NUMBER
                - FLOAT

      - name: ICON
        description: "{{ doc('icon')}}"

      - name: DATA
        description: "{{ doc('data')}}"

      - name: DIM_FT_CONTRACT_METADATA_ID
        description: "{{doc('id')}}"
        tests:
          - not_null
          - unique:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'

      - name: INSERTED_TIMESTAMP
        description: "{{doc('inserted_timestamp')}}"

      - name: MODIFIED_TIMESTAMP
        description: "{{doc('modified_timestamp')}}"

'''
'''--- models/gold/core/core__ez_token_transfers.sql ---
{{ config(
    materialized = 'view',
    secure = false,
    tags = ['core']
) }}

WITH token_transfers AS (

    SELECT
        *
    FROM
        {{ ref('silver__token_transfers') }}
)
SELECT
    block_id,
    block_timestamp,
    tx_hash,
    action_id,
    contract_address,
    from_address,
    to_address,
    memo,
    amount_raw,
    amount_raw_precise,
    transfer_type,
    transfers_id AS fact_token_transfers_id,
    COALESCE(inserted_timestamp, _inserted_timestamp, '2000-01-01' :: TIMESTAMP_NTZ) AS inserted_timestamp,
    COALESCE(modified_timestamp, _inserted_timestamp, '2000-01-01' :: TIMESTAMP_NTZ) AS modified_timestamp
FROM
    token_transfers

'''
'''--- models/gold/core/core__ez_token_transfers.yml ---
version: 2

models:
  - name: core__ez_token_transfers
    description: This table records all the token transfers native and nep-141
    columns:
      - name: BLOCK_ID
        description: "{{ doc('block_id')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - NUMBER
                - FLOAT

      - name: BLOCK_TIMESTAMP
        description: "{{ doc('block_timestamp')}}"
        tests:
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - TIMESTAMP_NTZ
          - not_null:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'

      - name: TX_HASH
        description: "{{ doc('tx_hash')}}"
        tests:
          - not_null

      - name: CONTRACT_ADDRESS
        description: "{{ doc('contract_address')}}"

      - name: FROM_ADDRESS
        description: "{{ doc('from_address')}}"

      - name: TO_ADDRESS
        description: "{{ doc('to_address')}}"

      - name: MEMO
        description: "{{ doc('memo')}}"

      - name: AMOUNT_RAW
        description: "{{ doc('amount_raw')}}"

      - name: AMOUNT_RAW_PRECISE
        description: "{{ doc('amount_adj')}}"

      - name: TRANSFER_TYPE
        description: "{{ doc('transfer_type')}}"

      - name: HAS_PRICE
        description: "Boolean value indicating if the token has a price"

      - name: FACT_TOKEN_TRANSFERS_ID
        description: "{{doc('id')}}"
        tests:
          - unique:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'
          - not_null:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'

      - name: INSERTED_TIMESTAMP
        description: "{{doc('inserted_timestamp')}}"

      - name: MODIFIED_TIMESTAMP
        description: "{{doc('modified_timestamp')}}"

'''
'''--- models/gold/core/core__fact_actions_events.sql ---
{{ config(
    materialized = 'view',
    secure = false,
    tags = ['core']
) }}

WITH actions AS (

    SELECT
        *
    FROM
        {{ ref('silver__actions_events_s3') }}
)
SELECT
    action_id,
    tx_hash,
    receipt_object_id,
    predecessor_id,
    receiver_id,
    signer_id,
    block_id,
    block_timestamp,
    action_index,
    action_name,
    action_data,
    logs,
    receipt_succeeded,
    COALESCE(
        actions_events_id,
        {{ dbt_utils.generate_surrogate_key(
            ['receipt_object_id', 'action_index']
        ) }}
    ) AS fact_actions_events_id,
    COALESCE(inserted_timestamp, _inserted_timestamp, '2000-01-01' :: TIMESTAMP_NTZ) AS inserted_timestamp,
    COALESCE(modified_timestamp, _inserted_timestamp, '2000-01-01' :: TIMESTAMP_NTZ) AS modified_timestamp
FROM
    actions

'''
'''--- models/gold/core/core__fact_actions_events.yml ---
version: 2

models:
  - name: core__fact_actions_events
    description: |-
      This table extracts all action events from a transaction and stores the argument data under action_data.
    tests:
      - dbt_utils.recency:
          datepart: hours
          field: block_timestamp
          interval: 2

    columns:
      - name: ACTION_ID
        description: "{{ doc('action_id')}}"
        tests:
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - STRING
                - VARCHAR

      - name: TX_HASH
        description: "{{ doc('tx_hash')}}"
        tests:
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - STRING
                - VARCHAR
          - not_null:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'

      - name: RECEIPT_OBJECT_ID
        description: "{{ doc('receipt_object_id')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - STRING
                - VARCHAR

      - name: RECEIVER_ID
        description: "{{ doc('receiver_id')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - STRING
                - VARCHAR

      - name: PREDECESSOR_ID
        description: "{{ doc('predecessor_id')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - STRING
                - VARCHAR

      - name: SIGNER_ID
        description: "{{ doc('signer_id')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - STRING
                - VARCHAR

      - name: BLOCK_ID
        description: "{{ doc('block_id')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - NUMBER
                - FLOAT

      - name: BLOCK_TIMESTAMP
        description: "{{ doc('block_timestamp')}}"
        tests:
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - TIMESTAMP_NTZ
          - not_null:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'

      - name: ACTION_INDEX
        description: "{{ doc('action_index')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - NUMBER

      - name: ACTION_NAME
        description: "{{ doc('action_name')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - STRING
                - VARCHAR

      - name: ACTION_DATA
        description: "{{ doc('action_data')}}"
        tests:
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - OBJECT
                - VARIANT

      - name: LOGS
        description: "{{ doc('logs')}}"
        
      - name: RECEIPT_SUCCEEDED
        description: "{{ doc('receipt_succeeded')}}"

      - name: FACT_ACTIONS_EVENTS_ID
        description: "{{ doc('id')}}"
        tests:
          - unique:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours' AND FACT_ACTIONS_EVENTS_ID != 'cf646ad92e6df243ffabf07c47c0f2c1'
          - not_null:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'

      - name: INSERTED_TIMESTAMP
        description: "{{ doc('inserted_timestamp')}}"

      - name: MODIFIED_TIMESTAMP
        description: "{{ doc('modified_timestamp')}}"

'''
'''--- models/gold/core/core__fact_actions_events_function_call.sql ---
{{ config(
    materialized = 'view',
    secure = false,
    tags = ['core']
) }}

WITH actions_events_function_call AS (

    SELECT
        *
    FROM
        {{ ref('silver__actions_events_function_call_s3') }}
)
SELECT
    action_id,
    tx_hash,
    receiver_id,
    predecessor_id,
    signer_id,
    block_id,
    block_timestamp,
    action_name,
    method_name,
    args,
    deposit,
    attached_gas,
    logs,
    receipt_succeeded,
    COALESCE(
        actions_events_function_call_id,
        {{ dbt_utils.generate_surrogate_key(
            ['action_id']
        ) }}
    ) AS fact_actions_events_function_call_id,
    COALESCE(inserted_timestamp, _inserted_timestamp, '2000-01-01' :: TIMESTAMP_NTZ) AS inserted_timestamp,
    COALESCE(modified_timestamp, _inserted_timestamp, '2000-01-01' :: TIMESTAMP_NTZ) AS modified_timestamp
FROM
    actions_events_function_call

'''
'''--- models/gold/core/core__fact_actions_events_function_call.yml ---
version: 2

models:
  - name: core__fact_actions_events_function_call
    description: |-
      This table extracts all FunctionCall events from actions and decodes the arguments for easy use. If further nested arguments are encoded, the snowflake function `try_base64_decode_string()` will likely work.
    tests:
      - dbt_utils.recency:
          datepart: hours
          field: block_timestamp
          interval: 2

    columns:
      - name: ACTION_ID
        description: "{{ doc('action_id')}}"
        tests:
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - STRING
                - VARCHAR

      - name: TX_HASH
        description: "{{ doc('tx_hash')}}"
        tests:
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - STRING
                - VARCHAR
          - not_null:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'

      - name: RECEIVER_ID
        description: "{{ doc('receiver_id')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - STRING
                - VARCHAR

      - name: PREDECESSOR_ID
        description: "{{ doc('predecessor_id')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - STRING
                - VARCHAR

      - name: SIGNER_ID
        description: "{{ doc('signer_id')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - STRING
                - VARCHAR

      - name: BLOCK_ID
        description: "{{ doc('block_id')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - NUMBER
                - FLOAT

      - name: BLOCK_TIMESTAMP
        description: "{{ doc('block_timestamp')}}"
        tests:
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - TIMESTAMP_NTZ
          - not_null:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'

      - name: ACTION_NAME
        description: "{{ doc('action_name')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - STRING
                - VARCHAR

      - name: METHOD_NAME
        description: "{{ doc('method_name')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - STRING
                - VARCHAR

      - name: ARGS
        description: "{{ doc('args')}}"
        tests:
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - VARIANT
                - OBJECT

      - name: DEPOSIT
        description: "{{ doc('deposit')}}"
        tests:
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - NUMBER
                - FLOAT

      - name: ATTACHED_GAS
        description: "{{ doc('attached_gas')}}"
        tests:
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - NUMBER
                - FLOAT

      - name: LOGS
        description: "{{ doc('logs')}}"
        tests:
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - ARRAY
                - VARIANT
                - OBJECT

      - name: RECEIPT_SUCCEEDED
        description: "{{ doc('receipt_succeeded')}}"
        tests:
          - not_null

      - name: FACT_ACTIONS_EVENTS_FUNCTION_CALL_ID
        description: "{{doc('id')}}"
        tests:
          - unique:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'
          - not_null:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'

      - name: INSERTED_TIMESTAMP
        description: "{{doc('inserted_timestamp')}}"

      - name: MODIFIED_TIMESTAMP
        description: "{{doc('modified_timestamp')}}"

'''
'''--- models/gold/core/core__fact_blocks.sql ---
{{ config(
    materialized = 'view',
    secure = false,
    tags = ['core']
) }}

WITH blocks AS (

    SELECT
        *
    FROM
        {{ ref('silver__streamline_blocks') }}
)
SELECT
    block_id,
    block_timestamp,
    block_hash,
    tx_count, -- TO DEPRECATE
    block_author,
    header,
    header :challenges_result :: ARRAY AS block_challenges_result,
    header :challenges_root :: STRING AS block_challenges_root,
    header :chunk_headers_root :: STRING AS chunk_headers_root,
    header :chunk_tx_root :: STRING AS chunk_tx_root,
    header :chunk_mask :: ARRAY AS chunk_mask,
    header :chunk_receipts_root :: STRING AS chunk_receipts_root,
    chunks,
    header :chunks_included :: NUMBER AS chunks_included,
    epoch_id,
    header :epoch_sync_data_hash :: STRING AS epoch_sync_data_hash,
    events, -- TO DEPRECATE
    gas_price,
    header :last_ds_final_block :: STRING AS last_ds_final_block,
    header :last_final_block :: STRING AS last_final_block,
    latest_protocol_version,
    header: next_bp_hash :: STRING AS next_bp_hash,
    next_epoch_id,
    header :outcome_root :: STRING AS outcome_root,
    prev_hash,
    header :prev_height :: NUMBER AS prev_height,
    header :prev_state_root :: STRING AS prev_state_root,
    header :random_value :: STRING AS random_value,
    header :rent_paid :: FLOAT AS rent_paid,
    header :signature :: STRING AS signature,
    total_supply,
    validator_proposals,
    validator_reward,
    COALESCE(
        streamline_blocks_id,
        {{ dbt_utils.generate_surrogate_key(
            ['block_id']
        ) }}
    ) AS fact_blocks_id,
    COALESCE(inserted_timestamp, _inserted_timestamp, '2000-01-01' :: TIMESTAMP_NTZ) AS inserted_timestamp,
    COALESCE(modified_timestamp, _inserted_timestamp, '2000-01-01' :: TIMESTAMP_NTZ) AS modified_timestamp
FROM
    blocks

'''
'''--- models/gold/core/core__fact_blocks.yml ---
version: 2

models:
  - name: core__fact_blocks
    description: |-
      This table records all the blocks of Near blockchain.
    tests:
      - dbt_utils.recency:
          datepart: hours
          field: block_timestamp
          interval: 2

    columns:
      - name: BLOCK_ID
        description: "{{ doc('block_id')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - NUMBER
                - FLOAT

      - name: BLOCK_TIMESTAMP
        description: "{{ doc('block_timestamp')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - TIMESTAMP_NTZ

      - name: BLOCK_HASH
        description: "{{ doc('block_hash')}}"
        tests:
          - not_null
          - unique:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - STRING
                - VARCHAR

      - name: TX_COUNT
        description: "{{ doc('tx_count')}}"

      - name: BLOCK_AUTHOR
        description: "{{ doc('block_author')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - STRING
                - VARCHAR

      - name: HEADER
        description: "{{ doc('header')}}"
        tests:
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - VARIANT
                - OBJECT

      - name: BLOCK_CHALLENGES_RESULT
        description: "{{ doc('block_challenges_result')}}"
        tests:
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - ARRAY
                - VARIANT
                - OBJECT

      - name: BLOCK_CHALLENGES_ROOT
        description: "{{ doc('block_challenges_root')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - STRING
                - VARCHAR

      - name: CHUNK_HEADERS_ROOT
        description: "{{ doc('chunk_headers_root')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - STRING
                - VARCHAR

      - name: CHUNK_TX_ROOT
        description: "{{ doc('chunk_tx_root')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - STRING
                - VARCHAR

      - name: CHUNK_MASK
        description: "{{ doc('chunk_mask')}}"
        tests:
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - ARRAY
                - VARIANT
                - OBJECT

      - name: CHUNK_RECEIPTS_ROOT
        description: "{{ doc('chunk_receipts_root')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - STRING
                - VARCHAR

      - name: CHUNKS
        description: "{{ doc('chunks')}}"
        tests:
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - ARRAY
                - VARIANT
                - OBJECT

      - name: CHUNKS_INCLUDED
        description: "{{ doc('chunks_included')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - NUMBER

      - name: EPOCH_ID
        description: "{{ doc('epoch_id')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - STRING
                - VARCHAR

      - name: EPOCH_SYNC_DATA_HASH
        description: "{{ doc('epoch_sync_data_hash')}}"
        tests:
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - STRING
                - VARCHAR
                - NULL

      - name: EVENTS
        description: "{{ doc('events')}}"

      - name: GAS_PRICE
        description: "{{ doc('gas_price')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - NUMBER
                - FLOAT

      - name: LAST_DS_FINAL_BLOCK
        description: "{{ doc('last_ds_final_block')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - STRING
                - VARCHAR

      - name: LAST_FINAL_BLOCK
        description: "{{ doc('last_final_block')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - STRING
                - VARCHAR

      - name: LATEST_PROTOCOL_VERSION
        description: "{{ doc('latest_protocol_version')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - NUMBER
                - FLOAT

      - name: NEXT_BP_HASH
        description: "{{ doc('next_bp_hash')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - STRING
                - VARCHAR

      - name: NEXT_EPOCH_ID
        description: "{{ doc('next_epoch_id')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - STRING
                - VARCHAR

      - name: OUTCOME_ROOT
        description: "{{ doc('outcome_root')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - STRING
                - VARCHAR

      - name: PREV_HASH
        description: "{{ doc('prev_hash')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - STRING
                - VARCHAR

      - name: PREV_HEIGHT
        description: "{{ doc('prev_height')}}"
        tests:
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - NUMBER
                - FLOAT

      - name: PREV_STATE_ROOT
        description: "{{ doc('prev_state_root')}}"
        tests:
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - STRING
                - VARCHAR

      - name: RANDOM_VALUE
        description: "{{ doc('random_value')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - STRING
                - VARCHAR

      - name: RENT_PAID
        description: "{{ doc('rent_paid')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - NUMBER
                - FLOAT

      - name: SIGNATURE
        description: "{{ doc('signature')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - STRING
                - VARCHAR

      - name: TOTAL_SUPPLY
        description: "{{ doc('total_supply')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - NUMBER
                - FLOAT

      - name: VALIDATOR_PROPOSALS
        description: "{{ doc('validator_proposals')}}"
        tests:
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - ARRAY
                - VARIANT
                - OBJECT

      - name: VALIDATOR_REWARD
        description: "{{ doc('validator_reward')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - NUMBER
                - FLOAT

      - name: FACT_BLOCKS_ID
        description: "{{doc('id')}}"
        tests:
          - unique:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'
          - not_null:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'

      - name: INSERTED_TIMESTAMP
        description: "{{doc('inserted_timestamp')}}"

      - name: MODIFIED_TIMESTAMP
        description: "{{doc('modified_timestamp')}}"

'''
'''--- models/gold/core/core__fact_developer_activity.sql ---
{{ config(
    materialized = 'view',
    tags = ['core', 'activity']
) }}

WITH github_data AS (

    SELECT
        *
    FROM
        {{ ref('silver__github_data') }}
)
SELECT
    repo_owner,
    repo_name,
    endpoint_name,
    DATA,
    provider,
    endpoint_github,
    _inserted_timestamp AS snapshot_timestamp,
    COALESCE(
        github_data_id,
        {{ dbt_utils.generate_surrogate_key(
            ['_res_id']
        ) }}
    ) AS fact_developer_activity_id,
    COALESCE(inserted_timestamp, _inserted_timestamp, '2000-01-01' :: TIMESTAMP_NTZ) AS inserted_timestamp,
    COALESCE(modified_timestamp, _inserted_timestamp, '2000-01-01' :: TIMESTAMP_NTZ) AS modified_timestamp
FROM
    github_data

'''
'''--- models/gold/core/core__fact_developer_activity.yml ---
version: 2

models:
  - name: core__fact_developer_activity
    description: Table for developer activity

    columns:
      - name: REPO_OWNER
        description: "Repo owner"

      - name: REPO_NAME
        description: "Repo name"
        tests:
          - not_null

      - name: ENDPOINT_NAME
        description: "Endpoint name for the data"

      - name: DATA
        description: "Data from the endpoint"

      - name: PROVIDER
        description: "Provider for the data"

      - name: ENDPOINT_GITHUB
        description: " Endpoint for data"

      - name: SNAPSHOT_TIMESTAMP
        description: "Timestamp when the data was inserted into the table"

      - name: FACT_DEVELOPER_ACTIVITY_ID
        description: "{{doc('id')}}"
        tests:
          - not_null
          - unique:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'

      - name: INSERTED_TIMESTAMP
        description: "{{doc('inserted_timestamp')}}"

      - name: MODIFIED_TIMESTAMP
        description: "{{doc('modified_timestamp')}}"

'''
'''--- models/gold/core/core__fact_logs.sql ---
{{ config(
    materialized = 'view',
    secure = false,
    tags = ['core']
) }}

WITH logs AS (

    SELECT
        *
    FROM
        {{ ref('silver__logs_s3') }}
)
SELECT
    block_id,
    block_timestamp,
    tx_hash,
    receipt_object_id,
    predecessor_id,
    receiver_id,
    signer_id,
    clean_log,
    gas_burnt,
    COALESCE(
        logs_id,
        {{ dbt_utils.generate_surrogate_key(
            ['log_id']
        ) }}
    ) AS fact_logs_id,
    COALESCE(inserted_timestamp, _inserted_timestamp, '2000-01-01' :: TIMESTAMP_NTZ) AS inserted_timestamp,
    COALESCE(modified_timestamp, _inserted_timestamp, '2000-01-01' :: TIMESTAMP_NTZ) AS modified_timestamp
FROM
    logs

'''
'''--- models/gold/core/core__fact_logs.yml ---
version: 2

models:
  - name: core__fact_logs
    description: |-
      This table extracts all logs from receipts and decodes the arguments for easy use.
    tests:
      - dbt_utils.recency:
          datepart: hours
          field: block_timestamp
          interval: 2

    columns:
      - name: TX_HASH
        description: "{{ doc('tx_hash')}}"
        tests:
          - not_null:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'

      - name: RECEIPT_OBJECT_ID
        description: "{{ doc('receipt_object_id')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - STRING
                - VARCHAR

      - name: BLOCK_ID
        description: "{{ doc('block_id')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - NUMBER
                - FLOAT

      - name: BLOCK_TIMESTAMP
        description: "{{ doc('block_timestamp')}}"
        tests:
          - not_null:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'

      - name: RECEIVER_ID
        description: "{{ doc('receiver_id')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - STRING
                - VARCHAR

      - name: PREDECESSOR_ID
        description: "{{ doc('predecessor_id')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - STRING
                - VARCHAR

      - name: GAS_BURNT
        description: "{{ doc('gas_burnt')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - NUMBER
                - FLOAT

      - name: SIGNER_ID
        description: "{{ doc('signer_id')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - STRING
                - VARCHAR

      - name: CLEAN_LOG
        description: "{{ doc('clean_log')}}"
        tests:
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - STRING
                - VARCHAR
                - OBJECT
                - ARRAY

      - name: FACT_LOGS_ID
        description: "{{doc('id')}}"
        tests:
          - unique:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'
          - not_null:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'

      - name: INSERTED_TIMESTAMP
        description: "{{doc('inserted_timestamp')}}"

      - name: MODIFIED_TIMESTAMP
        description: "{{doc('modified_timestamp')}}"

'''
'''--- models/gold/core/core__fact_receipts.sql ---
{{ config(
    materialized = 'view',
    secure = false,
    tags = ['core']
) }}

WITH receipts AS (

    SELECT
        *
    FROM
        {{ ref('silver__streamline_receipts_final') }}
)
SELECT
    block_timestamp,
    block_id,
    tx_hash,
    receipt_object_id,
    receipt_outcome_id,
    receiver_id,
    receipt_actions AS actions,
    execution_outcome AS outcome,
    gas_burnt,
    status_value,
    logs,
    proof,
    metadata,
    COALESCE(
        streamline_receipts_final_id,
        {{ dbt_utils.generate_surrogate_key(
            ['receipt_object_id']
        ) }}
    ) AS fact_receipts_id,
    COALESCE(inserted_timestamp, _inserted_timestamp, '2000-01-01' :: TIMESTAMP_NTZ) AS inserted_timestamp,
    COALESCE(modified_timestamp, _inserted_timestamp, '2000-01-01' :: TIMESTAMP_NTZ) AS modified_timestamp
FROM
    receipts

'''
'''--- models/gold/core/core__fact_receipts.yml ---
version: 2

models:
  - name: core__fact_receipts
    description: Decoded and flattened transaction receipts from the block shards.
    tests:
      - dbt_utils.recency:
          datepart: hours
          field: block_timestamp
          interval: 2

    columns:
      - name: BLOCK_TIMESTAMP
        description: "{{ doc('block_timestamp')}}"
        tests:
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - TIMESTAMP_NTZ
          - not_null:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'

      - name: BLOCK_ID
        description: "{{ doc('block_id')}}"
        tests:
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - NUMBER
                - FLOAT

      - name: TX_HASH
        description: "{{ doc('tx_hash')}}"
        tests:
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - STRING
                - VARCHAR
          - not_null:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'

      - name: RECEIPT_OBJECT_ID
        description: "{{ doc('receipt_object_id')}}"
        tests:
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - STRING
                - VARCHAR

      - name: RECEIPT_OUTCOME_ID
        description: "{{ doc('receipt_outcome_id')}}"
        tests:
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - ARRAY
                - VARIANT

      - name: RECEIVER_ID
        description: "{{ doc('receiver_id')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - STRING
                - VARCHAR

      - name: ACTIONS
        description: "{{ doc('actions')}}"
        tests:
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - OBJECT
                - VARIANT

      - name: OUTCOME
        description: "{{ doc('outcome')}}"
        tests:
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - OBJECT
                - VARIANT

      - name: GAS_BURNT
        description: "{{ doc('gas_burnt')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - NUMBER
                - DOUBLE
                - FLOAT

      - name: STATUS_VALUE
        description: "{{ doc('status_value')}}"
        tests:
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - VARIANT
                - OBJECT

      - name: LOGS
        description: "{{ doc('logs')}}"
        tests:
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - ARRAY
                - VARIANT
                - OBJECT

      - name: PROOF
        description: "{{ doc('proof')}}"
        tests:
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - ARRAY
                - VARIANT
                - OBJECT

      - name: METADATA
        description: "{{ doc('metadata')}}"
        tests:
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - VARIANT
                - OBJECT

      - name: FACT_RECEIPTS_ID
        description: "{{doc('id')}}"
        tests:
          - unique:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'
          - not_null:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'

      - name: INSERTED_TIMESTAMP
        description: "{{doc('inserted_timestamp')}}"

      - name: MODIFIED_TIMESTAMP
        description: "{{doc('modified_timestamp')}}"

'''
'''--- models/gold/core/core__fact_transactions.sql ---
{{ config(
    materialized = 'view',
    secure = false,
    tags = ['core']
) }}

WITH transactions AS (

    SELECT
        *
    FROM
        {{ ref('silver__streamline_transactions_final') }}
)
SELECT
    tx_hash,
    block_id,
    block_hash,
    block_timestamp,
    nonce,
    signature,
    tx_receiver,
    tx_signer,
    tx,
    gas_used,
    transaction_fee,
    attached_gas,
    tx_succeeded,
    COALESCE(
        streamline_transactions_final_id,
        {{ dbt_utils.generate_surrogate_key(
            ['tx_hash']
        ) }}
    ) AS fact_transactions_id,
    COALESCE(inserted_timestamp, _inserted_timestamp, '2000-01-01' :: TIMESTAMP_NTZ) AS inserted_timestamp,
    COALESCE(modified_timestamp, _inserted_timestamp, '2000-01-01' :: TIMESTAMP_NTZ) AS modified_timestamp
FROM
    transactions

'''
'''--- models/gold/core/core__fact_transactions.yml ---
version: 2

models:
  - name: core__fact_transactions
    description: |-
      Transactions on the NEAR blockchain.

    tests:
      - dbt_utils.recency:
          datepart: hours
          field: block_timestamp
          interval: 2

    columns:
      - name: BLOCK_ID
        description: "{{ doc('block_id')}}"
        tests:
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - NUMBER
                - FLOAT

      - name: BLOCK_HASH
        description: "{{ doc('block_hash')}}"
        tests:
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - STRING
                - VARCHAR

      - name: TX_HASH
        description: "{{ doc('tx_hash')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - STRING
                - VARCHAR

      - name: BLOCK_TIMESTAMP
        description: "{{ doc('block_timestamp')}}"
        tests:
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - TIMESTAMP_NTZ
          - not_null:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'

      - name: NONCE
        description: "{{ doc('nonce')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - NUMBER

      - name: SIGNATURE
        description: "{{ doc('signature')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - STRING
                - VARCHAR

      - name: TX_RECEIVER
        description: "{{ doc('tx_receiver')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - STRING
                - VARCHAR

      - name: TX_SIGNER
        description: "{{ doc('tx_signer')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - STRING
                - VARCHAR

      - name: TX
        description: "{{ doc('tx')}}"
        tests:
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - OBJECT
                - VARIANT

      - name: GAS_USED
        description: "{{ doc('gas_used')}}"
        tests:
          - not_null:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - NUMBER
                - FLOAT

      - name: ATTACHED_GAS
        description: "{{ doc('attached_gas')}}"
        tests:
          - not_null:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - NUMBER
                - FLOAT

      - name: TRANSACTION_FEE
        description: "{{ doc('transaction_fee')}}"
        tests:
          - not_null:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - NUMBER
                - FLOAT

      - name: TX_SUCCEEDED
        description: "{{ doc('tx_succeeded')}}"
        tests:
          - not_null:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - BOOLEAN

      - name: FACT_TRANSACTIONS_ID
        description: "{{doc('id')}}"
        tests:
          - unique:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'
          - not_null:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'

      - name: INSERTED_TIMESTAMP
        description: "{{doc('inserted_timestamp')}}"
        
      - name: MODIFIED_TIMESTAMP
        description: "{{doc('modified_timestamp')}}"

'''
'''--- models/gold/core/core__fact_transfers.sql ---
{{ config(
    materialized = 'view',
    secure = false,
    tags = ['core']
) }}

WITH transfers AS (

    SELECT
        *
    FROM
        {{ ref('silver__transfers_s3') }}
)
SELECT
    block_id,
    block_timestamp,
    action_id,
    deposit,
    tx_hash,
    tx_signer,
    tx_receiver,
    predecessor_id,
    signer_id,
    receiver_id,
    transaction_fee,
    gas_used,
    tx_succeeded,
    receipt_succeeded,
    status,
    COALESCE(
        transfers_id,
        {{ dbt_utils.generate_surrogate_key(
            ['action_id']
        ) }}
    ) AS fact_transfers_id,
    inserted_timestamp,
    modified_timestamp
FROM
    transfers

'''
'''--- models/gold/core/core__fact_transfers.yml ---
version: 2

models:
  - name: core__fact_transfers
    description: |-
      Deprecating soon! Please migrate to the ez_token_transfers model which includes both native near transfers and FT (nep141) transfers. This model will be deprecated by the end of May 2024.
    tests:
      - dbt_utils.recency:
          datepart: hours
          field: block_timestamp
          interval: 2

    columns:
      - name: TX_HASH
        description: "{{ doc('tx_hash')}}"
        tests:
          - not_null:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - STRING
                - VARCHAR

      - name: ACTION_ID
        description: "{{ doc('action_id')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - STRING
                - VARCHAR

      - name: BLOCK_ID
        description: "{{ doc('block_id')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - NUMBER
                - FLOAT

      - name: BLOCK_TIMESTAMP
        description: "{{ doc('block_timestamp')}}"
        tests:
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - TIMESTAMP_NTZ

      - name: TX_SIGNER
        description: "{{ doc('tx_signer')}}"
        tests:
          - not_null:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - STRING
                - VARCHAR

      - name: TX_RECEIVER
        description: "{{ doc('tx_receiver')}}"
        tests:
          - not_null:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - STRING
                - VARCHAR

      - name: DEPOSIT
        description: "{{ doc('deposit')}}"
        tests:
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - NUMBER
                - FLOAT

      - name: SIGNER_ID
        description: "{{ doc('signer_id')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - STRING
                - VARCHAR

      - name: RECEIVER_ID
        description: "{{ doc('receiver_id')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - STRING
                - VARCHAR

      - name: TRANSACTION_FEE
        description: "{{ doc('transaction_fee')}}"
        tests:
          - not_null:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - NUMBER
                - FLOAT

      - name: GAS_USED
        description: "{{ doc('gas_used')}}"
        tests:
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - NUMBER
                - FLOAT

      - name: TX_SUCCEEDED
        description: "{{ doc('tx_succeeded')}}"
        tests:
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - BOOLEAN

      - name: RECEIPT_SUCCEEDED
        description: "{{ doc('receipt_succeeded')}}"
        tests:
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - BOOLEAN

      - name: STATUS
        description: "{{ doc('status')}}"
        tests:
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - BOOLEAN

      - name: FACT_TRANSFERS_ID
        description: "{{doc('id')}}"
        tests:
          - unique:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'
          - not_null:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'

      - name: INSERTED_TIMESTAMP
        description: "{{doc('inserted_timestamp')}}"

      - name: MODIFIED_TIMESTAMP
        description: "{{doc('modified_timestamp')}}"

'''
'''--- models/gold/defi/defi__ez_bridge_activity.sql ---
{{ config(
    materialized = 'view',
    secure = false,
    meta ={ 'database_tags':{ 'table':{ 'PURPOSE': 'DEFI, BRIDGING' }} },
    tags = ['core']
) }}

WITH fact_bridging AS (

    SELECT
        block_id,
        block_timestamp,
        tx_hash,
        token_address,
        amount_unadj,
        destination_address,
        source_address,
        platform,
        bridge_address,
        destination_chain,
        source_chain,
        method_name,
        direction,
        receipt_succeeded,
        fact_bridge_activity_id AS ez_bridge_activity_id,
        inserted_timestamp,
        modified_timestamp
    FROM
        {{ ref('defi__fact_bridge_activity') }}
),
labels AS (
    SELECT
        contract_address,
        NAME,
        symbol,
        decimals
    FROM
        {{ ref('silver__ft_contract_metadata') }}
),
prices AS (
    SELECT
        DATE_TRUNC(
            'hour',
            hour
        ) AS block_timestamp,
        token_address AS contract_address,
        AVG(price) AS price_usd
    FROM
        {{ ref('silver__complete_token_prices') }}
    GROUP BY
        1,
        2
),
FINAL AS (
    SELECT
        b.block_id,
        b.block_timestamp,
        b.tx_hash,
        b.token_address,
        b.amount_unadj,
        l1.symbol,
        b.amount_unadj / pow(
            10,
            l1.decimals
        ) AS amount,
        amount * p1.price_usd AS amount_usd,
        b.destination_address,
        b.source_address,
        b.platform,
        b.bridge_address,
        b.destination_chain,
        b.source_chain,
        b.method_name,
        b.direction,
        b.receipt_succeeded,
        b.ez_bridge_activity_id,
        b.inserted_timestamp,
        b.modified_timestamp
    FROM
        fact_bridging b
        LEFT JOIN labels l1
        ON b.token_address = l1.contract_address
        LEFT JOIN prices p1
        ON b.token_address = p1.contract_address
        AND DATE_TRUNC(
            'hour',
            b.block_timestamp
        ) = p1.block_timestamp
)
SELECT
    *
FROM
    FINAL

'''
'''--- models/gold/defi/defi__ez_bridge_activity.yml ---
version: 2

models:
  - name: defi__ez_bridge_activity
    description: >
      Modeled bridge activity, tracking tokens through the NEAR Ecosystem.
      Token labels and USD Price appended to record, where available.
    tests:
      - dbt_utils.recency:
          datepart: day
          field: block_timestamp
          interval: 1

    columns:
      - name: BLOCK_ID
        description: "{{ doc('block_id')}}"
        tests:
          - not_null

      - name: BLOCK_TIMESTAMP
        description: "{{ doc('block_timestamp')}}"
        tests:
          - not_null:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'

      - name: TX_HASH
        description: "{{ doc('tx_hash')}}"
        tests:
          - not_null:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'

      - name: TOKEN_ADDRESS
        description: "{{ doc('token_contract')}}"
        tests:
          - not_null:
              where: receipt_succeeded

      - name: AMOUNT_UNADJ
        description: "{{ doc('amount_raw')}}"
        tests:
          - not_null:
              where: receipt_succeeded

      - name: SYMBOL
        description: "{{ doc('symbol')}}"

      - name: AMOUNT
        description: "{{ doc('amount')}}"

      - name: AMOUNT_USD
        description: "{{ doc('amount_usd')}}"
 
      - name: DESTINATION_ADDRESS
        description: "{{ doc('destination_address')}}"

      - name: SOURCE_ADDRESS
        description: "{{ doc('source_address')}}"

      - name: PLATFORM
        description: "{{ doc('platform')}}"
        tests:
          - not_null

      - name: BRIDGE_ADDRESS
        description: "{{ doc('contract_address')}}"
        tests:
          - not_null

      - name: DESTINATION_CHAIN
        description: "{{ doc('destination_chain')}}"
        tests:
          - not_null:
              where: receipt_succeeded and platform != 'multichain'

      - name: SOURCE_CHAIN
        description: "{{ doc('source_chain')}}"
        tests:
          - not_null:
              where: receipt_succeeded and platform != 'multichain'

      - name: METHOD_NAME
        description: "{{ doc('method_name')}}"
        tests:
          - not_null

      - name: DIRECTION
        description: "{{ doc('direction')}}"
        tests:
          - not_null

      - name: RECEIPT_SUCCEEDED
        description: "{{ doc('receipt_succeeded')}}"
        tests:
          - not_null

      - name: EZ_BRIDGE_ACTIVITY_ID
        description: "{{ doc('id')}}"
        tests:
          - unique:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'
          - not_null:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'

      - name: INSERTED_TIMESTAMP
        description: "{{ doc('inserted_timestamp')}}"

      - name: MODIFIED_TIMESTAMP
        description: "{{ doc('modified_timestamp')}}"

'''
'''--- models/gold/defi/defi__ez_dex_swaps.sql ---
{{ config(
    materialized = 'view',
    secure = false,
    meta ={ 'database_tags':{ 'table':{ 'PURPOSE': 'DEFI, SWAPS' }} },
    tags = ['core']
) }}

WITH dex_swaps AS (

    SELECT
        tx_hash,
        receipt_object_id,
        block_id,
        block_timestamp,
        receiver_id,
        signer_id,
        swap_index,
        amount_out_raw,
        token_out,
        amount_in_raw,
        token_in,
        swap_input_data,
        LOG,
        dex_swaps_v2_id AS ez_dex_swaps_id,
        inserted_timestamp,
        modified_timestamp
    FROM
        {{ ref('silver__dex_swaps_v2') }}
),
labels AS (
    SELECT
        contract_address,
        NAME,
        symbol,
        decimals
    FROM
        {{ ref('silver__ft_contract_metadata') }}
),
prices AS (
    SELECT
        DATE_TRUNC(
            'hour',
            hour
        ) AS block_timestamp,
        token_address AS contract_address,
        AVG(price) AS price_usd
    FROM
        {{ ref('silver__complete_token_prices') }}
    GROUP BY
        1,
        2
),
FINAL AS (
    SELECT
        s.tx_hash,
        s.receipt_object_id,
        s.block_id,
        s.block_timestamp,
        s.receiver_id AS platform,
        s.swap_input_data :pool_id :: INT AS pool_id,
        s.signer_id AS trader,
        s.swap_index,
        s.amount_out_raw,
        s.amount_out_raw / pow(
            10,
            l1.decimals
        ) AS amount_out,
        amount_out * p1.price_usd AS amount_out_usd,
        s.token_out AS token_out_contract,
        l1.symbol AS symbol_out,
        s.amount_in_raw,
        s.amount_in_raw / pow(
            10,
            l2.decimals
        ) AS amount_in,
        amount_in * p2.price_usd AS amount_in_usd,
        s.token_in AS token_in_contract,
        l2.symbol AS symbol_in,
        s.swap_input_data,
        s.log,
        s.ez_dex_swaps_id,
        s.inserted_timestamp,
        s.modified_timestamp
    FROM
        dex_swaps s
        LEFT JOIN labels l1
        ON s.token_out = l1.contract_address
        LEFT JOIN labels l2
        ON s.token_in = l2.contract_address
        LEFT JOIN prices p1
        ON DATE_TRUNC(
            'hour',
            s.block_timestamp
        ) = p1.block_timestamp
        AND s.token_out = p1.contract_address
        LEFT JOIN prices p2
        ON DATE_TRUNC(
            'hour',
            s.block_timestamp
        ) = p2.block_timestamp
        AND s.token_in = p2.contract_address
)
SELECT
    *
FROM
    FINAL

'''
'''--- models/gold/defi/defi__ez_dex_swaps.yml ---
version: 2

models:
  - name: defi__ez_dex_swaps
    description: >
      DEX Swaps on the NEAR blockchain, with label and price data joined in for ease of use (where available).
      Note - view updated February 2024 to use the same v2 Swaps model as fact_dex_swaps.
      TOKEN_IN and TOKEN_OUT are now SYMBOL_IN/OUT.
      POOL ID is found in the SWAP_INPUT_DATA, where available.

    columns:
      - name: TX_HASH
        description: "{{ doc('tx_hash')}}"

      - name: BLOCK_ID
        description: "{{ doc('block_id')}}"

      - name: BLOCK_TIMESTAMP
        description: "{{ doc('block_timestamp')}}"

      - name: PLATFORM
        description: "{{ doc('platform')}}"

      - name: POOL_ID
        description: "{{ doc('pool_id')}}"

      - name: TRADER
        description: "{{ doc('trader')}}"

      - name: SWAP_INDEX
        description: "{{ doc('swap_index')}}"

      - name: AMOUNT_OUT_RAW
        description: "{{ doc('amount_raw')}}"
      
      - name: AMOUNT_OUT
        description: "{{ doc('amount_out')}}"

      - name: AMOUNT_OUT_USD
        description: "{{ doc('amount_usd')}}"
 
      - name: TOKEN_OUT_CONTRACT
        description: "{{ doc('contract_address')}}"

      - name: SYMBOL_OUT
        description: "{{ doc('symbol')}}"

      - name: AMOUNT_IN_RAW
        description: "{{ doc('amount_raw')}}"
      
      - name: AMOUNT_IN
        description: "{{ doc('amount_in')}}"

      - name: AMOUNT_IN_USD
        description: "{{ doc('amount_usd')}}"
 
      - name: TOKEN_IN_CONTRACT
        description: "{{ doc('contract_address')}}"

      - name: SYMBOL_IN
        description: "{{ doc('symbol')}}"

      - name: SWAP_INPUT_DATA
        description: "{{ doc('swap_input_data') }}"

      - name: LOG
        description: "{{doc('log')}}"

      - name: EZ_DEX_SWAPS_ID
        description: "{{doc('id')}}"

      - name: INSERTED_TIMESTAMP
        description: "{{doc('inserted_timestamp')}}"

      - name: MODIFIED_TIMESTAMP
        description: "{{doc('modified_timestamp')}}"

'''
'''--- models/gold/defi/defi__ez_lending.sql ---
{{ config(
    materialized = 'view',
    secure = false,
    meta ={ 'database_tags':{ 'table':{ 'PURPOSE': 'DEFI, LENDING' }} },
    tags = ['core']
) }}

WITH lending AS (

    SELECT
        platform,
        tx_hash,
        block_id,
        block_timestamp,
        sender_id,
        actions,
        contract_address,
        amount_raw,
        burrow_lending_id AS ez_lending_id,
        token_address,
        inserted_timestamp,
        modified_timestamp
    FROM
        {{ ref('silver__burrow_lending') }}
),
labels AS (
    SELECT
        contract_address,
        NAME,
        symbol,
        decimals
    FROM
        {{ ref('silver__ft_contract_metadata') }}
),
prices AS (
    SELECT
        DATE_TRUNC(
            'hour',
            hour
        ) AS block_timestamp,
        token_address AS contract_address,
        AVG(price) AS price_usd
    FROM
        {{ ref('silver__complete_token_prices') }}
    GROUP BY
        1,
        2
),
FINAL AS (
    SELECT
        l.platform,
        l.tx_hash,
        l.block_id,
        l.block_timestamp,
        l.sender_id,
        l.actions,
        l.contract_address,
        l.token_address,
        lb.name,
        lb.symbol,
        l.amount_raw,
        l.amount_raw / pow(
            10,
            lb.decimals
        ) AS amount,
        amount * p.price_usd AS amount_usd,
        l.ez_lending_id,
        l.inserted_timestamp,
        l.modified_timestamp
    FROM
        lending l
        LEFT JOIN labels lb
        ON l.token_address = lb.contract_address
        LEFT JOIN prices p
        ON DATE_TRUNC(
            'hour',
            l.block_timestamp
        ) = p.block_timestamp
        AND l.token_address = p.contract_address
)
SELECT
    *
FROM
    FINAL

'''
'''--- models/gold/defi/defi__ez_lending.yml ---
version: 2
models:
  - name: defi__ez_lending
    description: |-
      Modeled activity for lending, with token contract and price info joined in for ease of use.
    tests:
      - dbt_utils.recency:
          datepart: hours
          field: block_timestamp
          interval: 24

    columns:
      - name: platform
        description: "Lending protocol"
        tests:
          - not_null

      - name: TX_HASH
        description: "{{ doc('tx_hash')}}"
        tests:
          - not_null

      - name: block_id
        description: "{{ doc('block_id')}}"
        tests:
          - not_null

      - name: BLOCK_TIMESTAMP
        description: "{{ doc('block_timestamp')}}"
        tests:
          - not_null:
              where: inserted_timestamp <= current_timestamp - interval '1 hour'

      - name: SENDER_ID
        description: "{{ doc('sender_id')}}"
        tests:
          - not_null

      - name: ACTIONS
        description: "{{ doc('action')}}"
        tests:
          - not_null

      - name: CONTRACT_ADDRESS
        description: "{{ doc('contract_address')}}"
        tests:
          - not_null

      - name: TOKEN_ADDRESS
        description: "{{ doc('token_contract')}}"
        tests:
          - not_null

      - name: NAME
        description: "{{ doc('name')}}"

      - name: SYMBOL
        description: "{{ doc('symbol')}}"

      - name: AMOUNT_RAW
        description: "{{ doc('amount_raw')}}"
        tests:
          - not_null

      - name: AMOUNT
        description: "{{ doc('amount')}}"

      - name: AMOUNT_USD
        description: "{{ doc('amount_usd')}}"

      - name: EZ_LENDING_ID
        description: "{{ doc('id')}}"
        tests:
          - not_null

'''
'''--- models/gold/defi/defi__fact_bridge_activity.sql ---
{{ config(
    materialized = 'view',
    secure = false,
    meta ={ 'database_tags':{ 'table':{ 'PURPOSE': 'DEFI, BRIDGING' }} },
    tags = ['core']
) }}

WITH 
rainbow AS (

    SELECT
        block_id,
        block_timestamp,
        tx_hash,
        token_address,
        amount_raw,
        destination_address,
        source_address,
        platform,
        bridge_address,
        destination_chain_id AS destination_chain,
        source_chain_id AS source_chain,
        method_name,
        direction,
        receipt_succeeded,
        bridge_rainbow_id AS fact_bridge_activity_id,
        inserted_timestamp,
        modified_timestamp
    FROM
        {{ ref('silver__bridge_rainbow') }}
),
wormhole AS (
    SELECT
        block_id,
        block_timestamp,
        tx_hash,
        token_address,
        amount_raw,
        destination_address,
        source_address,
        platform,
        bridge_address,
        id.blockchain AS destination_chain,
        id2.blockchain AS source_chain,
        method_name,
        direction,
        receipt_succeeded,
        bridge_wormhole_id AS fact_bridge_activity_id,
        inserted_timestamp,
        modified_timestamp
    FROM
        {{ ref('silver__bridge_wormhole') }} b
    LEFT JOIN {{ ref('seeds__wormhole_ids') }} id ON b.destination_chain_id = id.id
    LEFT JOIN {{ ref('seeds__wormhole_ids') }} id2 ON b.source_chain_id = id2.id
),
multichain AS (
    SELECT
        block_id,
        block_timestamp,
        tx_hash,
        token_address,
        amount_raw,
        destination_address,
        source_address,
        platform,
        bridge_address,
        id.blockchain AS destination_chain,
        id2.blockchain AS source_chain,
        method_name,
        direction,
        receipt_succeeded,
        bridge_multichain_id AS fact_bridge_activity_id,
        inserted_timestamp,
        modified_timestamp
    FROM
        {{ ref('silver__bridge_multichain') }} b
    LEFT JOIN {{ ref('seeds__multichain_ids') }} id ON b.destination_chain_id = id.id
    LEFT JOIN {{ ref('seeds__multichain_ids') }} id2 ON b.source_chain_id = id2.id
),
allbridge AS (
    SELECT
        block_id,
        block_timestamp,
        tx_hash,
        token_address,
        amount_raw,
        destination_address,
        source_address,
        platform,
        bridge_address,
        id.blockchain AS destination_chain,
        id2.blockchain AS source_chain,
        method_name,
        direction,
        receipt_succeeded,
        bridge_allbridge_id AS fact_bridge_activity_id,
        inserted_timestamp,
        modified_timestamp
    FROM
        {{ ref('silver__bridge_allbridge') }} b
    LEFT JOIN {{ ref('seeds__allbridge_ids') }} id ON b.destination_chain_id = id.id
    LEFT JOIN {{ ref('seeds__allbridge_ids') }} id2 ON b.source_chain_id = id2.id
),
FINAL AS (
    SELECT
        *
    FROM
        rainbow
    UNION ALL
    SELECT
        *
    FROM
        wormhole
    UNION ALL
    SELECT
        *
    FROM
        multichain
    UNION ALL
    SELECT
        *
    FROM
        allbridge
)
SELECT
        block_id,
        block_timestamp,
        tx_hash,
        token_address,
        amount_raw AS amount_unadj,
        destination_address,
        source_address,
        platform,
        bridge_address,
        LOWER(destination_chain) AS destination_chain,
        LOWER(source_chain) AS source_chain,
        method_name,
        direction,
        receipt_succeeded,
        fact_bridge_activity_id,
        inserted_timestamp,
        modified_timestamp
FROM
    FINAL

'''
'''--- models/gold/defi/defi__fact_bridge_activity.yml ---
version: 2

models:
  - name: defi__fact_bridge_activity
    description: |-
      Modeled bridge activity, tracking tokens through the NEAR Ecosystem.
    tests:
      - dbt_utils.recency:
          datepart: day
          field: block_timestamp
          interval: 1

    columns:
      - name: BLOCK_ID
        description: "{{ doc('block_id')}}"
        tests:
          - not_null

      - name: BLOCK_TIMESTAMP
        description: "{{ doc('block_timestamp')}}"
        tests:
          - not_null:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'

      - name: TX_HASH
        description: "{{ doc('tx_hash')}}"
        tests:
          - not_null:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'

      - name: TOKEN_ADDRESS
        description: "{{ doc('token_contract')}}"
        tests:
          - not_null:
              where: receipt_succeeded

      - name: AMOUNT_UNADJ
        description: "{{ doc('amount_raw')}}"
        tests:
          - not_null:
              where: receipt_succeeded

      - name: DESTINATION_ADDRESS
        description: "{{ doc('destination_address')}}"

      - name: SOURCE_ADDRESS
        description: "{{ doc('source_address')}}"

      - name: PLATFORM
        description: "{{ doc('platform')}}"
        tests:
          - not_null

      - name: BRIDGE_ADDRESS
        description: "{{ doc('contract_address')}}"
        tests:
          - not_null

      - name: DESTINATION_CHAIN
        description: "{{ doc('destination_chain')}}"
        tests:
          - not_null:
              where: receipt_succeeded and platform != 'multichain'

      - name: SOURCE_CHAIN
        description: "{{ doc('source_chain')}}"
        tests:
          - not_null:
              where: receipt_succeeded and platform != 'multichain'

      - name: METHOD_NAME
        description: "{{ doc('method_name')}}"
        tests:
          - not_null

      - name: DIRECTION
        description: "{{ doc('direction')}}"
        tests:
          - not_null

      - name: RECEIPT_SUCCEEDED
        description: "{{ doc('receipt_succeeded')}}"
        tests:
          - not_null

      - name: FACT_BRIDGE_ACTIVITY_ID
        description: "{{ doc('id')}}"
        tests:
          - unique:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'
          - not_null:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'

      - name: INSERTED_TIMESTAMP
        description: "{{ doc('inserted_timestamp')}}"

      - name: MODIFIED_TIMESTAMP
        description: "{{ doc('modified_timestamp')}}"

'''
'''--- models/gold/defi/defi__fact_dex_swaps.sql ---
{{ config(
    materialized = 'view',
    secure = false,
    meta ={ 'database_tags':{ 'table':{ 'PURPOSE': 'DEFI, SWAPS' }} },
    tags = ['core']
) }}

SELECT
    tx_hash,
    receipt_object_id,
    block_id,
    block_timestamp,
    receiver_id,
    signer_id,
    swap_index,
    amount_out_raw,
    token_out,
    amount_in_raw,
    token_in,
    swap_input_data,
    LOG,
    dex_swaps_v2_id AS fact_dex_swaps_id,
    inserted_timestamp,
    modified_timestamp
FROM
    {{ ref('silver__dex_swaps_v2') }}

'''
'''--- models/gold/defi/defi__fact_dex_swaps.yml ---
version: 2

models:
  - name: defi__fact_dex_swaps
    description: |-
      Parses log output data for swap information. It was determined logs must be used over inputs in a FunctionCall as only the output contains actual swap information. See tx AfvgkUxP8taJNBLaZYvFumFrrePpJujb2gjQJz7YbRiM as an example.
    tests:
      - dbt_utils.recency:
          datepart: hours
          field: block_timestamp
          interval: 12

    columns:
      - name: TX_HASH
        description: "{{ doc('tx_hash')}}"
        tests:
          - not_null:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'

      - name: RECEIPT_OBJECT_ID
        description: "{{ doc('receipt_object_id')}}"
        tests:
          - not_null

      - name: BLOCK_ID
        description: "{{ doc('block_id')}}"
        tests:
          - not_null

      - name: BLOCK_TIMESTAMP
        description: "{{ doc('block_timestamp')}}"
        tests:
          - not_null:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'

      - name: RECEIVER_ID
        description: "{{ doc('receiver_id')}}"
        tests:
          - not_null

      - name: SIGNER_ID
        description: "{{ doc('signer_id')}}"
        tests:
          - not_null

      - name: SWAP_INDEX
        description: "{{ doc('index')}}"
        tests:
          - not_null

      - name: AMOUNT_OUT_RAW
        description: "{{ doc('amount_out_raw')}}"
        tests:
          - not_null

      - name: TOKEN_OUT
        description: "{{ doc('token_out')}}"
        tests:
          - not_null

      - name: AMOUNT_IN_RAW
        description: "{{ doc('amount_in_raw')}}"
        tests:
          - not_null

      - name: TOKEN_IN
        description: "{{ doc('token_in')}}"
        tests:
          - not_null
          
      - name: SWAP_INPUT_DATA
        description: "{{ doc('swap_input_data')}}"

      - name: LOG
        description: "{{ doc('clean_log')}}"

      - name: FACT_DEX_SWAPS_ID
        description: "{{doc('id')}}"
        tests:
          - unique:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'
          - not_null:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'

      - name: INSERTED_TIMESTAMP
        description: "{{doc('inserted_timestamp')}}"

      - name: MODIFIED_TIMESTAMP
        description: "{{doc('modified_timestamp')}}"

'''
'''--- models/gold/defi/defi__fact_lending.sql ---
{{ config(
    materialized = 'view',
    secure = false,
    meta ={ 'database_tags':{ 'table':{ 'PURPOSE': 'DEFI, LENDING' }} },
    tags = ['core']
) }}

WITH burrow AS (
    SELECT
        *
    FROM
        {{ ref('silver__burrow_lending') }}
),
FINAL AS (
    SELECT
        platform,
        tx_hash,
        block_id,
        block_timestamp,
        sender_id,
        actions,
        contract_address,
        token_address,
        amount_raw,
        burrow_lending_id AS fact_lending_id,
        inserted_timestamp,
        modified_timestamp
    FROM
        burrow
)
SELECT
    *
FROM
    FINAL
'''
'''--- models/gold/defi/defi__fact_lending.yml ---
version: 2
models:
  - name: defi__fact_lending
    description: |-
      Modeled activity for lending
    tests:
      - dbt_utils.recency:
          datepart: hours
          field: block_timestamp
          interval: 24

    columns:
      - name: platform
        description: "Lending protocol"
        tests:
          - not_null

      - name: TX_HASH
        description: "{{ doc('tx_hash')}}"
        tests:
          - not_null

      - name: block_id
        description: "{{ doc('block_id')}}"
        tests:
          - not_null

      - name: BLOCK_TIMESTAMP
        description: "{{ doc('block_timestamp')}}"
        tests:
          - not_null:
              where: inserted_timestamp <= current_timestamp - interval '1 hour'

      - name: SENDER_ID
        description: "{{ doc('sender_id')}}"
        tests:
          - not_null

      - name: ACTIONS
        description: "{{ doc('action')}}"
        tests:
          - not_null

      - name: CONTRACT_ADDRESS
        description: "{{ doc('contract_address')}}"
        tests:
          - not_null

      - name: AMOUNT_RAW
        description: "{{ doc('amount_raw')}}"
        tests:
          - not_null

      - name: TOKEN_ADDRESS
        description: "{{ doc('token_contract')}}"
        tests:
          - not_null

      - name: FACT_LENDING_ID
        description: "{{ doc('id')}}"
        tests:
          - not_null

'''
'''--- models/gold/governance/gov__dim_staking_pools.sql ---
{{ config(
    materialized = 'view',
    secure = false,
    tags = ['core', 'governance'],
    meta ={ 'database_tags':{ 'table':{ 'PURPOSE': 'STAKING, GOVERNANCE' }}}
) }}

WITH staking_pools AS (

    SELECT
        *
    FROM
        {{ ref('silver__staking_pools_s3') }}
)
SELECT
    tx_hash,
    block_timestamp,
    owner,
    address,
    reward_fee_fraction,
    tx_type,
    COALESCE(
        staking_pools_id,
        {{ dbt_utils.generate_surrogate_key(
            ['tx_hash']
        ) }}
    ) AS dim_staking_pools_id,
    COALESCE(inserted_timestamp, _inserted_timestamp, '2000-01-01' :: TIMESTAMP_NTZ) AS inserted_timestamp,
    COALESCE(modified_timestamp, _inserted_timestamp, '2000-01-01' :: TIMESTAMP_NTZ) AS modified_timestamp
FROM
    staking_pools

'''
'''--- models/gold/governance/gov__dim_staking_pools.yml ---
version: 2

models:
  - name: gov__dim_staking_pools
    description: |-
      This table contains registered staking pools with NEAR.
    tests:
      - dbt_utils.recency:
          datepart: day
          field: block_timestamp
          interval: 30

    columns:
      - name: TX_HASH
        description: "{{ doc('tx_hash') }}"
        tests:
          - not_null:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - STRING
                - VARCHAR

      - name: BLOCK_TIMESTAMP
        description: "{{ doc('block_timestamp')}}"
        tests:
          - not_null:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - TIMESTAMP_NTZ

      - name: OWNER
        description: "{{ doc('staking_pool_owner')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - STRING
                - VARCHAR

      - name: ADDRESS
        description: "{{ doc('staking_pool_address')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - STRING
                - VARCHAR

      - name: REWARD_FEE_FRACTION
        description: "{{ doc('staking_pool_reward_fee_fraction')}}"
        tests:
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - VARIANT
                - OBJECT

      - name: TX_TYPE
        description: "{{ doc('staking_pool_tx_type') }}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - STRING
                - VARCHAR
          - dbt_expectations.expect_column_values_to_be_in_set:
              value_set: ["Create", "Update"]

      - name: DIM_STAKING_POOLS_ID
        description: "{{doc('id')}}"
        tests:
          - unique:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'
          - not_null:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'

      - name: INSERTED_TIMESTAMP
        description: "{{doc('inserted_timestamp')}}"

      - name: MODIFIED_TIMESTAMP
        description: "{{doc('modified_timestamp')}}"

'''
'''--- models/gold/governance/gov__fact_lockup_actions.sql ---
{{ config(
    materialized = 'view',
    secure = false,
    tags = ['core', 'governance'],
    meta ={ 'database_tags':{ 'table':{ 'PURPOSE': 'STAKING, GOVERNANCE' }}}
) }}

WITH lockup_actions AS (

    SELECT
        tx_hash,
        block_timestamp,
        block_id,
        deposit,
        lockup_account_id,
        owner_account_id,
        lockup_duration,
        lockup_timestamp,
        lockup_timestamp_ntz,
        release_duration,
        vesting_schedule,
        transfers_information,
        COALESCE(
            lockup_actions_id,
            {{ dbt_utils.generate_surrogate_key(
                ['tx_hash']
            ) }}
        ) AS fact_lockup_actions_id,
        COALESCE(inserted_timestamp, _inserted_timestamp, '2000-01-01' :: TIMESTAMP_NTZ) AS inserted_timestamp,
        COALESCE(modified_timestamp, _inserted_timestamp, '2000-01-01' :: TIMESTAMP_NTZ) AS modified_timestamp
    FROM
        {{ ref('silver__lockup_actions') }}
)
SELECT
    *
FROM
    lockup_actions

'''
'''--- models/gold/governance/gov__fact_lockup_actions.yml ---
version: 2

models:
  - name: gov__fact_lockup_actions
    description: |-
      This table records all disbursements by the contract lockup.near.

    columns:
      - name: TX_HASH
        description: "{{ doc('tx_hash')}}"
        tests:
          - not_null:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'

      - name: BLOCK_TIMESTAMP
        description: "{{ doc('block_timestamp')}}"
        tests:
          - not_null:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'

      - name: BLOCK_ID
        description: "{{ doc('block_id')}}"
        tests:
          - not_null

      - name: DEPOSIT
        description: "{{ doc('deposit')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - DOUBLE
                - FLOAT
                - NUMBER

      - name: LOCKUP_ACCOUNT_ID
        description: "{{ doc('lockup_account_id')}}"
        tests:
          - not_null

      - name: OWNER_ACCOUNT_ID
        description: "{{ doc('owner_account_id')}}"
        tests:
          - not_null

      - name: LOCKUP_DURATION
        description: "{{ doc('lockup_duration')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - VARCHAR

      - name: LOCKUP_TIMESTAMP
        description: "{{ doc('lockup_timestamp')}}"
        tests:
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - VARCHAR

      - name: LOCKUP_TIMESTAMP_NTZ
        description: "{{ doc('lockup_timestamp_ntz')}}"
        tests:
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - TIMESTAMP_NTZ

      - name: RELEASE_DURATION
        description: "{{ doc('release_duration')}}"
        tests:
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - VARCHAR

      - name: VESTING_SCHEDULE
        description: "{{ doc('vesting_schedule')}}"

      - name: TRANSFERS_INFORMATION
        description: "{{ doc('transfers_information')}}"

      - name: FACT_LOCKUP_ACTIONS_ID
        description: "{{doc('id')}}"
        tests:
          - unique:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'
          - not_null:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'

      - name: INSERTED_TIMESTAMP
        description: "{{doc('inserted_timestamp')}}"

      - name: MODIFIED_TIMESTAMP
        description: "{{doc('modified_timestamp')}}"

'''
'''--- models/gold/governance/gov__fact_staking_actions.sql ---
{{ config(
    materialized = 'view',
    secure = false,
    tags = ['core', 'governance'],
    meta ={ 'database_tags':{ 'table':{ 'PURPOSE': 'STAKING, GOVERNANCE' }}}
) }}

WITH staking_actions AS (

    SELECT
        tx_hash,
        block_id,
        block_timestamp,
        receipt_object_id,
        receiver_id AS address,
        signer_id,
        action,
        amount_adj AS amount,
        COALESCE(
            staking_actions_v2_id,
            {{ dbt_utils.generate_surrogate_key(
                ['tx_hash']
            ) }}
        ) AS fact_staking_actions_id,
        COALESCE(inserted_timestamp, _inserted_timestamp, '2000-01-01' :: TIMESTAMP_NTZ) AS inserted_timestamp,
        COALESCE(modified_timestamp, _inserted_timestamp, '2000-01-01' :: TIMESTAMP_NTZ) AS modified_timestamp
    FROM
        {{ ref('silver__staking_actions_v2') }}
)
SELECT
    *
FROM
    staking_actions

'''
'''--- models/gold/governance/gov__fact_staking_actions.yml ---
version: 2

models:
  - name: gov__fact_staking_actions
    description: |-
      An updated version of the staking actions table which looks at all logs, instead of just the first receipt.
      There are four actions taken when staking: staking->deposit->unstaking->withdraw.
      Note - in this core view the amount is decimal adjusted by 10^24.
    tests:
      - dbt_utils.recency:
          datepart: day
          field: block_timestamp
          interval: 1

    columns:
      - name: TX_HASH
        description: "{{ doc('tx_hash') }}"
        tests:
          - not_null:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'

      - name: BLOCK_ID
        description: "{{ doc('block_id') }}"
        tests:
          - not_null

      - name: BLOCK_TIMESTAMP
        description: "{{ doc('block_timestamp') }}"
        tests:
          - not_null:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'

      - name: RECEIPT_OBJECT_ID
        description: "{{ doc('receipt_object_id') }}"
        tests:
          - not_null

      - name: ADDRESS
        description: "{{ doc('pool_address') }}"
        tests:
          - not_null

      - name: SIGNER_ID
        description: "{{ doc('signer_id') }}"
        tests:
          - not_null

      - name: ACTION
        description: "{{ doc('staking_action') }}"
        tests:
          - not_null

      - name: AMOUNT
        description: "{{ doc('amount') }}"
        tests:
          - not_null

      - name: FACT_STAKING_ACTIONS_ID
        description: "{{doc('id')}}"
        tests:
          - unique:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'
          - not_null:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'

      - name: INSERTED_TIMESTAMP
        description: "{{doc('inserted_timestamp')}}"

      - name: MODIFIED_TIMESTAMP
        description: "{{doc('modified_timestamp')}}"

'''
'''--- models/gold/governance/gov__fact_staking_pool_balances.sql ---
{{ config(
    materialized = 'view',
    secure = false,
    tags = ['core', 'governance'],
    meta ={ 'database_tags':{ 'table':{ 'PURPOSE': 'STAKING, GOVERNANCE' }}}
) }}

WITH balance_changes AS (

    SELECT
        tx_hash,
        block_id,
        block_timestamp,
        receipt_object_id,
        receiver_id AS address,
        amount_adj AS balance,
        COALESCE(
            pool_balances_id,
            {{ dbt_utils.generate_surrogate_key(
                ['tx_hash']
            ) }}
        ) AS fact_staking_pool_balances_id,
        COALESCE(inserted_timestamp, _inserted_timestamp, '2000-01-01' :: TIMESTAMP_NTZ) AS inserted_timestamp,
        COALESCE(modified_timestamp, _inserted_timestamp, '2000-01-01' :: TIMESTAMP_NTZ) AS modified_timestamp
    FROM
        {{ ref('silver__pool_balances') }}
)
SELECT
    *
FROM
    balance_changes

'''
'''--- models/gold/governance/gov__fact_staking_pool_balances.yml ---
version: 2

models:
  - name: gov__fact_staking_pool_balances
    description: |-
      Staking pool balances as extracted from receipt logs when an individual makes a staking action.
      To calculate balance at a point in time, isolate a single record for each pool. This table is transactional-based, so balances are updated with every staking event by users.
      Note - the amount in balance is decimal adjusted by 10^24.
    tests:
      - dbt_utils.recency:
          datepart: day
          field: block_timestamp
          interval: 1

    columns:
      - name: TX_HASH
        description: "{{ doc('tx_hash') }}"
        tests:
          - not_null:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'

      - name: BLOCK_ID
        description: "{{ doc('block_id') }}"
        tests:
          - not_null

      - name: BLOCK_TIMESTAMP
        description: "{{ doc('block_timestamp') }}"
        tests:
          - not_null:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'

      - name: RECEIPT_OBJECT_ID
        description: "{{ doc('receipt_object_id') }}"
        tests:
          - not_null

      - name: ADDRESS
        description: "{{ doc('pool_address') }}"
        tests:
          - not_null

      - name: BALANCE
        description: "{{ doc('balance') }}"
        tests:
          - not_null

      - name: FACT_STAKING_POOL_BALANCES_ID
        description: "{{doc('id')}}"
        tests:
          - unique:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'
          - not_null:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'

      - name: INSERTED_TIMESTAMP
        description: "{{doc('inserted_timestamp')}}"

      - name: MODIFIED_TIMESTAMP
        description: "{{doc('modified_timestamp')}}"

'''
'''--- models/gold/governance/gov__fact_staking_pool_daily_balances.sql ---
{{ config(
    materialized = 'view',
    secure = false,
    tags = ['core', 'governance'],
    meta ={ 'database_tags':{ 'table':{ 'PURPOSE': 'STAKING, GOVERNANCE' }}}
) }}

WITH daily_balance AS (

    SELECT
        date_day AS DATE,
        address,
        balance,
        COALESCE(
            pool_balance_daily_id,
            {{ dbt_utils.generate_surrogate_key(
                ['date_day', 'address']
            ) }}
        ) AS fact_staking_pool_daily_balances_id,
        COALESCE(inserted_timestamp, '2000-01-01' :: TIMESTAMP_NTZ) AS inserted_timestamp,
        COALESCE(modified_timestamp, '2000-01-01' :: TIMESTAMP_NTZ) AS modified_timestamp
    FROM
        {{ ref('silver__pool_balance_daily') }}
)
SELECT
    *
FROM
    daily_balance

'''
'''--- models/gold/governance/gov__fact_staking_pool_daily_balances.yml ---
version: 2

models:
  - name: gov__fact_staking_pool_daily_balances
    description: |-
      Aggregates the balances of each pool for each day, taking the last balance reported for each pool. This always excludes the present date.
    tests:
      - dbt_utils.recency:
          datepart: day
          field: date
          interval: 2

    columns:
      - name: DATE
        description: "{{ doc('date') }}"
        tests:
          - not_null

      - name: ADDRESS
        description: "{{ doc('pool_address') }}"
        tests:
          - not_null

      - name: BALANCE
        description: "{{ doc('balance') }}"
        tests:
          - not_null

      - name: FACT_STAKING_POOL_DAILY_BALANCES_ID
        description: "{{doc('id')}}"
        tests:
          - unique:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'
          - not_null:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'

      - name: INSERTED_TIMESTAMP
        description: "{{doc('inserted_timestamp')}}"

      - name: MODIFIED_TIMESTAMP
        description: "{{doc('modified_timestamp')}}"

'''
'''--- models/gold/horizon/horizon__fact_decoded_actions.sql ---
{{ config(
    materialized = 'view',
    tags = ['core', 'horizon']
) }}

WITH horizon AS (

    SELECT
        action_id_horizon,
        receipt_object_id,
        tx_hash,
        block_id,
        block_timestamp,
        method_name,
        args,
        deposit,
        attached_gas,
        receiver_id,
        signer_id,
        receipt_succeeded,
        COALESCE(
            horizon_decoded_actions_id,
            {{ dbt_utils.generate_surrogate_key(
                ['action_id_horizon']
            ) }}
        ) AS fact_decoded_actions_id,
        COALESCE(inserted_timestamp, _inserted_timestamp, '2000-01-01' :: TIMESTAMP_NTZ) AS inserted_timestamp,
        COALESCE(modified_timestamp, _inserted_timestamp, '2000-01-01' :: TIMESTAMP_NTZ) AS modified_timestamp
    FROM
        {{ ref('silver_horizon__decoded_actions') }}
    WHERE
        method_name != 'set'
)
SELECT
    *
FROM
    horizon

'''
'''--- models/gold/horizon/horizon__fact_decoded_actions.yml ---

version: 2

models:
  - name: horizon__fact_decoded_actions
    description: |-
      Decoded FunctionCall events for receipts where the contract nearhorizon.near was called.

    columns:
      - name: ACTION_ID_HORIZON
        description: "{{ doc('action_id')}}"

      - name: RECEIPT_OBJECT_ID
        description: "{{ doc('receipt_object_id')}}"

      - name: TX_HASH
        description: "{{ doc('tx_hash')}}"
        tests:
          - not_null:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'

      - name: BLOCK_ID
        description: "{{ doc('block_id')}}"

      - name: BLOCK_TIMESTAMP
        description: "{{ doc('block_timestamp')}}"
        tests:
          - not_null:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'

      - name: METHOD_NAME
        description: "{{ doc('method_name')}}"

      - name: ARGS
        description: "{{ doc('args')}}"

      - name: DEPOSIT
        description: "{{ doc('deposit')}}"

      - name: ATTACHED_GAS
        description: "{{ doc('attached_gas')}}"

      - name: RECEIVER_ID
        description: "{{ doc('receiver_id')}}"
      
      - name: SIGNER_ID
        description: "{{ doc('signer_id')}}"

      - name: RECEIPT_SUCCEEDED
        description: "{{ doc('receipt_succeeded')}}"

      - name: FACT_DECODED_ACTIONS_ID
        description: "{{doc('id')}}"
        tests:
          - unique:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'
          - not_null:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'

      - name: INSERTED_TIMESTAMP
        description: "{{doc('inserted_timestamp')}}"

      - name: MODIFIED_TIMESTAMP
        description: "{{doc('modified_timestamp')}}"

'''
'''--- models/gold/nft/nft__dim_nft_contract_metadata.sql ---
{{ config(
    materialized = 'view',
    tags = ['core', 'nft', 'livequery', 'nearblocks']
) }}

WITH nft_contract_metadata AS (

    SELECT
        *
    FROM
        {{ ref('silver__nft_contract_metadata') }}
)
SELECT
    contract_address,
    NAME,
    symbol,
    base_uri,
    icon,
    tokens,
    COALESCE(
        nft_contract_metadata_id,
        {{ dbt_utils.generate_surrogate_key(
            ['contract_address']
        ) }}
    ) AS dim_nft_contract_metadata_id,
    COALESCE(inserted_timestamp, _inserted_timestamp, '2000-01-01' :: TIMESTAMP_NTZ) AS inserted_timestamp,
    COALESCE(modified_timestamp, _inserted_timestamp, '2000-01-01' :: TIMESTAMP_NTZ) AS modified_timestamp
FROM
    nft_contract_metadata

'''
'''--- models/gold/nft/nft__dim_nft_contract_metadata.yml ---
version: 2

models:
  - name: nft__dim_nft_contract_metadata
    description: |-
      NFT Contract-level metadata provided by the Nearblocks NFT endpoint.

    columns:
      - name: CONTRACT_ADDRESS
        description: "{{ doc('contract_address')}}"
        tests:
          - not_null

      - name: NAME
        description: "{{ doc('name')}}"
        tests:
          - not_null
          
      - name: SYMBOL
        description: "{{ doc('symbol')}}"

      - name: BASE_URI
        description: "{{ doc('base_uri')}}"

      - name: ICON
        description: "{{ doc('icon')}}"

      - name: TOKENS
        description: "{{ doc('tokens')}}"

      - name: DIM_NFT_CONTRACT_METADATA_ID
        description: "{{doc('id')}}"
        tests:
          - unique:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'
          - not_null:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'

      - name: INSERTED_TIMESTAMP
        description: "{{doc('inserted_timestamp')}}"

      - name: MODIFIED_TIMESTAMP
        description: "{{doc('modified_timestamp')}}"

'''
'''--- models/gold/nft/nft__dim_nft_series_metadata.sql ---
{{ config(
    materialized = 'view',
    tags = ['core', 'nft', 'pagoda']
) }}

WITH series_metadata AS (

    SELECT
        *
    FROM
        {{ ref('silver__nft_series_metadata') }}
)
SELECT
    contract_address,
    series_id,
    token_metadata :title :: STRING AS series_title,
    metadata_id,
    contract_metadata,
    token_metadata,
    COALESCE(
        nft_series_metadata_id,
        {{ dbt_utils.generate_surrogate_key(
            ['metadata_id']
        ) }}
    ) AS dim_nft_series_metadata_id,
    COALESCE(inserted_timestamp, _inserted_timestamp, '2000-01-01' :: TIMESTAMP_NTZ) AS inserted_timestamp,
    COALESCE(modified_timestamp, _inserted_timestamp, '2000-01-01' :: TIMESTAMP_NTZ) AS modified_timestamp
FROM
    series_metadata

'''
'''--- models/gold/nft/nft__dim_nft_series_metadata.yml ---
version: 2

models:
  - name: nft__dim_nft_series_metadata
    description: |-
      NFT Series-level metadata provided by the Pagoda NFT endpoint.

    columns:
      - name: CONTRACT_ADDRESS
        description: "{{ doc('contract_address')}}"
        tests:
          - not_null

      - name: SERIES_ID
        description: "{{ doc('series_id')}}"
        tests:
          - not_null

      - name: SERIES_TITLE
        description: "{{ doc('series_title')}}"

      - name: METADATA_ID
        description: "{{ doc('metadata_id')}}"

      - name: CONTRACT_METADATA
        description: "{{ doc('contract_metadata')}}"

      - name: TOKEN_METADATA
        description: "{{ doc('token_metadata')}}"

      - name: DIM_NFT_SERIES_METADATA_ID
        description: "{{doc('id')}}"
        tests:
          - unique:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'
          - not_null:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'

      - name: INSERTED_TIMESTAMP
        description: "{{doc('inserted_timestamp')}}"

      - name: MODIFIED_TIMESTAMP
        description: "{{doc('modified_timestamp')}}"

'''
'''--- models/gold/nft/nft__ez_nft_sales.sql ---
{{ config(
    materialized = 'view',
    meta ={ 'database_tags':{ 'table':{ 'PURPOSE': 'NFT' }}},
    tags = ['core', 'nft']
) }}

WITH nft_sales AS (

    SELECT
        receipt_id,
        block_id,
        block_timestamp,
        tx_hash,
        seller_address,
        buyer_address,
        platform_address,
        platform_name,
        nft_address,
        token_id,
        price,
        price_usd,
        method_name,
        log,
        gas_burned,
        nft_sales_id AS ez_nft_sales_id,
        COALESCE(inserted_timestamp, _inserted_timestamp, '2000-01-01' :: TIMESTAMP_NTZ) AS inserted_timestamp,
        COALESCE(modified_timestamp, _inserted_timestamp, '2000-01-01' :: TIMESTAMP_NTZ) AS modified_timestamp
    FROM
        {{ ref('silver__nft_sales') }}
)
SELECT
    *
FROM
    nft_sales

'''
'''--- models/gold/nft/nft__ez_nft_sales.yml ---
version: 2

models:
  - name: nft__ez_nft_sales
    description: |-
      This table records all the NFT sales actions of the main Near marketplaces.
    columns:
      - name: RECEIPT_ID
        description: "{{ doc('receipt_id')}}"
        tests:
          - not_null

      - name: BLOCK_ID
        description: "{{ doc('block_id')}}"

      - name: BLOCK_TIMESTAMP
        description: "{{ doc('block_timestamp')}}"
        tests:
          - not_null:
              where: inserted_timestamp <= current_timestamp - interval '10 hour'

      - name: TX_HASH
        description: "{{ doc('tx_hash')}}"
        tests:
          - not_null

      - name: GAS_BURNED
        description: "{{ doc('attached_gas')}}"
        tests:
          - not_null

      - name: SELLER_ADDRESS
        description: "{{ doc('from_address')}}"
        tests:
          - not_null

      - name: BUYER_ADDRESS
        description: "{{ doc('to_address')}}"
        tests:
          - not_null

      - name: PLATFORM_ADDRESS
        description: "Platform Address"
        tests:
          - not_null

      - name: PLATFORM_NAME
        description: "Platform Name"
        tests:
          - not_null

      - name: NFT_ADDRESS
        description: "NFT Address"
        tests:
          - not_null

      - name: TOKEN_ID
        description: "{{ doc('token_id')}}"
        tests:
          - not_null

      - name: PRICE
        description: "{{ doc('raw_price')}}"
        tests:
          - not_null

      - name: PRICE_USD
        description: "{{ doc('price_usd')}}"

      - name: METHOD_NAME
        description: "{{ doc('method_name')}}"
        tests:
          - not_null

      - name: LOG
        description: "{{ doc('logs')}}"
        tests:
          - not_null

      - name: LOGS_INDEX
        description: "ROW NUMBER"

      - name: NFT_SALES_ID
        description: "{{doc('id')}}"

      - name: INSERTED_TIMESTAMP
        description: "{{doc('inserted_timestamp')}}"

      - name: MODIFIED_TIMESTAMP
        description: "{{doc('modified_timestamp')}}"

'''
'''--- models/gold/nft/nft__fact_nft_mints.sql ---
{{ config(
    materialized = 'view',
    meta ={ 'database_tags':{ 'table':{ 'PURPOSE': 'NFT' }}},
    tags = ['core', 'nft']
) }}

WITH nft_mints AS (

    SELECT
        receipt_object_id,
        tx_hash,
        block_id,
        block_timestamp,
        token_id,
        method_name,
        args,
        memo,
        deposit,
        tx_receiver,
        receiver_id,
        signer_id,
        owner_id,
        owner_per_tx,
        mint_per_tx,
        gas_burnt,
        transaction_fee,
        implied_price,
        tx_status, -- TODO migrate to tx_succeeded
        mint_action_id,
        COALESCE(
            standard_nft_mint_id,
            {{ dbt_utils.generate_surrogate_key(
                ['mint_action_id']
            ) }}
        ) AS fact_nft_mints_id,
        COALESCE(inserted_timestamp, _inserted_timestamp, '2000-01-01' :: TIMESTAMP_NTZ) AS inserted_timestamp,
        COALESCE(modified_timestamp, _inserted_timestamp, '2000-01-01' :: TIMESTAMP_NTZ) AS modified_timestamp
    FROM
        {{ ref('silver__standard_nft_mint_s3') }}
)
SELECT
    *
FROM
    nft_mints

'''
'''--- models/gold/nft/nft__fact_nft_mints.yml ---
version: 2

models:
  - name: nft__fact_nft_mints
    description: |-
      This table records all the NFT Mints per the NEP171 standard, across various methods.

    columns:
      - name: RECEIPT_OBJECT_ID
        description: "{{ doc('receipt_object_id') }}"
        tests:
          - not_null

      - name: TX_HASH
        description: "{{ doc('tx_hash') }}"
        tests:
          - not_null:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'

      - name: BLOCK_ID
        description: "{{ doc('block_id')}}"
        tests:
          - not_null

      - name: BLOCK_TIMESTAMP
        description: "{{ doc('block_timestamp')}}"
        tests:
          - not_null:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'

      - name: TOKEN_ID
        description: "{{ doc('nft_token_id') }}"
        tests:
          - not_null:
              where: signer_id != 'decentland.near'

      - name: METHOD_NAME
        description: "{{ doc('method_name') }}"

      - name: ARGS
        description: "{{ doc('args') }}"

      - name: MEMO
        description: "{{ doc('memo') }}"

      - name: DEPOSIT
        description: "{{ doc('deposit') }}"
        tests:
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - NUMBER
                - FLOAT

      - name: RECEIVER_ID
        description: "{{ doc('receiver_id')}}"
        tests:
          - not_null

      - name: SIGNER_ID
        description: "{{ doc('signer_id')}}"
        tests:
          - not_null

      - name: OWNER_ID
        description: "{{ doc('owner_id') }}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - STRING
                - VARCHAR

      - name: OWNER_PER_TX
        description: "{{ doc('owner_per_tx') }}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - NUMBER
                - FLOAT

      - name: MINT_PER_TX
        description: "{{ doc('mint_per_tx') }}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - NUMBER
                - FLOAT

      - name: GAS_BURNT
        description: "{{ doc('gas_burnt') }}"
        tests:
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - NUMBER
                - FLOAT
          - not_null:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'

      - name: TRANSACTION_FEE
        description: "{{ doc('transaction_fee') }}"
        tests:
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - NUMBER
                - FLOAT
          - not_null:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'

      - name: TX_STATUS
        description: "{{ doc('tx_status') }}"
        tests:
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - STRING
                - VARCHAR
          - not_null:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'

      - name: FACT_NFT_MINTS_ID
        description: "{{doc('id')}}"
        tests:
          - unique:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'
          - not_null:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'

      - name: INSERTED_TIMESTAMP
        description: "{{doc('inserted_timestamp')}}"

      - name: MODIFIED_TIMESTAMP
        description: "{{doc('modified_timestamp')}}"

'''
'''--- models/gold/nft/nft__fact_nft_transfers.sql ---
{{ config(
    materialized = 'view',
    meta ={ 'database_tags':{ 'table':{ 'PURPOSE': 'NFT' }}},
    tags = ['core', 'nft']
) }}

WITH nft_token_transfers AS (

    SELECT
        *
    FROM
        {{ ref('silver__nft_transfers') }}
)
SELECT
    block_id,
    block_timestamp,
    tx_hash,
    action_id,
    contract_address,
    from_address,
    to_address,
    token_id,
    nft_transfers_id AS fact_nft_transfers_id,
    COALESCE(inserted_timestamp, _inserted_timestamp, '2000-01-01' :: TIMESTAMP_NTZ) AS inserted_timestamp,
    COALESCE(modified_timestamp, _inserted_timestamp, '2000-01-01' :: TIMESTAMP_NTZ) AS modified_timestamp
FROM
    nft_token_transfers

'''
'''--- models/gold/nft/nft__fact_nft_transfers.yml ---
version: 2

models:
  - name: nft__fact_nft_transfers
    description: This table contains all the NFT transfers
    columns:
      - name: BLOCK_ID
        description: "{{ doc('block_id')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - NUMBER
                - FLOAT

      - name: BLOCK_TIMESTAMP
        description: "{{ doc('block_timestamp')}}"
        tests:
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - TIMESTAMP_NTZ
          - not_null:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'

      - name: TX_HASH
        description: "{{ doc('tx_hash')}}"
        tests:
          - not_null

      - name: CONTRACT_ADDRESS
        description: "{{ doc('contract_address')}}"

      - name: FROM_ADDRESS
        description: "{{ doc('from_address')}}"

      - name: TO_ADDRESS
        description: "{{ doc('to_address')}}"

      - name: TOKEN_ID
        description: "{{ doc('token_id')}}"

      - name: FACT_NFT_TRANSFERS_ID
        description: "{{doc('id')}}"
        tests:
          - unique:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'
          - not_null:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'

      - name: INSERTED_TIMESTAMP
        description: "{{doc('inserted_timestamp')}}"

      - name: MODIFIED_TIMESTAMP
        description: "{{doc('modified_timestamp')}}"

'''
'''--- models/gold/price/_legacy/price__fact_prices.sql ---
{{ config(
    materialized = 'view',
    secure = false,
    meta ={ 'database_tags':{ 'table':{ 'PURPOSE': 'PRICE' }}},
    tags = ['core', 'price']
) }}

WITH oracle_prices AS (

    SELECT
        block_timestamp AS TIMESTAMP,
        token,
        symbol,
        token_contract,
        raw_price,
        price_usd,
        source,
        COALESCE(
            prices_oracle_id,
            {{ dbt_utils.generate_surrogate_key(
                ['tx_hash', 'block_id', 'token_contract']
            ) }}
        ) AS fact_prices_id,
        inserted_timestamp,
        modified_timestamp
    FROM
        {{ ref('silver__prices_oracle_s3') }}
)
SELECT
    *
FROM
    oracle_prices

'''
'''--- models/gold/price/_legacy/price__fact_prices.yml ---
version: 2

models:
  - name: price__fact_prices
    description: |-
      Deprecating soon! Please use price.ez_prices_hourly or price.fact_prices_ohlc_hourly instead.
    tests:
      - dbt_utils.recency:
          datepart: hours
          field: timestamp
          interval: 12

    columns:
      - name: TIMESTAMP
        description: "{{ doc('timestamp')}}"
        tests:
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - TIMESTAMP_NTZ

      - name: TOKEN
        description: "{{ doc('token')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - STRING
                - VARCHAR

      - name: SYMBOL
        description: "{{ doc('symbol')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - STRING
                - VARCHAR

      - name: TOKEN_CONTRACT
        description: "{{ doc('token_contract')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - STRING
                - VARCHAR

      - name: RAW_PRICE
        description: "{{ doc('price_usd')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - FLOAT
                - DOUBLE

      - name: PRICE_USD
        description: "{{ doc('price_usd')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - FLOAT
                - DOUBLE

      - name: SOURCE
        description: "{{ doc('source')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - STRING
                - VARCHAR

      - name: FACT_PRICES_ID
        description: "{{doc('id')}}"
        tests:
          - unique:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'
          - not_null:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'

      - name: INSERTED_TIMESTAMP
        description: "{{doc('inserted_timestamp')}}"

      - name: MODIFIED_TIMESTAMP
        description: "{{doc('modified_timestamp')}}"

'''
'''--- models/gold/price/price__dim_asset_metadata.sql ---
{{ config(
    materialized = 'view',
    persist_docs ={ "relation": true,
    "columns": true }
) }}

SELECT
    token_address,
    asset_id,
    symbol,
    name,
    platform AS blockchain,
    platform_id AS blockchain_id,
    provider,
    inserted_timestamp,
    modified_timestamp,
    complete_provider_asset_metadata_id AS dim_asset_metadata_id
FROM
    {{ ref('silver__complete_provider_asset_metadata') }}

'''
'''--- models/gold/price/price__dim_asset_metadata.yml ---
version: 2
models:
  - name: price__dim_asset_metadata
    description: '{{ doc("prices_dim_asset_metadata_table_doc") }}'

    columns:
      - name: PROVIDER
        description: '{{ doc("prices_provider")}}'
      - name: ASSET_ID
        description: '{{ doc("prices_asset_id") }}'
      - name: NAME
        description: '{{ doc("prices_name") }}'
      - name: SYMBOL
        description: '{{ doc("prices_symbol") }}'
      - name: TOKEN_ADDRESS
        description: '{{ doc("prices_token_address") }}'
      - name: BLOCKCHAIN
        description: '{{ doc("prices_blockchain") }}'
      - name: BLOCKCHAIN_ID
        description: '{{ doc("prices_blockchain_id") }}'
      - name: DIM_ASSET_METADATA_ID
        description: '{{ doc("id") }}'   
      - name: INSERTED_TIMESTAMP

'''
'''--- models/gold/price/price__ez_asset_metadata.sql ---
{{ config(
    materialized = 'view',
    persist_docs ={ "relation": true,
    "columns": true }
) }}

SELECT
    token_address,
    asset_id,
    symbol,
    NAME,
    decimals,
    blockchain,
    FALSE AS is_native,
    is_deprecated,
    inserted_timestamp,
    modified_timestamp,
    complete_token_asset_metadata_id AS ez_asset_metadata_id
FROM
    {{ ref('silver__complete_token_asset_metadata') }}
UNION ALL
SELECT
    NULL AS token_address,
    asset_id,
    symbol,
    NAME,
    decimals,
    blockchain,
    is_deprecated,
    TRUE AS is_native,
    inserted_timestamp,
    modified_timestamp,
    complete_native_asset_metadata_id AS ez_asset_metadata_id
FROM
    {{ ref('silver__complete_native_asset_metadata') }}

'''
'''--- models/gold/price/price__ez_asset_metadata.yml ---
version: 2
models:
  - name: price__ez_asset_metadata
    description: '{{ doc("prices_ez_asset_metadata_table_doc") }}'

    columns:
      - name: ASSET_ID
        description: '{{ doc("prices_asset_id") }}'
      - name: NAME
        description: '{{ doc("prices_name") }}'
      - name: SYMBOL
        description: '{{ doc("prices_symbol") }}'
      - name: TOKEN_ADDRESS
        description: '{{ doc("prices_token_address") }}'
      - name: BLOCKCHAIN
        description: '{{ doc("prices_blockchain") }}'
      - name: DECIMALS
        description: '{{ doc("prices_decimals") }}'
      - name: IS_NATIVE
        description: '{{ doc("prices_is_native") }}'
      - name: IS_DEPRECATED
        description: '{{ doc("prices_is_deprecated") }}'
      - name: EZ_ASSET_METADATA_ID
        description: '{{ doc("id") }}'   
      - name: INSERTED_TIMESTAMP
        description: '{{ doc("inserted_timestamp") }}'   
      - name: MODIFIED_TIMESTAMP
        description: '{{ doc("modified_timestamp") }}' 
      
'''
'''--- models/gold/price/price__ez_prices_hourly.sql ---
{{ config(
    materialized = 'view',
    persist_docs ={ "relation": true,
    "columns": true }
) }}

SELECT
    HOUR,
    token_address,
    symbol,
    NAME,
    decimals,
    price,
    blockchain,
    FALSE AS is_native,
    is_deprecated,
    is_imputed,
    inserted_timestamp,
    modified_timestamp,
    complete_token_prices_id AS ez_prices_hourly_id
FROM
    {{ ref('silver__complete_token_prices') }}
UNION ALL
SELECT
    HOUR,
    NULL AS token_address,
    symbol,
    NAME,
    decimals,
    price,
    blockchain,
    TRUE AS is_native,
    is_deprecated,
    is_imputed,
    inserted_timestamp,
    modified_timestamp,
    complete_native_prices_id AS ez_prices_hourly_id
FROM
    {{ ref('silver__complete_native_prices') }}

'''
'''--- models/gold/price/price__ez_prices_hourly.yml ---
version: 2
models:
  - name: price__ez_prices_hourly
    description: '{{ doc("prices_ez_prices_hourly_table_doc") }}'

    columns:
      - name: HOUR
        description: '{{ doc("prices_hour")}}'
      - name: TOKEN_ADDRESS
        description: '{{ doc("prices_token_address") }}'
      - name: SYMBOL
        description: '{{ doc("prices_symbol") }}'
      - name: BLOCKCHAIN
        description: '{{ doc("prices_blockchain") }}'
      - name: DECIMALS
        description: '{{ doc("prices_decimals") }}'
      - name: PRICE
        description: '{{ doc("prices_price") }}'
      - name: IS_NATIVE
        description: '{{ doc("prices_is_native") }}'
      - name: IS_IMPUTED
        description: '{{ doc("prices_is_imputed") }}'
      - name: IS_DEPRECATED
        description: '{{ doc("prices_is_deprecated") }}'
      - name: EZ_PRICES_HOURLY_ID
        description: '{{ doc("id") }}'   
      - name: INSERTED_TIMESTAMP
        description: '{{ doc("inserted_timestamp") }}'   
      - name: MODIFIED_TIMESTAMP
        description: '{{ doc("modified_timestamp") }}' 

'''
'''--- models/gold/price/price__fact_prices_ohlc_hourly.sql ---
{{ config(
    materialized = 'view',
    persist_docs ={ "relation": true,
    "columns": true }
) }}

SELECT
    asset_id,
    recorded_hour AS HOUR,
    OPEN,
    high,
    low,
    CLOSE,
    provider,
    inserted_timestamp,
    modified_timestamp,
    complete_provider_prices_id AS fact_prices_ohlc_hourly_id
FROM
    {{ ref('silver__complete_provider_prices') }}

'''
'''--- models/gold/price/price__fact_prices_ohlc_hourly.yml ---
version: 2
models:
  - name: price__fact_prices_ohlc_hourly
    description: '{{ doc("prices_fact_prices_ohlc_hourly_table_doc") }}'

    columns:
      - name: HOUR
        description: '{{ doc("prices_hour")}}'
      - name: ASSET_ID
        description: '{{ doc("prices_asset_id") }}'
      - name: OPEN
        description: '{{ doc("prices_open") }}'
      - name: HIGH
        description: '{{ doc("prices_high") }}'
      - name: LOW
        description: '{{ doc("prices_low") }}'
      - name: CLOSE
        description: '{{ doc("prices_close") }}'
      - name: FACT_PRICES_OHLC_HOURLY_ID
        description: '{{ doc("id") }}'   
      - name: INSERTED_TIMESTAMP
        description: '{{ doc("inserted_timestamp") }}'   
      - name: MODIFIED_TIMESTAMP
        description: '{{ doc("modified_timestamp") }}' 

'''
'''--- models/gold/social/social__fact_addkey_events.sql ---
{{ config(
    materialized = 'view',
    tags = ['core', 'social']
) }}

SELECT
    action_id,
    tx_hash,
    block_id,
    block_timestamp,
    allowance,
    signer_id,
    COALESCE(
        social_addkey_id,
        {{ dbt_utils.generate_surrogate_key(
            ['action_id']
        ) }}
    ) AS fact_addkey_events_id,
    COALESCE(inserted_timestamp, _inserted_timestamp, '2000-01-01' :: TIMESTAMP_NTZ) AS inserted_timestamp,
    COALESCE(modified_timestamp, _inserted_timestamp, '2000-01-01' :: TIMESTAMP_NTZ) AS modified_timestamp
FROM
    {{ ref('silver_social__addkey') }}

'''
'''--- models/gold/social/social__fact_addkey_events.yml ---

version: 2

models:
  - name: social__fact_addkey_events
    description: |-
      All AddKey events for the contract social.near, which indicate a wallet or user authorizing use of the contract as a high-level proxy for interest in the platform.

    columns:
      - name: ACTION_ID
        description: "{{ doc('block_id')}}"

      - name: TX_HASH
        description: "{{ doc('tx_hash')}}"
        tests:
          - not_null:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'

      - name: BLOCK_ID
        description: "{{ doc('block_id')}}"

      - name: BLOCK_TIMESTAMP
        description: "{{ doc('block_timestamp')}}"
        tests:
          - not_null:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'

      - name: ALLOWANCE
        description: "{{ doc('allowance')}}"

      - name: SIGNER_ID
        description: "{{ doc('signer_id')}}"

      - name: FACT_ADDKEY_EVENTS_ID
        description: "{{doc('id')}}"
        tests:
          - unique:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'
          - not_null:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'

      - name: INSERTED_TIMESTAMP
        description: "{{doc('inserted_timestamp')}}"

      - name: MODIFIED_TIMESTAMP
        description: "{{doc('modified_timestamp')}}"

'''
'''--- models/gold/social/social__fact_decoded_actions.sql ---
{{ config(
    materialized = 'view',
    tags = ['core', 'social']
) }}

SELECT
    action_id_social,
    tx_hash,
    block_id,
    block_timestamp,
    signer_id,
    predecessor_id,
    node,
    node_data,
    COALESCE(
        social_decoded_actions_id,
        {{ dbt_utils.generate_surrogate_key(
            ['action_id_social']
        ) }}
    ) AS fact_decoded_actions_id,
    COALESCE(inserted_timestamp, _inserted_timestamp, '2000-01-01' :: TIMESTAMP_NTZ) AS inserted_timestamp,
    COALESCE(modified_timestamp, _inserted_timestamp, '2000-01-01' :: TIMESTAMP_NTZ) AS modified_timestamp
FROM
    {{ ref('silver_social__decoded_actions') }}

'''
'''--- models/gold/social/social__fact_decoded_actions.yml ---
version: 2

models:
  - name: social__fact_decoded_actions
    description: |-
      Decoded FunctionCall events for receipts where the contract social.near was called.

    columns:
      - name: ACTION_ID_SOCIAL
        description: "{{ doc('action_id')}}"

      - name: TX_HASH
        description: "{{ doc('tx_hash')}}"
        tests:
          - not_null:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'

      - name: BLOCK_ID
        description: "{{ doc('block_id')}}"

      - name: BLOCK_TIMESTAMP
        description: "{{ doc('block_timestamp')}}"
        tests:
          - not_null:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'

      - name: SIGNER_ID
        description: "{{ doc('signer_id')}}"

      - name: PREDECESSOR_ID
        description: "{{ doc('predecessor_id')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - STRING
                - VARCHAR

      - name: NODE
        description: "{{ doc('node')}}"

      - name: NODE_DATA
        description: "{{ doc('node_data')}}"

      - name: FACT_DECODED_ACTIONS_ID
        description: "{{doc('id')}}"
        tests:
          - unique:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'
          - not_null:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'

      - name: INSERTED_TIMESTAMP
        description: "{{doc('inserted_timestamp')}}"

      - name: MODIFIED_TIMESTAMP
        description: "{{doc('modified_timestamp')}}"

'''
'''--- models/gold/social/social__fact_posts.sql ---
{{ config(
    materialized = 'view',
    tags = ['core', 'social']
) }}

SELECT
    tx_hash,
    action_id_social,
    block_id,
    block_timestamp,
    signer_id,
    post_type,
    post_text,
    post_image,
    COALESCE(
        social_posts_id,
        {{ dbt_utils.generate_surrogate_key(
            ['action_id_social']
        ) }}
    ) AS fact_posts_id,
    COALESCE(inserted_timestamp, _inserted_timestamp, '2000-01-01' :: TIMESTAMP_NTZ) AS inserted_timestamp,
    COALESCE(modified_timestamp, _inserted_timestamp, '2000-01-01' :: TIMESTAMP_NTZ) AS modified_timestamp
FROM
    {{ ref('silver_social__posts') }}

'''
'''--- models/gold/social/social__fact_posts.yml ---

version: 2

models:
  - name: social__fact_posts
    description: |-
      Cleaned and curated post data on Near Social.

    columns:
      - name: ACTION_ID_SOCIAL
        description: "{{ doc('block_id')}}"

      - name: TX_HASH
        description: "{{ doc('tx_hash')}}"
        tests:
          - not_null:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'

      - name: BLOCK_ID
        description: "{{ doc('block_id')}}"

      - name: BLOCK_TIMESTAMP
        description: "{{ doc('block_timestamp')}}"
        tests:
          - not_null:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'

      - name: SIGNER_ID
        description: "{{ doc('signer_id')}}"

      - name: POST_TYPE
        description: "{{ doc('profile_section')}}"

      - name: POST_TEXT
        description: "{{ doc('profile_data')}}"

      - name: POST_IMAGE
        description: "{{ doc('profile_data')}}"

      - name: FACT_POSTS_ID
        description: "{{doc('id')}}"
        tests:
          - unique:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'
          - not_null:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'

      - name: INSERTED_TIMESTAMP
        description: "{{doc('inserted_timestamp')}}"

      - name: MODIFIED_TIMESTAMP
        description: "{{doc('modified_timestamp')}}"

'''
'''--- models/gold/social/social__fact_profile_changes.sql ---
{{ config(
    materialized = 'view',
    tags = ['core', 'social']
) }}

SELECT
    action_id_profile,
    tx_hash,
    block_id,
    block_timestamp,
    signer_id,
    profile_section,
    profile_data,
    COALESCE(
        social_profile_changes_id,
        {{ dbt_utils.generate_surrogate_key(
            ['action_id_profile']
        ) }}
    ) AS fact_profile_changes_id,
    COALESCE(inserted_timestamp, _inserted_timestamp, '2000-01-01' :: TIMESTAMP_NTZ) AS inserted_timestamp,
    COALESCE(modified_timestamp, _inserted_timestamp, '2000-01-01' :: TIMESTAMP_NTZ) AS modified_timestamp
FROM
    {{ ref('silver_social__profile_changes') }}

'''
'''--- models/gold/social/social__fact_profile_changes.yml ---

version: 2

models:
  - name: social__fact_profile_changes
    description: |-
      Events from the node `profile` that indicate a change to a user's profile.

    columns:
      - name: ACTION_ID_PROFILE
        description: "{{ doc('action_id_profile')}}"

      - name: TX_HASH
        description: "{{ doc('tx_hash')}}"
        tests:
          - not_null:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'

      - name: BLOCK_ID
        description: "{{ doc('block_id')}}"

      - name: BLOCK_TIMESTAMP
        description: "{{ doc('block_timestamp')}}"
        tests:
          - not_null:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'

      - name: SIGNER_ID
        description: "{{ doc('signer_id')}}"

      - name: PROFILE_SECTION
        description: "{{ doc('profile_section')}}"

      - name: PROFILE_DATA
        description: "{{ doc('profile_data')}}"

      - name: FACT_PROFILE_CHANGES_ID
        description: "{{doc('id')}}"
        tests:
          - unique:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'
          - not_null:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'

      - name: INSERTED_TIMESTAMP
        description: "{{doc('inserted_timestamp')}}"

      - name: MODIFIED_TIMESTAMP
        description: "{{doc('modified_timestamp')}}"

'''
'''--- models/gold/social/social__fact_widget_deployments.sql ---
{{ config(
    materialized = 'view',
    tags = ['core', 'social']
) }}

SELECT
    tx_hash,
    action_id_social,
    block_id,
    block_timestamp,
    signer_id,
    widget_name,
    source_code,
    metadata,
    branch,
    widget_modules_used,
    widget_url,
    social_widgets_id AS fact_widget_deployments_id,
    inserted_timestamp AS inserted_timestamp,
    modified_timestamp AS modified_timestamp
FROM
    {{ ref('silver_social__widgets') }}

'''
'''--- models/gold/social/social__fact_widget_deployments.yml ---

version: 2

models:
  - name: social__fact_widget_deployments
    description: |-
      Cleaned and curated widget deployments on Near Social.

    columns:
      - name: ACTION_ID_SOCIAL
        description: "{{ doc('block_id')}}"

      - name: TX_HASH
        description: "{{ doc('tx_hash')}}"
        tests:
          - not_null:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'

      - name: BLOCK_ID
        description: "{{ doc('block_id')}}"

      - name: BLOCK_TIMESTAMP
        description: "{{ doc('block_timestamp')}}"
        tests:
          - not_null:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'

      - name: SIGNER_ID
        description: "{{ doc('signer_id')}}"

      - name: WIDGET_NAME
        description: "{{ doc('widget_name')}}"

      - name: SOURCE_CODE
        description: "{{ doc('source_code')}}"

      - name: METADATA
        description: "{{ doc('metadata')}}"

      - name: BRANCH
        description: "{{ doc('branch')}}"

      - name: WIDGET_MODULES_USED
        description: "{{ doc('widget_modules_used')}}"

      - name: WIDGET_URL
        description: "{{ doc('widget_url')}}"

      - name: FACT_WIDGET_DEPLOYMENTS_ID
        description: "{{doc('id')}}"
        tests:
          - unique:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'
          - not_null:
              where: inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days' AND SYSDATE() - INTERVAL '2 hours'

      - name: INSERTED_TIMESTAMP
        description: "{{doc('inserted_timestamp')}}"

      - name: MODIFIED_TIMESTAMP
        description: "{{doc('modified_timestamp')}}"

'''
'''--- models/gold/stats/stats__ez_core_metrics_hourly.sql ---
{{ config(
    materialized = 'view',
    tags = ['core']
) }}

WITH prices AS (
    --get closing price for the hour

    SELECT
        HOUR AS block_timestamp_hour,
        price AS price_usd
    FROM
        {{ ref('silver__complete_token_prices') }}
    WHERE
        token_address IN (
            'near',
            'wrap.near'
        ) 
        qualify ROW_NUMBER() over (
            PARTITION BY block_timestamp_hour
            ORDER BY
                HOUR DESC
        ) = 1
)
SELECT
    b.block_timestamp_hour,
    b.block_number_min,
    b.block_number_max,
    b.block_count,
    t.transaction_count,
    t.transaction_count_success,
    t.transaction_count_failed,
    t.unique_from_count,
    t.unique_to_count,
    t.total_fees AS total_fees_native,
    ROUND(
        t.total_fees * p.price_usd,
        2
    ) AS total_fees_usd,
    t.core_metrics_hourly_id AS ez_core_metrics_hourly_id,
    GREATEST(
        b.inserted_timestamp,
        t.inserted_timestamp
    ) AS inserted_timestamp,
    GREATEST(
        b.modified_timestamp,
        t.modified_timestamp
    ) AS modified_timestamp
FROM
    {{ ref('silver_stats__core_metrics_block_hourly') }}
    b
    JOIN {{ ref('silver_stats__core_metrics_hourly') }}
    t
    ON b.block_timestamp_hour = t.block_timestamp_hour
    LEFT JOIN prices p
    ON b.block_timestamp_hour = p.block_timestamp_hour

'''
'''--- models/gold/stats/stats__ez_core_metrics_hourly.yml ---
version: 2
models:
  - name: stats__ez_core_metrics_hourly
    description: '{{ doc("ez_core_metrics_hourly_table_doc") }}'

    columns:
      - name: BLOCK_TIMESTAMP_HOUR
        description: '{{ doc("block_timestamp_hour") }}'
      - name: BLOCK_NUMBER_MIN
        description: '{{ doc("block_number_min") }}'
      - name: BLOCK_NUMBER_MAX
        description: '{{ doc("block_number_max") }}'
      - name: BLOCK_COUNT
        description: '{{ doc("block_count") }}'
      - name: TRANSACTION_COUNT
        description: '{{ doc("transaction_count") }}'
      - name: TRANSACTION_COUNT_SUCCESS
        description: '{{ doc("transaction_count_success") }}'
      - name: TRANSACTION_COUNT_FAILED
        description: '{{ doc("transaction_count_failed") }}'
      - name: UNIQUE_FROM_COUNT
        description: '{{ doc("unique_from_count") }}'
      - name: UNIQUE_TO_COUNT
        description: '{{ doc("unique_to_count") }}'
      - name: TOTAL_FEES_NATIVE
        description: '{{ doc("total_fees_native") }}'
      - name: TOTAL_FEES_USD
        description: '{{ doc("total_fees_usd") }}'
      - name: EZ_CORE_METRICS_HOURLY_ID
        description: '{{ doc("id") }}'
      - name: INSERTED_TIMESTAMP
        description: '{{ doc("inserted_timestamp") }}'
      - name: MODIFIED_TIMESTAMP
        description: '{{ doc("modified_timestamp") }}'

'''
'''--- models/silver/_observability/silver_observability__blocks_completeness.sql ---
-- depends_on: {{ ref('silver__streamline_blocks') }}
{{ config(
    materialized = 'incremental',
    unique_key = 'test_timestamp',
    full_refresh = False,
    tags = ['observability']
) }}

WITH blocks_joined AS (

    SELECT
        A.block_id AS current_block_id,
        A.block_timestamp AS current_block_timestamp,
        A.block_hash AS current_block_hash,
        b.block_id AS next_block_id,
        b.block_timestamp AS next_block_timestamp,
        b.prev_hash AS next_prev_hash
    FROM
        {{ ref('silver__streamline_blocks') }} A
        LEFT JOIN {{ ref('silver__streamline_blocks') }}
        b
        ON A.block_hash = b.prev_hash
    WHERE
        A.block_timestamp < b.block_timestamp -- Ensuring temporal order
        AND A.block_timestamp <= DATEADD('hour', -12, SYSDATE())

{% if is_incremental() %}
AND (
    A.block_id >= (
        SELECT
            MIN(block_id)
        FROM
            (
                SELECT
                    MIN(block_id) AS block_id
                FROM
                    {{ ref('silver__streamline_blocks') }}
                WHERE
                    block_timestamp BETWEEN DATEADD('hour', -96, SYSDATE())
                    AND DATEADD('hour', -95, SYSDATE())
                UNION
                SELECT
                    MIN(VALUE) - 1 AS block_id
                FROM
                    (
                        SELECT
                            blocks_impacted_array
                        FROM
                            {{ this }}
                            qualify ROW_NUMBER() over (
                                ORDER BY
                                    test_timestamp DESC
                            ) = 1
                    ),
                    LATERAL FLATTEN(
                        input => blocks_impacted_array
                    )
            )
    ) {% if var('OBSERV_FULL_TEST') %}
        OR b.block_id >= 9820210
    {% endif %}
)
{% endif %}
),
blocks_impacted AS (
    SELECT
        current_block_id,
        current_block_timestamp,
        current_block_hash
    FROM
        blocks_joined
    WHERE
        next_block_id IS NULL -- Where there is no next block
        OR current_block_hash != next_prev_hash -- Or the hash doesn't match
),
aggregated_data AS (
    SELECT
        MIN(
            A.current_block_id
        ) AS min_block,
        MAX(
            A.current_block_id
        ) AS max_block,
        MIN(
            A.current_block_timestamp
        ) AS min_block_timestamp,
        MAX(
            A.current_block_timestamp
        ) AS max_block_timestamp,
        COUNT(
            DISTINCT A.current_block_id
        ) AS blocks_tested,
        COUNT(
            DISTINCT b.current_block_id
        ) AS blocks_impacted_count,
        ARRAY_AGG(
            DISTINCT b.current_block_id
        ) AS blocks_impacted_array
    FROM
        blocks_joined A
        LEFT JOIN blocks_impacted b
        ON A.current_block_id = b.current_block_id
)
SELECT
    'blocks' AS test_name,
    min_block,
    max_block,
    min_block_timestamp,
    max_block_timestamp,
    blocks_tested,
    blocks_impacted_count,
    blocks_impacted_array,
    SYSDATE() AS test_timestamp
FROM
    aggregated_data

'''
'''--- models/silver/_observability/silver_observability__blocks_completeness.yml ---
version: 2

models:
  - name: silver_observability__blocks_completeness
    description: |-
      Observability model that queries the blocks table at a designated interval to record and track the completeness of the data.
    tests:
      - dbt_utils.recency:
          datepart: day
          field: test_timestamp
          interval: 1
      - dbt_utils.recency:
          datepart: hours
          field: max_block_timestamp
          interval: 24

    columns:
      - name: TEST_NAME
        description: "{{ doc('test_name') }}"

      - name: MIN_BLOCK
        description: "{{ doc('min_block') }}"

      - name: MAX_BLOCK
        description: "{{ doc('max_block') }}"

      - name: MIN_BLOCK_TIMESTAMP
        description: "{{ doc('min_block_timestamp') }}"

      - name: MAX_BLOCK_TIMESTAMP
        description: "{{ doc('max_block_timestamp') }}"

      - name: BLOCKS_TESTED
        description: "{{ doc('blocks_tested') }}"

      - name: BLOCKS_IMPACTED_COUNT
        description: "{{ doc('blocks_impacted_count') }}"

      - name: BLOCKS_IMPACTED_ARRAY
        description: "{{ doc('blocks_impacted_array') }}"

      - name: TEST_TIMESTAMP
        description: "{{ doc('test_timestamp') }}"

'''
'''--- models/silver/_observability/silver_observability__chunks_completeness.sql ---
-- depends_on: {{ ref('silver__streamline_blocks') }}
{{ config(
    materialized = 'incremental',
    unique_key = 'test_timestamp',
    full_refresh = False,
    tags = ['observability']
) }}

WITH block_chunks_included AS (

    SELECT
        block_id,
        block_timestamp,
        header :chunks_included :: INT AS chunks_included,
        _partition_by_block_number,
        _inserted_timestamp
    FROM
        {{ ref('silver__streamline_blocks') }}
    WHERE
        block_timestamp <= DATEADD('hour', -12, SYSDATE())
{% if is_incremental() %}
AND (
    block_id >= (
        SELECT
            MIN(block_id)
        FROM
            (
                SELECT
                    MIN(block_id) AS block_id
                FROM
                    {{ ref('silver__streamline_blocks') }}
                WHERE
                    block_timestamp BETWEEN DATEADD('hour', -96, SYSDATE())
                    AND DATEADD('hour', -95, SYSDATE())
                UNION
                SELECT
                    MIN(VALUE) - 1 AS block_id
                FROM
                    (
                        SELECT
                            blocks_impacted_array
                        FROM
                            {{ this }}
                            qualify ROW_NUMBER() over (
                                ORDER BY
                                    test_timestamp DESC
                            ) = 1
                    ),
                    LATERAL FLATTEN(
                        input => blocks_impacted_array
                    )
            )
    ) {% if var('OBSERV_FULL_TEST') %}
        OR block_id >= 9820210
    {% endif %}
)
{% endif %}
),
summary_stats AS (

    SELECT
        MIN(block_id) AS min_block,
        MAX(block_id) AS max_block,
        MIN(block_timestamp) AS min_block_timestamp,
        MAX(block_timestamp) AS max_block_timestamp,
        COUNT(1) AS blocks_tested
    FROM
        block_chunks_included
),
chunks_per_block AS (
    SELECT
        block_id,
        MAX(_inserted_timestamp) AS _inserted_timestamp,
        COUNT(
            DISTINCT chunk :header :chunk_hash :: STRING
        ) AS chunk_ct
    FROM
        {{ ref('silver__streamline_shards') }}
    WHERE 
        block_id >= (SELECT min_block FROM summary_stats) 
    AND
        block_id <= (SELECT max_block FROM summary_stats)
    GROUP BY
        1
),
comp AS (
    SELECT
        _partition_by_block_number,
        b.block_id AS bblock_id,
        C.block_id AS cblock_id,
        b.chunks_included,
        C.chunk_ct,
        b._inserted_timestamp AS b_inserted_timestamp,
        C._inserted_timestamp AS c_inserted_timestamp
    FROM
        block_chunks_included b full
        OUTER JOIN chunks_per_block C USING (block_id)
),
missing AS (
    SELECT
        *
    FROM
        comp
    WHERE
        chunks_included > 0
        AND (
            bblock_id IS NULL
            OR cblock_id IS NULL
            OR chunks_included != chunk_ct
        )
        AND b_inserted_timestamp <= SYSDATE() - INTERVAL '1 hour'
        AND c_inserted_timestamp <= SYSDATE() - INTERVAL '1 hour'
    ORDER BY
        1
),
impacted_blocks AS (
    SELECT
        COUNT(1) AS blocks_impacted_count,
        ARRAY_AGG(BBLOCK_ID) within GROUP (
            ORDER BY
                2
        ) AS blocks_impacted_array
    FROM
        missing
)

SELECT
    'chunk' AS test_name,
    min_block,
    max_block,
    min_block_timestamp,
    max_block_timestamp,
    blocks_tested,
    blocks_impacted_count,
    blocks_impacted_array,
    SYSDATE() AS test_timestamp
FROM
    summary_stats
    JOIN impacted_blocks
    ON 1 = 1

'''
'''--- models/silver/_observability/silver_observability__chunks_completeness.yml ---
version: 2

models:
  - name: silver_observability__chunks_completeness
    description: |-
      Observability model that queries the blocks table at a designated interval to record and track the completeness of the data.
    tests:
      - dbt_utils.recency:
          datepart: day
          field: test_timestamp
          interval: 1
      - dbt_utils.recency:
          datepart: hours
          field: max_block_timestamp
          interval: 24

    columns:
      - name: TEST_NAME
        description: "{{ doc('test_name') }}"

      - name: MIN_BLOCK
        description: "{{ doc('min_block') }}"

      - name: MAX_BLOCK
        description: "{{ doc('max_block') }}"

      - name: MIN_BLOCK_TIMESTAMP
        description: "{{ doc('min_block_timestamp') }}"

      - name: MAX_BLOCK_TIMESTAMP
        description: "{{ doc('max_block_timestamp') }}"

      - name: BLOCKS_TESTED
        description: "{{ doc('blocks_tested') }}"

      - name: BLOCKS_IMPACTED_COUNT
        description: "{{ doc('blocks_impacted_count') }}"

      - name: BLOCKS_IMPACTED_ARRAY
        description: "{{ doc('blocks_impacted_array') }}"

      - name: TEST_TIMESTAMP
        description: "{{ doc('test_timestamp') }}"

'''
'''--- models/silver/_observability/silver_observability__logs_completeness.sql ---
{{ config(
    materialized = 'incremental',
    unique_key = 'test_timestamp',
    full_refresh = False,
    tags = ['observability']
) }}

WITH summary_stats AS (

    SELECT
        MIN(block_id) AS min_block,
        MAX(block_id) AS max_block,
        MIN(block_timestamp) AS min_block_timestamp,
        MAX(block_timestamp) AS max_block_timestamp,
        COUNT(1) AS blocks_tested
    FROM
        {{ ref('silver__streamline_blocks') }}
    WHERE
        block_timestamp <= DATEADD('hour', -12, SYSDATE())

{% if is_incremental() %}
AND (
    block_id >= (
        SELECT
            MIN(block_id)
        FROM
            (
                SELECT
                    MIN(block_id) AS block_id
                FROM
                    {{ ref('silver__streamline_blocks') }}
                WHERE
                    block_timestamp BETWEEN DATEADD('hour', -96, SYSDATE())
                    AND DATEADD('hour', -95, SYSDATE())
                UNION
                SELECT
                    MIN(VALUE) - 1 AS block_id
                FROM
                    (
                        SELECT
                            blocks_impacted_array
                        FROM
                            {{ this }}
                            qualify ROW_NUMBER() over (
                                ORDER BY
                                    test_timestamp DESC
                            ) = 1
                    ),
                    LATERAL FLATTEN(
                        input => blocks_impacted_array
                    )
            )
    ) {% if var('OBSERV_FULL_TEST') %}
        OR block_id >= 9820210
    {% endif %}
)
{% endif %}
),
block_range AS (
    SELECT
        _id AS block_id
    FROM
        {{ source(
            'crosschain_silver',
            'number_sequence') 
        }}
    WHERE
        _id BETWEEN (
            SELECT
                min_block
            FROM
                summary_stats
        )
        AND (
            SELECT
                max_block
            FROM
                summary_stats
        )
),
broken_blocks AS (
    SELECT
        DISTINCT block_id as block_id
    FROM
        {{ ref('silver__streamline_receipts_final') }}
        r
        LEFT JOIN {{ ref('silver__logs_s3') }}
        l USING (
            block_id,
            tx_hash
        )
        JOIN block_range USING (block_id)
    WHERE
        l.tx_hash IS NULL
        AND ARRAY_SIZE(
            r.logs
        ) > 0
),
impacted_blocks AS (
    SELECT
        COUNT(1) AS blocks_impacted_count,
        ARRAY_AGG(block_id) within GROUP (
            ORDER BY
                2
        ) AS blocks_impacted_array
    FROM
        broken_blocks
)
SELECT
    'event_logs' AS test_name,
    min_block,
    max_block,
    min_block_timestamp,
    max_block_timestamp,
    blocks_tested,
    blocks_impacted_count,
    blocks_impacted_array,
    SYSDATE() AS test_timestamp
FROM
    summary_stats
    JOIN impacted_blocks
    ON 1 = 1

        
'''
'''--- models/silver/_observability/silver_observability__logs_completeness.yml ---
version: 2

models:
  - name: silver_observability__logs_completeness
    description: |-
      Observability model that queries the blocks table at a designated interval to record and track the completeness of the data.
    tests:
      - dbt_utils.recency:
          datepart: day
          field: test_timestamp
          interval: 1
      - dbt_utils.recency:
          datepart: hours
          field: max_block_timestamp
          interval: 24

    columns:
      - name: TEST_NAME
        description: "{{ doc('test_name') }}"

      - name: MIN_BLOCK
        description: "{{ doc('min_block') }}"

      - name: MAX_BLOCK
        description: "{{ doc('max_block') }}"

      - name: MIN_BLOCK_TIMESTAMP
        description: "{{ doc('min_block_timestamp') }}"

      - name: MAX_BLOCK_TIMESTAMP
        description: "{{ doc('max_block_timestamp') }}"

      - name: BLOCKS_TESTED
        description: "{{ doc('blocks_tested') }}"

      - name: BLOCKS_IMPACTED_COUNT
        description: "{{ doc('blocks_impacted_count') }}"

      - name: BLOCKS_IMPACTED_ARRAY
        description: "{{ doc('blocks_impacted_array') }}"

      - name: TEST_TIMESTAMP
        description: "{{ doc('test_timestamp') }}"

'''
'''--- models/silver/actions/silver__actions_events_addkey_s3.sql ---
{{ config(
  materialized = 'incremental',
  incremental_strategy = 'merge',
  merge_exclude_columns = ["inserted_timestamp"],
  unique_key = 'action_id',
  cluster_by = ['block_timestamp::DATE', '_inserted_timestamp::DATE'],
  tags = ['actions', 'curated']
) }}

{# NOTE - used downstream in Social models, no longer a gold view on just this #}

WITH action_events AS (

  SELECT
    action_id,
    tx_hash,
    block_id,
    block_timestamp,
    action_data,
    _partition_by_block_number,
    _inserted_timestamp,
    modified_timestamp AS _modified_timestamp
  FROM
    {{ ref('silver__actions_events_s3') }}
  WHERE
    action_name = 'AddKey' 
    {% if var("MANUAL_FIX") %}
      AND {{ partition_load_manual('no_buffer') }}
    {% else %}
      {% if var('IS_MIGRATION') %}
        AND {{ incremental_load_filter('_inserted_timestamp') }}
      {% else %}
        AND {{ incremental_load_filter('_modified_timestamp') }}
      {% endif %}
    {% endif %}
),
addkey_events AS (
  SELECT
    action_id,
    tx_hash,
    block_id,
    block_timestamp,
    action_data :access_key :nonce :: NUMBER AS nonce,
    action_data :public_key :: STRING AS public_key,
    action_data :access_key :permission AS permission,
    action_data :access_key :permission :FunctionCall :allowance :: FLOAT AS allowance,
    action_data :access_key :permission :FunctionCall :method_names :: ARRAY AS method_name,
    action_data :access_key :permission :FunctionCall :receiver_id :: STRING AS receiver_id,
    _partition_by_block_number,
    _inserted_timestamp,
    _modified_timestamp
  FROM
    action_events
)
SELECT
  *,
  {{ dbt_utils.generate_surrogate_key(
    ['action_id']
  ) }} AS actions_events_addkey_id,
  SYSDATE() AS inserted_timestamp,
  SYSDATE() AS modified_timestamp,
  '{{ invocation_id }}' AS _invocation_id
FROM
  addkey_events

'''
'''--- models/silver/actions/silver__actions_events_addkey_s3.yml ---
version: 2

models:
  - name: silver__actions_events_addkey_s3
    description: |-
      Deprecting soon - no longer updating.

    columns:
      - name: ACTION_ID
        description: "{{ doc('action_id')}}"

      - name: TX_HASH
        description: "{{ doc('tx_hash')}}"

      - name: BLOCK_ID
        description: "{{ doc('block_id')}}"

      - name: BLOCK_TIMESTAMP
        description: "{{ doc('block_timestamp')}}"

      - name: NONCE
        description: "{{ doc('nonce')}}"

      - name: PUBLIC_KEY
        description: "{{ doc('public_key')}}"

      - name: PERMISSION
        description: "{{ doc('permission')}}"

      - name: ALLOWANCE
        description: "{{ doc('allowance')}}"

      - name: METHOD_NAME
        description: "{{ doc('method_name')}}"

      - name: RECEIVER_ID
        description: "{{ doc('receiver_id')}}"

      - name: _PARTITION_BY_BLOCK_NUMBER
        description: "{{ doc('_partition_by_block_number')}}"

      - name: _INSERTED_TIMESTAMP
        description: "{{ doc('_inserted_timestamp')}}"

      - name: _MODIFIED_TIMESTAMP
        description: "{{ doc('_modified_timestamp')}}"

      - name: actions_events_addkey_id
        description: "{{doc('id')}}"

      - name: inserted_timestamp
        description: "{{doc('inserted_timestamp')}}"

      - name: modified_timestamp
        description: "{{doc('modified_timestamp')}}"

      - name: _invocation_id
        description: "{{doc('invocation_id')}}"

'''
'''--- models/silver/actions/silver__actions_events_function_call_s3.sql ---
{{ config(
  materialized = 'incremental',
  incremental_strategy = 'merge',
  merge_exclude_columns = ["inserted_timestamp"],
  cluster_by = ['block_timestamp::DATE', '_inserted_timestamp::DATE'],
  unique_key = 'action_id',
  tags = ['actions', 'curated']
) }}

WITH action_events AS (

  SELECT
    action_id,
    tx_hash,
    receiver_id,
    predecessor_id,
    signer_id,
    block_id,
    block_timestamp,
    action_name,
    action_data,
    logs,
    receipt_succeeded,
    _partition_by_block_number,
    _inserted_timestamp,
    modified_timestamp AS _modified_timestamp
  FROM
    {{ ref('silver__actions_events_s3') }}
  WHERE
    action_name = 'FunctionCall' 

    {% if var("MANUAL_FIX") %}
      AND {{ partition_load_manual('no_buffer') }}
    {% else %}
      {% if is_incremental() %}
        AND _modified_timestamp >= (
            SELECT
                MAX(_modified_timestamp)
            FROM
                {{ this }}
        )
      {% endif %}
    {% endif %}
),
FINAL AS (
  SELECT
    action_id,
    tx_hash,
    receiver_id,
    predecessor_id,
    signer_id,
    block_id,
    block_timestamp,
    action_name,
    action_data :method_name :: STRING AS method_name,
    COALESCE(
      TRY_PARSE_JSON(TRY_BASE64_DECODE_STRING(action_data :args)),
      action_data :args
    ) AS args,
    action_data :deposit :: NUMBER AS deposit,
    action_data :gas :: NUMBER AS attached_gas,
    logs,
    receipt_succeeded,
    _partition_by_block_number,
    _inserted_timestamp,
    _modified_timestamp
  FROM
    action_events
)
SELECT
  *,
  {{ dbt_utils.generate_surrogate_key(
    ['action_id']
  ) }} AS actions_events_function_call_id,
  SYSDATE() AS inserted_timestamp,
  SYSDATE() AS modified_timestamp,
  '{{ invocation_id }}' AS _invocation_id
FROM
  FINAL

'''
'''--- models/silver/actions/silver__actions_events_function_call_s3.yml ---
version: 2

models:
  - name: silver__actions_events_function_call_s3
    description: |-
      This table extracts all FunctionCall events from actions and decodes the arguments for easy use.

    columns:
      - name: ACTION_ID
        description: "{{ doc('action_id')}}"

      - name: TX_HASH
        description: "{{ doc('tx_hash')}}"
        tests:
          - not_null:
              where: _inserted_timestamp <= current_timestamp - interval '1 hour'

      - name: RECEIVER_ID
        description: "{{ doc('receiver_id')}}"

      - name: PREDECESSOR_ID
        description: "{{ doc('predecessor_id')}}"

      - name: SIGNER_ID
        description: "{{ doc('signer_id')}}"

      - name: BLOCK_ID
        description: "{{ doc('block_id')}}"

      - name: BLOCK_TIMESTAMP
        description: "{{ doc('block_timestamp')}}"
        tests:
          - not_null:
              where: _inserted_timestamp <= current_timestamp - interval '1 hour'

      - name: ACTION_NAME
        description: "{{ doc('action_name')}}"

      - name: METHOD_NAME
        description: "{{ doc('method_name')}}"

      - name: ARGS
        description: "{{ doc('args')}}"

      - name: DEPOSIT
        description: "{{ doc('deposit')}}"

      - name: ATTACHED_GAS
        description: "{{ doc('attached_gas')}}"

      - name: LOGS
        description: "{{ doc('logs')}}"

      - name: RECEIPT_SUCCEEDED
        description: "{{ doc('receipt_succeeded')}}"

      - name: _PARTITION_BY_BLOCK_NUMBER
        description: "{{ doc('_partition_by_block_number')}}"

      - name: _INSERTED_TIMESTAMP
        description: "{{ doc('_inserted_timestamp')}}"

      - name: _MODIFIED_TIMESTAMP
        description: "{{ doc('_modified_timestamp')}}"

      - name: ACTIONS_EVENTS_FUNCTION_CALL_ID
        description: "{{doc('id')}}"

      - name: INSERTED_TIMESTAMP
        description: "{{doc('inserted_timestamp')}}"

      - name: MODIFIED_TIMESTAMP
        description: "{{doc('modified_timestamp')}}"

      - name: _INVOCATION_ID
        description: "{{doc('invocation_id')}}"

'''
'''--- models/silver/actions/silver__actions_events_s3.sql ---
{{ config(
    materialized = 'incremental',
    incremental_strategy = 'merge',
    merge_exclude_columns = ["inserted_timestamp"],
    cluster_by = ['block_timestamp::DATE', '_inserted_timestamp::DATE'],
    unique_key = 'action_id',
    tags = ['actions', 'curated']
) }}

WITH receipts AS (

    SELECT
        tx_hash,
        receipt_object_id,
        receiver_id,
        signer_id,
        block_id,
        block_timestamp,
        chunk_hash,
        logs,
        receipt_actions,
        execution_outcome,
        receipt_succeeded,
        gas_burnt,
        _partition_by_block_number,
        _inserted_timestamp,
        modified_timestamp AS _modified_timestamp
    FROM
        {{ ref('silver__streamline_receipts_final') }}

        {% if var("MANUAL_FIX") %}
        WHERE
            {{ partition_load_manual('no_buffer') }}
        {% else %}
            {% if is_incremental() %}
            WHERE _modified_timestamp >= (
                SELECT
                    MAX(_modified_timestamp)
                FROM
                    {{ this }}
            )
        {% endif %}
        {% endif %}
),
flatten_actions AS (
    SELECT
        tx_hash,
        receipt_object_id,
        receiver_id,
        signer_id,
        block_id,
        block_timestamp,
        chunk_hash,
        logs,
        receipt_actions,
        receipt_actions :predecessor_id :: STRING as predecessor_id,
        receipt_actions :receipt :Action :gas_price :: NUMBER as gas_price,
        execution_outcome,
        gas_burnt,
        execution_outcome :outcome :tokens_burnt :: NUMBER as tokens_burnt,
        VALUE AS action_object,
        INDEX AS action_index,
        receipt_succeeded,
        _partition_by_block_number,
        _inserted_timestamp,
        _modified_timestamp
    FROM
        receipts,
        LATERAL FLATTEN(
            input => receipt_actions :receipt :Action :actions
        )
),
FINAL AS (
    SELECT
        concat_ws(
            '-',
            receipt_object_id,
            action_index
        ) AS action_id,
        block_id,
        block_timestamp,
        tx_hash,
        receipt_object_id,
        chunk_hash,
        predecessor_id,
        receiver_id,
        signer_id,
        action_index,
        key AS action_name,
        TRY_PARSE_JSON(VALUE) AS action_data,
        logs,
        receipt_succeeded,
        gas_price,
        gas_burnt,
        tokens_burnt,
        _partition_by_block_number,
        _inserted_timestamp,
        _modified_timestamp
    FROM
        flatten_actions,
        LATERAL FLATTEN(
            input => action_object
        )
)
SELECT
    *,
    {{ dbt_utils.generate_surrogate_key(
        ['receipt_object_id', 'action_index']
    ) }} AS actions_events_id,
    SYSDATE() AS inserted_timestamp,
    SYSDATE() AS modified_timestamp,
    '{{ invocation_id }}' AS _invocation_id
FROM
    FINAL

'''
'''--- models/silver/actions/silver__actions_events_s3.yml ---
version: 2

models:
  - name: silver__actions_events_s3
    description: |-
      This table extracts all action events from a receipt and stores the argument data under action_data.

    columns:
      - name: ACTION_ID
        description: "{{ doc('action_id')}}"
        tests:
          - unique:
              where: tx_hash != 'J4CZZQrZK6kYPVLkrdbTEpcqhUNZiRxktbMzHviqeGgf'
          - not_null
          
      - name: BLOCK_ID
        description: "{{ doc('block_id')}}"

      - name: BLOCK_TIMESTAMP
        description: "{{ doc('block_timestamp')}}"
        tests:
          - not_null:
              where: _inserted_timestamp <= current_timestamp - interval '1 hour'

      - name: TX_HASH
        description: "{{ doc('tx_hash')}}"
        tests:
          - not_null:
              where: _inserted_timestamp <= current_timestamp - interval '1 hour'
               
      - name: RECEIPT_OBJECT_ID
        description: "{{ doc('receipt_object_id')}}"

      - name: CHUNK_HASH
        description: "{{ doc('chunk_hash')}}"
        tests:
          - not_null:
              where: "block_id not in (34691244, 34691277)"
  
      - name: RECEIVER_ID
        description: "{{ doc('receiver_id')}}"

      - name: PREDECESSOR_ID
        description: "{{ doc('predecessor_id')}}"

      - name: SIGNER_ID
        description: "{{ doc('signer_id')}}"

      - name: ACTION_INDEX
        description: "{{ doc('action_index')}}"
          
      - name: ACTION_NAME
        description: "{{ doc('action_name')}}"
          
      - name: ACTION_DATA
        description: "{{ doc('action_data')}}"

      - name: LOGS
        description: "{{ doc('logs')}}"

      - name: RECEIPT_SUCCEEDED
        description: "{{ doc('receipt_succeeded')}}"

      - name: _PARTITION_BY_BLOCK_NUMBER
        description: "{{ doc('_partition_by_block_number')}}"

      - name: _INSERTED_TIMESTAMP
        description: "{{ doc('_inserted_timestamp')}}"

      - name: _MODIFIED_TIMESTAMP
        description: "{{ doc('_modified_timestamp')}}"

      - name: ACTIONS_EVENTS_ID
        description: "{{doc('id')}}"

      - name: INSERTED_TIMESTAMP
        description: "{{doc('inserted_timestamp')}}"

      - name: MODIFIED_TIMESTAMP
        description: "{{doc('modified_timestamp')}}"

      - name: _INVOCATION_ID
        description: "{{doc('invocation_id')}}"

'''
'''--- models/silver/atlas/silver__atlas_accounts_created.sql ---
{{ config(
    materialized = 'incremental',
    unique_key = 'atlas_account_created_id',
    incremental_strategy = 'merge',
    merge_exclude_columns = ["inserted_timestamp"],
    tags = ['atlas']
) }}

WITH accts AS (

    SELECT
        receiver_id,
        block_timestamp,
        modified_timestamp AS _modified_timestamp
    FROM
        {{ ref('silver__streamline_receipts_final') }}
    WHERE
        receipt_succeeded
        {% if var("MANUAL_FIX") %}
            AND {{ partition_load_manual('no_buffer') }}
        {% else %}
            {% if is_incremental() %}
                AND _modified_timestamp >= (
                    SELECT
                        MAX(_modified_timestamp) - INTERVAL '2 days'
                    FROM
                        {{ this }}
                )
            {% endif %}
        {% endif %}

        qualify ROW_NUMBER() over (
            PARTITION BY receiver_id
            ORDER BY
                block_timestamp
        ) = 1
),
FINAL AS (
    SELECT
        block_timestamp :: DATE AS "DAY",
        COUNT(*) AS wallets_created,
        MAX(_modified_timestamp) AS _modified_timestamp
    FROM
        accts
    GROUP BY
        1
)
SELECT
    day,
    wallets_created,
    _modified_timestamp,
    {{ dbt_utils.generate_surrogate_key(
        ['DAY']
    ) }} AS atlas_account_created_id,
    SYSDATE() AS inserted_timestamp,
    SYSDATE() AS modified_timestamp,
    '{{ invocation_id }}' AS _invocation_id
FROM
    FINAL
WHERE
    DAY IS NOT NULL

'''
'''--- models/silver/atlas/silver__atlas_accounts_created.yml ---
version: 2

models:
  - name: silver__atlas_accounts_created
    description: |-
      Wallet creation on NEAR
    columns:
      - name: atlas_account_created_id
        description: "{{ doc('id')}}"
        tests:
          - not_null
          - unique

      - name: day
        description: "{{ doc('date')}}"
        tests:
          - not_null

      - name: wallets_created
        description: "{{ doc('wallets_created')}}"
        tests:
          - not_null

      - name: inserted_timestamp
        description: "{{doc('inserted_timestamp')}}"
        tests:
          - not_null

      - name: modified_timestamp
        description: "{{doc('modified_timestamp')}}"
        tests:
          - not_null

      - name: _invocation_id
        description: "{{doc('invocation_id')}}"

'''
'''--- models/silver/atlas/silver__atlas_address_first_action.sql ---
{{ config(
    materialized = 'incremental',
    incremental_stratege = 'merge',
    merge_exclude_columns = ["inserted_timestamp"],
    unique_key = 'address',
    post_hook = "ALTER TABLE {{ this }} ADD SEARCH OPTIMIZATION",
    tags = ['atlas']
) }}

WITH txs AS (

    SELECT
        tx_signer AS address,
        block_id,
        block_timestamp,
        tx_hash,
        _partition_by_block_number,
        _inserted_timestamp,
        modified_timestamp AS _modified_timestamp
    FROM
        {{ ref('silver__streamline_transactions_final') }}
    WHERE
        {% if var("MANUAL_FIX") %}
            {{ partition_load_manual('no_buffer') }}
        {% else %}
            {% if var('IS_MIGRATION') %}
                {{ incremental_load_filter('_inserted_timestamp') }}
            {% else %}
                {{ incremental_load_filter('_modified_timestamp') }}
            {% endif %}
        {% endif %}
),
FINAL AS (
    SELECT
        address,
        MIN(block_timestamp) AS first_tx_timestamp,
        MIN(block_id) AS first_tx_block_id,
        MIN(_partition_by_block_number) AS _partition_by_block_number,
        MIN(_inserted_timestamp) AS _inserted_timestamp,
        MIN(_modified_timestamp) AS _modified_timestamp
    FROM
        txs
    GROUP BY
        1
)
SELECT
    {{ dbt_utils.generate_surrogate_key(
        ['address']
    ) }} AS atlas_address_first_action_id,
    address,
    first_tx_timestamp,
    first_tx_block_id,
    _partition_by_block_number,
    _inserted_timestamp,
    _modified_timestamp,
    SYSDATE() AS inserted_timestamp,
    SYSDATE() AS modified_timestamp,
    '{{ invocation_id }}' AS _invocation_id
FROM
    FINAL qualify ROW_NUMBER() over (
        PARTITION BY address
        ORDER BY
            first_tx_timestamp
    ) = 1

'''
'''--- models/silver/atlas/silver__atlas_address_first_action.yml ---
version: 2

models:
  - name: silver__atlas_address_first_action
    description: |-
      Parses transactions table for the block number and timestamp of a wallets first signed transaction.

    columns:
      - name: atlas_address_first_action_id
        description: "{{ doc('id') }}"
        tests:
          - not_null
          - unique

      - name: address
        description: "{{ doc('address') }}"
        tests:
          - not_null
          - unique

      - name: first_tx_timestamp
        description: "{{ doc('block_timestamp')}}"
        tests:
          - not_null

      - name: first_tx_block_id
        description: "{{ doc('block_id') }}"
        tests:
          - not_null

      - name: _partition_by_block_number
        description: "{{ doc('_partition_by_block_number') }}"

      - name: _inserted_timestamp
        description: "{{ doc('_inserted_timestamp') }}"
        tests:
          - name: not_null_silver__atlas_address_first_action_INSERTED_TIMESTAMP_
            test_name: not_null

      - name: _modified_timestamp
        description: "{{ doc('_modified_timestamp') }}"

      - name: inserted_timestamp
        description: "{{ doc('inserted_timestamp') }}"
        tests:
          - not_null

      - name: modified_timestamp
        description: "{{ doc('modified_timestamp') }}"
        tests:
          - not_null

      - name: _invocation_id
        description: "{{ doc('invocation_id') }}"

'''
'''--- models/silver/atlas/silver__atlas_maa.sql ---
{{ config(
    materialized = 'incremental',
    incremental_stratege = 'merge',
    merge_exclude_columns = ["inserted_timestamp"],
    unique_key = 'day',
    tags = ['atlas']
) }}

WITH dates AS (

    SELECT
        date_day AS day
    FROM
        {{ source(
            'crosschain',
            'dim_dates'
        ) }}

{% if is_incremental() %}
WHERE
    date_day > (
        SELECT
            MAX(day)
        FROM
            {{ this }}
    )
    AND date_day < SYSDATE() :: DATE
{% else %}
WHERE
    date_day BETWEEN '2020-07-22'
    AND SYSDATE() :: DATE
{% endif %}
),
signer_first_date AS (
    SELECT
        address,
        first_tx_timestamp
    FROM
        {{ ref('silver__atlas_address_first_action') }}
),
txns AS (
    SELECT
        block_timestamp :: DATE AS day,
        tx_signer,
        first_tx_timestamp,
        _inserted_timestamp
    FROM
        {{ ref('silver__streamline_transactions_final') }}
        t
        LEFT JOIN signer_first_date s
        ON t.tx_signer = s.address

        {% if var("MANUAL_FIX") %}
    WHERE
        {{ partition_load_manual('no_buffer') }}
    {% else %}

{% if is_incremental() %}
WHERE
    block_timestamp :: DATE >= (
        SELECT
            MAX(day)
        FROM
            {{ this }}
    ) - INTERVAL '30 days'
{% endif %}
{% endif %}
),
FINAL AS (
    SELECT
        d.day,
        COUNT(
            DISTINCT tx_signer
        ) AS maa,
        COUNT(
            DISTINCT IFF(
                first_tx_timestamp >= d.day - INTERVAL '30 Days'
                AND first_tx_timestamp < d.day,
                tx_signer,
                NULL
            )
        ) AS new_maas,
        MAX(_inserted_timestamp) AS _inserted_timestamp
    FROM
        dates d
        LEFT JOIN txns t
        ON t.day < d.day
        AND t.day >= d.day - INTERVAL '30 days'
    WHERE
        d.day != SYSDATE() :: DATE
    GROUP BY
        1
)
SELECT
    {{ dbt_utils.generate_surrogate_key(
        ['day']
    ) }} AS atlas_maa_id,
    day,
    maa,
    new_maas,
    maa - new_maas AS returning_maas,
    _inserted_timestamp,
    SYSDATE() AS inserted_timestamp,
    SYSDATE() AS modified_timestamp,
    '{{ invocation_id }}' AS _invocation_id
FROM
    FINAL

'''
'''--- models/silver/atlas/silver__atlas_maa.yml ---
version: 2

models:
  - name: silver__atlas_maa
    description: |-
      Monthly Active Accounts (wallets) on NEAR, including new and returning wallets, calculated over a rolling 30 day window. An active account, here, is defined as the signing of at least one transaction.

    columns:
      - name: atlas_maa_id
        description: "{{ doc('id') }}"
        tests:
          - not_null
          - unique

      - name: day
        description: "{{ doc('active_day') }}"
        tests:
          - not_null
          - unique

      - name: maa
        description: "{{ doc('maa')}}"
        tests:
          - not_null

      - name: new_maas
        description: "{{ doc('new_maas') }}"
        tests:
          - not_null

      - name: returning_maas
        description: "{{ doc('returning_maas') }}"
        tests:
          - not_null

      - name: _inserted_timestamp
        description: "{{ doc('_inserted_timestamp') }}"
        tests:
          - name: not_null_silver__atlas_near_maa_INSERTED_TIMESTAMP_
            test_name: not_null

      - name: inserted_timestamp
        description: "{{ doc('inserted_timestamp') }}"
        tests:
          - not_null

      - name: modified_timestamp
        description: "{{ doc('modified_timestamp') }}"
        tests:
          - not_null

      - name: _invocation_id
        description: "{{ doc('invocation_id') }}"

'''
'''--- models/silver/atlas/silver__atlas_nft_30_trailing.sql ---
{{ config(
    materialized = 'incremental',
    unique_key = 'atlas_nft_30_trailing_id',
    incremental_strategy = "merge",
    merge_exclude_columns = ["inserted_timestamp"],
    tags = ['atlas']
) }}

WITH date_range AS (

    SELECT
        date_day AS DAY
    FROM
        {{ ref('silver__dates') }}
    WHERE

{% if is_incremental() %}
date_day >= SYSDATE() - INTERVAL '3 DAY'
{% else %}
    date_day >= '2021-01-01' -- first day of data
{% endif %}
AND date_day <= SYSDATE() :: DATE
),
FINAL AS (
    SELECT
        d.day AS DAY,
        COUNT(
            t.tx_hash
        ) AS txns
    FROM
        date_range d
        LEFT JOIN {{ ref('silver__atlas_nft_transactions') }}
        t
        ON t.day BETWEEN d.day - INTERVAL '29 day'
        AND d.day
    GROUP BY
        d.day
)
SELECT
    {{ dbt_utils.generate_surrogate_key(
        ['day']
    ) }} AS atlas_nft_30_trailing_id,
    DAY,
    txns,
    SYSDATE() AS inserted_timestamp,
    SYSDATE() AS modified_timestamp,
    '{{ invocation_id }}' AS _invocation_id
FROM
    FINAL

'''
'''--- models/silver/atlas/silver__atlas_nft_30_trailing.yml ---
version: 2

models:
  - name: silver__atlas_nft_30_trailing
    description: |-
      This incremental dbt model generates a summary of NFT transactions from the 'silver__atlas_nft_transactions' table. It provides a daily count of transactions, accounting for a 30-day lookback period for each day within the specified date range.

    columns:
      - name: atlas_nft_30_trailing_id
        description: "{{ doc('id')}}"
        tests:
          - not_null
          - unique

      - name: day
        description: "{{ doc('date')}}"
        tests:
          - not_null
          - unique
      - name: txns
        description: "{{ doc('tx_count')}}"
        tests:
          - not_null

      - name: inserted_timestamp
        description: "{{doc('inserted_timestamp')}}"
        tests:
          - not_null

      - name: modified_timestamp
        description: "{{doc('modified_timestamp')}}"
        tests:
          - not_null

      - name: _invocation_id
        description: "{{doc('invocation_id')}}"

'''
'''--- models/silver/atlas/silver__atlas_nft_detailed.sql ---
{{ config(
    materialized = 'table',
    unique_key = 'atlas_nft_detailed_id',
    tags = ['atlas']
) }}

WITH nft_data AS (

    SELECT
        *
    FROM
        {{ ref('silver__atlas_nft_transactions') }}
)
SELECT
    {{ dbt_utils.generate_surrogate_key(
        ['DAY', 'receiver_id']
    ) }} AS atlas_nft_detailed_id,
    DAY,
    receiver_id,
    COUNT(
        DISTINCT token_id
    ) AS tokens,
    COUNT(
        CASE
            WHEN method_name = 'nft_transfer' THEN tx_hash
        END
    ) AS all_transfers,
    COUNT(
        DISTINCT owner
    ) AS owners,
    COUNT(*) AS transactions,
    COUNT(
        CASE
            WHEN method_name != 'nft_transfer' THEN tx_hash
        END
    ) AS mints,
    SYSDATE() AS inserted_timestamp,
    SYSDATE() AS modified_timestamp,
    '{{ invocation_id }}' AS _invocation_id,
    MAX(_inserted_timestamp) AS _inserted_timestamp
FROM
    nft_data
GROUP BY
    1,
    2,
    3
ORDER BY
    4 DESC

'''
'''--- models/silver/atlas/silver__atlas_nft_detailed.yml ---
version: 2

models:
  - name: silver__atlas_nft_detailed
    description: |-
      This is an incremental dbt model that gives an overview of NFT transactions in NEAR.

columns:
  - name: atlas_nft_detailed_id
    description: "{{ doc('id')}}"
    tests:
      - not_null
      - unique

  - name: day
    description: "{{ doc('date')}}"
    tests:
      - not_null

  - name: receiver_id
    description: "The identifier of the receiver in the NFT transaction."
    tests:
      - not_null

  - name: tokens
    description: "The count of unique tokens transferred to the receiver on the given day."
    tests:
      - not_null

  - name: all_transfers
    description: "The total number of 'nft_transfer' method transactions that occurred."
    tests:
      - not_null

  - name: owners
    description: "The count of distinct owners who have interacted with the NFT."
    tests:
      - not_null

  - name: transactions
    description: "{{ doc('tx_count')}}"
    tests:
      - not_null

  - name: mints
    description: "The count of transactions where the 'method_name' is not 'nft_transfer', indicating minting actions."
    tests:
      - not_null

  - name: inserted_timestamp
    description: "{{doc('inserted_timestamp')}}"
    tests:
      - not_null

  - name: modified_timestamp
    description: "{{doc('modified_timestamp')}}"
    tests:
      - not_null

  - name: _invocation_id
    description: "{{doc('invocation_id')}}"

'''
'''--- models/silver/atlas/silver__atlas_nft_table.sql ---
{{ config(
  materialized = 'table',
  unique_key = 'atlas_nft_table_id',
  tags = ['atlas']
) }}

WITH nft_data AS (

  SELECT
    *
  FROM
    {{ ref('silver__atlas_nft_transactions') }}
)
SELECT
  {{ dbt_utils.generate_surrogate_key(
    ['receiver_id']
  ) }} AS atlas_nft_table_id,
  receiver_id,
  COUNT(
    DISTINCT token_id
  ) AS tokens,
  COUNT(
    CASE
      WHEN method_name = 'nft_transfer'
      AND DAY >= (SYSDATE() :: DATE - INTERVAL '1 day') THEN tx_hash END
    ) AS transfers_24h,
    COUNT(
      CASE
        WHEN method_name = 'nft_transfer'
        AND DAY >= (SYSDATE() :: DATE - INTERVAL '3 day') THEN tx_hash END
      ) AS transfers_3d,
      COUNT(
        CASE
          WHEN method_name = 'nft_transfer' THEN tx_hash
        END
      ) AS all_transfers,
      COUNT(
        DISTINCT owner
      ) AS owners,
      COUNT(*) AS transactions,
      COUNT(
        CASE
          WHEN method_name != 'nft_transfer' THEN tx_hash
        END
      ) AS mints,
      SYSDATE() AS inserted_timestamp,
      SYSDATE() AS modified_timestamp,
      '{{ invocation_id }}' AS _invocation_id
      FROM
        nft_data
      GROUP BY
        1,
        2
      ORDER BY
        3 DESC

'''
'''--- models/silver/atlas/silver__atlas_nft_table.yml ---
version: 2

models:
  - name: silver__atlas_nft_table
    description: |-
      This view model provides a breakdown of NFT transaction activities by receiver_id. It includes counts of unique tokens, transfers within the last 24 hours and 3 days, all transfers, unique owners, total transactions, and minting events.
      
    columns:
      - name: atlas_nft_table_id
        description: "{ { doc('id')}}"
        tests:
          - unique
          - not_null

      - name: receiver_id
        description: "{ { doc('receiver_id')}}"
        tests:
          - not_null

      - name: tokens
        description: "The count of unique tokens that have been received by the receiver_id."
        tests:
          - not_null

      - name: transfers_24h
        description: "The count of 'nft_transfer' transactions that occurred in the last 24 hours."
        tests:
          - not_null

      - name: transfers_3d
        description: "The count of 'nft_transfer' transactions that occurred in the last 3 days."
        tests:
          - not_null

      - name: all_transfers
        description: "The total count of 'nft_transfer' transactions."
        tests:
          - not_null

      - name: owners
        description: "The count of distinct owners that have interacted with the receiver's tokens."
        tests:
          - not_null

      - name: transactions
        description: "{{ doc('tx_count')}}"
        tests:
          - not_null

      - name: mints
        description: "The count of transactions where the method_name indicates a minting event rather than a transfer."
        tests:
          - not_null

      - name: inserted_timestamp
        description: "{{doc('inserted_timestamp')}}"
        tests:
          - not_null

      - name: modified_timestamp
        description: "{{doc('modified_timestamp')}}"
        tests:
          - not_null

      - name: _invocation_id
        description: "{{doc('invocation_id')}}"

'''
'''--- models/silver/atlas/silver__atlas_nft_transactions.sql ---
{{ config(
    materialized = "incremental",
    cluster_by = ["day"],
    unique_key = "atlas_nft_transactions_id",
    merge_exclude_columns = ["inserted_timestamp"],
    incremental_strategy = "merge",
    tags = ['atlas']
) }}

WITH nft_mints AS (

    SELECT
        block_timestamp :: DATE AS DAY,
        receipt_object_id,
        tx_hash,
        method_name,
        receiver_id,
        signer_id,
        owner_id AS owner,
        token_id,
        _partition_by_block_number,
        _inserted_timestamp,
        modified_timestamp AS _modified_timestamp
    FROM
        {{ ref('silver__standard_nft_mint_s3') }}
    WHERE
        {% if var("MANUAL_FIX") %}
            {{ partition_load_manual('no_buffer') }}
        {% else %}
            {% if var('IS_MIGRATION') %}
                {{ incremental_load_filter('_inserted_timestamp') }}
            {% else %}
                {{ incremental_load_filter('_modified_timestamp') }}
            {% endif %}
        {% endif %}
),
nft_transfers AS (
    SELECT
        block_timestamp :: DATE AS DAY,
        SPLIT(
            action_id,
            '-'
        ) [0] :: STRING AS receipt_object_id,
        tx_hash,
        method_name,
        receiver_id,
        signer_id,
        args ['receiver_id'] AS owner,
        args ['token_id'] AS token_id,
        _partition_by_block_number,
        _inserted_timestamp,
        modified_timestamp AS _modified_timestamp
    FROM
        {{ ref('silver__actions_events_function_call_s3') }}
    WHERE
        method_name = 'nft_transfer'
        AND {% if var("MANUAL_FIX") %}
            {{ partition_load_manual('no_buffer') }}
        {% else %}
            {% if var('IS_MIGRATION') %}
                {{ incremental_load_filter('_inserted_timestamp') }}
            {% else %}
                {{ incremental_load_filter('_modified_timestamp') }}
            {% endif %}
        {% endif %}
),
unioned_nft_data AS (
    SELECT
        *
    FROM
        nft_mints
    UNION ALL
    SELECT
        *
    FROM
        nft_transfers
)
SELECT
    {{ dbt_utils.generate_surrogate_key(
        ['receipt_object_id', 'method_name', 'token_id', 'owner']
    ) }} AS atlas_nft_transactions_id,
    DAY,
    tx_hash,
    method_name,
    receiver_id,
    signer_id,
    owner,
    token_id,
    SYSDATE() AS inserted_timestamp,
    SYSDATE() AS modified_timestamp,
    '{{ invocation_id }}' AS _invocation_id,
    _partition_by_block_number,
    _inserted_timestamp,
    _modified_timestamp
FROM
    unioned_nft_data
WHERE
    -- failed receipts may have unparsable base64 FunctionCall args
    token_id IS NOT NULL
    AND owner IS NOT NULL 
qualify ROW_NUMBER() over (
    PARTITION BY atlas_nft_transactions_id
    ORDER BY
        _inserted_timestamp DESC
) = 1

'''
'''--- models/silver/atlas/silver__atlas_nft_transactions.yml ---
version: 2

models:
  - name: silver__atlas_nft_transactions
    description: |-
      This incremental dbt model unifies NFT minting and transfer data into a single view, providing a comprehensive look at NFT activities. It captures daily activities by transaction hash, method name, receiver ID, signer ID, owner, and token ID.
    tests:
      - dbt_utils.recency:
          datepart: day
          field: _inserted_timestamp
          interval: 1

    columns:
      - name: atlas_nft_transactions_id
        description: "{{doc('id')}}"
        tests:
          - unique
          - not_null

      - name: day
        description: "{{doc('date')}}"
        tests:
          - not_null

      - name: tx_hash
        description: "{{doc('tx_hash')}}"
        tests:
          - not_null

      - name: method_name
        description: "{{doc('method_name')}}"
        tests:
          - not_null

      - name: receiver_id
        description: "{{doc('receiver_id')}}"
        tests:
          - not_null

      - name: signer_id
        description: "{{doc('signer_id')}}"
        tests:
          - not_null

      - name: owner
        description: "{{doc('owner')}}"
        tests:
          - not_null

      - name: token_id
        description: "{{doc('token_id')}}"
        tests:
          - not_null

      - name: inserted_timestamp
        description: "{{doc('inserted_timestamp')}}"
        tests:
          - not_null

      - name: modified_timestamp
        description: "{{doc('modified_timestamp')}}"
        tests:
          - not_null

      - name: _invocation_id
        description: "{{doc('invocation_id')}}"

      - name: _partition_by_block_number
        description: "{{doc('_partition_by_block_number')}}"

      - name: _inserted_timestamp
        description: "{{doc('_inserted_timestamp')}}"
        tests:
          - not_null

      - name: _modified_timestamp
        description: "{{doc('_modified_timestamp')}}"
'''
'''--- models/silver/atlas/supply/README.md ---
# NEAR Daily Supply
The set of models in this folder calculate the total supply of NEAR, derived from a model originally built by the Foundation. The composite parts of the below query (locked staked, locked unstaked, staked) have been segmented into separate sql models and are combined in `silver__atlas_supply.sql`. The model `silver__atlas_supply_daily_staked_supply.sql` has been replaced with an existing model in the Flipside project `silver__pool_balance_daily`, which follows a similar mechanic of extracting staked balance per pool, per day, from the logs emitted by staking actions on-chain.  

### Original SQL
[Link to Data Studio Query by dweinstein13](https://flipsidecrypto.xyz/dweinstein33/q/u29te7T8c36t/ad---total-supply-atlas)  

```sql
 WITH

lockup_receipts AS (
    SELECT fr.tx_hash
         , fr.block_timestamp
         , fr.actions:predecessor_id::string AS predecessor_id
         , fr.receiver_id
         , fr.actions
         , OBJECT_KEYS(fr.status_value)[0]::string AS status
         , fr.logs
    
    FROM near.core.fact_receipts AS fr
    WHERE fr.receiver_id LIKE '%.lockup.near'
      AND status != 'Failure'
),

daily_lockup_locked_balances AS (
    WITH

    -- new lockup contract created
    new_lockup_txs AS (
        SELECT lr.tx_hash
             , lr.block_timestamp
             , lr.receiver_id AS lockup_account_id
        FROM lockup_receipts AS lr,
            LATERAL FLATTEN( input => lr.actions:receipt:Action:actions )
        WHERE value:FunctionCall:method_name::string = 'new'
    ),
    
    
    -- vesting is stopped by the Foundation
    terminate_vesting_txs AS (
        SELECT lr.tx_hash
             , lr.block_timestamp
             , lr.receiver_id AS lockup_account_id
             , split(lr.logs[0], 'unvested balance is ')[1]::bigint / 1e24 AS unvested_balance
        FROM lockup_receipts AS lr,
            LATERAL FLATTEN( input => lr.actions:receipt:Action:actions )
        WHERE value:FunctionCall:method_name::string = 'terminate_vesting'
    ),
    
    
    terminate_vesting_txs_with_vesting_schedule AS (
        SELECT tv.*
             , fc.args:vesting_schedule_with_salt:vesting_schedule AS vesting_schedule
    
        FROM terminate_vesting_txs AS tv
            LEFT JOIN near.core.fact_actions_events_function_call AS fc
                ON fc.tx_hash = tv.tx_hash
                AND fc.method_name = 'terminate_vesting'
    
        QUALIFY row_number() OVER (partition by tv.tx_hash order by tv.block_timestamp) = 1  -- dedupe
    ),
    
    
    -- unvested tokens are withdrawn (effectively unlocked into circulating supply)
    termination_withdraw_txs AS (
        SELECT lr.tx_hash
             , lr.block_timestamp
             , lr.receiver_id AS lockup_account_id
             , split(split(lr.logs[0], ' of terminated unvested balance')[0], 'Withdrawing ')[1]::bigint / 1e24 AS withdrawn_amount
        FROM lockup_receipts AS lr,
            LATERAL FLATTEN( input => lr.actions:receipt:Action:actions )
        WHERE value:FunctionCall:method_name::string = 'termination_withdraw'
     -- Simplify logic -> get only first termination withdrawal
        -- QUALIFY row_number() OVER (partition by lockup_account_id order by block_timestamp) = 1
    ),
    
    
    daily_termination_withdrawn_amount AS (
        SELECT lockup_account_id
             , block_timestamp::date AS utc_date
             , sum(withdrawn_amount) AS withdrawn_amount
        FROM termination_withdraw_txs
        GROUP BY 1,2
    ),
    
    
    -- lockup amounts
    deposits AS (
        SELECT lr.tx_hash
             , lr.block_timestamp
             , value:Transfer:deposit::bigint / 1e24 AS deposit_amount
        FROM lockup_receipts AS lr,
            LATERAL FLATTEN( input => lr.actions:receipt:Action:actions )
        WHERE OBJECT_KEYS(value:Transfer)[0]::string = 'deposit'
    ),
    
    
    lockup_contracts AS (
        SELECT lcr.tx_hash
             , lcr.block_timestamp
             , lcr.lockup_account_id
             , fc1.args:lockup_duration::bigint AS input_lockup_duration_ns
             , fc1.args:lockup_timestamp::bigint AS input_lockup_timestamp_epoch
             , fc1.args:owner_account_id::string AS owner_account_id
             , fc1.args:release_duration::bigint AS input_release_duration_ns
             , coalesce(tv.vesting_schedule, fc1.args:vesting_schedule:VestingSchedule) AS vesting_schedule_
             , vesting_schedule_:cliff_timestamp::bigint AS vesting_cliff_timestamp_epoch
             , vesting_schedule_:start_timestamp::bigint AS vesting_start_timestamp_epoch
             , vesting_schedule_:end_timestamp::bigint AS vesting_end_timestamp_epoch
             , coalesce( fc1.args:transfers_information:TransfersEnabled:transfers_timestamp::bigint, 
                         1602614338293769340 ) AS transfers_enabled_timestamp_epoch
             , d.deposit_amount
    
             , tv.block_timestamp AS terminate_vesting_timestamp
             , tv.unvested_balance AS termination_unvested_amount
    
             , tw.block_timestamp AS termination_withdraw_timestamp
             , tw.withdrawn_amount AS termination_withdrawn_amount
    
             , (CASE WHEN OBJECT_KEYS(fc1.args:vesting_schedule)[0]::string = 'VestingHash'
                     THEN True ELSE False END) AS is_private_vesting
    
        FROM new_lockup_txs AS lcr
            LEFT JOIN near.core.fact_actions_events_function_call AS fc1
                ON fc1.tx_hash = lcr.tx_hash
                AND fc1.method_name = 'new'
    
            LEFT JOIN deposits AS d
                ON d.tx_hash = lcr.tx_hash
    
            LEFT JOIN terminate_vesting_txs_with_vesting_schedule AS tv
                ON tv.lockup_account_id = lcr.lockup_account_id
    
            LEFT JOIN termination_withdraw_txs AS tw
                ON tw.lockup_account_id = lcr.lockup_account_id
    
        WHERE lcr.tx_hash IN (SELECT tx_hash FROM new_lockup_txs)
          AND d.deposit_amount > 0
    ),
    
    
    lockup_contracts__parsed AS (
        SELECT lockup_account_id
            -- the number of times the same lockup account ID has been used (used as part of lockup unique identifier)
             , row_number() OVER (partition by lockup_account_id order by block_timestamp) AS lockup_index
             , owner_account_id
             , deposit_amount AS lockup_amount
    
            -- timestamp when tokens were locked (lock start)
             , block_timestamp AS deposit_timestamp
    
            -- timestamp when transfers were enabled in the blockchain (default reference when lockup_timestamp is null)
             , to_timestamp(transfers_enabled_timestamp_epoch, 9) AS transfers_enabled_timestamp
    
            -- timestamp when tokens start unlocking (explicit parameter)
             , to_timestamp(input_lockup_timestamp_epoch, 9) AS input_lockup_timestamp
    
            -- if lockup_timestamp is null, calculate unlock start from lockup duration
             , timestampadd(nanoseconds, input_lockup_duration_ns, transfers_enabled_timestamp) AS calculated_lockup_timestamp
    
            -- lockup mechanism
             , input_lockup_duration_ns
             , input_release_duration_ns
    
            -- Max between input and calculated lockup timestamp
             , (CASE WHEN input_lockup_timestamp IS NOT NULL
                     THEN greatest(input_lockup_timestamp, calculated_lockup_timestamp)
                     ELSE calculated_lockup_timestamp END) AS lockup_timestamp
    
            -- If release_duration is not provided, tokens are immediately unlocked
             , (CASE WHEN input_release_duration_ns IS NOT NULL
                     THEN timestampadd(nanosecond, input_release_duration_ns, lockup_timestamp)  -- linear release if release_duration is provided, else full unlock
                     ELSE lockup_timestamp END) AS lockup_end_timestamp
    
            -- vesting mechanism
             , is_private_vesting
             , to_timestamp(vesting_start_timestamp_epoch, 9) AS vesting_start_timestamp
             , to_timestamp(vesting_end_timestamp_epoch, 9) AS vesting_end_timestamp
             , to_timestamp(vesting_cliff_timestamp_epoch, 9) AS vesting_cliff_timestamp
    
            -- vesting termination
             , terminate_vesting_timestamp
             , termination_unvested_amount
             , termination_withdraw_timestamp
             , termination_withdrawn_amount
    
             , tx_hash AS _tx_hash
    
             , (CASE WHEN lockup_timestamp IS NOT NULL AND vesting_start_timestamp IS NULL
                     THEN least(deposit_timestamp, lockup_timestamp)
                     WHEN lockup_timestamp IS NULL AND vesting_start_timestamp IS NOT NULL
                     THEN least(deposit_timestamp, vesting_start_timestamp)
                     ELSE least(deposit_timestamp, lockup_timestamp, vesting_start_timestamp) END)::date AS _lockup_start_date
    
             , (CASE WHEN lockup_end_timestamp IS NOT NULL AND vesting_end_timestamp IS NULL
                     THEN lockup_end_timestamp
                     WHEN lockup_end_timestamp IS NULL AND vesting_end_timestamp IS NOT NULL
                     THEN vesting_end_timestamp
                     ELSE greatest(lockup_end_timestamp, vesting_end_timestamp) END)::date AS _lockup_end_date
    
        FROM lockup_contracts
    ),
    
    
    lockup_contracts_daily_balance__prep_1 AS (
        WITH dates AS ( SELECT DISTINCT dateadd(day, -seq4(), CURRENT_DATE) AS utc_date
                        FROM TABLE(GENERATOR(rowcount => 10000))
                        WHERE utc_date BETWEEN '2020-01-01' AND CURRENT_DATE )
    
        SELECT lc.lockup_account_id
             , lc.lockup_index
             , lc.owner_account_id
    
             , d.utc_date
             , d.utc_date + interval '1 day' - interval '1 nanosecond' AS block_timestamp  -- End of day block timestamp
    
             , lc.lockup_amount
             , lc.deposit_timestamp
    
            -- Lockup logic
             , lc.lockup_timestamp
             , lc.lockup_end_timestamp
             , greatest(0, timestampdiff(nanosecond, block_timestamp, lockup_end_timestamp)) AS lockup_time_left_ns
             , (CASE WHEN block_timestamp >= lockup_timestamp
                     THEN (CASE WHEN input_release_duration_ns > 0
                                THEN (CASE WHEN block_timestamp >= lockup_end_timestamp
                                           THEN 0  -- everything is released
                                           ELSE lockup_amount * lockup_time_left_ns / input_release_duration_ns
                                           END)
                                ELSE 0 END)
                     ELSE lockup_amount  -- The entire balance is still locked before the lockup timestamp
                     END) AS unreleased_amount
    
            -- Vesting logic
             , lc.vesting_start_timestamp
             , lc.vesting_cliff_timestamp
             , lc.vesting_end_timestamp
             , lc.terminate_vesting_timestamp
             , lc.termination_unvested_amount
             , greatest(0, timestampdiff(nanosecond, block_timestamp, vesting_end_timestamp)) AS vesting_time_left_ns
             , timestampdiff(nanosecond, vesting_start_timestamp, vesting_end_timestamp) AS vesting_total_time_ns
    
        FROM lockup_contracts__parsed AS lc, dates AS d
        WHERE d.utc_date BETWEEN lc._lockup_start_date
                             AND lc._lockup_end_date
    ),
    
    
    lockup_contracts_daily_balance__prep_2 AS (
        SELECT lc.*
             , sum(coalesce(dtw.withdrawn_amount, 0))
                    OVER (partition by lc.lockup_account_id, lc.lockup_index
                              order by lc.utc_date
                              rows between unbounded preceding
                                       and current row) AS termination_withdrawn_amount
        
        FROM lockup_contracts_daily_balance__prep_1 AS lc
            LEFT JOIN daily_termination_withdrawn_amount AS dtw
                ON dtw.lockup_account_id = lc.lockup_account_id
                AND dtw.utc_date = lc.utc_date
    
    ),
    
    
    lockup_contracts_daily_balance AS (
        SELECT lc.*
    
            -- Vesting logic
    
            -- Not 100% accurate due to private vesting lockups (unknown/hidden vesting parameters)
             , (CASE WHEN block_timestamp >= terminate_vesting_timestamp
                     THEN termination_unvested_amount - termination_withdrawn_amount
                     ELSE (CASE WHEN block_timestamp < vesting_cliff_timestamp
                                THEN lockup_amount  -- Before the cliff, nothing is vested
                                WHEN block_timestamp >= vesting_end_timestamp
                                THEN 0  -- After the end, everything is vested
                                ELSE lockup_amount * vesting_time_left_ns / vesting_total_time_ns
                                END)
                     END) AS unvested_amount
    
            -- Combined logic
             , greatest(unreleased_amount - termination_withdrawn_amount, coalesce(unvested_amount, 0)) AS locked_amount
    
             , locked_amount - coalesce(lag(locked_amount) OVER (partition by lc.lockup_account_id, lc.lockup_index order by lc.utc_date), 0) AS unlocked_amount_today
    
        FROM lockup_contracts_daily_balance__prep_2 AS lc
    )

    SELECT * FROM lockup_contracts_daily_balance
),

daily_lockup_staking_balances AS (
    WITH

    lockup_staking_logs AS (
        SELECT lr.tx_hash
             , lr.block_timestamp
             , value:FunctionCall:method_name::string AS method_name
             , lr.receiver_id AS lockup_account_id
             , (CASE method_name
                    WHEN 'stake'
                    THEN split(split(lr.logs[0], ' at the staking pool')[0], 'Staking ')[1]::bigint / 1e24
                    
                    WHEN 'deposit_and_stake'
                    THEN split(split(lr.logs[0], ' to the staking pool')[0], 'Depositing and staking ')[1]::bigint / 1e24
    
                    WHEN 'unstake'
                    THEN split(split(lr.logs[0], ' from the staking pool')[0], 'Unstaking ')[1]::bigint / 1e24
    
                    END) AS amount
    
             , lr.logs
    
        FROM lockup_receipts AS lr,
            LATERAL FLATTEN( input => lr.actions:receipt:Action:actions )
        WHERE method_name IN ('stake','deposit_and_stake',
                              'unstake','unstake_all')
    ),
    
    
    daily_staking_stats AS (
        SELECT lockup_account_id
             , block_timestamp::date AS utc_date
             , sum(CASE WHEN method_name IN ('stake','deposit_and_stake') THEN amount ELSE 0 END) AS staked_amount_
             , sum(CASE WHEN method_name IN ('unstake') THEN amount ELSE 0 END) AS unstaked_amount_
             , (CASE WHEN count(CASE WHEN method_name = 'unstake_all' THEN tx_hash ELSE NULL END) > 0
                     THEN True ELSE False END) AS unstaked_all
        FROM lockup_staking_logs
        GROUP BY 1,2
    ),
    
    
    lockup_stakers AS (
        SELECT lockup_account_id
             , min(block_timestamp)::date AS start_date
        FROM lockup_staking_logs
        GROUP BY 1
    ),
    
    
    lockup_stakers_daily_balances__prep_1 AS (
        WITH dates AS ( SELECT DISTINCT dateadd(day, -seq4(), CURRENT_DATE) AS utc_date
                        FROM TABLE(GENERATOR(rowcount => 10000))
                        WHERE utc_date BETWEEN '2020-09-01' AND CURRENT_DATE )
    
        SELECT ls.lockup_account_id
             , d.utc_date
    
        FROM lockup_stakers AS ls, dates AS d
        WHERE d.utc_date >= ls.start_date
    ),
    
    
    lockup_stakers_daily_balances__prep_2 AS (
        SELECT d.lockup_account_id
             , d.utc_date
             , coalesce(dss.staked_amount_, 0) AS staked_amount
             , coalesce(dss.unstaked_amount_, 0) AS unstaked_amount
             , dss.unstaked_all
             , sum(CASE WHEN dss.unstaked_all = True THEN 1 ELSE 0 END)
                  OVER (partition by d.lockup_account_id
                        order by d.utc_date
                        rows between unbounded preceding
                                 and current row) AS _unstake_counter
    
        FROM lockup_stakers_daily_balances__prep_1 AS d
            LEFT JOIN daily_staking_stats AS dss
                ON dss.lockup_account_id = d.lockup_account_id
                AND dss.utc_date = d.utc_date
    ),
    
    
    lockup_stakers_daily_balances__prep_3 AS (
        SELECT *
             , coalesce(lag(_unstake_counter) 
                  OVER (partition by lockup_account_id
                            order by utc_date)
               , 0) AS staking_period_index
        FROM lockup_stakers_daily_balances__prep_2
    ),
    
    
    lockup_stakers_daily_balances__prep_4 AS (
        SELECT *
             , sum(staked_amount - unstaked_amount) 
                  OVER (partition by lockup_account_id, staking_period_index
                            order by utc_date
                            rows between unbounded preceding
                                     and current row) AS _cumulative_staked_amount
    
             , (CASE WHEN unstaked_all = True THEN 0 ELSE _cumulative_staked_amount END) AS staked_balance
        FROM lockup_stakers_daily_balances__prep_3
    ),
    
    
    lockup_stakers_daily_balances AS (
        SELECT lockup_account_id
             , utc_date
             , staked_balance
        FROM lockup_stakers_daily_balances__prep_4
    )
    
    
    SELECT * FROM lockup_stakers_daily_balances
),

daily_lockup_locked_and_staking_balances AS (
    SELECT l.lockup_account_id
         , l.utc_date
         , l.locked_amount
         , coalesce(s.staked_balance, 0) AS staked_amount
         , least(staked_amount, locked_amount) AS locked_and_staked_amount

    FROM daily_lockup_locked_balances AS l
        LEFT JOIN daily_lockup_staking_balances AS s
            ON s.lockup_account_id = l.lockup_account_id
            AND s.utc_date = l.utc_date
),

daily_locked_and_staked_supply AS (
    SELECT utc_date
         , sum(locked_amount) AS total_locked_supply
         , sum(locked_and_staked_amount) AS locked_and_staked_supply

    FROM daily_lockup_locked_and_staking_balances
    GROUP BY 1
),

daily_staked_supply AS (
    WITH
    
    dim_epochs AS (
     	SELECT epoch_id
      		 , min(block_id) AS min_block_id
      		 , max(block_id) AS max_block_id
      		 , count(*) AS blocks
      		 , count(distinct block_author) AS block_producers
      		 , min(block_timestamp) AS start_time
      		 , max(block_timestamp) AS end_time
      		 , max(total_supply) / 1e24 AS total_near_supply
      		 , row_number() OVER (order by min_block_id asc) - 1 + 900 AS epoch_num
      
      	FROM near.core.fact_blocks AS b
      	GROUP BY 1
    ),
    
    
    staking_actions AS (
      	SELECT r.tx_hash
          	 , r.block_timestamp
          	 , r.receiver_id AS validator_address
          	 , replace(split(l.value::string, ': Contract received total')[0], 'Epoch ', '')::integer AS epoch_num
          	 , split(split(l.value::string, 'New total staked balance is ')[1], '. Total number of shares')[0]::bigint / 1e24 AS staked_balance
          
        FROM near.core.fact_receipts AS r
      	   , lateral flatten( input => r.logs ) AS l
      
        WHERE ( right(receiver_id, 12) = '.poolv1.near' OR right(receiver_id, 10) = '.pool.near' )
          AND r.tx_hash IN ( SELECT tx_hash 
          				     FROM near.core.fact_actions_events_function_call
          				     WHERE method_name IN ('ping','stake','unstake','stake_all','unstake_all','deposit_and_stake') )
          AND left(l.value::string, 6) = 'Epoch '
    
      	QUALIFY row_number() OVER (partition by epoch_num, validator_address order by block_timestamp desc) = 1
    ),
    
    
    proposals AS (
      	SELECT b.block_id
          	 , b.block_timestamp
          	 , b.epoch_id
          	 , vp.value['account_id'] AS validator_address
          	 , vp.value['stake']::bigint / 1e24 AS staked_balance
        FROM near.core.fact_blocks AS b
           , lateral flatten( input => b.chunks ) AS c
           , lateral flatten( input => c.value['validator_proposals']) AS vp
      	-- WHERE b.block_timestamp >= '2021-09-01'
        QUALIFY row_number() OVER (partition by validator_address, epoch_id order by block_timestamp desc) = 1
    ),
    
    
    proposals_per_epoch AS (
      	SELECT p.block_timestamp
      		 , p.epoch_id
      		 , p.validator_address
      		 , p.staked_balance
      		 , e.epoch_num
      
      	FROM proposals AS p
      		INNER JOIN dim_epochs AS e
      			ON e.epoch_id = p.epoch_id
    
      	QUALIFY row_number() OVER (partition by epoch_num, validator_address order by block_timestamp desc) = 1
    ),
    
    
    block_producers_per_epoch AS (
      	SELECT b.epoch_id
      		 , e.epoch_num
      		 , b.block_author AS validator_address
      		 , sa.staked_balance
      		 , count(distinct b.block_id) OVER (partition by b.epoch_id, b.block_author) AS blocks_produced
      
      	FROM near.core.fact_blocks AS b
      		INNER JOIN dim_epochs AS e
      			ON e.epoch_id = b.epoch_id
    
      		LEFT JOIN staking_actions AS sa
      			ON sa.epoch_num = e.epoch_num
      			AND sa.validator_address = b.block_author
    
      	QUALIFY row_number() OVER (partition by b.epoch_id, b.block_author order by b.block_timestamp desc) = 1
    ),
    
    
    dim_validators AS (
      	SELECT validator_address
      		 , min(start_epoch) AS start_epoch
      		 , min(start_time) AS start_time
      
      	FROM (
    		SELECT validator_address
        		 , min(epoch_num) AS start_epoch
        		 , min(block_timestamp) AS start_time
        	FROM staking_actions AS sa
        	GROUP BY 1
      
        	UNION ALL
      
        	SELECT block_author AS validator_address
        		 , min(e.epoch_num) AS start_epoch
        		 , min(b.block_timestamp) AS start_time
        	FROM near.core.fact_blocks AS b
        		LEFT JOIN dim_epochs AS e
        			ON b.block_id BETWEEN e.min_block_id AND e.max_block_id
        	GROUP BY 1
        ) AS x
      
      	GROUP BY 1
    ),
    
    
    dim_table AS (
      	SELECT v.validator_address
      		 , e.epoch_num
      		 , e.start_time
      		 , e.total_near_supply
      
      	FROM dim_validators AS v, dim_epochs AS e
      	WHERE v.start_epoch <= e.epoch_num
    ),
    
    
    validator_status_per_epoch AS (
      	SELECT dt.epoch_num
      		 , dt.start_time
      		 , dt.validator_address
      		 , coalesce(
      				last_value(coalesce(bp.staked_balance, p.staked_balance)) IGNORE NULLS
      					OVER (partition by dt.validator_address 
      					  	  order by dt.epoch_num
      					  	  rows between unbounded preceding
      								   and current row),
      				0) AS staked_balance
      		 , bp.blocks_produced
      		 , (CASE WHEN p.validator_address IS NOT NULL THEN True ELSE False END) AS is_proposer
      
      	FROM dim_table AS dt
      		LEFT JOIN block_producers_per_epoch AS bp
      			ON bp.epoch_num = dt.epoch_num
      			AND bp.validator_address= dt.validator_address
    
      		LEFT JOIN proposals_per_epoch AS p
      			ON p.epoch_num = dt.epoch_num
      			AND p.validator_address= dt.validator_address
    
    ),
    
    
    epoch_stats AS (
      	SELECT epoch_num
          	 , start_time
      		 , sum(staked_balance) AS total_near_staked
          
        FROM validator_status_per_epoch
        WHERE staked_balance > 0
        GROUP BY 1,2
    ),
    
    
    epoch_stats_2 AS (
      	SELECT es.*
      		 , de.total_near_supply
      		 , de.total_near_supply - es.total_near_staked AS other_near_supply
      	 	 , 100.00 * total_near_staked / total_near_supply AS perc_staked_supply
      	FROM epoch_stats AS es
      		LEFT JOIN dim_epochs AS de
      			ON de.epoch_num = es.epoch_num
    )
    
    
    SELECT start_time::date AS utc_date
         , total_near_staked AS total_staked_supply
         , total_near_supply AS total_supply
    FROM epoch_stats_2
    QUALIFY row_number() OVER (partition by utc_date order by start_time desc) = 1
),

daily_supply_stats AS (
    SELECT s.utc_date
         , s.total_supply
         , s.total_staked_supply
         , s.total_supply - s.total_staked_supply AS total_nonstaked_supply
         , ls.total_locked_supply
         , ls.locked_and_staked_supply
         , greatest(0, total_staked_supply - locked_and_staked_supply) AS nonlocked_and_staked_supply
         , greatest(0, total_locked_supply - locked_and_staked_supply) AS locked_and_nonstaked_supply
         , total_supply
            - locked_and_staked_supply
            - locked_and_nonstaked_supply
            - nonlocked_and_staked_supply AS nonlocked_and_nonstaked_supply

         , total_supply - total_locked_supply AS circulating_supply
         , total_locked_supply AS locked_supply

    FROM daily_staked_supply AS s
        LEFT JOIN daily_locked_and_staked_supply AS ls
            ON ls.utc_date = s.utc_date
),

output AS (
    SELECT utc_date
         , utc_date AS "Date"
         , total_supply AS "Total Supply - Actual"
         , total_staked_supply AS "Staked Supply"
         , total_nonstaked_supply AS "Non-staked Supply"
         , circulating_supply AS "Circulating Supply"
         , total_supply - circulating_supply as "Total Supply"
         , total_locked_supply AS "Locked Supply"
         , nonlocked_and_nonstaked_supply AS "Liquid Supply"
         , total_supply - nonlocked_and_nonstaked_supply  AS "Non-liquid Supply"

         , locked_and_staked_supply AS "Staked (Locked Supply)"
         , locked_and_nonstaked_supply AS "Non-staked (Locked Supply)"

         , nonlocked_and_staked_supply AS "Staked (Circulating Supply)"
         , nonlocked_and_nonstaked_supply AS "Non-staked (Circulating Supply)"

         , total_locked_supply / total_supply AS perc_locked_supply
         , circulating_supply / total_supply AS perc_circulating_supply

         , locked_and_staked_supply / total_locked_supply AS perc_staked__locked
         , nonlocked_and_staked_supply / circulating_supply AS perc_staked__circulating

         , 1 AS dummy

    FROM daily_supply_stats
)

SELECT *
FROM output
WHERE utc_date >= '2023-01-01'
ORDER BY utc_date DESC 
```

'''
'''--- models/silver/atlas/supply/silver__atlas_supply.sql ---
{{ config(
    materialized = "table",
    cluster_by = ["utc_date"],
    unique_key = "atlas_supply_id",
    tags = ['atlas']
) }}

WITH daily_lockup_locked_balances AS (

    SELECT
        *
    FROM
        {{ ref('silver__atlas_supply_daily_lockup_locked_balances') }}
),
daily_lockup_staking_balances AS (
    SELECT
        *
    FROM
        {{ ref('silver__atlas_supply_daily_lockup_staking_balances') }}
),
daily_lockup_locked_and_staking_balances AS (
    SELECT
        l.lockup_account_id,
        l.utc_date,
        l.locked_amount,
        COALESCE(
            s.staked_balance,
            0
        ) AS staked_amount,
        LEAST(
            staked_amount,
            locked_amount
        ) AS locked_and_staked_amount
    FROM
        daily_lockup_locked_balances AS l
        LEFT JOIN daily_lockup_staking_balances AS s
        ON s.lockup_account_id = l.lockup_account_id
        AND s.utc_date = l.utc_date
),
daily_locked_and_staked_supply AS (
    SELECT
        utc_date,
        SUM(locked_amount) AS total_locked_supply,
        SUM(locked_and_staked_amount) AS locked_and_staked_supply
    FROM
        daily_lockup_locked_and_staking_balances
    GROUP BY
        1
),
daily_staked_supply AS (
    SELECT
        date_day AS utc_date,
        SUM(balance) AS total_staked_supply
    FROM
        {{ ref('silver__pool_balance_daily') }}
    GROUP BY
        1
),
daily_total_supply AS (
    SELECT
        end_time :: DATE AS utc_date,
        total_near_supply AS total_supply
    FROM
        {{ ref('silver__atlas_supply_epochs') }}
        qualify ROW_NUMBER() over (
            PARTITION BY end_time :: DATE
            ORDER BY
                end_time DESC
        ) = 1
),
daily_supply_stats AS (
    SELECT
        s.utc_date,
        ts.total_supply,
        s.total_staked_supply,
        ts.total_supply - s.total_staked_supply AS total_nonstaked_supply,
        ls.total_locked_supply,
        ls.locked_and_staked_supply,
        GREATEST(
            0,
            total_staked_supply - locked_and_staked_supply
        ) AS nonlocked_and_staked_supply,
        GREATEST(
            0,
            total_locked_supply - locked_and_staked_supply
        ) AS locked_and_nonstaked_supply,
        total_supply - locked_and_staked_supply - locked_and_nonstaked_supply - nonlocked_and_staked_supply AS nonlocked_and_nonstaked_supply,
        total_supply - total_locked_supply AS circulating_supply,
        total_locked_supply AS locked_supply
    FROM
        daily_staked_supply AS s
        LEFT JOIN daily_locked_and_staked_supply AS ls
        ON ls.utc_date = s.utc_date
        LEFT JOIN daily_total_supply AS ts
        ON ts.utc_date = s.utc_date
),
output AS (
    SELECT
        utc_date,
        total_supply,
        total_staked_supply,
        total_nonstaked_supply,
        circulating_supply,
        total_locked_supply,
        nonlocked_and_nonstaked_supply AS liquid_supply,
        total_supply - nonlocked_and_nonstaked_supply AS nonliquid_supply,
        locked_and_staked_supply AS staked_locked_supply,
        locked_and_nonstaked_supply AS non_staked_locked_supply,
        nonlocked_and_staked_supply AS staked_circulating_supply,
        nonlocked_and_nonstaked_supply AS nonstaked_circulating_supply,
        total_locked_supply / total_supply AS perc_locked_supply,
        circulating_supply / total_supply AS perc_circulating_supply,
        locked_and_staked_supply / total_locked_supply AS perc_staked_locked,
        nonlocked_and_staked_supply / circulating_supply AS perc_staked_circulating
    FROM
        daily_supply_stats
)
SELECT
    utc_date,
    total_supply,
    total_staked_supply,
    total_nonstaked_supply,
    circulating_supply,
    total_locked_supply,
    liquid_supply,
    nonliquid_supply,
    staked_locked_supply,
    non_staked_locked_supply,
    staked_circulating_supply,
    nonstaked_circulating_supply,
    perc_locked_supply,
    perc_circulating_supply,
    perc_staked_locked,
    perc_staked_circulating,
    {{ dbt_utils.generate_surrogate_key(['utc_date']) }} AS atlas_supply_id,
    SYSDATE() AS inserted_timestamp,
    SYSDATE() AS modified_timestamp,
    '{{ invocation_id }}' AS _invocation_id
FROM
    output

'''
'''--- models/silver/atlas/supply/silver__atlas_supply.yml ---
version: 2

models:
  - name: silver__atlas_supply
    description: |-
      A table represeting calculations for the supply of NEAR across various categories, such as staked and locked.
    columns:
      - name: utc_date
        description: "{{ doc('utc_date') }}"
        tests:
          - not_null
      - name: total_supply
        description: "{{ doc('total_supply') }}"
        tests:
          - not_null
      - name: total_staked_supply
        description: "{{ doc('total_staked_supply') }}"
        tests:
          - not_null
      - name: total_nonstaked_supply
        description: "{{ doc('total_nonstaked_supply') }}"
        tests:
          - not_null
      - name: circulating_supply
        description: "{{ doc('circulating_supply') }}"
        tests:
          - not_null
      - name: total_locked_supply
        description: "{{ doc('total_locked_supply') }}"
        tests:
          - not_null
      - name: liquid_supply
        description: "{{ doc('liquid_supply') }}"
        tests:
          - not_null
      - name: nonliquid_supply
        description: "{{ doc('nonliquid_supply') }}"
        tests:
          - not_null
      - name: staked_locked_supply
        description: "{{ doc('staked_locked_supply') }}"
        tests:
          - not_null
      - name: non_staked_locked_supply
        description: "{{ doc('non_staked_locked_supply') }}"
        tests:
          - not_null
      - name: staked_circulating_supply
        description: "{{ doc('staked_circulating_supply') }}"
        tests:
          - not_null
      - name: nonstaked_circulating_supply
        description: "{{ doc('nonstaked_circulating_supply') }}"
        tests:
          - not_null
      - name: perc_locked_supply
        description: "{{ doc('perc_locked_supply') }}"
        tests:
          - not_null
      - name: perc_circulating_supply
        description: "{{ doc('perc_circulating_supply') }}"
        tests:
          - not_null
      - name: perc_staked_locked
        description: "{{ doc('perc_staked_locked') }}"
        tests:
          - not_null
      - name: perc_staked_circulating
        description: "{{ doc('perc_staked_circulating') }}"
        tests:
          - not_null
      - name: atlas_supply_id
        description: "{{ doc('id') }}"
        tests:
          - not_null
          - unique
      - name: inserted_timestamp
        description: "{{ doc('inserted_timestamp') }}"

      - name: modified_timestamp
        description: "{{ doc('modified_timestamp') }}"

      - name: _invocation_id
        description: "{{ doc('invocation_id') }}"

'''
'''--- models/silver/atlas/supply/silver__atlas_supply_daily_lockup_locked_balances.sql ---
{{ config(
    materialized = "table",
    cluster_by = ["utc_date"],
    unique_key = "atlas_daily_lockup_locked_balances_id",
    tags = ['atlas', 'atlas_supply']
) }}

WITH lockup_receipts AS (

    SELECT
        *
    FROM
        {{ ref('silver__atlas_supply_lockup_receipts') }}
),
function_call AS (
    SELECT
        *
    FROM
        {{ ref('silver__actions_events_function_call_s3') }}
),
dates AS (
    SELECT
        date_day AS utc_date
    FROM
        {{ source(
            'crosschain',
            'dim_dates'
        ) }}
),
new_lockup_txs AS (
    -- new lockup contract created
    SELECT
        receipt_object_id,
        tx_hash,
        block_timestamp,
        receiver_id AS lockup_account_id,
        _inserted_timestamp,
        _partition_by_block_number
    FROM
        lockup_receipts,
        LATERAL FLATTEN(
            input => actions :receipt :Action :actions
        )
    WHERE
        VALUE :FunctionCall :method_name :: STRING = 'new'
),
terminate_vesting_txs AS (
    -- vesting is stopped by the Foundation
    SELECT
        tx_hash,
        block_timestamp,
        receiver_id AS lockup_account_id,
        SPLIT(
            logs [0],
            'unvested balance is '
        ) [1] :: bigint / 1e24 AS unvested_balance,
        _inserted_timestamp,
        _partition_by_block_number
    FROM
        lockup_receipts,
        LATERAL FLATTEN(
            input => actions :receipt :Action :actions
        )
    WHERE
        VALUE :FunctionCall :method_name :: STRING = 'terminate_vesting'
),
terminate_vesting_txs_with_vesting_schedule AS (
    SELECT
        tv.*,
        fc.args :vesting_schedule_with_salt :vesting_schedule AS vesting_schedule,
        tv._inserted_timestamp,
        tv._partition_by_block_number
    FROM
        terminate_vesting_txs AS tv
        LEFT JOIN function_call AS fc
        ON fc.tx_hash = tv.tx_hash
        AND fc.method_name = 'terminate_vesting' qualify ROW_NUMBER() over (
            PARTITION BY tv.tx_hash
            ORDER BY
                tv.block_timestamp
        ) = 1 -- dedupe
),
-- unvested tokens are withdrawn (effectively unlocked into circulating supply)
termination_withdraw_txs AS (
    SELECT
        tx_hash,
        block_timestamp,
        receiver_id AS lockup_account_id,
        SPLIT(
            SPLIT(
                logs [0],
                ' of terminated unvested balance'
            ) [0],
            'Withdrawing '
        ) [1] :: bigint / 1e24 AS withdrawn_amount,
        _inserted_timestamp,
        _partition_by_block_number
    FROM
        lockup_receipts,
        LATERAL FLATTEN(
            input => actions :receipt :Action :actions
        )
    WHERE
        VALUE :FunctionCall :method_name :: STRING = 'termination_withdraw' -- Simplify logic -> get only first termination withdrawal
        -- QUALIFY row_number() OVER (partition by lockup_account_id order by block_timestamp) = 1
),
daily_termination_withdrawn_amount AS (
    SELECT
        lockup_account_id,
        block_timestamp :: DATE AS utc_date,
        SUM(withdrawn_amount) AS withdrawn_amount
    FROM
        termination_withdraw_txs
    GROUP BY
        1,
        2
),
-- lockup amounts
deposits AS (
    SELECT
        tx_hash,
        block_timestamp,
        VALUE :Transfer :deposit :: bigint / 1e24 AS deposit_amount,
        _inserted_timestamp,
        _partition_by_block_number
    FROM
        lockup_receipts,
        LATERAL FLATTEN(
            input => actions :receipt :Action :actions
        )
    WHERE
        object_keys(
            VALUE :Transfer
        ) [0] :: STRING = 'deposit'
),
lockup_contracts AS (
    SELECT
        lcr.tx_hash,
        lcr.block_timestamp,
        lcr.lockup_account_id,
        fc1.args :lockup_duration :: bigint AS input_lockup_duration_ns,
        fc1.args :lockup_timestamp :: bigint AS input_lockup_timestamp_epoch,
        fc1.args :owner_account_id :: STRING AS owner_account_id,
        fc1.args :release_duration :: bigint AS input_release_duration_ns,
        COALESCE(
            tv.vesting_schedule,
            fc1.args :vesting_schedule :VestingSchedule
        ) AS vesting_schedule_,
        vesting_schedule_ :cliff_timestamp :: bigint AS vesting_cliff_timestamp_epoch,
        vesting_schedule_ :start_timestamp :: bigint AS vesting_start_timestamp_epoch,
        vesting_schedule_ :end_timestamp :: bigint AS vesting_end_timestamp_epoch,
        COALESCE(
            fc1.args :transfers_information :TransfersEnabled :transfers_timestamp :: bigint,
            1602614338293769340
        ) AS transfers_enabled_timestamp_epoch,
        d.deposit_amount,
        tv.block_timestamp AS terminate_vesting_timestamp,
        tv.unvested_balance AS termination_unvested_amount,
        tw.block_timestamp AS termination_withdraw_timestamp,
        tw.withdrawn_amount AS termination_withdrawn_amount,
        (
            CASE
                WHEN object_keys(
                    fc1.args :vesting_schedule
                ) [0] :: STRING = 'VestingHash' THEN TRUE
                ELSE FALSE
            END
        ) AS is_private_vesting,
        lcr._inserted_timestamp,
        lcr._partition_by_block_number
    FROM
        new_lockup_txs AS lcr
        LEFT JOIN function_call AS fc1
        ON fc1.tx_hash = lcr.tx_hash
        AND fc1.method_name = 'new'
        LEFT JOIN deposits AS d
        ON d.tx_hash = lcr.tx_hash
        LEFT JOIN terminate_vesting_txs_with_vesting_schedule AS tv
        ON tv.lockup_account_id = lcr.lockup_account_id
        LEFT JOIN termination_withdraw_txs AS tw
        ON tw.lockup_account_id = lcr.lockup_account_id
    WHERE
        lcr.tx_hash IN (
            SELECT
                tx_hash
            FROM
                new_lockup_txs
        )
        AND d.deposit_amount > 0
),
lockup_contracts__parsed AS (
    SELECT
        lockup_account_id,
        -- the number of times the same lockup account ID has been used (used as part of lockup unique identifier)
        ROW_NUMBER() over (
            PARTITION BY lockup_account_id
            ORDER BY
                block_timestamp
        ) AS lockup_index,
        owner_account_id,
        deposit_amount AS lockup_amount,
        -- timestamp when tokens were locked (lock start)
        block_timestamp AS deposit_timestamp,
        -- timestamp when transfers were enabled in the blockchain (default reference when lockup_timestamp is null)
        TO_TIMESTAMP(
            transfers_enabled_timestamp_epoch,
            9
        ) AS transfers_enabled_timestamp,
        -- timestamp when tokens start unlocking (explicit parameter)
        TO_TIMESTAMP(
            input_lockup_timestamp_epoch,
            9
        ) AS input_lockup_timestamp,
        -- if lockup_timestamp is null, calculate unlock start from lockup duration
        TIMESTAMPADD(
            nanoseconds,
            input_lockup_duration_ns,
            transfers_enabled_timestamp
        ) AS calculated_lockup_timestamp,
        -- lockup mechanism
        input_lockup_duration_ns,
        input_release_duration_ns,
        -- Max between input and calculated lockup timestamp
        (
            CASE
                WHEN input_lockup_timestamp IS NOT NULL THEN GREATEST(
                    input_lockup_timestamp,
                    calculated_lockup_timestamp
                )
                ELSE calculated_lockup_timestamp
            END
        ) AS lockup_timestamp,
        -- If release_duration is not provided, tokens are immediately unlocked
        (
            CASE
                WHEN input_release_duration_ns IS NOT NULL THEN TIMESTAMPADD(
                    nanosecond,
                    input_release_duration_ns,
                    lockup_timestamp
                ) -- linear release if release_duration is provided, else full unlock
                ELSE lockup_timestamp
            END
        ) AS lockup_end_timestamp,
        -- vesting mechanism
        is_private_vesting,
        TO_TIMESTAMP(
            vesting_start_timestamp_epoch,
            9
        ) AS vesting_start_timestamp,
        TO_TIMESTAMP(
            vesting_end_timestamp_epoch,
            9
        ) AS vesting_end_timestamp,
        TO_TIMESTAMP(
            vesting_cliff_timestamp_epoch,
            9
        ) AS vesting_cliff_timestamp,
        -- vesting termination
        terminate_vesting_timestamp,
        termination_unvested_amount,
        termination_withdraw_timestamp,
        termination_withdrawn_amount,
        tx_hash AS _tx_hash,
        (
            CASE
                WHEN lockup_timestamp IS NOT NULL
                AND vesting_start_timestamp IS NULL THEN LEAST(
                    deposit_timestamp,
                    lockup_timestamp
                )
                WHEN lockup_timestamp IS NULL
                AND vesting_start_timestamp IS NOT NULL THEN LEAST(
                    deposit_timestamp,
                    vesting_start_timestamp
                )
                ELSE LEAST(
                    deposit_timestamp,
                    lockup_timestamp,
                    vesting_start_timestamp
                )
            END
        ) :: DATE AS _lockup_start_date,
        (
            CASE
                WHEN lockup_end_timestamp IS NOT NULL
                AND vesting_end_timestamp IS NULL THEN lockup_end_timestamp
                WHEN lockup_end_timestamp IS NULL
                AND vesting_end_timestamp IS NOT NULL THEN vesting_end_timestamp
                ELSE GREATEST(
                    lockup_end_timestamp,
                    vesting_end_timestamp
                )
            END
        ) :: DATE AS _lockup_end_date,
        _inserted_timestamp,
        _partition_by_block_number
    FROM
        lockup_contracts
),
{# TODO - above might be 1 table, and below aggregation another one. Below CTS is where the cross join with dates is happening, calculating the time remaining and resulting balance(s) #}
lockup_contracts_daily_balance__prep_1 AS (
    SELECT
        lc.lockup_account_id,
        lc.lockup_index,
        lc.owner_account_id,
        d.utc_date,
        d.utc_date + INTERVAL '1 day' - INTERVAL '1 nanosecond' AS block_timestamp,
        -- End of day block timestamp
        lc.lockup_amount,
        lc.deposit_timestamp,
        -- Lockup logic
        lc.lockup_timestamp,
        lc.lockup_end_timestamp,
        GREATEST(
            0,
            TIMESTAMPDIFF(
                nanosecond,
                block_timestamp,
                lockup_end_timestamp
            )
        ) AS lockup_time_left_ns,
        (
            CASE
                WHEN block_timestamp >= lockup_timestamp THEN (
                    CASE
                        WHEN input_release_duration_ns > 0 THEN (
                            CASE
                                WHEN block_timestamp >= lockup_end_timestamp THEN 0 -- everything is released
                                ELSE lockup_amount * lockup_time_left_ns / input_release_duration_ns
                            END
                        )
                        ELSE 0
                    END
                )
                ELSE lockup_amount -- The entire balance is still locked before the lockup timestamp
            END
        ) AS unreleased_amount,
        -- Vesting logic
        lc.vesting_start_timestamp,
        lc.vesting_cliff_timestamp,
        lc.vesting_end_timestamp,
        lc.terminate_vesting_timestamp,
        lc.termination_unvested_amount,
        GREATEST(
            0,
            TIMESTAMPDIFF(
                nanosecond,
                block_timestamp,
                vesting_end_timestamp
            )
        ) AS vesting_time_left_ns,
        TIMESTAMPDIFF(
            nanosecond,
            vesting_start_timestamp,
            vesting_end_timestamp
        ) AS vesting_total_time_ns,
        lc._inserted_timestamp,
        lc._partition_by_block_number
    FROM
        lockup_contracts__parsed AS lc,
        dates AS d
    WHERE
        d.utc_date BETWEEN lc._lockup_start_date
        AND lc._lockup_end_date
),
lockup_contracts_daily_balance__prep_2 AS (
    SELECT
        lc.*,
        SUM(COALESCE(dtw.withdrawn_amount, 0)) over (
            PARTITION BY lc.lockup_account_id,
            lc.lockup_index
            ORDER BY
                lc.utc_date rows BETWEEN unbounded preceding
                AND CURRENT ROW
        ) AS termination_withdrawn_amount
    FROM
        lockup_contracts_daily_balance__prep_1 AS lc
        LEFT JOIN daily_termination_withdrawn_amount AS dtw
        ON dtw.lockup_account_id = lc.lockup_account_id
        AND dtw.utc_date = lc.utc_date
),
lockup_contracts_daily_balance AS (
    SELECT
        lc.*,
        -- Vesting logic
        -- Not 100% accurate due to private vesting lockups (unknown/hidden vesting parameters)
        (
            CASE
                WHEN block_timestamp >= terminate_vesting_timestamp THEN termination_unvested_amount - termination_withdrawn_amount
                ELSE (
                    CASE
                        WHEN block_timestamp < vesting_cliff_timestamp THEN lockup_amount -- Before the cliff, nothing is vested
                        WHEN block_timestamp >= vesting_end_timestamp THEN 0 -- After the end, everything is vested
                        ELSE lockup_amount * vesting_time_left_ns / vesting_total_time_ns
                    END
                )
            END
        ) AS unvested_amount,
        -- Combined logic
        GREATEST(
            unreleased_amount - termination_withdrawn_amount,
            COALESCE(
                unvested_amount,
                0
            )
        ) AS locked_amount,
        locked_amount - COALESCE(LAG(locked_amount) over (PARTITION BY lc.lockup_account_id, lc.lockup_index
    ORDER BY
        lc.utc_date), 0) AS unlocked_amount_today
    FROM
        lockup_contracts_daily_balance__prep_2 AS lc
)
SELECT
    lockup_account_id,
    lockup_index,
    owner_account_id,
    utc_date,
    block_timestamp,
    lockup_amount,
    deposit_timestamp,
    lockup_timestamp,
    lockup_end_timestamp,
    lockup_time_left_ns,
    unreleased_amount,
    vesting_start_timestamp,
    vesting_cliff_timestamp,
    vesting_end_timestamp,
    terminate_vesting_timestamp,
    termination_unvested_amount,
    vesting_time_left_ns,
    vesting_total_time_ns,
    termination_withdrawn_amount,
    unvested_amount,
    locked_amount,
    unlocked_amount_today,
    _inserted_timestamp,
    _partition_by_block_number,
    {{ dbt_utils.generate_surrogate_key(['utc_date', 'lockup_account_id', 'lockup_index', 'owner_account_id']) }} AS atlas_daily_lockup_locked_balances_id,
    SYSDATE() AS inserted_timestamp,
    SYSDATE() AS modified_timestamp,
    '{{ invocation_id }}' AS _invocation_id
FROM
    lockup_contracts_daily_balance

'''
'''--- models/silver/atlas/supply/silver__atlas_supply_daily_lockup_locked_balances.yml ---
version: 2

models:
  - name: silver__atlas_supply_daily_lockup_locked_balances
    description: |-
      Calculates daily balance of locked balance on a per lockup account-basis.

    columns:
      - name: lockup_account_id
        description: "{{ doc('lockup_account_id') }}"
        tests:
          - not_null
      - name: lockup_index
        description: "{{ doc('lockup_index') }}"
        tests:
          - not_null
      - name: owner_account_id
        description: "{{ doc('owner_account_id') }}"
        tests:
          - not_null
      - name: utc_date
        description: "{{ doc('utc_date') }}"
        tests:
          - not_null
      - name: block_timestamp
        description: "{{ doc('block_timestamp') }}"
        tests:
          - not_null
      - name: lockup_amount
        description: "{{ doc('lockup_amount') }}"
        tests:
          - not_null
      - name: deposit_timestamp
        description: "{{ doc('deposit_timestamp') }}"
        tests:
          - not_null
      - name: lockup_timestamp
        description: "{{ doc('lockup_timestamp') }}"

      - name: lockup_end_timestamp
        description: "{{ doc('lockup_end_timestamp') }}"

      - name: lockup_time_left_ns
        description: "{{ doc('lockup_time_left_ns') }}"

      - name: unreleased_amount
        description: "{{ doc('unreleased_amount') }}"

      - name: vesting_start_timestamp
        description: "{{ doc('vesting_start_timestamp') }}"

      - name: vesting_cliff_timestamp
        description: "{{ doc('vesting_cliff_timestamp') }}"

      - name: vesting_end_timestamp
        description: "{{ doc('vesting_end_timestamp') }}"

      - name: terminate_vesting_timestamp
        description: "{{ doc('terminate_vesting_timestamp') }}"

      - name: termination_unvested_amount
        description: "{{ doc('termination_unvested_amount') }}"

      - name: vesting_time_left_ns
        description: "{{ doc('vesting_time_left_ns') }}"

      - name: vesting_total_time_ns
        description: "{{ doc('vesting_total_time_ns') }}"

      - name: termination_withdrawn_amount
        description: "{{ doc('termination_withdrawn_amount') }}"

      - name: unvested_amount
        description: "{{ doc('unvested_amount') }}"

      - name: locked_amount
        description: "{{ doc('locked_amount') }}"
        tests:
          - not_null
      - name: unlocked_amount_today
        description: "{{ doc('unlocked_amount_today') }}"
        tests:
          - not_null
      - name: _inserted_timestamp
        description: "{{ doc('_inserted_timestamp') }}"

      - name: _partition_by_block_number
        description: "{{ doc('_partition_by_block_number') }}"

      - name: atlas_daily_lockup_locked_balances_id
        description: "{{ doc('id') }}"
        tests:
          - not_null
          - unique

      - name: inserted_timestamp
        description: "{{ doc('inserted_timestamp') }}"

      - name: modified_timestamp
        description: "{{ doc('modified_timestamp') }}"

      - name: _invocation_id
        description: "{{ doc('invocation_id') }}"

'''
'''--- models/silver/atlas/supply/silver__atlas_supply_daily_lockup_staking_balances.sql ---
{{ config(
    materialized = "table",
    cluster_by = ["utc_date"],
    unique_key = "atlas_daily_lockup_staking_balances_id",
    tags = ['atlas', 'atlas_supply']
) }}

WITH lockup_receipts AS (

    SELECT
        *
    FROM
        {{ ref('silver__atlas_supply_lockup_receipts') }}
),
dates AS (
    SELECT
        date_day AS utc_date
    FROM
        {{ source(
            'crosschain',
            'dim_dates'
        ) }}
),
lockup_staking_logs AS (
    SELECT
        lr.tx_hash,
        lr.block_timestamp,
        VALUE :FunctionCall :method_name :: STRING AS method_name,
        lr.receiver_id AS lockup_account_id,
        (
            CASE
                method_name
                WHEN 'stake' THEN SPLIT(SPLIT(lr.logs [0], ' at the staking pool') [0], 'Staking ') [1] :: bigint / 1e24
                WHEN 'deposit_and_stake' THEN SPLIT(SPLIT(lr.logs [0], ' to the staking pool') [0], 'Depositing and staking ') [1] :: bigint / 1e24
                WHEN 'unstake' THEN SPLIT(SPLIT(lr.logs [0], ' from the staking pool') [0], 'Unstaking ') [1] :: bigint / 1e24
            END
        ) AS amount,
        lr.logs,
        _inserted_timestamp,
        _partition_by_block_number
    FROM
        lockup_receipts AS lr,
        LATERAL FLATTEN(
            input => lr.actions :receipt :Action :actions
        )
    WHERE
        method_name IN (
            'stake',
            'deposit_and_stake',
            'unstake',
            'unstake_all'
        )
),
daily_staking_stats AS (
    SELECT
        lockup_account_id,
        block_timestamp :: DATE AS utc_date,
        SUM(
            CASE
                WHEN method_name IN (
                    'stake',
                    'deposit_and_stake'
                ) THEN amount
                ELSE 0
            END
        ) AS staked_amount_,
        SUM(
            CASE
                WHEN method_name IN ('unstake') THEN amount
                ELSE 0
            END
        ) AS unstaked_amount_,
        (
            CASE
                WHEN COUNT(
                    CASE
                        WHEN method_name = 'unstake_all' THEN tx_hash
                        ELSE NULL
                    END
                ) > 0 THEN TRUE
                ELSE FALSE
            END
        ) AS unstaked_all,
        MIN(_inserted_timestamp) AS _inserted_timestamp
    FROM
        lockup_staking_logs
    GROUP BY
        1,
        2
),
lockup_stakers AS (
    SELECT
        lockup_account_id,
        MIN(block_timestamp) :: DATE AS start_date
    FROM
        lockup_staking_logs
    GROUP BY
        1
),
lockup_stakers_daily_balances__prep_1 AS (
    SELECT
        ls.lockup_account_id,
        d.utc_date
    FROM
        lockup_stakers AS ls,
        dates AS d
    WHERE
        d.utc_date >= ls.start_date
),
lockup_stakers_daily_balances__prep_2 AS (
    SELECT
        d.lockup_account_id,
        d.utc_date,
        COALESCE(
            dss.staked_amount_,
            0
        ) AS staked_amount,
        COALESCE(
            dss.unstaked_amount_,
            0
        ) AS unstaked_amount,
        dss.unstaked_all,
        SUM(
            CASE
                WHEN dss.unstaked_all = TRUE THEN 1
                ELSE 0
            END
        ) over (
            PARTITION BY d.lockup_account_id
            ORDER BY
                d.utc_date rows BETWEEN unbounded preceding
                AND CURRENT ROW
        ) AS _unstake_counter,
        dss._inserted_timestamp
    FROM
        lockup_stakers_daily_balances__prep_1 AS d
        LEFT JOIN daily_staking_stats AS dss
        ON dss.lockup_account_id = d.lockup_account_id
        AND dss.utc_date = d.utc_date
),
lockup_stakers_daily_balances__prep_3 AS (
    SELECT
        *,
        COALESCE(LAG(_unstake_counter) over (PARTITION BY lockup_account_id
    ORDER BY
        utc_date), 0) AS staking_period_index
    FROM
        lockup_stakers_daily_balances__prep_2
),
lockup_stakers_daily_balances__prep_4 AS (
    SELECT
        *,
        SUM(
            staked_amount - unstaked_amount
        ) over (
            PARTITION BY lockup_account_id,
            staking_period_index
            ORDER BY
                utc_date rows BETWEEN unbounded preceding
                AND CURRENT ROW
        ) AS _cumulative_staked_amount,
        (
            CASE
                WHEN unstaked_all = TRUE THEN 0
                ELSE _cumulative_staked_amount
            END
        ) AS staked_balance
    FROM
        lockup_stakers_daily_balances__prep_3
),
lockup_stakers_daily_balances AS (
    SELECT
        lockup_account_id,
        utc_date,
        staked_balance,
        _inserted_timestamp
    FROM
        lockup_stakers_daily_balances__prep_4
)
SELECT
    lockup_account_id,
    utc_date,
    staked_balance,
    _inserted_timestamp,
    {{ dbt_utils.generate_surrogate_key(['lockup_account_id', 'utc_date']) }} AS atlas_daily_lockup_staking_balances_id,
    SYSDATE() AS inserted_timestamp,
    SYSDATE() AS modified_timestamp,
    '{{ invocation_id }}' AS _invocation_id
FROM
    lockup_stakers_daily_balances

'''
'''--- models/silver/atlas/supply/silver__atlas_supply_daily_lockup_staking_balances.yml ---
version: 2

models:
  - name: silver__atlas_supply_daily_lockup_staking_balances
    description: |-
      Calculates daily balance of staked balance on a per lockup account-basis.

    columns:
      - name: lockup_account_id
        description: "{{ doc('lockup_account_id') }}"
        tests:
          - not_null
      - name: utc_date
        description: "{{ doc('utc_date') }}"
        tests:
          - not_null
      - name: staked_balance
        description: "{{ doc('staked_balance') }}"
        tests:
          - not_null
      - name: _inserted_timestamp
        description: "{{ doc('_inserted_timestamp') }}"

      - name: atlas_daily_lockup_staking_balances_id
        description: "{{ doc('id') }}"
        tests:
          - not_null
          - unique

      - name: inserted_timestamp
        description: "{{ doc('inserted_timestamp') }}"

      - name: modified_timestamp
        description: "{{ doc('modified_timestamp') }}"

      - name: _invocation_id
        description: "{{ doc('invocation_id') }}"

'''
'''--- models/silver/atlas/supply/silver__atlas_supply_daily_staked_supply.sql ---
{{ config(
    materialized = "table",
    cluster_by = ["utc_date"],
    unique_key = "atlas_daily_staked_supply_id",
    merge_exclude_columns = ["inserted_timestamp"],
    tags = ['atlas', 'atlas_supply'],
    enabled = False
) }}

{# 
DISABLED / archived 12/1/2023
Note - seems like a more complicated way to get to the result in silver__pool_balances(_daily). Both look for logs that emit the updated staked total,
but this query is calculating extra proposer and epoch stats and not using them.
Unnecessary compute, possibly from a separate analytical process.
The numbers do seem to differ, but individual pool balances in my silver table match near-staking exactly.
#}

WITH receipts AS (

    SELECT
        *,
        receipt_actions AS actions,
        execution_outcome AS outcome
    FROM
        {{ ref('silver__streamline_receipts_final') }}

{% if is_incremental() %}
WHERE
    _inserted_timestamp :: DATE >= (
        SELECT
            MAX(utc_date) - INTERVAL '2 days'
        FROM
            {{ this }}
    )
{% endif %}
),
function_call AS (
    SELECT
        distinct tx_hash
    FROM
        {{ ref('silver__actions_events_function_call_s3') }}
    WHERE
        method_name IN (
            'ping',
            'stake',
            'unstake',
            'stake_all',
            'unstake_all',
            'deposit_and_stake'
        )

{% if is_incremental() %}
AND _inserted_timestamp :: DATE >= (
    SELECT
        MAX(utc_date) - INTERVAL '2 days'
    FROM
        {{ this }}
)
{% endif %}
),
blocks AS (
    SELECT
        *
    FROM
        {{ ref('silver__streamline_blocks') }}

{% if is_incremental() %}
WHERE
    _inserted_timestamp :: DATE >= (
        SELECT
            MAX(utc_date) - INTERVAL '2 days'
        FROM
            {{ this }}
    )
{% endif %}
),
epochs AS (
    SELECT
        *
    FROM
        {{ ref('silver__atlas_supply_epochs') }}
),
staking_actions AS (
    SELECT
        r.tx_hash,
        r.block_timestamp,
        r.receiver_id AS validator_address,
        REPLACE(
            SPLIT(
                l.value :: STRING,
                ': Contract received total'
            ) [0],
            'Epoch ',
            ''
        ) :: INTEGER AS epoch_num,
        SPLIT(
            SPLIT(
                l.value :: STRING,
                'New total staked balance is '
            ) [1],
            '. Total number of shares'
        ) [0] :: bigint / 1e24 AS staked_balance
    FROM
        receipts AS r,
        LATERAL FLATTEN(
            input => r.logs
        ) AS l
    WHERE
        (RIGHT(receiver_id, 12) = '.poolv1.near'
        OR RIGHT(receiver_id, 10) = '.pool.near')
        AND r.tx_hash IN (
            SELECT
                tx_hash
            FROM
                function_call
        )
        AND LEFT(
            l.value :: STRING,
            6
        ) = 'Epoch ' qualify ROW_NUMBER() over (
            PARTITION BY epoch_num,
            validator_address
            ORDER BY
                block_timestamp DESC
        ) = 1
)
,
proposals AS (
    SELECT
        b.block_id,
        b.block_timestamp,
        b.epoch_id,
        vp.value ['account_id'] AS validator_address,
        vp.value ['stake'] :: bigint / 1e24 AS staked_balance
    FROM
        blocks AS b,
        LATERAL FLATTEN(
            input => b.chunks
        ) AS C,
        LATERAL FLATTEN(
            input => C.value ['validator_proposals']
        ) AS vp -- WHERE b.block_timestamp >= '2021-09-01'
        qualify ROW_NUMBER() over (
            PARTITION BY validator_address,
            epoch_id
            ORDER BY
                block_timestamp DESC
        ) = 1
),
proposals_per_epoch AS (
    SELECT
        p.block_timestamp,
        p.epoch_id,
        p.validator_address,
        p.staked_balance,
        e.epoch_num
    FROM
        proposals AS p
        INNER JOIN epochs AS e
        ON e.epoch_id = p.epoch_id qualify ROW_NUMBER() over (
            PARTITION BY epoch_num,
            validator_address
            ORDER BY
                block_timestamp DESC
        ) = 1
),
block_producers_per_epoch AS (
    SELECT
        b.epoch_id,
        e.epoch_num,
        b.block_author AS validator_address,
        sa.staked_balance,
        COUNT(
            DISTINCT b.block_id
        ) over (
            PARTITION BY b.epoch_id,
            b.block_author
        ) AS blocks_produced
    FROM
        blocks AS b
        INNER JOIN epochs AS e
        ON e.epoch_id = b.epoch_id
        LEFT JOIN staking_actions AS sa
        ON sa.epoch_num = e.epoch_num
        AND sa.validator_address = b.block_author qualify ROW_NUMBER() over (
            PARTITION BY b.epoch_id,
            b.block_author
            ORDER BY
                b.block_timestamp DESC
        ) = 1
),
dim_validators AS (
    SELECT
        validator_address,
        MIN(start_epoch) AS start_epoch,
        MIN(start_time) AS start_time
    FROM
        (
            SELECT
                validator_address,
                MIN(epoch_num) AS start_epoch,
                MIN(block_timestamp) AS start_time
            FROM
                staking_actions AS sa
            GROUP BY
                1
            UNION ALL
            SELECT
                block_author AS validator_address,
                MIN(
                    e.epoch_num
                ) AS start_epoch,
                MIN(
                    b.block_timestamp
                ) AS start_time
            FROM
                blocks AS b
                LEFT JOIN epochs AS e
                ON b.block_id BETWEEN e.min_block_id
                AND e.max_block_id
            GROUP BY
                1
        ) AS x
    GROUP BY
        1
),
dim_table AS (
    SELECT
        v.validator_address,
        e.epoch_num,
        e.start_time,
        e.total_near_supply
    FROM
        dim_validators AS v,
        epochs AS e
    WHERE
        v.start_epoch <= e.epoch_num
),
validator_status_per_epoch AS (
    SELECT
        dt.epoch_num,
        dt.start_time,
        dt.validator_address,
        COALESCE(
            LAST_VALUE(COALESCE(bp.staked_balance, p.staked_balance)) ignore nulls over (
                PARTITION BY dt.validator_address
                ORDER BY
                    dt.epoch_num rows BETWEEN unbounded preceding
                    AND CURRENT ROW
            ),
            0
        ) AS staked_balance,
        bp.blocks_produced,
        (
            CASE
                WHEN p.validator_address IS NOT NULL THEN TRUE
                ELSE FALSE
            END
        ) AS is_proposer
    FROM
        dim_table AS dt
        LEFT JOIN block_producers_per_epoch AS bp
        ON bp.epoch_num = dt.epoch_num
        AND bp.validator_address = dt.validator_address
        LEFT JOIN proposals_per_epoch AS p
        ON p.epoch_num = dt.epoch_num
        AND p.validator_address = dt.validator_address
),
epoch_stats AS (
    SELECT
        epoch_num,
        start_time,
        SUM(staked_balance) AS total_near_staked
    FROM
        validator_status_per_epoch
    WHERE
        staked_balance > 0
    GROUP BY
        1,
        2
),
epoch_stats_2 AS (
    SELECT
        es.*,
        de.total_near_supply,
        de.total_near_supply - es.total_near_staked AS other_near_supply,
        100.00 * total_near_staked / total_near_supply AS perc_staked_supply
    FROM
        epoch_stats AS es
        LEFT JOIN epochs AS de
        ON de.epoch_num = es.epoch_num
),
FINAL AS (
    SELECT
        start_time :: DATE AS utc_date,
        total_near_staked AS total_staked_supply,
        total_near_supply AS total_supply
    FROM
        epoch_stats_2 qualify ROW_NUMBER() over (
            PARTITION BY utc_date
            ORDER BY
                start_time DESC
        ) = 1
)
SELECT
    utc_date,
    total_staked_supply,
    total_supply,
    {{ dbt_utils.generate_surrogate_key(['utc_date']) }} AS atlas_daily_staked_supply_id,
    SYSDATE() AS inserted_timestamp,
    SYSDATE() AS modified_timestamp,
    '{{ invocation_id }}' AS _invocation_id
FROM
    FINAL

'''
'''--- models/silver/atlas/supply/silver__atlas_supply_daily_staked_supply.yml ---
version: 2

models:
  - name: silver__atlas_supply_daily_staked_supply
    description: |-
      A currently disabled model. The CTE in the original SQL has been converted to dbt-jinja, before being deprecated in favor of another model that captures daily staked balance in a more efficient manner.
      This is being retained for archive purposes.

'''
'''--- models/silver/atlas/supply/silver__atlas_supply_epochs.sql ---
{{ config(
    materialized = "table",
    cluster_by = ["epoch_id"],
    unique_key = "atlas_epochs_id",
    tags = ['atlas']
) }}

WITH blocks AS (

    SELECT
        *
    FROM
        {{ ref('silver__streamline_blocks') }}
    WHERE
        {% if var("MANUAL_FIX") %}
            {{ partition_load_manual('no_buffer') }}
        {% else %}
            {{ incremental_load_filter('_inserted_timestamp') }}
        {% endif %}
),
epochs AS (
    SELECT
        epoch_id,
        MIN(block_id) AS min_block_id,
        MAX(block_id) AS max_block_id,
        COUNT(*) AS blocks,
        COUNT(
            DISTINCT block_author
        ) AS block_producers,
        MIN(block_timestamp) AS start_time,
        MAX(block_timestamp) AS end_time,
        MAX(total_supply) / 1e24 AS total_near_supply,
        ROW_NUMBER() over (
            ORDER BY
                min_block_id ASC
        ) - 1 + 900 AS epoch_num
    FROM
        blocks AS b
    GROUP BY
        1
)
SELECT
    epoch_id,
    min_block_id,
    max_block_id,
    blocks,
    block_producers,
    start_time,
    end_time,
    total_near_supply,
    epoch_num,
    {{ dbt_utils.generate_surrogate_key(['epoch_id']) }} AS atlas_epochs_id,
    SYSDATE() AS inserted_timestamp,
    SYSDATE() AS modified_timestamp,
    '{{ invocation_id }}' AS _invocation_id
FROM
    epochs

'''
'''--- models/silver/atlas/supply/silver__atlas_supply_epochs.yml ---
version: 2

models:
  - name: silver__atlas_supply_epochs
    description: |-
      Daily snapshot of each epoch on Near.

    columns:
      - name: epoch_id
        description: "{{ doc('epoch_id') }}"
        tests:
          - not_null
      - name: min_block_id
        description: "{{ doc('min_block_id') }}"
        tests:
          - not_null
      - name: max_block_id
        description: "{{ doc('max_block_id') }}"
        tests:
          - not_null
      - name: blocks
        description: "{{ doc('blocks') }}"
        tests:
          - not_null
      - name: block_producers
        description: "{{ doc('block_producers') }}"
        tests:
          - not_null
      - name: start_time
        description: "{{ doc('start_time') }}"
        tests:
          - not_null
      - name: end_time
        description: "{{ doc('end_time') }}"
        tests:
          - not_null
      - name: total_near_supply
        description: "{{ doc('total_near_supply') }}"
        tests:
          - not_null
      - name: epoch_num
        description: "{{ doc('epoch_num') }}"
        tests:
          - not_null
      - name: atlas_epochs_id
        description: "{{ doc('id') }}"
        tests:
          - not_null
          - unique
      - name: inserted_timestamp  
        description: "{{ doc('inserted_timestamp') }}"
      - name: modified_timestamp
        description: "{{ doc('modified_timestamp') }}"
      - name: _invocation_id
        description: "{{ doc('invocation_id') }}"

'''
'''--- models/silver/atlas/supply/silver__atlas_supply_lockup_receipts.sql ---
{{ config(
    materialized = "incremental",
    cluster_by = ["receipt_object_id"],
    unique_key = "atlas_supply_lockup_receipts_id",
    merge_exclude_columns = ["inserted_timestamp"],
    incremental_strategy = "merge",
    tags = ['atlas']
) }}

WITH receipts AS (

    SELECT
        receipt_object_id,
        tx_hash,
        block_timestamp,
        receipt_actions,
        receiver_id,
        status_value,
        logs,
        _partition_by_block_number,
        _inserted_timestamp,
        modified_timestamp AS _modified_timestamp
    FROM
        {{ ref('silver__streamline_receipts_final') }}
    WHERE
        {% if var("MANUAL_FIX") %}
            {{ partition_load_manual('no_buffer') }}
        {% else %}
            {% if var('IS_MIGRATION') %}
                {{ incremental_load_filter('_inserted_timestamp') }}
            {% else %}
                {{ incremental_load_filter('_modified_timestamp') }}
            {% endif %}
        {% endif %}
),
FINAL AS (
    SELECT
        receipt_object_id,
        tx_hash,
        block_timestamp,
        receipt_actions :predecessor_id :: STRING AS predecessor_id,
        receiver_id,
        receipt_actions AS actions,
        object_keys(
            status_value
        ) [0] :: STRING AS status,
        logs,
        _partition_by_block_number,
        _inserted_timestamp,
        _modified_timestamp
    FROM
        receipts
    WHERE
        receiver_id LIKE '%.lockup.near'
        AND status != 'Failure'
)
SELECT
    *,
    {{ dbt_utils.generate_surrogate_key(['receipt_object_id']) }} AS atlas_supply_lockup_receipts_id,
    SYSDATE() AS inserted_timestamp,
    SYSDATE() AS modified_timestamp,
    '{{ invocation_id }}' AS _invocation_id
FROM
    FINAL

'''
'''--- models/silver/atlas/supply/silver__atlas_supply_lockup_receipts.yml ---
version: 2

models:
  - name: silver__atlas_supply_lockup_receipts
    description: |-
      Receipts for lockup transactions.

    columns:
      - name: receipt_object_id
        description: "{{ doc('receipt_object_id') }}"
        tests:
          - not_null
      - name: tx_hash
        description: "{{ doc('tx_hash') }}"
        tests:
          - not_null
      - name: block_timestamp
        description: "{{ doc('block_timestamp') }}"
        tests:
          - not_null
      - name: predecessor_id
        description: "{{ doc('predecessor_id') }}"
        tests:
          - not_null
      - name: receiver_id
        description: "{{ doc('receiver_id') }}"
        tests:
          - not_null
      - name: actions
        description: "{{ doc('actions') }}"
        tests:
          - not_null
      - name: status
        description: "{{ doc('status_value') }}"
        tests:
          - not_null
      - name: logs
        description: "{{ doc('logs') }}"
      - name: _partition_by_block_number
        description: "{{ doc('_partition_by_block_number') }}"
      - name: _inserted_timestamp
        description: "{{ doc('_inserted_timestamp') }}"
      - name: _modified_timestamp
        description: "{{ doc('_modified_timestamp') }}"
      - name: atlas_supply_lockup_receipts_id
        description: "{{ doc('id') }}"
        tests:
          - not_null
          - unique
      - name: inserted_timestamp
        description: "{{ doc('inserted_timestamp') }}"
      - name: modified_timestamp
        description: "{{ doc('modified_timestamp') }}"
      - name: _invocation_id
        description: "{{ doc('invocation_id') }}"

'''
'''--- models/silver/curated/defi/bridge/silver__bridge_allbridge.sql ---
{{ config(
    materialized = 'incremental',
    incremental_strategy = 'merge',
    merge_exclude_columns = ["inserted_timestamp"],
    unique_key = 'bridge_allbridge_id',
    cluster_by = ['block_timestamp::DATE', '_modified_timestamp::DATE'],
    tags = ['curated'],
) }}

WITH functioncall AS (

    SELECT
        block_id,
        block_timestamp,
        tx_hash,
        method_name,
        args,
        logs,
        receiver_id,
        signer_id,
        receipt_succeeded,
        _inserted_timestamp,
        _partition_by_block_number,
        modified_timestamp
    FROM
        {{ ref('silver__actions_events_function_call_s3') }}
    WHERE
        receiver_id = 'bridge.a11bd.near'

        {% if var("MANUAL_FIX") %}
            AND {{ partition_load_manual('no_buffer') }}
        {% else %}
            {% if is_incremental() %}

                AND 
                    modified_timestamp >= (
                        SELECT MAX(_modified_timestamp) FROM {{ this }}
                        )

            {% endif %}

        {% endif %}
),
outbound_near AS (
    -- burn
    SELECT
        block_id,
        block_timestamp,
        tx_hash,
        args :create_lock_args :token_id :: STRING AS token_address,
        args :create_lock_args :amount :: INT AS amount_raw,
        args :fee :: INT AS amount_fee_raw,
        args :memo :: STRING AS memo,
        args :create_lock_args :recipient :: STRING AS destination_address,
        args :create_lock_args :sender :: STRING AS source_address,
        LOWER(
            args :create_lock_args :destination :: STRING
        ) AS destination_chain_id,
        'near' AS source_chain_id,
        args,
        receipt_succeeded,
        method_name,
        'outbound' AS direction,
        _inserted_timestamp,
        _partition_by_block_number,
        modified_timestamp AS _modified_timestamp
    FROM
        functioncall
    WHERE
        method_name = 'callback_create_lock'
),
inbound_to_near AS (
    -- mint
    SELECT
        block_id,
        block_timestamp,
        tx_hash,
        args :token_id :: STRING AS token_address,
        args :unlock_args :amount :: INT AS amount_raw,
        args :fee :: INT AS amount_fee_raw,
        args :memo :: STRING AS memo,
        args :unlock_args :recipient :: STRING AS destination_address,
        null AS source_address,
        'near' AS destination_chain_id,
        LOWER(
            args :unlock_args :lock_source :: STRING
        ) AS source_chain_id,
        args,
        receipt_succeeded,
        method_name,
        'inbound' AS direction,
        _inserted_timestamp,
        _partition_by_block_number,
        modified_timestamp AS _modified_timestamp
    FROM
        functioncall
    WHERE
        method_name = 'callback_create_unlock'
),
FINAL AS (
    SELECT
        *
    FROM
        outbound_near
    UNION ALL
    SELECT
        *
    FROM
        inbound_to_near
)
SELECT
    *,
    'bridge.a11bd.near' AS bridge_address,
    'allbridge' AS platform,
    {{ dbt_utils.generate_surrogate_key(
        ['tx_hash']
    ) }} AS bridge_allbridge_id,
    SYSDATE() AS inserted_timestamp,
    SYSDATE() AS modified_timestamp,
    '{{ invocation_id }}' AS _invocation_id
FROM
    FINAL

'''
'''--- models/silver/curated/defi/bridge/silver__bridge_allbridge.yml ---
version: 2

models:
  - name: silver__bridge_allbridge
    description: |-
      Extracts data from actions table to build a view of bridge activity through the Allbridge.
    tests:
      - dbt_utils.recency:
          datepart: week
          field: block_timestamp
          interval: 1

    columns:
      - name: BLOCK_ID
        description: "{{ doc('block_id')}}"

      - name: BLOCK_TIMESTAMP
        description: "{{ doc('block_timestamp')}}"

      - name: TX_HASH
        description: "{{ doc('tx_hash')}}"
        tests:
          - not_null:
              where: _inserted_timestamp <= CURRENT_TIMESTAMP - interval '1 hour'
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - STRING
                - VARCHAR

      - name: TOKEN_ADDRESS
        description: "{{ doc('token_contract')}}"
        tests:
          - not_null:
              where: _inserted_timestamp <= CURRENT_TIMESTAMP - interval '1 hour' AND receipt_succeeded
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - STRING
                - VARCHAR

      - name: AMOUNT_RAW
        description: "{{ doc('amount_raw')}}"
        tests:
          - not_null:
              where: _inserted_timestamp <= CURRENT_TIMESTAMP - interval '1 hour' AND receipt_succeeded
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - INTEGER
                - NUMBER

      - name: AMOUNT_FEE_RAW
        description: "{{ doc('amount_raw')}}"
        tests:
          - not_null:
              where: _inserted_timestamp <= CURRENT_TIMESTAMP - interval '1 hour' AND receipt_succeeded
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - INTEGER
                - NUMBER

      - name: MEMO
        description: "{{ doc('memo')}}"

      - name: DESTINATION_ADDRESS
        description: "{{ doc('destination_address')}}"
        tests:
          - not_null:
              where: _inserted_timestamp <= CURRENT_TIMESTAMP - interval '1 hour' AND receipt_succeeded
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - STRING
                - VARCHAR

      - name: SOURCE_ADDRESS
        description: "{{ doc('source_address')}}"

      - name: PLATFORM
        description: "{{ doc('platform')}}"

      - name: BRIDGE_ADDRESS
        description: "{{ doc('contract_address')}}"

      - name: DESTINATION_CHAIN_ID
        description: "{{ doc('chain_id')}}"

      - name: SOURCE_CHAIN_ID
        description: "{{ doc('chain_id')}}"

      - name: ARGS
        description: "{{ doc('args')}}"

      - name: RECEIPT_SUCCEEDED
        description: "{{ doc('receipt_succeeded')}}"
        tests:
          - not_null

      - name: METHOD_NAME
        description: "{{ doc('method_name')}}"

      - name: DIRECTION
        description: "{{ doc('direction')}}"

      - name: _INSERTED_TIMESTAMP
        description: "{{ doc('_inserted_timestamp')}}"
        
      - name: _PARTITION_BY_BLOCK_NUMBER
        description: "{{ doc('_partition_by_block_number')}}"

      - name: BRIDGE_ALLBRIDGE_ID
        description: "{{ doc('id')}}"
        tests:
          - unique

      - name: INSERTED_TIMESTAMP
        description: "{{ doc('inserted_timestamp')}}"

      - name: MODIFIED_TIMESTAMP
        description: "{{ doc('modified_timestamp')}}"

      - name: _INVOCATION_ID
        description: "{{ doc('invocation_id')}}"

'''
'''--- models/silver/curated/defi/bridge/silver__bridge_multichain.sql ---
{{ config(
    materialized = 'incremental',
    incremental_strategy = 'merge',
    merge_exclude_columns = ["inserted_timestamp"],
    unique_key = 'bridge_multichain_id',
    cluster_by = ['block_timestamp::DATE', '_modified_timestamp::DATE'],
    tags = ['curated', 'exclude_from_schedule'],
) }}

WITH functioncall AS (

    SELECT
        block_id,
        block_timestamp,
        tx_hash,
        method_name,
        args,
        logs,
        receiver_id,
        signer_id,
        receipt_succeeded,
        _inserted_timestamp,
        _partition_by_block_number,
        modified_timestamp
    FROM
        {{ ref('silver__actions_events_function_call_s3') }}
    WHERE
        method_name = 'ft_transfer'  -- Both directions utilize ft_transfer

        {% if var("MANUAL_FIX") %}
            AND {{ partition_load_manual('no_buffer') }}
        {% else %}
            {% if is_incremental() %}

                AND 
                    modified_timestamp >= (
                        SELECT MAX(_modified_timestamp) FROM {{ this }}
                        )

            {% endif %}

        {% endif %}

),
inbound AS (
    SELECT
        block_id,
        block_timestamp,
        tx_hash,
        receiver_id AS token_address,
        args :amount :: INT AS amount_raw,
        args :memo :: STRING AS memo,
        args :receiver_id :: STRING AS destination_address,
        NULL AS source_address,
        '1001313161554' AS destination_chain_id,
        SPLIT(
            memo,
            ':'
        ) [2] :: STRING AS source_chain_id,
        receipt_succeeded,
        method_name,
        'inbound' AS direction,
        _partition_by_block_number,
        _inserted_timestamp,
        modified_timestamp AS _modified_timestamp
    FROM
        functioncall
    WHERE
        signer_id = 'mpc-multichain.near'
),
outbound AS (
    SELECT
        block_id,
        block_timestamp,
        tx_hash,
        receiver_id AS token_address,
        args :amount :: INT AS amount_raw,
        args :memo :: STRING AS memo,
        SPLIT(
            memo,
            ' '
        ) [0] :: STRING AS destination_address,
        signer_id AS source_address,
        SPLIT(
            memo,
            ' '
        ) [1] :: STRING AS destination_chain_id,
        '1001313161554' AS source_chain_id,
        receipt_succeeded,
        method_name,
        'outbound' AS direction,
        _partition_by_block_number,
        _inserted_timestamp,
        modified_timestamp AS _modified_timestamp
    FROM
        functioncall
    WHERE
        args :receiver_id :: STRING = 'mpc-multichain.near'
),
FINAL AS (
    SELECT
        *
    FROM
        inbound
    UNION ALL
    SELECT
        *
    FROM
        outbound
)
SELECT
    *,
    'mpc-multichain.near' AS bridge_address,
    'multichain' AS platform,
    {{ dbt_utils.generate_surrogate_key(
        ['tx_hash']
    ) }} AS bridge_multichain_id,
    SYSDATE() AS inserted_timestamp,
    SYSDATE() AS modified_timestamp,
    '{{ invocation_id }}' AS _invocation_id
FROM
    FINAL

'''
'''--- models/silver/curated/defi/bridge/silver__bridge_multichain.yml ---
version: 2

models:
  - name: silver__bridge_multichain
    description: |-
      Extracts data from actions table to build a view of historical bridge activity through the Multichain Bridge.

    columns:
      - name: BLOCK_ID
        description: "{{ doc('block_id')}}"

      - name: BLOCK_TIMESTAMP
        description: "{{ doc('block_timestamp')}}"

      - name: TX_HASH
        description: "{{ doc('tx_hash')}}"

      - name: TOKEN_ADDRESS
        description: "{{ doc('token_contract')}}"

      - name: AMOUNT_RAW
        description: "{{ doc('amount_raw')}}"

      - name: MEMO
        description: "{{ doc('memo')}}"

      - name: DESTINATION_ADDRESS
        description: "{{ doc('destination_address')}}"

      - name: SOURCE_ADDRESS
        description: "{{ doc('source_address')}}"

      - name: PLATFORM
        description: "{{ doc('platform')}}"

      - name: BRIDGE_ADDRESS
        description: "{{ doc('contract_address')}}"

      - name: DESTINATION_CHAIN_ID
        description: "{{ doc('chain_id')}}"

      - name: SOURCE_CHAIN_ID
        description: "{{ doc('chain_id')}}"

      - name: RECEIPT_SUCCEEDED
        description: "{{ doc('receipt_succeeded')}}"
        tests:
          - not_null

      - name: METHOD_NAME
        description: "{{ doc('method_name')}}"

      - name: DIRECTION
        description: "{{ doc('direction')}}"

      - name: _INSERTED_TIMESTAMP
        description: "{{ doc('_inserted_timestamp')}}"
        
      - name: _PARTITION_BY_BLOCK_NUMBER
        description: "{{ doc('_partition_by_block_number')}}"

      - name: BRIDGE_MULTICHAIN_ID
        description: "{{ doc('id')}}"
        tests:
          - unique

      - name: INSERTED_TIMESTAMP
        description: "{{ doc('inserted_timestamp')}}"

      - name: MODIFIED_TIMESTAMP
        description: "{{ doc('modified_timestamp')}}"

      - name: _INVOCATION_ID
        description: "{{ doc('invocation_id')}}"

'''
'''--- models/silver/curated/defi/bridge/silver__bridge_rainbow.sql ---
{{ config(
    materialized = 'incremental',
    incremental_strategy = 'merge',
    merge_exclude_columns = ["inserted_timestamp"],
    unique_key = 'bridge_rainbow_id',
    cluster_by = ['block_timestamp::DATE', '_modified_timestamp::DATE'],
    tags = ['curated'],
) }}

WITH functioncall AS (

    SELECT
        block_id,
        block_timestamp,
        tx_hash,
        method_name,
        args,
        logs,
        receiver_id,
        signer_id,
        receipt_succeeded,
        _inserted_timestamp,
        _partition_by_block_number,
        modified_timestamp AS _modified_timestamp
    FROM
        {{ ref('silver__actions_events_function_call_s3') }}

        {% if var("MANUAL_FIX") %}
            WHERE {{ partition_load_manual('no_buffer') }}
        {% else %}

            {% if is_incremental() %}
            WHERE _modified_timestamp >= (
                SELECT
                    MAX(_modified_timestamp)
                FROM
                    {{ this }}
            )
            {% endif %}
        {% endif %}
),
outbound_near_to_aurora AS (
    -- ft_transfer_call sends token to aurora
    -- EVM address logged in method action under msg
    SELECT
        block_id,
        block_timestamp,
        tx_hash,
        receiver_id AS token_address,
        args :amount :: INT AS amount_raw,
        args :memo :: STRING AS memo,
        LPAD(
            IFF(len(SPLIT(args :msg :: STRING, ':') [1]) = 104, SUBSTR(args :msg :: STRING, -40), args :msg :: STRING),
            42,
            '0x'
        ) AS destination_address,
        signer_id AS source_address,
        'Aurora' AS destination_chain_id,
        'Near' AS source_chain_id,
        receipt_succeeded,
        method_name,
        'aurora' AS bridge_address,
        'outbound' AS direction,
        _inserted_timestamp,
        _partition_by_block_number,
        _modified_timestamp
    FROM
        functioncall
    WHERE
        method_name = 'ft_transfer_call'
        AND args :receiver_id :: STRING = 'aurora'
        AND (
            receiver_id = 'aurora'
            OR receiver_id LIKE '%.factory.bridge.near'
        )
),
inbound_aurora_to_near AS (
    -- ft_transfer called on token contract, signed by relay.aurora
    -- recipient in actions JSON of ft_transfer, signer evm address in log of "submit" method
    -- no explicit mention of bridge method / contract
    SELECT
        block_id,
        block_timestamp,
        tx_hash,
        receiver_id AS token_address,
        args :amount :: INT AS amount_raw,
        args :memo :: STRING AS memo,
        args :receiver_id :: STRING AS destination_address,
        'Near' AS destination_chain_id,
        'Aurora' AS source_chain_id,
        receipt_succeeded,
        method_name,
        'aurora' AS bridge_address,
        'inbound' AS direction,
        _inserted_timestamp,
        _partition_by_block_number,
        args,
        _modified_timestamp
    FROM
        functioncall
    WHERE
        method_name = 'ft_transfer'
        AND signer_id = 'relay.aurora'
        AND NOT (
            -- Exclude 1 NEAR fee for fast bridge
            signer_id = 'relay.aurora'
            AND receiver_id = 'wrap.near'
            AND args :receiver_id :: STRING IN (
                '74abd625a1132b9b3258313a99828315b10ef864.aurora',
                '055707c67977e8217f98f19cfa8aca18b2282d0c.aurora',
                'e0302be5963b1f13003ab3a4798d2853bae731a7.aurora'
            )
        )
),
inbound_a2n_src_address AS (
    SELECT
        tx_hash,
        REGEXP_SUBSTR(
            logs [0] :: STRING,
            '0x[0-9a-fA-F]{40}'
        ) AS source_address
    FROM
        functioncall
    WHERE
        tx_hash IN (
            SELECT
                tx_hash
            FROM
                inbound_aurora_to_near
        )
        AND method_name = 'submit'
),
inbound_a2n_final AS (
    SELECT
        A.block_id,
        A.block_timestamp,
        A.tx_hash,
        A.token_address,
        A.amount_raw,
        A.memo,
        A.destination_address,
        b.source_address,
        A.destination_chain_id,
        A.source_chain_id,
        A.receipt_succeeded,
        A.method_name,
        A.bridge_address,
        A.direction,
        A._inserted_timestamp,
        A._partition_by_block_number,
        A._modified_timestamp
    FROM
        inbound_aurora_to_near A
        LEFT JOIN inbound_a2n_src_address b
        ON A.tx_hash = b.tx_hash
),
outbound_near_to_eth AS (
    -- determined by finish_withdraw method call on factory.bridge.near
    -- if signed by aurora relayer, likely aurora<->eth bridge
    SELECT
        block_id,
        block_timestamp,
        tx_hash,
        signer_id = 'relay.aurora' AS is_aurora,
        receiver_id AS token_address,
        args :amount :: INT AS amount_raw,
        NULL AS memo,
        LPAD(
            args :recipient :: STRING,
            42,
            '0x'
        ) AS destination_address,
        IFF(
            is_aurora,
            destination_address,
            signer_id
        ) AS source_address,
        'Ethereum' AS destination_chain_id,
        IFF(
            is_aurora,
            'Aurora',
            'Near'
        ) AS source_chain_id,
        receipt_succeeded,
        method_name,
        'factory.bridge.near' AS bridge_address,
        'outbound' AS direction,
        _inserted_timestamp,
        _partition_by_block_number,
        _modified_timestamp
    FROM
        functioncall
    WHERE
        tx_hash IN (
            SELECT
                DISTINCT tx_hash
            FROM
                functioncall
            WHERE
                receiver_id = 'factory.bridge.near'
                AND method_name = 'finish_withdraw'
        )
        AND method_name = 'withdraw'
),
inbound_eth_to_near AS (
    -- determined by finish_deposit method call on factory.bridge.near
    SELECT
        tx_hash,
        MIN(block_id) AS block_id,
        MIN(block_timestamp) AS block_timestamp,
        OBJECT_AGG(
            method_name,
            OBJECT_CONSTRUCT(
                'args',
                args,
                'logs',
                logs,
                'receiver_id',
                receiver_id,
                'signer_id',
                signer_id
            )
        ) AS actions,
        booland_agg(receipt_succeeded) AS receipt_succeeded,
        MIN(_inserted_timestamp) AS _inserted_timestamp,
        MIN(_partition_by_block_number) AS _partition_by_block_number,
        MIN(_modified_timestamp) AS _modified_timestamp
    FROM
        functioncall
    WHERE
        tx_hash IN (
            SELECT
                DISTINCT tx_hash
            FROM
                functioncall
            WHERE
                receiver_id = 'factory.bridge.near'
                AND method_name = 'finish_deposit'
        )
        AND method_name IN (
            'mint',
            'ft_transfer_call',
            'finish_deposit'
        )
    GROUP BY
        1
),
inbound_e2n_final AS (
    -- inbound token is minted on chain, take contract and amt from mint event
    SELECT
        block_id,
        block_timestamp,
        tx_hash,
        actions :ft_transfer_call :args :receiver_id :: STRING = 'aurora' AS is_aurora,
        actions :mint :receiver_id :: STRING AS token_address,
        actions :mint :args :amount :: INT AS amount_raw,
        actions :ft_transfer_call :args :memo :: STRING AS memo,
        LPAD(
            actions :ft_transfer_call :args :msg :: STRING,
            42,
            '0x'
        ) AS source_address,
        -- if minted by aurora contract, token is minted on near and bridged to aurora via xfer
        -- otherwise destination addr is the recipient of the transfer call
        IFF(
            is_aurora,
            source_address,
            COALESCE(
                actions :ft_transfer_call :args :receiver_id :: STRING,
                actions :mint :args :account_id :: STRING
            )
        ) AS destination_address,
        IFF(
            is_aurora,
            'Aurora',
            'Near'
        ) AS destination_chain_id,
        'Ethereum' AS source_chain_id,
        receipt_succeeded,
        IFF(
            is_aurora,
            'ft_transfer_call',
            'mint'
        ) AS method_name,
        'factory.bridge.near' AS bridge_address,
        'inbound' AS direction,
        _inserted_timestamp,
        _partition_by_block_number,
        _modified_timestamp
    FROM
        inbound_eth_to_near
),
FINAL AS (
    SELECT
        block_id,
        block_timestamp,
        tx_hash,
        token_address,
        amount_raw,
        memo,
        destination_address,
        source_address,
        destination_chain_id,
        source_chain_id,
        receipt_succeeded,
        method_name,
        bridge_address,
        direction,
        _inserted_timestamp,
        _partition_by_block_number,
        _modified_timestamp
    FROM
        outbound_near_to_aurora
    UNION ALL
    SELECT
        block_id,
        block_timestamp,
        tx_hash,
        token_address,
        amount_raw,
        memo,
        destination_address,
        source_address,
        destination_chain_id,
        source_chain_id,
        receipt_succeeded,
        method_name,
        bridge_address,
        direction,
        _inserted_timestamp,
        _partition_by_block_number,
        _modified_timestamp
    FROM
        inbound_a2n_final
    UNION ALL
    SELECT
        block_id,
        block_timestamp,
        tx_hash,
        token_address,
        amount_raw,
        memo,
        destination_address,
        source_address,
        destination_chain_id,
        source_chain_id,
        receipt_succeeded,
        method_name,
        bridge_address,
        direction,
        _inserted_timestamp,
        _partition_by_block_number,
        _modified_timestamp
    FROM
        outbound_near_to_eth
    UNION ALL
    SELECT
        block_id,
        block_timestamp,
        tx_hash,
        token_address,
        amount_raw,
        memo,
        destination_address,
        source_address,
        destination_chain_id,
        source_chain_id,
        receipt_succeeded,
        method_name,
        bridge_address,
        direction,
        _inserted_timestamp,
        _partition_by_block_number,
        _modified_timestamp
    FROM
        inbound_e2n_final
)
SELECT
    *,
    'rainbow' AS platform,
    {{ dbt_utils.generate_surrogate_key(
        ['tx_hash', 'source_chain_id', 'destination_address']
    ) }} AS bridge_rainbow_id,
    SYSDATE() AS inserted_timestamp,
    SYSDATE() AS modified_timestamp,
    '{{ invocation_id }}' AS _invocation_id
FROM
    FINAL

'''
'''--- models/silver/curated/defi/bridge/silver__bridge_rainbow.yml ---
version: 2

models:
  - name: silver__bridge_rainbow
    description: |-
      Extracts data from actions table to build a view of bridge activity through the Rainbow Bridge. Methods defined and explained [here](https://github.com/aurora-is-near/rainbow-token-connector/tree)
    tests:
      - dbt_utils.recency:
          datepart: week
          field: block_timestamp
          interval: 1

    columns:
      - name: BLOCK_ID
        description: "{{ doc('block_id')}}"

      - name: BLOCK_TIMESTAMP
        description: "{{ doc('block_timestamp')}}"

      - name: TX_HASH
        description: "{{ doc('tx_hash')}}"
        tests:
          - not_null:
              where: _inserted_timestamp <= CURRENT_TIMESTAMP - interval '1 hour'
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - STRING
                - VARCHAR

      - name: TOKEN_ADDRESS
        description: "{{ doc('token_contract')}}"
        tests:
          - not_null:
              where: _inserted_timestamp <= CURRENT_TIMESTAMP - interval '1 hour' AND receipt_succeeded
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - STRING
                - VARCHAR

      - name: AMOUNT_RAW
        description: "{{ doc('amount_raw')}}"
        tests:
          - not_null:
              where: _inserted_timestamp <= CURRENT_TIMESTAMP - interval '1 hour' AND receipt_succeeded
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - INTEGER
                - NUMBER

      - name: MEMO
        description: "{{ doc('memo')}}"

      - name: DESTINATION_ADDRESS
        description: "{{ doc('destination_address')}}"
        tests:
          - not_null:
              where: _inserted_timestamp <= CURRENT_TIMESTAMP - interval '1 hour' AND receipt_succeeded
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - STRING
                - VARCHAR

      - name: SOURCE_ADDRESS
        description: "{{ doc('source_address')}}"

      - name: BRIDGE_ADDRESS
        description: "{{ doc('contract_address')}}"

      - name: PLATFORM
        description: "{{ doc('platform')}}"

      - name: DESTINATION_CHAIN_ID
        description: "{{ doc('chain_id')}}"

      - name: SOURCE_CHAIN_ID
        description: "{{ doc('chain_id')}}"

      - name: RECEIPT_SUCCEEDED
        description: "{{ doc('receipt_succeeded')}}"
        tests:
          - not_null

      - name: METHOD_NAME
        description: "{{ doc('method_name')}}"

      - name: DIRECTION
        description: "{{ doc('direction')}}"

      - name: _INSERTED_TIMESTAMP
        description: "{{ doc('_inserted_timestamp')}}"
        
      - name: _PARTITION_BY_BLOCK_NUMBER
        description: "{{ doc('_partition_by_block_number')}}"

      - name: BRIDGE_RAINBOW_ID
        description: "{{ doc('id')}}"
        tests:
          - unique

      - name: INSERTED_TIMESTAMP
        description: "{{ doc('inserted_timestamp')}}"

      - name: MODIFIED_TIMESTAMP
        description: "{{ doc('modified_timestamp')}}"

      - name: _INVOCATION_ID
        description: "{{ doc('invocation_id')}}"

'''
'''--- models/silver/curated/defi/bridge/silver__bridge_wormhole.sql ---
{{ config(
    materialized = 'incremental',
    incremental_strategy = 'merge',
    merge_exclude_columns = ["inserted_timestamp"],
    unique_key = 'bridge_wormhole_id',
    cluster_by = ['block_timestamp::DATE', '_modified_timestamp::DATE'],
    tags = ['curated'],
) }}

WITH functioncall AS (

    SELECT
        block_id,
        block_timestamp,
        tx_hash,
        method_name,
        args,
        logs,
        receiver_id,
        signer_id,
        receipt_succeeded,
        _inserted_timestamp,
        _partition_by_block_number,
        modified_timestamp AS _modified_timestamp
    FROM
        {{ ref('silver__actions_events_function_call_s3') }}
    WHERE
        (signer_id LIKE '%.portalbridge.near'
        OR receiver_id LIKE '%.portalbridge.near')

        {% if var("MANUAL_FIX") %}
        AND {{ partition_load_manual('no_buffer') }}
        {% else %}
        {% if is_incremental() %}
            AND _modified_timestamp >= (
                SELECT
                    MAX(_modified_timestamp)
                FROM
                    {{ this }}
            )
        {% endif %}
        {% endif %}
),
outbound_near AS (
    -- burn
    SELECT
        block_id,
        block_timestamp,
        tx_hash,
        receiver_id AS token_address,
        logs,
        args,
        args :amount :: INT AS amount_raw,
        args :memo :: STRING AS memo,
        args :receiver :: STRING AS destination_address,
        signer_id AS source_address,
        args :chain :: INT AS destination_chain_id,
        15 AS source_chain_id,
        receipt_succeeded,
        method_name,
        'outbound' AS direction,
        _inserted_timestamp,
        _partition_by_block_number,
        _modified_timestamp
    FROM
        functioncall
    WHERE
        method_name = 'vaa_withdraw' 
        -- all the burns or withdraws are followed by a  publish_message in contract contract.w...to.near with the result
        -- example D35BNkK4gfPuuoWMGGJ6RNA3rjDoK66gPYASmfRy7rER (near)
        -- we can make sure that this is happening by checking that publish_message exists and is successful
),
inbound_to_near AS (
    -- mint
    SELECT
        block_id,
        block_timestamp,
        tx_hash,
        receiver_id AS token_address,
        logs,
        args,
        args :amount :: INT AS amount_raw,
        args :memo :: STRING AS memo,
        args :account_id :: STRING AS destination_address,
        NULL AS source_address,
        -- "In eth is Weth contract -- jum"
        args: recipient_chain :: INT AS destination_chain_id,
        receipt_succeeded,
        method_name,
        'inbound' AS direction,
        _inserted_timestamp,
        _partition_by_block_number,
        _modified_timestamp
    FROM
        functioncall
    WHERE
        method_name = 'vaa_transfer'
),
inbound_src_id AS (
    SELECT
        tx_hash,
        REGEXP_SUBSTR(
            logs [1],
            '\\d+'
        ) :: INT AS wormhole_chain_id
    FROM
        functioncall
    WHERE
        tx_hash IN (
            SELECT
                DISTINCT tx_hash
            FROM
                inbound_to_near
        )
        AND method_name = 'submit_vaa'
        AND receiver_id = 'contract.portalbridge.near'
),
inbound_final AS (
    SELECT
        block_id,
        block_timestamp,
        i.tx_hash,
        token_address,
        logs,
        args,
        amount_raw,
        memo,
        destination_address,
        source_address,
        destination_chain_id,
        src.wormhole_chain_id AS source_chain_id,
        receipt_succeeded,
        method_name,
        direction,
        _inserted_timestamp,
        _partition_by_block_number,
        i._modified_timestamp
    FROM
        inbound_to_near i
        LEFT JOIN inbound_src_id src
        ON i.tx_hash = src.tx_hash
),
FINAL AS (
    SELECT
        block_id,
        block_timestamp,
        tx_hash,
        token_address,
        amount_raw,
        memo,
        destination_address,
        source_address,
        destination_chain_id,
        source_chain_id,
        receipt_succeeded,
        method_name,
        direction,
        _inserted_timestamp,
        _partition_by_block_number,
        _modified_timestamp
    FROM
        outbound_near
    UNION ALL
    SELECT
        block_id,
        block_timestamp,
        tx_hash,
        token_address,
        amount_raw,
        memo,
        destination_address,
        source_address,
        destination_chain_id,
        source_chain_id,
        receipt_succeeded,
        method_name,
        direction,
        _inserted_timestamp,
        _partition_by_block_number,
        _modified_timestamp
    FROM
        inbound_final
)
SELECT
    *,
    'portalbridge.near' AS bridge_address,
    'wormhole' AS platform,
    {{ dbt_utils.generate_surrogate_key(
        ['tx_hash']
    ) }} AS bridge_wormhole_id,
    SYSDATE() AS inserted_timestamp,
    SYSDATE() AS modified_timestamp,
    '{{ invocation_id }}' AS _invocation_id
FROM
    FINAL

'''
'''--- models/silver/curated/defi/bridge/silver__bridge_wormhole.yml ---
version: 2

models:
  - name: silver__bridge_wormhole
    description: |-
      Extracts data from actions table to build a view of bridge activity through the Wormhople Portal Bridge.
    tests:
      - dbt_utils.recency:
          datepart: month
          field: block_timestamp
          interval: 1

    columns:
      - name: BLOCK_ID
        description: "{{ doc('block_id')}}"

      - name: BLOCK_TIMESTAMP
        description: "{{ doc('block_timestamp')}}"

      - name: TX_HASH
        description: "{{ doc('tx_hash')}}"
        tests:
          - not_null:
              where: _inserted_timestamp <= CURRENT_TIMESTAMP - interval '1 hour'
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - STRING
                - VARCHAR

      - name: TOKEN_ADDRESS
        description: "{{ doc('token_contract')}}"
        tests:
          - not_null:
              where: _inserted_timestamp <= CURRENT_TIMESTAMP - interval '1 hour' AND receipt_succeeded
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - STRING
                - VARCHAR

      - name: AMOUNT_RAW
        description: "{{ doc('amount_raw')}}"
        tests:
          - not_null:
              where: _inserted_timestamp <= CURRENT_TIMESTAMP - interval '1 hour' AND receipt_succeeded
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - INTEGER
                - NUMBER

      - name: MEMO
        description: "{{ doc('memo')}}"

      - name: DESTINATION_ADDRESS
        description: "{{ doc('destination_address')}}"
        tests:
          - not_null:
              where: _inserted_timestamp <= CURRENT_TIMESTAMP - interval '1 hour' AND receipt_succeeded
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - STRING
                - VARCHAR

      - name: SOURCE_ADDRESS
        description: "{{ doc('source_address')}}"

      - name: PLATFORM
        description: "{{ doc('platform')}}"

      - name: BRIDGE_ADDRESS
        description: "{{ doc('contract_address')}}"

      - name: DESTINATION_CHAIN_ID
        description: "{{ doc('chain_id')}}"
        tests:
          - not_null:
              where: _inserted_timestamp <= CURRENT_TIMESTAMP - interval '1 hour' AND receipt_succeeded
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - NUMBER
                - INTEGER

      - name: SOURCE_CHAIN_ID
        description: "{{ doc('chain_id')}}"
        tests:
          - not_null:
              where: _inserted_timestamp <= CURRENT_TIMESTAMP - interval '1 hour' AND receipt_succeeded
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - NUMBER
                - INTEGER

      - name: RECEIPT_SUCCEEDED
        description: "{{ doc('receipt_succeeded')}}"
        tests:
          - not_null

      - name: METHOD_NAME
        description: "{{ doc('method_name')}}"

      - name: DIRECTION
        description: "{{ doc('direction')}}"

      - name: _INSERTED_TIMESTAMP
        description: "{{ doc('_inserted_timestamp')}}"
        
      - name: _PARTITION_BY_BLOCK_NUMBER
        description: "{{ doc('_partition_by_block_number')}}"

      - name: BRIDGE_WORMHOLE_ID
        description: "{{ doc('id')}}"
        tests:
          - unique

      - name: INSERTED_TIMESTAMP
        description: "{{ doc('inserted_timestamp')}}"

      - name: MODIFIED_TIMESTAMP
        description: "{{ doc('modified_timestamp')}}"

      - name: _INVOCATION_ID
        description: "{{ doc('invocation_id')}}"

'''
'''--- models/silver/curated/defi/lending/burrow/silver__burrow_borrows.sql ---
{{ config(
    materialized = 'incremental',
    incremental_strategy = 'merge',
    merge_exclude_columns = ["inserted_timestamp"],
    unique_key = "burrow_borrows_id",
    cluster_by = ['block_timestamp::DATE'],
    tags = ['curated']
) }}

WITH --borrows from Burrow LendingPool contracts
borrows AS (

    SELECT
        action_id as action_id,
        block_id,
        block_timestamp,
        tx_hash,
        method_name,
        args,
        receiver_id,
        receipt_succeeded,
        _inserted_timestamp,
        _partition_by_block_number,
        modified_timestamp AS _modified_timestamp
    FROM
        {{ ref('silver__actions_events_function_call_s3') }}
    WHERE
        receiver_id = 'contract.main.burrow.near'
        AND method_name = 'oracle_on_call'
        AND receipt_succeeded = TRUE

        {% if var("MANUAL_FIX") %}
        AND {{ partition_load_manual('no_buffer') }}
        {% else %}
        {% if is_incremental() %}
            AND _modified_timestamp >= (
                SELECT
                    MAX(_modified_timestamp)
                FROM
                    {{ this }}
            )
        {% endif %}
        {% endif %}

),
FINAL AS (
    SELECT
        *,
        args :sender_id :: STRING AS sender_id,
        receiver_id AS contract_address,
        PARSE_JSON(
            args :msg
        ) :Execute :actions [0] : Borrow :: OBJECT  AS segmented_data,
        segmented_data :token_id AS token_contract_address,
        COALESCE( segmented_data :amount,segmented_data :max_amount)  AS amount_raw,
        'borrow' :: STRING AS actions
    FROM
        borrows
    WHERE
        segmented_data IS NOT NULL
)
SELECT
    action_id,
    tx_hash,
    block_id,
    block_timestamp,
    sender_id,
    actions,
    contract_address,
    amount_raw,
    token_contract_address,
    _inserted_timestamp,
    _modified_timestamp,
    _partition_by_block_number,
    {{ dbt_utils.generate_surrogate_key(
        ['action_id']
    ) }} AS burrow_borrows_id,
    SYSDATE() AS inserted_timestamp,
    SYSDATE() AS modified_timestamp,
    '{{ invocation_id }}' AS _invocation_id
FROM
    FINAL

'''
'''--- models/silver/curated/defi/lending/burrow/silver__burrow_borrows.yml ---
version: 2
models:
  - name: silver__burrow_borrows
    columns:
      - name: action_id
        description: "{{ doc('action_id')}}"
        tests:
          - not_null
          - unique

      - name: TX_HASH
        description: "{{ doc('tx_hash')}}"
        tests:
          - not_null

      - name: block_id
        description: "{{ doc('block_id')}}"
        tests:
          - not_null

      - name: BLOCK_TIMESTAMP
        description: "{{ doc('block_timestamp')}}"
        tests:
          - not_null:
              where: _inserted_timestamp <= current_timestamp - interval '1 hour'

      - name: SENDER_ID
        description: "{{ doc('sender_id')}}"

      - name: ACTIONS
        description: "{{ doc('action')}}"

      - name: CONTRACT_ADDRESS
        description: "{{ doc('contract_address')}}"

      - name: AMOUNT_RAW
        description: "{{ doc('amount_raw')}}"

      - name: TOKEN_CONTRACT_ADDRESS
        description: "{{ doc('token_contract')}}"

      - name: _PARTITION_BY_BLOCK_NUMBER
        description: "{{ doc('_partition_by_block_number')}}"

      - name: BURROW_BORROWS_ID
        description: "{{doc('id')}}"
        test:
          - not_null
          - unique

      - name: INSERTED_TIMESTAMP
        description: "{{doc('inserted_timestamp')}}"

      - name: MODIFIED_TIMESTAMP
        description: "{{doc('modified_timestamp')}}"

      - name: _INVOCATION_ID
        description: "{{doc('invocation_id')}}"

'''
'''--- models/silver/curated/defi/lending/burrow/silver__burrow_collaterals.sql ---
{{ config(
    materialized = 'incremental',
    incremental_strategy = 'merge',
    merge_exclude_columns = ["inserted_timestamp"],
    unique_key = "burrow_collaterals_id",
    cluster_by = ['block_timestamp::DATE'],
    tags = ['curated']
) }}

WITH
actions AS (

    SELECT
        action_id AS action_id,
        block_id,
        block_timestamp,
        tx_hash,
        method_name,
        args,
        logs,
        receiver_id,
        receipt_succeeded,
        _inserted_timestamp,
        _partition_by_block_number,
        modified_timestamp AS _modified_timestamp
    FROM
        {{ ref('silver__actions_events_function_call_s3') }}
    WHERE
        receiver_id = 'contract.main.burrow.near'
        AND receipt_succeeded = TRUE

        {% if var("MANUAL_FIX") %}
        AND 
        {{ partition_load_manual('no_buffer') }}
        {% else %}
            {% if is_incremental() %}
        
            AND _modified_timestamp >= (
                SELECT
                    MAX(_modified_timestamp)
                FROM
                    {{ this }}
            )
        {% endif %}
        {% endif %}
),
FINAL AS (
    SELECT
        *,
        args :sender_id:: STRING AS sender_id,
        receiver_id AS contract_address,
        CASE 
            WHEN method_name = 'ft_on_transfer' THEN PARSE_JSON(SUBSTRING(logs [1], 12))
            WHEN method_name = 'oracle_on_call' THEN PARSE_JSON(SUBSTRING(logs [0], 12))
        END :: OBJECT  AS segmented_data,
        segmented_data :data [0] :account_id AS account_id,
        segmented_data :data [0] :token_id AS token_contract_address,
        segmented_data :data [0] :amount :: NUMBER AS amount_raw,
        segmented_data :event :: STRING AS actions
    FROM 
        actions
    WHERE
        (
        (method_name = 'ft_on_transfer'
        AND args:msg != ''
        AND actions = 'increase_collateral') -- increase_collateral
            OR
        (method_name = 'oracle_on_call'
        AND actions = 'decrease_collateral') -- decrease_collateral
        )
    )
SELECT
    action_id,
    tx_hash,
    block_id,
    block_timestamp,
    sender_id,
    actions,
    contract_address,
    amount_raw,
    token_contract_address,
    _inserted_timestamp,
    _modified_timestamp,
    _partition_by_block_number,
    {{ dbt_utils.generate_surrogate_key(
        ['action_id']
    ) }} AS burrow_collaterals_id,
    SYSDATE() AS inserted_timestamp,
    SYSDATE() AS modified_timestamp,
    '{{ invocation_id }}' AS _invocation_id
FROM
    FINAL

'''
'''--- models/silver/curated/defi/lending/burrow/silver__burrow_collaterals.yml ---
version: 2
models:
  - name: silver__burrow_collaterals
    columns:
      - name: action_id
        description: "{{ doc('action_id')}}"
        tests:
          - not_null
          - unique

      - name: TX_HASH
        description: "{{ doc('tx_hash')}}"
        tests:
          - not_null

      - name: block_id
        description: "{{ doc('block_id')}}"
        tests:
          - not_null

      - name: BLOCK_TIMESTAMP
        description: "{{ doc('block_timestamp')}}"
        tests:
          - not_null:
              where: _inserted_timestamp <= current_timestamp - interval '1 hour'

      - name: SENDER_ID
        description: "{{ doc('sender_id')}}"

      - name: ACTIONS
        description: "{{ doc('action')}}"

      - name: CONTRACT_ADDRESS
        description: "{{ doc('contract_address')}}"

      - name: AMOUNT_RAW
        description: "{{ doc('amount_raw')}}"

      - name: TOKEN_CONTRACT_ADDRESS
        description: "{{ doc('token_contract')}}"

      - name: _PARTITION_BY_BLOCK_NUMBER
        description: "{{ doc('_partition_by_block_number')}}"

      - name: BURROW_COLLATERALS_ID
        description: "{{doc('id')}}"
        test:
          - not_null
          - unique

      - name: INSERTED_TIMESTAMP
        description: "{{doc('inserted_timestamp')}}"

      - name: MODIFIED_TIMESTAMP
        description: "{{doc('modified_timestamp')}}"

      - name: _INVOCATION_ID
        description: "{{doc('invocation_id')}}"

'''
'''--- models/silver/curated/defi/lending/burrow/silver__burrow_deposits.sql ---
{{ config(
    materialized = 'incremental',
    incremental_strategy = 'merge',
    merge_exclude_columns = ["inserted_timestamp"],
    unique_key = "burrow_deposits_id",
    cluster_by = ['block_timestamp::DATE'],
    tags = ['curated']
) }}

WITH
deposits AS (

    SELECT
        action_id AS action_id,
        block_id,
        block_timestamp,
        tx_hash,
        method_name,
        args,
        logs,
        receiver_id,
        receipt_succeeded,
        _inserted_timestamp,
        _partition_by_block_number,
        modified_timestamp AS _modified_timestamp
    FROM
        {{ ref('silver__actions_events_function_call_s3') }}
    WHERE
        receiver_id = 'contract.main.burrow.near'
        AND method_name = 'ft_on_transfer'
        AND receipt_succeeded = TRUE

        {% if var("MANUAL_FIX") %}
        AND {{ partition_load_manual('no_buffer') }}
        {% else %}

            {% if is_incremental() %}

            AND _modified_timestamp >= (
                SELECT
                    MAX(_modified_timestamp)
                FROM
                    {{ this }}
            )
        {% endif %}
        {% endif %}
),
FINAL AS (
    SELECT
        *,
        args :sender_id:: STRING AS sender_id,
        receiver_id AS contract_address,
        PARSE_JSON(SUBSTRING(logs [0], 12)) :: OBJECT AS segmented_data,
        segmented_data :data [0] :account_id AS account_id,
        segmented_data :data [0] :token_id AS token_contract_address,
        segmented_data :data [0] :amount :: NUMBER AS amount_raw,
        segmented_data :event :: STRING AS actions
    FROM
        deposits
    )
SELECT
    action_id,
    tx_hash,
    block_id,
    block_timestamp,
    sender_id,
    actions,
    contract_address,
    amount_raw,
    token_contract_address,
    _inserted_timestamp,
    _modified_timestamp,
    _partition_by_block_number,
    {{ dbt_utils.generate_surrogate_key(
        ['action_id']
    ) }} AS burrow_deposits_id,
    SYSDATE() AS inserted_timestamp,
    SYSDATE() AS modified_timestamp,
    '{{ invocation_id }}' AS _invocation_id
FROM
    FINAL

'''
'''--- models/silver/curated/defi/lending/burrow/silver__burrow_deposits.yml ---
version: 2
models:
  - name: silver__burrow_deposits
    columns:
      - name: action_id
        description: "{{ doc('action_id')}}"
        tests:
          - not_null
          - unique

      - name: TX_HASH
        description: "{{ doc('tx_hash')}}"
        tests:
          - not_null

      - name: block_id
        description: "{{ doc('block_id')}}"
        tests:
          - not_null

      - name: BLOCK_TIMESTAMP
        description: "{{ doc('block_timestamp')}}"
        tests:
          - not_null:
              where: _inserted_timestamp <= current_timestamp - interval '1 hour'

      - name: SENDER_ID
        description: "{{ doc('sender_id')}}"

      - name: ACTIONS
        description: "{{ doc('action')}}"

      - name: CONTRACT_ADDRESS
        description: "{{ doc('contract_address')}}"

      - name: AMOUNT_RAW
        description: "{{ doc('amount_raw')}}"

      - name: TOKEN_CONTRACT_ADDRESS
        description: "{{ doc('token_contract')}}"

      - name: _PARTITION_BY_BLOCK_NUMBER
        description: "{{ doc('_partition_by_block_number')}}"

      - name: BURROW_DEPOSITS_ID
        description: "{{doc('id')}}"
        test:
          - not_null
          - unique

      - name: INSERTED_TIMESTAMP
        description: "{{doc('inserted_timestamp')}}"

      - name: MODIFIED_TIMESTAMP
        description: "{{doc('modified_timestamp')}}"

      - name: _INVOCATION_ID
        description: "{{doc('invocation_id')}}"

'''
'''--- models/silver/curated/defi/lending/burrow/silver__burrow_repays.sql ---
{{ config(
    materialized = 'incremental',
    incremental_strategy = 'merge',
    merge_exclude_columns = ["inserted_timestamp"],
    unique_key = "burrow_repays_id",
    cluster_by = ['block_timestamp::DATE'],
    tags = ['curated']
) }}

WITH
actions AS (

    SELECT
        action_id AS action_id,
        block_id,
        block_timestamp,
        tx_hash,
        method_name,
        args,
        logs,
        receiver_id,
        receipt_succeeded,
        _inserted_timestamp,
        _partition_by_block_number,
        modified_timestamp AS _modified_timestamp
    FROM
        {{ ref('silver__actions_events_function_call_s3') }}
    WHERE
        receiver_id = 'contract.main.burrow.near'
        AND receipt_succeeded = TRUE

        {% if var("MANUAL_FIX") %}
        AND {{ partition_load_manual('no_buffer') }}
        {% else %}
            {% if is_incremental() %}
            AND _modified_timestamp >= (
                SELECT
                    MAX(_modified_timestamp)
                FROM
                    {{ this }}
            )
        {% endif %}
        {% endif %}
),
FINAL AS (
    SELECT
        *,
        args :sender_id:: STRING AS sender_id,
        receiver_id AS contract_address,
        PARSE_JSON(SUBSTRING(logs [1], 12)) :: OBJECT AS segmented_data,
        segmented_data :data [0] :account_id AS account_id,
        segmented_data :data [0] :token_id AS token_contract_address,
        segmented_data :data [0] :amount :: NUMBER AS amount_raw,
        segmented_data :event :: STRING AS actions
    FROM
        actions
    WHERE
    (
        (
            method_name = 'ft_on_transfer' -- repay_from_deposit
            AND args:msg != ''
        ) OR (
            method_name = 'oracle_on_call' -- repay_from_decrease_collateral
            )
        )
        AND actions = 'repay'
    )
SELECT
    action_id,
    tx_hash,
    block_id,
    block_timestamp,
    sender_id,
    actions,
    contract_address,
    amount_raw,
    token_contract_address,
    _inserted_timestamp,
    _modified_timestamp,
    _partition_by_block_number,
    {{ dbt_utils.generate_surrogate_key(
        ['action_id']
    ) }} AS burrow_repays_id,
    SYSDATE() AS inserted_timestamp,
    SYSDATE() AS modified_timestamp,
    '{{ invocation_id }}' AS _invocation_id
FROM
    FINAL

'''
'''--- models/silver/curated/defi/lending/burrow/silver__burrow_repays.yml ---
version: 2
models:
  - name: silver__burrow_repays
    columns:
      - name: action_id
        description: "{{ doc('action_id')}}"
        tests:
          - not_null
          - unique

      - name: TX_HASH
        description: "{{ doc('tx_hash')}}"
        tests:
          - not_null

      - name: block_id
        description: "{{ doc('block_id')}}"
        tests:
          - not_null

      - name: BLOCK_TIMESTAMP
        description: "{{ doc('block_timestamp')}}"
        tests:
          - not_null:
              where: _inserted_timestamp <= current_timestamp - interval '1 hour'

      - name: SENDER_ID
        description: "{{ doc('sender_id')}}"

      - name: ACTIONS
        description: "{{ doc('action')}}"

      - name: CONTRACT_ADDRESS
        description: "{{ doc('contract_address')}}"

      - name: AMOUNT_RAW
        description: "{{ doc('amount_raw')}}"

      - name: TOKEN_CONTRACT_ADDRESS
        description: "{{ doc('token_contract')}}"

      - name: _PARTITION_BY_BLOCK_NUMBER
        description: "{{ doc('_partition_by_block_number')}}"

      - name: BURROW_REPAYS_ID
        description: "{{doc('id')}}"
        test:
          - not_null
          - unique

      - name: INSERTED_TIMESTAMP
        description: "{{doc('inserted_timestamp')}}"

      - name: MODIFIED_TIMESTAMP
        description: "{{doc('modified_timestamp')}}"

      - name: _INVOCATION_ID
        description: "{{doc('invocation_id')}}"

'''
'''--- models/silver/curated/defi/lending/burrow/silver__burrow_withdraws.sql ---
{{ config(
    materialized = 'incremental',
    incremental_strategy = 'merge',
    merge_exclude_columns = ["inserted_timestamp"],
    unique_key = "burrow_withdraws_id",
    cluster_by = ['block_timestamp::DATE'],
    tags = ['curated']
) }}

WITH -- successfull withdraws
withdraws AS (

    SELECT
        action_id AS action_id,
        block_id,
        block_timestamp,
        tx_hash,
        method_name,
        args,
        logs,
        receiver_id,
        receipt_succeeded,
        _inserted_timestamp,
        _partition_by_block_number,
        modified_timestamp AS _modified_timestamp
    FROM
        {{ ref('silver__actions_events_function_call_s3') }}
    WHERE
        receiver_id = 'contract.main.burrow.near'
        AND method_name = 'after_ft_transfer'
        AND receipt_succeeded = TRUE

        {% if var("MANUAL_FIX") %}
        AND {{ partition_load_manual('no_buffer') }}
        {% else %}
            {% if is_incremental() %}
            AND _modified_timestamp >= (
                SELECT
                    MAX(_modified_timestamp)
                FROM
                    {{ this }}
            )
        {% endif %}
        {% endif %}
),
FINAL AS (
    SELECT
        *,
        receiver_id AS contract_address,
        PARSE_JSON(SUBSTRING(logs [0], 12)) :: OBJECT AS segmented_data,
        segmented_data :data [0] :account_id AS sender_id,
        segmented_data :data [0] :token_id AS token_contract_address,
        segmented_data :data [0] :amount :: NUMBER AS amount_raw,
        segmented_data :event :: STRING AS actions
    FROM
        withdraws
)
SELECT
    action_id,
    tx_hash,
    block_id,
    block_timestamp,
    sender_id,
    actions,
    contract_address,
    amount_raw,
    token_contract_address,
    _inserted_timestamp,
    _modified_timestamp,
    _partition_by_block_number,
    {{ dbt_utils.generate_surrogate_key(
        ['action_id']
    ) }} AS burrow_withdraws_id,
    SYSDATE() AS inserted_timestamp,
    SYSDATE() AS modified_timestamp,
    '{{ invocation_id }}' AS _invocation_id
FROM
    FINAL
'''
'''--- models/silver/curated/defi/lending/burrow/silver__burrow_withdraws.yml ---
version: 2
models:
  - name: silver__burrow_withdraws
    columns:
      - name: action_id
        description: "{{ doc('action_id')}}"
        tests:
          - not_null
          - unique

      - name: TX_HASH
        description: "{{ doc('tx_hash')}}"
        tests:
          - not_null

      - name: block_id
        description: "{{ doc('block_id')}}"
        tests:
          - not_null

      - name: BLOCK_TIMESTAMP
        description: "{{ doc('block_timestamp')}}"
        tests:
          - not_null:
              where: _inserted_timestamp <= current_timestamp - interval '1 hour'

      - name: SENDER_ID
        description: "{{ doc('sender_id')}}"

      - name: ACTIONS
        description: "{{ doc('action')}}"

      - name: CONTRACT_ADDRESS
        description: "{{ doc('contract_address')}}"

      - name: AMOUNT_RAW
        description: "{{ doc('amount_raw')}}"

      - name: TOKEN_CONTRACT_ADDRESS
        description: "{{ doc('token_contract')}}"

      - name: _PARTITION_BY_BLOCK_NUMBER
        description: "{{ doc('_partition_by_block_number')}}"

      - name: BURROW_WITHDRAWS_ID
        description: "{{doc('id')}}"
        test:
          - not_null
          - unique

      - name: INSERTED_TIMESTAMP
        description: "{{doc('inserted_timestamp')}}"

      - name: MODIFIED_TIMESTAMP
        description: "{{doc('modified_timestamp')}}"

      - name: _INVOCATION_ID
        description: "{{doc('invocation_id')}}"

'''
'''--- models/silver/curated/defi/lending/silver__burrow_lending.sql ---
{{ config(
    materialized = 'view',
    tags = ['core']
) }}

WITH borrows AS
(
    SELECT
        *
    FROM
        {{ ref('silver__burrow_borrows') }}

),
collaterals AS
(
    SELECT
        *
    FROM
        {{ ref('silver__burrow_collaterals') }}
),
deposits AS
(
    SELECT
        *
    FROM
        {{ ref('silver__burrow_deposits') }}

),
repays AS
(
    SELECT
        *
    FROM
        {{ ref('silver__burrow_repays') }}
),
withdrawals AS
(
    SELECT
        *
    FROM
        {{ ref('silver__burrow_withdraws') }}

),
FINAL AS (
    SELECT
        burrow_borrows_id as  burrow_lending_id,
        *
    FROM
        borrows
    UNION ALL
    SELECT
        burrow_collaterals_id as  burrow_lending_id,
        *
    FROM
        collaterals
    UNION ALL
    SELECT
        burrow_deposits_id as  burrow_lending_id,
        *
    FROM
        deposits
    UNION ALL
    SELECT
        burrow_repays_id as  burrow_lending_id,
        *
    FROM
        repays
    UNION ALL
    SELECT
        burrow_withdraws_id as  burrow_lending_id,
        *
    FROM
        withdrawals
)
SELECT
    'burrow' as platform,
    tx_hash,
    block_id,
    block_timestamp,
    sender_id,
    actions,
    contract_address,
    amount_raw,
    burrow_lending_id,
    token_contract_address as token_address,
    inserted_timestamp,
    modified_timestamp
FROM
    FINAL
'''
'''--- models/silver/curated/defi/silver__dex_swaps_s3.sql ---
{{ config(
    materialized = "incremental",
    unique_key = "swap_id",
    incremental_strategy = "merge",
    merge_exclude_columns = ["inserted_timestamp"],
    cluster_by = ["block_timestamp::DATE"],
    tags = ['curated'],
    enabled = False
) }}
{# DEPRECATED JANUARY 2024 #}
WITH base_swap_calls AS (

    SELECT
        block_id,
        block_timestamp,
        tx_hash,
        action_id,
        args,
        _inserted_timestamp,
        method_name
    FROM
        {{ ref('silver__actions_events_function_call_s3') }}
    WHERE
        method_name IN (
            'swap',
            'ft_transfer_call'
        ) {% if var("MANUAL_FIX") %}
            AND {{ partition_load_manual('no_buffer') }}
        {% else %}
            AND {{ incremental_load_filter('_inserted_timestamp') }}
        {% endif %}
),
base_swaps AS (
    SELECT
        block_id,
        block_timestamp,
        tx_hash,
        action_id,
        IFF(
            method_name = 'ft_transfer_call',
            TRY_PARSE_JSON(TRY_PARSE_JSON(args) :msg),
            TRY_PARSE_JSON(args)
        ) :actions AS actions,
        _inserted_timestamp
    FROM
        base_swap_calls
),
agg_swaps AS (
    SELECT
        tx_hash,
        ANY_VALUE(block_id) AS block_id,
        ANY_VALUE(block_timestamp) AS block_timestamp,
        ARRAY_AGG(
            action.value
        ) within GROUP (
            ORDER BY
                action_id,
                action.index
        ) AS action_list,
        ANY_VALUE(_inserted_timestamp) AS _inserted_timestamp
    FROM
        base_swaps,
        LATERAL FLATTEN(
            input => actions
        ) action
    GROUP BY
        1
),
actions AS (
    SELECT
        block_id,
        block_timestamp,
        tx_hash,
        NULLIF(
            action.value :pool_id,
            NULL
        ) AS pool_id,
        NULLIF(
            action.value :token_in,
            NULL
        ) :: text AS token_in,
        NULLIF(
            action.value :token_out,
            NULL
        ) :: text AS token_out,
        action.index AS swap_index,
        _inserted_timestamp
    FROM
        agg_swaps,
        LATERAL FLATTEN(
            input => action_list
        ) action
    WHERE
        NOT RLIKE(
            pool_id,
            '.*[a-z].*',
            'i'
        )
),
receipts AS (
    SELECT
        block_id,
        tx_hash,
        -- TODO use the receipt succeeded column here
        CASE
            WHEN PARSE_JSON(
                r.status_value
            ) :Failure IS NOT NULL THEN 'Fail'
            ELSE 'Success'
        END AS success_or_fail,
        logs
    FROM
        {{ ref("silver__streamline_receipts_final") }}
        r
    WHERE
        tx_hash IN (
            SELECT
                tx_hash
            FROM
                actions
        )
),
flat_receipts AS (
    SELECT
        tx_hash,
        l.value,
        l.index,
        success_or_fail
    FROM
        receipts,
        LATERAL FLATTEN(
            input => logs
        ) l
),
swap_logs AS (
    SELECT
        tx_hash,
        ROW_NUMBER() over (
            PARTITION BY tx_hash
            ORDER BY
                INDEX ASC
        ) - 1 AS swap_index,
        VALUE,
        success_or_fail
    FROM
        flat_receipts
    WHERE
        VALUE LIKE 'Swapped%'
),
transactions AS (
    SELECT
        block_id,
        block_timestamp,
        tx_hash,
        tx_signer,
        tx_receiver
    FROM
        {{ ref("silver__streamline_transactions_final") }}
    WHERE
        tx_hash IN (
            SELECT
                tx_hash
            FROM
                actions
        )
),
token_labels AS (
    SELECT
        *
    FROM
        {{ ref("silver__token_labels") }}
),
final_table AS (
    SELECT
        swap_logs.swap_index,
        actions._inserted_timestamp,
        actions.block_id,
        actions.block_timestamp,
        swap_logs.tx_hash,
        CONCAT(
            swap_logs.tx_hash,
            '-',
            swap_logs.swap_index
        ) AS swap_id,
        swap_logs.value AS log_data,
        transactions.tx_signer AS trader,
        transactions.tx_receiver AS platform,
        LAST_VALUE(
            swap_logs.success_or_fail
        ) over (
            PARTITION BY swap_logs.tx_hash
            ORDER BY
                swap_logs.success_or_fail DESC
        ) AS txn_status,
        actions.pool_id :: INT AS pool_id,
        actions.token_in,
        actions.token_out
    FROM
        actions
        INNER JOIN swap_logs
        ON (
            swap_logs.tx_hash = actions.tx_hash
            AND swap_logs.swap_index = actions.swap_index
        )
        JOIN transactions
        ON actions.tx_hash = transactions.tx_hash
),
FINAL AS (
    SELECT
        block_id,
        block_timestamp,
        tx_hash,
        swap_id,
        platform,
        trader,
        pool_id,
        token_in,
        token_labels_in.symbol AS token_in_symbol,
        REGEXP_SUBSTR(
            log_data,
            'Swapped (\\d+)',
            1,
            1,
            'e'
        ) :: NUMBER AS amount_in_raw,
        amount_in_raw / pow(10, IFNULL(token_labels_in.decimals, 0)) AS amount_in,
        token_out,
        token_labels_out.symbol AS token_out_symbol,
        REGEXP_SUBSTR(
            log_data,
            'Swapped \\d+ .+ for (\\d+)',
            1,
            1,
            'e'
        ) :: NUMBER AS amount_out_raw,
        amount_out_raw / pow(10, IFNULL(token_labels_out.decimals, 0)) AS amount_out,
        swap_index,
        _inserted_timestamp
    FROM
        final_table
        LEFT JOIN token_labels AS token_labels_in
        ON final_table.token_in = token_labels_in.token_contract
        LEFT JOIN token_labels AS token_labels_out
        ON final_table.token_out = token_labels_out.token_contract
    WHERE
        txn_status = 'Success'
        AND log_data IS NOT NULL
)
SELECT
    *,
    {{ dbt_utils.generate_surrogate_key(
        ['swap_id']
    ) }} AS dex_swaps_id,
    SYSDATE() AS inserted_timestamp,
    SYSDATE() AS modified_timestamp,
    '{{ invocation_id }}' AS _invocation_id
FROM
    FINAL

'''
'''--- models/silver/curated/defi/silver__dex_swaps_s3.yml ---
version: 2

models:
  - name: silver__dex_swaps_s3
    description: |-
      This table records all the swap transactions occurring in NEAR. This model is being deprecated as of January 2024. It will remain live through February for users to migrate to the new model.
      This logic is outdated / inaccurate.

    columns:
      - name: BLOCK_ID
        description: "{{ doc('block_id')}}"

      - name: BLOCK_TIMESTAMP
        description: "{{ doc('block_timestamp')}}"
        tests:
          - not_null:
              where: _inserted_timestamp <= CURRENT_TIMESTAMP - interval '1 hour'
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - TIMESTAMP_NTZ

      - name: TX_HASH
        description: "{{ doc('tx_hash')}}"
        tests:
          - not_null:
              where: _inserted_timestamp <= CURRENT_TIMESTAMP - interval '1 hour'
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - STRING
                - VARCHAR

      - name: SWAP_ID
        description: "{{ doc('swap_id')}}"

      - name: PLATFORM
        description: "{{ doc('platform')}}"

      - name: TRADER
        description: "{{ doc('trader')}}"

      - name: POOL_ID
        description: "{{ doc('pool_id')}}"

      - name: TOKEN_IN
        description: "{{ doc('token_in')}}"

      - name: AMOUNT_IN
        description: "{{ doc('amount_in')}}"

      - name: TOKEN_OUT
        description: "{{ doc('token_out')}}"

      - name: AMOUNT_OUT
        description: "{{ doc('amount_out')}}"

      - name: SWAP_INDEX
        description: "{{ doc('swap_index')}}"

      - name: _INSERTED_TIMESTAMP
        description: "{{ doc('_inserted_timestamp')}}"

      - name: DEX_SWAPS_ID
        description: "{{doc('id')}}"

      - name: INSERTED_TIMESTAMP
        description: "{{doc('inserted_timestamp')}}"

      - name: MODIFIED_TIMESTAMP
        description: "{{doc('modified_timestamp')}}"

      - name: _INVOCATION_ID
        description: "{{doc('invocation_id')}}"

'''
'''--- models/silver/curated/defi/silver__dex_swaps_v2.sql ---
{{ config(
    materialized = 'incremental',
    incremental_strategy = 'merge',
    merge_exclude_columns = ["inserted_timestamp"],
    unique_key = 'dex_swaps_v2_id',
    tags = ['curated'],
) }}
{# Note - multisource model #}
WITH swap_logs AS (

    SELECT
        tx_hash,
        receipt_object_id,
        block_id,
        block_timestamp,
        receiver_id,
        signer_id,
        log_index,
        clean_log,
        _partition_by_block_number,
        _inserted_timestamp,
        modified_timestamp AS _modified_timestamp
    FROM
        {{ ref('silver__logs_s3') }}
    WHERE
        receipt_succeeded
        AND clean_log LIKE 'Swapped%'
        AND receiver_id NOT LIKE '%dragon_bot.near' 

        {% if var("MANUAL_FIX") %}
        AND {{ partition_load_manual('no_buffer') }}
        {% else %}
            {% if is_incremental() %}
            AND _modified_timestamp >= (
                SELECT
                    MAX(_modified_timestamp)
                FROM
                    {{ this }}
            )
        {% endif %}
        {% endif %}
),
receipts AS (
    SELECT
        receipt_object_id,
        receipt_actions,
        receiver_id,
        signer_id,
        _partition_by_block_number,
        _inserted_timestamp,
        modified_timestamp AS _modified_timestamp
    FROM
        {{ ref('silver__streamline_receipts_final') }}
    WHERE
        receipt_object_id IN (
            SELECT
                receipt_object_id
            FROM
                swap_logs
        )
        {% if var("MANUAL_FIX") %}
        AND {{ partition_load_manual('no_buffer') }}
        {% else %}
            {% if is_incremental() %}
            AND _modified_timestamp >= (
                SELECT
                    MAX(_modified_timestamp)
                FROM
                    {{ this }}
            )
        {% endif %}
        {% endif %}
),
swap_outcome AS (
    SELECT
        tx_hash,
        receipt_object_id,
        block_id,
        block_timestamp,
        receiver_id,
        signer_id,
        ROW_NUMBER() over (
            PARTITION BY receipt_object_id
            ORDER BY
                log_index ASC
        ) - 1 AS swap_index,
        COALESCE(SPLIT(clean_log, ',') [0], clean_log) AS LOG,
        REGEXP_REPLACE(
            LOG,
            '.*Swapped (\\d+) (.*) for (\\d+) (.*)',
            '\\1'
        ) :: INT AS amount_out_raw,
        REGEXP_REPLACE(
            LOG,
            '.*Swapped \\d+ (\\S+) for (\\d+) (.*)',
            '\\1'
        ) :: STRING AS token_out,
        REGEXP_REPLACE(
            LOG,
            '.*Swapped \\d+ \\S+ for (\\d+) (.*)',
            '\\1'
        ) :: INT AS amount_in_raw,
        REGEXP_REPLACE(
            LOG,
            '.*Swapped \\d+ \\S+ for \\d+ (.*)',
            '\\1'
        ) :: STRING AS token_in,
        _partition_by_block_number,
        _inserted_timestamp,
        _modified_timestamp
    FROM
        swap_logs
),
parse_actions AS (
    SELECT
        tx_hash,
        o.receipt_object_id,
        block_id,
        block_timestamp,
        receiver_id,
        signer_id,
        swap_index,
        LOG,
        amount_out_raw,
        token_out,
        amount_in_raw,
        token_in,
        ARRAY_SIZE(
            receipt_actions :receipt :Action :actions
        ) AS action_ct,
        TRY_PARSE_JSON(
            TRY_BASE64_DECODE_STRING(
                CASE
                    -- Some swaps first have a register or storage action, then swap in final action (some may have both, so could be 2 or 3 actions)
                    WHEN receipt_actions :receipt :Action :actions [0] :FunctionCall :method_name IN (
                        'register_tokens',
                        'storage_deposit'
                    ) THEN receipt_actions :receipt :Action :actions [action_ct - 1] :FunctionCall :args -- <3,000 swaps across Ref and Refv2 execute multiple swaps in 1 receipt, with inputs spread across multiple action entities
                    WHEN action_ct > 1 THEN receipt_actions :receipt :Action :actions [action_ct - 1] :FunctionCall :args -- most all other swaps execute multiswaps in 1 receipt, with 1 log and 1 action (that may contain an array of inputs for multiswap, per below)
                    ELSE receipt_actions :receipt :Action :actions [0] :FunctionCall :args
                END
            )
        ) AS decoded_action,
        TRY_PARSE_JSON(
            COALESCE(
                TRY_PARSE_JSON(
                    COALESCE(
                        -- input data is stored in the decoded action
                        -- for multi-swaps, there is (often) one action with an array of input dicts that correspond with the swap index
                        decoded_action :msg,
                        -- Swap must be capitalized! Autoformat may change to "swap"
                        decoded_action :operation: Swap,
                        decoded_action
                    )
                ) :actions [swap_index],
                -- may also be stored directly in msg key, rather than within an array of size 1
                decoded_action :msg,
                -- signer test_near.near executed multistep swaps, with separate actions, and one encoded input per action
                decoded_action :actions [0]
            )
        ) AS swap_input_data,
        r.receiver_id AS receipt_receiver_id,
        r.signer_id AS receipt_signer_id,
        o._partition_by_block_number,
        o._inserted_timestamp,
        o._modified_timestamp
    FROM
        swap_outcome o
        LEFT JOIN receipts r USING (receipt_object_id)
),
FINAL AS (
    SELECT
        tx_hash,
        receipt_object_id,
        block_id,
        block_timestamp,
        receiver_id,
        signer_id,
        swap_index,
        amount_out_raw,
        token_out,
        amount_in_raw,
        token_in,
        swap_input_data,
        LOG,
        _partition_by_block_number,
        _inserted_timestamp,
        _modified_timestamp
    FROM
        parse_actions
)
SELECT
    *,
    {{ dbt_utils.generate_surrogate_key(
        ['receipt_object_id', 'swap_index']
    ) }} AS dex_swaps_v2_id,
    SYSDATE() AS inserted_timestamp,
    SYSDATE() AS modified_timestamp,
    '{{ invocation_id }}' AS _invocation_id
FROM
    FINAL

'''
'''--- models/silver/curated/defi/silver__dex_swaps_v2.yml ---
version: 2

models:
  - name: silver__dex_swaps_v2
    description: |-
      Parses log output data for swap information. It was determined logs must be used over inputs in a FunctionCall as only the output contains actual swap information. See tx AfvgkUxP8taJNBLaZYvFumFrrePpJujb2gjQJz7YbRiM as an example.
    tests:
      - dbt_utils.recency:
          datepart: day
          field: block_timestamp
          interval: 1

    columns:
      - name: TX_HASH
        description: "{{ doc('tx_hash')}}"
        tests:
          - not_null:
              where: _inserted_timestamp <= CURRENT_TIMESTAMP - interval '1 hour'
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - STRING
                - VARCHAR

      - name: RECEIPT_OBJECT_ID
        description: "{{ doc('receipt_object_id')}}"
        tests:
          - not_null

      - name: BLOCK_ID
        description: "{{ doc('block_id')}}"

      - name: BLOCK_TIMESTAMP
        description: "{{ doc('block_timestamp')}}"
        tests:
          - not_null:
              where: _inserted_timestamp <= CURRENT_TIMESTAMP - interval '1 hour'
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - TIMESTAMP_NTZ

      - name: RECEIVER_ID
        description: "{{ doc('receiver_id')}}"

      - name: SIGNER_ID
        description: "{{ doc('signer_id')}}"
      
      - name: SWAP_INDEX
        description: "{{ doc('index')}}"

      - name: AMOUNT_OUT_RAW
        description: "{{ doc('amount_out_raw')}}"
        tests:
          - not_null

      - name: TOKEN_OUT
        description: "{{ doc('token_out')}}"
        tests:
          - not_null

      - name: AMOUNT_IN_RAW
        description: "{{ doc('amount_in_raw')}}"
        tests:
          - not_null

      - name: TOKEN_IN
        description: "{{ doc('token_in')}}"
        tests:
          - not_null

      - name: SWAP_INPUT_DATA
        description: "{{ doc('swap_input_data')}}"
        tests:
          - not_null

      - name: LOG
        description: "{{ doc('clean_log')}}"

      - name: _PARTITION_BY_BLOCK_NUMBER
        description: "{{doc('_partition_by_block_number')}}"

      - name: _INSERTED_TIMESTAMP
        description: "{{doc('_inserted_timestamp')}}"

      - name: _MODIFIED_TIMESTAMP
        description: "{{doc('_modified_timestamp')}}"

      - name: DEX_SWAPS_V2_ID
        description: "{{doc('id')}}"
        tests:
          - unique

      - name: INSERTED_TIMESTAMP
        description: "{{doc('inserted_timestamp')}}"

      - name: MODIFIED_TIMESTAMP
        description: "{{doc('modified_timestamp')}}"

      - name: _INVOCATION_ID
        description: "{{doc('invocation_id')}}"

'''
'''--- models/silver/curated/nft/silver__nft_sales.sql ---
{{ config(
    materialized = 'incremental',
    merge_exclude_columns = ["inserted_timestamp"],
    cluster_by = ['block_timestamp::DATE'],
    unique_key = 'nft_sales_id',
    incremental_strategy = 'merge',
    tags = ['curated']
) }}

WITH actions_events AS (

    SELECT
        block_id,
        block_timestamp,
        tx_hash,
        action_id,
        signer_id,
        receiver_id,
        method_name,
        deposit,
        args,
        logs,
        attached_gas,
        _partition_by_block_number,
        _inserted_timestamp,
        modified_timestamp AS _modified_timestamp
    FROM
        {{ ref('silver__actions_events_function_call_s3') }}
    WHERE
        receipt_succeeded = TRUE
        AND logs [0] IS NOT NULL

    {% if var("MANUAL_FIX") %}
      AND {{ partition_load_manual('no_buffer') }}
    {% else %}
        {% if is_incremental() %}
        AND _modified_timestamp >= (
            SELECT
                MAX(_modified_timestamp)
            FROM
                {{ this }}
        )
        {% endif %}
    {% endif %}
),
prices AS (
    --get closing price for the hour
    SELECT
        DATE_TRUNC(
            'HOUR',
            block_timestamp
        ) AS block_timestamp_hour,
        price_usd
    FROM
        {{ ref('silver__prices_oracle_s3') }}
    WHERE
        token = 'Wrapped NEAR fungible token' qualify ROW_NUMBER() over (
            PARTITION BY block_timestamp_hour
            ORDER BY
                block_timestamp DESC
        ) = 1
),
raw_logs AS (
    SELECT
        *,
        l.index AS logs_index,
        TRY_PARSE_JSON(REPLACE(l.value :: STRING, 'EVENT_JSON:', '')) AS event_json
    FROM
        actions_events A,
        LATERAL FLATTEN(
            input => A.logs
        ) l
),
------------------------------- MINTBASE  -------------------------------
mintbase_nft_sales AS (
    SELECT
        action_id,
        block_id,
        block_timestamp,
        tx_hash,
        attached_gas,
        IFF(method_name = 'buy', TRUE, FALSE) AS is_buy,  --- else resolve_nft_payout
        IFF(is_buy, args :nft_contract_id, args :token :owner_id) :: STRING AS seller_address,
        IFF( is_buy, signer_id, args :token :current_offer :from) :: STRING AS buyer_address,
        receiver_id AS platform_address,
        'Mintbase' AS platform_name,
        IFF(is_buy, args :nft_contract_id, args :token :store_id) :: STRING AS nft_address,
        IFF(is_buy, args :token_id, args :token :id) :: STRING AS token_id,
        IFF(is_buy, deposit, args :token :current_offer :price) / 1e24 AS price,
        IFF(is_buy, 'nft_sale', 'nft_sold') AS method_name,
        args AS LOG,
        logs_index,
        _inserted_timestamp,
        _modified_timestamp,
        _partition_by_block_number
    FROM
        raw_logs
    WHERE
        (
            receiver_id = 'simple.market.mintbase1.near'
            AND method_name = 'buy'
        )
        OR (
            receiver_id = 'market.mintbase1.near'
            AND method_name = 'resolve_nft_payout'
        )
),
------------------------ OTHER MARKETPLACES  -------------------------------
other_nft_sales AS (
    SELECT
        action_id,
        block_id,
        block_timestamp,
        tx_hash,
        attached_gas,
        COALESCE(
            args :market_data :owner_id,
            args :sale :owner_id,
            args :seller_id
        ) :: STRING AS seller_address,
        COALESCE(
            args :buyer_id,
            args :offer_data :buyer_id
        ) :: STRING AS buyer_address,
        receiver_id AS platform_address,
        CASE
            WHEN receiver_id = 'marketplace.paras.near' THEN 'Paras'
            WHEN receiver_id = 'market.l2e.near' THEN 'L2E'
            WHEN receiver_id = 'market.nft.uniqart.near' THEN 'UniqArt'
            WHEN receiver_id = 'market.tradeport.near' THEN 'TradePort'
            WHEN receiver_id = 'market.fewandfar.near' THEN 'FewAndFar'
            WHEN receiver_id = 'apollo42.near' THEN 'Apollo42'
        END :: STRING AS platform_name,
        COALESCE(
            args :market_data :nft_contract_id,
            args :sale :nft_contract_id,
            args :offer_data :nft_contract_id
        ) :: STRING AS nft_address,
        COALESCE(
            args :market_data :token_id,
            args :sale :token_id,
            args :token_id
        ) :: STRING AS token_id,
        COALESCE(
            args :price,
            args :offer_data :price,
            args: market_data :price
        ) / 1e24 AS price,
        method_name,
        args AS LOG,
        logs_index,
        _inserted_timestamp,
        _modified_timestamp,
        _partition_by_block_number
    FROM
        raw_logs
    WHERE
        receiver_id IN (
            'apollo42.near',
            'market.tradeport.near',
            'market.nft.uniqart.near',
            'market.l2e.near',
            'marketplace.paras.near',
            'market.fewandfar.near'
        )
        AND method_name IN (
            'resolve_purchase',
            'resolve_offer'
        )
),
------------------------------- MITTE  -------------------------------
mitte_nft_sales AS (
    SELECT
        action_id,
        block_id,
        block_timestamp,
        tx_hash,
        attached_gas,
        CASE
            WHEN SPLIT(
                event_json :data :order [2],
                ':'
            ) [1] = 'near' THEN event_json :data :order [6]
            ELSE event_json :data :order [1]
        END :: STRING AS seller_address,
        CASE
            WHEN SPLIT(
                event_json :data :order [2],
                ':'
            ) [1] = 'near' THEN event_json :data :order [1]
            ELSE event_json :data :order [6]
        END :: STRING AS buyer_address,
        receiver_id AS platform_address,
        'Mitte' AS platform_name,
        CASE
            WHEN SPLIT(
                event_json :data :order [2],
                ':'
            ) [1] = 'near' THEN SPLIT(
                event_json :data :order [7],
                ':'
            ) [1]
            ELSE SPLIT(
                event_json :data :order [2],
                ':'
            ) [1]
        END :: STRING AS nft_address,
        CASE
            WHEN SPLIT(
                event_json :data :order [2],
                ':'
            ) [1] = 'near'
            AND SPLIT(
                event_json :data :order [7],
                ':'
            ) [4] IS NULL THEN SPLIT(
                event_json :data :order [7],
                ':'
            ) [2]
            WHEN SPLIT(
                event_json :data :order [2],
                ':'
            ) [1] = 'near'
            AND SPLIT(
                event_json :data :order [7],
                ':'
            ) [4] IS NOT NULL THEN SPLIT(
                event_json :data :order [7],
                ':'
            ) [2] || ':' || SPLIT(
                event_json :data :order [7],
                ':'
            ) [3]
            WHEN SPLIT(
                event_json :data :order [2],
                ':'
            ) [4] IS NULL THEN SPLIT(
                event_json :data :order [2],
                ':'
            ) [2]
            ELSE SPLIT(
                event_json :data :order [2],
                ':'
            ) [2] || ':' || SPLIT(
                event_json :data :order [2],
                ':'
            ) [3]
        END :: STRING AS token_id,
        CASE
            WHEN SPLIT(
                event_json :data :order [2],
                ':'
            ) [1] = 'near' THEN SPLIT(
                event_json :data :order [2],
                ':'
            ) [3]
            ELSE SPLIT(
                event_json :data :order [7],
                ':'
            ) [3]
        END / 1e24 AS price,
        event_json :event :: STRING AS method_name,
        event_json AS LOG,
        logs_index,
        _inserted_timestamp,
        _modified_timestamp,
        _partition_by_block_number
    FROM
        raw_logs
    WHERE
        receiver_id = 'a.mitte-orderbook.near'
        AND event_json :event :: STRING != 'nft_mint'
        AND event_json :data :order [6] :: STRING != ''
),
------------------------------- FINAL   -------------------------------
sales_union AS (
    SELECT
        action_id,
        block_id,
        block_timestamp,
        tx_hash,
        attached_gas,
        seller_address,
        buyer_address,
        platform_address,
        platform_name,
        nft_address,
        token_id,
        price,
        method_name,
        LOG,
        logs_index,
        _inserted_timestamp,
        _modified_timestamp,
        _partition_by_block_number
    FROM
        mintbase_nft_sales
    UNION ALL
    SELECT
        *
    FROM
        other_nft_sales
    UNION ALL
    SELECT
        *
    FROM
        mitte_nft_sales
),
FINAL AS (
    SELECT
        split_part(action_id, '-', 1) AS receipt_id,
        block_id,
        block_timestamp,
        tx_hash,
        attached_gas AS gas_burned,
        seller_address,
        buyer_address,
        platform_address,
        platform_name,
        nft_address,
        token_id,
        method_name,
        LOG,
        price,
        s.price * p.price_usd AS price_usd,
        logs_index,
        _inserted_timestamp,
        _modified_timestamp,
        _partition_by_block_number
    FROM
        sales_union s
        LEFT JOIN prices p
        ON DATE_TRUNC(
            'hour',
            s.block_timestamp
        ) = p.block_timestamp_hour
)
SELECT
    *,
    {{ dbt_utils.generate_surrogate_key(
        ['receipt_id', 'logs_index']
    ) }} AS nft_sales_id,
    SYSDATE() AS inserted_timestamp,
    SYSDATE() AS modified_timestamp,
    '{{ invocation_id }}' AS _invocation_id
FROM
    FINAL

'''
'''--- models/silver/curated/nft/silver__nft_sales.yml ---
version: 2

models:
  - name: silver__nft_sales
    description: |-
      This table records all the NFT sales actions of the mainy Near marketplaces..
    tests:
      - dbt_utils.unique_combination_of_columns:
          combination_of_columns:
            - receipt_id
            - logs_index
    columns:
      - name: RECEIPT_ID
        description: "{{ doc('receipt_id')}}"

      - name: BLOCK_ID
        description: "{{ doc('block_id')}}"

      - name: BLOCK_TIMESTAMP
        description: "{{ doc('block_timestamp')}}"
        tests:
          - not_null:
              where: _inserted_timestamp <= current_timestamp - interval '10 hour'

      - name: TX_HASH
        description: "{{ doc('tx_hash')}}"

      - name: GAS_BURNED
        description: "{{ doc('attached_gas')}}"

      - name: SELLER_ADDRESS
        description: "{{ doc('from_address')}}"

      - name: BUYER_ADDRESS
        description: "{{ doc('to_address')}}"

      - name: PLATFORM_ADDRESS
        description: "{{ doc('tx_signer')}}"

      - name: PLATFORM_NAME
        description: "Platform Name"

      - name: NFT_ADDRESS
        description: "NFT Address"

      - name: TOKEN_ID
        description: "{{ doc('token_id')}}"

      - name: PRICE
        description: "{{ doc('raw_price')}}"

      - name: PRICE_USD
        description: "{{ doc('price_usd')}}"

      - name: METHOD_NAME
        description: "{{ doc('method_name')}}"

      - name: LOGS
        description: "{{ doc('logs')}}"

      - name: LOGS_INDEX
        description: "ROW NUMBER"

      - name: _INSERTED_TIMESTAMP
        description: "{{ doc('_inserted_timestamp')}}"

      - name: _MODIFIED_TIMESTAMP
        description: "{{ doc('_modified_timestamp')}}"

      - name: _PARTITION_BY_BLOCK_NUMBER
        description: "{{ doc('_partition_by_block_number')}}"

      - name: NFT_SALES_ID
        description: "{{doc('id')}}"

      - name: INSERTED_TIMESTAMP
        description: "{{doc('inserted_timestamp')}}"

      - name: MODIFIED_TIMESTAMP
        description: "{{doc('modified_timestamp')}}"

      - name: _INVOCATION_ID
        description: "{{doc('invocation_id')}}"

'''
'''--- models/silver/curated/nft/silver__nft_transfers.sql ---
{{ config(
    materialized = 'incremental',
    merge_exclude_columns = ["inserted_timestamp"],
    cluster_by = ['block_timestamp::DATE'],
    unique_key = 'nft_transfers_id',
    incremental_strategy = 'merge',
    tags = ['curated']
) }}

WITH actions_events AS (

    SELECT
        block_id,
        block_timestamp,
        tx_hash,
        action_id,
        signer_id,
        receiver_id,
        logs,
        _inserted_timestamp,
        modified_timestamp as _modified_timestamp,
        _partition_by_block_number
    FROM
        {{ ref('silver__actions_events_function_call_s3') }}
    WHERE
        receipt_succeeded = TRUE
        AND logs [0] IS NOT NULL
        {% if var("MANUAL_FIX") %}
        AND {{ partition_load_manual('no_buffer') }}
        {% else %}
            {% if is_incremental() %}
            AND _modified_timestamp >= (
                SELECT
                    MAX(_modified_timestamp)
                FROM
                    {{ this }}
            )
        {% endif %}
        {% endif %}
), 

--------------------------------    NFT Transfers    --------------------------------
nft_logs AS (
    SELECT
        block_id,
        signer_id,
        block_timestamp,
        tx_hash,
        action_id,
        TRY_PARSE_JSON(REPLACE(b.value, 'EVENT_JSON:')) AS DATA,
        receiver_id AS contract_id,
        b.index as logs_rn,
        _inserted_timestamp,
        _modified_timestamp,
        _partition_by_block_number
    FROM
        actions_events
        JOIN LATERAL FLATTEN(
            input => logs
        ) b
    WHERE
        DATA :event IN (
            'nft_transfer',
            'nft_mint'
        )
),
--------------------------------        FINAL      --------------------------------
nft_transfers AS (
    SELECT
        block_id,
        block_timestamp,
        tx_hash,
        action_id,
        contract_id :: STRING AS contract_address,
        COALESCE(
            A.value :old_owner_id,
            signer_id
        ) :: STRING AS from_address,
        COALESCE(
            A.value :new_owner_id,
            A.value :owner_id
        ) :: STRING AS to_address,
        A.value :token_ids AS token_ids,
        token_ids [0] :: STRING AS token_id,
        logs_rn + A.index as transfer_rn,
        _inserted_timestamp,
        _modified_timestamp,
        _partition_by_block_number
    FROM
        nft_logs
        JOIN LATERAL FLATTEN(
            input => DATA :data
        ) A
    WHERE
        token_id IS NOT NULL
),

nft_final AS (
    SELECT
        block_id,
        block_timestamp,
        tx_hash,
        action_id,
        contract_address,
        from_address,
        to_address,
        B.value :: STRING AS token_id,
        transfer_rn + B.index as rn,
        _inserted_timestamp,
        _modified_timestamp,
        _partition_by_block_number
    FROM
        nft_transfers
    JOIN LATERAL FLATTEN(
            input => token_ids
        ) B
),
FINAL AS (
    SELECT
        block_id,
        block_timestamp,
        tx_hash,
        action_id,
        rn,
        contract_address,
        from_address,
        to_address,
        token_id,
        _inserted_timestamp,
        _modified_timestamp,
        _partition_by_block_number
    FROM
        nft_final
)
SELECT
    *,
    {{ dbt_utils.generate_surrogate_key(
        ['tx_hash', 'action_id','contract_address','from_address','to_address','token_id','rn']
    ) }} AS nft_transfers_id,
    SYSDATE() AS inserted_timestamp,
    SYSDATE() AS modified_timestamp,
    '{{ invocation_id }}' AS _invocation_id
FROM
    FINAL
'''
'''--- models/silver/curated/nft/silver__nft_transfers.yml ---
version: 2

models:
  - name: silver__nft_transfers
    tests:
      - dbt_utils.unique_combination_of_columns:
          combination_of_columns:
            - tx_hash
            - action_id
            - contract_address
            - from_address
            - to_address
            - token_id
            - rn

    description: |-
      This table records all the NFT Transfer actions of the Near blockchain.
    columns:
      - name: BLOCK_ID
        description: "{{ doc('block_id')}}"

      - name: BLOCK_TIMESTAMP
        description: "{{ doc('block_timestamp')}}"
        tests:
          - not_null:
              where: _inserted_timestamp <= current_timestamp - interval '10 hour'

      - name: TX_HASH
        description: "{{ doc('tx_hash')}}"

      - name: RN
        description: "Row number"

      - name: ACTION_ID
        description: "{{ doc('action_id')}}"

      - name: CONTRACT_ADDRESS
        description: "{{ doc('tx_signer')}}"

      - name: FROM_ADDRESS
        description: "{{ doc('from_address')}}"

      - name: TO_ADDRESS
        description: "{{ doc('to_address')}}"

      - name: TOKEN_ID
        description: "{{ doc('token_id')}}"

      - name: _INSERTED_TIMESTAMP
        description: "{{ doc('_inserted_timestamp')}}"

      - name: _MODIFIED_TIMESTAMP
        description: "{{ doc('_modified_timestamp')}}"

      - name: NFT_TRANSFERS_ID
        description: "{{doc('id')}}"

      - name: INSERTED_TIMESTAMP
        description: "{{doc('inserted_timestamp')}}"

      - name: MODIFIED_TIMESTAMP
        description: "{{doc('modified_timestamp')}}"

      - name: _INVOCATION_ID
        description: "{{doc('invocation_id')}}"

'''
'''--- models/silver/curated/nft/silver__standard_nft_mint_s3.sql ---
{{ config(
    materialized = "incremental",
    cluster_by = ["block_timestamp::DATE"],
    unique_key = "mint_action_id",
    incremental_strategy = "merge",
    merge_exclude_columns = ["inserted_timestamp"],
    tags = ['curated']
) }}
{# Note - multisource model #}
WITH logs AS (

    SELECT
        log_id,
        receipt_object_id,
        tx_hash,
        block_id,
        block_timestamp,
        receiver_id,
        signer_id,
        gas_burnt,
        clean_log,
        is_standard,
        _partition_by_block_number,
        _inserted_timestamp,
        modified_timestamp AS _modified_timestamp
    FROM
        {{ ref('silver__logs_s3') }}
    {% if var("MANUAL_FIX") %}
      WHERE {{ partition_load_manual('no_buffer') }}
    {% else %}
            {% if is_incremental() %}
        WHERE _modified_timestamp >= (
            SELECT
                MAX(_modified_timestamp)
            FROM
                {{ this }}
        )
    {% endif %}
    {% endif %}
),
tx AS (
    SELECT
        tx_hash,
        tx_signer,
        tx_receiver,
        tx_succeeded,
        tx_status, -- TODO deprecate col
        transaction_fee,
        modified_timestamp AS _modified_timestamp
    FROM
        {{ ref('silver__streamline_transactions_final') }}
    {% if var("MANUAL_FIX") %}
      WHERE {{ partition_load_manual('no_buffer') }}
    {% else %}
            {% if is_incremental() %}
        WHERE _modified_timestamp >= (
            SELECT
                MAX(_modified_timestamp)
            FROM
                {{ this }}
        )
    {% endif %}
    {% endif %}
),
function_call AS (
    SELECT
        action_id,
        tx_hash,
        TRY_PARSE_JSON(args) AS args_json,
        method_name,
        deposit,
        modified_timestamp AS _modified_timestamp
    FROM
        {{ ref("silver__actions_events_function_call_s3") }}
    {% if var("MANUAL_FIX") %}
      WHERE {{ partition_load_manual('no_buffer') }}
    {% else %}
            {% if is_incremental() %}
        WHERE _modified_timestamp >= (
            SELECT
                MAX(_modified_timestamp)
            FROM
                {{ this }}
        )
    {% endif %}
    {% endif %}
),
standard_logs AS (
    SELECT
        log_id AS logs_id,
        concat_ws(
            '-',
            receipt_object_id,
            '0'
        ) AS action_id,
        tx_hash,
        receipt_object_id,
        block_id,
        block_timestamp,
        receiver_id,
        signer_id,
        gas_burnt,
        TRY_PARSE_JSON(clean_log) AS clean_log,
        COUNT(*) over (
            PARTITION BY tx_hash
        ) AS log_counter,
        _partition_by_block_number,
        _inserted_timestamp,
        _modified_timestamp
    FROM
        logs
    WHERE
        is_standard
),
nft_events AS (
    SELECT
        standard_logs.*,
        function_call.method_name,
        function_call.deposit,
        function_call.args_json,
        clean_log :data AS DATA,
        clean_log :event AS event,
        clean_log :standard AS STANDARD,
        clean_log :version AS version
    FROM
        standard_logs
        INNER JOIN function_call
        ON standard_logs.action_id = function_call.action_id
    WHERE
        STANDARD = 'nep171' -- nep171 nft STANDARD, version  nep245 IS multitoken STANDARD,  nep141 IS fungible token STANDARD
        AND event = 'nft_mint'
),
raw_mint_events AS (
    SELECT
        action_id,
        tx_hash,
        receipt_object_id,
        block_id,
        block_timestamp,
        receiver_id,
        signer_id,
        gas_burnt,
        INDEX AS batch_index,
        args_json,
        method_name,
        deposit,
        ARRAY_SIZE(
            DATA :: ARRAY
        ) AS owner_per_tx,
        VALUE :owner_id :: STRING AS owner_id,
        VALUE :token_ids :: ARRAY AS tokens,
        TRY_PARSE_JSON(
            VALUE :memo
        ) AS memo,
        log_counter,
        _partition_by_block_number,
        _inserted_timestamp,
        _modified_timestamp
    FROM
        nft_events,
        LATERAL FLATTEN(
            input => DATA
        )
),
mint_events AS (
    SELECT
        action_id,
        tx_hash,
        receipt_object_id,
        block_id,
        block_timestamp,
        receiver_id,
        signer_id,
        args_json,
        method_name,
        deposit,
        owner_per_tx,
        gas_burnt,
        batch_index,
        owner_id,
        memo,
        INDEX AS token_index,
        ARRAY_SIZE(
            tokens
        ) AS mint_per_tx,
        VALUE :: STRING AS token_id,
        concat_ws(
            '-',
            action_id,
            COALESCE(
                batch_index,
                '0'
            ),
            COALESCE(
                token_index,
                '0'
            ),
            COALESCE(
                token_id,
                '0'
            )
        ) AS mint_action_id,
        log_counter,
        _partition_by_block_number,
        _inserted_timestamp,
        _modified_timestamp
    FROM
        raw_mint_events,
        LATERAL FLATTEN(
            input => tokens
        )
),
mint_tx AS (
    SELECT
        tx_hash,
        tx_signer,
        tx_receiver,
        tx_succeeded,
        tx_status,
        transaction_fee
    FROM
        tx
    WHERE
        tx_hash IN (
            SELECT
                DISTINCT tx_hash
            FROM
                mint_events
        )
),
FINAL AS (
    SELECT
        mint_events.action_id,
        mint_events.mint_action_id,
        mint_events.tx_hash,
        mint_events.block_id,
        mint_events.block_timestamp,
        mint_events.method_name,
        mint_events.args_json AS args,
        mint_events.deposit,
        mint_tx.tx_signer AS tx_signer,
        mint_tx.tx_receiver AS tx_receiver,
        mint_tx.tx_succeeded AS tx_succeeded,
        mint_tx.tx_status AS tx_status,
        mint_events.receipt_object_id,
        mint_events.receiver_id,
        mint_events.signer_id,
        mint_events.owner_id,
        mint_events.token_id,
        mint_events.memo,
        mint_events.owner_per_tx,
        mint_events.mint_per_tx,
        mint_events.gas_burnt,
        -- gas burnt during receipt processing
        mint_tx.transaction_fee,
        -- gas burnt during entire transaction processing
        mint_events.log_counter,
        (
            mint_events.deposit / mint_events.log_counter
        ) :: FLOAT AS implied_price,
        mint_events._partition_by_block_number,
        mint_events._inserted_timestamp,
        mint_events._modified_timestamp
    FROM
        mint_events
        INNER JOIN mint_tx
        ON mint_events.tx_hash = mint_tx.tx_hash
)
SELECT
    *,
    {{ dbt_utils.generate_surrogate_key(
        ['mint_action_id']
    ) }} AS standard_nft_mint_id,
    SYSDATE() AS inserted_timestamp,
    SYSDATE() AS modified_timestamp,
    '{{ invocation_id }}' AS _invocation_id
FROM
    FINAL

'''
'''--- models/silver/curated/nft/silver__standard_nft_mint_s3.yml ---
version: 2

models:
  - name: silver__standard_nft_mint_s3
    description: |-
      This table records all the NFT Mints per the NEP171 standard, across various methods.

    columns:
      - name: ACTION_ID
        description: "{{ doc('action_id') }}"
        tests:
          - not_null:
              where: _inserted_timestamp <= current_timestamp - interval '1 hour'

      - name: MINT_ACTION_ID
        description: "{{ doc('mint_action_id') }}"
        tests:
          - unique:
              where: receiver_id != 'realbirds.near'
          - not_null:
              where: _inserted_timestamp <= current_timestamp - interval '1 hour'

      - name: TX_HASH
        description: "{{ doc('tx_hash') }}"
        tests:
          - not_null:
              where: _inserted_timestamp <= current_timestamp - interval '1 hour'

      - name: BLOCK_ID
        description: "{{ doc('block_id')}}"

      - name: BLOCK_TIMESTAMP
        description: "{{ doc('block_timestamp')}}"
        tests:
          - not_null:
              where: _inserted_timestamp <= current_timestamp - interval '1 hour'

      - name: METHOD_NAME
        description: "{{ doc('method_name') }}"
        tests:
          - not_null:
              where: _inserted_timestamp <= current_timestamp - interval '1 hour'

      - name: ARGS
        description: "{{ doc('args') }}"

      - name: DEPOSIT
        description: "{{ doc('deposit') }}"

      - name: TX_SIGNER
        description: "{{ doc('tx_signer') }}"

      - name: TX_RECEIVER
        description: "{{ doc('tx_receiver') }}"
        tests:
          - not_null:
              where: _inserted_timestamp <= current_timestamp - interval '1 hour'

      - name: TX_SUCCEEDED
        description: "{{ doc('tx_succeeded') }}"

      - name: TX_STATUS
        description: "{{ doc('tx_status') }}"
        tests:
          - not_null:
              where: _inserted_timestamp <= current_timestamp - interval '1 hour'

      - name: RECEIPT_OBJECT_ID
        description: "{{ doc('receipt_object_id') }}"

      - name: RECEIVER_ID
        description: "{{ doc('receiver_id')}}"

      - name: SIGNER_ID
        description: "{{ doc('signer_id')}}"

      - name: OWNER_PER_TX
        description: "{{ doc('owner_per_tx') }}"

      - name: OWNER_ID
        description: "{{ doc('owner_id') }}"

      - name: MEMO
        description: "{{ doc('memo') }}"

      - name: MINT_PER_TX
        description: "{{ doc('mint_per_tx') }}"

      - name: TOKEN_ID
        description: "{{ doc('nft_token_id') }}"

      - name: GAS_BURNT
        description: "{{ doc('gas_burnt') }}"

      - name: IMPLIED_PRICE
        description: "{{ doc('implied_price') }}"

      - name: TRANSACTION_FEE
        description: "{{ doc('transaction_fee') }}"
        tests:
          - not_null:
              where: _inserted_timestamp <= current_timestamp - interval '1 hour'

      - name: _PARTITION_BY_BLOCK_NUMBER
        description: "{{ doc('_partition_by_block_number') }}"

      - name: _INSERTED_TIMESTAMP
        description: "{{ doc('_inserted_timestamp')}}"

      - name: _MODIFIED_TIMESTAMP
        description: "{{ doc('_modified_timestamp')}}"

      - name: STANDARD_NFT_MINT_ID
        description: "{{doc('id')}}"

      - name: INSERTED_TIMESTAMP
        description: "{{doc('inserted_timestamp')}}"

      - name: MODIFIED_TIMESTAMP
        description: "{{doc('modified_timestamp')}}"

      - name: _INVOCATION_ID
        description: "{{doc('invocation_id')}}"

'''
'''--- models/silver/curated/silver__lockup_actions.sql ---
{{ config(
    materialized = 'incremental',
    merge_exclude_columns = ["inserted_timestamp"],
    unique_key = 'tx_hash',
    tags = ['curated'],
) }}
{# Note - multisource model #}
WITH txs AS (

    SELECT
        tx_hash,
        tx_succeeded,
        _partition_by_block_number,
        _inserted_timestamp,
        modified_timestamp AS _modified_timestamp
    FROM
        {{ ref('silver__streamline_transactions_final') }}

    {% if var("MANUAL_FIX") %}
      WHERE {{ partition_load_manual('no_buffer') }}
    {% else %}
            {% if is_incremental() %}
        WHERE _modified_timestamp >= (
            SELECT
                MAX(_modified_timestamp)
            FROM
                {{ this }}
        )
    {% endif %}
    {% endif %}
),
function_calls AS (
    SELECT
        tx_hash,
        action_id,
        block_timestamp,
        block_id,
        signer_id,
        receiver_id,
        args,
        deposit,
        method_name,
        _partition_by_block_number,
        _inserted_timestamp,
        modified_timestamp AS _modified_timestamp
    FROM
        {{ ref('silver__actions_events_function_call_s3') }}
    WHERE 
        receipt_succeeded = TRUE

    {% if var("MANUAL_FIX") %}
      AND {{ partition_load_manual('no_buffer') }}
    {% else %}
            {% if is_incremental() %}
        AND _modified_timestamp >= (
            SELECT
                MAX(_modified_timestamp)
            FROM
                {{ this }}
        )
    {% endif %}
    {% endif %}

),
xfers AS (
    SELECT
        tx_hash,
        action_id,
        block_timestamp,
        block_id,
        deposit,
        _partition_by_block_number,
        _inserted_timestamp,
        modified_timestamp AS _modified_timestamp
    FROM
        {{ ref('silver__transfers_s3') }}

    {% if var("MANUAL_FIX") %}
      WHERE {{ partition_load_manual('no_buffer') }}
    {% else %}
            {% if is_incremental() %}
        WHERE _modified_timestamp >= (
            SELECT
                MAX(_modified_timestamp)
            FROM
                {{ this }}
        )
    {% endif %}
    {% endif %}
),
lockup_actions AS (
    SELECT
        tx_hash,
        action_id,
        SPLIT(
            action_id,
            '-'
        ) [0] :: STRING AS receipt_object_id,
        block_timestamp,
        block_id,
        signer_id,
        receiver_id,
        args,
        deposit,
        method_name,
        _partition_by_block_number,
        _inserted_timestamp,
        _modified_timestamp
    FROM
        function_calls
    WHERE
        (
            signer_id = 'lockup.near'
            OR receiver_id = 'lockup.near'
            OR receiver_id ILIKE '%lockup.near'
        )
        AND method_name IN (
            'on_lockup_create',
            'create',
            'new'
        )
        AND tx_hash NOT IN (
            'Ez6rNL3fP62c4nMroYUmjVR4MbqEeVoL6RzmuajGQrkS',
            'TcCm1jzMFnwgAT3Wh2Qr1n2tR7ZVXKcv3ThKbXAhe7H',
            'm3mf5maDHfD2MXjvRnxp38ZA5BAVnRumiebPEqjGmuC'
        )
),
agg_arguments AS (
    SELECT
        tx_hash,
        OBJECT_AGG(
            method_name,
            receipt_object_id :: variant
        ) AS receipt_object_ids,
        OBJECT_AGG(
            method_name,
            receiver_id :: variant
        ) AS receiver_ids,
        MIN(block_id) AS block_id,
        MIN(block_timestamp) AS block_timestamp,
        OBJECT_AGG(
            method_name,
            args
        ) AS args_all,
        COUNT(
            DISTINCT method_name
        ) AS method_count,
        MIN(_partition_by_block_number) AS _partition_by_block_number,
        MIN(_inserted_timestamp) AS _inserted_timestamp,
        MIN(_modified_timestamp) AS _modified_timestamp
    FROM
        lockup_actions
    GROUP BY
        1
),
lockup_xfers AS (
    SELECT
        tx_hash,
        action_id,
        SPLIT(
            action_id,
            '-'
        ) [0] :: STRING AS receipt_object_id,
        block_timestamp,
        block_id,
        deposit,
        _partition_by_block_number,
        _inserted_timestamp,
        _modified_timestamp
    FROM
        xfers
    WHERE
        tx_hash IN (
            SELECT
                DISTINCT tx_hash
            FROM
                lockup_actions
        )
),
parse_args_json AS (
    SELECT
        A.tx_hash,
        receipt_object_ids,
        A.block_id,
        A.block_timestamp,
        COALESCE(
            args_all :on_lockup_create :attached_deposit :: DOUBLE,
            x.deposit
        ) AS deposit,
        COALESCE(
            args_all :on_lockup_create :lockup_account_id :: STRING,
            receiver_ids :new :: STRING
        ) AS lockup_account_id,
        COALESCE(
            args_all :new :owner_account_id :: STRING,
            args_all :create :owner_account_id :: STRING
        ) AS owner_account_id,
        COALESCE(
            args_all :new :lockup_duration :: STRING,
            args_all :create :lockup_duration :: STRING
        ) AS lockup_duration,
        COALESCE(
            args_all :new :lockup_timestamp :: STRING,
            args_all :create :lockup_timestamp :: STRING
        ) AS lockup_timestamp,
        COALESCE(
            args_all :new :release_duration :: STRING,
            args_all :create :release_duration :: STRING
        ) AS release_duration,
        COALESCE(
            args_all :new :vesting_schedule :: STRING,
            args_all :create :vesting_schedule :: STRING
        ) AS vesting_schedule,
        args_all :new :transfers_information :: STRING AS transfers_information,
        args_all,
        A._partition_by_block_number,
        A._inserted_timestamp,
        A._modified_timestamp
    FROM
        agg_arguments A
        LEFT JOIN lockup_xfers x
        ON A.receipt_object_ids :new :: STRING = x.receipt_object_id
),
FINAL AS (
    SELECT
        f.tx_hash,
        f.receipt_object_ids,
        f.block_timestamp,
        f.block_id,
        deposit,
        lockup_account_id,
        owner_account_id,
        lockup_duration,
        lockup_timestamp,
        TO_TIMESTAMP_NTZ(lockup_timestamp) AS lockup_timestamp_ntz,
        release_duration,
        vesting_schedule,
        transfers_information,
        args_all,
        f._partition_by_block_number,
        f._inserted_timestamp,
        f._modified_timestamp
    FROM
        parse_args_json f
        LEFT JOIN txs USING (tx_hash)
    WHERE
        tx_succeeded
)
SELECT
    *,
    {{ dbt_utils.generate_surrogate_key(
        ['tx_hash']
    ) }} AS lockup_actions_id,
    SYSDATE() AS inserted_timestamp,
    SYSDATE() AS modified_timestamp,
    '{{ invocation_id }}' AS _invocation_id
FROM
    FINAL

'''
'''--- models/silver/curated/silver__lockup_actions.yml ---
version: 2

models:
  - name: silver__lockup_actions
    description: |-
      This table records all disbursements by the contract lockup.near.

    columns:
      - name: TX_HASH
        description: "{{ doc('tx_hash')}}"
        tests: 
          - not_null:
              where: _inserted_timestamp <= current_timestamp - interval '1 hour'

      - name: BLOCK_TIMESTAMP
        description: "{{ doc('block_timestamp')}}"
        tests:
          - not_null:
              where: _inserted_timestamp <= current_timestamp - interval '1 hour'

      - name: BLOCK_ID
        description: "{{ doc('block_id')}}"

      - name: DEPOSIT
        description: "{{ doc('deposit')}}"

      - name: LOCKUP_ACCOUNT_ID
        description: "{{ doc('lockup_account_id')}}"

      - name: OWNER_ACCOUNT_ID
        description: "{{ doc('owner_account_id')}}"

      - name: LOCKUP_DURATION
        description: "{{ doc('lockup_duration')}}"

      - name: LOCKUP_TIMESTAMP
        description: "{{ doc('lockup_timestamp')}}"

      - name: LOCKUP_TIMESTAMP_NTZ
        description: "{{ doc('lockup_timestamp_ntz')}}"

      - name: RELEASE_DURATION
        description: "{{ doc('release_duration')}}"

      - name: VESTING_SCHEDULE
        description: "{{ doc('vesting_schedule')}}"

      - name: TRANSFERS_INFORMATION
        description: "{{ doc('transfers_information')}}"
        
      - name: _PARTITION_BY_BLOCK_NUMBER
        description: "{{ doc('_partition_by_block_number')}}"

      - name: _INSERTED_TIMESTAMP
        description: "{{ doc('_inserted_timestamp')}}"

      - name: _MODIFIED_TIMESTAMP
        description: "{{ doc('_modified_timestamp')}}"

      - name: LOCKUP_ACTIONS_ID
        description: "{{doc('id')}}"

      - name: INSERTED_TIMESTAMP
        description: "{{doc('inserted_timestamp')}}"

      - name: MODIFIED_TIMESTAMP
        description: "{{doc('modified_timestamp')}}"

      - name: _INVOCATION_ID
        description: "{{doc('invocation_id')}}"

'''
'''--- models/silver/curated/silver__logs_s3.sql ---
{{ config(
    materialized = "incremental",
    merge_exclude_columns = ["inserted_timestamp"],
    cluster_by = ["_inserted_timestamp::DATE","block_timestamp::DATE"],
    unique_key = "log_id",
    incremental_strategy = "merge",
    tags = ['curated']
) }}

WITH receipts AS (

    SELECT
        block_id,
        block_timestamp,
        tx_hash,
        receipt_object_id,
        logs,
        receiver_id,
        receipt_actions :predecessor_id :: STRING AS predecessor_id,
        signer_id,
        gas_burnt,
        receipt_succeeded,
        _partition_by_block_number,
        _inserted_timestamp,
        modified_timestamp AS _modified_timestamp
    FROM
        {{ ref('silver__streamline_receipts_final') }}

    {% if var("MANUAL_FIX") %}
      WHERE {{ partition_load_manual('no_buffer') }}
    {% else %}
            {% if is_incremental() %}
        WHERE _modified_timestamp >= (
            SELECT
                MAX(_modified_timestamp)
            FROM
                {{ this }}
        )
    {% endif %}
    {% endif %}
),
FINAL AS (
    SELECT
        block_id,
        block_timestamp,
        tx_hash,
        receipt_object_id,
        concat_ws(
            '-',
            receipt_object_id,
            INDEX
        ) AS log_id,
        INDEX AS log_index,
        receiver_id,
        predecessor_id,
        signer_id,
        COALESCE(TRY_PARSE_JSON(VALUE), TRY_PARSE_JSON(SPLIT(VALUE, 'EVENT_JSON:') [1]), VALUE :: STRING) AS clean_log,
        VALUE ILIKE 'event_json:%' AS is_standard,
        gas_burnt,
        receipt_succeeded,
        _partition_by_block_number,
        _inserted_timestamp,
        _modified_timestamp
    FROM
        receipts,
        LATERAL FLATTEN(
            input => logs
        )
)
SELECT
    *,
    {{ dbt_utils.generate_surrogate_key(
        ['log_id']
    ) }} AS logs_id,
    SYSDATE() AS inserted_timestamp,
    SYSDATE() AS modified_timestamp,
    '{{ invocation_id }}' AS _invocation_id
FROM
    FINAL

'''
'''--- models/silver/curated/silver__logs_s3.yml ---
version: 2

models:
  - name: silver__logs_s3
    description: |-
      This table extracts all logs from receipts and decodes the arguments for easy use.

    columns:
      - name: BLOCK_ID
        description: "{{ doc('block_id')}}"

      - name: BLOCK_TIMESTAMP
        description: "{{ doc('block_timestamp')}}"

      - name: TX_HASH
        description: "{{ doc('tx_hash')}}"
        tests:
          - not_null:
              where: _inserted_timestamp <= current_timestamp - interval '2 hours'

      - name: RECEIPT_OBJECT_ID
        description: "{{ doc('receipt_object_id')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - STRING
                - VARCHAR

      - name: LOG_ID
        description: "{{ doc('log_id')}}"

      - name: LOG_INDEX
        description: "{{ doc('index')}}"

      - name: RECEIVER_ID
        description: "{{ doc('receiver_id')}}"
        
      - name: PREDECESSOR_ID
        description: "{{ doc('predecessor_id')}}"

      - name: SIGNER_ID
        description: "{{ doc('signer_id')}}"

      - name: CLEAN_LOG
        description: "{{ doc('clean_log')}}"
        tests:
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - STRING
                - VARCHAR
                - OBJECT
                - ARRAY

      - name: IS_STANDARD
        description: "{{ doc('is_standard')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - BOOLEAN

      - name: GAS_BURNT
        description: "{{ doc('gas_burnt')}}"

      - name: RECEIPT_SUCCEEDED
        description: "{{ doc('receipt_succeeded')}}"

      - name: _PARTITION_BY_BLOCK_NUMBER
        description: "{{ doc('_partition_by_block_number')}}"

      - name: _INSERTED_TIMESTAMP
        description: "{{ doc('_inserted_timestamp')}}"

      - name: _MODIFIED_TIMESTAMP
        description: "{{ doc('_modified_timestamp')}}"

      - name: LOGS_ID
        description: "{{doc('id')}}"

      - name: INSERTED_TIMESTAMP
        description: "{{doc('inserted_timestamp')}}"

      - name: MODIFIED_TIMESTAMP
        description: "{{doc('modified_timestamp')}}"

      - name: _INVOCATION_ID
        description: "{{doc('invocation_id')}}"

'''
'''--- models/silver/curated/silver__token_transfers.sql ---
{{ config(
    materialized = 'incremental',
    merge_exclude_columns = ["inserted_timestamp"],
    cluster_by = ['block_timestamp::DATE'],
    unique_key = 'transfers_id',
    incremental_strategy = 'merge',
    tags = ['curated']
) }}
{# Note - multisource model #}
-- Curation Challenge - 'https://flipsidecrypto.xyz/Hossein/transfer-sector-of-near-curation-challenge-zgM44F'

WITH actions_events AS (

    SELECT
        block_id,
        block_timestamp,
        tx_hash,
        action_id,
        signer_id,
        receiver_id,
        action_name,
        method_name,
        deposit,
        logs,
        receipt_succeeded,
        _inserted_timestamp,
        modified_timestamp as _modified_timestamp,
        _partition_by_block_number
    FROM
        {{ ref('silver__actions_events_function_call_s3') }}
    WHERE
        receipt_succeeded = TRUE
        AND logs [0] IS NOT NULL

    {% if var("MANUAL_FIX") %}
      AND {{ partition_load_manual('no_buffer') }}
    {% else %}
        {% if is_incremental() %}
        AND _modified_timestamp >= (
            SELECT
                MAX(_modified_timestamp)
            FROM
                {{ this }}
        )
        {% endif %}
    {% endif %}
), 
swaps_raw AS (
    SELECT
        block_id,
        block_timestamp,
        tx_hash,
        swap_index,
        receipt_object_id,
        token_in,
        token_out,
        signer_id,
        receiver_id,
        amount_in_raw,
        amount_out_raw,
        _inserted_timestamp,
        modified_timestamp AS _modified_timestamp,
        _partition_by_block_number
    FROM
        {{ ref('silver__dex_swaps_v2') }}

    {% if var("MANUAL_FIX") %}
      WHERE {{ partition_load_manual('no_buffer') }}
    {% else %}
        {% if is_incremental() %}
            WHERE
                _modified_timestamp >= (
                    SELECT
                        MAX(_modified_timestamp)
                    FROM
                        {{ this }}
                )
            {% endif %}
    {% endif %}
),
----------------------------    Native Token Transfers   ------------------------------
native_transfers AS (

    SELECT
        block_id,
        block_timestamp,
        tx_hash,
        action_id,
        signer_id AS from_address,
        receiver_id AS to_address,
        IFF(REGEXP_LIKE(deposit, '^[0-9]+$'), deposit, NULL) AS amount_unadjusted,
        --numeric validation (there are some exceptions that needs to be ignored)
        receipt_succeeded,
        _inserted_timestamp,
        modified_timestamp AS _modified_timestamp,
        _partition_by_block_number
    FROM
        {{ ref('silver__transfers_s3') }}
    WHERE
        status = TRUE AND deposit != 0

    {% if var("MANUAL_FIX") %}
      AND {{ partition_load_manual('no_buffer') }}
    {% else %}
        {% if is_incremental() %}
        AND _modified_timestamp >= (
            SELECT
                MAX(_modified_timestamp)
            FROM
                {{ this }}
        )
        {% endif %}
    {% endif %}
), 
------------------------------   NEAR Tokens (NEP 141) --------------------------------
swaps AS (
    SELECT
        block_id,
        block_timestamp,
        tx_hash,
        receipt_object_id,
        token_in AS contract_address,
        signer_id AS from_address,
        receiver_id AS to_address,
        amount_in_raw :: variant AS amount_unadjusted,
        'swap' AS memo,
        swap_index as rn,
        _inserted_timestamp,
        _modified_timestamp,
        _partition_by_block_number
    FROM
        swaps_raw
    UNION ALL
    SELECT
        block_id,
        block_timestamp,
        tx_hash,
        receipt_object_id,
        token_out AS contract_address,
        receiver_id AS from_address,
        signer_id AS to_address,
        amount_out_raw :: variant AS amount_unadjusted,
        'swap' AS memo,
        swap_index + 1 as rn,
        _inserted_timestamp,
        _modified_timestamp,
        _partition_by_block_number
    FROM
        swaps_raw
),
orders AS (
    SELECT
        block_id,
        block_timestamp,
        tx_hash,
        action_id,
        receiver_id,
        TRY_PARSE_JSON(REPLACE(g.value, 'EVENT_JSON:')) AS DATA,
        DATA :event :: STRING AS event,
        g.index as rn,
        _inserted_timestamp,
        _modified_timestamp,
        _partition_by_block_number
    FROM
        actions_events
        JOIN LATERAL FLATTEN(
            input => logs
        ) g
    WHERE
        DATA :event:: STRING = 'order_added'
),
orders_final AS (
    SELECT
        block_id,
        block_timestamp,
        tx_hash,
        action_id,
        f.value :sell_token :: STRING AS contract_address,
        f.value :owner_id :: STRING AS from_address,
        receiver_id :: STRING AS to_address,
        (
            f.value :original_amount
        ) :: variant AS amount_unadjusted,
        'order' AS memo,
        f.index as rn,
        _inserted_timestamp,
        _modified_timestamp,
        _partition_by_block_number
    FROM
        orders
        JOIN LATERAL FLATTEN(
            input => DATA :data
        ) f
    WHERE
        amount_unadjusted > 0
),
add_liquidity AS (
    SELECT
        block_id,
        block_timestamp,
        tx_hash,
        action_id,
        REGEXP_SUBSTR(
            SPLIT.value,
            '"\\d+ ([^"]*)["]',
            1,
            1,
            'e',
            1
        ) :: STRING AS contract_address,
        NULL AS from_address,
        receiver_id AS to_address,
        REGEXP_SUBSTR(
            SPLIT.value,
            '"(\\d+) ',
            1,
            1,
            'e',
            1
        ) :: variant AS amount_unadjusted,
        'add_liquidity' AS memo,
        index as rn,
        _inserted_timestamp,
        _modified_timestamp,
        _partition_by_block_number
    FROM
        actions_events,
        LATERAL FLATTEN (
            input => SPLIT(
                REGEXP_SUBSTR(
                    logs [0],
                    '\\["(.*?)"\\]'
                ),
                ','
            )
        ) SPLIT
    WHERE
        logs [0] LIKE 'Liquidity added [%minted % shares'
),
ft_transfers_mints AS (
    SELECT
        block_id,
        block_timestamp,
        tx_hash,
        action_id,
        TRY_PARSE_JSON(REPLACE(VALUE, 'EVENT_JSON:')) AS DATA,
        b.index as logs_rn,
        receiver_id AS contract_address,
        _inserted_timestamp,
        _modified_timestamp,
        _partition_by_block_number
    FROM
        actions_events
        JOIN LATERAL FLATTEN(
            input => logs
        ) b
    WHERE
        DATA :event:: STRING IN (
            'ft_transfer',
            'ft_mint'
        )
),
ft_transfers_mints_final AS (
    SELECT
        block_id,
        block_timestamp,
        tx_hash,
        action_id,
        contract_address,
        NVL(
            f.value :old_owner_id,
            NULL
        ) :: STRING AS from_address,
        NVL(
            f.value :new_owner_id,
            f.value :owner_id
        ) :: STRING AS to_address,
        f.value :amount :: variant AS amount_unadjusted,
        f.value :memo :: STRING AS memo,
        logs_rn + f.index as rn,
        _inserted_timestamp,
        _modified_timestamp,
        _partition_by_block_number
    FROM
        ft_transfers_mints
        JOIN LATERAL FLATTEN(
            input => DATA :data
        ) f
    WHERE
        amount_unadjusted > 0
),
nep_transfers AS (
    SELECT
        *
    FROM
        ft_transfers_mints_final
    UNION ALL
    SELECT
        *
    FROM
        orders_final
    UNION ALL
    SELECT
        *
    FROM
        swaps
    UNION ALL
    SELECT
        *
    FROM
        add_liquidity
),
------------------------------  MODELS --------------------------------

native_final AS (
    SELECT
        block_id,
        block_timestamp,
        tx_hash,
        action_id,
        'wrap.near' AS contract_address,
        from_address :: STRING,
        to_address :: STRING,
        NULL AS memo,
        '0' AS rn,
        'native' as transfer_type,
        amount_unadjusted :: STRING AS amount_raw,
        amount_unadjusted :: FLOAT AS amount_raw_precise,
        _inserted_timestamp,
        _modified_timestamp,
        _partition_by_block_number
    FROM
        native_transfers
),

nep_final AS (
    SELECT
        block_id,
        block_timestamp,
        tx_hash,
        action_id,
        contract_address,
        from_address,
        to_address,
        memo,
        rn :: STRING as rn,
        'nep141' as transfer_type,
        amount_unadjusted :: STRING AS amount_raw,
        amount_unadjusted :: FLOAT AS amount_raw_precise,
        _inserted_timestamp,
        _modified_timestamp,
        _partition_by_block_number
    FROM
        nep_transfers
),
------------------------------   FINAL --------------------------------
transfer_union AS (

        SELECT
            *
        FROM
            nep_final
        UNION ALL
        SELECT
            *
        FROM
            native_final  
),
FINAL AS (
    SELECT
        block_id,
        block_timestamp,
        tx_hash,
        action_id,
        rn,
        contract_address,
        from_address,
        to_address,
        memo,
        amount_raw,
        amount_raw_precise,
        transfer_type,
        _inserted_timestamp,
        _modified_timestamp,
        _partition_by_block_number
    FROM
        transfer_union

)
SELECT
    *,
    {{ dbt_utils.generate_surrogate_key(
        ['tx_hash', 'action_id','contract_address','amount_raw','from_address','to_address','memo','rn']
    ) }} AS transfers_id,
    SYSDATE() AS inserted_timestamp,
    SYSDATE() AS modified_timestamp,
    '{{ invocation_id }}' AS _invocation_id
FROM
    FINAL

'''
'''--- models/silver/curated/silver__token_transfers.yml ---
version: 2

models:
  - name: silver__token_transfers
    tests:
      - dbt_utils.unique_combination_of_columns:
          combination_of_columns:
            - tx_hash
            - action_id
            - contract_address
            - amount_raw
            - from_address
            - to_address
            - memo
            - rn
    description: |-
      This table records all the  Native Token + FTs Transfers  of the Near blockchain.
    columns:
      - name: BLOCK_ID
        description: "{{ doc('block_id')}}"

      - name: BLOCK_TIMESTAMP
        description: "{{ doc('block_timestamp')}}"
        tests:
          - not_null:
              where: _inserted_timestamp <= current_timestamp - interval '10 hour'

      - name: TX_HASH
        description: "{{ doc('tx_hash')}}"

      - name: ACTION_ID
        description: "{{ doc('action_id')}}"

      - name: CONTRACT_ADDRESS
        description: "{{ doc('tx_signer')}}"

      - name: FROM_ADDRESS
        description: "{{ doc('from_address')}}"

      - name: RN
        description: "Row number"

      - name: TO_ADDRESS
        description: "{{ doc('to_address')}}"

      - name: MEMO
        description: "{{ doc('memo')}}"

      - name: AMOUNT_RAW
        description: "{{ doc('amount_raw')}}"

      - name: AMOUNT_RAW_PRECISE
        description: "{{ doc('amount_adj')}}"

      - name: TRANSFER_TYPE
        description: "{{ doc('transfer_type')}}"

      - name: _INSERTED_TIMESTAMP
        description: "{{ doc('_inserted_timestamp')}}"

      - name: _MODIFIED_TIMESTAMP
        description: "{{ doc('_modified_timestamp')}}"

      - name: TRANSFERS_ID
        description: "{{doc('id')}}"

      - name: INSERTED_TIMESTAMP
        description: "{{doc('inserted_timestamp')}}"

      - name: MODIFIED_TIMESTAMP
        description: "{{doc('modified_timestamp')}}"

      - name: _INVOCATION_ID
        description: "{{doc('invocation_id')}}"

'''
'''--- models/silver/curated/silver__transfers_s3.sql ---
{{ config(
  materialized = 'incremental',
  merge_exclude_columns = ["inserted_timestamp"],
  cluster_by = ['block_timestamp::DATE'],
  unique_key = 'action_id',
  incremental_strategy = 'merge',
  tags = ['curated']
) }}
{# Note - multisource model #}
WITH action_events AS(

  SELECT
    tx_hash,
    block_id,
    block_timestamp,
    action_id,
    action_data :deposit :: INT AS deposit,
    predecessor_id,
    receiver_id,
    signer_id,
    receipt_succeeded,
    gas_price,
    gas_burnt,
    tokens_burnt,
    _partition_by_block_number,
    _inserted_timestamp,
    modified_timestamp AS _modified_timestamp
  FROM
    {{ ref('silver__actions_events_s3') }}
  WHERE
    action_name = 'Transfer' 

    {% if var("MANUAL_FIX") %}
      AND {{ partition_load_manual('no_buffer') }}
    {% else %}
            {% if is_incremental() %}
        AND _modified_timestamp >= (
            SELECT
                MAX(_modified_timestamp)
            FROM
                {{ this }}
        )
    {% endif %}
    {% endif %}
),
txs AS (
  SELECT
    tx_hash,
    tx :receipt ::ARRAY AS tx_receipt,
    block_id,
    block_timestamp,
    tx_receiver,
    tx_signer,
    transaction_fee,
    gas_used,
    tx_succeeded,
    _partition_by_block_number,
    _inserted_timestamp,
    modified_timestamp AS _modified_timestamp
  FROM
    {{ ref('silver__streamline_transactions_final') }}

    {% if var("MANUAL_FIX") %}
      WHERE {{ partition_load_manual('no_buffer') }}
    {% else %}
            {% if is_incremental() %}
        WHERE _modified_timestamp >= (
            SELECT
                MAX(_modified_timestamp)
            FROM
                {{ this }}
        )
    {% endif %}
    {% endif %}
),
actions AS (
  SELECT
    A.tx_hash,
    A.action_id,
    A.block_id,
    A.block_timestamp,
    t.tx_signer,
    t.tx_receiver,
    A.predecessor_id,
    A.receiver_id,
    A.signer_id,
    A.deposit,
    t.transaction_fee,
    A.gas_burnt AS gas_used,
    A.receipt_succeeded,
    t.tx_succeeded,
    A._partition_by_block_number,
    A._inserted_timestamp,
    A._modified_timestamp
  FROM
    action_events A
    INNER JOIN txs t
    ON A.tx_hash = t.tx_hash
),
FINAL AS (
  SELECT
    block_id,
    block_timestamp,
    action_id,
    deposit,
    tx_hash,
    tx_signer,
    tx_receiver,
    predecessor_id,
    signer_id,
    receiver_id,
    transaction_fee,
    gas_used,
    tx_succeeded,
    receipt_succeeded,
    ARRAY_MIN([tx_succeeded, receipt_succeeded]) :: BOOLEAN AS status,
    _partition_by_block_number,
    _inserted_timestamp,
    _modified_timestamp
  FROM
    actions
)
SELECT
  *,
  {{ dbt_utils.generate_surrogate_key(
    ['action_id']
  ) }} AS transfers_id,
  SYSDATE() AS inserted_timestamp,
  SYSDATE() AS modified_timestamp,
  '{{ invocation_id }}' AS _invocation_id
FROM
  FINAL

'''
'''--- models/silver/curated/silver__transfers_s3.yml ---
version: 2

models:
  - name: silver__transfers_s3
    description: |-
      This table records all the Transfer actions of the Near blockchain.

    columns:
      - name: TX_HASH
        description: "{{ doc('tx_hash')}}"

      - name: ACTION_ID
        description: "{{ doc('action_id')}}"

      - name: BLOCK_ID
        description: "{{ doc('block_id')}}"

      - name: BLOCK_TIMESTAMP
        description: "{{ doc('block_timestamp')}}"
        tests:
          - not_null:
              where: _inserted_timestamp <= current_timestamp - interval '1 hour'

      - name: TX_SIGNER
        description: "{{ doc('tx_signer')}}"

      - name: TX_RECEIVER
        description: "{{ doc('tx_receiver')}}"

      - name: PREDECESSOR_ID
        description: "{{ doc('predecessor_id')}}"

      - name: SIGNER_ID
        description: "{{ doc('signer_id')}}"
      
      - name: RECEIVER_ID
        description: "{{ doc('receiver_id')}}"

      - name: DEPOSIT
        description: "{{ doc('deposit')}}"

      - name: TRANSACTION_FEE
        description: "{{ doc('transaction_fee')}}"
        tests:
          - not_null:
              where: _inserted_timestamp <= current_timestamp - interval '1 hour'

      - name: GAS_USED
        description: "{{ doc('gas_used')}}"
        tests:
          - not_null:
              where: _inserted_timestamp <= current_timestamp - interval '1 hour'

      - name: TX_SUCCEEDED
        description: "{{ doc('tx_succeeded')}}"
      
      - name: RECEIPT_SUCCEEDED
        description: "{{ doc('receipt_succeeded')}}"

      - name: STATUS
        description: "{{ doc('status')}}"
        tests:
          - not_null:
              where: _inserted_timestamp <= current_timestamp - interval '1 hour'

      - name: _PARTITION_BY_BLOCK_NUMBER
        description: "{{ doc('_partition_by_block_number')}}"

      - name: _INSERTED_TIMESTAMP
        description: "{{ doc('_inserted_timestamp')}}"

      - name: _MODIFIED_TIMESTAMP
        description: "{{ doc('_modified_timestamp')}}"

      - name: TRANSFERS_ID
        description: "{{doc('id')}}"

      - name: INSERTED_TIMESTAMP
        description: "{{doc('inserted_timestamp')}}"

      - name: MODIFIED_TIMESTAMP
        description: "{{doc('modified_timestamp')}}"

      - name: _INVOCATION_ID
        description: "{{doc('invocation_id')}}"

'''
'''--- models/silver/curated/silver__transfers_s3_inc.sql ---
{{ config(
  materialized = 'incremental',
  merge_exclude_columns = ["inserted_timestamp"],
  cluster_by = ['block_timestamp::DATE'],
  unique_key = 'action_id',
  incremental_strategy = 'merge',
  tags = ['curated'],
  enabled = False
) }}
{# TODO - test and apply, where applicable.
Model disabled but will keep in repo for ref #}
{# Note - multisource model #}
{% if execute %}

{% if is_incremental() %}
{% set max_modified_query %}

SELECT
  MAX(_modified_timestamp) AS _modified_timestamp
FROM
  {{ this }}

  {% endset %}
  {% set max_modified_timestamp = run_query(max_modified_query).columns [0].values() [0] %}
{% endif %}

{% set query = """ CREATE OR REPLACE TEMPORARY TABLE silver.transfers_s3_temp_dates as SELECT MIN(COALESCE(b._modified_timestamp,'2050-01-01') ) as _modified_timestamp FROM """ ~ ref('silver__actions_events_s3') ~ """ a join """ ~ ref('silver__streamline_transactions_final') ~ """ b ON A.tx_hash = b.tx_hash WHERE a.action_name = 'Transfer' """ %}
{% set incr = "" %}

{% if is_incremental() %}
{% set incr = """ AND GREATEST(a._modified_timestamp,b._modified_timestamp) >= '""" ~ max_modified_timestamp ~ """' """ %}
{% endif %}

{% do run_query(
  query ~ incr
) %}
{% endif %}

WITH action_events AS(
  SELECT
    tx_hash,
    block_id,
    block_timestamp,
    action_id,
    action_data :deposit :: INT AS deposit,
    predecessor_id,
    receiver_id,
    signer_id,
    receipt_succeeded,
    gas_price,
    gas_burnt,
    tokens_burnt,
    _partition_by_block_number,
    _inserted_timestamp,
    modified_timestamp AS _modified_timestamp
  FROM
    {{ ref('silver__actions_events_s3') }}
  WHERE
    action_name = 'Transfer' {% if var("MANUAL_FIX") %}
      AND {{ partition_load_manual('no_buffer') }}
    {% else %}

{% if is_incremental() %}
AND _modified_timestamp >= '{{ max_modified_timestamp }}'
{% endif %}
{% endif %}
),
txs AS (
  SELECT
    tx_hash,
    tx :receipt :: ARRAY AS tx_receipt,
    block_id,
    block_timestamp,
    tx_receiver,
    tx_signer,
    transaction_fee,
    gas_used,
    tx_succeeded,
    _partition_by_block_number,
    _inserted_timestamp,
    modified_timestamp AS _modified_timestamp
  FROM
    {{ ref('silver__streamline_transactions_final') }}

    {% if var("MANUAL_FIX") %}
    WHERE
      {{ partition_load_manual('no_buffer') }}
    {% else %}

{% if is_incremental() %}
WHERE
  _modified_timestamp >= (
    SELECT
      MAX(_modified_timestamp)
    FROM
      silver.transfers_s3_temp_dates
  )
{% endif %}
{% endif %}
),
actions AS (
  SELECT
    A.tx_hash,
    A.action_id,
    A.block_id,
    A.block_timestamp,
    t.tx_signer,
    t.tx_receiver,
    A.predecessor_id,
    A.receiver_id,
    A.signer_id,
    A.deposit,
    t.transaction_fee,
    A.gas_burnt AS gas_used,
    A.receipt_succeeded,
    t.tx_succeeded,
    A._partition_by_block_number,
    A._inserted_timestamp,
    A._modified_timestamp
  FROM
    action_events A
    INNER JOIN txs t
    ON A.tx_hash = t.tx_hash
),
FINAL AS (
  SELECT
    block_id,
    block_timestamp,
    action_id,
    deposit,
    tx_hash,
    tx_signer,
    tx_receiver,
    predecessor_id,
    signer_id,
    receiver_id,
    transaction_fee,
    gas_used,
    tx_succeeded,
    receipt_succeeded,
    array_min([tx_succeeded, receipt_succeeded]) :: BOOLEAN AS status,
    _partition_by_block_number,
    _inserted_timestamp,
    _modified_timestamp
  FROM
    actions
)
SELECT
  *,
  {{ dbt_utils.generate_surrogate_key(
    ['action_id']
  ) }} AS transfers_id,
  SYSDATE() AS inserted_timestamp,
  SYSDATE() AS modified_timestamp,
  '{{ invocation_id }}' AS _invocation_id
FROM
  FINAL

'''
'''--- models/silver/curated/staking/silver__pool_balance_daily.sql ---
{{ config(
    materialized = 'table',
    cluster_by = ['date_day'],
    unique_key = '_id',
    tags = ['curated']
) }}

WITH pool_balances AS (

    SELECT
        *
    FROM
        {{ ref('silver__pool_balances') }}
),
all_staking_pools AS (
    SELECT
        receiver_id AS address,
        MIN(
            block_timestamp :: DATE
        ) AS min_date
    FROM
        {{ ref('silver__pool_balances') }}
    GROUP BY
        1
),
dates AS (
    SELECT
        date_day
    FROM
        {{ ref('silver__dates') }}
    WHERE
        date_day >= '2020-08-25'
        AND date_day < CURRENT_DATE
),
boilerplate AS (
    SELECT
        ap.address,
        d.date_day
    FROM
        all_staking_pools ap
        CROSS JOIN dates d
    WHERE
        d.date_day >= ap.min_date
),
daily_balance AS (
    SELECT
        block_timestamp :: DATE AS date_day,
        receiver_id AS address,
        amount_adj AS balance
    FROM
        pool_balances qualify ROW_NUMBER() over (
            PARTITION BY address,
            block_timestamp :: DATE
            ORDER BY
                block_id DESC
        ) = 1
),
imputed_balance AS (
    SELECT
        b.date_day,
        b.address,
        daily.balance,
        LAST_VALUE(
            balance ignore nulls
        ) over(
            PARTITION BY address
            ORDER BY
                b.date_day rows unbounded preceding
        ) AS daily_balance
    FROM
        boilerplate b
        LEFT JOIN daily_balance daily USING (
            date_day,
            address
        )
)
SELECT
    date_day,
    address,
    daily_balance AS balance,
    concat_ws(
        '-',
        date_day,
        address
    ) AS _id,
    {{ dbt_utils.generate_surrogate_key(
        ['date_day', 'address']
    ) }} AS pool_balance_daily_id,
    SYSDATE() AS inserted_timestamp,
    SYSDATE() AS modified_timestamp,
    '{{ invocation_id }}' AS _invocation_id
FROM
    imputed_balance

'''
'''--- models/silver/curated/staking/silver__pool_balance_daily.yml ---
version: 2

models:
  - name: silver__pool_balance_daily
    description: |-
      Aggregates the balances of each pool for each day, taking the last balance reported for each pool. This excludes the present date, as it is not yet complete.

    columns:
      - name: date_day
        description: "{{ doc('date') }}"
        tests:
          - not_null

      - name: address
        description: "{{ doc('address') }}"
        tests:
          - not_null

      - name: balance
        description: "{{ doc('balance') }}"
        tests:
          - not_null

      - name: _id
        description: "A unique key column for this silver model."
        tests:
          - not_null
          - unique

      - name: POOL_BALANCE_DAILY_ID
        description: "{{doc('id')}}"

      - name: INSERTED_TIMESTAMP
        description: "{{doc('inserted_timestamp')}}"

      - name: MODIFIED_TIMESTAMP
        description: "{{doc('modified_timestamp')}}"

      - name: _INVOCATION_ID
        description: "{{doc('invocation_id')}}"

'''
'''--- models/silver/curated/staking/silver__pool_balances.sql ---
{{ config(
    materialized = 'table',
    unique_key = 'tx_hash',
    tags = ['curated'],
    cluster_by = ['_partition_by_block_number', 'block_timestamp::date']
) }}

WITH pool_events AS (

    SELECT
        *
    FROM
        {{ ref('silver__pool_events') }}
    WHERE
        {% if var("MANUAL_FIX") %}
            {{ partition_load_manual('no_buffer') }}
        {% else %}
            {{ incremental_load_filter('_inserted_timestamp') }}
        {% endif %}
),
FINAL AS (
    SELECT
        tx_hash,
        block_id,
        block_timestamp,
        receipt_object_id,
        receiver_id,
        signer_id,
        LOG,
        TO_NUMBER(
            REGEXP_SUBSTR(
                LOG,
                'Contract total staked balance is (\\d+)',
                1,
                1,
                'e',
                1
            )
        ) AS amount_raw,
        amount_raw / pow(
            10,
            24
        ) AS amount_adj,
        _partition_by_block_number,
        _inserted_timestamp
    FROM
        pool_events
    WHERE
        LOG LIKE 'Contract total staked balance is%'
)
SELECT
    *,
    {{ dbt_utils.generate_surrogate_key(
        ['tx_hash']
    ) }} AS pool_balances_id,
    SYSDATE() AS inserted_timestamp,
    SYSDATE() AS modified_timestamp,
    '{{ invocation_id }}' AS _invocation_id
FROM
    FINAL

'''
'''--- models/silver/curated/staking/silver__pool_balances.yml ---
version: 2

models:
  - name: silver__pool_balances
    description: |-
      Staking pool balances as extracted from receipt logs when an individual makes a staking action.
      To calculate balance at a point in time, isolate a single record for each pool. This table is transactional-based, so balances are updated with every staking event by users.

    columns:
      - name: tx_hash
        description: "{{ doc('tx_hash') }}"

      - name: block_id
        description: "{{ doc('block_id') }}"

      - name: block_timestamp
        description: "{{ doc('block_timestamp') }}"

      - name: receipt_object_id
        description: "{{ doc('receipt_object_id') }}"

      - name: receiver_id
        description: "{{ doc('receiver_id') }}"

      - name: signer_id
        description: "{{ doc('signer_id') }}"

      - name: LOG
        description: "{{ doc('log') }}"

      - name: amount_raw
        description: "{{ doc('amount_raw') }}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - NUMBER

      - name: amount_adj
        description: "{{ doc('amount_adj') }}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - FLOAT
                - DOUBLE

      - name: _partition_by_block_number
        description: "{{ doc('_partition_by_block_number') }}"

      - name: POOL_BALANCES_ID
        description: "{{doc('id')}}"

      - name: INSERTED_TIMESTAMP
        description: "{{doc('inserted_timestamp')}}"

      - name: MODIFIED_TIMESTAMP
        description: "{{doc('modified_timestamp')}}"

      - name: _INVOCATION_ID
        description: "{{doc('invocation_id')}}"

'''
'''--- models/silver/curated/staking/silver__pool_events.sql ---
{{ config(
    materialized = 'table',
    unique_key = 'tx_hash',
    tags = ['curated'],
    cluster_by = ['_partition_by_block_number', 'block_timestamp::date']
) }}

WITH receipts AS (

    SELECT
        *
    FROM
        {{ ref('silver__streamline_receipts_final') }}
    WHERE
        {% if var("MANUAL_FIX") %}
            {{ partition_load_manual('no_buffer') }}
        {% else %}
            {{ incremental_load_filter('_inserted_timestamp') }}
        {% endif %}
        AND receipt_succeeded
),
FINAL AS (
    SELECT
        tx_hash,
        block_id,
        block_timestamp,
        receipt_object_id,
        receiver_id,
        signer_id,
        status_value,
        logs,
        VALUE AS LOG,
        _partition_by_block_number,
        _inserted_timestamp
    FROM
        receipts,
        LATERAL FLATTEN(logs)
    WHERE
        ARRAY_SIZE(logs) > 0
        AND receiver_id ILIKE '%.pool%.near'
)
SELECT
    *,
    {{ dbt_utils.generate_surrogate_key(
        ['tx_hash']
    ) }} AS pool_events_id,
    SYSDATE() AS inserted_timestamp,
    SYSDATE() AS modified_timestamp,
    '{{ invocation_id }}' AS _invocation_id
FROM
    FINAL

'''
'''--- models/silver/curated/staking/silver__pool_events.yml ---
version: 2

models:
  - name: silver__pool_events
    description: |-
      Flattened logs from receipt events where the recipient is a staking pool, for use in multiple downstream models.

    columns:
      - name: tx_hash
        description: "{{ doc('tx_hash') }}"
        tests:
          - not_null:
              where: _inserted_timestamp <= current_timestamp - interval '1 hour'
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - VARCHAR

      - name: block_id
        description: "{{ doc('block_id') }}"
        tests:
          - not_null

      - name: block_timestamp
        description: "{{ doc('block_timestamp') }}"
        tests:
          - not_null
          - dbt_expectations.expect_row_values_to_have_recent_data:
              datepart: day
              interval: 1

      - name: receipt_object_id
        description: "{{ doc('receipt_object_id') }}"
        tests:
          - not_null

      - name: receiver_id
        description: "{{ doc('receiver_id') }}"
        tests:
          - not_null

      - name: signer_id
        description: "{{ doc('signer_id') }}"
        tests:
          - not_null

      - name: status_value
        description: "{{ doc('status_value') }}"
        tests:
          - not_null

      - name: logs
        description: "{{ doc('logs') }}"
        tests:
          - not_null

      - name: LOG
        description: "{{ doc('log') }}"
        tests:
          - not_null

      - name: _partition_by_block_number
        description: "{{ doc('_partition_by_block_number') }}"

      - name: _INSERTED_TIMESTAMP
        description: "{{ doc('_inserted_timestamp')}}"

      - name: POOL_EVENTS_ID
        description: "{{doc('id')}}"

      - name: INSERTED_TIMESTAMP
        description: "{{doc('inserted_timestamp')}}"

      - name: MODIFIED_TIMESTAMP
        description: "{{doc('modified_timestamp')}}"

      - name: _INVOCATION_ID
        description: "{{doc('invocation_id')}}"

'''
'''--- models/silver/curated/staking/silver__staking_actions_v2.sql ---
{{ config(
    materialized = 'table',
    unique_key = 'tx_hash',
    incremental_strategy = 'merge',
    merge_exclude_columns = ["inserted_timestamp"],
    tags = ['curated'],
    cluster_by = ['_partition_by_block_number', 'block_timestamp::date']
) }}

WITH pool_events AS (

    SELECT
        tx_hash,
        block_id,
        block_timestamp,
        receipt_object_id,
        receiver_id,
        signer_id,
        status_value,
        logs,
        LOG,
        _partition_by_block_number,
        _inserted_timestamp,
        modified_timestamp AS _modified_timestamp
    FROM
        {{ ref('silver__pool_events') }}
    WHERE
        {% if var("MANUAL_FIX") %}
            {{ partition_load_manual('no_buffer') }}
        {% else %}
            {% if var('IS_MIGRATION') %}
                {{ incremental_load_filter('_inserted_timestamp') }}
            {% else %}
                {{ incremental_load_filter('_modified_timestamp') }}
            {% endif %}
        {% endif %}
),
staking_actions AS (
    SELECT
        tx_hash,
        block_id,
        block_timestamp,
        receipt_object_id,
        receiver_id,
        signer_id,
        status_value,
        logs,
        LOG,
        SPLIT(
            LOG,
            ' '
        ) AS log_parts,
        SPLIT(
            log_parts [0] :: STRING,
            '@'
        ) [1] :: STRING AS log_signer_id,
        log_parts [1] :: STRING AS action,
        SPLIT(
            log_parts [2] :: STRING,
            '.'
        ) [0] :: NUMBER AS amount_raw,
        amount_raw :: FLOAT / pow(
            10,
            24
        ) AS amount_adj,
        LENGTH(
            amount_raw :: STRING
        ) AS decimals,
        signer_id = log_signer_id AS _log_signer_id_match,
        _partition_by_block_number,
        _inserted_timestamp,
        _modified_timestamp
    FROM
        pool_events
    WHERE
        TRUE
        AND receiver_id != signer_id
        AND LOG LIKE '@%'
),
FINAL AS (
    SELECT
        tx_hash,
        block_id,
        block_timestamp,
        receipt_object_id,
        receiver_id,
        signer_id,
        status_value,
        logs,
        LOG,
        log_signer_id,
        action,
        amount_raw,
        amount_adj,
        decimals,
        _log_signer_id_match,
        _partition_by_block_number,
        _inserted_timestamp,
        _modified_timestamp
    FROM
        staking_actions
)
SELECT
    *,
    {{ dbt_utils.generate_surrogate_key(
        ['tx_hash']
    ) }} AS staking_actions_v2_id,
    SYSDATE() AS inserted_timestamp,
    SYSDATE() AS modified_timestamp,
    '{{ invocation_id }}' AS _invocation_id
FROM
    FINAL

'''
'''--- models/silver/curated/staking/silver__staking_actions_v2.yml ---
version: 2

models:
  - name: silver__staking_actions_v2
    description: |-
      An updated version of the staking actions table which looks at all logs, instead of just the first receipt.
      There are four actions taken when staking: staking->deposit->unstaking->withdraw.

    columns:
      - name: tx_hash
        description: "{{ doc('tx_hash') }}"

      - name: block_id
        description: "{{ doc('block_id') }}"

      - name: block_timestamp
        description: "{{ doc('block_timestamp') }}"

      - name: receipt_object_id
        description: "{{ doc('receipt_object_id') }}"

      - name: receiver_id
        description: "{{ doc('receiver_id') }}"

      - name: signer_id
        description: "{{ doc('signer_id') }}"

      - name: status_value
        description: "{{ doc('status_value') }}"

      - name: logs
        description: "{{ doc('logs') }}"

      - name: LOG
        description: "{{ doc('log') }}"

      - name: log_signer_id
        description: "{{ doc('log_signer_id') }}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - VARCHAR

      - name: action
        description: "{{ doc('staking_action') }}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - VARCHAR
          - accepted_values:
              values:
                - deposited
                - withdrawing
                - staking
                - unstaking

      - name: amount_raw
        description: "{{ doc('amount_raw') }}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - NUMBER

      - name: amount_adj
        description: "{{ doc('amount_adj') }}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - FLOAT
                - DOUBLE

      - name: decimals
        description: "{{ doc('decimals') }}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - NUMBER

      - name: _log_signer_id_match
        description: "{{ doc('_log_signer_id_match') }}"

      - name: _PARTITION_BY_BLOCK_NUMBER
        description: "{{ doc('_partition_by_block_number') }}"

      - name: _INSERTED_TIMESTAMP
        description: "{{ doc('_inserted_timestamp')}}"

      - name: _MODIFIED_TIMESTAMP
        description: "{{ doc('_modified_timestamp') }}"

      - name: STAKING_ACTIONS_V2_ID
        description: "{{doc('id')}}"

      - name: INSERTED_TIMESTAMP
        description: "{{doc('inserted_timestamp')}}"

      - name: MODIFIED_TIMESTAMP
        description: "{{doc('modified_timestamp')}}"

      - name: _INVOCATION_ID
        description: "{{doc('invocation_id')}}"

'''
'''--- models/silver/curated/staking/silver__staking_epochs.sql ---
{{ config(
    materialized = 'table',
    unique_key = '_epoch_id',
    incremental_strategy = 'merge',
    merge_exclude_columns = ["inserted_timestamp"],
    tags = ['curated'],
    cluster_by = ['block_id']
) }}

WITH pool_events AS (

    SELECT
        *
    FROM
        {{ ref('silver__pool_events') }}
    WHERE
        {% if var("MANUAL_FIX") %}
            {{ partition_load_manual('no_buffer') }}
        {% else %}
            {{ incremental_load_filter('_inserted_timestamp') }}
        {% endif %}
        AND LOG LIKE 'Epoch%'
),
FINAL AS (
    SELECT
        tx_hash,
        block_id,
        block_timestamp,
        receiver_id AS pool_id,
        SUBSTR(REGEXP_SUBSTR(LOG, 'Epoch [0-9]+'), 7) :: NUMBER AS epoch_number,
        REGEXP_SUBSTR(
            REGEXP_SUBSTR(
                LOG,
                'Contract received total rewards of [0-9]+'
            ),
            '[0-9]+'
        ) :: NUMBER AS reward_tokens,
        REGEXP_SUBSTR(
            REGEXP_SUBSTR(
                LOG,
                'New total staked balance is [0-9]+'
            ),
            '[0-9]+'
        ) :: NUMBER AS total_staked_balance,
        REGEXP_SUBSTR(
            REGEXP_SUBSTR(
                LOG,
                'Total number of shares [0-9]+'
            ),
            '[0-9]+'
        ) :: NUMBER AS total_staking_shares,
        LOG,
        _partition_by_block_number,
        {{ dbt_utils.generate_surrogate_key(['pool_id', 'epoch_number']) }} AS _epoch_id,
        _inserted_timestamp
    FROM
        pool_events
)
SELECT
    *,
    _epoch_id AS staking_epochs_id,
    SYSDATE() AS inserted_timestamp,
    SYSDATE() AS modified_timestamp,
    '{{ invocation_id }}' AS _invocation_id
FROM
    FINAL

'''
'''--- models/silver/curated/staking/silver__staking_epochs.yml ---
version: 2

models:
  - name: silver__staking_epochs
    description: |-
      This table extracts epoch information for each pool from the logs of the reward receipts. 
      Note, it appears that the epoch log is only recorded during an act of withdrawal or deposit by a delegator, anbd not on each epoch.

    tests:
        - dbt_utils.recency:
            datepart: day
            field: block_timestamp
            interval: 1

    columns:
      - name: TX_HASH
        description: "{{ doc('tx_hash')}}"
        tests:
          - not_null

      - name: BLOCK_ID
        description: "{{ doc('block_id')}}"
        tests:
          - not_null

      - name: BLOCK_TIMESTAMP
        description: "{{ doc('block_timestamp')}}"
        tests:
          - not_null

      - name: POOL_ID
        description: "{{ doc('pool_id')}}"
        tests:
          - not_null

      - name: EPOCH_NUMBER
        description: "{{ doc('epoch_number')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_of_type:
              column_type: NUMBER

      - name: REWARD_TOKENS
        description: "{{ doc('reward_tokens')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_of_type:
              column_type: NUMBER

      - name: TOTAL_STAKED_BALANCE
        description: "{{ doc('total_staked_balance')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_of_type:
              column_type: NUMBER

      - name: TOTAL_STAKING_SHARES
        description: "{{ doc('total_staking_shares')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_of_type:
              column_type: NUMBER

      - name: LOG
        description: "{{ doc('log')}}"

      - name: _PARTITION_BY_BLOCK_NUMBER
        description: "{{ doc('_partition_by_block_number')}}"

      - name: _EPOCH_ID
        description: "{{ doc('_epoch_id')}}"
        tests:
          - unique
          - not_null

      - name: _INSERTED_TIMESTAMP
        description: "{{ doc('_inserted_timestamp')}}"

      - name: STAKING_EPOCHS_ID
        description: "{{doc('id')}}"

      - name: INSERTED_TIMESTAMP
        description: "{{doc('inserted_timestamp')}}"

      - name: MODIFIED_TIMESTAMP
        description: "{{doc('modified_timestamp')}}"

      - name: _INVOCATION_ID
        description: "{{doc('invocation_id')}}"

'''
'''--- models/silver/curated/staking/silver__staking_pools_s3.sql ---
{{ config(
    materialized = 'incremental',
    cluster_by = ['block_timestamp'],
    unique_key = 'tx_hash',
    incremental_strategy = 'merge',
    merge_exclude_columns = ["inserted_timestamp"],
    tags = ['curated']
) }}
{# Note - multisource model #}
WITH txs AS (

    SELECT
        tx_hash,
        block_timestamp,
        block_id,
        tx_signer,
        tx_receiver,
        tx,
        tx_status,
        _partition_by_block_number,
        _inserted_timestamp,
        modified_timestamp AS _modified_timestamp
    FROM
        {{ ref('silver__streamline_transactions_final') }}

    {% if var("MANUAL_FIX") %}
      WHERE {{ partition_load_manual('no_buffer') }}
    {% else %}
        WHERE _modified_timestamp >= (
            SELECT
                MAX(_modified_timestamp)
            FROM
                {{ this }}
        )
    {% endif %}
),
function_calls AS (
    SELECT
        tx_hash,
        block_timestamp,
        block_id,
        SPLIT(
            action_id,
            '-'
        ) [0] :: STRING AS receipt_object_id,
        receiver_id,
        signer_id,
        method_name,
        args,
        _partition_by_block_number,
        _inserted_timestamp,
        modified_timestamp AS _modified_timestamp
    FROM
        {{ ref('silver__actions_events_function_call_s3') }}
    WHERE
        method_name IN (
            'create_staking_pool',
            'update_reward_fee_fraction',
            'new'
        ) 

    {% if var("MANUAL_FIX") %}
      AND {{ partition_load_manual('no_buffer') }}
    {% else %}
            {% if is_incremental() %}
        AND _modified_timestamp >= (
            SELECT
                MAX(_modified_timestamp)
            FROM
                {{ this }}
        )
    {% endif %}
    {% endif %}
),
add_addresses_from_tx AS (
    SELECT
        fc.tx_hash,
        fc.block_timestamp,
        fc.block_id,
        receipt_object_id,
        tx_receiver,
        tx_signer,
        receiver_id,
        signer_id,
        method_name,
        args,
        tx_status,
        txs._partition_by_block_number,
        txs._inserted_timestamp,
        txs._modified_timestamp
    FROM
        function_calls fc
        LEFT JOIN txs USING (tx_hash)
),
new_pools AS (
    SELECT
        tx_hash,
        block_timestamp,
        block_id,
        args :owner_id :: STRING AS owner,
        receiver_id AS address,
        TRY_PARSE_JSON(
            args :reward_fee_fraction
        ) AS reward_fee_fraction,
        'Create' AS tx_type,
        _partition_by_block_number,
        _inserted_timestamp,
        _modified_timestamp
    FROM
        add_addresses_from_tx
    WHERE
        tx_hash IN (
            SELECT
                DISTINCT tx_hash
            FROM
                add_addresses_from_tx
            WHERE
                method_name = 'create_staking_pool'
        )
        AND method_name = 'new'
),
updated_pools AS (
    SELECT
        tx_hash,
        block_timestamp,
        block_id,
        tx_signer AS owner,
        tx_receiver AS address,
        TRY_PARSE_JSON(
            args :reward_fee_fraction
        ) AS reward_fee_fraction,
        'Update' AS tx_type,
        _partition_by_block_number,
        _inserted_timestamp,
        _modified_timestamp
    FROM
        add_addresses_from_tx
    WHERE
        method_name = 'update_reward_fee_fraction'
        AND reward_fee_fraction IS NOT NULL
),
FINAL AS (
    SELECT
        *
    FROM
        new_pools
    UNION ALL
    SELECT
        *
    FROM
        updated_pools
)
SELECT
    *,
    {{ dbt_utils.generate_surrogate_key(
        ['tx_hash']
    ) }} AS staking_pools_id,
    SYSDATE() AS inserted_timestamp,
    SYSDATE() AS modified_timestamp,
    '{{ invocation_id }}' AS _invocation_id
FROM
    FINAL
WHERE
    address LIKE '%pool%'

'''
'''--- models/silver/curated/staking/silver__staking_pools_s3.yml ---
version: 2

models:
  - name: silver__staking_pools_s3
    description: |-
      This table extracts all staking pools registered with NEAR.

    columns:
      - name: tx_hash
        description: "{{ doc('tx_hash')}}"

      - name: block_timestamp
        description: "{{ doc('block_timestamp')}}"

      - name: owner
        description: "{{ doc('staking_pool_owner')}}"

      - name: address
        description: "{{ doc('staking_pool_address')}}"

      - name: reward_fee_fraction
        description: "{{ doc('staking_pool_reward_fee_fraction')}}"

      - name: tx_type
        description: "{{ doc('staking_pool_tx_type') }}"

      - name: _PARTITION_BY_BLOCK_NUMBER
        description: "{{ doc('_partition_by_block_number')}}"

      - name: _INSERTED_TIMESTAMP
        description: "{{ doc('_inserted_timestamp')}}"

      - name: _MODIFIED_TIMESTAMP
        description: "{{ doc('_modified_timestamp')}}"

      - name: STAKING_POOLS_ID
        description: "{{doc('id')}}"

      - name: INSERTED_TIMESTAMP
        description: "{{doc('inserted_timestamp')}}"

      - name: MODIFIED_TIMESTAMP
        description: "{{doc('modified_timestamp')}}"

      - name: _INVOCATION_ID
        description: "{{doc('invocation_id')}}"

'''
'''--- models/silver/github/silver__github_data.sql ---
{{ config(
    materialized = 'incremental',
    merge_exclude_columns = ["inserted_timestamp"],
    unique_key = ['_res_id'],
    cluster_by = ['_inserted_timestamp::DATE'],
    tags = ['activity']
) }}

WITH github AS (

    SELECT
        repo_owner,
        repo_name,
        endpoint_name,
        DATA,
        provider,
        endpoint_github,
        _inserted_timestamp,
        _res_id
    FROM
        {{ source(
            'crosschain_silver',
            'github_activity'
        ) }}
    WHERE
        project_name = 'near'

{% if is_incremental() %}
AND _inserted_timestamp > (
    SELECT
        MAX(_inserted_timestamp)
    FROM
        {{ this }}
)
{% endif %}
)
SELECT
    *,
    {{ dbt_utils.generate_surrogate_key(
        ['_res_id']
    ) }} AS github_data_id,
    SYSDATE() AS inserted_timestamp,
    SYSDATE() AS modified_timestamp,
    '{{ invocation_id }}' AS _invocation_id
FROM
    github

'''
'''--- models/silver/github/silver__github_data.yml ---
version: 2

models:
  - name: silver__github_data
    description: Table for Near Github data

    columns:
      - name: REPO_OWNER
        description: "Repo owner"

      - name: REPO_NAME
        description: "Repo name"

      - name: ENDPOINT_NAME
        description: "Endpoint name for the data"

      - name: DATA
        description: "Data from the endpoint"

      - name: PROVIDER
        description: "Provider for the data"

      - name: ENDPOINT_GITHUB
        description: "Endpoint for data"

      - name: INSERTED_AT
        description: "Timestamp when the data was inserted into the table"

      - name: GITHUB_DATA_ID
        description: "{{doc('id')}}"

      - name: INSERTED_TIMESTAMP
        description: "{{doc('inserted_timestamp')}}"

      - name: MODIFIED_TIMESTAMP
        description: "{{doc('modified_timestamp')}}"

      - name: _INVOCATION_ID
        description: "{{doc('invocation_id')}}"

'''
'''--- models/silver/horizon/silver_horizon__decoded_actions.sql ---
{{ config(
    materialized = 'incremental',
    merge_exclude_columns = ["inserted_timestamp"],
    unique_key = 'action_id_horizon',
    cluster_by = ['_inserted_timestamp::date', '_partition_by_block_number'],
    tags = ['curated', 'horizon']
) }}
{# Note - multisource model #}
WITH all_horizon_receipts AS (

    SELECT
        tx_hash,
        receipt_object_id,
        receiver_id,
        signer_id,
        receipt_succeeded,
        logs,
        _partition_by_block_number,
        _inserted_timestamp,
        modified_timestamp AS _modified_timestamp
    FROM
        {{ ref('silver_horizon__receipts') }}

        {% if var("MANUAL_FIX") %}
        WHERE {{ partition_load_manual('no_buffer') }}
        {% else %}
            {% if is_incremental() %}
            WHERE _modified_timestamp >= (
                SELECT
                    MAX(_modified_timestamp)
                FROM
                    {{ this }}
            )
        {% endif %}
        {% endif %}
),
decoded_function_calls AS (
    SELECT
        SPLIT(
            action_id,
            '-'
        ) [0] :: STRING AS receipt_object_id,
        action_id,
        tx_hash,
        block_id,
        block_timestamp,
        method_name,
        args,
        deposit,
        attached_gas,
        _partition_by_block_number,
        _inserted_timestamp,
        modified_timestamp AS _modified_timestamp
    FROM
        {{ ref('silver__actions_events_function_call_s3') }}
    WHERE
        _partition_by_block_number >= 85000000
        AND SPLIT(
            action_id,
            '-'
        ) [0] :: STRING IN (
            SELECT
                DISTINCT receipt_object_id
            FROM
                all_horizon_receipts
        )

        {% if var("MANUAL_FIX") %}
        AND {{ partition_load_manual('no_buffer') }}
        {% else %}
            {% if is_incremental() %}
            AND _modified_timestamp >= (
                SELECT
                    MAX(_modified_timestamp)
                FROM
                    {{ this }}
            )
        {% endif %}
        {% endif %}
),
FINAL AS (
    SELECT
        fc.action_id,
        fc.tx_hash,
        r.receipt_object_id,
        fc.block_id,
        fc.block_timestamp,
        fc.method_name,
        fc.args,
        fc.deposit,
        fc.attached_gas,
        r.receiver_id,
        r.signer_id,
        r.receipt_succeeded,
        r.logs,
        fc._partition_by_block_number,
        fc._inserted_timestamp,
        fc._modified_timestamp
    FROM
        decoded_function_calls fc
        LEFT JOIN all_horizon_receipts r USING (receipt_object_id)
)
SELECT
    action_id AS action_id_horizon,
    tx_hash,
    receipt_object_id,
    block_id,
    block_timestamp,
    method_name,
    args,
    deposit,
    attached_gas,
    receiver_id,
    signer_id,
    receipt_succeeded,
    _partition_by_block_number,
    _inserted_timestamp,
    _modified_timestamp,
    {{ dbt_utils.generate_surrogate_key(
        ['action_id_horizon']
    ) }} AS horizon_decoded_actions_id,
    SYSDATE() AS inserted_timestamp,
    SYSDATE() AS modified_timestamp,
    '{{ invocation_id }}' AS _invocation_id
FROM
    FINAL

'''
'''--- models/silver/horizon/silver_horizon__decoded_actions.yml ---

version: 2

models:
  - name: silver_horizon__decoded_actions
    description: |-
      Decoded FunctionCall events for receipts where the contract nearhorizon.near was called.

    columns:
      - name: action_id_horizon
        description: "{{ doc('action_id')}}"
        tests:
          - unique

      - name: tx_hash
        description: "{{ doc('tx_hash')}}"
        tests:
          - not_null:
              where: _inserted_timestamp <= current_timestamp - interval '1 hour'

      - name: receipt_object_id
        description: "{{ doc('receipt_object_id')}}"

      - name: block_id
        description: "{{ doc('block_id')}}"

      - name: block_timestamp
        description: "{{ doc('block_timestamp')}}"
        tests: 
          - not_null:
              where: _inserted_timestamp <= current_timestamp - interval '1 hour'

      - name: method_name
        description: "{{ doc('method_name')}}"
        tests:
          - not_null

      - name: args
        description: "{{ doc('args')}}"
        tests: 
          - not_null

      - name: deposit
        description: "{{ doc('deposit')}}"

      - name: attached_gas
        description: "{{ doc('attached_gas')}}"

      - name: receiver_id
        description: "{{ doc('receiver_id')}}"
        tests: 
          - not_null

      - name: signer_id
        description: "{{ doc('signer_id')}}"
        tests:
          - not_null

      - name: receipt_succeeded
        description: "{{ doc('receipt_succeeded')}}"

      - name: _partition_by_block_number
        description: "{{ doc('_partition_by_block_number')}}"

      - name: _INSERTED_TIMESTAMP
        description: "{{ doc('_inserted_timestamp')}}"

      - name: _MODIFIED_TIMESTAMP
        description: "{{ doc('_modified_timestamp')}}"

      - name: HORIZON_DECODED_ACTIONS_ID
        description: "{{doc('id')}}"

      - name: INSERTED_TIMESTAMP
        description: "{{doc('inserted_timestamp')}}"

      - name: MODIFIED_TIMESTAMP
        description: "{{doc('modified_timestamp')}}"

      - name: _INVOCATION_ID
        description: "{{doc('invocation_id')}}"

'''
'''--- models/silver/horizon/silver_horizon__receipts.sql ---
{{ config(
    materialized = 'incremental',
    merge_exclude_columns = ["inserted_timestamp"],
    unique_key = 'receipt_object_id',
    cluster_by = ['_inserted_timestamp::date', 'block_timestamp::DATE'],
    tags = ['curated', 'horizon']
) }}

WITH all_horizon_receipts AS (

    SELECT
        tx_hash,
        receipt_object_id,
        block_id,
        block_timestamp,
        receipt_index,
        chunk_hash,
        receipt_actions,
        execution_outcome,
        receipt_outcome_id,
        receiver_id,
        signer_id,
        receipt_type,
        gas_burnt,
        status_value,
        receipt_succeeded,
        logs,
        proof,
        metadata,
        _partition_by_block_number,
        _inserted_timestamp,
        modified_timestamp AS _modified_timestamp
    FROM
        {{ ref('silver__streamline_receipts_final') }}

        WHERE (
            LOWER(signer_id) = 'nearhorizon.near'
            OR LOWER(receiver_id) = 'nearhorizon.near'
            )
        AND _partition_by_block_number >= 86000000

        {% if var("MANUAL_FIX") %}
        AND {{ partition_load_manual('no_buffer') }}
        {% else %}
            {% if is_incremental() %}
            AND _modified_timestamp >= (
                SELECT
                    MAX(_modified_timestamp)
                FROM
                    {{ this }}
            )
        {% endif %}
        {% endif %}
)

    SELECT
        *,
        {{ dbt_utils.generate_surrogate_key(
            ['receipt_object_id']
        ) }} AS horizon_receipts_id,
        SYSDATE() AS inserted_timestamp,
        SYSDATE() AS modified_timestamp,
        '{{ invocation_id }}' AS _invocation_id
    FROM
        all_horizon_receipts

'''
'''--- models/silver/horizon/silver_horizon__receipts.yml ---

version: 2

models:
  - name: silver_horizon__receipts
    description: |-
      Filtered receipts where the signer or receiver is the contract nearsocial.near.

    columns:
      - name: tx_hash
        description: "{{ doc('tx_hash')}}"

      - name: block_id
        description: "{{ doc('block_id')}}"

      - name: receipt_index
        description: "{{ doc('receipt_index')}}"

      - name: chunk_hash
        description: "{{ doc('chunk_hash')}}"

      - name: receipt_actions
        description: "{{ doc('receipt')}}"

      - name: execution_outcome
        description: "{{ doc('execution_outcome')}}"

      - name: receipt_object_id
        description: "{{ doc('receipt_object_id')}}"
        tests: 
          - unique

      - name: receipt_outcome_id
        description: "{{ doc('receipt_outcome_id')}}"

      - name: receiver_id
        description: "{{ doc('receiver_id')}}"

      - name: signer_id
        description: "{{ doc('signer_id')}}"

      - name: receipt_type
        description: "{{ doc('receipt_type')}}"

      - name: gas_burnt
        description: "{{ doc('gas_burnt')}}"

      - name: status_value
        description: "{{ doc('status_value')}}"

      - name: receipt_succeeded
        description: "{{ doc('receipt_succeeded')}}"

      - name: logs
        description: "{{ doc('logs')}}"

      - name: proof
        description: "{{ doc('proof')}}"

      - name: metadata
        description: "{{ doc('metadata')}}"

      - name: _partition_by_block_number
        description: "{{ doc('_partition_by_block_number')}}"

      - name: _INSERTED_TIMESTAMP
        description: "{{ doc('_inserted_timestamp')}}"

      - name: _MODIFIED_TIMESTAMP
        description: "{{ doc('_modified_timestamp')}}"

      - name: HORIZON_RECEIPTS_ID
        description: "{{doc('id')}}"

      - name: INSERTED_TIMESTAMP
        description: "{{doc('inserted_timestamp')}}"

      - name: MODIFIED_TIMESTAMP
        description: "{{doc('modified_timestamp')}}"

      - name: _INVOCATION_ID
        description: "{{doc('invocation_id')}}"

'''
'''--- models/silver/labels/silver__address_labels.sql ---
{{ config(
    materialized = 'incremental',
    merge_exclude_columns = ["inserted_timestamp"],
    unique_key = 'address',
    cluster_by = 'address',
    tags = ['labels'],
    post_hook = "ALTER TABLE {{ this }} ADD SEARCH OPTIMIZATION ON EQUALITY(address); DELETE FROM {{ this }} WHERE _is_deleted = TRUE;"
) }}

WITH address_labels AS (

    SELECT
        system_created_at,
        blockchain,
        address,
        creator,
        label_type,
        label_subtype,
        address_name,
        project_name,
        labels_combined_id,
        _is_deleted,
        _inserted_timestamp,
        _modified_timestamp
        
    FROM
        {{ ref('bronze__address_labels') }}

{% if is_incremental() %}
WHERE
    {{ incremental_load_filter('_modified_timestamp') }}
{% endif %}
)
SELECT
    system_created_at,
    blockchain,
    address,
    creator,
    address_name,
    project_name,
    label_type,
    label_subtype,
    label_type AS l1_label,
    label_subtype AS l2_label,
    _inserted_timestamp,
    _modified_timestamp,
    _is_deleted,
    labels_combined_id  as address_labels_id,
    SYSDATE() AS inserted_timestamp,
    SYSDATE() AS modified_timestamp,
    '{{ invocation_id }}' AS _invocation_id
FROM
    address_labels

'''
'''--- models/silver/labels/silver__api_nearblocks_fts.sql ---
{{ config(
    materialized = 'incremental',
    merge_exclude_columns = ["inserted_timestamp"],
    unique_key = '_res_id',
    incremental_strategy = 'merge',
    cluster_by = ['_inserted_timestamp::date', 'token_contract'],
    tags = ['api', 'labels']
) }}
{# Deprecated 9/25/2023, TODO disable via config.
12 / 11 / 2023 note - DATA IN bronze still used IN gold VIEW.#}
WITH nearblocks_token_api AS (

    SELECT
        *
    FROM
        {{ target.database }}.bronze_api.nearblocks_fts
    WHERE
        {{ incremental_load_filter('_inserted_timestamp') }}
        qualify ROW_NUMBER() over (
            PARTITION BY concat_ws(
                '-',
                _inserted_timestamp :: DATE,
                token_contract
            )
            ORDER BY
                _inserted_timestamp DESC
        ) = 1
),
FINAL AS (
    SELECT
        _inserted_timestamp :: DATE AS DATE,
        token_name AS token,
        token_contract,
        token_data,
        token_data :decimals :: NUMBER AS decimals,
        token_data :symbol :: STRING AS symbol,
        provider,
        _inserted_timestamp,
        _res_id,
        {{ dbt_utils.generate_surrogate_key(
            ['_res_id']
        ) }} AS api_nearblocks_fts_id,
        SYSDATE() AS inserted_timestamp,
        SYSDATE() AS modified_timestamp,
        '{{ invocation_id }}' AS _invocation_id
    FROM
        nearblocks_token_api
)
SELECT
    *
FROM
    FINAL

'''
'''--- models/silver/labels/silver__api_nearblocks_fts.yml ---
version: 2

models:
  - name: silver__api_nearblocks_fts
    description: |-
      Holds data ingested from the Nearblocks Fungible Token API endpoint at: https://api.nearblocks.io/api-docs/#/FTs/get_v1_fts

    columns:
      - name: date
        description: "The date from the UTC timestamp when the API was called and the data for this token was ingested."

      - name: token
        description: "{{ doc('token')}}"

      - name: token_contract
        description: "{{ doc('token_contract')}}"

      - name: token_data
        description: "{{ doc('token_data')}}"

      - name: decimals
        description: "{{ doc('decimals')}}"

      - name: symbol
        description: "{{ doc('symbol')}}"

      - name: provider
        description: "{{ doc('provider')}}"

      - name: _inserted_timestamp
        description: "{{ doc('_inserted_timestamp')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - TIMESTAMP_NTZ
          - dbt_expectations.expect_row_values_to_have_recent_data:
              datepart: day
              interval: 1

      - name: _res_id
        description: "{{ doc('_res_id')}}"
        tests:
          - unique
          - not_null:
              name: not_null_silver__api_nearblocks_fts_res_id
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - VARCHAR
                - STRING
              name: dbt_expectations_expect_column_values_to_be_in_type_list_silver__api_nearblocks_fts_res_id__STRING

      - name: API_NEARBLOCKS_FTS_ID
        description: "{{doc('id')}}"

      - name: INSERTED_TIMESTAMP
        description: "{{doc('inserted_timestamp')}}"

      - name: MODIFIED_TIMESTAMP
        description: "{{doc('modified_timestamp')}}"

      - name: _INVOCATION_ID
        description: "{{doc('invocation_id')}}"

'''
'''--- models/silver/labels/silver__dates.sql ---
{{ config(
    materialized = 'table',
    unique_key = 'date_day',
    tags = ['labels']
) }}

WITH dim_dates AS (

    SELECT
        date_day,
        prior_date_day,
        next_date_day,
        prior_year_date_day,
        prior_year_over_year_date_day,
        day_of_week,
        day_of_week_iso,
        day_of_week_name,
        day_of_week_name_short,
        day_of_month,
        day_of_year,
        week_start_date,
        week_end_date,
        prior_year_week_start_date,
        prior_year_week_end_date,
        week_of_year,
        iso_week_start_date,
        iso_week_end_date,
        prior_year_iso_week_start_date,
        prior_year_iso_week_end_date,
        iso_week_of_year,
        prior_year_week_of_year,
        prior_year_iso_week_of_year,
        month_of_year,
        month_name,
        month_name_short,
        month_start_date,
        month_end_date,
        prior_year_month_start_date,
        prior_year_month_end_date,
        quarter_of_year,
        quarter_start_date,
        quarter_end_date,
        year_number,
        year_start_date,
        year_end_date
    FROM
        {{ ref('bronze__dates') }}
)
SELECT
    *
FROM
    dim_dates

'''
'''--- models/silver/labels/silver__foundation_labels.sql ---
{{ config(
    materialized = 'table',
    cluster_by = 'wallet_address',
    unique_key = 'wallet_address',
    tags = ['labels']
) }}

WITH labels AS (

    SELECT
        project_name,
        category,
        wallet_address,
        enabled
    FROM
        {{ ref('seeds__near_project_labels_v1') }}
)
SELECT
    '2023-05-05' :: TIMESTAMP AS system_created_at,
    project_name,
    category,
    wallet_address,
    enabled,
    'Near Foundation' AS creator,
    {{ dbt_utils.generate_surrogate_key(
        ['wallet_address']
    ) }} AS foundation_labels_id,
    SYSDATE() AS inserted_timestamp,
    SYSDATE() AS modified_timestamp,
    '{{ invocation_id }}' AS _invocation_id
FROM
    labels

'''
'''--- models/silver/labels/silver__ft_contract_metadata.sql ---
{{ config(
    materialized = 'incremental',
    unique_key = 'contract_address',
    incremental_strategy = 'merge',
    merge_exclude_columns = ["inserted_timestamp"],
    tags = ['livequery', 'nearblocks']
) }}

WITH livequery_results AS (

    SELECT
        *
    FROM
        {{ ref('livequery__request_nearblocks_ft_metadata') }}

{% if is_incremental() %}
WHERE
    _inserted_timestamp >= (
        SELECT
            MAX(_inserted_timestamp)
        FROM
            {{ this }}
    )
{% endif %}
),
flatten_results AS (
    SELECT
        VALUE :contract :: STRING AS contract_address,
        VALUE :decimals :: INT AS decimals,
        VALUE :icon :: STRING AS icon,
        VALUE :name :: STRING AS NAME,
        VALUE :symbol :: STRING AS symbol,
        VALUE AS DATA,
        _inserted_timestamp,
        _res_id
    FROM
        livequery_results,
        LATERAL FLATTEN(
            input => DATA :data :tokens
        )
),
FINAL AS (
    SELECT
        contract_address,
        decimals,
        icon,
        NAME,
        symbol,
        DATA,
        _inserted_timestamp,
        _res_id
    FROM
        flatten_results 
        qualify ROW_NUMBER() over (
            PARTITION BY contract_address
            ORDER BY
                _inserted_timestamp DESC
        ) = 1
)
SELECT
    *,
    {{ dbt_utils.generate_surrogate_key(
        ['contract_address']
    ) }} AS ft_contract_metadata_id,
    SYSDATE() AS inserted_timestamp,
    SYSDATE() AS modified_timestamp,
    '{{ invocation_id }}' AS _invocation_id
FROM
    FINAL

'''
'''--- models/silver/labels/silver__ft_contract_metadata.yml ---
version: 2

models:
  - name: silver__ft_contract_metadata
    description: |-
      Fungible Token contract metadata provided by the Nearblocks NFT endpoint.
    tests:
      - dbt_utils.recency:
          datepart: day
          field: _inserted_timestamp
          interval: 14

    columns:
      - name: CONTRACT_ADDRESS
        description: "{{ doc('contract_address')}}"
        tests:
          - not_null
          - unique
          - dbt_expectations.expect_column_values_to_be_of_type:
              column_type: VARCHAR

      - name: DECIMALS
        description: "{{ doc('decimals')}}"
        tests:
          - not_null

      - name: ICON
        description: "{{ doc('icon')}}"

      - name: NAME
        description: "{{ doc('name')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_of_type:
              column_type: VARCHAR

      - name: SYMBOL
        description: "{{ doc('symbol')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_of_type:
              column_type: VARCHAR

      - name: DATA
        description: "{{ doc('data')}}"

      - name: _INSERTED_TIMESTAMP
        description: "{{ doc('_inserted_timestamp')}}"

      - name: _RES_ID
        description: "{{ doc('_res_id')}}"

      - name: FT_CONTRACT_METADATA_ID
        description: "{{doc('id')}}"

      - name: INSERTED_TIMESTAMP
        description: "{{doc('inserted_timestamp')}}"

      - name: MODIFIED_TIMESTAMP
        description: "{{doc('modified_timestamp')}}"

      - name: _INVOCATION_ID
        description: "{{doc('invocation_id')}}"

'''
'''--- models/silver/labels/silver__nft_contract_metadata.sql ---
{{ config(
    materialized = 'incremental',
    merge_exclude_columns = ["inserted_timestamp"],
    unique_key = 'contract_address',
    incremental_strategy = 'merge',
    tags = ['livequery', 'nearblocks'],
) }}

WITH livequery_results AS (

    SELECT
        *
    FROM
        {{ ref('livequery__request_nearblocks_nft_metadata') }}

{% if is_incremental() %}
WHERE
    _inserted_timestamp >= (
        SELECT
            MAX(_inserted_timestamp)
        FROM
            {{ this }}
    )
{% endif %}
),
flatten_results AS (
    SELECT
        VALUE :base_uri :: STRING AS base_uri,
        VALUE :contract :: STRING AS contract_address,
        VALUE :icon :: STRING AS icon,
        VALUE :name :: STRING AS NAME,
        VALUE :symbol :: STRING AS symbol,
        VALUE :tokens :: INT AS tokens,
        VALUE AS DATA,
        _inserted_timestamp,
        _res_id
    FROM
        livequery_results,
        LATERAL FLATTEN(
            input => DATA :data :tokens
        )
),
FINAL AS (
    SELECT
        base_uri,
        contract_address,
        icon,
        NAME,
        symbol,
        tokens,
        DATA,
        _inserted_timestamp,
        _res_id
    FROM
        flatten_results qualify ROW_NUMBER() over (
            PARTITION BY contract_address
            ORDER BY
                _inserted_timestamp DESC
        ) = 1
)
SELECT
    *,
    {{ dbt_utils.generate_surrogate_key(
        ['contract_address']
    ) }} AS nft_contract_metadata_id,
    SYSDATE() AS inserted_timestamp,
    SYSDATE() AS modified_timestamp,
    '{{ invocation_id }}' AS _invocation_id
FROM
    FINAL

'''
'''--- models/silver/labels/silver__nft_contract_metadata.yml ---
version: 2

models:
  - name: silver__nft_contract_metadata
    description: |-
      NFT Contract-level metadata provided by the Nearblocks NFT endpoint.
    tests:
      - dbt_utils.recency:
          datepart: day
          field: _inserted_timestamp
          interval: 7

    columns:
      - name: BASE_URI
        description: "{{ doc('base_uri')}}"

      - name: CONTRACT_ADDRESS
        description: "{{ doc('contract_address')}}"
        tests:
          - not_null
          - unique
          - dbt_expectations.expect_column_values_to_be_of_type:
              column_type: VARCHAR

      - name: ICON
        description: "{{ doc('icon')}}"

      - name: NAME
        description: "{{ doc('name')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_of_type:
              column_type: VARCHAR

      - name: SYMBOL
        description: "{{ doc('symbol')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_of_type:
              column_type: VARCHAR

      - name: TOKENS
        description: "{{ doc('tokens')}}"

      - name: DATA
        description: "{{ doc('data')}}"

      - name: _INSERTED_TIMESTAMP
        description: "{{ doc('_inserted_timestamp')}}"

      - name: _RES_ID
        description: "{{ doc('_res_id')}}"

      - name: NFT_CONTRACT_METADATA_ID
        description: "{{doc('id')}}"

      - name: INSERTED_TIMESTAMP
        description: "{{doc('inserted_timestamp')}}"

      - name: MODIFIED_TIMESTAMP
        description: "{{doc('modified_timestamp')}}"

      - name: _INVOCATION_ID
        description: "{{doc('invocation_id')}}"

'''
'''--- models/silver/labels/silver__nft_series_metadata.sql ---
{{ config(
    materialized = 'incremental',
    merge_exclude_columns = ["inserted_timestamp"],
    unique_key = 'metadata_id',
    incremental_strategy = 'merge',
    tags = ['livequery', 'pagoda']
) }}

WITH livequery_response AS (

    SELECT
        *
    FROM
        {{ ref('livequery__request_pagoda_nft_metadata') }}
    WHERE
        call_succeeded

{% if is_incremental() %}
AND _request_timestamp >= (
    SELECT
        MAX(_request_timestamp)
    FROM
        {{ this }}
)
{% endif %}
),
FINAL AS (
    SELECT
        contract_account_id AS contract_address,
        series_id,
        metadata_id,
        lq_response :data :contract_metadata :: variant AS contract_metadata,
        lq_response :data :nft :metadata :: variant AS token_metadata,
        _inserted_timestamp,
        _request_timestamp
    FROM
        livequery_response
)
SELECT
    *,
    {{ dbt_utils.generate_surrogate_key(
        ['metadata_id']
    ) }} AS nft_series_metadata_id,
    SYSDATE() AS inserted_timestamp,
    SYSDATE() AS modified_timestamp,
    '{{ invocation_id }}' AS _invocation_id
FROM
    FINAL 
    qualify ROW_NUMBER() over (
        PARTITION BY metadata_id
        ORDER BY
            _request_timestamp DESC
    ) = 1

'''
'''--- models/silver/labels/silver__nft_series_metadata.yml ---
version: 2

models:
  - name: silver__nft_series_metadata
    description: |-
      NFT Series-level metadata provided by the Pagoda NFT endpoint.
    tests:
      - dbt_utils.recency:
          datepart: day
          field: _request_timestamp
          interval: 5

    columns:
      - name: CONTRACT_ADDRESS
        description: "{{ doc('contract_address')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_of_type:
              column_type: VARCHAR

      - name: SERIES_ID
        description: "{{ doc('series_id')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_of_type:
              column_type: VARCHAR

      - name: METADATA_ID
        description: "{{ doc('metadata_id')}}"
        tests:
          - not_null
          - unique
          - dbt_expectations.expect_column_values_to_be_of_type:
              column_type: VARCHAR

      - name: CONTRACT_METADATA
        description: "{{ doc('contract_metadata')}}"

      - name: TOKEN_METADATA
        description: "{{ doc('token_metadata')}}"

      - name: _INSERTED_TIMESTAMP
        description: "{{ doc('_inserted_timestamp')}}"

      - name: _REQUEST_TIMESTAMP
        description: "{{ doc('_request_timestamp')}}"

      - name: NFT_SERIES_METADATA_ID
        description: "{{doc('id')}}"

      - name: INSERTED_TIMESTAMP
        description: "{{doc('inserted_timestamp')}}"

      - name: MODIFIED_TIMESTAMP
        description: "{{doc('modified_timestamp')}}"

      - name: _INVOCATION_ID
        description: "{{doc('invocation_id')}}"

'''
'''--- models/silver/labels/silver__token_labels.sql ---
{{ config(
    materialized = 'view',
    unique_key = 'token_contract'
) }}

WITH labels_seed AS (

    SELECT
        token,
        symbol,
        token_contract,
        decimals
    FROM
        {{ ref('seeds__token_labels') }}
)
SELECT
    *,
    {{ dbt_utils.generate_surrogate_key(
        ['token_contract']
    ) }} AS token_labels_id,
    SYSDATE() AS inserted_timestamp,
    SYSDATE() AS modified_timestamp,
    '{{ invocation_id }}' AS _invocation_id
FROM
    labels_seed

'''
'''--- models/silver/labels/silver__token_labels.yml ---
version: 2

models:
  - name: silver__token_labels
    description: |-
      This table contains symbol, contract address and decimal information about tokens on NEAR. Have some token information to add? Open a PR on the MetricsDAO GitHub.

    columns:
      - name: token
        description: "{{ doc('token')}}"

      - name: symbol
        description: "{{ doc('symbol')}}"

      - name: token_contract
        description: "{{ doc('token_contract')}}"

      - name: decimals
        description: "{{ doc('decimals')}}"

      - name: TOKEN_LABELS_ID
        description: "{{doc('id')}}"

      - name: INSERTED_TIMESTAMP
        description: "{{doc('inserted_timestamp')}}"

      - name: MODIFIED_TIMESTAMP
        description: "{{doc('modified_timestamp')}}"

      - name: _INVOCATION_ID
        description: "{{doc('invocation_id')}}"

'''
'''--- models/silver/livequery/livequery__request_nearblocks_ft_metadata.py ---
import anyjson as json
import snowflake.snowpark.types as T

from datetime import datetime

def model(dbt, session):

    dbt.config(
        materialized='incremental',
        unique_key='_RES_ID',
        packages=['anyjson'],
        tags=['livequery', 'nearblocks'],
        incremental_strategy='delete+insert'
    )

    # define api parameters
    page = 1
    url_params = {
        'page': page,
        'per_page': 50,
        'sort': 'holders',
        'order': 'desc'
    }

    # define parameters for udf_api
    method = 'GET'
    headers = {}  # no header required for this api
    data = {}  # arguments passed in URL via GET request
    base_url = 'https://api.nearblocks.io/v1/fts'

    # define result df schema with columns
    schema = T.StructType([
        T.StructField('PAGE', T.IntegerType()),
        T.StructField('REQUEST_SQL', T.StringType()),
        T.StructField('RESPONSE_COUNT', T.IntegerType()),
        T.StructField('DATA', T.VariantType()),
        T.StructField('_INSERTED_TIMESTAMP', T.TimestampType()),
        T.StructField('_RES_ID', T.StringType())
    ])

    # define result df
    result_df = session.create_dataframe(
        [],
        schema
    )
    # set upper limit
    max_page = 100

    while True:
        # set url for GET request based on url_params
        url = f'{base_url}?{"&".join([f"{k}={v}" for k, v in url_params.items()])}'

        # call udf api (max 50 requests per page)
        call_udf_sql = f"select livequery.live.udf_api('{method}', '{url}', {headers}, {data})"
        # execute udf_api call
        response = session.sql(call_udf_sql).collect()
        
        try:
            token_count = len(json.loads(response[0][0])['data']['tokens'])
        except:
            break
        if token_count > 0:

            _inserted_timestamp = datetime.utcnow()
            _res_id = f'{_inserted_timestamp.date()}-{page}'

            # append response to result df
            result_df = result_df.union(
                session.create_dataframe(
                    [
                        [
                            page,
                            call_udf_sql,
                            token_count,
                            json.loads(response[0][0]),
                            _inserted_timestamp,
                            _res_id
                        ]
                    ],
                    schema
                )
            )

            # increment page
            page += 1

            # update data
            url_params.update({'page': page})

            # break if max page reached
            if page > max_page:
                break

        else:
            break

    return result_df

'''
'''--- models/silver/livequery/livequery__request_nearblocks_nft_metadata.py ---
import anyjson as json
import snowflake.snowpark.types as T

from datetime import datetime

def model(dbt, session):

    dbt.config(
        materialized='incremental',
        unique_key='_RES_ID',
        packages=['anyjson'],
        tags=['livequery', 'nearblocks'],
        incremental_strategy='delete+insert'
    )

    # define api parameters
    page = 1
    url_params = {
        'page': page,
        'per_page': 50,
        'sort': 'holders',
        'order': 'desc'
    }

    # define parameters for udf_api
    method = 'GET'
    headers = {}  # no header required for this api
    data = {}  # arguments passed in URL via GET request
    base_url = 'https://api.nearblocks.io/v1/nfts'

    # define result df schema with columns
    schema = T.StructType([
        T.StructField('PAGE', T.IntegerType()),
        T.StructField('REQUEST_SQL', T.StringType()),
        T.StructField('RESPONSE_COUNT', T.IntegerType()),
        T.StructField('DATA', T.VariantType()),
        T.StructField('_INSERTED_TIMESTAMP', T.TimestampType()),
        T.StructField('_RES_ID', T.StringType())
    ])

    # define result df
    result_df = session.create_dataframe(
        [],
        schema
    )

    # set upper limit
    max_page = 100

    while True:
        # set url for GET request based on url_params
        url = f'{base_url}?{"&".join([f"{k}={v}" for k, v in url_params.items()])}'

        # call udf api (max 50 requests per page)
        call_udf_sql = f"select livequery.live.udf_api('{method}', '{url}', {headers}, {data})"

        # execute udf_api call
        response = session.sql(call_udf_sql).collect()
        try:
            token_count = len(json.loads(response[0][0])['data']['tokens'])
        except:
            break
        if token_count > 0:

            _inserted_timestamp = datetime.utcnow()
            _res_id = f'{_inserted_timestamp.date()}-{page}'

            # append response to result df
            result_df = result_df.union(
                session.create_dataframe(
                    [
                        [
                            page,
                            call_udf_sql,
                            token_count,
                            json.loads(response[0][0]),
                            _inserted_timestamp,
                            _res_id
                        ]
                    ],
                    schema
                )
            )

            # increment page
            page += 1

            # update data
            url_params.update({'page': page})

            # break if max page reached
            if page > max_page:
                break

        else:
            break

    return result_df

'''
'''--- models/silver/livequery/livequery__request_pagoda_nft_metadata.sql ---
{{ config(
    materialized = 'incremental',
    unique_key = 'metadata_id',
    incremental_strategy = 'delete+insert',
    tags = ['livequery', 'pagoda']
) }}

WITH nfts_minted AS (

    SELECT
        tx_hash,
        block_id,
        receiver_id AS contract_account_id,
        token_id,
        IFF(
            -- if token id does not include a series id, then set contract to series id, else extract from token id
            -- note: if a nft is deployed as its own contract, we will see this behavior
            -- if launched as part of a marketplace contract, like paras, the series id is included in the token id
            SPLIT(
                token_id,
                ':'
            ) [1] IS NULL,
            contract_account_id,
            SPLIT(
                token_id,
                ':'
            ) [0]
        ) AS series_id,
        MD5(
            receiver_id || series_id
        ) AS metadata_id,
        _inserted_timestamp
    FROM
        {{ ref('silver__standard_nft_mint_s3') }}
    WHERE
        contract_account_id NOT IN (
            'nft-assets.l2e.near' -- broken
        )
),

{% if is_incremental() %}
have_metadata AS (
    SELECT
        DISTINCT metadata_id
    FROM
        {{ this }}
),
{% endif %}

final_nfts_to_request AS (
    SELECT
        *
    FROM
        nfts_minted

{% if is_incremental() %}
WHERE
    metadata_id NOT IN (
        SELECT
            metadata_id
        FROM
            have_metadata
    )
{% endif %}
),
lq_request AS (
    SELECT
        tx_hash,
        block_id,
        contract_account_id,
        token_id,
        series_id,
        metadata_id,
        'https://near-mainnet.api.pagoda.co/eapi/v1/NFT/' || contract_account_id || '/' || token_id AS res_url,
        live.udf_api(
            'GET',
            res_url,
            { 
                'x-api-key': '{{ var('PAGODA_API_KEY', NULL) }}',
                'Content-Type': 'application/json'
            },
            {}
        ) AS lq_response,
        SYSDATE() AS _request_timestamp,
        _inserted_timestamp
    FROM
        final_nfts_to_request
    LIMIT
        {{ var(
            'SQL_LIMIT', 250
        ) }}
), FINAL AS (
    SELECT
        tx_hash,
        block_id,
        contract_account_id,
        token_id,
        series_id,
        metadata_id,
        res_url,
        lq_response,
        (
            lq_response :data :message IS NULL
        )
        AND (
            lq_response :error IS NULL
        ) AS call_succeeded,
        COALESCE(
            lq_response :data :code :: INT,
            lq_response :status_code :: INT
        ) AS error_code,
        lq_response :data :message :: STRING AS error_message,
        _request_timestamp,
        _inserted_timestamp
    FROM
        lq_request
)
SELECT
    *
FROM
    FINAL

'''
'''--- models/silver/prices/_legacy/silver__prices_oracle_s3.sql ---
{{ config(
    materialized = 'incremental',
    merge_exclude_columns = ["inserted_timestamp"],
    unique_key = 'block_id',
    incremental_strategy = 'delete+insert',
    cluster_by = ['block_timestamp::DATE'],
    tags = ['curated']
) }}

WITH token_labels AS (

    SELECT
        *
    FROM
        {{ ref('silver__token_labels') }}
),
events_function_call AS (
    SELECT
        block_id,
        tx_hash,
        block_timestamp,
        receiver_id,
        method_name,
        args,
        _partition_by_block_number,
        _inserted_timestamp,
        modified_timestamp AS _modified_timestamp
    FROM
        {{ ref('silver__actions_events_function_call_s3') }}

    {% if var("MANUAL_FIX") %}
      WHERE {{ partition_load_manual('no_buffer') }}
    {% else %}
            {% if is_incremental() %}
        WHERE _modified_timestamp >= (
            SELECT
                MAX(_modified_timestamp)
            FROM
                {{ this }}
        )
    {% endif %}
    {% endif %}
),
prices AS (
    SELECT
        block_id,
        tx_hash,
        block_timestamp,
        receiver_id,
        INDEX,
        VALUE :asset_id :: STRING AS token_contract,
        VALUE :price :multiplier :: DOUBLE AS raw_price,
        CASE
            WHEN token_contract IN ('4691937a7508860f876c9c0a2a617e7d9e945d4b.factory.bridge.near') THEN 6
            WHEN token_contract IN (
                'aaaaaa20d9e0e2461697782ef11675f668207961.factory.bridge.near'
            )
            AND block_id > 77644611 THEN 5
            WHEN token_contract IN (
                '2260fac5e5542a773aa44fbcfedf7c193bc2c599.factory.bridge.near'
            )
            AND block_id > 77644611 THEN 2
            WHEN token_contract IN (
                '2260fac5e5542a773aa44fbcfedf7c193bc2c599.factory.bridge.near'
            )
            AND len(raw_price) < 9 THEN 2
            ELSE 4
        END AS decimals,
        raw_price / pow(
            10,
            decimals
        ) AS price_usd,
        _partition_by_block_number,
        _inserted_timestamp,
        _modified_timestamp
    FROM
        events_function_call,
        LATERAL FLATTEN(
            input => args :prices
        )
    WHERE
        method_name = 'report_prices'
),
FINAL AS (
    SELECT
        p.block_id,
        p.tx_hash,
        p.block_timestamp,
        p.index,
        l.token,
        l.symbol,
        p.token_contract,
        p.raw_price,
        p.price_usd,
        p.receiver_id AS source,
        p._partition_by_block_number,
        p._inserted_timestamp,
        p._modified_timestamp
    FROM
        prices p
        LEFT JOIN token_labels l USING (token_contract)
)
SELECT
    *,
    {{ dbt_utils.generate_surrogate_key(
        ['tx_hash', 'block_id', 'token_contract']
    ) }} AS prices_oracle_id,
    SYSDATE() AS inserted_timestamp,
    SYSDATE() AS modified_timestamp,
    '{{ invocation_id }}' AS _invocation_id
FROM
    FINAL
WHERE
    token_contract != 'aurora'

'''
'''--- models/silver/prices/_legacy/silver__prices_oracle_s3.yml ---
version: 2

models:
  - name: silver__prices_oracle_s3
    description: |-
      This table parses messages from the contract `priceoracle.near` and extracts the available price data.

    columns:
      - name: BLOCK_ID
        description: "{{ doc('block_id')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - NUMBER
                - FLOAT

      - name: BLOCK_TIMESTAMP
        description: "{{ doc('block_timestamp')}}"
        tests:
          - not_null:
              where: _inserted_timestamp <= current_timestamp - interval '1 hour'

      - name: TX_HASH
        description: "{{ doc('tx_hash')}}"
        tests:
          - not_null:
              where: _inserted_timestamp <= current_timestamp - interval '1 hour'
              
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - STRING
                - VARCHAR

      - name: INDEX
        description: "{{ doc('index')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - NUMBER

      - name: TOKEN
        description: "{{ doc('token')}}"

      - name: SYMBOL
        description: "{{ doc('symbol')}}"

      - name: TOKEN_CONTRACT
        description: "{{ doc('token_contract')}}"

      - name: RAW_PRICE
        description: "{{ doc('raw_price')}}"

      - name: DECIMALS
        description: "{{ doc('decimals')}}"

      - name: PRICE_USD
        description: "{{ doc('price_usd')}}"

      - name: SOURCE
        description: "{{ doc('source')}}"

      - name: _PARTITION_BY_BLOCK_NUMBER
        description: "{{ doc('_partition_by_block_number')}}"

      - name: _INSERTED_TIMESTAMP
        description: "{{ doc('_inserted_timestamp')}}"

      - name: _MODIFIED_TIMESTAMP
        description: "{{ doc('_modified_timestamp')}}"

      - name: PRICES_ORACLE_ID
        description: "{{doc('id')}}"

      - name: INSERTED_TIMESTAMP
        description: "{{doc('inserted_timestamp')}}"

      - name: MODIFIED_TIMESTAMP
        description: "{{doc('modified_timestamp')}}"

      - name: _INVOCATION_ID
        description: "{{doc('invocation_id')}}"

'''
'''--- models/silver/prices/silver__complete_native_asset_metadata.sql ---
{{ config(
    materialized = 'incremental',
    incremental_strategy = 'delete+insert',
    unique_key = 'complete_native_asset_metadata_id',
    tags = ['scheduled_non_core']
) }}

SELECT
    asset_id,
    symbol,
    NAME,
    decimals,
    blockchain,
    is_deprecated,
    provider,
    source,
    _inserted_timestamp,
    inserted_timestamp,
    modified_timestamp,
    complete_native_asset_metadata_id,
    _invocation_id
FROM
    {{ ref(
        'bronze__complete_native_asset_metadata'
    ) }}

{% if is_incremental() %}
WHERE
    modified_timestamp >= (
        SELECT
            MAX(
                modified_timestamp
            )
        FROM
            {{ this }}
    )
{% endif %}

'''
'''--- models/silver/prices/silver__complete_native_asset_metadata.yml ---
version: 2
models:
  - name: silver__complete_native_asset_metadata
    tests:
      - dbt_utils.unique_combination_of_columns:
          combination_of_columns:
            - SYMBOL
          
    columns:
      - name: PROVIDER
        tests:
          - not_null
      - name: SYMBOL
        tests:
          - not_null
      - name: BLOCKCHAIN
        tests:
          - not_null
      - name: MODIFIED_TIMESTAMP
        tests:
          - not_null
      - name: COMPLETE_NATIVE_ASSET_METADATA_ID
        tests:
          - unique
'''
'''--- models/silver/prices/silver__complete_native_prices.sql ---
{{ config(
    materialized = 'incremental',
    incremental_strategy = 'delete+insert',
    unique_key = 'complete_native_prices_id',
    tags = ['scheduled_non_core']
) }}

SELECT
    HOUR,
    asset_id,
    symbol,
    NAME,
    decimals,
    price,
    blockchain,
    is_imputed,
    is_deprecated,
    provider,
    source,
    _inserted_timestamp,
    inserted_timestamp,
    modified_timestamp,
    complete_native_prices_id,
    _invocation_id
FROM
    {{ ref(
        'bronze__complete_native_prices'
    ) }}

{% if is_incremental() %}
WHERE
    modified_timestamp >= (
        SELECT
            MAX(
                modified_timestamp
            )
        FROM
            {{ this }}
    )
{% endif %}

'''
'''--- models/silver/prices/silver__complete_native_prices.yml ---
version: 2
models:
  - name: silver__complete_native_prices
    tests:
      - dbt_utils.unique_combination_of_columns:
          combination_of_columns:
            - HOUR
            - SYMBOL

    columns:
      - name: HOUR
        tests:
          - not_null
      - name: SYMBOL
        tests:
          - not_null
      - name: BLOCKCHAIN
        tests:
          - not_null
      - name: PROVIDER
        tests:
          - not_null
      - name: PRICE
        tests: 
          - not_null
      - name: IS_IMPUTED
        tests: 
          - not_null
      - name: _INSERTED_TIMESTAMP
        tests:
          - not_null
      - name: MODIFIED_TIMESTAMP
        tests:
          - not_null
      - name: COMPLETE_NATIVE_PRICES_ID
        tests:
          - unique
'''
'''--- models/silver/prices/silver__complete_provider_asset_metadata.sql ---
{{ config(
    materialized = 'incremental',
    incremental_strategy = 'delete+insert',
    unique_key = 'complete_provider_asset_metadata_id',
    tags = ['scheduled_non_core']
) }}

SELECT
    asset_id,
    token_address,
    NAME,
    symbol,
    platform,
    platform_id,
    provider,
    source,
    _inserted_timestamp,
    inserted_timestamp,
    modified_timestamp,
    complete_provider_asset_metadata_id,
    _invocation_id
FROM
    {{ ref(
        'bronze__complete_provider_asset_metadata'
    ) }}

{% if is_incremental() %}
WHERE
    modified_timestamp >= (
        SELECT
            MAX(
                modified_timestamp
            )
        FROM
            {{ this }}
    )
{% endif %}
'''
'''--- models/silver/prices/silver__complete_provider_asset_metadata.yml ---
version: 2
models:
  - name: silver__complete_provider_asset_metadata
    tests:
      - dbt_utils.unique_combination_of_columns:
          combination_of_columns:
            - ASSET_ID
            - TOKEN_ADDRESS
            - NAME
            - SYMBOL
            - PLATFORM
            - PLATFORM_ID
            - PROVIDER
    columns:
      - name: PROVIDER
        tests:
          - not_null
      - name: ASSET_ID
        tests:
          - not_null
      - name: MODIFIED_TIMESTAMP
        tests:
          - not_null
      - name: COMPLETE_PROVIDER_ASSET_METADATA_ID
        tests:
          - unique
'''
'''--- models/silver/prices/silver__complete_provider_prices.sql ---
{{ config(
    materialized = 'incremental',
    incremental_strategy = 'delete+insert',
    unique_key = 'complete_provider_prices_id',
    tags = ['scheduled_non_core']
) }}

SELECT
    p.asset_id,
    recorded_hour,
    OPEN,
    high,
    low,
    CLOSE,
    p.provider,
    p.source,
    p._inserted_timestamp,
    p.inserted_timestamp,
    p.modified_timestamp,
    p.complete_provider_prices_id,
    p._invocation_id
FROM
    {{ ref(
        'bronze__complete_provider_prices'
    ) }}
    p
    INNER JOIN {{ ref('bronze__complete_provider_asset_metadata') }}
    m
    ON p.asset_id = m.asset_id

{% if is_incremental() %}
WHERE
    p.modified_timestamp >= (
        SELECT
            MAX(
                modified_timestamp
            )
        FROM
            {{ this }}
    )
{% endif %}

qualify(ROW_NUMBER() over (PARTITION BY p.asset_id, recorded_hour, p.provider
ORDER BY
    p.modified_timestamp DESC)) = 1

'''
'''--- models/silver/prices/silver__complete_provider_prices.yml ---
version: 2
models:
  - name: silver__complete_provider_prices
    tests:
      - dbt_utils.unique_combination_of_columns:
          combination_of_columns:
            - ASSET_ID
            - RECORDED_HOUR
            - PROVIDER
    columns:
      - name: PROVIDER
        tests:
          - not_null
      - name: ASSET_ID
        tests:
          - not_null
      - name: RECORDED_HOUR
        tests:
          - not_null
      - name: MODIFIED_TIMESTAMP
        tests:
          - not_null
      - name: COMPLETE_PROVIDER_PRICES_ID
        tests:
          - unique
'''
'''--- models/silver/prices/silver__complete_token_asset_metadata.sql ---
{{ config(
    materialized = 'incremental',
    incremental_strategy = 'delete+insert',
    unique_key = 'complete_token_asset_metadata_id',
    tags = ['scheduled_non_core']
) }}

SELECT
    LOWER(
        A.token_address
    ) AS token_address,
    asset_id,
    symbol,
    NAME,
    decimals,
    blockchain,
    blockchain_name,
    blockchain_id,
    is_deprecated,
    provider,
    source,
    _inserted_timestamp,
    inserted_timestamp,
    modified_timestamp,
    complete_token_asset_metadata_id,
    _invocation_id
FROM
    {{ ref(
        'bronze__complete_token_asset_metadata'
    ) }} A

{% if is_incremental() %}
WHERE
    modified_timestamp >= (
        SELECT
            MAX(
                modified_timestamp
            )
        FROM
            {{ this }}
    )
{% endif %}

'''
'''--- models/silver/prices/silver__complete_token_asset_metadata.yml ---
version: 2
models:
  - name: silver__complete_token_asset_metadata
    tests:
      - dbt_utils.unique_combination_of_columns:
          combination_of_columns:
            - TOKEN_ADDRESS
            - BLOCKCHAIN
          
    columns:
      - name: PROVIDER
        tests:
          - not_null
      - name: TOKEN_ADDRESS
        tests:
          - not_null
      - name: BLOCKCHAIN
        tests:
          - not_null
      - name: BLOCKCHAIN_ID
        tests:
          - not_null
      - name: MODIFIED_TIMESTAMP
        tests:
          - not_null
      - name: COMPLETE_TOKEN_ASSET_METADATA_ID
        tests:
          - unique
'''
'''--- models/silver/prices/silver__complete_token_prices.sql ---
{{ config(
    materialized = 'incremental',
    incremental_strategy = 'delete+insert',
    unique_key = 'complete_token_prices_id',
    tags = ['scheduled_non_core']
) }}

SELECT
    HOUR,
    LOWER(
        p.token_address
    ) AS token_address,
    asset_id,
    symbol,
    NAME,
    decimals,
    price,
    blockchain,
    blockchain_name,
    blockchain_id,
    is_imputed,
    is_deprecated,
    provider,
    source,
    _inserted_timestamp,
    inserted_timestamp,
    modified_timestamp,
    complete_token_prices_id,
    _invocation_id
FROM
    {{ ref(
        'bronze__complete_token_prices'
    ) }}
    p

{% if is_incremental() %}
WHERE
    modified_timestamp >= (
        SELECT
            MAX(
                modified_timestamp
            )
        FROM
            {{ this }}
    )
{% endif %}

'''
'''--- models/silver/prices/silver__complete_token_prices.yml ---
version: 2
models:
  - name: silver__complete_token_prices
    tests:
      - dbt_utils.unique_combination_of_columns:
          combination_of_columns:
            - HOUR
            - TOKEN_ADDRESS
            - BLOCKCHAIN

    columns:
      - name: HOUR
        tests:
          - not_null
      - name: TOKEN_ADDRESS
        tests:
          - not_null
      - name: BLOCKCHAIN
        tests:
          - not_null
      - name: BLOCKCHAIN_ID
        tests:
          - not_null
      - name: PROVIDER
        tests:
          - not_null
      - name: PRICE
        tests: 
          - not_null
      - name: IS_IMPUTED
        tests: 
          - not_null
      - name: _INSERTED_TIMESTAMP
        tests:
          - not_null
      - name: MODIFIED_TIMESTAMP
        tests:
          - not_null
      - name: COMPLETE_TOKEN_PRICES_ID
        tests:
          - unique
'''
'''--- models/silver/social/silver_social__addkey.sql ---
{{ config(
    materialized = 'incremental',
    merge_exclude_columns = ["inserted_timestamp"],
    unique_key = 'action_id',
    cluster_by = ['block_timestamp::date'],
    tags = ['curated', 'social']
) }}
{# Note - multisource model #}
WITH receipts AS (

    SELECT
        receipt_object_id,
        signer_id,
        _partition_by_block_number,
        _inserted_timestamp,
        modified_timestamp AS _modified_timestamp
    FROM
        {{ ref('silver__streamline_receipts_final') }}
    WHERE
        _partition_by_block_number >= 59670000

    {% if var("MANUAL_FIX") %}
      AND {{ partition_load_manual('no_buffer') }}
    {% else %}
            {% if is_incremental() %}
        AND _modified_timestamp >= (
            SELECT
                MAX(_modified_timestamp)
            FROM
                {{ this }}
        )
    {% endif %}
    {% endif %}
),
from_addkey_event AS (
    SELECT
        action_id,
        tx_hash,
        block_id,
        block_timestamp,
        allowance,
        method_name,
        receiver_id,
        'AddKey' AS _source,
        _partition_by_block_number,
        _inserted_timestamp,
        modified_timestamp AS _modified_timestamp
    FROM
        {{ ref('silver__actions_events_addkey_s3') }}
    WHERE
        receiver_id = 'social.near'
    {% if var("MANUAL_FIX") %}
      AND {{ partition_load_manual('no_buffer') }}
    {% else %}
            {% if is_incremental() %}
        AND _modified_timestamp >= (
            SELECT
                MAX(_modified_timestamp)
            FROM
                {{ this }}
        )
    {% endif %}
    {% endif %}
),
nested_in_functioncall AS (
    SELECT
        action_id,
        tx_hash,
        block_id,
        block_timestamp,
        args :request :actions [0] :permission :allowance :: FLOAT AS allowance,
        args :request :actions [0] :permission :method_names :: ARRAY AS method_name,
        LOWER(
            args :request :actions [0] :permission :receiver_id :: STRING
        ) AS receiver_id,
        'FunctionCall' AS _source,
        _partition_by_block_number,
        _inserted_timestamp,
        modified_timestamp AS _modified_timestamp
    FROM
        {{ ref('silver__actions_events_function_call_s3') }}
    WHERE
        method_name = 'add_request_and_confirm'
        AND receiver_id = 'social.near'
    {% if var("MANUAL_FIX") %}
      AND {{ partition_load_manual('no_buffer') }}
    {% else %}
            {% if is_incremental() %}
        AND _modified_timestamp >= (
            SELECT
                MAX(_modified_timestamp)
            FROM
                {{ this }}
        )
    {% endif %}
    {% endif %}
),
combine AS (
    SELECT
        SPLIT(
            action_id,
            '-'
        ) [0] :: STRING AS receipt_id_from_action,
        action_id,
        tx_hash,
        block_id,
        block_timestamp,
        allowance,
        _source,
        _partition_by_block_number,
        _inserted_timestamp,
        _modified_timestamp
    FROM
        from_addkey_event
    UNION
    SELECT
        SPLIT(
            action_id,
            '-'
        ) [0] :: STRING AS receipt_id_from_action,
        action_id,
        tx_hash,
        block_id,
        block_timestamp,
        allowance,
        _source,
        _partition_by_block_number,
        _inserted_timestamp,
        _modified_timestamp
    FROM
        nested_in_functioncall
),
FINAL AS (
    SELECT
        A.receipt_id_from_action,
        A.action_id,
        A.tx_hash,
        A.block_id,
        A.block_timestamp,
        A.allowance,
        r.signer_id,
        A._source,
        A._partition_by_block_number,
        A._inserted_timestamp,
        A._modified_timestamp
    FROM
        combine A
        LEFT JOIN receipts r
        ON receipt_id_from_action = r.receipt_object_id
)
SELECT
    *,
    {{ dbt_utils.generate_surrogate_key(
        ['action_id']
    ) }} AS social_addkey_id,
    SYSDATE() AS inserted_timestamp,
    SYSDATE() AS modified_timestamp,
    '{{ invocation_id }}' AS _invocation_id
FROM
    FINAL

'''
'''--- models/silver/social/silver_social__addkey.yml ---

version: 2

models:
  - name: silver_social__addkey
    description: |-
      All AddKey events for the contract social.near, which indicate a wallet or user authorizing use of the contract as a high-level proxy for interest in the platform.

    columns:
      - name: receipt_id_from_action
        description: "{{ doc('receipt_object_id')}}"

      - name: action_id
        description: "{{ doc('block_id')}}"
        tests:
          - unique

      - name: tx_hash
        description: "{{ doc('tx_hash')}}"

      - name: block_id
        description: "{{ doc('block_id')}}"

      - name: block_timestamp
        description: "{{ doc('block_timestamp')}}"

      - name: allowance
        description: "{{ doc('allowance')}}"

      - name: signer_id
        description: "{{ doc('signer_id')}}"
        tests:
          - not_null

      - name: _source
        description: "{{ doc('_source')}}"

      - name: _partition_by_block_number
        description: "{{ doc('_partition_by_block_number')}}"

      - name: _INSERTED_TIMESTAMP
        description: "{{ doc('_inserted_timestamp')}}"

      - name: _MODIFIED_TIMESTAMP
        description: "{{ doc('_modified_timestamp')}}"

      - name: SOCIAL_ADDKEY_ID
        description: "{{doc('id')}}"

      - name: INSERTED_TIMESTAMP
        description: "{{doc('inserted_timestamp')}}"

      - name: MODIFIED_TIMESTAMP
        description: "{{doc('modified_timestamp')}}"

      - name: _INVOCATION_ID
        description: "{{doc('invocation_id')}}"

'''
'''--- models/silver/social/silver_social__decoded_actions.sql ---
{{ config(
    materialized = 'incremental',
    merge_exclude_columns = ["inserted_timestamp"],
    unique_key = 'action_id_social',
    cluster_by = ['_inserted_timestamp::date', '_partition_by_block_number'],
    tags = ['curated', 'social']
) }}
{# Note - multisource model #}
WITH all_social_receipts AS (

    SELECT
        receipt_object_id,
        receiver_id,
        predecessor_id,
        signer_id,
        execution_outcome,
        _partition_by_block_number,
        _inserted_timestamp,
        modified_timestamp AS _modified_timestamp
    FROM
        {{ ref('silver_social__receipts') }}
    WHERE
        {# NOTE - 5 "maintenance" receipts prior to 75mm that create/add/revoke keys, etc. Largely irrelevant to the platform. #}
         _partition_by_block_number >= 75000000

    {% if var("MANUAL_FIX") %}
      AND {{ partition_load_manual('no_buffer') }}
    {% else %}
            {% if is_incremental() %}
        AND _modified_timestamp >= (
            SELECT
                MAX(_modified_timestamp)
            FROM
                {{ this }}
        )
    {% endif %}
    {% endif %}
),
decoded_function_calls AS (
    SELECT
        SPLIT(
            action_id,
            '-'
        ) [0] :: STRING AS receipt_object_id,
        action_id,
        tx_hash,
        block_id,
        block_timestamp,
        method_name,
        args,
        deposit,
        attached_gas,
        _partition_by_block_number,
        _inserted_timestamp,
        modified_timestamp AS _modified_timestamp
    FROM
        {{ ref('silver__actions_events_function_call_s3') }}
    WHERE
        _partition_by_block_number >= 75000000
        AND SPLIT(
            action_id,
            '-'
        ) [0] :: STRING IN (
            SELECT
                DISTINCT receipt_object_id
            FROM
                all_social_receipts
        )
    {% if var("MANUAL_FIX") %}
      AND {{ partition_load_manual('no_buffer') }}
    {% else %}
            {% if is_incremental() %}
        AND _modified_timestamp >= (
            SELECT
                MAX(_modified_timestamp)
            FROM
                {{ this }}
        )
    {% endif %}
    {% endif %}
),
join_wallet_ids AS (
    SELECT
        fc.action_id,
        fc.tx_hash,
        fc.block_id,
        fc.block_timestamp,
        fc.method_name,
        fc.args,
        fc.deposit,
        fc.attached_gas,
        r.receiver_id,
        r.predecessor_id,
        r.signer_id,
        r.execution_outcome,
        fc._partition_by_block_number,
        fc._inserted_timestamp,
        fc._modified_timestamp
    FROM
        decoded_function_calls fc
        LEFT JOIN all_social_receipts r USING (receipt_object_id)
    WHERE
        method_name = 'set'
),
action_data AS (
    SELECT
        action_id,
        tx_hash,
        block_id,
        block_timestamp,
        COALESCE(
            args :data [predecessor_id],
            args :data [signer_id],
            args :data :accountId
        ) AS set_action_data,
        attached_gas,
        receiver_id,
        predecessor_id,
        signer_id,
        _partition_by_block_number,
        _inserted_timestamp,
        _modified_timestamp
    FROM
        join_wallet_ids
),
flattened_actions AS (
    SELECT
        concat_ws(
            '-',
            action_id,
            key
        ) AS action_id_social,
        tx_hash,
        block_id,
        block_timestamp,
        signer_id,
        predecessor_id,
        key AS node,
        VALUE AS node_data,
        _partition_by_block_number,
        _inserted_timestamp,
        _modified_timestamp
    FROM
        action_data,
        LATERAL FLATTEN (
            input => set_action_data
        )
)
SELECT
    *,
    {{ dbt_utils.generate_surrogate_key(
        ['action_id_social']
    ) }} AS social_decoded_actions_id,
    SYSDATE() AS inserted_timestamp,
    SYSDATE() AS modified_timestamp,
    '{{ invocation_id }}' AS _invocation_id
FROM
    flattened_actions

'''
'''--- models/silver/social/silver_social__decoded_actions.yml ---

version: 2

models:
  - name: silver_social__decoded_actions
    description: |-
      Decoded FunctionCall events for receipts where the contract social.near was called.

    columns:
      - name: action_id_social
        description: "{{ doc('action_id')}}"
        tests:
          - unique

      - name: tx_hash
        description: "{{ doc('tx_hash')}}"

      - name: block_id
        description: "{{ doc('block_id')}}"

      - name: block_timestamp
        description: "{{ doc('block_timestamp')}}"

      - name: PREDECESSOR_ID
        description: "{{ doc('predecessor_id')}}"

      - name: signer_id
        description: "{{ doc('signer_id')}}"
        tests: 
          - not_null

      - name: node
        description: "{{ doc('node')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - varchar

      - name: node_data
        description: "{{ doc('node_data')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - object
                - variant

      - name: _partition_by_block_number
        description: "{{ doc('_partition_by_block_number')}}"

      - name: _INSERTED_TIMESTAMP
        description: "{{ doc('_inserted_timestamp')}}"

      - name: _MODIFIED_TIMESTAMP
        description: "{{ doc('_modified_timestamp')}}"

      - name: SOCIAL_DECODED_ACTIONS_ID
        description: "{{doc('id')}}"

      - name: INSERTED_TIMESTAMP
        description: "{{doc('inserted_timestamp')}}"

      - name: MODIFIED_TIMESTAMP
        description: "{{doc('modified_timestamp')}}"

      - name: _INVOCATION_ID
        description: "{{doc('invocation_id')}}"

'''
'''--- models/silver/social/silver_social__posts.sql ---
{{ config(
    materialized = 'incremental',
    merge_exclude_columns = ["inserted_timestamp"],
    unique_key = 'action_id_social',
    cluster_by = ['_inserted_timestamp::date', '_partition_by_block_number'],
    tags = ['curated', 'social']
) }}

WITH decoded_actions AS (

    SELECT
        tx_hash,
        action_id_social,
        block_id,
        block_timestamp,
        signer_id,
        node_data,
        _partition_by_block_number,
        _inserted_timestamp,
        modified_timestamp AS _modified_timestamp
    FROM
        {{ ref('silver_social__decoded_actions') }}
    WHERE
        node = 'post'

    {% if var("MANUAL_FIX") %}
      AND {{ partition_load_manual('no_buffer') }}
    {% else %}
            {% if is_incremental() %}
        AND _modified_timestamp >= (
            SELECT
                MAX(_modified_timestamp)
            FROM
                {{ this }}
        )
    {% endif %}
    {% endif %}
),
posts AS (
    SELECT
        tx_hash,
        action_id_social,
        block_id,
        block_timestamp,
        signer_id,
        TRY_PARSE_JSON(
            node_data :main
        ) AS parsed_node_data,
        parsed_node_data :type :: STRING AS post_type,
        parsed_node_data :text :: STRING AS post_text,
        parsed_node_data :image :: STRING AS post_image,
        _partition_by_block_number,
        _inserted_timestamp,
        _modified_timestamp
    FROM
        decoded_actions
    WHERE
        TRY_PARSE_JSON(
            node_data :main
        ) IS NOT NULL
)
SELECT
    tx_hash,
    action_id_social,
    block_id,
    block_timestamp,
    signer_id,
    post_type,
    post_text,
    post_image,
    _partition_by_block_number,
    _inserted_timestamp,
    _modified_timestamp,
    {{ dbt_utils.generate_surrogate_key(
        ['action_id_social']
    ) }} AS social_posts_id,
    SYSDATE() AS inserted_timestamp,
    SYSDATE() AS modified_timestamp,
    '{{ invocation_id }}' AS _invocation_id
FROM
    posts

'''
'''--- models/silver/social/silver_social__posts.yml ---

version: 2

models:
  - name: silver_social__posts
    description: |-
      Cleaned and curated post data on Near Social.

    columns:
      - name: action_id_social
        description: "{{ doc('block_id')}}"
        tests:
          - unique

      - name: tx_hash
        description: "{{ doc('tx_hash')}}"
        tests:
          - not_null

      - name: block_id
        description: "{{ doc('block_id')}}"

      - name: block_timestamp
        description: "{{ doc('block_timestamp')}}"
        tests:
          - not_null

      - name: signer_id
        description: "{{ doc('signer_id')}}"

      - name: post_type
        description: "{{ doc('profile_section')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - varchar

      - name: post_text
        description: "{{ doc('profile_data')}}"
        tests:
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - varchar

      - name: post_image
        description: "{{ doc('profile_data')}}"
        tests:
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - varchar

      - name: _partition_by_block_number
        description: "{{ doc('_partition_by_block_number')}}"

      - name: _INSERTED_TIMESTAMP
        description: "{{ doc('_inserted_timestamp')}}"

      - name: _MODIFIED_TIMESTAMP
        description: "{{ doc('_modified_timestamp')}}"

      - name: SOCIAL_POSTS_ID
        description: "{{doc('id')}}"

      - name: INSERTED_TIMESTAMP
        description: "{{doc('inserted_timestamp')}}"

      - name: MODIFIED_TIMESTAMP
        description: "{{doc('modified_timestamp')}}"

      - name: _INVOCATION_ID
        description: "{{doc('invocation_id')}}"

'''
'''--- models/silver/social/silver_social__profile_changes.sql ---
{{ config(
    materialized = 'incremental',
    merge_exclude_columns = ["inserted_timestamp"],
    unique_key = 'action_id_profile',
    cluster_by = ['block_timestamp::date', 'signer_id'],
    tags = ['curated', 'social']
) }}

WITH decoded_actions AS (

    SELECT
        action_id_social,
        tx_hash,
        block_id,
        block_timestamp,
        signer_id,
        node_data,
        _partition_by_block_number,
        _inserted_timestamp,
        modified_timestamp AS _modified_timestamp
    FROM
        {{ ref('silver_social__decoded_actions') }}
    WHERE
        node = 'profile'

    {% if var("MANUAL_FIX") %}
      AND {{ partition_load_manual('no_buffer') }}
    {% else %}
            {% if is_incremental() %}
        AND _modified_timestamp >= (
            SELECT
                MAX(_modified_timestamp)
            FROM
                {{ this }}
        )
    {% endif %}
    {% endif %}
),
flatten_profile_json AS (
    SELECT
        concat_ws(
            '-',
            action_id_social,
            key
        ) AS action_id_profile,
        action_id_social,
        tx_hash,
        block_id,
        block_timestamp,
        signer_id,
        key AS profile_section,
        VALUE :: STRING AS profile_data,
        -- must store as string due to various possible inputs
        _partition_by_block_number,
        _inserted_timestamp,
        _modified_timestamp
    FROM
        decoded_actions,
        LATERAL FLATTEN(node_data)
)
SELECT
    action_id_social,
    action_id_profile,
    tx_hash,
    block_id,
    block_timestamp,
    signer_id,
    profile_section,
    profile_data,
    _partition_by_block_number,
    _inserted_timestamp,
    _modified_timestamp,
    {{ dbt_utils.generate_surrogate_key(
        ['action_id_profile']
    ) }} AS social_profile_changes_id,
    SYSDATE() AS inserted_timestamp,
    SYSDATE() AS modified_timestamp,
    '{{ invocation_id }}' AS _invocation_id
FROM
    flatten_profile_json

'''
'''--- models/silver/social/silver_social__profile_changes.yml ---

version: 2

models:
  - name: silver_social__profile_changes
    description: |-
      Events from the node `profile` that indicate a change to a user's profile.

    columns:
      - name: action_id_profile
        description: "{{ doc('action_id_profile')}}"
        tests:
          - unique

      - name: action_id_social
        description: "{{ doc('action_id_social')}}"

      - name: tx_hash
        description: "{{ doc('tx_hash')}}"

      - name: block_id
        description: "{{ doc('block_id')}}"

      - name: block_timestamp
        description: "{{ doc('block_timestamp')}}"

      - name: signer_id
        description: "{{ doc('signer_id')}}"

      - name: profile_section
        description: "{{ doc('profile_section')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - varchar

      - name: profile_data
        description: "{{ doc('profile_data')}}"
        tests:
          - not_null:
              where: profile_section not in ('horizon_tnc', 'team')
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - varchar

      - name: _partition_by_block_number
        description: "{{ doc('_partition_by_block_number')}}"

      - name: _INSERTED_TIMESTAMP
        description: "{{ doc('_inserted_timestamp')}}"

      - name: _MODIFIED_TIMESTAMP
        description: "{{ doc('_modified_timestamp')}}"

      - name: SOCIAL_PROFILE_CHANGES_ID
        description: "{{doc('id')}}"

      - name: INSERTED_TIMESTAMP
        description: "{{doc('inserted_timestamp')}}"

      - name: MODIFIED_TIMESTAMP
        description: "{{doc('modified_timestamp')}}"

      - name: _INVOCATION_ID
        description: "{{doc('invocation_id')}}"

'''
'''--- models/silver/social/silver_social__receipts.sql ---
{{ config(
    materialized = 'incremental',
    merge_exclude_columns = ["inserted_timestamp"],
    unique_key = 'receipt_object_id',
    cluster_by = ['_inserted_timestamp::date', '_partition_by_block_number'],
    tags = ['curated', 'social']
) }}

WITH all_social_receipts AS (

    SELECT
        tx_hash,
        receipt_object_id,
        block_id,
        block_timestamp,
        receipt_index,
        chunk_hash,
        receipt_actions,
        execution_outcome,
        receipt_outcome_id,
        receiver_id,
        receipt_actions :predecessor_id :: STRING AS predecessor_id,
        signer_id,
        receipt_type,
        gas_burnt,
        status_value,
        logs,
        proof,
        metadata,
        _partition_by_block_number,
        _inserted_timestamp,
        modified_timestamp AS _modified_timestamp
    FROM
        {{ ref('silver__streamline_receipts_final') }}
    WHERE
        (
            LOWER(signer_id) = 'social.near'
            OR LOWER(receiver_id) = 'social.near'
        )

    {% if var("MANUAL_FIX") %}
      AND {{ partition_load_manual('no_buffer') }}
    {% else %}
        {% if is_incremental() %}
        AND _modified_timestamp >= (
            SELECT
                MAX(_modified_timestamp)
            FROM
                {{ this }}
        )
    {% endif %}
    {% endif %}
)
    SELECT
        *,
        {{ dbt_utils.generate_surrogate_key(
            ['receipt_object_id']
        ) }} AS social_receipts_id,
        SYSDATE() AS inserted_timestamp,
        SYSDATE() AS modified_timestamp,
        '{{ invocation_id }}' AS _invocation_id
    FROM
        all_social_receipts

'''
'''--- models/silver/social/silver_social__receipts.yml ---

version: 2

models:
  - name: silver_social__receipts
    description: |-
      Filtered receipts where the signer or receiver is the contract social.near.

    columns:
      - name: tx_hash
        description: "{{ doc('tx_hash')}}"

      - name: block_id
        description: "{{ doc('block_id')}}"

      - name: receipt_index
        description: "{{ doc('receipt_index')}}"

      - name: chunk_hash
        description: "{{ doc('chunk_hash')}}"

      - name: receipt_actions
        description: "{{ doc('receipt')}}"

      - name: execution_outcome
        description: "{{ doc('execution_outcome')}}"

      - name: receipt_object_id
        description: "{{ doc('receipt_object_id')}}"
        tests: 
          - unique

      - name: receipt_outcome_id
        description: "{{ doc('receipt_outcome_id')}}"

      - name: receiver_id
        description: "{{ doc('receiver_id')}}"

      - name: PREDECESSOR_ID
        description: "{{ doc('predecessor_id')}}"

      - name: signer_id
        description: "{{ doc('signer_id')}}"

      - name: receipt_type
        description: "{{ doc('receipt_type')}}"

      - name: gas_burnt
        description: "{{ doc('gas_burnt')}}"

      - name: status_value
        description: "{{ doc('status_value')}}"

      - name: logs
        description: "{{ doc('logs')}}"

      - name: proof
        description: "{{ doc('proof')}}"

      - name: metadata
        description: "{{ doc('metadata')}}"

      - name: _partition_by_block_number
        description: "{{ doc('_partition_by_block_number')}}"

      - name: _INSERTED_TIMESTAMP
        description: "{{ doc('_inserted_timestamp')}}"

      - name: _MODIFIED_TIMESTAMP
        description: "{{ doc('_modified_timestamp')}}"

      - name: SOCIAL_RECEIPTS_ID
        description: "{{doc('id')}}"

      - name: INSERTED_TIMESTAMP
        description: "{{doc('inserted_timestamp')}}"

      - name: MODIFIED_TIMESTAMP
        description: "{{doc('modified_timestamp')}}"

      - name: _INVOCATION_ID
        description: "{{doc('invocation_id')}}"

'''
'''--- models/silver/social/silver_social__widgets.sql ---
{{ config(
    materialized = 'incremental',
    merge_exclude_columns = ["inserted_timestamp"],
    unique_key = 'social_widgets_id',
    cluster_by = ['_inserted_timestamp::date', '_partition_by_block_number'],
    tags = ['curated', 'social']
) }}

WITH decoded_actions AS (

    SELECT
        tx_hash,
        action_id_social,
        block_id,
        block_timestamp,
        predecessor_id,
        signer_id,
        node_data,
        _partition_by_block_number,
        _inserted_timestamp,
        modified_timestamp AS _modified_timestamp
    FROM
        {{ ref('silver_social__decoded_actions') }}
    WHERE
        node = 'widget'
    
    {% if var("MANUAL_FIX") %}
      AND {{ partition_load_manual('no_buffer') }}
    {% else %}
        {% if is_incremental() %}
        AND _modified_timestamp >= (
            SELECT
                MAX(_modified_timestamp)
            FROM
                {{ this }}
        )
    {% endif %}
    {% endif %}
),
widgets AS (
    SELECT
        tx_hash,
        action_id_social,
        block_id,
        block_timestamp,
        predecessor_id,
        signer_id,
        node_data,
        KEY :: STRING AS widget_name,
        TRY_PARSE_JSON(
            value
        ) AS source_data,
        CONCAT(
            'https://near.social/#/',
            signer_id,
            '/widget/',
            widget_name
        ) AS widget_url,
        _partition_by_block_number,
        _inserted_timestamp,
        _modified_timestamp
    FROM
        decoded_actions,
    LATERAL FLATTEN(
    input => node_data
    )
)
SELECT
    tx_hash,
    action_id_social,
    block_id,
    block_timestamp,
    signer_id,
    widget_name,
    source_data :"" :: STRING AS source_code,
    TRY_PARSE_JSON(
        source_data :metadata
    ) AS metadata,
    TRY_PARSE_JSON(
        source_data :branch
    ) AS branch,
    TRY_PARSE_JSON(
        source_data :widgetModulesUsed
    ) AS widget_modules_used,
    widget_url,
    source_data AS _source_data,
    node_data AS _node_data,
    _partition_by_block_number,
    _inserted_timestamp,
    _modified_timestamp,
    {{ dbt_utils.generate_surrogate_key(
        ['action_id_social', 'widget_name']
    ) }} AS social_widgets_id,
    SYSDATE() AS inserted_timestamp,
    SYSDATE() AS modified_timestamp,
    '{{ invocation_id }}' AS _invocation_id
FROM
    widgets

'''
'''--- models/silver/social/silver_social__widgets.yml ---
version: 2

models:
  - name: silver_social__widgets
    description: |-
      Cleaned and curated widget data on Near Social.

    columns:
      - name: social_widgets_id
        description: "{{ doc('id')}}"

      - name: tx_hash
        description: "{{ doc('tx_hash')}}"
        tests:
          - not_null

      - name: block_id
        description: "{{ doc('block_id')}}"

      - name: block_timestamp
        description: "{{ doc('block_timestamp')}}"
        tests:
          - not_null

      - name: signer_id
        description: "{{ doc('signer_id')}}"

      - name: _node_data
        description: "{{ doc('node_data')}}"

      - name: widget_name
        description: "{{ doc('widget_name')}}"
        tests:
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - varchar

      - name: _source_data
        description: "{{ doc('_source_data')}}"
        tests:
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - variant
                - object

      - name: source_code
        description: "{{ doc('source_code')}}"
        tests:
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - varchar

      - name: metadata
        description: "{{ doc('metadata')}}"
        tests:
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - variant
                - object

      - name: branch
        description: "{{ doc('branch')}}"
        tests:
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - variant
                - object

      - name: widget_modules_used
        description: "{{ doc('widget_modules_used')}}"
        tests:
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - variant
                - object

      - name: widget_url
        description: "{{ doc('widget_url')}}"
        tests:
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - varchar

      - name: _partition_by_block_number
        description: "{{ doc('_partition_by_block_number')}}"

      - name: _INSERTED_TIMESTAMP
        description: "{{ doc('_inserted_timestamp')}}"

      - name: _MODIFIED_TIMESTAMP
        description: "{{ doc('_modified_timestamp')}}"

      - name: SOCIAL_WIDGETS_ID
        description: "{{doc('id')}}"
        tests:
          - unique

      - name: INSERTED_TIMESTAMP
        description: "{{doc('inserted_timestamp')}}"

      - name: MODIFIED_TIMESTAMP
        description: "{{doc('modified_timestamp')}}"

      - name: _INVOCATION_ID
        description: "{{doc('invocation_id')}}"

'''
'''--- models/silver/stats/silver_stats__core_metrics_block_hourly.sql ---
{{ config(
    materialized = 'incremental',
    incremental_strategy = 'delete+insert',
    unique_key = "block_timestamp_hour",
    cluster_by = ['block_timestamp_hour::DATE'],
    tags = ['curated']
) }}
/* run incremental timestamp value first then use it as a static value */
{% if execute %}

{% if is_incremental() %}
{% set query %}

SELECT
    MIN(DATE_TRUNC('hour', block_timestamp)) block_timestamp_hour
FROM
    {{ ref('silver__streamline_blocks') }}
WHERE
    _inserted_timestamp >= (
        SELECT
            MAX(_inserted_timestamp)
        FROM
            {{ this }}
    ) {% endset %}
    {% set min_block_timestamp_hour = run_query(query).columns [0].values() [0] %}
{% endif %}
{% endif %}
SELECT
    DATE_TRUNC(
        'hour',
        block_timestamp
    ) AS block_timestamp_hour,
    MIN(block_id) AS block_number_min,
    MAX(block_id) AS block_number_max,
    COUNT(
        1
    ) AS block_count,
    MAX(_inserted_timestamp) AS _inserted_timestamp,
    {{ dbt_utils.generate_surrogate_key(
        ['block_timestamp_hour']
    ) }} AS core_metrics_block_hourly_id,
    SYSDATE() AS inserted_timestamp,
    SYSDATE() AS modified_timestamp,
    '{{ invocation_id }}' AS _invocation_id
FROM
    {{ ref('silver__streamline_blocks') }}
WHERE
    block_timestamp_hour < DATE_TRUNC(
        'hour',
        CURRENT_TIMESTAMP
    )

{% if is_incremental() %}
AND DATE_TRUNC(
    'hour',
    block_timestamp
) >= '{{ min_block_timestamp_hour }}'
{% endif %}
GROUP BY
    1

'''
'''--- models/silver/stats/silver_stats__core_metrics_block_hourly.yml ---
version: 2
models:
  - name: silver_stats__core_metrics_block_hourly
    tests:
      - dbt_utils.unique_combination_of_columns:
          combination_of_columns:
            - BLOCK_TIMESTAMP_HOUR
    columns:
      - name: BLOCK_TIMESTAMP_HOUR
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - TIMESTAMP_LTZ
                - TIMESTAMP_NTZ
      - name: BLOCK_NUMBER_MIN
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - NUMBER
                - FLOAT
      - name: BLOCK_NUMBER_MAX
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - NUMBER
                - FLOAT
      - name: BLOCK_COUNT
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - NUMBER
                - FLOAT
      - name: _INSERTED_TIMESTAMP
        tests:
          - dbt_expectations.expect_row_values_to_have_recent_data:
              datepart: day
              interval: 1

'''
'''--- models/silver/stats/silver_stats__core_metrics_hourly.sql ---
{{ config(
    materialized = 'incremental',
    incremental_strategy = 'delete+insert',
    unique_key = "block_timestamp_hour",
    cluster_by = ['block_timestamp_hour::DATE'],
    tags = ['curated']
) }}
/* run incremental timestamp value first then use it as a static value */
{% if execute %}

{% if is_incremental() %}
{% set query %}

SELECT
    MIN(DATE_TRUNC('hour', block_timestamp)) block_timestamp_hour
FROM
    {{ ref('silver__streamline_transactions_final') }}
WHERE
    _inserted_timestamp >= (
        SELECT
            MAX(_inserted_timestamp)
        FROM
            {{ this }}
    ) {% endset %}
    {% set min_block_timestamp_hour = run_query(query).columns [0].values() [0] %}
{% endif %}
{% endif %}
SELECT
    DATE_TRUNC(
        'hour',
        block_timestamp
    ) AS block_timestamp_hour,
    COUNT(
        DISTINCT tx_hash
    ) AS transaction_count,
    COUNT(
        DISTINCT CASE
            WHEN tx_succeeded THEN tx_hash
        END
    ) AS transaction_count_success,
    COUNT(
        DISTINCT CASE
            WHEN NOT tx_succeeded THEN tx_hash
        END
    ) AS transaction_count_failed,
    COUNT(
        DISTINCT tx_signer
    ) AS unique_from_count,
    COUNT(
        DISTINCT tx_receiver
    ) AS unique_to_count,
    SUM(transaction_fee / pow(10, 24)) AS total_fees,
    MAX(_inserted_timestamp) AS _inserted_timestamp,
    {{ dbt_utils.generate_surrogate_key(
        ['block_timestamp_hour']
    ) }} AS core_metrics_hourly_id,
    SYSDATE() AS inserted_timestamp,
    SYSDATE() AS modified_timestamp,
    '{{ invocation_id }}' AS _invocation_id
FROM
    {{ ref('silver__streamline_transactions_final') }}
WHERE
    block_timestamp_hour < DATE_TRUNC(
        'hour',
        CURRENT_TIMESTAMP
    )

{% if is_incremental() %}
AND DATE_TRUNC(
    'hour',
    block_timestamp
) >= '{{ min_block_timestamp_hour }}'
{% endif %}
GROUP BY
    1

'''
'''--- models/silver/stats/silver_stats__core_metrics_hourly.yml ---
version: 2
models:
  - name: silver_stats__core_metrics_hourly
    tests:
      - dbt_utils.unique_combination_of_columns:
          combination_of_columns:
            - BLOCK_TIMESTAMP_HOUR
    columns:
      - name: BLOCK_TIMESTAMP_HOUR
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - TIMESTAMP_LTZ
                - TIMESTAMP_NTZ
      # - name: BLOCK_NUMBER_MIN
      #   tests:
      #     - not_null
      #     - dbt_expectations.expect_column_values_to_be_in_type_list:
      #         column_type_list:
      #           - NUMBER
      #           - FLOAT
      # - name: BLOCK_NUMBER_MAX
      #   tests:
      #     - not_null
      #     - dbt_expectations.expect_column_values_to_be_in_type_list:
      #         column_type_list:
      #           - NUMBER
      #           - FLOAT
      # - name: BLOCK_COUNT
      #   tests:
      #     - not_null
      #     - dbt_expectations.expect_column_values_to_be_in_type_list:
      #         column_type_list:
      #           - NUMBER
      #           - FLOAT
      - name: TRANSACTION_COUNT
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - NUMBER
                - FLOAT
      - name: TRANSACTION_COUNT_SUCCESS
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - NUMBER
                - FLOAT
      - name: TRANSACTION_COUNT_FAILED
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - NUMBER
                - FLOAT
      - name: UNIQUE_FROM_COUNT
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - NUMBER
                - FLOAT
      - name: UNIQUE_TO_COUNT
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - NUMBER
                - FLOAT
      - name: TOTAL_FEES
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - DECIMAL
                - FLOAT
                - NUMBER
      - name: _INSERTED_TIMESTAMP
        tests:
          - dbt_expectations.expect_row_values_to_have_recent_data:
              datepart: day
              interval: 1

'''
'''--- models/silver/streamline/helpers/_retry_range.sql ---
{{ config(
    materialized = 'ephemeral',
    tags = ['helper', 'receipt_map']
) }}

SELECT
    receipt_object_id,
    block_id,
    _partition_by_block_number,
    _inserted_timestamp
FROM
    {{ target.database }}.silver.streamline_receipts_final
WHERE
    _inserted_timestamp >= SYSDATE() - INTERVAL '3 days'
    AND (
        tx_hash IS NULL
        OR block_timestamp IS NULL
    )

'''
'''--- models/silver/streamline/helpers/silver__flatten_receipts.sql ---
{{ config(
    materialized = 'view',
    tags = ['helper', 'receipt_map']
) }}

WITH receipts AS (

    SELECT
        A.receipt_id PARENT,
        b.value :: STRING item,
        block_id,
        _partition_by_block_number,
        _inserted_timestamp
    FROM
        {{ ref('silver__streamline_receipts') }} A
        JOIN LATERAL FLATTEN(
            A.outcome_receipts,
            outer => TRUE
        ) b

    {% if var("MANUAL_FIX") %}
        WHERE
            {{ partition_load_manual('front') }}
    {% else %}
        WHERE
            {% if var('IS_MIGRATION') %}
                _inserted_timestamp >= (
                    SELECT 
                        MAX(_inserted_timestamp) - INTERVAL '{{ var('STREAMLINE_LOAD_LOOKBACK_HOURS') }} hours'
                    FROM 
                        {{ target.database }}.silver.streamline_receipts_final
                )
                OR
            {% endif %}
                _partition_by_block_number >= (
                    SELECT
                        MIN(_partition_by_block_number) - (3000 * {{ var('RECEIPT_MAP_LOOKBACK_HOURS') }})
                    FROM
                        (
                            SELECT MIN(_partition_by_block_number) AS _partition_by_block_number FROM {{ ref('_retry_range') }}
                            UNION ALL
                            SELECT MAX(_partition_by_block_number) AS _partition_by_block_number FROM {{ target.database }}.silver.streamline_receipts_final
                        )
                )
    {% endif %}
)
SELECT
    *
FROM
    receipts

'''
'''--- models/silver/streamline/helpers/silver__receipt_tx_hash_mapping.sql ---
{{ config(
    materalized = 'view',
    unique_key = 'receipt_id',
    tags = ['helper', 'receipt_map']
) }}

WITH 
recursive ancestrytree AS (

    SELECT
        item,
        PARENT
    FROM
        {{ ref('silver__flatten_receipts') }}
    WHERE
        PARENT IS NOT NULL
    UNION ALL
    SELECT
        items.item,
        t.parent
    FROM
        ancestrytree t
        JOIN {{ ref('silver__flatten_receipts') }}
        items
        ON t.item = items.parent
),
txs AS (
    SELECT
        tx_hash,
        outcome_receipts,
        _partition_by_block_number
    FROM
        {{ ref('silver__streamline_transactions') }}

        {% if var("MANUAL_FIX") %}
        WHERE
            {{ partition_load_manual('front') }}
        {% else %}
        WHERE
            {% if var('IS_MIGRATION') %}
                _inserted_timestamp >= (
                    SELECT 
                        MAX(_inserted_timestamp) - INTERVAL '{{ var('STREAMLINE_LOAD_LOOKBACK_HOURS') }} hours'
                    FROM 
                        {{ target.database }}.silver.streamline_receipts_final
                )
                OR
            {% endif %}
                _partition_by_block_number >= (
                    SELECT
                        MIN(_partition_by_block_number) - (3000 * {{ var('RECEIPT_MAP_LOOKBACK_HOURS') }})
                    FROM
                        (
                            SELECT MIN(_partition_by_block_number) AS _partition_by_block_number FROM {{ ref('_retry_range') }}
                            UNION ALL
                            SELECT MAX(_partition_by_block_number) AS _partition_by_block_number FROM {{ target.database }}.silver.streamline_receipts_final
                        )
                )
        {% endif %}
),
FINAL AS (
    SELECT
        tx_hash,
        A.item,
        FALSE is_primary_receipt
    FROM
        ancestrytree A
        JOIN txs b
        ON A.parent = b.outcome_receipts [0] :: STRING
    WHERE
        item IS NOT NULL
    UNION ALL
    SELECT
        A.tx_hash,
        outcome_receipts [0] :: STRING AS receipt_id,
        TRUE is_primary_receipt
    FROM
        txs A
)
SELECT
    tx_hash,
    item AS receipt_id,
    is_primary_receipt
FROM
    FINAL

'''
'''--- models/silver/streamline/silver__streamline_blocks.sql ---
{{ config(
    materialized = 'incremental',
    incremental_strategy = 'merge',
    merge_exclude_columns = ['inserted_timestamp'],
    cluster_by = ['_inserted_timestamp::DATE', '_partition_by_block_number'],
    unique_key = 'block_id',
    tags = ['load', 'load_blocks'],
    full_refresh = False
) }}

WITH external_blocks AS (

    SELECT
        metadata$filename AS _filename,
        VALUE,
        _partition_by_block_number
    FROM
        {{ source(
            "streamline",
            "blocks"
        ) }}
    WHERE
        _partition_by_block_number >= (
            SELECT
                MAX(_partition_by_block_number) - (3000 * {{ var('STREAMLINE_LOAD_LOOKBACK_HOURS') }})
            FROM
                {{ this }}
        )
),
meta AS (
    SELECT
        job_created_time AS _inserted_timestamp,
        file_name AS _filename
    FROM
        TABLE(
            information_schema.external_table_file_registration_history(
                start_time => DATEADD(
                    'hour', 
                    -{{ var('STREAMLINE_LOAD_LOOKBACK_HOURS') }},
                    SYSDATE()
                ),
                table_name => '{{ source( 'streamline', 'blocks' ) }}'
            )
        ) A
),
blocks AS (
    SELECT
        e.value :header :height :: NUMBER AS block_id,
        TO_TIMESTAMP_NTZ(
            e.value :header :timestamp :: STRING
        ) AS block_timestamp,
        e.value :header :hash :: STRING AS block_hash,
        e.value :header :prev_hash :: STRING AS prev_hash,
        e.value :author :: STRING AS block_author,
        e.value :header :gas_price :: NUMBER AS gas_price,
        e.value :header :total_supply :: NUMBER AS total_supply,
        e.value :header :validator_proposals :: ARRAY AS validator_proposals,
        e.value :header :validator_reward :: NUMBER AS validator_reward,
        e.value :header :latest_protocol_version :: NUMBER AS latest_protocol_version,
        e.value :header :epoch_id :: STRING AS epoch_id,
        e.value :header :next_epoch_id :: STRING AS next_epoch_id,
        NULL AS tx_count,
        -- tx_count is legacy field, deprecate from core view
        [] AS events,
        -- events does not exist, Figment created this
        e.value :chunks :: ARRAY AS chunks,
        e.value :header :: OBJECT AS header,
        e._partition_by_block_number,
        m._inserted_timestamp
    FROM
        external_blocks e
        LEFT JOIN meta m USING (
            _filename
        )
    {% if is_incremental() %}
        WHERE
            _inserted_timestamp >= (
                SELECT
                    MAX(_inserted_timestamp)
                FROM
                    {{ this }}
            )
    {% endif %}

)
SELECT
    *,
    {{ dbt_utils.generate_surrogate_key(
        ['block_id']
    ) }} AS streamline_blocks_id,
    SYSDATE() AS inserted_timestamp,
    SYSDATE() AS modified_timestamp,
    '{{ invocation_id }}' AS _invocation_id
FROM
    blocks 
    qualify ROW_NUMBER() over (
        PARTITION BY block_id
        ORDER BY
            _inserted_timestamp DESC
    ) = 1

'''
'''--- models/silver/streamline/silver__streamline_blocks.yml ---
version: 2

models:
  - name: silver__streamline_blocks
    description: |-
      Parses the blocks JSON files for NEAR.

    columns:
      - name: BLOCK_ID
        description: "{{ doc('block_id')}}"

      - name: BLOCK_TIMESTAMP
        description: "{{ doc('block_timestamp')}}"

      - name: BLOCK_HASH
        description: "{{ doc('block_hash')}}"

      - name: TX_COUNT
        description: "{{ doc('tx_count')}}"

      - name: BLOCK_AUTHOR
        description: "{{ doc('block_author')}}"

      - name: CHUNKS
        description: "{{ doc('chunks')}}"

      - name: EPOCH_ID
        description: "{{ doc('epoch_id')}}"

      - name: EVENTS
        description: "{{ doc('events')}}"

      - name: GAS_PRICE
        description: "{{ doc('gas_price')}}"

      - name: LATEST_PROTOCOL_VERSION
        description: "{{ doc('latest_protocol_version')}}"

      - name: NEXT_EPOCH_ID
        description: "{{ doc('next_epoch_id')}}"

      - name: PREV_HASH
        description: "{{ doc('prev_hash')}}"

      - name: TOTAL_SUPPLY
        description: "{{ doc('total_supply')}}"

      - name: VALIDATOR_PROPOSALS
        description: "{{ doc('validator_proposals')}}"

      - name: VALIDATOR_REWARD
        description: "{{ doc('validator_reward')}}"

      - name: HEADER
        description: "{{ doc('header')}}"

      - name: _partition_by_block_number
        description: "{{ doc('_partition_by_block_number')}}"

      - name: _MODIFIED_TIMESTAMP
        description: "{{ doc('_modified_timestamp')}}"

      - name: _INSERTED_TIMESTAMP
        description: "{{ doc('_inserted_timestamp')}}"

      - name: STREAMLINE_BLOCKS_ID
        description: "{{doc('id')}}"

      - name: INSERTED_TIMESTAMP
        description: "{{doc('inserted_timestamp')}}"

      - name: MODIFIED_TIMESTAMP
        description: "{{doc('modified_timestamp')}}"

      - name: _INVOCATION_ID
        description: "{{doc('invocation_id')}}"

'''
'''--- models/silver/streamline/silver__streamline_receipts.sql ---
{{ config(
    materialized = 'incremental',
    incremental_strategy = 'merge',
    merge_exclude_columns = ['inserted_timestamp'],
    unique_key = 'receipt_id',
    cluster_by = ['_inserted_timestamp::date', '_partition_by_block_number'],
    tags = ['load', 'load_shards']
) }}

WITH shards AS (

    SELECT
        block_id,
        shard_id,
        receipt_execution_outcomes,
        chunk :header :chunk_hash :: STRING AS chunk_hash,
        _partition_by_block_number,
        _inserted_timestamp,
        modified_timestamp AS _modified_timestamp
    FROM
        {{ ref('silver__streamline_shards') }}
    WHERE
        ARRAY_SIZE(receipt_execution_outcomes) > 0
    {% if var('MANUAL_FIX') %}
        AND
            {{ partition_load_manual('no_buffer') }}
    {% else %}
        {% if is_incremental() %}
            AND _modified_timestamp >= (
                SELECT
                    MAX(_modified_timestamp)
                FROM
                    {{ this }}
            )
        {% endif %}
    {% endif %}
),
flatten_receipts AS (

    SELECT
        concat_ws(
            '-',
            shard_id,
            INDEX
        ) AS receipt_execution_outcome_id,
        block_id,
        shard_id,
        chunk_hash,
        INDEX AS receipt_outcome_execution_index,
        VALUE :execution_outcome :: OBJECT AS execution_outcome,
        VALUE :receipt :: OBJECT AS receipt,
        VALUE :receipt :receipt_id :: STRING AS receipt_id,
        VALUE :execution_outcome :id :: STRING AS receipt_outcome_id,
        _partition_by_block_number,
        _inserted_timestamp,
        _modified_timestamp
    FROM
        shards,
        LATERAL FLATTEN(
            input => receipt_execution_outcomes
        )
),
FINAL AS (
    SELECT
        receipt :receipt_id :: STRING AS receipt_id,
        block_id,
        shard_id,
        receipt_outcome_execution_index AS receipt_index,
        chunk_hash,
        receipt,
        execution_outcome,
        execution_outcome :outcome :status :Failure IS NULL AS receipt_succeeded,
        TRY_PARSE_JSON(
            execution_outcome :outcome :status :Failure
        ) AS failure_message,
        object_keys(
            failure_message
        ) [0] :: STRING AS error_type_0,
        COALESCE(
            object_keys(
                TRY_PARSE_JSON(
                    failure_message [error_type_0] :kind
                )
            ) [0] :: STRING,
            failure_message [error_type_0] :kind :: STRING
        ) AS error_type_1,
        COALESCE(
            object_keys(
                TRY_PARSE_JSON(
                    failure_message [error_type_0] :kind [error_type_1]
                )
            ) [0] :: STRING,
            failure_message [error_type_0] :kind [error_type_1] :: STRING
        ) AS error_type_2,
        failure_message [error_type_0] :kind [error_type_1] [error_type_2] :: STRING AS error_message,
        execution_outcome :outcome :receipt_ids :: ARRAY AS outcome_receipts,
        receipt :receiver_id :: STRING AS receiver_id,
        receipt :receipt :Action :signer_id :: STRING AS signer_id,
        LOWER(
            object_keys(
                receipt :receipt
            ) [0] :: STRING
        ) AS receipt_type,
        _partition_by_block_number,
        _inserted_timestamp,
        _modified_timestamp
    FROM
        flatten_receipts
)
SELECT
    *,
    {{ dbt_utils.generate_surrogate_key(
        ['receipt_id']
    ) }} AS streamline_receipts_id,
    SYSDATE() AS inserted_timestamp,
    SYSDATE() AS modified_timestamp,
    '{{ invocation_id }}' AS _invocation_id
FROM
    FINAL

'''
'''--- models/silver/streamline/silver__streamline_receipts.yml ---
version: 2

models:
  - name: silver__streamline_receipts
    description: |-
      Singular receipt objects with the shard id and chunk hash from which it was included. 
      These receipts are only action receipts from the execution outcome of the shard.

    columns:
      - name: BLOCK_ID
        description: "{{ doc('block_id')}}"

      - name: SHARD_ID
        description: "{{ doc('shard_id')}}"

      - name: RECEIPT_INDEX
        description: "{{ doc('receipt_index')}}"

      - name: CHUNK_HASH
        description: "{{ doc('chunk_hash')}}"

      - name: RECEIPT
        description: "{{ doc('receipt')}}"

      - name: EXECUTION_OUTCOME
        description: "{{ doc('execution_outcome')}}"

      - name: RECEIPT_SUCCEEDED
        description: "{{ doc('receipt_succeeded')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - BOOLEAN

      - name: ERROR_TYPE_0
        description: "{{ doc('error_type_0')}}"
        tests:
          - not_null:
              where: NOT RECEIPT_SUCCEEDED 
            
      - name: ERROR_TYPE_1
        description: "{{ doc('error_type_1')}}"
        tests:
          - not_null:
              where: NOT RECEIPT_SUCCEEDED
            
      - name: ERROR_TYPE_2
        description: "{{ doc('error_type_2')}}"
        tests:
          - not_null:
              where: NOT RECEIPT_SUCCEEDED AND ERROR_TYPE_1 NOT IN ('DelegateActionExpired', 'DelegateActionInvalidSignature')
            
      - name: ERROR_MESSAGE
        description: "{{ doc('error_message')}}"

      - name: OUTCOME_RECEIPTS
        description: "{{ doc('receipt_outcome_id')}}"
        tests:
          - not_null

      - name: RECEIPT_ID
        description: "{{ doc('receipt_id')}}"
        tests:
          - not_null
          - unique

      - name: RECEIVER_ID
        description: "{{ doc('receiver_id')}}"
        tests:
          - not_null

      - name: SIGNER_ID
        description: "{{ doc('signer_id')}}"
        tests:
          - not_null

      - name: RECEIPT_TYPE
        description: "{{ doc('receipt_type')}}"
        tests:
          - not_null

      - name: _MODIFIED_TIMESTAMP
        description: "{{ doc('_modified_timestamp')}}"

      - name: _PARTITION_BY_BLOCK_NUMBER
        description: "{{ doc('_partition_by_block_number')}}"

      - name: _INSERTED_TIMESTAMP
        description: "{{ doc('_inserted_timestamp')}}"

      - name: STREAMLINE_RECEIPTS_ID
        description: "{{doc('id')}}"
        tests:
          - unique

      - name: INSERTED_TIMESTAMP
        description: "{{doc('inserted_timestamp')}}"

      - name: MODIFIED_TIMESTAMP
        description: "{{doc('modified_timestamp')}}"

      - name: _INVOCATION_ID
        description: "{{doc('invocation_id')}}"

'''
'''--- models/silver/streamline/silver__streamline_receipts_final.sql ---
{{ config(
    materialized = 'incremental',
    incremental_strategy = 'merge',
    merge_exclude_columns = ['inserted_timestamp'],
    unique_key = 'receipt_object_id',
    cluster_by = ['_inserted_timestamp::date', '_modified_timestamp::DATE', '_partition_by_block_number', 'block_timestamp::DATE'],
    tags = ['receipt_map'],
    full_refresh = False
) }}

WITH retry_range AS (

    SELECT
        *
    FROM
        {{ ref('_retry_range')}}

),
base_receipts AS (
    SELECT
        receipt_id,
        block_id,
        shard_id,
        receipt_index,
        chunk_hash,
        receipt,
        execution_outcome,
        outcome_receipts,
        receiver_id,
        signer_id,
        receipt_type,
        receipt_succeeded,
        error_type_0,
        error_type_1,
        error_type_2,
        error_message,
        _partition_by_block_number,
        _inserted_timestamp,
        modified_timestamp AS _modified_timestamp
    FROM
        {{ ref('silver__streamline_receipts') }} r

    {% if var('MANUAL_FIX') %}

        WHERE
            {{ partition_load_manual('no_buffer') }}
            
    {% else %}

        WHERE
            _partition_by_block_number >= (
                SELECT
                    MIN(_partition_by_block_number) - (3000 * {{ var('RECEIPT_MAP_LOOKBACK_HOURS') }})
                FROM
                    (
                        SELECT MIN(_partition_by_block_number) AS _partition_by_block_number FROM retry_range
                        UNION ALL
                        SELECT MAX(_partition_by_block_number) AS _partition_by_block_number FROM {{ this }}
                    )
            )
            AND (
                {% if is_incremental() %}
                    _modified_timestamp >= (
                        SELECT
                            MAX(_modified_timestamp)
                        FROM
                            {{ this }}
                    )
                OR 
                {% endif %}
                receipt_id IN (
                    SELECT
                        DISTINCT receipt_object_id
                    FROM
                        retry_range
                )
            )
    {% endif %}
),
blocks AS (
    SELECT
        block_id,
        block_timestamp,
        _partition_by_block_number,
        _inserted_timestamp
        {% if not var('IS_MIGRATION') %}
        , modified_timestamp AS _modified_timestamp
        {% endif %}
    FROM
        {{ ref('silver__streamline_blocks') }}

    {% if var('MANUAL_FIX') %}
        WHERE
            {{ partition_load_manual('no_buffer') }}
    {% else %}
        WHERE
            _partition_by_block_number >= (
                SELECT
                    MIN(_partition_by_block_number) - (3000 * {{ var('RECEIPT_MAP_LOOKBACK_HOURS') }})
                FROM
                    (
                        SELECT MIN(_partition_by_block_number) AS _partition_by_block_number FROM retry_range
                        UNION ALL
                        SELECT MAX(_partition_by_block_number) AS _partition_by_block_number FROM {{ this }}
                    )
            )
    {% endif %}
),
append_tx_hash AS (
    SELECT
        m.tx_hash,
        r.receipt_id,
        r.block_id,
        r.shard_id,
        r.receipt_index,
        r.chunk_hash,
        r.receipt,
        r.execution_outcome,
        r.outcome_receipts,
        r.receiver_id,
        r.signer_id,
        r.receipt_type,
        r.receipt_succeeded,
        r.error_type_0,
        r.error_type_1,
        r.error_type_2,
        r.error_message,
        r._partition_by_block_number,
        r._inserted_timestamp,
        r._modified_timestamp
    FROM
        base_receipts r
        LEFT JOIN {{ ref('silver__receipt_tx_hash_mapping') }}
        m USING (receipt_id)
),
FINAL AS (
    SELECT
        tx_hash,
        receipt_id AS receipt_object_id,
        r.block_id,
        b.block_timestamp,
        receipt_index,
        chunk_hash,
        receipt AS receipt_actions,
        execution_outcome,
        outcome_receipts AS receipt_outcome_id,
        receiver_id,
        signer_id,
        receipt_type,
        execution_outcome :outcome :gas_burnt :: NUMBER AS gas_burnt,
        execution_outcome :outcome :status :: variant AS status_value,
        execution_outcome :outcome :logs :: ARRAY AS logs,
        execution_outcome :proof :: ARRAY AS proof,
        execution_outcome :outcome :metadata :: variant AS metadata,
        receipt_succeeded,
        error_type_0,
        error_type_1,
        error_type_2,
        error_message,
        _partition_by_block_number,
        _inserted_timestamp,
        _modified_timestamp
    FROM
        append_tx_hash r
        INNER JOIN blocks b USING (block_id)
)
SELECT
    *,
    {{ dbt_utils.generate_surrogate_key(
        ['receipt_object_id']
    ) }} AS streamline_receipts_final_id,
    SYSDATE() AS inserted_timestamp,
    SYSDATE() AS modified_timestamp,
    '{{ invocation_id }}' AS _invocation_id
FROM
    FINAL

'''
'''--- models/silver/streamline/silver__streamline_receipts_final.yml ---
version: 2

models:
  - name: silver__streamline_receipts_final
    description: |-
      Singular receipt objects with the shard id and chunk hash from which it was included. 

    columns:
      - name: TX_HASH
        description: "{{ doc('tx_hash')}}"
        tests:
          - not_null:
              where: _inserted_timestamp <= current_timestamp - interval '1 hour'

      - name: BLOCK_ID
        description: "{{ doc('block_id')}}"
        tests:
          - not_null:
              where: _inserted_timestamp <= current_timestamp - interval '1 hour'

      - name: BLOCK_TIMESTAMP
        description: "{{ doc('block_timestamp')}}"
        tests:
          - not_null:
              where: _inserted_timestamp <= current_timestamp - interval '1 hour'

      - name: RECEIPT_INDEX
        description: "{{ doc('receipt_index')}}"

      - name: CHUNK_HASH
        description: "{{ doc('chunk_hash')}}"
        tests:
          - not_null:
              where: "block_id not in (34691244, 34691277)"

      - name: RECEIPT_ACTIONS
        description: "{{ doc('receipt')}}"

      - name: EXECUTION_OUTCOME
        description: "{{ doc('execution_outcome')}}"

      - name: RECEIPT_OBJECT_ID
        description: "{{ doc('receipt_object_id')}}"

      - name: RECEIPT_OUTCOME_ID
        description: "{{ doc('receipt_outcome_id')}}"

      - name: RECEIVER_ID
        description: "{{ doc('receiver_id')}}"

      - name: SIGNER_ID
        description: "{{ doc('signer_id')}}"

      - name: RECEIPT_TYPE
        description: "{{ doc('receipt_type')}}"

      - name: GAS_BURNT
        description: "{{ doc('gas_burnt')}}"

      - name: STATUS_VALUE
        description: "{{ doc('status_value')}}"

      - name: LOGS
        description: "{{ doc('logs')}}"

      - name: PROOF
        description: "{{ doc('proof')}}"

      - name: METADATA
        description: "{{ doc('metadata')}}"

      - name: RECEIPT_SUCCEEDED
        description: "{{ doc('receipt_succeeded')}}"

      - name: ERROR_TYPE_0
        description: "{{ doc('error_type_0')}}"
    
      - name: ERROR_TYPE_1
        description: "{{ doc('error_type_1')}}"

      - name: ERROR_TYPE_2
        description: "{{ doc('error_type_2')}}"
      
      - name: ERROR_MESSAGE
        description: "{{ doc('error_message')}}"

      - name: _MODIFIED_TIMESTAMP
        description: "{{ doc('_modified_timestamp')}}"

      - name: _PARTITION_BY_BLOCK_NUMBER
        description: "{{ doc('_partition_by_block_number')}}"

      - name: _INSERTED_TIMESTAMP
        description: "{{ doc('_inserted_timestamp')}}"

      - name: STREAMLINE_RECEIPTS_FINAL_ID
        description: "{{doc('id')}}"
        tests:
          - unique

      - name: INSERTED_TIMESTAMP
        description: "{{doc('inserted_timestamp')}}"

      - name: MODIFIED_TIMESTAMP
        description: "{{doc('modified_timestamp')}}"

      - name: _INVOCATION_ID
        description: "{{doc('invocation_id')}}"

'''
'''--- models/silver/streamline/silver__streamline_shards.sql ---
{{ config(
    materialized = 'incremental',
    incremental_strategy = 'merge',
    merge_exclude_columns = ['inserted_timestamp'],
    cluster_by = ['_inserted_timestamp::DATE', '_partition_by_block_number'],
    unique_key = 'shard_id',
    tags = ['load', 'load_shards'],
    full_refresh = False
) }}

WITH external_shards AS (

    SELECT
        metadata$filename AS _filename,
        VALUE,
        _partition_by_block_number
    FROM
        {{ source(
            "streamline",
            "shards"
        ) }}
    WHERE
        _partition_by_block_number >= (
            SELECT
                MAX(_partition_by_block_number) - (3000 * {{ var('STREAMLINE_LOAD_LOOKBACK_HOURS') }})
            FROM
                {{ this }}
        )
),
meta AS (
    SELECT
        job_created_time AS _inserted_timestamp,
        file_name AS _filename
    FROM
        TABLE(
            information_schema.external_table_file_registration_history(
                start_time => DATEADD(
                    'hour', 
                    -{{ var('STREAMLINE_LOAD_LOOKBACK_HOURS') }},
                    SYSDATE()
                ),
                table_name => '{{ source( 'streamline', 'shards' ) }}'
            )
        ) A
),
shards AS (
    SELECT
        e._filename,
        SPLIT(
            e._filename,
            '/'
        ) [0] :: NUMBER AS block_id,
        RIGHT(SPLIT(e._filename, '.') [0], 1) :: NUMBER AS _shard_number,
        concat_ws(
            '-',
            block_id :: STRING,
            _shard_number :: STRING
        ) AS shard_id,
        e.value :chunk :: variant AS chunk,
        e.value :receipt_execution_outcomes :: variant AS receipt_execution_outcomes,
        e.value :shard_id :: NUMBER AS shard_number,
        e.value :state_changes :: variant AS state_changes,
        e._partition_by_block_number,
        m._inserted_timestamp
    FROM
        external_shards e
        LEFT JOIN meta m USING (_filename)

    {% if is_incremental() %}
        WHERE
            _inserted_timestamp >= (
                SELECT
                    MAX(_inserted_timestamp)
                FROM
                    {{ this }}
            )
    {% endif %}
)
SELECT
    *,
    {{ dbt_utils.generate_surrogate_key(
        ['shard_id']
    ) }} AS streamline_shards_id,
    SYSDATE() AS inserted_timestamp,
    SYSDATE() AS modified_timestamp,
    '{{ invocation_id }}' AS _invocation_id
FROM
    shards 
    qualify ROW_NUMBER() over (
        PARTITION BY shard_id
        ORDER BY
            _inserted_timestamp DESC
    ) = 1

'''
'''--- models/silver/streamline/silver__streamline_shards.yml ---
version: 2

models:
  - name: silver__streamline_shards
    description: |-
      Parses the shards JSON files for NEAR.

    columns:
      - name: BLOCK_ID
        description: "{{ doc('block_id')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - NUMBER
                - INTEGER

      - name: SHARD_ID
        description: "{{ doc('shard_id')}}"
        tests:
          - not_null
          - unique

      - name: CHUNK
        description: "{{ doc('chunks')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - VARIANT
                - OBJECT

      - name: RECEIPT_EXECUTION_OUTCOMES
        description: "{{ doc('receipt_execution_outcomes')}}"

      - name: SHARD_NUMBER
        description: "{{ doc('shard_number')}}"
        tests:
          - not_null
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - NUMBER
                - INTEGER

      - name: STATE_CHANGES
        description: "{{ doc('state_changes')}}"
        tests:
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - ARRAY
                - VARIANT

      - name: _PARTITION_BY_BLOCK_NUMBER
        description: "{{ doc('_partition_by_block_number')}}"

      - name: _MODIFIED_TIMESTAMP
        description: "{{ doc('_modified_timestamp')}}"

      - name: _INSERTED_TIMESTAMP
        description: "{{ doc('_inserted_timestamp')}}"

      - name: STREAMLINE_SHARDS_ID
        description: "{{doc('id')}}"

      - name: INSERTED_TIMESTAMP
        description: "{{doc('inserted_timestamp')}}"

      - name: MODIFIED_TIMESTAMP
        description: "{{doc('modified_timestamp')}}"

      - name: _INVOCATION_ID
        description: "{{doc('invocation_id')}}"

'''
'''--- models/silver/streamline/silver__streamline_transactions.sql ---
{{ config(
    materialized = 'incremental',
    incremental_strategy = 'merge',
    merge_exclude_columns = ['inserted_timestamp'],
    unique_key = 'tx_hash',
    cluster_by = ['_inserted_timestamp::date', '_partition_by_block_number'],
    tags = ['load', 'load_shards']
) }}

WITH chunks AS (

    SELECT
        block_id,
        shard_id,
        chunk,
        _partition_by_block_number,
        _inserted_timestamp,
        modified_timestamp AS _modified_timestamp
    FROM
        {{ ref('silver__streamline_shards') }}
    WHERE
        chunk != 'null'

    {% if var('MANUAL_FIX') %}
        AND
            {{ partition_load_manual('no_buffer') }}
    {% else %}
        {% if is_incremental() %}
            AND _modified_timestamp >= (
                SELECT
                    MAX(_modified_timestamp)
                FROM
                    {{ this }}
            )
        {% endif %}
    {% endif %}
),
flatten_transactions AS (
    SELECT
        VALUE :transaction :hash :: STRING AS tx_hash,
        block_id,
        shard_id,
        INDEX AS transactions_index,
        chunk :header :chunk_hash :: STRING AS chunk_hash,
        VALUE :outcome :execution_outcome :outcome :receipt_ids :: ARRAY AS outcome_receipts,
        VALUE AS tx,
        _partition_by_block_number,
        _inserted_timestamp,
        _modified_timestamp
    FROM
        chunks,
        LATERAL FLATTEN(
            input => chunk :transactions :: ARRAY
        )
),
txs AS (
    SELECT
        tx_hash,
        block_id,
        shard_id,
        transactions_index,
        chunk_hash,
        outcome_receipts,
        tx,
        tx :transaction :actions :: variant AS _actions,
        tx :transaction :hash :: STRING AS _hash,
        tx :transaction :nonce :: STRING AS _nonce,
        tx :outcome :execution_outcome :: variant AS _outcome,
        tx :transaction :public_key :: STRING AS _public_key,
        [] AS _receipt,
        tx :transaction :receiver_id :: STRING AS _receiver_id,
        tx :transaction :signature :: STRING AS _signature,
        tx :transaction :signer_id :: STRING AS _signer_id,
        _partition_by_block_number,
        _inserted_timestamp,
        _modified_timestamp
    FROM
        flatten_transactions
),
FINAL AS (
    SELECT
        tx_hash,
        block_id,
        shard_id,
        transactions_index,
        chunk_hash,
        outcome_receipts,
        tx,
        _actions,
        _hash,
        _nonce,
        _outcome,
        _public_key,
        _receipt,
        _receiver_id,
        _signature,
        _signer_id,
        _partition_by_block_number,
        _inserted_timestamp,
        _modified_timestamp
    FROM
        txs
)
SELECT
    *,
    {{ dbt_utils.generate_surrogate_key(
        ['tx_hash']
    ) }} AS streamline_transactions_id,
    SYSDATE() AS inserted_timestamp,
    SYSDATE() AS modified_timestamp,
    '{{ invocation_id }}' AS _invocation_id
FROM
    FINAL

'''
'''--- models/silver/streamline/silver__streamline_transactions.yml ---
version: 2

models:
  - name: silver__streamline_transactions
    description: |-
      Singular transaction objects with the shard id and chunk hash from which it was included. 
    tests:
      - dbt_utils.unique_combination_of_columns:
          combination_of_columns:
            - tx_hash
            - block_id

    columns:
      - name: TX_HASH
        description: "{{ doc('tx_hash')}}"
        tests:
          - not_null

      - name: BLOCK_ID
        description: "{{ doc('block_id')}}"
        tests:
          - not_null

      - name: SHARD_ID
        description: "{{ doc('shard_id')}}"
        tests:
          - not_null

      - name: TRANSACTIONS_INDEX
        description: "{{ doc('receipt_index')}}"
        tests:
          - not_null

      - name: _MODIFIED_TIMESTAMP
        description: "{{ doc('_modified_timestamp')}}"

      - name: CHUNK_HASH
        description: "{{ doc('chunk_hash')}}"
        tests:
          - not_null

      - name: TX
        description: "{{ doc('tx')}}"
        tests:
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - OBJECT
                - VARIANT

      - name: _INSERTED_TIMESTAMP
        description: "{{ doc('_inserted_timestamp')}}"

      - name: STREAMLINE_TRANSACTIONS_ID
        description: "{{doc('id')}}"
        tests:
          - unique

      - name: INSERTED_TIMESTAMP
        description: "{{doc('inserted_timestamp')}}"

      - name: MODIFIED_TIMESTAMP
        description: "{{doc('modified_timestamp')}}"

      - name: _INVOCATION_ID
        description: "{{doc('invocation_id')}}"

'''
'''--- models/silver/streamline/silver__streamline_transactions_final.sql ---
{{ config(
  materialized = 'incremental',
  incremental_strategy = 'delete+insert',
  unique_key = 'tx_hash',
  cluster_by = ['_modified_timestamp::DATE', '_partition_by_block_number'],
  tags = ['receipt_map']
) }}

WITH int_txs AS (

  SELECT
    block_id,
    tx_hash,
    shard_id,
    transactions_index,
    chunk_hash,
    outcome_receipts,
    _actions,
    _hash,
    _nonce,
    _outcome,
    _public_key,
    _receiver_id,
    _signature,
    _signer_id,
    _partition_by_block_number,
    _inserted_timestamp,
    modified_timestamp AS _modified_timestamp
  FROM
    {{ ref('silver__streamline_transactions') }}

    {% if var('MANUAL_FIX') %}

        WHERE
            {{ partition_load_manual('no_buffer') }}
            
    {% else %}
      WHERE
        {{ partition_incremental_load(
          6000,
          6000,
          0
        ) }}

    {% endif %}
),
int_receipts AS (
  SELECT
    block_id,
    block_timestamp,
    tx_hash,
    receipt_object_id,
    execution_outcome,
    receipt_succeeded,
    gas_burnt,
    _partition_by_block_number,
    _inserted_timestamp,
    modified_timestamp AS _modified_timestamp
  FROM
    {{ ref('silver__streamline_receipts_final') }}

    {% if var('MANUAL_FIX') %}

        WHERE
            {{ partition_load_manual('end') }}
            
    {% else %}

      WHERE
        {{ partition_incremental_load(
          6000,
          6000,
          0
        ) }}

    {% endif %}

),
int_blocks AS (
  SELECT
    block_id,
    block_hash,
    block_timestamp,
    _partition_by_block_number,
    _inserted_timestamp,
    modified_timestamp AS _modified_timestamp
  FROM
    {{ ref('silver__streamline_blocks') }}
  WHERE
    _partition_by_block_number >= (
      SELECT MIN(_partition_by_block_number) FROM int_txs
    )
),
receipt_array AS (
  SELECT
    tx_hash,
    ARRAY_AGG(execution_outcome) within GROUP (
      ORDER BY
        block_timestamp
    ) AS receipt
  FROM
    int_receipts
  GROUP BY
    1
),
base_transactions AS (
  SELECT
    t.tx_hash,
    t.block_id,
    b.block_hash,
    b.block_timestamp,
    t.shard_id,
    transactions_index,
    t.chunk_hash,
    outcome_receipts,
    OBJECT_CONSTRUCT(
      'actions',
      _actions,
      'hash',
      _hash,
      'nonce',
      _nonce,
      'outcome',
      _outcome,
      'public_key',
      _public_key,
      'receipt',
      r.receipt,
      'receiver_id',
      _receiver_id,
      'signature',
      _signature,
      'signer_id',
      _signer_id
    ) AS tx,
    _partition_by_block_number,
    t._inserted_timestamp,
    GREATEST(
      t._modified_timestamp,
      b._modified_timestamp) AS _modified_timestamp
  FROM
    int_txs t
    LEFT JOIN receipt_array r USING (tx_hash)
    LEFT JOIN int_blocks b USING (block_id)
),
{# The following steps were copied directly from legacy tx model to replicate columns #}
actions AS (
  SELECT
    tx_hash,
    SUM(
      VALUE :FunctionCall :gas :: NUMBER
    ) AS attached_gas
  FROM
    base_transactions,
    LATERAL FLATTEN(
      input => tx :actions
    )
  GROUP BY
    1
),
transactions AS (
  SELECT
    block_id,
    tx :outcome :block_hash :: STRING AS block_hash,
    tx_hash,
    block_timestamp,
    tx :nonce :: NUMBER AS nonce,
    tx :signature :: STRING AS signature,
    tx :receiver_id :: STRING AS tx_receiver,
    tx :signer_id :: STRING AS tx_signer,
    tx,
    tx :outcome :outcome :gas_burnt :: NUMBER AS transaction_gas_burnt,
    tx :outcome :outcome :tokens_burnt :: NUMBER AS transaction_tokens_burnt,
    _partition_by_block_number,
    _inserted_timestamp,
    _modified_timestamp
  FROM
    base_transactions
),
gas_burnt AS (
  SELECT
    tx_hash,
    SUM(gas_burnt) AS receipt_gas_burnt,
    SUM(execution_outcome :outcome :tokens_burnt :: NUMBER) AS receipt_tokens_burnt,
    MAX(_modified_timestamp) AS _modified_timestamp
  FROM
    int_receipts
  WHERE
    execution_outcome :outcome: tokens_burnt :: NUMBER != 0
  GROUP BY 
    1
),
determine_tx_status AS (
  SELECT
    DISTINCT tx_hash,
      LAST_VALUE(
      receipt_succeeded
    ) over (
      PARTITION BY tx_hash
      ORDER BY
        block_id ASC
    ) AS tx_succeeded
  FROM
    int_receipts
),
FINAL AS (
  SELECT
    t.block_id,
    t.block_hash,
    t.tx_hash,
    t.block_timestamp,
    t.nonce,
    t.signature,
    t.tx_receiver,
    t.tx_signer,
    t.tx,
    t.transaction_gas_burnt + g.receipt_gas_burnt AS gas_used,
    t.transaction_tokens_burnt + g.receipt_tokens_burnt AS transaction_fee,
    COALESCE(
      actions.attached_gas,
      gas_used
    ) AS attached_gas,
    s.tx_succeeded,
    IFF (
      tx_succeeded,
      'Success',
      'Fail'
    ) AS tx_status, -- DEPRECATE TX_STATUS IN GOLD
    t._partition_by_block_number,
    t._inserted_timestamp,
    GREATEST(
      t._modified_timestamp,
      g._modified_timestamp
    ) AS _modified_timestamp
  FROM
    transactions AS t
    LEFT JOIN determine_tx_status s
    ON t.tx_hash = s.tx_hash
    LEFT JOIN actions
    ON t.tx_hash = actions.tx_hash
    LEFT JOIN gas_burnt g
    ON t.tx_hash = g.tx_hash
)
SELECT
  tx_hash,
  block_id,
  block_hash,
  block_timestamp,
  nonce,
  signature,
  tx_receiver,
  tx_signer,
  tx,
  gas_used,
  transaction_fee,
  attached_gas,
  tx_succeeded,
  tx_status,
  _partition_by_block_number,
  _inserted_timestamp,
  _modified_timestamp,
  {{ dbt_utils.generate_surrogate_key(
    ['tx_hash']
  ) }} AS streamline_transactions_final_id,
  SYSDATE() AS inserted_timestamp,
  SYSDATE() AS modified_timestamp,
  '{{ invocation_id }}' AS _invocation_id
FROM
  FINAL 

'''
'''--- models/silver/streamline/silver__streamline_transactions_final.yml ---
version: 2

models:
  - name: silver__streamline_transactions_final
    description: |-
      Singular transaction objects with the shard id and chunk hash from which it was included. 

    columns:
      - name: TX_HASH
        description: "{{ doc('tx_hash')}}"

      - name: BLOCK_ID
        description: "{{ doc('block_id')}}"
        tests:
          - not_null:
              where: _inserted_timestamp <= current_timestamp - interval '1 hour'

      - name: BLOCK_TIMESTAMP
        description: "{{ doc('block_timestamp')}}"
        tests:
          - not_null:
              where: _inserted_timestamp <= current_timestamp - interval '1 hour'

      - name: BLOCK_HASH
        description: "{{ doc('block_hash')}}"
        tests:
          - not_null:
              where: _inserted_timestamp <= current_timestamp - interval '1 hour'

      - name: _PARTITION_BY_BLOCK_NUMBER
        description: "{{ doc('_partition_by_block_number')}}"

      - name: NONCE
        description: "{{ doc('nonce')}}"

      - name: SIGNATURE
        description: "{{ doc('signature')}}"

      - name: TX_RECEIVER
        description: "{{ doc('tx_receiver')}}"

      - name: TX_SIGNER
        description: "{{ doc('tx_signer')}}"

      - name: TX
        description: "{{ doc('tx')}}"

      - name: TX_SUCCEEDED
        description: "{{ doc('tx_succeeded')}}"
        tests:
          - dbt_expectations.expect_column_values_to_be_in_type_list:
              column_type_list:
                - BOOLEAN
          - not_null:
              where: _inserted_timestamp <= current_timestamp - interval '1 hour'

      - name: TX_STATUS
        description: "{{ doc('tx_status')}}"
        tests:
          - not_null:
              where: _inserted_timestamp <= current_timestamp - interval '1 hour'

      - name: GAS_USED
        description: "{{ doc('gas_used')}}"
        tests:
          - not_null:
              where: _inserted_timestamp <= current_timestamp - interval '1 hour'

      - name: ATTACHED_GAS
        description: "{{ doc('attached_gas')}}"
        tests:
          - not_null:
              where: _inserted_timestamp <= current_timestamp - interval '1 hour'

      - name: TRANSACTION_FEE
        description: "{{ doc('transaction_fee')}}"
        tests:
          - not_null:
              where: _inserted_timestamp <= current_timestamp - interval '1 hour'

      - name: _MODIFIED_TIMESTAMP
        description: "{{ doc('_modified_timestamp')}}"

      - name: _INSERTED_TIMESTAMP
        description: "{{ doc('_inserted_timestamp')}}"

      - name: STREAMLINE_TRANSACTIONS_FINAL_ID
        description: "{{doc('id')}}"
        tests:
          - unique

      - name: INSERTED_TIMESTAMP
        description: "{{doc('inserted_timestamp')}}"

      - name: MODIFIED_TIMESTAMP
        description: "{{doc('modified_timestamp')}}"

      - name: _INVOCATION_ID
        description: "{{doc('invocation_id')}}"

'''
'''--- models/sources.yml ---
version: 2

sources:
  - name: crosschain
    schema: core
    database: crosschain
    tables:
      - name: dim_dates

  - name: crosschain_silver
    database: crosschain
    schema: silver
    tables:
      - name: number_sequence
      - name: github_activity
      - name: labels_combined
      - name: complete_token_asset_metadata
      - name: complete_token_prices
      - name: complete_provider_asset_metadata
      - name: complete_provider_prices
      - name: complete_native_asset_metadata
      - name: complete_native_prices

  - name: streamline
    database: streamline
    schema: near_lake
    tables:
      - name: blocks
      - name: shards

'''
'''--- package-lock.yml ---
packages:
- package: calogica/dbt_expectations
  version: 0.8.0
- package: dbt-labs/dbt_utils
  version: 1.0.0
- git: https://github.com/FlipsideCrypto/fsc-utils.git
  revision: 3a45311f3e94c8a695443f77aab433a05b894f90
- package: get-select/dbt_snowflake_query_tags
  version: 2.3.2
- package: calogica/dbt_date
  version: 0.7.2
- git: https://github.com/FlipsideCrypto/livequery-models.git
  revision: bca494102fbd2d621d32746e9a7fe780678044f8
sha1_hash: fbcbdbe8b2795b045e82d914d8fe7cf4421a01bc

'''
'''--- packages.yml ---
packages:
  - package: calogica/dbt_expectations
    version: 0.8.0
  - package: dbt-labs/dbt_utils
    version: 1.0.0
  - git: https://github.com/FlipsideCrypto/fsc-utils.git
    revision: "v1.9.3"
  - package: get-select/dbt_snowflake_query_tags
    version: [">=2.0.0", "<3.0.0"]

'''
'''--- profiles.yml ---
near:
  target: dev
  outputs:
    dev:
      type: snowflake
      account: "{{ env_var('SF_ACCOUNT') }}"
      # User/password auth
      user: "{{ env_var('SF_USERNAME') }}"
      authenticator: externalbrowser
      password: "{{ env_var('SF_PASSWORD') }}"
      role: "{{ env_var('SF_ROLE') }}"
      schema: "{{ env_var('SF_SCHEMA') }}"
      region: "{{ env_var('SF_REGION') }}"
      database: "{{ env_var('SF_DATABASE') }}"
      warehouse: "{{ env_var('SF_WAREHOUSE') }}"
      threads: 4
      client_session_keep_alive: False
      query_tag: near_curator
  config:
    send_anonymous_usage_stats: False

'''
'''--- python_scripts/test_alert/dbt_test_alert.py ---
import datetime
import requests
import json
import sys
import os

def log_test_result():
    """Reads the run_results.json file and returns a dictionary of targeted test results"""

    filepath = "target/run_results.json"

    with open(filepath) as f:
        run = json.load(f)

    logs = []
    messages = {
        "fail": [],
        "warn": []
    }
    test_count = 0
    warn_count = 0
    fail_count = 0

    for test in run["results"]:
        test_count += 1
        if test["status"] != "pass":
            logs.append(test)

            message = f"{test['failures']} record failure(s) in {test['unique_id']}"

            if test["status"] == "warn":
                messages["warn"].append(message)
                warn_count += 1
            elif test["status"] == "fail":
                messages["fail"].append(message)
                fail_count += 1

    dbt_test_result = {
        "logs": logs,
        "messages": messages,
        "test_count": test_count,
        "warn_count": warn_count,
        "fail_count": fail_count,
        "elapsed_time": str(datetime.timedelta(seconds=run["elapsed_time"]))
    }

    return dbt_test_result

def create_message(**kwargs):
    messageBody = {
        "text": f"Hey{' <!here>' if len(kwargs['messages']['fail']) > 0 else ''}, new DBT test results for :{os.environ.get('DATABASE').split('_DEV')[0]}: {os.environ.get('DATABASE')}",
        "attachments": [
            {
                "color": kwargs["color"],
                "fields": [
                    {
                        "title": "Total Tests Run",
                        "value": kwargs["test_count"],
                        "short": True
                    },
                    {
                        "title": "Total Time Elapsed",
                        "value": kwargs["elapsed_time"],
                        "short": True
                    },
                    {
                        "title": "Number of Unsuccessful Tests",
                        "value": f"Fail: {kwargs['fail_count']}, Warn: {kwargs['warn_count']}",
                        "short": True
                    },
                    {
                        "title": "Failed Tests:",
                        "value": "\n".join(kwargs["messages"]["fail"]) if len(kwargs["messages"]["fail"]) > 0 else "None :)",
                        "short": False
                    }
                ],
                "actions": [

                    {
                        "type": "button",
                        "text": "View Warnings",
                        "style": "primary",
                        "url": "https://github.com/FlipsideCrypto/near-models/actions/workflows/dbt_test.yml",
                        "confirm": {
                            "title": f"{kwargs['warn_count']} Warnings",
                            "text": "\n".join(kwargs["messages"]["warn"]) if len(kwargs["messages"]["warn"]) > 0 else "None :)",
                            "ok_text": "Continue to GHA",
                            "dismiss_text": "Dismiss"
                        }
                    }
                ]
            }
        ]
    }

    return messageBody

def send_alert(webhook_url):
    """Sends a message to a slack channel"""

    url = webhook_url

    data = log_test_result()

    send_message = create_message(
        fail_count=data["fail_count"],
        warn_count=data["warn_count"],
        test_count=data["test_count"],
        messages=data["messages"],
        elapsed_time=data["elapsed_time"],
        color="#f44336" if data["fail_count"] > 0 else "#4CAF50"
    )

    x = requests.post(url, json=send_message)

    # test config to continue on error in workflow, so we want to exit with a non-zero code if there are any failures
    if data['fail_count'] > 0:
        sys.exit(1)

if __name__ == '__main__':

    webhook_url = os.environ.get("SLACK_WEBHOOK_URL")
    send_alert(webhook_url)

'''
'''--- python_scripts/token_labels/README.md ---
# Near DBT Project - Python Scripts

## Setup

1. Install Python 3 in your machine https://www.python.org/downloads/.

2. Open your terminal/command prompt and go to this directory.

3. Run the following command:

> `pip install -r requirements.txt`

4. Run the Python script by typing:

> `python <script name here>.py`

(e.g. `python token_labels_retriever.py`)

## Troubleshooting

1. Check if you're in the right directory
2. If the commands are not recognized, you need to add Python in your environment variables

'''
'''--- python_scripts/token_labels/requirements.txt ---
pandas==1.4.2
requests==2.27.1

'''
'''--- python_scripts/token_labels/token_labels_retriever.py ---
import pandas as pd
import requests

def table_retriever():
    token_labels = requests.get('https://api.stats.ref.finance/api/last-tvl').json()
    df = pd.json_normalize(token_labels)[['token_account_id', 'ftInfo.name','ftInfo.symbol', 'ftInfo.decimals']]
    df.columns = ['token_contract', 'token', 'symbol', 'decimals']
    return df
    
if __name__ == '__main__':
    df = table_retriever()
    df.to_csv('../data/seeds__token_labels.csv', index=False)
'''
'''--- requirements.txt ---
dbt-snowflake>=1.7,<1.8
protobuf==4.25.3
'''
'''--- tests/tests__chunk_gaps.sql ---
{{ config(
    error_if = '>=10',
    warn_if = 'BETWEEN 1 AND 9',
    tags = ['gap_test']
) }}

WITH blocks AS (

    SELECT
        block_id,
        header :chunks_included :: INT AS chunk_ct_expected,
        _partition_by_block_number,
        _inserted_timestamp
    FROM
        {{ ref('silver__streamline_blocks') }}

        {% if var('DBT_FULL_TEST') %}
        WHERE
            _inserted_timestamp < SYSDATE() - INTERVAL '1 hour'
        {% else %}
        WHERE
            _inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days'
            AND SYSDATE() - INTERVAL '1 hour'
        {% endif %}
),
shards AS (
    SELECT
        block_id,
        MAX(_inserted_timestamp) AS _inserted_timestamp,
        COUNT(
            DISTINCT chunk :header :chunk_hash :: STRING
        ) AS chunk_ct_actual
    FROM
        {{ ref('silver__streamline_shards') }}

        {% if var('DBT_FULL_TEST') %}
        WHERE
            _inserted_timestamp < SYSDATE() - INTERVAL '1 hour'
        {% else %}
        WHERE
            _inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days'
            AND SYSDATE() - INTERVAL '1 hour'
        {% endif %}
    GROUP BY
        1
),
comp AS (
    SELECT
        b.block_id AS b_block_id,
        s.block_id AS s_block_id,
        b.chunk_ct_expected,
        s.chunk_ct_actual,
        _partition_by_block_number,
        b._inserted_timestamp AS _inserted_timestamp_blocks,
        s._inserted_timestamp AS _inserted_timestamp_shards
    FROM
        blocks b full
        OUTER JOIN shards s USING (block_id)
)
SELECT
    COALESCE(
        b_block_id,
        s_block_id
    ) AS block_id,
    chunk_ct_expected,
    chunk_ct_actual,
    _partition_by_block_number,
    (
        chunk_ct_actual != chunk_ct_expected
        OR b_block_id IS NULL
        OR s_block_id IS NULL
    ) AS is_missing
FROM
    comp
WHERE
    chunk_ct_expected > 0
    AND is_missing 
    {# Filter out false positive from blocks at start of window #}
    AND _inserted_timestamp_blocks > SYSDATE() - INTERVAL '7 days' + INTERVAL '1 hour'
    AND _inserted_timestamp_shards > SYSDATE() - INTERVAL '7 days' + INTERVAL '1 hour'
ORDER BY
    1

'''
'''--- tests/tests__log_gap.sql ---
{{ config(
    severity = "error"
) }}

WITH r_logs AS (

    SELECT
        DISTINCT receipt_object_id,
        block_timestamp,
        block_id
    FROM
        {{ ref('silver__streamline_receipts_final') }}
    WHERE
        ARRAY_SIZE(logs) > 0 {% if var('DBT_FULL_TEST') %}
            AND _inserted_timestamp < SYSDATE() - INTERVAL '1 hour'
        {% else %}
            AND _inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days'
            AND SYSDATE() - INTERVAL '1 hour'
        {% endif %}
),
logs AS (
    SELECT
        DISTINCT receipt_object_id,
        block_timestamp,
        block_id
    FROM
        {{ ref('silver__logs_s3') }}

        {% if var('DBT_FULL_TEST') %}
        WHERE
            _inserted_timestamp < SYSDATE() - INTERVAL '1 hour'
        {% else %}
        WHERE
            _inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days'
            AND SYSDATE() - INTERVAL '1 hour'
        {% endif %}
) -- logs in receipts that do not make it to logs
SELECT
    *
FROM
    r_logs
EXCEPT
SELECT
    *
FROM
    logs

'''
'''--- tests/tests__receipt_gaps.sql ---
{{ config(
    error_if = '>=10',
    warn_if = 'BETWEEN 1 AND 9',
    tags = ['gap_test']
) }}

WITH shards AS (

    SELECT
        block_id,
        _partition_by_block_number,
        SUM(ARRAY_SIZE(receipt_execution_outcomes)) AS receipt_ct_expected
    FROM
        {{ ref('silver__streamline_shards') }}

        {% if var('DBT_FULL_TEST') %}
        WHERE
            _inserted_timestamp < SYSDATE() - INTERVAL '1 hour'
        {% else %}
        WHERE
            _inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days'
            AND SYSDATE() - INTERVAL '1 hour'
        {% endif %}
    GROUP BY
        1,
        2
),
receipts AS (
    SELECT
        block_id,
        _partition_by_block_number,
        COUNT(DISTINCT receipt_id) AS receipt_ct_actual_distinct,
        COUNT(1) AS receipt_ct_actual_all
    FROM
        {{ ref('silver__streamline_receipts') }}

        {% if var('DBT_FULL_TEST') %}
        WHERE
            _inserted_timestamp < SYSDATE() - INTERVAL '1 hour'
        {% else %}
        WHERE
            _inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days'
            AND SYSDATE() - INTERVAL '1 hour'
        {% endif %}
    GROUP BY
        1,
        2
),
diffs AS (
    SELECT
        s.block_id,
        s.receipt_ct_expected,
        r.receipt_ct_actual_distinct,
        r.receipt_ct_actual_all,
        s._partition_by_block_number
    FROM
        shards s
        LEFT JOIN receipts r
        ON s.block_id = r.block_id
)
SELECT
    *
FROM
    diffs
WHERE
    receipt_ct_expected != receipt_ct_actual_distinct
    OR receipt_ct_expected != receipt_ct_actual_all
    OR receipt_ct_actual_distinct != receipt_ct_actual_all
ORDER BY
    block_id

'''
'''--- tests/tests__streamline_block_gaps.sql ---
{{ config(
    severity = 'error',
    tags = ['gap_test']
) }}

WITH silver_blocks AS (

  SELECT
    block_id,
    block_id - 1 AS missing_block_id,
    block_timestamp,
    block_hash,
    prev_hash,
    LAG(block_hash) over (
      ORDER BY
        block_timestamp ASC,
        block_id ASC
    ) AS prior_hash,
    _partition_by_block_number,
    _inserted_timestamp,
    SYSDATE() AS _test_timestamp
  FROM
    {{ ref('silver__streamline_blocks') }}

    {% if var('DBT_FULL_TEST') %}
    WHERE
      _inserted_timestamp < SYSDATE() - INTERVAL '1 hour'
    {% else %}
    WHERE
      _inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days'
      AND SYSDATE() - INTERVAL '1 hour'
    {% endif %}
)
SELECT
  *
FROM
  silver_blocks
WHERE
  prior_hash <> prev_hash {# Filter out false positive from blocks at start of window (whose parent hash was cut off) #}
  AND (_inserted_timestamp > SYSDATE() - INTERVAL '7 days' + INTERVAL '1 hour')

'''
'''--- tests/tests__tx_gaps.sql ---
{{ config(
    error_if = '>=10',
    warn_if = 'BETWEEN 1 AND 9',
    tags = ['gap_test']
) }}

WITH shards AS (

    SELECT
        block_id,
        _partition_by_block_number,
        SUM(ARRAY_SIZE(chunk :transactions :: ARRAY)) AS tx_ct_expected
    FROM
        {{ ref('silver__streamline_shards') }}

        {% if var('DBT_FULL_TEST') %}
        WHERE
            _inserted_timestamp < SYSDATE() - INTERVAL '1 hour'
        {% else %}
        WHERE
            _inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days'
            AND SYSDATE() - INTERVAL '1 hour'
        {% endif %}
    GROUP BY
        1,
        2
),
txs AS (
    SELECT
        block_id,
        _partition_by_block_number,
        COUNT(DISTINCT tx_hash) AS tx_ct_actual_distinct,
        COUNT(1) AS tx_ct_actual_all
    FROM
        {{ ref('silver__streamline_transactions') }}

        {% if var('DBT_FULL_TEST') %}
        WHERE
            _inserted_timestamp < SYSDATE() - INTERVAL '1 hour'
        {% else %}
        WHERE
            _inserted_timestamp BETWEEN SYSDATE() - INTERVAL '7 days'
            AND SYSDATE() - INTERVAL '1 hour'
        {% endif %}
    GROUP BY
        1,
        2
),
diffs AS (
    SELECT
        s.block_id,
        s.tx_ct_expected,
        t.tx_ct_actual_distinct,
        t.tx_ct_actual_all,
        s._partition_by_block_number
    FROM
        shards s
        LEFT JOIN txs t
        ON s.block_id = t.block_id
)
SELECT
    *
FROM
    diffs
WHERE
    tx_ct_expected != tx_ct_actual_distinct
    OR tx_ct_expected != tx_ct_actual_all
    OR tx_ct_actual_distinct != tx_ct_actual_all
ORDER BY
    block_id

'''