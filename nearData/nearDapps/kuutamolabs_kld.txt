*GitHub Repository "kuutamolabs/kld"*

'''--- .github/dependabot.yml ---
version: 2
updates:
  - package-ecosystem: "github-actions"
    directory: "/"
    schedule:
      interval: "weekly"
  - package-ecosystem: "cargo"
    directory: "/"
    schedule:
      interval: "weekly"
      day: "friday"
      time: "23:50"
  - package-ecosystem: "cargo"
    directory: "/mgr"
    schedule:
      interval: "weekly"
      day: "friday"
      time: "23:50"
  - package-ecosystem: "cargo"
    directory: "/ctl"
    schedule:
      interval: "weekly"
      day: "friday"
      time: "23:50"

'''
'''--- .github/workflows/typo.yml ---
name: typo checker

concurrency:
  group: typo-${{ github.head_ref }}
  cancel-in-progress: true

on:
  pull_request:

jobs:
  run:
    name: Spell Check with Typos
    runs-on: ubuntu-latest
    steps:
    - name: Checkout Actions Repository
      uses: actions/checkout@v4

    - name: Ignore implicit configuration file
      uses: crate-ci/typos@master

'''
'''--- .github/workflows/upgrade-flakes.yml ---
name: "Update flakes"
on:
  repository_dispatch:
  workflow_dispatch:
  schedule:
    - cron:  '51 23 * * 5'
permissions:
  contents: write
  pull-requests: write
jobs:
  createPullRequest:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Install Nix
        uses: cachix/install-nix-action@v26
        with:
          extra_nix_config: |
            experimental-features = nix-command flakes
      - name: Update flake.lock
        uses: DeterminateSystems/update-flake-lock@v21

'''
'''--- Cargo.toml ---
[workspace]
members = [
    "kld",
    "test-utils",
    "tui",
]

'''
'''--- README.md ---
# ðŸŒ˜kuutamo lightning distribution
### a Lighting Service Provider (LSP) router node cluster

**Nota bene**: kuutamo is bleeding edge decentralized financial infrastructure. Use with caution and only with funds you are prepared to lose.
If you want to put it into production and would like to discuss SRE overlay support, please get in touch with us at [opencore-support@kuutamo.co](mailto:opencore-support@kuutamo.co)

## Prerequisites

- 1 or 3 server(s)/node(s): Any Linux OS
- 1 client/local machine: Any Linux OS

## Key components

### Client side:
- `kld-mgr`       - A CLI tool that will SSH to your server(s) to perform the initial deployment
- `kld-cli`       - A CLI tool that uses the kld API to support LSP operations
- `kld-tui`       - A Terminal User Interface that uses the kld API to support LSP operations (WIP)

### Server side:
- `kld`             - an LSP router, built on [LDK](https://github.com/lightningdevkit)
- `cockroachdb`     - a cloud-native, distributed SQL database
- `telegraf`        - an agent for collecting and sending metrics to any URL that supports the [Prometheus's Remote Write API](https://prometheus.io/docs/prometheus/latest/configuration/configuration/#remote_write)
- `promtail`        - an agent which ships the contents of local logs to a private Grafana Loki instance or Grafana Cloud
- `bitcoind`        - a bitcoin client
- `electrs`         - a bitcoin database indexer
- `kuutamo-upgrade` - an updater service that will monitor the deployment repository and apply any required upgrades

## Nix quickstart

kld-mgr:
```bash
nix run github:kuutamolabs/kld#kld-mgr -- help
```

kld-cli:
```bash
nix run github:kuutamolabs/kld#kld-cli -- help
```

kld-tui:
```bash
nix run github:kuutamolabs/kld#kld-tui -- help
```

## Installing Nix

1. Install the Nix package manager, if you don't already have it. https://zero-to-nix.com/start/install

2. Trust pre-built binaries (optional):
```shell
$ printf 'trusted-substituters = https://cache.garnix.io https://cache.nixos.org/\ntrusted-public-keys = cache.garnix.io:CTFPyKSLcx5RMJKfLo5EEPUObbA78b0YQ2DTCJXqr9g= cache.nixos.org-1:6NCHdD59X431o0gWypbMrAURkbJ16ZPMQFGspcDShjY=' | sudo tee -a /etc/nix/nix.conf && sudo systemctl restart nix-daemon
```

3. Test
```shell
$ nix run --refresh github:kuutamolabs/kld#kld-mgr -- help
```

## Install and in life operations

By default, nodes are locked down once installed and cannot be connected to over SSH. Nodes are upgraded using a GitOps model enabling complete system change auditability.

The `kuutamo-updater` service checks for updates in your private deployment repository. If found, the cluster will upgrade.
The maintainers of the deployment repository control when upgrades are accepted. They will review/audit, approve and merge the updated `flake.lock` PR.

An example install and upgrade workflow is shown below using GitHub. Other Git platforms such as Bitbucket and GitLab can be used inplace.
`kld-mgr` requires root SSH access to server(s) to perform the initial install.
Other cluster bootstrap methods can be used, such as via USB disk or PXE.

> Note: For Test/Dev deployments you can retain Root and SSH capabilities by setting the `DEBUG` environment variable to `true` when performing `install`.

Although monitoring is not mandatory for deploying a node, it is highly recommended.
Configure the `self_monitoring_url`, `self_monitoring_username`, and `self_monitoring_password` fields of the host in the `kld.toml`.
To view Logs remotely set the `promtail_client` in the form `https://<user_id>:<token>@<client hostname>/loki/api/vi/push`

![install and upgrade GitOps setup](./install-upgrade-gitops.jpg)

- Step 1: Generate example `kld.toml`
```shell
$ nix run github:kuutamolabs/kld#kld-mgr generate-example > kld.toml
```
- Step 2: Generate classic token with full repo permission, please refer to the [Github doc](https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/managing-your-personal-access-tokens)

- Step 5.1: Generate deployment config
```shell
$ nix run github:kuutamolabs/kld#kld-mgr generate-config ./deployment
```
- Step 5.2: Setup Git & GitHub deployment repository
```shell
$ cd ./deployment
$ git init
$ git add .
$ git commit -m "init deploy"
$ git remote add origin git@github.com:my-org/deployment
$ git push
$ cd ..
```

- Step 6: Add the flake-lock-update Github Action
 ```shell
$ mkdir -p ./deployment/.github/workflows
$ curl https://raw.githubusercontent.com/DeterminateSystems/update-flake-lock/main/.github/workflows/update.yml --output ./deployment/.github/workflows/upgrade.yml
```
Please refer to [update-flake-lock](https://github.com/DeterminateSystems/update-flake-lock) to configure this Action to your requirements.

- Step 7: Install
```shell
$ nix run github:kuutamolabs/kld#kld-mgr install
```
- Connect to node via API. kld API is served on port `2244`
```shell
$ nix run github:kuutamolabs/kld/mgr#kld-cli -- -t "x.x.x.x:2244" -c "secrets/lightning/ca.pem" -m "secrets/admin.macaroon get-info"
```

## kld-cli

```shell
$ nix run github:kuutamolabs/kld#kld-cli -- help
```
```
Usage: kld-cli --target <TARGET> --cert-path <CERT_PATH> --macaroon-path <MACAROON_PATH> <COMMAND>

Commands:
  get-info                    Fetch information about this lightning node
  sign                        Creates a signature of the message using nodes secret key (message limit 65536 chars)
  get-balance                 Fetch confirmed and unconfirmed on-chain balance
  new-address                 Generates new on-chain address for receiving funds
  withdraw                    Send on-chain funds out of the wallet
  list-funds                  Show available funds from the internal wallet
  list-peers                  Fetch a list of this nodes peers
  connect-peer                Connect with a network peer
  disconnect-peer             Disconnect from a network peer
  list-channels               Fetch a list of this nodes open channels
  open-channel                Open a channel with another node
  set-channel-fee             Set channel fees
  close-channel               Close a channel
  network-nodes               Get node information from the network graph
  network-channels            Get channel information from the network graph
  fee-rates                   Return feerate estimates, either satoshi-per-kw or satoshi-per-kb
  keysend                     Pay a node without an invoice
  generate-invoice            Generate a bolt11 invoice for receiving a payment
  list-invoices               List all invoices
  pay-invoice                 Pay an invoice
  list-payments               List all payments
  estimate-channel-liquidity  Estimate channel liquidity to a target node
  local-remote-balance        Fetch the aggregate local and remote channel balances (msat) of the node
  get-fees                    Get node routing fees
  list-forwards               Fetch a list of the forwarded htlcs
  help                        Print this message or the help of the given subcommand(s)

Options:
  -t, --target <TARGET>                IP address or hostname of the target machine
  -c, --cert-path <CERT_PATH>          Path to the TLS cert of the target API
  -m, --macaroon-path <MACAROON_PATH>  Path to the macaroon for authenticating with the API
  -h, --help                           Print help
  -V, --version                        Print version

```

'''
'''--- bors.toml ---
cut_body_after = "" # don't include text from the PR body in the merge commit message
status = [
  "Evaluate flake.nix",
  "check cockroachdb [x86_64-linux]",
  "check kld [x86_64-linux]",
  "check kld-benches [x86_64-linux]",
  "check kld-clippy [x86_64-linux]",
  "check kld-mgr [x86_64-linux]",
  "check kld-mgr-clippy [x86_64-linux]",
  "check kld-mgr-tests [x86_64-linux]",
  "check kld-tests [x86_64-linux]",
  "check treefmt [x86_64-linux]",
  "devShell default [x86_64-linux]",
  "package bitcoind [x86_64-linux]",
  "package cockroachdb [x86_64-linux]",
  "package default [x86_64-linux]",
  "package kld [x86_64-linux]",
  "package kld-mgr [x86_64-linux]",
  "package remote-pdb [x86_64-linux]"
]

'''
'''--- ctl/Cargo.toml ---
[package]
name = "kld-ctl"
version = "0.1.0"
edition = "2021"
description = "A general node controller for lightning knd"

[workspace]

[dependencies]
anyhow = "1.0.82"
clap = { version = "4.5.4", features = ["derive"] }
serde = "1.0"
serde_derive = "1.0.188"
toml = "0.8.12"

'''
'''--- ctl/src/main.rs ---
mod system_info;
use system_info::system_info;

use clap::Parser;

#[derive(clap::Parser)]
#[clap(author, version, about, long_about = None)]
enum Command {
    SystemInfo(SystemInfoArgs),
}

#[derive(clap::Args)]
/// Show system info
struct SystemInfoArgs {
    /// Display system info with inline format
    #[clap(long)]
    inline: bool,
}

fn main() {
    match Command::parse() {
        Command::SystemInfo(arg) => system_info(arg.inline),
    }
}

'''
'''--- ctl/src/system_info.rs ---
use anyhow::{anyhow, Context, Result};
use serde_derive::Deserialize;
use std::env;

#[derive(Deserialize)]
struct SystemInfo {
    git_sha: String,
    git_commit_date: String,
    deployment_flake: Option<String>,
    upgrade_time: Option<String>,
}

fn read_system_info() -> Result<SystemInfo> {
    let content = std::fs::read_to_string("/etc/system-info.toml")
        .context("fail to read /etc/system-info.toml")?;
    Ok(toml::from_str::<SystemInfo>(&content)?)
}

fn bitcoind_version() -> Result<String> {
    let output = std::process::Command::new("bitcoind")
        .args(["--version"])
        .output()
        .context("could not run bitcoind command")?;
    std::str::from_utf8(&output.stdout)?
        .split('\n')
        .next()
        .and_then(|line| line.split("Bitcoin Core version ").nth(1))
        .ok_or(anyhow!(
            "failed to parse version from bitcoind command output"
        ))
        .map(|version| version.into())
}

fn cockroach_version() -> Result<String> {
    let output = std::process::Command::new("cockroach")
        .args(["version"])
        .output()
        .context("could not run cockroach command")?;
    std::str::from_utf8(&output.stdout)?
        .split('\n')
        .next()
        .and_then(|line| line.split("Build Tag:        ").nth(1))
        .ok_or(anyhow!("failed to parse version from cockroach output"))
        .map(|version| version.into())
}

fn kld_cli_version() -> Result<String> {
    // Note:
    // All versions of kld related tools in lightning-knd are not guaranteed the same
    // so we need this.
    let output = std::process::Command::new("kld-cli")
        .args(["-V"])
        .output()
        .context("could not run kld-cli command")?;
    std::str::from_utf8(&output.stdout)?
        .split('\n')
        .next()
        .and_then(|line| line.split("kld ").nth(1))
        .ok_or(anyhow!(
            "failed to parse version from kld-cli command output"
        ))
        .map(|version| version.into())
}
fn disk_encrypted_status() -> Result<bool> {
    let output = std::process::Command::new("cryptsetup")
        .args(["isLuks", "/dev/md/root"])
        .output()
        .context("could not get disk encrypted status")?;
    Ok(output.status.success())
}

pub fn system_info(inline: bool) {
    let mut info = vec![
        ("kld-ctl version", env!("CARGO_PKG_VERSION").to_string()),
        (
            "disk encrypted",
            disk_encrypted_status()
                .map(|s| s.to_string())
                .unwrap_or("unknown".to_string()),
        ),
    ];

    if let Ok(system_info) = read_system_info() {
        info.push(("git sha", system_info.git_sha));
        info.push(("git commit date", system_info.git_commit_date));
        if let Some(deployment_flake) = system_info.deployment_flake {
            info.push(("deployment flake", deployment_flake));
        }
        if let Some(time) = system_info.upgrade_time {
            info.push(("upgrade time", time));
        }
    }

    if let Ok(version) = bitcoind_version() {
        info.push(("bitcoind version", version));
    };

    if let Ok(version) = cockroach_version() {
        info.push(("cockroach version", version));
    };

    if let Ok(version) = kld_cli_version() {
        info.push(("kld-cli version", version));
    };

    if inline {
        let system_info: Vec<String> = info
            .iter()
            .map(|i| format!("{}={}", i.0.replace(' ', "-"), i.1))
            .collect();
        println!("{}", system_info.join(" "));
    } else {
        let system_info: Vec<String> = info.iter().map(|i| format!("{}: {}", i.0, i.1)).collect();
        println!("{}", system_info.join("\n"));
    }
}

'''
'''--- example/kld.toml ---
# Global configuration affecting all hosts
[global]
# Flake url for your deployment config
# Please refer https://github.com/kuutamolabs/deployment-example
deployment_flake = "github:kuutamolabs/deployment-example"

# Tokens for access the deployment flake and the dependencies thereof
# Please make sure it is never exipired,
# because we can not update the token after deploy
access_tokens = "github.com=ghp_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"

# Flake url for KND
knd_flake = "github:kuutamolabs/lightning-knd"

# Directory where the secrets are stored i.e. certificates
secret_directory = "secrets"

# The default values of host will use if any corresponding value is not provided in following hosts
[host_defaults]
# The default Ipv4 gateway of all node
# ipv4_gateway = "192.168.0.254"

# The default Ipv4 CIDR for all node
# ipv4_cidr = 24

# The default Ipv6 gateway of all node
# ipv6_gateway = ""

# The default Ipv6 CIDR of all node
# ipv6_cidr = 0

# The default ssh public keys of the user
# After installation the user could login as root with the corresponding ssh private key
public_ssh_keys = ["ssh-ed25519 AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA...",]

# The default admin user for install,
# Please use `ubuntu` when you use OVH to install at first time,
# Ubuntu did not allow `root` login
# install_ssh_user = "ubuntu"

# Extra nixos module will deploy to the node
extra_nixos_modules = []

# Default disk configure on all node
# disks = ["/dev/vdb",]

# The default Token file for monitoring, default is "kuutamo-monitoring.token"
# Provide this if you have a different file
# kuutamo_monitoring_token_file = "kuutamo-monitoring.token"

# The default self monitoring server
# The url should implements [Prometheus's Remote Write API] (https://prometheus.io/docs/prometheus/latest/configuration/configuration/#remote_write).
# self_monitoring_url = "https://my.monitoring.server/api/v1/push"

# The default http basic auth username to access self monitoring server
# self_monitoring_username = ""

# The default http basic auth password to access self monitoring server
# self_monitoring_password = ""

# The default push endpoint for the promtail client with auth to collect the journal logs for all nodes
# ex: https://<user_id>:<token>@<client hostname>/loki/api/vi/push
# promtail_client = ""

# The default alias color for all node
# kld_node_alias_color = "6e2cf7"

# The default probe interval for all node
# probe_interval = 0

# The default probe amount in msat for all node
# probe_amt_msat = 0

# The list of targets to probe
# probe_targets = []

# The graceful period in seconds when a shutdown signal is received
# shutdown_graceful_sec = 5

# The configuration for the host, if any field not provided will use from host_defaults
# For general use case, following fields is needed
# - one of network should be configured (ipv4 or ipv6)
# - the disk information of the node
[hosts.example]
# Ipv4 address of the node
# ipv4_address = "192.168.0.1"

# Ipv4 gateway of the node
# ipv4_gateway = "192.168.0.254"

# Ipv4 CIDR of the node
# ipv4_cidr = 24

# Nixos module will deploy to the node
nixos_module = "kld-node"

# Mac address of the node
# mac_address = "00:0A:02:0B:03:0C"

# Ipv6 address of the node
# ipv6_address = ""

# Ipv6 gateway of the node
# ipv6_gateway = ""

# Ipv6 cidr of the node
# ipv6_cidr = 0

# Admin user for install,
# Please use `ubuntu` when you use OVH to install at first time,
# Ubuntu did not allow `root` login
# install_ssh_user = "ubuntu"

# Setup host name for connection and host label on monitoring dashboard
# hostname = ""

# Disk configure on the node
# disks = ["/dev/vdb",]

# bitcoind_disks = [ "", ]

# String for node_alias, currently it only accept 32 chars ascii string for this field
# kld_node_alias = ""

# The default alias color for the node
# kld_node_alias_color = "6e2cf7"

# Set kld log level to `error`, `warn`, `info`, `debug`, `trace`
# kld_log_level = "info"

# Token file for monitoring, default is "kuutamo-monitoring.token"
# Provide this if you have a different file
# kuutamo_monitoring_token_file = "kuutamo-monitoring.token"

# Self monitoring server
# The url should implements [Prometheus's Remote Write API] (https://prometheus.io/docs/prometheus/latest/configuration/configuration/#remote_write).
# self_monitoring_url = "https://my.monitoring.server/api/v1/push"

# The http basic auth username to access self monitoring server
# self_monitoring_username = ""

# The http basic auth password to access self monitoring server
# self_monitoring_password = ""

# The push endpoint for the promtail client with auth to collect the journal logs for the node
# ex: https://<user_id>:<token>@<client hostname>/loki/api/vi/push
# promtail_client = ""

# The communication port of kld
# kld_rest_api_port = 2244

# The ip addresses list will allow to communicate with kld, if empty, the kld-cli can only
# use on the node.
kld_api_ip_access_list = []

# The interface to access network
# network_interface = "eth0"

# By default, the nodes in cluster will update daily, sequetially, starting at 2 AM UTC.
# On a per node basis you can override this with the setting below
# upgrade_schedule = "*-*-* 2:00:00"

# The probe interval in second for the node
# probe_interval = 5

# The default probe amount in msat for the node
# probe_amt_msat = 50000

# The list of targets to probe
probe_targets = []

# The graceful period in seconds when a shutdown signal is received
# shutdown_graceful_sec = 5

'''
'''--- kld/Cargo.toml ---
[package]
name = "kld"
version = "0.3.0"
edition = "2021"

[[bin]]
name = "kld"
path = "src/kld/main.rs"

[[bin]]
name = "kld-cli"
path = "src/cli/main.rs"

[lib]
doctest = false

[dependencies]
lightning = { version = "0.0.121", features = ["max_level_trace", "_test_utils"] }
lightning-block-sync = { version = "0.0.121", features = [ "rpc-client" ] }
lightning-invoice = "0.29.0"
lightning-net-tokio = "0.0.121"
lightning-background-processor = { version = "0.0.121", features = [ "futures" ] }
lightning-rapid-gossip-sync = "0.0.122"
lightning-liquidity = "0.1.0-alpha.2"

macaroon = "0.3.0"
bitcoin = "0.30.2"
bitcoincore-rpc-json = "0.17.0"
bitcoin_hashes = "0.12.0"
chrono = "0.4.37"
base64 = "0.22.0"
bdk = { git = "https://github.com/kuutamolabs/bdk", branch = "0.29.0-allow-begin-match-fail", features = [ "electrum", "all-keys" ] }
anyhow = { version = "1.0.81", features = [ "backtrace" ] }
futures = "0.3"
rand = "0.8.5"
log = { version = "0.4", features = ["std"] }
tokio = { version = "1", features = [ "full" ] }
prometheus = "0.13.2"
hyper = { version = "0.14.27", features = [ "full" ] }
futures-util = { version = "0.3", default-features = false }
serde = { version = "1.0", features = [ "derive" ] }
serde_json = "1.0"
axum = { version = "0.6.20", features = ["ws", "headers"] }
axum-server = { version = "0.5", features = ["tls-rustls"] }
tower-http = { version = "0.4.4", features = [ "cors" ] }
async-trait = "0.1.79"
clap = { version = "4.5", features = ["derive", "env"] }
reqwest = { version = "0.11", features = [ "blocking", "native-tls", "json", "stream", "multipart" ] }
thiserror = "1.0"
uuid = { version = "1.8.0", features = [ "v4", "fast-rng" ] }
time = "0.3.29"
hex = "0.4.3"

# database
bitvec = "1.0.1"
tokio-postgres = { version = "0.7.9", features = ["runtime", "with-bit-vec-0_6", "with-uuid-1", "with-time-0_3"] }
postgres-openssl = "0.5.0"
postgres-types = { version = "0.2.5", features = [ "derive" ] }
openssl = "0.10.64"
refinery = { version = "0.8.14", features = [ "tokio-postgres" ] }

# paperclip generated
tokio-util = { version = "0.7.10", features = ["codec"] }
http = "0.2"
serde_yaml = "0.9"
lazy_static = "1.4"
bytes = "1.6"
mime = { git = "https://github.com/hyperium/mime" }
url = "2.5"
serde_derive = "1"

[dev-dependencies]
test-utils = { path = "../test-utils" }
criterion = { version = "0.5.1", features = ["async_tokio"] }
bincode = "1.3.3"

[build-dependencies]
clap = { version = "4.5", features = ["derive", "env"] }
clap_complete = "4.5"
paperclip = { version = "0.8", features = ["v2", "codegen"] }

'''
'''--- kld/build.rs ---
use clap::CommandFactory;
use paperclip::v2::{
    self,
    codegen::{DefaultEmitter, Emitter, EmitterState},
    models::{DefaultSchema, ResolvableApi},
};

use std::env;
use std::ffi::OsStr;
use std::fs::{read_dir, read_to_string, File, OpenOptions};
use std::io::Write;

use clap_complete::{generate_to, shells::Bash};

include!("src/cli/commands.rs");

fn main() {
    let out_dir = env::var("OUT_DIR").unwrap();
    generate_api(&out_dir);
    patch_api(&out_dir);
    generate_cli_completion(&out_dir);
}

fn generate_cli_completion(out_dir: &String) {
    let mut cmd = KldCliCommand::command();
    let _path = generate_to(Bash, &mut cmd, "kld-cli", out_dir).unwrap();

    println!("cargo:rerun-if-changed=src/cli/commands.rs");
}

fn generate_api(out_dir: &String) {
    let spec_path = "src/api/spec.yaml";

    let fd = File::open(spec_path).expect("spec not found");
    let raw: ResolvableApi<DefaultSchema> =
        v2::from_reader(fd).expect("failed to deserialise spec");
    let schema = raw.resolve().expect("resolution");

    let mut state = EmitterState::default();
    state.mod_prefix = "crate::api::codegen::";
    state.working_dir = out_dir.into();

    let emitter = DefaultEmitter::from(state);
    emitter.generate(&schema).expect("codegen");

    println!("cargo:rerun-if-changed={spec_path}");
}

/// Patch with unsigned integer based types, which are blockchain native
/// Also handle timestamp and user_channel_id types
fn patch_api(out_dir: &String) {
    for entry in read_dir(out_dir)
        .expect("OUT_DIR is expected with cargo build")
        .flatten()
    {
        let path = entry.path();
        if path.extension() == Some(OsStr::new("rs")) {
            let contents = read_to_string(&path).expect("Can not read rust file under OUT_DIR");
            let new = contents
                .replace("user_channel_id: i64", "user_channel_id: u128")
                .replace(
                    "user_channel_id(mut self, value: impl Into<i64>)",
                    "user_channel_id(mut self, value: impl Into<u128>)",
                )
                .replace(
                    "force_close_spend_delay: Option<i64>",
                    "force_close_spend_delay: Option<u16>",
                )
                .replace(
                    "force_close_spend_delay(mut self, value: impl Into<i64>)",
                    "force_close_spend_delay(mut self, value: impl Into<u16>)",
                )
                .replace("cltv_expiry_delta: i64", "cltv_expiry_delta: u16")
                .replace(
                    "cltv_expiry_delta(mut self, value: impl Into<i64>)",
                    "cltv_expiry_delta(mut self, value: impl Into<u16>)",
                )
                .replace("i64", "u64")
                .replace("i32", "u32")
                .replace("_timestamp: u64", "_timestamp: i64")
                .replace("_timestamp: Option<u64>", "_timestamp: Option<i64>")
                .replace(
                    "_timestamp(mut self, value: impl Into<u64>)",
                    "_timestamp(mut self, value: impl Into<i64>)",
                );
            let mut file = OpenOptions::new()
                .write(true)
                .truncate(true)
                .open(path)
                .expect("Can not reopen rust file under OUT_DIR");
            let _ = file
                .write(new.as_bytes())
                .expect("Can not rewrite rust file under OUT_DIR");
        }
    }
}

'''
'''--- kld/src/api/channels.rs ---
use std::collections::HashMap;
use std::str::FromStr;
use std::sync::Arc;

use super::payloads::{
    ChannelFee, FundChannel, FundChannelResponse, SetChannelFee, SetChannelFeeResponse,
};
use crate::api::SocketAddress;
use crate::database::{forward::ForwardStatus, ChannelRecord};
use crate::ldk::htlc_destination_to_string;
use anyhow::Context;
use axum::extract::Path;
use axum::extract::Query;
use axum::{response::IntoResponse, Extension, Json};
use bitcoin::secp256k1::PublicKey;
use lightning::events::HTLCDestination;
use lightning::ln::channelmanager::ChannelDetails;
use lightning::ln::features::ChannelTypeFeatures;
use lightning::ln::ChannelId;
use lightning::util::config::MaxDustHTLCExposure;

use crate::api::bad_request;
use crate::ldk::LightningInterface;
use crate::ldk::PeerStatus;
use crate::to_string_empty;

use super::codegen::get_kld_channel_response::GetKldChannelResponseItem;
use super::codegen::get_v1_channel_history_response::GetV1ChannelHistoryResponseItem;
use super::codegen::get_v1_channel_list_forwards_response::{
    GetV1ChannelListForwardsResponseItem, GetV1ChannelListForwardsResponseItemStatus,
};
use super::codegen::get_v1_channel_list_peer_channels_response::GetV1ChannelListPeerChannelsResponseState;
use super::codegen::get_v1_channel_list_peer_channels_response::{
    GetV1ChannelListPeerChannelsResponse, GetV1ChannelListPeerChannelsResponseOpener,
};
use super::codegen::get_v1_channel_localremotebal_response::GetV1ChannelLocalremotebalResponse;
use super::internal_server;
use super::ApiError;

pub(crate) async fn list_channels(
    Extension(lightning_interface): Extension<Arc<dyn LightningInterface + Send + Sync>>,
) -> Result<impl IntoResponse, ApiError> {
    let mut channels_in_mem = lightning_interface.list_active_channels();
    let channels_in_db = match lightning_interface.list_channels().await {
        Ok(channels) => channels,
        Err(e) => {
            log::error!("error on fetching channel records: {e}");
            lightning_interface.update_channels(&channels_in_mem).await;
            Vec::new()
        }
    };

    let mut response = vec![];

    for ChannelRecord {
        channel_id,
        counterparty,
        open_timestamp,
        update_timestamp,
        closure_reason,
        detail,
    } in channels_in_db
    {
        if let Some(mut detail) = detail {
            let config = detail.config.unwrap_or_default();
            let (config_max_dust_htlc_exposure_is_fixed, config_max_dust_htlc_exposure_value) =
                match config.max_dust_htlc_exposure {
                    MaxDustHTLCExposure::FixedLimitMsat(value) => (true, value),
                    MaxDustHTLCExposure::FeeRateMultiplier(value) => (false, value),
                };

            let mut has_monitor = false;
            let mut is_found = None;
            for (idx, channel) in channels_in_mem.iter().enumerate() {
                // Patch the detail which in memory, these channels are listed from channel manager, and
                // should has channel monitor on it now.
                if channel.channel_id == detail.channel_id {
                    is_found = Some(idx);
                }
            }
            if let Some(idx) = is_found {
                detail = channels_in_mem.remove(idx);
                has_monitor = true;
            }

            response.push(GetKldChannelResponseItem {
                channel_id: hex::encode(detail.channel_id.0),
                counterparty_node_id: detail.counterparty.node_id.to_string(),
                counterparty_unspendable_punishment_reserve: detail
                    .counterparty
                    .unspendable_punishment_reserve,
                counterparty_outbound_htlc_minimum_msat: detail
                    .counterparty
                    .outbound_htlc_minimum_msat,
                counterparty_outbound_htlc_maximum_msat: detail
                    .counterparty
                    .outbound_htlc_maximum_msat,
                funding_txo: detail
                    .funding_txo
                    .map(|txo| format!("{}:{}", txo.txid, txo.index))
                    .unwrap_or_default(),
                features: detail.channel_type.map(format_features).unwrap_or_default(),
                short_channel_id: detail.short_channel_id,
                outbound_scid_alias: detail.outbound_scid_alias,
                inbound_scid_alias: detail.inbound_scid_alias,
                channel_value_satoshis: detail.channel_value_satoshis,
                unspendable_punishment_reserve: detail.unspendable_punishment_reserve,
                user_channel_id: detail.user_channel_id,
                feerate_sat_per_1000_weight: detail.feerate_sat_per_1000_weight,
                balance_msat: detail.balance_msat,
                outbound_capacity_msat: detail.outbound_capacity_msat,
                next_outbound_htlc_limit_msat: detail.next_outbound_htlc_limit_msat,
                next_outbound_htlc_minimum_msat: detail.next_outbound_htlc_minimum_msat,
                inbound_capacity_msat: detail.inbound_capacity_msat,
                confirmations_required: detail.confirmations_required,
                confirmations: detail.confirmations,
                force_close_spend_delay: detail.force_close_spend_delay,
                is_outbound: detail.is_outbound,
                is_channel_ready: detail.is_channel_ready,
                channel_shutdown_state: detail.channel_shutdown_state.map(|s| format!("{s:?}")),
                is_usable: detail.is_usable,
                is_public: detail.is_public,
                inbound_htlc_minimum_msat: detail.inbound_htlc_minimum_msat,
                inbound_htlc_maximum_msat: detail.inbound_htlc_maximum_msat,
                config_forwarding_fee_proportional_millionths: config
                    .forwarding_fee_proportional_millionths,
                config_forwarding_fee_base_msat: config.forwarding_fee_base_msat,
                config_cltv_expiry_delta: config.cltv_expiry_delta,
                config_max_dust_htlc_exposure_is_fixed,
                config_max_dust_htlc_exposure_value,
                config_force_close_avoidance_max_fee_satoshis: config
                    .force_close_avoidance_max_fee_satoshis,
                config_accept_underpaying_htlcs: config.accept_underpaying_htlcs,
                has_monitor,
                open_timestamp: open_timestamp.unix_timestamp(),
                update_timestamp: update_timestamp.unix_timestamp(),
                closure_reason,
            });
        } else {
            response.push(GetKldChannelResponseItem {
                channel_id,
                counterparty_node_id: counterparty,
                open_timestamp: open_timestamp.unix_timestamp(),
                update_timestamp: update_timestamp.unix_timestamp(),
                closure_reason,
                ..Default::default()
            });
        }
    }
    // log error if any channel not exist in the DB
    for detail in channels_in_mem.into_iter() {
        log::error!(
            "Channel miss from DB, channel: {}, funding_txo: {}",
            hex::encode(detail.channel_id.0),
            detail
                .funding_txo
                .map(|txo| format!("{}:{}", txo.txid, txo.index))
                .unwrap_or_default(),
        );
        let config = detail.config.unwrap_or_default();
        let (config_max_dust_htlc_exposure_is_fixed, config_max_dust_htlc_exposure_value) =
            match config.max_dust_htlc_exposure {
                MaxDustHTLCExposure::FixedLimitMsat(value) => (true, value),
                MaxDustHTLCExposure::FeeRateMultiplier(value) => (false, value),
            };
        response.push(GetKldChannelResponseItem {
            channel_id: hex::encode(detail.channel_id.0),
            counterparty_node_id: detail.counterparty.node_id.to_string(),
            counterparty_unspendable_punishment_reserve: detail
                .counterparty
                .unspendable_punishment_reserve,
            counterparty_outbound_htlc_minimum_msat: detail.counterparty.outbound_htlc_minimum_msat,
            counterparty_outbound_htlc_maximum_msat: detail.counterparty.outbound_htlc_maximum_msat,
            funding_txo: detail
                .funding_txo
                .map(|txo| format!("{}:{}", txo.txid, txo.index))
                .unwrap_or_default(),
            features: detail.channel_type.map(format_features).unwrap_or_default(),
            short_channel_id: detail.short_channel_id,
            outbound_scid_alias: detail.outbound_scid_alias,
            inbound_scid_alias: detail.inbound_scid_alias,
            channel_value_satoshis: detail.channel_value_satoshis,
            unspendable_punishment_reserve: detail.unspendable_punishment_reserve,
            user_channel_id: detail.user_channel_id,
            feerate_sat_per_1000_weight: detail.feerate_sat_per_1000_weight,
            balance_msat: detail.balance_msat,
            outbound_capacity_msat: detail.outbound_capacity_msat,
            next_outbound_htlc_limit_msat: detail.next_outbound_htlc_limit_msat,
            next_outbound_htlc_minimum_msat: detail.next_outbound_htlc_minimum_msat,
            inbound_capacity_msat: detail.inbound_capacity_msat,
            confirmations_required: detail.confirmations_required,
            confirmations: detail.confirmations,
            force_close_spend_delay: detail.force_close_spend_delay,
            is_outbound: detail.is_outbound,
            is_channel_ready: detail.is_channel_ready,
            channel_shutdown_state: detail.channel_shutdown_state.map(|s| format!("{s:?}")),
            is_usable: detail.is_usable,
            is_public: detail.is_public,
            inbound_htlc_minimum_msat: detail.inbound_htlc_minimum_msat,
            inbound_htlc_maximum_msat: detail.inbound_htlc_maximum_msat,
            config_forwarding_fee_proportional_millionths: config
                .forwarding_fee_proportional_millionths,
            config_forwarding_fee_base_msat: config.forwarding_fee_base_msat,
            config_cltv_expiry_delta: config.cltv_expiry_delta,
            config_max_dust_htlc_exposure_is_fixed,
            config_max_dust_htlc_exposure_value,
            config_force_close_avoidance_max_fee_satoshis: config
                .force_close_avoidance_max_fee_satoshis,
            config_accept_underpaying_htlcs: config.accept_underpaying_htlcs,
            has_monitor: true,
            open_timestamp: 0,
            update_timestamp: 0,
            closure_reason: Some("** Invalid Channel Record **".into()),
        });
    }
    Ok(Json(response))
}

pub(crate) async fn list_peer_channels(
    Extension(lightning_interface): Extension<Arc<dyn LightningInterface + Send + Sync>>,
) -> Result<impl IntoResponse, ApiError> {
    let peers = lightning_interface
        .list_peers()
        .await
        .map_err(internal_server)?;

    let channels = lightning_interface.list_active_channels();
    let mut response = vec![];
    for channel in channels {
        let config = channel
            .config
            .context("expected channel config")
            .map_err(internal_server)?;

        response.push(GetV1ChannelListPeerChannelsResponse {
            alias: lightning_interface
                .alias_of(&channel.counterparty.node_id)
                .unwrap_or_default(),
            channel_id: hex::encode(channel.channel_id.0),
            dust_limit_msat: match config.max_dust_htlc_exposure {
                MaxDustHTLCExposure::FixedLimitMsat(x) => x,
                MaxDustHTLCExposure::FeeRateMultiplier(x) => x,
            },
            features: channel
                .channel_type
                .map(format_features)
                .unwrap_or_default(),
            fee_base_msat: config.forwarding_fee_base_msat,
            fee_proportional_millionths: config.forwarding_fee_proportional_millionths,
            funding: None,
            funding_txid: channel.funding_txo.map(|x| x.txid.to_string()),
            htlcs: None,
            opener: if channel.is_outbound {
                GetV1ChannelListPeerChannelsResponseOpener::Local
            } else {
                GetV1ChannelListPeerChannelsResponseOpener::Remote
            },
            peer_connected: peers
                .iter()
                .find(|p| p.public_key == channel.counterparty.node_id)
                .map(|p| p.status == PeerStatus::Connected)
                .unwrap_or_default(),
            peer_id: channel.counterparty.node_id.to_string(),
            private: !channel.is_public,
            receivable_msat: channel.inbound_capacity_msat,
            short_channel_id: channel.short_channel_id.map(|x| x.to_string()),
            spendable_msat: channel.outbound_capacity_msat,
            state: if channel.is_usable {
                GetV1ChannelListPeerChannelsResponseState::ChanneldNormal
            } else {
                GetV1ChannelListPeerChannelsResponseState::Openingd
            },
            our_reserve_msat: channel.unspendable_punishment_reserve.map(|x| x * 1000),
            their_reserve_msat: (channel.counterparty.unspendable_punishment_reserve * 1000),
            to_them_msat: ((channel.channel_value_satoshis * 1000) - channel.balance_msat),
            minimum_htlc_in_msat: channel.inbound_htlc_minimum_msat,
            max_total_htlc_in_msat: channel.inbound_htlc_maximum_msat,
            minimum_htlc_out_msat: channel.next_outbound_htlc_minimum_msat,
            maximum_htlc_out_msat: channel.next_outbound_htlc_limit_msat,
            to_us_msat: channel.balance_msat,
            total_msat: channel.channel_value_satoshis * 1000,
        })
    }
    Ok(Json(response))
}

pub(crate) async fn open_channel(
    Extension(lightning_interface): Extension<Arc<dyn LightningInterface + Send + Sync>>,
    Json(fund_channel): Json<FundChannel>,
) -> Result<impl IntoResponse, ApiError> {
    let (public_key, net_address) = match fund_channel.id.split_once('@') {
        Some((public_key, net_address)) => (
            PublicKey::from_str(public_key).map_err(bad_request)?,
            Some(net_address.parse::<SocketAddress>().map_err(bad_request)?),
        ),
        None => (
            PublicKey::from_str(&fund_channel.id).map_err(bad_request)?,
            None,
        ),
    };
    lightning_interface
        .connect_peer(public_key, net_address)
        .await
        .map_err(internal_server)?;

    let value = fund_channel.satoshis.parse::<u64>().map_err(bad_request)?;
    let push_msat = fund_channel
        .push_msat
        .map(|x| x.parse::<u64>())
        .transpose()
        .map_err(bad_request)?;

    let mut user_config = lightning_interface.user_config();
    if let Some(announce) = fund_channel.announce {
        user_config.channel_handshake_config.announced_channel = announce;
    }

    let result = lightning_interface
        .open_channel(
            public_key,
            value,
            push_msat,
            fund_channel.fee_rate,
            Some(user_config),
        )
        .await
        .map_err(internal_server)?;

    let response = FundChannelResponse {
        tx: result.transaction,
        txid: result.txid.to_string(),
        channel_id: hex::encode(result.channel_id.0),
    };
    Ok(Json(response))
}

pub(crate) async fn set_channel_fee(
    Extension(lightning_interface): Extension<Arc<dyn LightningInterface + Send + Sync>>,
    Json(channel_fee): Json<ChannelFee>,
) -> Result<impl IntoResponse, ApiError> {
    let mut updated_channels = vec![];

    if channel_fee.id == "all" {
        let mut peer_channels: HashMap<PublicKey, Vec<ChannelDetails>> = HashMap::new();
        for channel in lightning_interface.list_active_channels() {
            if let Some(channel_ids) = peer_channels.get_mut(&channel.counterparty.node_id) {
                channel_ids.push(channel);
            } else {
                peer_channels.insert(channel.counterparty.node_id, vec![channel]);
            }
        }
        for (node_id, channels) in peer_channels {
            let channel_ids: Vec<ChannelId> = channels.iter().map(|c| c.channel_id).collect();
            let (base, ppm) = lightning_interface
                .set_channel_fee(&node_id, &channel_ids, channel_fee.ppm, channel_fee.base)
                .map_err(internal_server)?;
            for channel in channels {
                updated_channels.push(SetChannelFee {
                    base,
                    ppm,
                    peer_id: node_id.to_string(),
                    channel_id: hex::encode(channel.channel_id.0),
                    short_channel_id: to_string_empty!(channel.short_channel_id),
                });
            }
        }
    } else if let Some(channel) = lightning_interface.list_active_channels().iter().find(|c| {
        hex::encode(c.channel_id.0) == channel_fee.id
            || c.short_channel_id.unwrap_or_default().to_string() == channel_fee.id
    }) {
        let (base, ppm) = lightning_interface
            .set_channel_fee(
                &channel.counterparty.node_id,
                &[channel.channel_id],
                channel_fee.ppm,
                channel_fee.base,
            )
            .map_err(internal_server)?;
        updated_channels.push(SetChannelFee {
            base,
            ppm,
            peer_id: channel.counterparty.node_id.to_string(),
            channel_id: hex::encode(channel.channel_id.0),
            short_channel_id: to_string_empty!(channel.short_channel_id),
        });
    } else {
        return Err(ApiError::NotFound(channel_fee.id));
    }

    Ok(Json(SetChannelFeeResponse(updated_channels)))
}

pub(crate) async fn close_channel(
    Extension(lightning_interface): Extension<Arc<dyn LightningInterface + Send + Sync>>,
    Path(channel_id): Path<String>,
) -> Result<impl IntoResponse, ApiError> {
    if let Some(channel) = lightning_interface.list_active_channels().iter().find(|c| {
        hex::encode(c.channel_id.0) == channel_id
            || c.short_channel_id.unwrap_or_default().to_string() == channel_id
    }) {
        lightning_interface
            .close_channel(&channel.channel_id, &channel.counterparty.node_id, None)
            .await
            .map_err(internal_server)?;
        Ok(Json(()))
    } else {
        Err(ApiError::NotFound(channel_id))
    }
}

pub(crate) async fn close_channel_with_fee(
    Extension(lightning_interface): Extension<Arc<dyn LightningInterface + Send + Sync>>,
    Path(channel_id): Path<String>,
    Path(fee_rate): Path<u32>,
) -> Result<impl IntoResponse, ApiError> {
    if let Some(channel) = lightning_interface.list_active_channels().iter().find(|c| {
        hex::encode(c.channel_id.0) == channel_id
            || c.short_channel_id.unwrap_or_default().to_string() == channel_id
    }) {
        lightning_interface
            .close_channel(
                &channel.channel_id,
                &channel.counterparty.node_id,
                Some(fee_rate),
            )
            .await
            .map_err(internal_server)?;
        Ok(Json(()))
    } else {
        Err(ApiError::NotFound(channel_id))
    }
}

pub(crate) async fn force_close_channel_with_broadcast(
    Extension(lightning_interface): Extension<Arc<dyn LightningInterface + Send + Sync>>,
    Path(channel_id): Path<String>,
) -> Result<impl IntoResponse, ApiError> {
    if let Some(channel) = lightning_interface.list_active_channels().iter().find(|c| {
        hex::encode(c.channel_id.0) == channel_id
            || c.short_channel_id.unwrap_or_default().to_string() == channel_id
    }) {
        lightning_interface
            .force_close_channel(&channel.channel_id, &channel.counterparty.node_id, true)
            .await
            .map_err(internal_server)?;
        Ok(Json(()))
    } else {
        Err(ApiError::NotFound(channel_id))
    }
}

pub(crate) async fn force_close_channel_without_broadcast(
    Extension(lightning_interface): Extension<Arc<dyn LightningInterface + Send + Sync>>,
    Path(channel_id): Path<String>,
) -> Result<impl IntoResponse, ApiError> {
    if let Some(channel) = lightning_interface.list_active_channels().iter().find(|c| {
        hex::encode(c.channel_id.0) == channel_id
            || c.short_channel_id.unwrap_or_default().to_string() == channel_id
    }) {
        lightning_interface
            .force_close_channel(&channel.channel_id, &channel.counterparty.node_id, false)
            .await
            .map_err(internal_server)?;
        Ok(Json(()))
    } else {
        Err(ApiError::NotFound(channel_id))
    }
}

pub(crate) async fn local_remote_balance(
    Extension(lightning_interface): Extension<Arc<dyn LightningInterface + Send + Sync>>,
) -> Result<impl IntoResponse, ApiError> {
    let mut local_msat = 0;
    let mut remote_msat = 0;
    let mut pending_msat = 0;
    let mut inactive_msat = 0;
    for channel in lightning_interface.list_active_channels() {
        if channel.is_usable {
            local_msat += channel.balance_msat;
            remote_msat += (channel.channel_value_satoshis * 1000) - channel.balance_msat;
        } else if channel.is_channel_ready {
            inactive_msat += channel.balance_msat;
        } else {
            pending_msat += channel.balance_msat;
        }
    }
    Ok(Json(GetV1ChannelLocalremotebalResponse {
        inactive_balance: inactive_msat / 1000,
        pending_balance: pending_msat / 1000,
        local_balance: local_msat / 1000,
        remote_balance: remote_msat / 1000,
    }))
}

// Paperclip generates an enum but we need a struct to work with axum so have to make query params this way for now.
#[derive(Serialize, Deserialize)]
pub struct ListForwardsQueryParams {
    pub status: Option<GetV1ChannelListForwardsResponseItemStatus>,
}

pub(crate) async fn list_forwards(
    Extension(lightning_interface): Extension<Arc<dyn LightningInterface + Send + Sync>>,
    Query(params): Query<ListForwardsQueryParams>,
) -> Result<impl IntoResponse, ApiError> {
    let status = match params.status {
        None => None,
        Some(GetV1ChannelListForwardsResponseItemStatus::Settled) => Some(ForwardStatus::Succeeded),
        Some(GetV1ChannelListForwardsResponseItemStatus::Offered) => Some(ForwardStatus::Succeeded),
        _ => Some(ForwardStatus::Failed),
    };
    let mut response = vec![];
    for forward in lightning_interface
        .fetch_forwards(status)
        .await
        .map_err(internal_server)?
    {
        response.push(GetV1ChannelListForwardsResponseItem {
            failcode: match forward.htlc_destination {
                Some(HTLCDestination::NextHopChannel {
                    node_id: _,
                    channel_id: _,
                }) => Some("NextHopChannel".to_string()),
                Some(HTLCDestination::UnknownNextHop {
                    requested_forward_scid: _,
                }) => Some("UnknownNextHop".to_string()),
                Some(HTLCDestination::InvalidForward {
                    requested_forward_scid: _,
                }) => Some("InvalidFormat".to_string()),
                Some(HTLCDestination::FailedPayment { payment_hash: _ }) => {
                    Some("FailedPayment".to_string())
                }
                None => None,
            },
            failreason: forward
                .htlc_destination
                .as_ref()
                .map(htlc_destination_to_string),
            fee_msat: forward.fee,
            in_channel: hex::encode(forward.inbound_channel_id.0),
            in_msat: forward.amount,
            out_channel: forward.outbound_channel_id.map(|x| hex::encode(x.0)),
            out_msat: forward.amount.and_then(|a| forward.fee.map(|f| a - f)),
            payment_hash: match forward.htlc_destination {
                Some(HTLCDestination::FailedPayment { payment_hash }) => {
                    Some(hex::encode(payment_hash.0))
                }
                _ => None,
            },
            received_timestamp: forward.timestamp.unix_timestamp(),
            resolved_timestamp: Some(forward.timestamp.unix_timestamp()),
            status: match forward.status {
                ForwardStatus::Succeeded => GetV1ChannelListForwardsResponseItemStatus::Settled,
                ForwardStatus::Failed => GetV1ChannelListForwardsResponseItemStatus::Failed,
            },
        });
    }

    Ok(Json(response))
}

pub(crate) async fn channel_history(
    Extension(lightning_interface): Extension<Arc<dyn LightningInterface + Send + Sync>>,
) -> Result<impl IntoResponse, ApiError> {
    let channel_history = lightning_interface
        .channel_history()
        .await
        .map_err(internal_server)?;

    let mut response = vec![];

    for ChannelRecord {
        open_timestamp,
        update_timestamp,
        closure_reason,
        detail,
        ..
    } in channel_history
    {
        if let Some(detail) = detail {
            response.push(GetV1ChannelHistoryResponseItem {
                close_timestamp: update_timestamp.unix_timestamp(),
                closure_reason: closure_reason.unwrap_or_default(),
                counterparty: detail.counterparty.node_id.to_string(),
                funding_txo: detail
                    .funding_txo
                    .map(|txo| format!("{}:{}", txo.txid, txo.index))
                    .unwrap_or_default(),
                id: hex::encode(detail.channel_id.0),
                is_outbound: detail.is_outbound,
                is_public: detail.is_public,
                open_timestamp: open_timestamp.unix_timestamp(),
                scid: detail.short_channel_id.unwrap_or_default(),
                user_channel_id: detail.user_channel_id,
                value: detail.channel_value_satoshis,
            });
        }
    }

    Ok(Json(response))
}

fn format_features(channel_type: ChannelTypeFeatures) -> Vec<String> {
    channel_type
        .to_string()
        .split(", ")
        .filter_map(|feature| {
            let (k, v) = feature.split_once(": ")?;
            match v {
                "supported" => Some(format!("supported {k}")),
                "required" => Some(format!("required {k}")),
                _ => None,
            }
        })
        .collect()
}

'''
'''--- kld/src/api/invoices.rs ---
use std::{
    str::FromStr,
    sync::Arc,
    time::{SystemTime, UNIX_EPOCH},
};

use super::payloads::{GenerateInvoice, GenerateInvoiceResponse, Invoice, InvoiceStatus};
use anyhow::anyhow;
use axum::{
    extract::{Path, Query},
    response::IntoResponse,
    Extension, Json,
};
use lightning_invoice::{Bolt11Invoice, Bolt11InvoiceDescription};

use super::{
    codegen::get_v1_utility_decode_invoice_string_response::{
        GetV1UtilityDecodeInvoiceStringResponse, GetV1UtilityDecodeInvoiceStringResponseType,
    },
    empty_string_as_none,
};
use crate::{ldk::LightningInterface, MillisatAmount};

use super::{bad_request, internal_server, ApiError};

pub(crate) async fn generate_invoice(
    Extension(lightning_interface): Extension<Arc<dyn LightningInterface + Send + Sync>>,
    Json(invoice_request): Json<GenerateInvoice>,
) -> Result<impl IntoResponse, ApiError> {
    if invoice_request.label.len() > 100 {
        return Err(bad_request(anyhow!("Label max length is 100 chars")));
    }
    let invoice = lightning_interface
        .generate_invoice(
            invoice_request.label,
            Some(invoice_request.amount),
            invoice_request.description,
            invoice_request.expiry,
        )
        .await
        .map_err(internal_server)?;

    let response = GenerateInvoiceResponse {
        payment_hash: invoice.bolt11.to_string(),
        expires_at: invoice
            .bolt11
            .expires_at()
            .ok_or_else(|| bad_request(anyhow!("expiry is too far in the future")))?
            .as_secs() as u32,
        bolt11: invoice.bolt11.to_string(),
    };
    Ok(Json(response))
}

#[derive(Serialize, Deserialize)]
#[serde(rename_all = "camelCase")]
pub struct ListInvoiceParams {
    #[serde(default, deserialize_with = "empty_string_as_none")]
    pub label: Option<String>,
}

pub(crate) async fn list_invoices(
    Extension(lightning_interface): Extension<Arc<dyn LightningInterface + Send + Sync>>,
    Query(params): Query<ListInvoiceParams>,
) -> Result<impl IntoResponse, ApiError> {
    if let Some(label) = &params.label {
        if label.len() > 100 {
            return Err(bad_request(anyhow!("Label max length is 100 chars")));
        }
    }
    let mut response = vec![];
    let invoices = lightning_interface
        .list_invoices(params.label)
        .await
        .map_err(internal_server)?;
    for invoice in invoices {
        let description = match invoice.bolt11.description() {
            lightning_invoice::Bolt11InvoiceDescription::Direct(d) => d.to_string(),
            lightning_invoice::Bolt11InvoiceDescription::Hash(h) => hex::encode(h.0),
        };
        let amount_received_msat = invoice
            .payments
            .iter()
            .fold(MillisatAmount::default(), |sum, p| sum + p.amount);
        let status = if !invoice.payments.is_empty() {
            InvoiceStatus::Paid
        } else if invoice.bolt11.expiry_time()
            > SystemTime::now()
                .duration_since(UNIX_EPOCH)
                .map_err(internal_server)?
        {
            InvoiceStatus::Expired
        } else {
            InvoiceStatus::Unpaid
        };
        response.push(Invoice {
            label: invoice.label,
            bolt11: invoice.bolt11.to_string(),
            payment_hash: hex::encode(invoice.bolt11.payment_hash()),
            amount_msat: invoice.bolt11.amount_milli_satoshis(),
            status,
            amount_received_msat: if amount_received_msat > 0 {
                Some(amount_received_msat)
            } else {
                None
            },
            paid_at: invoice
                .payments
                .first()
                .map(|p| p.timestamp.unix_timestamp() as u32),
            description,
            expires_at: invoice.bolt11.expires_at().map(|d| d.as_secs()),
        });
    }
    Ok(Json(response))
}

pub(crate) async fn decode_invoice(
    Path(maybe_invoice): Path<String>,
) -> Result<impl IntoResponse, ApiError> {
    if let Ok(bolt11) = Bolt11Invoice::from_str(&maybe_invoice) {
        return Ok(Json(GetV1UtilityDecodeInvoiceStringResponse {
            type_: GetV1UtilityDecodeInvoiceStringResponseType::Bolt11,
            valid: bolt11.check_signature().is_ok(),
            amount_msat: bolt11.amount_milli_satoshis(),
            created_at: Some(
                bolt11
                    .timestamp()
                    .duration_since(UNIX_EPOCH)
                    .map_err(bad_request)?
                    .as_secs(),
            ),
            currency: Some(bolt11.currency().to_string()),
            description: match bolt11.description() {
                Bolt11InvoiceDescription::Direct(direct) => Some(direct.to_string()),
                Bolt11InvoiceDescription::Hash(hash) => Some(hash.0.to_string()),
            },
            expiry: Some(bolt11.expiry_time().as_secs()),
            min_final_cltv_expiry: Some(bolt11.min_final_cltv_expiry_delta()),
            payee: bolt11.payee_pub_key().map(|pk| pk.to_string()),
            payment_hash: Some(bolt11.payment_hash().to_string()),
            signature: Some(
                bolt11
                    .into_signed_raw()
                    .signature()
                    .to_standard()
                    .to_string(),
            ),
        }));
    }
    Err(bad_request(anyhow!("Invoice could not be decoded")))
}

'''
'''--- kld/src/api/macaroon_auth.rs ---
use base64::{engine::general_purpose, Engine};
use bitcoin::hashes::hex::FromHex;
use hyper::header;
#[cfg(not(test))]
use std::fs;
use std::sync::Arc;
#[cfg(test)]
use test_utils::fake_fs as fs;

use anyhow::Result;
use axum::{
    async_trait,
    extract::FromRequestParts,
    http::{request::Parts, Request, StatusCode},
    middleware::Next,
    response::IntoResponse,
    Extension,
};
use macaroon::{ByteString, Macaroon, MacaroonKey, Verifier};

use super::{unauthorized, ApiError};

pub struct MacaroonAuth {
    key: MacaroonKey,
}

impl MacaroonAuth {
    pub fn init(seed: &[u8; 32], data_dir: &str) -> Result<MacaroonAuth> {
        macaroon::initialize()?;
        let key = MacaroonKey::generate(seed);

        let admin_macaroon = Self::admin_macaroon(&key)?;
        let readonly_macaroon = Self::readonly_macaroon(&key)?;

        let mut buf = vec![];
        let base64 = admin_macaroon.serialize(macaroon::Format::V2)?;
        general_purpose::URL_SAFE.decode_vec(base64, &mut buf)?;

        fs::create_dir_all(format!("{data_dir}/macaroons"))?;
        // access.macaroon is compatible with CLN
        fs::write(format!("{data_dir}/macaroons/access.macaroon"), &buf)?;
        // admin.macaroon is compatible with LND
        fs::write(
            format!("{data_dir}/macaroons/admin.macaroon"),
            admin_macaroon.serialize(macaroon::Format::V2)?,
        )?;
        fs::write(
            format!("{data_dir}/macaroons/readonly.macaroon"),
            readonly_macaroon.serialize(macaroon::Format::V2)?,
        )?;

        Ok(MacaroonAuth { key })
    }

    pub fn verify_admin_macaroon(&self, macaroon: &Macaroon) -> Result<()> {
        let mut verifier = Verifier::default();
        verifier.satisfy_general(|caveat| verify_role(caveat, "admin"));
        Ok(verifier.verify(macaroon, &self.key, vec![])?)
    }

    pub fn verify_readonly_macaroon(&self, macaroon: &Macaroon) -> Result<()> {
        let mut verifier = Verifier::default();
        verifier.satisfy_general(|caveat| verify_role(caveat, "readonly"));
        Ok(verifier.verify(macaroon, &self.key, vec![])?)
    }

    fn admin_macaroon(key: &MacaroonKey) -> Result<Macaroon> {
        let mut macaroon = Macaroon::create(None, key, "admin".into())?;
        macaroon.add_first_party_caveat("roles = admin|readonly".into());
        Ok(macaroon)
    }

    fn readonly_macaroon(key: &MacaroonKey) -> Result<Macaroon> {
        let mut macaroon = Macaroon::create(None, key, "readonly".into())?;
        macaroon.add_first_party_caveat("roles = readonly".into());
        Ok(macaroon)
    }
}

fn verify_role(caveat: &ByteString, expected_role: &str) -> bool {
    if !caveat.0.starts_with(b"roles = ") {
        return false;
    }
    let strcaveat = match std::str::from_utf8(&caveat.0) {
        Ok(s) => s,
        Err(_) => return false,
    };

    strcaveat[8..].split('|').any(|r| r == expected_role)
}

pub async fn admin_auth<B>(
    macaroon: KldMacaroon,
    Extension(macaroon_auth): Extension<Arc<MacaroonAuth>>,
    request: Request<B>,
    next: Next<B>,
) -> Result<impl IntoResponse, ApiError> {
    macaroon_auth
        .verify_admin_macaroon(&macaroon.0)
        .map_err(unauthorized)?;
    Ok(next.run(request).await)
}

pub async fn readonly_auth<B>(
    macaroon: KldMacaroon,
    Extension(macaroon_auth): Extension<Arc<MacaroonAuth>>,
    request: Request<B>,
    next: Next<B>,
) -> Result<impl IntoResponse, ApiError> {
    macaroon_auth
        .verify_readonly_macaroon(&macaroon.0)
        .map_err(unauthorized)?;
    Ok(next.run(request).await)
}

pub struct KldMacaroon(pub Macaroon);

#[async_trait]
impl<S> FromRequestParts<S> for KldMacaroon
where
    S: Send + Sync,
{
    type Rejection = (StatusCode, &'static str);

    // May as well try to decode both base64 and hex macaroons.
    async fn from_request_parts(parts: &mut Parts, _state: &S) -> Result<Self, Self::Rejection> {
        let deserialize_err = (StatusCode::UNAUTHORIZED, "Unable to deserialize macaroon");

        let value = if let Some(value) = parts.headers.get(header::SEC_WEBSOCKET_PROTOCOL) {
            value
                .to_str()
                .map_err(|_| deserialize_err)?
                .split_once(',')
                .map(|s| s.0)
                .unwrap_or_default()
        } else {
            parts
                .headers
                .get("macaroon")
                .or_else(|| parts.headers.get("Grpc-Metadata-macaroon"))
                .ok_or((StatusCode::UNAUTHORIZED, "Missing macaroon header"))?
                .to_str()
                .map_err(|_| deserialize_err)?
        };

        let macaroon = Macaroon::deserialize(value).map(KldMacaroon);

        if macaroon.is_err() {
            if let Ok(bytes) = Vec::<u8>::from_hex(value) {
                if let Ok(macaroon) = Macaroon::deserialize_binary(&bytes).map(KldMacaroon) {
                    return Ok(macaroon);
                }
            }
        }

        macaroon.map_err(|_| deserialize_err)
    }
}

#[test]
fn test_readonly_macaroon() {
    let macaroon_auth = MacaroonAuth::init(&[3u8; 32], "").unwrap();
    let readonly_macaroon = MacaroonAuth::readonly_macaroon(&macaroon_auth.key).unwrap();

    macaroon_auth
        .verify_readonly_macaroon(&readonly_macaroon)
        .unwrap();
}

#[test]
fn test_admin_macaroon() {
    let macaroon_auth = MacaroonAuth::init(&[3u8; 32], "").unwrap();
    let admin_macaroon = MacaroonAuth::admin_macaroon(&macaroon_auth.key).unwrap();

    macaroon_auth
        .verify_admin_macaroon(&admin_macaroon)
        .unwrap();
}

'''
'''--- kld/src/api/mod.rs ---
mod channels;
mod invoices;
mod macaroon_auth;
mod network;
pub mod payloads;
mod payments;
mod peers;
pub mod routes;
mod skt_addr;
mod utility;
mod wallet;
mod ws;

pub use skt_addr::SocketAddress;

pub use macaroon_auth::{KldMacaroon, MacaroonAuth};
use serde::{Deserialize, Deserializer};
use serde_json::json;

use self::utility::get_info;
use crate::{
    api::{
        channels::{
            channel_history, close_channel, close_channel_with_fee,
            force_close_channel_with_broadcast, force_close_channel_without_broadcast,
            list_channels, list_forwards, list_peer_channels, local_remote_balance, open_channel,
            set_channel_fee,
        },
        invoices::{decode_invoice, generate_invoice, list_invoices},
        macaroon_auth::{admin_auth, readonly_auth},
        network::{
            fee_rates, get_network_channel, get_network_node, list_network_channels,
            list_network_nodes,
        },
        payments::{keysend, list_payments, pay_invoice},
        peers::{connect_peer, disconnect_peer, list_peers},
        utility::{estimate_channel_liquidity_range, get_fees, score, sign},
        wallet::{get_balance, list_funds, new_address, transfer},
        ws::ws_handler,
    },
    bitcoind::bitcoind_interface::BitcoindInterface,
    ldk::LightningInterface,
    wallet::WalletInterface,
};
use anyhow::{Context, Result};
use axum::{
    extract::Extension,
    middleware::from_fn,
    response::{IntoResponse, Response},
    routing::{delete, get, post},
    Json, Router,
};
use axum_server::{
    tls_rustls::{RustlsAcceptor, RustlsConfig},
    Handle, Server,
};
use futures::{future::Shared, Future};
use hyper::StatusCode;
use log::{error, info, warn};
use std::{net::SocketAddr, str::FromStr, sync::Arc, time::Duration};
use tower_http::cors::CorsLayer;

pub const API_VERSION: &str = env!("CARGO_PKG_VERSION");

pub struct RestApi {
    server: Server<RustlsAcceptor>,
}

pub async fn bind_api_server(listen_address: String, certs_dir: String) -> Result<RestApi> {
    let rustls_config = config(&certs_dir)
        .await
        .context("failed to load tls configuration")?;
    let addr = listen_address.parse()?;
    info!("Starting REST API on {addr}");
    Ok(RestApi {
        server: axum_server::bind_rustls(addr, rustls_config),
    })
}

impl RestApi {
    pub async fn serve(
        self,
        bitcoind_api: Arc<dyn BitcoindInterface + Send + Sync>,
        lightning_api: Arc<dyn LightningInterface + Send + Sync>,
        wallet_api: Arc<dyn WalletInterface + Send + Sync>,
        macaroon_auth: Arc<MacaroonAuth>,
        quit_signal: Shared<impl Future<Output = ()>>,
    ) -> Result<()> {
        let cors = CorsLayer::permissive();
        let handle = Handle::new();
        let readonly_routes = Router::new()
            .route(routes::ROOT, get(root))
            .route(routes::GET_INFO, get(get_info))
            .route(
                routes::ESTIMATE_CHANNEL_LIQUIDITY,
                get(estimate_channel_liquidity_range),
            )
            .route(routes::GET_BALANCE, get(get_balance))
            .route(routes::LIST_FUNDS, get(list_funds))
            .route(routes::LIST_PEER_CHANNELS, get(list_peer_channels))
            .route(routes::LIST_PEERS, get(list_peers))
            .route(routes::LIST_NETWORK_NODE, get(get_network_node))
            .route(routes::LIST_NETWORK_NODES, get(list_network_nodes))
            .route(routes::LIST_NETWORK_CHANNEL, get(get_network_channel))
            .route(routes::LIST_NETWORK_CHANNELS, get(list_network_channels))
            .route(routes::FEE_RATES, get(fee_rates))
            .route(routes::LIST_INVOICES, get(list_invoices))
            .route(routes::LIST_PAYMENTS, get(list_payments))
            .route(routes::LOCAL_REMOTE_BALANCE, get(local_remote_balance))
            .route(routes::GET_FEES, get(get_fees))
            .route(routes::LIST_FORWARDS, get(list_forwards))
            .route(routes::LIST_CHANNEL_HISTORY, get(channel_history))
            .route(routes::LIST_CHANNELS, get(list_channels))
            .route(routes::DECODE_INVOICE, get(decode_invoice))
            .route(routes::SCORER, get(score))
            .layer(from_fn(readonly_auth));

        let admin_routes = Router::new()
            .route(routes::SIGN, post(sign))
            .route(routes::OPEN_CHANNEL, post(open_channel))
            .route(routes::SET_CHANNEL_FEE, post(set_channel_fee))
            .route(routes::CLOSE_CHANNEL, delete(close_channel))
            .route(
                routes::CLOSE_CHANNEL_WITH_FEE,
                delete(close_channel_with_fee),
            )
            .route(
                routes::FORCE_CLOSE_CHANNEL_WITH_BROADCAST,
                delete(force_close_channel_with_broadcast),
            )
            .route(
                routes::FORCE_CLOSE_CHANNEL_WITHOUT_BROADCAST,
                delete(force_close_channel_without_broadcast),
            )
            .route(routes::NEW_ADDR, get(new_address))
            .route(routes::WITHDRAW, post(transfer))
            .route(routes::CONNECT_PEER, post(connect_peer))
            .route(routes::DISCONNECT_PEER, delete(disconnect_peer))
            .route(routes::KEYSEND, post(keysend))
            .route(routes::GENERATE_INVOICE, post(generate_invoice))
            .route(routes::PAY_INVOICE, post(pay_invoice))
            .route(routes::WEBSOCKET, get(ws_handler))
            .layer(from_fn(admin_auth));

        let routes = readonly_routes
            .merge(admin_routes)
            .fallback(handler_404)
            .layer(cors)
            .layer(Extension(bitcoind_api))
            .layer(Extension(lightning_api))
            .layer(Extension(wallet_api))
            .layer(Extension(macaroon_auth));

        tokio::select!(
            result = self.server.serve(routes.into_make_service_with_connect_info::<SocketAddr>()) => {
                    if let Err(e) = result {
                        error!("API server shutdown unexpectedly: {}", e);
                    } else {
                        info!("API server shutdown successfully.");
                    }
                }
            _ = quit_signal => {
                handle.graceful_shutdown(Some(Duration::from_secs(30)));
            }
        );
        Ok(())
    }
}

async fn root() -> Result<impl IntoResponse, ApiError> {
    Ok(())
}

async fn handler_404() -> impl IntoResponse {
    ApiError::NotFound("No such method".to_string())
}

async fn config(certs_dir: &str) -> Result<RustlsConfig> {
    let cert = format!("{certs_dir}/kld.crt");
    let key = format!("{certs_dir}/kld.key");
    RustlsConfig::from_pem_file(&cert, &key)
        .await
        .with_context(|| format!("failed to load certificates ({cert}) and private key ({key})"))
}

pub enum ApiError {
    Unauthorized,
    NotFound(String),
    BadRequest(Box<dyn std::error::Error>),
    InternalServerError(Box<dyn std::error::Error>),
}

impl IntoResponse for ApiError {
    fn into_response(self) -> Response {
        match self {
            ApiError::Unauthorized => build_api_error(
                StatusCode::UNAUTHORIZED,
                "Failed to verify macaroon".to_string(),
            ),
            ApiError::NotFound(s) => build_api_error(StatusCode::NOT_FOUND, s),
            ApiError::BadRequest(e) => build_api_error(StatusCode::BAD_REQUEST, e.to_string()),
            ApiError::InternalServerError(e) => {
                build_api_error(StatusCode::INTERNAL_SERVER_ERROR, e.to_string())
            }
        }
    }
}

fn build_api_error(status_code: StatusCode, detail: String) -> Response {
    let error = crate::api::payloads::Error {
        status: status_code.to_string(),
        detail,
    };
    if let Ok(value) = serde_json::to_value(error) {
        (status_code, Json(value)).into_response()
    } else {
        (
            StatusCode::INTERNAL_SERVER_ERROR,
            Json(json!({"status": StatusCode::INTERNAL_SERVER_ERROR.to_string()})),
        )
            .into_response()
    }
}

#[macro_export]
macro_rules! to_string_empty {
    ($v: expr) => {
        $v.map_or("".to_string(), |x| x.to_string())
    };
}

pub fn unauthorized(e: anyhow::Error) -> ApiError {
    info!("{}", e);
    ApiError::Unauthorized
}

pub fn internal_server(e: impl Into<anyhow::Error>) -> ApiError {
    let anyhow_err = e.into();
    warn!("{}", anyhow_err);
    ApiError::InternalServerError(anyhow_err.into())
}

pub fn bad_request(e: impl Into<anyhow::Error>) -> ApiError {
    let anyhow_err = e.into();
    info!("{}", anyhow_err);
    ApiError::BadRequest(anyhow_err.into())
}

#[allow(clippy::all)]
pub mod codegen {
    #![allow(dead_code)]
    include!(concat!(env!("OUT_DIR"), "/mod.rs"));
}

pub(crate) fn empty_string_as_none<'de, D, T>(de: D) -> Result<Option<T>, D::Error>
where
    D: Deserializer<'de>,
    T: FromStr,
    T::Err: std::fmt::Display,
{
    let opt = Option::<String>::deserialize(de)?;
    match opt.as_deref() {
        None | Some("") => Ok(None),
        Some(s) => FromStr::from_str(s)
            .map_err(serde::de::Error::custom)
            .map(Some),
    }
}

'''
'''--- kld/src/api/network.rs ---
use super::payloads::{
    FeeRates, FeeRatesResponse, NetworkChannel, NetworkNode, OnChainFeeEstimates,
};
use crate::api::SocketAddress;
use anyhow::anyhow;
use axum::{extract::Path, response::IntoResponse, Extension, Json};
use bitcoin::secp256k1::PublicKey;
use lightning::routing::gossip::{ChannelInfo, ChannelUpdateInfo, NodeId, NodeInfo};
use std::{str::FromStr, sync::Arc};

use crate::{bitcoind::bitcoind_interface::BitcoindInterface, ldk::LightningInterface};

use super::{bad_request, internal_server, ApiError};

pub(crate) async fn list_network_nodes(
    Extension(lightning_interface): Extension<Arc<dyn LightningInterface + Send + Sync>>,
) -> Result<impl IntoResponse, ApiError> {
    let nodes: Vec<NetworkNode> = lightning_interface
        .nodes()
        .unordered_iter()
        .filter_map(|(node_id, announcement)| to_api_node(node_id, announcement))
        .collect();
    Ok(Json(nodes))
}

pub(crate) async fn get_network_node(
    Extension(lightning_interface): Extension<Arc<dyn LightningInterface + Send + Sync>>,
    Path(id): Path<String>,
) -> Result<impl IntoResponse, ApiError> {
    let public_key = PublicKey::from_str(&id).map_err(bad_request)?;
    let node_id = NodeId::from_pubkey(&public_key);
    if let Some(node_info) = lightning_interface.get_node(&node_id) {
        if let Some(node) = to_api_node(&node_id, &node_info) {
            return Ok(Json(vec![node]));
        }
    }
    Err(ApiError::NotFound(id))
}

pub(crate) async fn get_network_channel(
    Extension(lightning_interface): Extension<Arc<dyn LightningInterface + Send + Sync>>,
    Path(id): Path<String>,
) -> Result<impl IntoResponse, ApiError> {
    let short_channel_id = u64::from_str(&id).map_err(bad_request)?;
    if let Some(channel_info) = lightning_interface.get_channel(short_channel_id) {
        return Ok(Json(to_api_channel(&short_channel_id, &channel_info)));
    }
    Err(ApiError::NotFound(id))
}

pub(crate) async fn list_network_channels(
    Extension(lightning_interface): Extension<Arc<dyn LightningInterface + Send + Sync>>,
) -> Result<impl IntoResponse, ApiError> {
    let mut channels = vec![];
    for (short_channel_id, channel_info) in lightning_interface.channels().unordered_iter() {
        channels.append(&mut to_api_channel(short_channel_id, channel_info))
    }
    Ok(Json(channels))
}

const CHANNEL_OPEN_VB: u32 = 152;
const MUTUAL_CLOSE_VB: u32 = 130;
const UNILATERAL_CLOSE_VB: u32 = 150;

pub(crate) async fn fee_rates(
    Extension(bitcoind_interface): Extension<Arc<dyn BitcoindInterface + Send + Sync>>,
    Path(style): Path<String>,
) -> Result<impl IntoResponse, ApiError> {
    let (urgent, normal, slow) = bitcoind_interface.fee_rates_kw();
    let mempool_info = bitcoind_interface
        .get_mempool_info()
        .await
        .map_err(internal_server)?;

    let onchain_fee_estimates = OnChainFeeEstimates {
        opening_channel_satoshis: ((normal as f32 / 1000.0) * CHANNEL_OPEN_VB as f32 * 4.0) as u32,
        mutual_close_satoshis: ((normal as f32 / 1000.0) * MUTUAL_CLOSE_VB as f32 * 4.0) as u32,
        unilateral_close_satoshis: ((normal as f32 / 1000.0) * UNILATERAL_CLOSE_VB as f32 * 4.0)
            as u32,
    };
    let response = match style.as_str() {
        "perkb" => {
            let fee_rates = FeeRates {
                urgent: urgent * 4,
                normal: normal * 4,
                slow: slow * 4,
                min_acceptable: (mempool_info.mempool_min_fee * 100000000.0) as u32,
                max_acceptable: urgent * 4,
            };
            FeeRatesResponse {
                perkb: Some(fee_rates),
                perkw: None,
                onchain_fee_estimates,
            }
        }
        "perkw" => {
            let fee_rates = FeeRates {
                urgent,
                normal,
                slow,
                min_acceptable: (mempool_info.mempool_min_fee * 25000000.0) as u32,
                max_acceptable: urgent,
            };
            FeeRatesResponse {
                perkb: None,
                perkw: Some(fee_rates),
                onchain_fee_estimates,
            }
        }
        _ => return Err(bad_request(anyhow!("unknown fee style {}", style))),
    };
    Ok(Json(response))
}

fn to_api_channel(short_channel_id: &u64, channel_info: &ChannelInfo) -> Vec<NetworkChannel> {
    let mut channels = vec![];

    let make_channel =
        |node_one: NodeId, node_two: NodeId, update_info: &ChannelUpdateInfo| NetworkChannel {
            source: hex::encode(node_one.as_array()),
            destination: hex::encode(node_two.as_array()),
            short_channel_id: *short_channel_id,
            public: true,
            satoshis: channel_info.capacity_sats.unwrap_or_default(),
            amount_msat: channel_info
                .capacity_sats
                .map(|s| s * 1000)
                .unwrap_or_default(),
            channel_flags: update_info
                .last_update_message
                .as_ref()
                .map_or(0, |m| m.contents.flags),
            active: update_info.enabled,
            last_update: update_info.last_update,
            base_fee_millisatoshi: update_info.fees.base_msat,
            fee_per_millionth: update_info.fees.proportional_millionths,
            delay: update_info.cltv_expiry_delta,
            htlc_minimum_msat: update_info.htlc_minimum_msat,
            htlc_maximum_msat: update_info.htlc_maximum_msat,
        };
    if let Some(update_info) = &channel_info.one_to_two {
        channels.push(make_channel(
            channel_info.node_one,
            channel_info.node_two,
            update_info,
        ));
    }
    if let Some(update_info) = &channel_info.two_to_one {
        channels.push(make_channel(
            channel_info.node_two,
            channel_info.node_one,
            update_info,
        ));
    }
    channels
}

fn to_api_node(node_id: &NodeId, node_info: &NodeInfo) -> Option<NetworkNode> {
    node_info.announcement_info.as_ref().map(|n| NetworkNode {
        node_id: hex::encode(node_id.as_array()),
        alias: n.alias.to_string(),
        color: hex::encode(n.rgb),
        last_timestamp: n.last_update,
        features: n.features.to_string(),
        addresses: n
            .addresses()
            .iter()
            .map(|a| SocketAddress(a.clone()).to_string())
            .collect(),
    })
}

'''
'''--- kld/src/api/payloads.rs ---
use std::{fmt::Display, str::FromStr};

use bitcoin::Transaction;
use serde::{de::Visitor, Deserialize, Serialize};

#[derive(Serialize, Deserialize)]
pub struct Error {
    pub status: String,
    pub detail: String,
}

#[derive(Serialize, Deserialize)]
pub struct GetInfo {
    pub id: String,
    pub alias: String,
    pub color: String,
    pub num_peers: usize,
    pub num_pending_channels: usize,
    pub num_active_channels: usize,
    pub num_inactive_channels: usize,
    #[serde(rename = "blockheight")]
    pub block_height: u64,
    pub synced_to_chain: bool,
    pub testnet: bool,
    pub chains: Vec<Chain>,
    pub version: String,
    pub api_version: String,
    pub network: String,
    pub address: Vec<String>,
    pub fees_collected_msat: u64,
}

#[derive(Serialize, Deserialize)]
pub struct Chain {
    pub chain: String,
    pub network: String,
}

#[derive(Serialize, Deserialize)]
pub struct NetworkChannel {
    pub source: String,
    pub destination: String,
    pub short_channel_id: u64,
    pub public: bool,
    pub satoshis: u64,
    pub amount_msat: u64,
    pub channel_flags: u8,
    pub active: bool,
    pub last_update: u32,
    pub base_fee_millisatoshi: u32,
    pub fee_per_millionth: u32,
    pub delay: u16,
    pub htlc_minimum_msat: u64,
    pub htlc_maximum_msat: u64,
}

#[derive(Serialize, Deserialize)]
#[serde(rename_all = "camelCase")]
pub struct WalletBalance {
    pub total_balance: u64,
    pub conf_balance: u64,
    pub unconf_balance: u64,
}

#[derive(Serialize, Deserialize)]
#[serde(rename_all = "camelCase")]
pub struct WalletTransfer {
    /// Any Bitcoin accepted type, including bech32
    pub address: String,
    /// Amount to be withdrawn. The string "all" can be used to specify withdrawal of all available funds
    pub satoshis: String,
    /// urgent, normal or slow
    pub fee_rate: Option<FeeRate>,
    /// minimum number of confirmations that used outputs should have
    pub min_conf: Option<String>,
    /// Specifies the utxos to be used to fund the channel, as an array of "txid:vout"
    pub utxos: Vec<String>,
}

#[derive(Serialize, Deserialize)]
pub struct WalletTransferResponse {
    /// Transaction
    pub tx: String,
    /// Transaction ID
    pub txid: String,
}

#[derive(Serialize, Deserialize, PartialEq, Debug)]
pub enum OutputStatus {
    Unconfirmed,
    Confirmed,
}

#[derive(Serialize, Deserialize)]
pub struct ListFundsOutput {
    pub txid: String,
    pub output: u32,
    pub amount_msat: u64,
    pub address: String,
    pub scriptpubkey: String,
    pub status: OutputStatus,
    #[serde(rename = "blockheight")]
    pub block_height: Option<u32>,
}

#[derive(Serialize, Deserialize)]
pub struct ListFundsChannel {
    pub peer_id: String,
    pub connected: bool,
    pub state: ChannelState,
    pub short_channel_id: String,
    pub channel_sat: u64,
    pub our_amount_msat: u64,
    pub amount_msat: u64,
    pub funding_txid: String,
    pub funding_output: u16,
}

#[derive(Serialize, Deserialize)]
pub struct ListFunds {
    pub outputs: Vec<ListFundsOutput>,
    pub channels: Vec<ListFundsChannel>,
}

#[derive(Serialize, Deserialize, PartialEq, Debug)]
pub enum ChannelState {
    Usable,
    Ready,
    Pending,
}

#[derive(Serialize, Deserialize, Default)]
#[serde(rename_all = "camelCase")]
pub struct FundChannel {
    /// Pub key of the peer
    pub id: String,
    /// Amount in satoshis
    pub satoshis: String,
    /// urgent/normal/slow/<sats>perkw/<sats>perkb
    pub fee_rate: Option<FeeRate>,
    /// Flag to announce the channel
    pub announce: Option<bool>,
    /// Minimum number of confirmations that used outputs should have
    pub min_conf: Option<u8>,
    /// Specifies the utxos to be used to fund the channel, as an array of "txid:vout"
    pub utxos: Vec<String>,
    /// Amount of millisatoshis to push to the channel peer at open
    pub push_msat: Option<String>,
    /// Bitcoin address to which the channel funds should be sent to on close
    pub close_to: Option<String>,
    /// Amount of liquidity you'd like to lease from the peer
    pub request_amt: Option<String>,
    /// Compact representation of the peer's expected channel lease terms
    pub compact_lease: Option<String>,
}

#[derive(Clone, Debug, PartialEq, Default)]
pub enum FeeRate {
    Urgent,
    #[default]
    Normal,
    Slow,
    PerKw(u32),
    PerKb(u32),
}

impl Serialize for FeeRate {
    fn serialize<S>(&self, serializer: S) -> Result<S::Ok, S::Error>
    where
        S: serde::Serializer,
    {
        match self {
            FeeRate::Urgent => serializer.serialize_str("urgent"),
            FeeRate::Normal => serializer.serialize_str("normal"),
            FeeRate::Slow => serializer.serialize_str("slow"),
            FeeRate::PerKw(x) => serializer.serialize_str(&format!("{x}perkw")),
            FeeRate::PerKb(x) => serializer.serialize_str(&format!("{x}perkb")),
        }
    }
}

struct FeeRateVisitor;

impl<'de> Visitor<'de> for FeeRateVisitor {
    type Value = FeeRate;

    fn expecting(&self, formatter: &mut std::fmt::Formatter) -> std::fmt::Result {
        formatter.write_str("urgent/normal/slow/<sats>perkw/<sats>perkb")
    }

    fn visit_str<E>(self, v: &str) -> Result<Self::Value, E>
    where
        E: serde::de::Error,
    {
        v.parse()
            .map_err(|e: ParseFeeRateError| serde::de::Error::custom(e.0))
    }
}

impl<'de> Deserialize<'de> for FeeRate {
    fn deserialize<D>(deserializer: D) -> Result<Self, D::Error>
    where
        D: serde::Deserializer<'de>,
    {
        deserializer.deserialize_str(FeeRateVisitor)
    }
}
#[derive(Debug, PartialEq, Eq)]
pub struct ParseFeeRateError(String);
impl Display for ParseFeeRateError {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        write!(f, "ParseFeeRateError: {}", self.0)
    }
}

impl std::error::Error for ParseFeeRateError {
    fn source(&self) -> Option<&(dyn std::error::Error + 'static)> {
        None
    }
}

impl FromStr for FeeRate {
    type Err = ParseFeeRateError;

    fn from_str(s: &str) -> Result<Self, Self::Err> {
        match s {
            "urgent" => Ok(FeeRate::Urgent),
            "normal" => Ok(FeeRate::Normal),
            "slow" => Ok(FeeRate::Slow),
            _ => {
                if s.ends_with("perkw") {
                    Ok(FeeRate::PerKw(
                        s.trim_end_matches("perkw")
                            .parse::<u32>()
                            .map_err(|_| ParseFeeRateError("expected u32 for perkw".to_string()))?,
                    ))
                } else if s.ends_with("perkb") {
                    Ok(FeeRate::PerKb(
                        s.trim_end_matches("perkb")
                            .parse::<u32>()
                            .map_err(|_| ParseFeeRateError("expected u32 for perkb".to_string()))?,
                    ))
                } else {
                    Err(ParseFeeRateError("unknown fee rate. Expecting one of urgent/normal/slow/<sats>perkw/<sats>perkb".to_string()))
                }
            }
        }
    }
}

#[derive(Serialize, Deserialize)]
pub struct FeeRates {
    pub urgent: u32,
    pub normal: u32,
    pub slow: u32,
    pub min_acceptable: u32,
    pub max_acceptable: u32,
}

#[derive(Serialize, Deserialize)]
pub struct OnChainFeeEstimates {
    pub opening_channel_satoshis: u32,
    pub mutual_close_satoshis: u32,
    pub unilateral_close_satoshis: u32,
}

#[derive(Serialize, Deserialize)]
#[serde(rename_all = "camelCase")]
pub struct FeeRatesResponse {
    #[serde(skip_serializing_if = "Option::is_none")]
    pub perkb: Option<FeeRates>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub perkw: Option<FeeRates>,
    pub onchain_fee_estimates: OnChainFeeEstimates,
}

#[derive(Serialize, Deserialize)]
#[serde(rename_all = "camelCase")]
pub struct FundChannelResponse {
    /// Transaction
    pub tx: Transaction,
    /// Transaction ID
    pub txid: String,
    /// channel_id of the newly created channel (hex)
    pub channel_id: String,
}

#[derive(Serialize, Deserialize, Clone)]
pub struct ChannelFee {
    // Short channel ID or channel id. It can be "all" for updating all channels.
    pub id: String,
    // Optional value in msats added as base fee to any routed payment.
    pub base: Option<u32>,
    // Optional value that is added proportionally per-millionths to any routed payment volume in satoshi.
    pub ppm: Option<u32>,
}

#[derive(Serialize, Deserialize)]
#[serde(rename_all = "camelCase")]
pub struct SetChannelFee {
    // Base fee in msats.
    pub base: u32,
    // Fee per-millionths
    pub ppm: u32,
    // Peer ID
    pub peer_id: String,
    // Channel ID
    pub channel_id: String,
    // Short channel ID
    pub short_channel_id: String,
}

#[derive(Serialize, Deserialize)]
pub struct SetChannelFeeResponse(pub Vec<SetChannelFee>);

#[derive(Serialize, Deserialize, PartialEq)]
pub struct Peer {
    pub id: String,
    pub connected: bool,
    pub netaddr: Option<String>,
    pub alias: String,
}

#[derive(Serialize, Deserialize)]
pub struct NetworkNode {
    #[serde(rename = "nodeid")]
    pub node_id: String,
    pub alias: String,
    pub color: String,
    pub last_timestamp: u32,
    pub features: String,
    pub addresses: Vec<String>,
}

#[derive(Serialize, Deserialize)]
pub struct SignRequest {
    pub message: String,
}

#[derive(Serialize, Deserialize)]
pub struct SignResponse {
    pub signature: String,
}

#[derive(Serialize, Deserialize, Default)]
pub struct KeysendRequest {
    // 33 byte, hex-encoded, pubkey of the node
    pub pubkey: String,
    // Amount in milli satoshis
    pub amount: u64,
    // Label for the payment
    pub label: Option<String>,
    // Fraction of the amount to be paid as fee (as a percentage)
    pub maxfeepercent: Option<f64>,
    // Keep retryinig to find routes for this long (seconds)
    pub retry_for: Option<u64>,
    // The payment can be delayed for more than this many blocks
    pub maxdelay: Option<u64>,
    // Amount for which the maxfeepercent check is skipped
    pub exemptfee: Option<u64>,
}

#[derive(Serialize, Deserialize)]
#[serde(rename_all = "camelCase")]
pub struct PaymentResponse {
    pub destination: String,
    pub payment_hash: String,
    pub created_at: u64,
    pub parts: u64,
    pub amount_msat: Option<u64>,
    pub amount_sent_msat: u64,
    pub payment_preimage: String,
    pub status: String,
}

#[derive(Serialize, Deserialize, Clone, Default)]
pub struct GenerateInvoice {
    // Amount in milli satoshis
    pub amount: u64,
    // Unique label for the invoice
    pub label: String,
    // Description for the invoice
    pub description: String,
    // Expiry time period for the invoice (seconds)
    pub expiry: Option<u32>,
    // Include routing hints for private channels (true or 1)
    pub private: Option<bool>,
    //  The fallbacks array is one or more fallback addresses to include in the invoice (in order from most-preferred to least).
    pub fallbacks: Option<Vec<String>>,
    // 64-digit hex string to be used as payment preimage for the created invoice. IMPORTANT> if you specify the preimage, you are responsible, to ensure appropriate care for generating using a secure pseudorandom generator seeded with sufficient entropy, and keeping the preimage secret. This parameter is an advanced feature intended for use with cutting-edge cryptographic protocols and should not be used unless explicitly needed.
    pub preimage: Option<String>,
}

#[derive(Serialize, Deserialize, Debug, PartialEq)]
pub enum InvoiceStatus {
    Unpaid,
    Paid,
    Expired,
}

#[derive(Serialize, Deserialize)]
pub struct Invoice {
    pub label: Option<String>,
    pub bolt11: String,
    pub payment_hash: String,
    pub description: String,
    pub status: InvoiceStatus,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub amount_msat: Option<u64>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub amount_received_msat: Option<u64>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub paid_at: Option<u32>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub expires_at: Option<u64>,
}

#[derive(Serialize, Deserialize)]
#[serde(rename_all = "camelCase")]
pub struct GenerateInvoiceResponse {
    pub payment_hash: String,
    pub expires_at: u32,
    pub bolt11: String,
}

#[derive(Serialize, Deserialize)]
pub struct PayInvoice {
    pub invoice: String,
    pub label: Option<String>,
}

#[test]
fn test_fee_rate() -> Result<(), ParseFeeRateError> {
    let urgent_fee_rate = FeeRate::from_str("urgent")?;
    assert_eq!(urgent_fee_rate, FeeRate::Urgent);

    let normal_fee_rate = FeeRate::from_str("normal")?;
    assert_eq!(normal_fee_rate, FeeRate::Normal);

    let slow_fee_rate = FeeRate::from_str("slow")?;
    assert_eq!(slow_fee_rate, FeeRate::Slow);

    let pkb_fee_rate = FeeRate::from_str("50perkb")?;
    assert_eq!(pkb_fee_rate, FeeRate::PerKb(50));

    let pkw_fee_rate = FeeRate::from_str("37perkw")?;
    assert_eq!(pkw_fee_rate, FeeRate::PerKw(37));
    Ok(())
}

'''
'''--- kld/src/api/payments.rs ---
use std::{str::FromStr, sync::Arc};

use super::payloads::{KeysendRequest, PayInvoice, PaymentResponse};
use anyhow::{anyhow, Context};
use axum::{extract::Query, response::IntoResponse, Extension, Json};
use lightning::routing::gossip::NodeId;

use crate::{
    database::{
        invoice::Invoice,
        payment::{PaymentDirection, PaymentStatus},
    },
    ldk::LightningInterface,
};

use super::{
    bad_request,
    codegen::get_v1_pay_list_payments_response::{
        GetV1PayListPaymentsResponse, GetV1PayListPaymentsResponsePaymentsItem,
        GetV1PayListPaymentsResponsePaymentsItemStatus,
    },
    empty_string_as_none, internal_server, ApiError,
};

pub(crate) async fn keysend(
    Extension(lightning_interface): Extension<Arc<dyn LightningInterface + Send + Sync>>,
    Json(keysend_request): Json<KeysendRequest>,
) -> Result<impl IntoResponse, ApiError> {
    let node_id = NodeId::from_str(&keysend_request.pubkey)
        .map_err(|_| bad_request(anyhow!("node id decode error")))?;
    let payment = lightning_interface
        .keysend_payment(node_id, keysend_request.amount)
        .await
        .map_err(internal_server)?;
    let response = PaymentResponse {
        destination: keysend_request.pubkey,
        payment_hash: hex::encode(
            payment
                .hash
                .context("missing payment hash")
                .map_err(internal_server)?
                .0,
        ),
        created_at: payment.timestamp.unix_timestamp() as u64,
        parts: 1,
        amount_msat: Some(keysend_request.amount),
        amount_sent_msat: keysend_request.amount * 1000,
        payment_preimage: payment
            .preimage
            .map(|i| hex::encode(i.0))
            .unwrap_or_default(),
        status: payment.status.to_string(),
    };
    Ok(Json(response))
}

pub(crate) async fn pay_invoice(
    Extension(lightning_interface): Extension<Arc<dyn LightningInterface + Send + Sync>>,
    Json(pay_invoice_request): Json<PayInvoice>,
) -> Result<impl IntoResponse, ApiError> {
    let invoice: Invoice = pay_invoice_request
        .invoice
        .try_into()
        .map_err(bad_request)?;
    let destination = invoice.payee_pub_key.to_string();
    let amount = invoice.amount;
    let payment = lightning_interface
        .pay_invoice(invoice, pay_invoice_request.label)
        .await
        .map_err(internal_server)?;
    let response = PaymentResponse {
        destination,
        payment_hash: hex::encode(
            payment
                .hash
                .context("missing payment hash")
                .map_err(internal_server)?
                .0,
        ),
        created_at: payment.timestamp.unix_timestamp() as u64,
        parts: 1,
        amount_msat: amount,
        amount_sent_msat: payment.amount,
        payment_preimage: payment
            .preimage
            .map(|i| hex::encode(i.0))
            .unwrap_or_default(),
        status: payment.status.to_string(),
    };
    Ok(Json(response))
}

#[derive(Serialize, Deserialize)]
#[serde(rename_all = "camelCase")]
pub struct ListPaysParams {
    #[serde(default, deserialize_with = "empty_string_as_none")]
    pub invoice: Option<String>,
    #[serde(default, deserialize_with = "empty_string_as_none")]
    pub direction: Option<String>,
}

pub(crate) async fn list_payments(
    Extension(lightning_interface): Extension<Arc<dyn LightningInterface + Send + Sync>>,
    Query(params): Query<ListPaysParams>,
) -> Result<impl IntoResponse, ApiError> {
    let invoice = params
        .invoice
        .map(|i| i.try_into())
        .transpose()
        .map_err(bad_request)?;
    let direction = params
        .direction
        .map(|d| PaymentDirection::from_str(&d))
        .transpose()
        .map_err(bad_request)?;
    let payments: Vec<GetV1PayListPaymentsResponsePaymentsItem> = lightning_interface
        .list_payments(invoice, direction)
        .await
        .map_err(internal_server)?
        .into_iter()
        .map(|p| GetV1PayListPaymentsResponsePaymentsItem {
            bolt11: p.bolt11.as_ref().map(|b| b.to_string()),
            status: match p.status {
                PaymentStatus::Pending => GetV1PayListPaymentsResponsePaymentsItemStatus::Pending,
                PaymentStatus::Succeeded => {
                    GetV1PayListPaymentsResponsePaymentsItemStatus::Complete
                }
                _ => GetV1PayListPaymentsResponsePaymentsItemStatus::Failed,
            },
            payment_preimage: p.preimage.map(|i| hex::encode(i.0)),
            amount_sent_msat: p.amount,
            amount_msat: p.bolt11.as_ref().and_then(|b| b.amount_milli_satoshis()),
            created_at: p.timestamp.unix_timestamp() as u64,
            destination: p
                .bolt11
                .and_then(|b| b.payee_pub_key().map(|pk| pk.to_string())),
            id: hex::encode(p.id.0),
            memo: p.label,
            payment_hash: p.hash.map(|h| hex::encode(h.0)),
        })
        .collect();
    Ok(Json(GetV1PayListPaymentsResponse { payments }))
}

'''
'''--- kld/src/api/peers.rs ---
use std::{str::FromStr, sync::Arc};

use super::codegen::{
    post_v1_peer_connect_body::PostV1PeerConnectBody,
    post_v1_peer_connect_response::PostV1PeerConnectResponse,
};
use super::payloads::Peer;
use crate::{
    api::bad_request,
    ldk::{LightningInterface, PeerStatus},
};
use anyhow::Result;
use axum::{extract::Path, response::IntoResponse, Extension, Json};
use bitcoin::secp256k1::PublicKey;
use http::StatusCode;

use super::{internal_server, ApiError};

pub(crate) async fn list_peers(
    Extension(lightning_interface): Extension<Arc<dyn LightningInterface + Send + Sync>>,
) -> Result<impl IntoResponse, ApiError> {
    let peers: Vec<Peer> = lightning_interface
        .list_peers()
        .await
        .map_err(internal_server)?
        .iter()
        .map(|p| Peer {
            id: hex::encode(p.public_key.serialize()),
            connected: p.status == PeerStatus::Connected,
            netaddr: p.net_address.as_ref().map(|a| a.to_string()),
            alias: p.alias.clone(),
        })
        .collect();

    Ok(Json(peers))
}

pub(crate) async fn connect_peer(
    Extension(lightning_interface): Extension<Arc<dyn LightningInterface + Send + Sync>>,
    Json(body): Json<PostV1PeerConnectBody>,
) -> Result<impl IntoResponse, ApiError> {
    let (public_key, net_address) = match body.id.split_once('@') {
        Some((public_key, net_address)) => (
            PublicKey::from_str(public_key).map_err(bad_request)?,
            Some(net_address.parse().map_err(bad_request)?),
        ),
        None => (PublicKey::from_str(&body.id).map_err(bad_request)?, None),
    };
    lightning_interface
        .connect_peer(public_key, net_address)
        .await
        .map_err(internal_server)?;

    Ok((
        StatusCode::CREATED,
        Json(PostV1PeerConnectResponse {
            id: hex::encode(public_key.serialize()),
        }),
    ))
}

pub(crate) async fn disconnect_peer(
    Extension(lightning_interface): Extension<Arc<dyn LightningInterface + Send + Sync>>,
    Path(id): Path<String>,
) -> Result<impl IntoResponse, ApiError> {
    let public_key = PublicKey::from_str(&id).map_err(bad_request)?;
    lightning_interface
        .disconnect_peer(public_key)
        .await
        .map_err(internal_server)?;

    Ok(Json(()))
}

'''
'''--- kld/src/api/routes.rs ---
/// NO-OP
pub const ROOT: &str = "/";
/// Sign
pub const SIGN: &str = "/v1/utility/signMessage";
/// Get node information.
pub const GET_INFO: &str = "/v1/getinfo";
/// Get node routing fees.
pub const GET_FEES: &str = "/v1/getFees";
/// Estimate channel liquidity range to a particular node.
pub const ESTIMATE_CHANNEL_LIQUIDITY: &str = "/v1/estimateChannelLiquidity";
/// Websocket
pub const WEBSOCKET: &str = "/v1/ws";

/// List on chain and channel funds
pub const LIST_FUNDS: &str = "/v1/listFunds";

/// --- Peers ---
/// Connect with a network peer.
pub const CONNECT_PEER: &str = "/v1/peer/connect";
/// Returns the list of peers connected with the node.
pub const LIST_PEERS: &str = "/v1/peer/listPeers";
/// Disconnect from a connected network peer.
pub const DISCONNECT_PEER: &str = "/v1/peer/disconnect/:id";

/// --- Channels ---
/// Get the list of channels for this nodes peers.
pub const LIST_PEER_CHANNELS: &str = "/v1/channel/listPeerChannels";
/// Open channel with a connected peer node.
pub const OPEN_CHANNEL: &str = "/v1/channel/openChannel";
/// Update channel fee policy.
pub const SET_CHANNEL_FEE: &str = "/v1/channel/setChannelFee";
/// Close an existing channel with a peer.
pub const CLOSE_CHANNEL: &str = "/v1/channel/closeChannel/:id";
/// Close an existing channel with a peer and specified fee rate.
pub const CLOSE_CHANNEL_WITH_FEE: &str = "/v1/channel/closeChannel/:id/:fee_rate";
/// Force close an existing channel with a peer.
pub const FORCE_CLOSE_CHANNEL_WITH_BROADCAST: &str =
    "/v1/channel/forceCloseChannelWithBoradCast/:id";
pub const FORCE_CLOSE_CHANNEL_WITHOUT_BROADCAST: &str =
    "/v1/channel/forceCloseChannelWithoutBoradCast/:id";
/// Fetch aggregate channel local and remote balances.
pub const LOCAL_REMOTE_BALANCE: &str = "/v1/channel/localremotebal";
/// Fetch the list of the forwarded htlcs.
pub const LIST_FORWARDS: &str = "/v1/channel/listForwards";
/// Fetch our channel history.
pub const LIST_CHANNEL_HISTORY: &str = "/v1/channel/history";

/// --- Network ---
/// Look up a node on the network.
pub const LIST_NETWORK_NODE: &str = "/v1/network/listNode/:id";
/// Return list of all nodes on the network
pub const LIST_NETWORK_NODES: &str = "/v1/network/listNode";
/// Look up a channel on the network
pub const LIST_NETWORK_CHANNEL: &str = "/v1/network/listChannel/:id";
/// Return list of all channels on the network
pub const LIST_NETWORK_CHANNELS: &str = "/v1/network/listChannel";
/// Return feerate estimates, either satoshi-per-kw or satoshi-per-kb
pub const FEE_RATES: &str = "/v1/network/feeRates/:style";

/// --- On chain wallet ---
/// Returns total, confirmed and unconfirmed on-chain balances.
pub const GET_BALANCE: &str = "/v1/getBalance";
/// Generate address for receiving on-chain funds.
pub const NEW_ADDR: &str = "/v1/newaddr";
/// Withdraw on-chain funds to an address.
pub const WITHDRAW: &str = "/v1/withdraw";

/// --- Payments ---
/// Send funds to a node without an invoice.
pub const KEYSEND: &str = "/v1/pay/keysend";
/// Pay a  bolt11 invoice.
pub const PAY_INVOICE: &str = "/v1/pay";
/// List payments.
pub const LIST_PAYMENTS: &str = "/v1/pay/listPayments";

/// --- Invoices ---
/// Generate a bolt11 invoice.
pub const GENERATE_INVOICE: &str = "/v1/invoice/genInvoice";
/// List the invoices on the node
pub const LIST_INVOICES: &str = "/v1/invoice/listInvoices";
/// Decode invoice
pub const DECODE_INVOICE: &str = "/v1/utility/decode/:invoice";

/// --- Kuutamo Apis ---
pub const SCORER: &str = "/kld/scorer";
pub const LIST_CHANNELS: &str = "/kld/channels";

'''
'''--- kld/src/api/skt_addr.rs ---
use core::ops::Deref;
use std::{
    fmt::Display,
    net::{Ipv4Addr, Ipv6Addr, SocketAddr, SocketAddrV4, SocketAddrV6},
    str::FromStr,
};

pub use lightning;
use serde::{Deserialize, Deserializer, Serialize, Serializer};

/// A wrapper for lightning::ln::msgs::SocketAddress
#[derive(Debug, PartialEq, Clone)]
pub struct SocketAddress(pub lightning::ln::msgs::SocketAddress);

impl SocketAddress {
    pub fn is_ipv4(&self) -> bool {
        matches!(self.0, lightning::ln::msgs::SocketAddress::TcpIpV4 { .. })
    }

    pub fn is_ipv6(&self) -> bool {
        matches!(self.0, lightning::ln::msgs::SocketAddress::TcpIpV6 { .. })
    }

    pub fn inner(self) -> lightning::ln::msgs::SocketAddress {
        self.0
    }
}

impl Deref for SocketAddress {
    type Target = lightning::ln::msgs::SocketAddress;

    fn deref(&self) -> &Self::Target {
        &self.0
    }
}

#[derive(Serialize, Deserialize)]
pub enum SocketAddressHelper {
    IPv4(([u8; 4], u16)),
    IPv6(([u8; 16], u16)),
    OnionV2([u8; 12]),
    // key , checksum, version, port
    OnionV3(([u8; 32], u16, u8, u16)),
    // port, hostname
    Hostname((u16, String)),
}

// Drop this when PR merge
// https://github.com/lightningdevkit/rust-lightning/pull/2670
impl Display for SocketAddress {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match &self.0 {
            lightning::ln::msgs::SocketAddress::TcpIpV4 { addr, port } => {
                write!(f, "{}:{port}", Ipv4Addr::from(*addr))?
            }
            lightning::ln::msgs::SocketAddress::TcpIpV6 { addr, port } => {
                write!(f, "[{}]:{port}", Ipv6Addr::from(*addr))?
            }
            lightning::ln::msgs::SocketAddress::OnionV2(bytes) => write!(f, "{bytes:?}.onion")?,
            lightning::ln::msgs::SocketAddress::OnionV3 {
                port,
                ed25519_pubkey,
                ..
            } => write!(f, "{ed25519_pubkey:?}.onion:{port}")?,
            lightning::ln::msgs::SocketAddress::Hostname { hostname, port } => {
                write!(f, "{hostname:?}:{port}")?
            }
        }
        Ok(())
    }
}

impl Serialize for SocketAddress {
    fn serialize<S>(&self, serializer: S) -> Result<S::Ok, S::Error>
    where
        S: Serializer,
    {
        let net_address_type = match &self.0 {
            lightning::ln::msgs::SocketAddress::TcpIpV4 { addr, port } => {
                SocketAddressHelper::IPv4((*addr, *port))
            }
            lightning::ln::msgs::SocketAddress::TcpIpV6 { addr, port } => {
                SocketAddressHelper::IPv6((*addr, *port))
            }
            lightning::ln::msgs::SocketAddress::OnionV2(bytes) => {
                SocketAddressHelper::OnionV2(*bytes)
            }
            lightning::ln::msgs::SocketAddress::OnionV3 {
                ed25519_pubkey,
                checksum,
                version,
                port,
            } => SocketAddressHelper::OnionV3((*ed25519_pubkey, *checksum, *version, *port)),
            lightning::ln::msgs::SocketAddress::Hostname { hostname, port } => {
                SocketAddressHelper::Hostname((*port, hostname.to_string()))
            }
        };
        net_address_type.serialize(serializer)
    }
}

impl<'de> Deserialize<'de> for SocketAddress {
    fn deserialize<D>(deserializer: D) -> Result<Self, D::Error>
    where
        D: Deserializer<'de>,
    {
        Deserialize::deserialize(deserializer).map(|helper| {
            let inner = match helper {
                SocketAddressHelper::IPv4((addr, port)) => {
                    lightning::ln::msgs::SocketAddress::TcpIpV4 { addr, port }
                }
                SocketAddressHelper::IPv6((addr, port)) => {
                    lightning::ln::msgs::SocketAddress::TcpIpV6 { addr, port }
                }
                SocketAddressHelper::OnionV2(bytes) => {
                    lightning::ln::msgs::SocketAddress::OnionV2(bytes)
                }
                SocketAddressHelper::OnionV3((ed25519_pubkey, checksum, version, port)) => {
                    lightning::ln::msgs::SocketAddress::OnionV3 {
                        ed25519_pubkey,
                        checksum,
                        version,
                        port,
                    }
                }
                SocketAddressHelper::Hostname((port, hostname)) => {
                    let hostname = lightning::util::ser::Hostname::try_from(hostname.clone())
                        .unwrap_or_else(|_| {
                            eprintln!("invalid hostname detected: {:?}", hostname);
                            lightning::util::ser::Hostname::try_from("".to_string())
                                .expect("Replcing invalid hostname with empty one")
                        });
                    lightning::ln::msgs::SocketAddress::Hostname { hostname, port }
                }
            };
            SocketAddress(inner)
        })
    }
}

impl From<lightning::ln::msgs::SocketAddress> for SocketAddress {
    fn from(inner: lightning::ln::msgs::SocketAddress) -> Self {
        Self(inner)
    }
}

impl From<SocketAddr> for SocketAddress {
    fn from(addr: SocketAddr) -> Self {
        SocketAddress(addr.into())
    }
}

impl From<SocketAddrV4> for SocketAddress {
    fn from(v4: SocketAddrV4) -> Self {
        SocketAddress(v4.into())
    }
}

impl From<SocketAddrV6> for SocketAddress {
    fn from(v6: SocketAddrV6) -> Self {
        SocketAddress(v6.into())
    }
}

impl FromStr for SocketAddress {
    type Err = anyhow::Error;

    fn from_str(s: &str) -> std::result::Result<Self, Self::Err> {
        if let Ok(addr) = lightning::ln::msgs::SocketAddress::from_str(s) {
            Ok(Self(addr))
        } else {
            anyhow::bail!("{} is not a valid socket address", s)
        }
    }
}

impl TryFrom<SocketAddress> for SocketAddr {
    type Error = anyhow::Error;

    fn try_from(address: SocketAddress) -> std::result::Result<Self, Self::Error> {
        match address.0 {
            lightning::ln::msgs::SocketAddress::TcpIpV4 { addr, port } => Ok(SocketAddr::V4(
                SocketAddrV4::new(Ipv4Addr::from(addr), port),
            )),
            lightning::ln::msgs::SocketAddress::TcpIpV6 { addr, port } => Ok(SocketAddr::V6(
                SocketAddrV6::new(Ipv6Addr::from(addr), port, 0, 0),
            )),
            _ => anyhow::bail!("unsupported address type"),
        }
    }
}

#[test]
fn test_netaddress() {
    let v4_addr = SocketAddress(lightning::ln::msgs::SocketAddress::TcpIpV4 {
        addr: Ipv4Addr::new(127, 0, 0, 1).octets(),
        port: 80,
    });
    let mut bytes = bincode::serialize(&v4_addr).unwrap();
    let v4_decoded: SocketAddress = bincode::deserialize(&bytes).unwrap();
    assert_eq!(v4_addr, v4_decoded);

    let v6_addr = SocketAddress(lightning::ln::msgs::SocketAddress::TcpIpV6 {
        addr: Ipv6Addr::new(0, 0, 0, 0, 0, 0, 0, 1).octets(),
        port: 80,
    });
    bytes = bincode::serialize(&v6_addr).unwrap();
    let v6_decoded: SocketAddress = bincode::deserialize(&bytes).unwrap();
    assert_eq!(v6_addr, v6_decoded);
}

'''
'''--- kld/src/api/utility.rs ---
use super::payloads::{Chain, GetInfo, SignRequest, SignResponse};
use super::API_VERSION;
use anyhow::anyhow;
use axum::Json;
use axum::{response::IntoResponse, Extension};
use bitcoin::Network;
use lightning::routing::gossip::NodeId;
use std::str::FromStr;
use std::sync::Arc;

use crate::bitcoind::bitcoind_interface::BitcoindInterface;
use crate::ldk::LightningInterface;
use crate::VERSION;

use super::codegen::get_v1_estimate_channel_liquidity_body::GetV1EstimateChannelLiquidityBody;
use super::codegen::get_v1_estimate_channel_liquidity_response::GetV1EstimateChannelLiquidityResponse;
use super::codegen::get_v1_get_fees_response::GetV1GetFeesResponse;
use super::{bad_request, internal_server, ApiError};

pub(crate) async fn get_info(
    Extension(bitcoind_interface): Extension<Arc<dyn BitcoindInterface + Send + Sync>>,
    Extension(lightning_interface): Extension<Arc<dyn LightningInterface + Send + Sync>>,
) -> Result<impl IntoResponse, ApiError> {
    let synced_to_chain = lightning_interface
        .synced()
        .await
        .map_err(internal_server)?;
    let fees_collected_msat = lightning_interface
        .fetch_total_forwards()
        .await
        .map_err(internal_server)?
        .fee;
    let info = GetInfo {
        id: lightning_interface.identity_pubkey().to_string(),
        alias: lightning_interface.alias(),
        num_pending_channels: lightning_interface.num_pending_channels(),
        num_active_channels: lightning_interface.num_active_channels(),
        num_inactive_channels: lightning_interface.num_inactive_channels(),
        num_peers: lightning_interface.num_peers(),
        block_height: bitcoind_interface
            .block_height()
            .await
            .map_err(internal_server)?,
        synced_to_chain,
        testnet: lightning_interface.network() != Network::Bitcoin,
        chains: vec![Chain {
            chain: "bitcoin".to_string(),
            network: lightning_interface.network().to_string(),
        }],
        version: VERSION.to_string(),
        api_version: API_VERSION.to_string(),
        color: "".to_string(),
        network: lightning_interface.network().to_string(),
        address: lightning_interface
            .public_addresses()
            .into_iter()
            .map(|a| a.to_string())
            .collect(),
        fees_collected_msat,
    };
    Ok(Json(info))
}

const MESSAGE_MAX_LENGTH: u16 = 65535;

pub(crate) async fn sign(
    Extension(lightning_interface): Extension<Arc<dyn LightningInterface + Send + Sync>>,
    Json(body): Json<SignRequest>,
) -> Result<impl IntoResponse, ApiError> {
    if body.message.len() > MESSAGE_MAX_LENGTH as usize {
        return Err(bad_request(anyhow!(
            "Max message length is {MESSAGE_MAX_LENGTH}"
        )));
    }

    let signature = lightning_interface
        .sign(body.message.as_bytes())
        .map_err(internal_server)?;
    Ok(Json(SignResponse { signature }))
}

pub(crate) async fn estimate_channel_liquidity_range(
    Extension(lightning_interface): Extension<Arc<dyn LightningInterface + Send + Sync>>,
    Json(body): Json<GetV1EstimateChannelLiquidityBody>,
) -> Result<impl IntoResponse, ApiError> {
    let node_id =
        NodeId::from_str(&body.target).map_err(|_| bad_request(anyhow!("node iddecode error")))?;
    match lightning_interface
        .estimated_channel_liquidity_range(body.scid, &node_id)
        .await
        .map_err(internal_server)?
    {
        Some((minimum, maximum)) => Ok(Json(GetV1EstimateChannelLiquidityResponse {
            minimum,
            maximum,
        })),
        None => Err(ApiError::NotFound(body.scid.to_string())),
    }
}

pub(crate) async fn get_fees(
    Extension(lightning_interface): Extension<Arc<dyn LightningInterface + Send + Sync>>,
) -> Result<impl IntoResponse, ApiError> {
    let total_forwards = lightning_interface
        .fetch_total_forwards()
        .await
        .map_err(internal_server)?;
    let response = GetV1GetFeesResponse {
        fee_collected: total_forwards.fee,
    };
    Ok(Json(response))
}

pub(crate) async fn score(
    Extension(lightning_interface): Extension<Arc<dyn LightningInterface + Send + Sync>>,
) -> Result<impl IntoResponse, ApiError> {
    let score = lightning_interface
        .scorer()
        .await
        .map_err(internal_server)?;
    Ok(score)
}

'''
'''--- kld/src/api/wallet.rs ---
use super::payloads::{
    ChannelState, ListFunds, ListFundsChannel, ListFundsOutput, OutputStatus, WalletBalance,
    WalletTransfer, WalletTransferResponse,
};
use anyhow::anyhow;
use axum::extract::Query;
use axum::{response::IntoResponse, Extension, Json};
use bitcoin::consensus::encode;
use bitcoin::Address;
use std::str::FromStr;
use std::sync::Arc;

use crate::ldk::LightningInterface;
use crate::ldk::PeerStatus;
use crate::to_string_empty;
use crate::wallet::WalletInterface;

use super::codegen::get_v1_newaddr_response::GetV1NewaddrResponse;
use super::{bad_request, internal_server, ApiError};

pub(crate) async fn get_balance(
    Extension(wallet): Extension<Arc<dyn WalletInterface + Send + Sync>>,
) -> Result<impl IntoResponse, ApiError> {
    let balance = wallet.balance().map_err(internal_server)?;
    let unconf_balance = balance.untrusted_pending + balance.trusted_pending;
    let total_balance = unconf_balance + balance.confirmed;
    let result = WalletBalance {
        total_balance,
        conf_balance: balance.confirmed,
        unconf_balance,
    };
    Ok(Json(result))
}

#[derive(Serialize, Deserialize, Default)]
#[serde(rename_all = "camelCase")]
pub struct NewAddressQueryParams {
    pub address_type: Option<String>,
}

pub(crate) async fn new_address(
    Extension(wallet): Extension<Arc<dyn WalletInterface + Send + Sync>>,
    Query(params): Query<NewAddressQueryParams>,
) -> Result<impl IntoResponse, ApiError> {
    if params.address_type.is_some_and(|t| t != "bech32") {
        return Err(bad_request(anyhow!("Unsupported address type")));
    }
    let address_info = wallet.new_external_address().map_err(internal_server)?;
    let response = GetV1NewaddrResponse {
        address: address_info.address.to_string(),
    };
    Ok(Json(response))
}

pub(crate) async fn transfer(
    Extension(wallet): Extension<Arc<dyn WalletInterface + Send + Sync>>,
    Json(wallet_transfer): Json<WalletTransfer>,
) -> Result<impl IntoResponse, ApiError> {
    let address = Address::from_str(&wallet_transfer.address).map_err(bad_request)?;

    let amount = if wallet_transfer.satoshis == "all" {
        u64::MAX
    } else {
        u64::from_str(&wallet_transfer.satoshis).map_err(bad_request)?
    };
    let (tx, tx_details) = wallet
        .transfer(address, amount, wallet_transfer.fee_rate, None, vec![])
        .await
        .map_err(internal_server)?;
    let tx_hex = encode::serialize_hex(&tx);
    let response = WalletTransferResponse {
        tx: tx_hex,
        txid: tx_details.txid.to_string(),
    };
    Ok(Json(response))
}

pub(crate) async fn list_funds(
    Extension(wallet): Extension<Arc<dyn WalletInterface + Send + Sync>>,
    Extension(lightning_interface): Extension<Arc<dyn LightningInterface + Send + Sync>>,
) -> Result<impl IntoResponse, ApiError> {
    let mut outputs = vec![];
    let utxos = wallet.list_utxos().map_err(internal_server)?;
    for (utxo, detail) in utxos {
        outputs.push(ListFundsOutput {
            txid: utxo.outpoint.txid.to_string(),
            output: utxo.outpoint.vout,
            amount_msat: utxo.txout.value * 1000,
            address: Address::from_script(&utxo.txout.script_pubkey, lightning_interface.network())
                .map(|a| a.to_string())
                .map_err(internal_server)?,
            scriptpubkey: utxo.txout.script_pubkey.to_asm_string(),
            status: if detail.confirmation_time.is_some() {
                OutputStatus::Confirmed
            } else {
                OutputStatus::Unconfirmed
            },
            block_height: detail.confirmation_time.map(|t| t.height),
        });
    }

    let mut channels = vec![];
    let peers = lightning_interface
        .list_peers()
        .await
        .map_err(internal_server)?;
    for channel in lightning_interface.list_active_channels() {
        if let Some(funding_txo) = channel.funding_txo {
            channels.push(ListFundsChannel {
                peer_id: channel.counterparty.node_id.to_string(),
                connected: peers
                    .iter()
                    .find(|p| p.public_key == channel.counterparty.node_id)
                    .map(|p| p.status == PeerStatus::Connected)
                    .unwrap_or_default(),
                state: if channel.is_usable {
                    ChannelState::Usable
                } else if channel.is_channel_ready {
                    ChannelState::Ready
                } else {
                    ChannelState::Pending
                },
                short_channel_id: to_string_empty!(channel.short_channel_id),
                our_amount_msat: channel.balance_msat,
                channel_sat: channel.channel_value_satoshis,
                amount_msat: channel.channel_value_satoshis * 1000,
                funding_txid: funding_txo.txid.to_string(),
                funding_output: funding_txo.index,
            });
        }
    }
    let response = ListFunds { outputs, channels };
    Ok(Json(response))
}

'''
'''--- kld/src/api/ws.rs ---
use std::{net::SocketAddr, ops::ControlFlow};

use axum::{
    extract::{
        ws::{Message, WebSocket},
        ConnectInfo, WebSocketUpgrade,
    },
    headers::UserAgent,
    response::IntoResponse,
    TypedHeader,
};
use futures::StreamExt;
use log::{debug, error, info};

use super::ApiError;

/// This is WIP. Just connects and checks macaroon at the moment.

/// The handler for the HTTP request (this gets called when the HTTP GET lands at the start
/// of websocket negotiation. After this completes, the actual switching from HTTP to
/// websocket protocol will occur.
/// This is the last point where we can extract TCP/IP metadata such as IP address of the client
/// as well as things from HTTP headers such as user-agent of the browser etc.
pub async fn ws_handler(
    ws: WebSocketUpgrade,
    user_agent: Option<TypedHeader<UserAgent>>,
    ConnectInfo(addr): ConnectInfo<SocketAddr>,
) -> Result<impl IntoResponse, ApiError> {
    let user_agent = user_agent
        .map(|a| a.to_string())
        .unwrap_or_else(|| "Unknown client".to_string());

    info!("`{}` at {} connected.", user_agent, addr.to_string());
    // finalize the upgrade process by returning upgrade callback.
    // we can customize the callback by sending additional info such as address.
    Ok(ws
        .protocols(["hex"])
        .on_upgrade(move |socket| handle_socket(socket, addr)))
}

/// Actual websocket statemachine (one will be spawned per connection)
async fn handle_socket(mut socket: WebSocket, who: SocketAddr) {
    //send a ping (unsupported by some browsers) just to kick things off and get a response
    if socket.send(Message::Ping(vec![])).await.is_ok() {
        debug!("Pinged {}...", who);
    } else {
        debug!("Could not send ping {}!", who);
        // no Error here since the only thing we can do is to close the connection.
        // If we can not send messages, there is no way to salvage the statemachine anyway.
        return;
    }

    // Since each client gets individual statemachine, we can pause handling
    // when necessary to wait for some external event (in this case illustrated by sleeping).
    // Waiting for this client to finish getting his greetings does not prevent other clients form
    // connecting to server and receiving their greetings.

    // By splitting socket we can send and receive at the same time. In this example we will send
    // unsolicited messages to client based on some sort of server's internal event (i.e .timer).
    let (mut _sender, mut receiver) = socket.split();

    /* To close connection.
        debug!("Sending close to {}...", who);
        if let Err(e) = sender
            .send(Message::Close(Some(CloseFrame {
                code: axum::extract::ws::close_code::NORMAL,
                reason: Cow::from("Goodbye"),
            })))
            .await
        {
            debug!("Could not send Close due to {}, probably it is ok?", e);
        }
    });*/

    // This second task will receive messages from client and print them on server console
    let recv_task = tokio::spawn(async move {
        while let Some(Ok(msg)) = receiver.next().await {
            // print message and break if instructed to do so
            if process_message(msg, who).is_break() {
                break;
            }
        }
    });

    if let Err(e) = recv_task.await {
        error!("{e}")
    };

    // returning from the handler closes the websocket connection
    info!("Websocket context {} destroyed", who);
}

/// helper to print contents of messages to stdout. Has special treatment for Close.
fn process_message(msg: Message, who: SocketAddr) -> ControlFlow<(), ()> {
    match msg {
        Message::Text(t) => {
            info!(">>> {} sent str: {:?}", who, t);
        }
        Message::Binary(d) => {
            info!(">>> {} sent {} bytes: {:?}", who, d.len(), d);
        }
        Message::Close(c) => {
            if let Some(cf) = c {
                info!(
                    ">>> {} sent close with code {} and reason `{}`",
                    who, cf.code, cf.reason
                );
            } else {
                info!(">>> {} somehow sent close message without CloseFrame", who);
            }
            return ControlFlow::Break(());
        }

        Message::Pong(v) => {
            info!(">>> {} sent pong with {:?}", who, v);
        }
        // You should never need to manually handle Message::Ping, as axum's websocket library
        // will do so for you automagically by replying with Pong and copying the v according to
        // spec. But if you need the contents of the pings you can see them here.
        Message::Ping(v) => {
            info!(">>> {} sent ping with {:?}", who, v);
        }
    }
    ControlFlow::Continue(())
}

'''
'''--- kld/src/bitcoind/bitcoind_client.rs ---
use std::{
    sync::{
        atomic::{AtomicU32, Ordering},
        Arc,
    },
    time::{Duration, SystemTime, UNIX_EPOCH},
};

use anyhow::{anyhow, bail, Context, Result};

use crate::settings::Network;
use crate::settings::Settings;
use async_trait::async_trait;
use base64::{engine::general_purpose, Engine};
use bitcoin::{consensus::encode, Address, BlockHash, Transaction, Txid};
use bitcoincore_rpc_json::{EstimateMode, EstimateSmartFeeResult, GetBlockchainInfoResult};
use lightning::chain::chaininterface::{BroadcasterInterface, ConfirmationTarget, FeeEstimator};
use lightning_block_sync::{
    http::{HttpEndpoint, JsonResponse},
    rpc::RpcClient,
    AsyncBlockSourceResult, BlockData, BlockHeaderData, BlockSource,
};
use log::{error, info};
use serde::Deserialize;
use serde_json::{json, Value};
use tokio::runtime::Handle;

use crate::{ldk::MIN_FEERATE, quit_signal, Service};

use super::bitcoind_interface::BitcoindInterface;

pub struct BitcoindClient {
    client: Arc<RpcClient>,
    priorities: Arc<Priorities>,
    handle: Handle,
}

impl BitcoindClient {
    pub async fn new(settings: &Settings) -> Result<BitcoindClient> {
        let cookie = std::fs::read(&settings.bitcoin_cookie_path)
            .context("Failed to read bitcoin cookie")?;
        let credentials = general_purpose::STANDARD.encode(cookie);
        let http_endpoint = HttpEndpoint::for_host(settings.bitcoind_rpc_host.clone())
            .with_port(settings.bitcoind_rpc_port);
        let client = Arc::new(
            RpcClient::new(&credentials, http_endpoint).context("failed to create rpc client")?,
        );

        let priorities = Arc::new(Priorities::new());
        let bitcoind_client = BitcoindClient {
            client,
            priorities,
            handle: tokio::runtime::Handle::current(),
        };

        // Check that the bitcoind we've connected to is running the network we expect
        let bitcoind_chain = bitcoind_client.get_blockchain_info().await?.chain;
        match (bitcoind_chain.as_ref(), settings.bitcoin_network) {
            ("main", Network::Bitcoin)
            | ("signet", Network::Signet)
            | ("test", Network::Testnet)
            | ("regtest", Network::Regtest) => (),
            _ => bail!(
                "Chain argument ({}) didn't match bitcoind chain ({bitcoind_chain})",
                settings.bitcoin_network,
            ),
        }
        Ok(bitcoind_client)
    }

    pub async fn wait_for_blockchain_synchronisation(&self) {
        info!("Waiting for blockchain synchronisation.");
        let wait_for_shutdown = tokio::spawn(quit_signal());
        while !wait_for_shutdown.is_finished() {
            if self.is_synchronised().await {
                info!("Blockchain is synchronised with network");
                return;
            }
            tokio::time::sleep(Duration::from_secs(5)).await;
        }
    }

    pub async fn send_transaction(&self, tx: &Transaction) -> Result<Txid> {
        let tx_serialized = json!(encode::serialize_hex(tx));
        BitcoindClient::send_transaction_with_client(self.client.clone(), tx_serialized).await
    }

    async fn send_transaction_with_client(
        client: Arc<RpcClient>,
        tx_serialized: Value,
    ) -> Result<Txid> {
        client
            .call_method::<JsonString>("sendrawtransaction", &[tx_serialized])
            .await?
            .deserialize()
    }

    pub async fn generate_to_address(
        &self,
        n_blocks: u64,
        address: &Address,
    ) -> Result<Vec<BlockHash>> {
        self.client
            .call_method::<JsonString>("generatetoaddress", &[json!(n_blocks), json!(address)])
            .await?
            .deserialize()
    }

    pub async fn get_block_hash(&self, height: u32) -> Result<BlockHash> {
        self.client
            .call_method::<JsonString>("getblockhash", &[json!(height)])
            .await?
            .deserialize()
    }

    pub fn poll_for_fee_estimates(&self) {
        let client = self.client.clone();
        let priorities = self.priorities.clone();
        tokio::spawn(async move {
            loop {
                BitcoindClient::estimate_fee(priorities.clone(), client.clone()).await;
                tokio::time::sleep(Duration::from_secs(60)).await;
            }
        });
    }

    async fn estimate_fee(priorities: Arc<Priorities>, client: Arc<RpcClient>) {
        for class in priorities.list_class() {
            match client
                .call_method::<JsonString>(
                    "estimatesmartfee",
                    &[json!(class.n_blocks), json!(class.estimate_mode)],
                )
                .await
                .map(|r| serde_json::from_str::<EstimateSmartFeeResult>(&r.0))
            {
                Ok(Ok(result)) => {
                    // Bitcoind returns fee in BTC/kB.
                    // So convert to sats and divide by 4 to get sats per 1000 weight units.
                    let fee = ((result
                        .fee_rate
                        .map(|amount| amount.to_sat())
                        .unwrap_or(class.default_fee_rate as u64)
                        / 4) as u32)
                        .max(MIN_FEERATE);
                    Priorities::store(class, fee);
                }
                Ok(Err(e)) => error!("Could not fetch fee estimate: {}", e),
                Err(e) => error!("Could not fetch fee estimate: {}", e),
            };
        }
    }

    /// To set up the lowest fee base for a testing environment
    pub fn set_lowest_fee_estimates(&self) {
        for class in self.priorities.list_class() {
            Priorities::store(class, 253);
        }
    }
}

#[derive(Clone, Debug, Deserialize)]
pub struct MempoolInfo {
    #[serde(rename = "mempoolminfee")]
    pub mempool_min_fee: f32,
}

#[async_trait]
impl BitcoindInterface for BitcoindClient {
    async fn get_blockchain_info(&self) -> Result<GetBlockchainInfoResult> {
        self.client
            .call_method::<JsonString>("getblockchaininfo", &[])
            .await?
            .deserialize()
    }

    async fn get_mempool_info(&self) -> Result<MempoolInfo> {
        self.client
            .call_method::<JsonString>("getmempoolinfo", &[])
            .await?
            .deserialize()
    }

    fn fee_rates_kw(&self) -> (u32, u32, u32) {
        let urgent = self.get_est_sat_per_1000_weight(ConfirmationTarget::OnChainSweep);
        let normal = self.get_est_sat_per_1000_weight(ConfirmationTarget::NonAnchorChannelFee);
        let slow = self.get_est_sat_per_1000_weight(ConfirmationTarget::ChannelCloseMinimum);
        (urgent, normal, slow)
    }

    async fn block_height(&self) -> Result<u64> {
        self.get_blockchain_info().await.map(|i| i.blocks)
    }
}

#[async_trait]
impl Service for BitcoindClient {
    async fn is_connected(&self) -> bool {
        self.get_best_block().await.is_ok()
    }

    async fn is_synchronised(&self) -> bool {
        let one_week = 60 * 60 * 24 * 7;
        let one_week_ago = SystemTime::now()
            .checked_sub(Duration::from_secs(one_week))
            .expect("wrong system time")
            .duration_since(UNIX_EPOCH)
            .expect("Wrong system time")
            .as_secs();
        match self.get_blockchain_info().await {
            Ok(info) => {
                info.blocks == info.headers
                    && info.median_time > one_week_ago
                    // Its rare to see 100% verification.
                    && info.verification_progress > 0.99
            }
            Err(_) => false,
        }
    }
}

#[async_trait]
pub trait BitcoindMetrics: Service {
    async fn block_height(&self) -> Result<u32>;
    fn fee_for(&self, target: ConfirmationTarget) -> u32;
}

#[async_trait]
impl BitcoindMetrics for BitcoindClient {
    async fn block_height(&self) -> Result<u32> {
        match self.client.get_best_block().await {
            Ok((_, Some(h))) => Ok(h),
            _ => Err(anyhow!("Could not get best block from bitcoind")),
        }
    }
    fn fee_for(&self, target: ConfirmationTarget) -> u32 {
        self.priorities.get(&target)
    }
}

struct JsonString(String);

impl JsonString {
    fn deserialize<'a, T>(&'a self) -> Result<T>
    where
        T: Deserialize<'a>,
    {
        serde_json::from_str(&self.0).map_err(|e| anyhow!(e))
    }
}

impl TryInto<JsonString> for JsonResponse {
    type Error = std::io::Error;

    fn try_into(self) -> std::result::Result<JsonString, Self::Error> {
        Ok(JsonString(self.0.to_string()))
    }
}

impl FeeEstimator for BitcoindClient {
    fn get_est_sat_per_1000_weight(&self, confirmation_target: ConfirmationTarget) -> u32 {
        self.priorities.get(&confirmation_target)
    }
}

impl BroadcasterInterface for BitcoindClient {
    fn broadcast_transactions(&self, txs: &[&Transaction]) {
        // This may error due to RL calling `broadcast_transaction` with the same transaction
        // multiple times, but the error is safe to ignore.
        let client = self.client.clone();
        for tx in txs {
            let tx_serialized = json!(encode::serialize_hex(tx));
            let client_cloned = client.clone();
            self.handle.spawn(async move {
                match BitcoindClient::send_transaction_with_client(client_cloned, tx_serialized)
                    .await
                {
                    Ok(txid) => {
                        info!("Broadcast transaction {txid}");
                    }
                    Err(e) => {
                        let err_str = e.to_string();
                        if !err_str.contains("Transaction already in block chain")
                            && !err_str.contains("Inputs missing or spent")
                            && !err_str.contains("bad-txns-inputs-missingorspent")
                            && !err_str.contains("txn-mempool-conflict")
                            && !err_str.contains("non-BIP68-final")
                            && !err_str.contains("insufficient fee, rejecting replacement ")
                        {
                            error!("Broadcast transaction: {}", e);
                        }
                    }
                }
            });
        }
    }
}

impl BlockSource for BitcoindClient {
    fn get_header<'a>(
        &'a self,
        header_hash: &'a BlockHash,
        height_hint: Option<u32>,
    ) -> AsyncBlockSourceResult<'a, BlockHeaderData> {
        Box::pin(async move { self.client.get_header(header_hash, height_hint).await })
    }

    fn get_block<'a>(
        &'a self,
        header_hash: &'a BlockHash,
    ) -> AsyncBlockSourceResult<'a, BlockData> {
        Box::pin(async move { self.client.get_block(header_hash).await })
    }

    fn get_best_block(&self) -> AsyncBlockSourceResult<(BlockHash, Option<u32>)> {
        Box::pin(async move { self.client.get_best_block().await })
    }
}

struct PriorityClass {
    // sats per 1000 weight unit
    fee_rate: AtomicU32,
    default_fee_rate: u32,
    n_blocks: u16,
    estimate_mode: EstimateMode,
}

struct Priorities {
    background: Arc<PriorityClass>,
    normal: Arc<PriorityClass>,
    high: Arc<PriorityClass>,
}

impl Priorities {
    fn new() -> Priorities {
        Priorities {
            background: Arc::new(PriorityClass {
                fee_rate: AtomicU32::new(MIN_FEERATE),
                default_fee_rate: MIN_FEERATE,
                n_blocks: 72,
                estimate_mode: EstimateMode::Conservative,
            }),
            normal: Arc::new(PriorityClass {
                fee_rate: AtomicU32::new(5000),
                default_fee_rate: 5000,
                n_blocks: 18,
                estimate_mode: EstimateMode::Conservative,
            }),
            high: Arc::new(PriorityClass {
                fee_rate: AtomicU32::new(10000),
                default_fee_rate: 10000,
                n_blocks: 6,
                estimate_mode: EstimateMode::Conservative,
            }),
        }
    }

    /// Return a base class and a mulipler
    fn priority_of(&self, conf_target: &ConfirmationTarget) -> (Arc<PriorityClass>, Option<f32>) {
        match conf_target {
            ConfirmationTarget::OnChainSweep => (self.high.clone(), None),
            ConfirmationTarget::NonAnchorChannelFee => (self.normal.clone(), None),
            ConfirmationTarget::ChannelCloseMinimum
            | ConfirmationTarget::AnchorChannelFee
            | ConfirmationTarget::MinAllowedAnchorChannelRemoteFee
            | ConfirmationTarget::MinAllowedNonAnchorChannelRemoteFee => {
                (self.background.clone(), None)
            }
        }
    }

    fn get(&self, conf_target: &ConfirmationTarget) -> u32 {
        let (priority, multiplier) = self.priority_of(conf_target);
        let base = priority.fee_rate.load(Ordering::Acquire);
        if let Some(multiplier) = multiplier {
            ((base as f32) * multiplier) as u32
        } else {
            base
        }
    }

    fn store(class: Arc<PriorityClass>, fee: u32) {
        class.fee_rate.store(fee, Ordering::Release);
    }

    fn list_class(&self) -> Vec<Arc<PriorityClass>> {
        vec![
            self.background.clone(),
            self.normal.clone(),
            self.high.clone(),
        ]
    }
}

'''
'''--- kld/src/bitcoind/bitcoind_interface.rs ---
use anyhow::Result;
use async_trait::async_trait;
use bitcoincore_rpc_json::GetBlockchainInfoResult;

use super::bitcoind_client::MempoolInfo;

#[async_trait]
pub trait BitcoindInterface: Send + Sync {
    async fn get_blockchain_info(&self) -> Result<GetBlockchainInfoResult>;

    async fn get_mempool_info(&self) -> Result<MempoolInfo>;

    fn fee_rates_kw(&self) -> (u32, u32, u32);

    async fn block_height(&self) -> Result<u64>;
}

'''
'''--- kld/src/bitcoind/mock.rs ---
use std::{str::FromStr, sync::Mutex};

use async_trait::async_trait;
use bitcoin::{BlockHash, Transaction, Txid};
use lightning::chain::chaininterface::{BroadcasterInterface, ConfirmationTarget, FeeEstimator};
use lightning_block_sync::{AsyncBlockSourceResult, BlockData, BlockHeaderData, BlockSource};

use crate::Service;

pub struct MockBitcoindClient {
    broadcast_transactions: Mutex<Vec<Txid>>,
    synchronised: bool,
}

impl Default for MockBitcoindClient {
    fn default() -> Self {
        Self {
            broadcast_transactions: Default::default(),
            synchronised: true,
        }
    }
}

#[async_trait]
impl Service for MockBitcoindClient {
    async fn is_connected(&self) -> bool {
        true
    }
    async fn is_synchronised(&self) -> bool {
        self.synchronised
    }
}

impl MockBitcoindClient {
    pub fn has_broadcast(&self, txid: Txid) -> bool {
        self.broadcast_transactions.lock().unwrap().contains(&txid)
    }

    pub fn set_synchronised(&mut self, synchronised: bool) {
        self.synchronised = synchronised;
    }
}

impl BroadcasterInterface for MockBitcoindClient {
    fn broadcast_transactions(&self, txs: &[&Transaction]) {
        for tx in txs {
            self.broadcast_transactions.lock().unwrap().push(tx.txid())
        }
    }
}

impl BlockSource for MockBitcoindClient {
    fn get_header<'a>(
        &'a self,
        _header_hash: &'a BlockHash,
        _height_hint: Option<u32>,
    ) -> AsyncBlockSourceResult<'a, BlockHeaderData> {
        todo!()
    }

    fn get_block<'a>(
        &'a self,
        _header_hash: &'a BlockHash,
    ) -> AsyncBlockSourceResult<'a, BlockData> {
        todo!()
    }

    fn get_best_block<'a>(&'_ self) -> AsyncBlockSourceResult<(BlockHash, Option<u32>)> {
        Box::pin(async {
            Ok((
                BlockHash::from_str(
                    "000000000000000000015d9e9473a56a7dde8ea974f0efd2ff9bd068f052134a",
                )
                .unwrap(),
                Some(782000),
            ))
        })
    }
}

impl FeeEstimator for MockBitcoindClient {
    fn get_est_sat_per_1000_weight(&self, confirmation_target: ConfirmationTarget) -> u32 {
        match confirmation_target {
            ConfirmationTarget::NonAnchorChannelFee => 2000,
            ConfirmationTarget::OnChainSweep => 10000,
            ConfirmationTarget::ChannelCloseMinimum
            | ConfirmationTarget::AnchorChannelFee
            | ConfirmationTarget::MinAllowedAnchorChannelRemoteFee
            | ConfirmationTarget::MinAllowedNonAnchorChannelRemoteFee => 500,
        }
    }
}

'''
'''--- kld/src/bitcoind/mod.rs ---
mod bitcoind_client;
pub mod bitcoind_interface;
mod utxo_lookup;

pub use bitcoind_client::{BitcoindClient, BitcoindMetrics, MempoolInfo};
pub use utxo_lookup::BitcoindUtxoLookup;

#[cfg(test)]
pub mod mock;
#[cfg(test)]
pub use mock::MockBitcoindClient;

'''
'''--- kld/src/bitcoind/utxo_lookup.rs ---
use std::sync::{Arc, Weak};

use crate::logger::KldLogger;
use crate::settings::Settings;
use bitcoin::blockdata::constants::ChainHash;
use lightning::routing::{
    gossip::P2PGossipSync,
    utxo::{UtxoFuture, UtxoLookup, UtxoLookupError, UtxoResult},
};
use lightning_block_sync::{BlockData, BlockSource};
use log::warn;
use tokio::runtime::Handle;

use crate::ldk::{
    channel_utils::{block_from_scid, tx_index_from_scid, vout_from_scid},
    NetworkGraph,
};

use super::BitcoindClient;

pub struct BitcoindUtxoLookup {
    bitcoind: Arc<BitcoindClient>,
    network_graph: Arc<NetworkGraph>,
    gossip_sync: Weak<P2PGossipSync<Arc<NetworkGraph>, Arc<BitcoindUtxoLookup>, Arc<KldLogger>>>,
    genesis: ChainHash,
    runtime: Handle,
}

impl BitcoindUtxoLookup {
    pub fn new(
        settings: &Settings,
        bitcoind: Arc<BitcoindClient>,
        network_graph: Arc<NetworkGraph>,
        gossip_sync: Weak<
            P2PGossipSync<Arc<NetworkGraph>, Arc<BitcoindUtxoLookup>, Arc<KldLogger>>,
        >,
    ) -> BitcoindUtxoLookup {
        BitcoindUtxoLookup {
            bitcoind,
            network_graph,
            gossip_sync,
            genesis: ChainHash::using_genesis_block(settings.bitcoin_network),
            runtime: tokio::runtime::Handle::current(),
        }
    }
}

impl UtxoLookup for BitcoindUtxoLookup {
    fn get_utxo(&self, genesis_hash: &ChainHash, short_channel_id: u64) -> UtxoResult {
        if *genesis_hash != self.genesis {
            return UtxoResult::Sync(Err(UtxoLookupError::UnknownChain));
        }
        let async_result = UtxoFuture::new();
        let result = async_result.clone();
        let network_graph = self.network_graph.clone();
        let bitcoind = self.bitcoind.clone();
        let gossip_sync = self.gossip_sync.clone();
        self.runtime.spawn(async move {
            let resolve = |utxo| {
                if let Some(gossip_sync) = gossip_sync.upgrade() {
                    result.resolve(&network_graph, gossip_sync, utxo);
                } else {
                    result.resolve_without_forwarding(&network_graph, utxo);
                }
            };
            let height = block_from_scid(&short_channel_id);
            let index = tx_index_from_scid(&short_channel_id);
            let vout = vout_from_scid(&short_channel_id);
            let block_hash = match bitcoind.get_block_hash(height).await {
                Ok(hash) => hash,
                Err(e) => {
                    warn!("Could not get block hash for height {height}: {e}");
                    return resolve(Err(UtxoLookupError::UnknownTx));
                }
            };
            let block = match bitcoind.as_ref().get_block(&block_hash).await {
                Ok(BlockData::FullBlock(block)) => block,
                _ => {
                    warn!("Could not get block with hash {block_hash}");
                    return resolve(Err(UtxoLookupError::UnknownTx));
                }
            };
            if let Some(tx) = block.txdata.get(index as usize) {
                if let Some(utxo) = tx.output.get(vout as usize) {
                    return resolve(Ok(utxo.clone()));
                }
            }
            resolve(Err(UtxoLookupError::UnknownTx))
        });
        UtxoResult::Async(async_result)
    }
}

'''
'''--- kld/src/cli/client.rs ---
use std::{
    fs::{self, File},
    io::Write,
    net::SocketAddr,
    path::PathBuf,
    str::FromStr,
};

use anyhow::Result;
use kld::api::codegen::{
    get_kld_channel_response::GetKldChannelResponseItem,
    get_v1_channel_history_response::GetV1ChannelHistoryResponseItem,
    get_v1_channel_list_forwards_response::GetV1ChannelListForwardsResponseItem,
    get_v1_channel_list_peer_channels_response::GetV1ChannelListPeerChannelsResponse,
    get_v1_channel_localremotebal_response::GetV1ChannelLocalremotebalResponse,
    get_v1_estimate_channel_liquidity_body::GetV1EstimateChannelLiquidityBody,
    get_v1_estimate_channel_liquidity_response::GetV1EstimateChannelLiquidityResponse,
    get_v1_get_fees_response::GetV1GetFeesResponse, get_v1_newaddr_response::GetV1NewaddrResponse,
    get_v1_pay_list_payments_response::GetV1PayListPaymentsResponse,
    get_v1_utility_decode_invoice_string_response::GetV1UtilityDecodeInvoiceStringResponse,
    post_v1_peer_connect_body::PostV1PeerConnectBody,
    post_v1_peer_connect_response::PostV1PeerConnectResponse,
};
use kld::api::payloads::{
    ChannelFee, FeeRate, FeeRatesResponse, FundChannel, FundChannelResponse, GenerateInvoice,
    GenerateInvoiceResponse, GetInfo, Invoice, KeysendRequest, ListFunds, NetworkChannel,
    NetworkNode, PayInvoice, PaymentResponse, Peer, SetChannelFeeResponse, SignRequest,
    SignResponse, WalletBalance, WalletTransfer, WalletTransferResponse,
};
use kld::api::routes;
use reqwest::{
    blocking::{Client, ClientBuilder, RequestBuilder, Response},
    header::{HeaderValue, CONTENT_TYPE},
    Certificate, Method,
};
use serde::{de::DeserializeOwned, Serialize};
use serde_json::to_string_pretty;

pub struct Api {
    host: SocketAddr,
    client: Client,
    macaroon: Vec<u8>,
}

impl Api {
    pub fn new(host: SocketAddr, cert_path: PathBuf, macaroon_path: PathBuf) -> Result<Api> {
        let macaroon = fs::read(macaroon_path)?;
        let cert = Certificate::from_pem(&fs::read(cert_path)?)?;
        // Rustls does not support IP addresses (hostnames only) so we need to use native tls (openssl)
        let client = ClientBuilder::new()
            .add_root_certificate(cert)
            .use_native_tls()
            .timeout(None)
            .build()?;
        Ok(Api {
            host,
            client,
            macaroon,
        })
    }

    pub fn sign(&self, message: String) -> Result<String> {
        let response = self
            .request_with_body(Method::POST, routes::SIGN, SignRequest { message })
            .send()?;
        deserialize::<SignResponse>(response)
    }

    pub fn get_info(&self) -> Result<String> {
        let response = self.request(Method::GET, routes::GET_INFO).send()?;
        deserialize::<GetInfo>(response)
    }

    pub fn get_balance(&self) -> Result<String> {
        let response = self.request(Method::GET, routes::GET_BALANCE).send()?;
        deserialize::<WalletBalance>(response)
    }

    pub fn new_address(&self) -> Result<String> {
        let response = self.request(Method::GET, routes::NEW_ADDR).send()?;
        deserialize::<GetV1NewaddrResponse>(response)
    }

    pub fn withdraw(
        &self,
        address: String,
        satoshis: String,
        fee_rate: Option<String>,
    ) -> Result<String> {
        let wallet_transfer = WalletTransfer {
            address,
            satoshis,
            fee_rate: fee_rate.map(|f| FeeRate::from_str(&f)).transpose()?,
            min_conf: None,
            utxos: vec![],
        };
        let response = self
            .request_with_body(Method::POST, routes::WITHDRAW, wallet_transfer)
            .send()?;
        deserialize::<WalletTransferResponse>(response)
    }

    pub fn list_funds(&self) -> Result<String> {
        let response = self.request(Method::GET, routes::LIST_FUNDS).send()?;
        deserialize::<ListFunds>(response)
    }

    pub fn list_channels(&self) -> Result<String> {
        let response = self.request(Method::GET, routes::LIST_CHANNELS).send()?;
        deserialize::<Vec<GetKldChannelResponseItem>>(response)
    }

    pub fn list_peer_channels(&self) -> Result<String> {
        let response = self
            .request(Method::GET, routes::LIST_PEER_CHANNELS)
            .send()?;
        deserialize::<Vec<GetV1ChannelListPeerChannelsResponse>>(response)
    }

    pub fn list_peers(&self) -> Result<String> {
        let response = self.request(Method::GET, routes::LIST_PEERS).send()?;
        deserialize::<Vec<Peer>>(response)
    }

    pub fn connect_peer(&self, id: String) -> Result<String> {
        let connect = PostV1PeerConnectBody { id };
        let response = self
            .request_with_body(Method::POST, routes::CONNECT_PEER, connect)
            .send()?;
        deserialize::<PostV1PeerConnectResponse>(response)
    }

    pub fn disconnect_peer(&self, id: String) -> Result<String> {
        let response = self
            .request(Method::DELETE, &routes::DISCONNECT_PEER.replace(":id", &id))
            .send()?;
        deserialize::<()>(response)
    }

    pub fn open_channel(
        &self,
        id: String,
        satoshis: String,
        push_msat: Option<String>,
        announce: Option<bool>,
        fee_rate: Option<String>,
    ) -> Result<String> {
        let open_channel = FundChannel {
            id,
            satoshis,
            fee_rate: fee_rate.map(|f| FeeRate::from_str(&f)).transpose()?,
            announce,
            min_conf: None,
            utxos: vec![],
            push_msat,
            close_to: None,
            request_amt: None,
            compact_lease: None,
        };
        let response = self
            .request_with_body(Method::POST, routes::OPEN_CHANNEL, open_channel)
            .send()?;
        deserialize::<FundChannelResponse>(response)
    }

    pub fn set_channel_fee(
        &self,
        id: String,
        base: Option<u32>,
        ppm: Option<u32>,
    ) -> Result<String> {
        let fee_request = ChannelFee { id, base, ppm };
        let response = self
            .request_with_body(Method::POST, routes::SET_CHANNEL_FEE, fee_request)
            .send()?;
        deserialize::<SetChannelFeeResponse>(response)
    }

    pub fn close_channel(&self, id: String, fee_rate: Option<u32>) -> Result<String> {
        let response = if let Some(fee_rate) = fee_rate {
            self.request(
                Method::DELETE,
                &routes::CLOSE_CHANNEL_WITH_FEE
                    .replace(":id", &id)
                    .replace(":fee_rate", &fee_rate.to_string()),
            )
            .send()?
        } else {
            self.request(Method::DELETE, &routes::CLOSE_CHANNEL.replace(":id", &id))
                .send()?
        };
        deserialize::<()>(response)
    }

    pub fn force_close_channel(&self, id: String, may_broadcast: bool) -> Result<String> {
        let response = if may_broadcast {
            self.request(
                Method::DELETE,
                &routes::FORCE_CLOSE_CHANNEL_WITH_BROADCAST.replace(":id", &id),
            )
            .send()?
        } else {
            self.request(
                Method::DELETE,
                &routes::FORCE_CLOSE_CHANNEL_WITHOUT_BROADCAST.replace(":id", &id),
            )
            .send()?
        };
        deserialize::<()>(response)
    }

    pub fn list_network_nodes(&self, id: Option<String>) -> Result<String> {
        let response = if let Some(id) = id {
            self.request(Method::GET, &routes::LIST_NETWORK_NODE.replace(":id", &id))
                .send()?
        } else {
            self.request(Method::GET, routes::LIST_NETWORK_NODES)
                .send()?
        };
        deserialize::<Vec<NetworkNode>>(response)
    }

    pub fn list_network_channels(&self, id: Option<String>) -> Result<String> {
        let response = if let Some(id) = id {
            self.request(
                Method::GET,
                &routes::LIST_NETWORK_CHANNEL.replace(":id", &id),
            )
            .send()?
        } else {
            self.request(Method::GET, routes::LIST_NETWORK_CHANNELS)
                .send()?
        };
        deserialize::<Vec<NetworkChannel>>(response)
    }

    pub fn fee_rates(&self, style: Option<String>) -> Result<String> {
        let response = self
            .request(
                Method::GET,
                &routes::FEE_RATES.replace(":style", &style.unwrap_or("perkb".to_string())),
            )
            .send()?;
        deserialize::<FeeRatesResponse>(response)
    }

    pub fn keysend(&self, public_key: String, amount: u64) -> Result<String> {
        let body = KeysendRequest {
            pubkey: public_key,
            amount,
            label: None,
            maxfeepercent: None,
            retry_for: None,
            maxdelay: None,
            exemptfee: None,
        };
        let response = self
            .request_with_body(Method::POST, routes::KEYSEND, body)
            .send()?;
        deserialize::<PaymentResponse>(response)
    }

    pub fn generate_invoice(
        &self,
        amount: u64,
        label: String,
        description: String,
        expiry: Option<u32>,
    ) -> Result<String> {
        let body = GenerateInvoice {
            amount,
            label,
            description,
            expiry,
            ..Default::default()
        };
        let response = self
            .request_with_body(Method::POST, routes::GENERATE_INVOICE, body)
            .send()?;
        deserialize::<GenerateInvoiceResponse>(response)
    }

    pub fn list_invoices(&self, label: Option<String>) -> Result<String> {
        let route = if let Some(label) = label {
            format!("{}?{label}", routes::LIST_INVOICES)
        } else {
            routes::LIST_INVOICES.to_string()
        };
        let response = self.request(Method::GET, &route).send()?;
        deserialize::<Vec<Invoice>>(response)
    }

    pub fn pay_invoice(&self, bolt11: String, label: Option<String>) -> Result<String> {
        let body = PayInvoice {
            invoice: bolt11,
            label,
        };
        let response = self
            .request_with_body(Method::POST, routes::PAY_INVOICE, body)
            .send()?;
        deserialize::<PaymentResponse>(response)
    }

    pub fn list_payments(
        &self,
        bolt11: Option<String>,
        direction: Option<String>,
    ) -> Result<String> {
        let mut params = vec![];
        if let Some(bolt11) = bolt11 {
            params.push(("bolt11", bolt11));
        }
        if let Some(direction) = direction {
            params.push(("direction", direction));
        }
        let response = self
            .request(Method::GET, routes::LIST_PAYMENTS)
            .query(&params)
            .send()?;
        deserialize::<GetV1PayListPaymentsResponse>(response)
    }

    pub fn estimate_channel_liquidity(&self, scid: u64, target: String) -> Result<String> {
        let body = GetV1EstimateChannelLiquidityBody { scid, target };
        let response = self
            .request_with_body(Method::GET, routes::ESTIMATE_CHANNEL_LIQUIDITY, body)
            .send()?;
        deserialize::<GetV1EstimateChannelLiquidityResponse>(response)
    }

    pub fn local_remote_balance(&self) -> Result<String> {
        let response = self
            .request(Method::GET, routes::LOCAL_REMOTE_BALANCE)
            .send()?;
        deserialize::<GetV1ChannelLocalremotebalResponse>(response)
    }

    pub fn get_fees(&self) -> Result<String> {
        let response = self.request(Method::GET, routes::GET_FEES).send()?;
        deserialize::<GetV1GetFeesResponse>(response)
    }

    pub fn list_forwards(&self, status: Option<String>) -> Result<String> {
        let mut params = vec![];
        if let Some(status) = status {
            params.push(("status", status));
        }
        let response = self
            .request(Method::GET, routes::LIST_FORWARDS)
            .query(&params)
            .send()?;
        deserialize::<Vec<GetV1ChannelListForwardsResponseItem>>(response)
    }

    pub fn channel_history(&self) -> Result<String> {
        let response = self
            .request(Method::GET, routes::LIST_CHANNEL_HISTORY)
            .send()?;
        deserialize::<Vec<GetV1ChannelHistoryResponseItem>>(response)
    }

    pub fn decode(&self, invoice: String) -> Result<String> {
        let response = self
            .request(
                Method::GET,
                &routes::DECODE_INVOICE.replace(":invoice", &invoice),
            )
            .send()?;
        deserialize::<GetV1UtilityDecodeInvoiceStringResponse>(response)
    }

    pub fn scorer(&self, path: PathBuf) -> Result<String> {
        let scorer = self.request(Method::GET, routes::SCORER).send()?.bytes()?;
        let mut f = File::create(&path)?;
        f.write_all(&scorer)?;

        Ok(format!("scorer save in {}", path.display()))
    }

    fn request_builder(&self, method: Method, route: &str) -> RequestBuilder {
        self.client
            .request(method, format!("https://{}{}", self.host, route))
            .header(CONTENT_TYPE, HeaderValue::from_static("application/json"))
            .header("macaroon", self.macaroon.clone())
    }

    fn request(&self, method: Method, route: &str) -> RequestBuilder {
        self.request_builder(method, route)
    }

    fn request_with_body<T: Serialize>(
        &self,
        method: Method,
        route: &str,
        body: T,
    ) -> RequestBuilder {
        let body = serde_json::to_string(&body).unwrap();
        self.request_builder(method, route).body(body)
    }
}

fn deserialize<T: DeserializeOwned + Serialize>(response: Response) -> Result<String> {
    if response.status().is_success() {
        Ok(to_string_pretty(&response.json::<T>()?)?)
    } else {
        Ok(to_string_pretty(
            &response.json::<kld::api::payloads::Error>()?,
        )?)
    }
}

'''
'''--- kld/src/cli/commands.rs ---
use std::{net::SocketAddr, path::PathBuf};

use clap::{Parser, Subcommand};

#[derive(Parser, Debug)]
#[command(author, version, about, long_about = None)]
pub struct KldCliCommand {
    /// IP address the target machine.
    #[arg(short, long, hide = true)]
    pub target: SocketAddr,
    /// Path to the TLS cert of the target API.
    #[arg(short, long, hide = true)]
    pub cert_path: PathBuf,
    /// Path to the macaroon for authenticating with the API.
    #[arg(short, long, hide = true)]
    pub macaroon_path: PathBuf,
    /// Command to run.
    #[clap(subcommand)]
    pub command: KldCliSubCommand,
}

#[derive(Subcommand, Debug)]
pub enum KldCliSubCommand {
    /// Fetch information about this lightning node.
    GetInfo,
    /// Creates a signature of the message using node's secret key (message limit 65536 chars)
    Sign {
        /// Message to be signed (max 65536 chars)
        #[arg()]
        message: String,
    },
    /// Fetch confirmed and unconfirmed on-chain balance.
    GetBalance,
    /// Generates new on-chain address for receiving funds.
    NewAddress,
    /// Send on-chain funds out of the wallet.
    Withdraw {
        /// The address to withdraw to.
        #[arg()]
        address: String,
        /// The amount to withdraw (in Satoshis). The string "all" will empty the wallet.
        #[arg()]
        amount: String,
        /// Fee rate [urgent/normal/slow/<sats>perkw/<sats>perkb]
        #[arg(short, long)]
        fee_rate: Option<String>,
    },
    /// Show available funds from the internal wallet.
    ListFunds,
    /// Fetch a list of this nodes peers.
    ListPeers,
    /// Connect with a network peer.
    ConnectPeer {
        /// The public key (id) of the node to connect to. Optionally provide host and port [id@host:port].
        #[arg()]
        public_key: String,
    },
    /// Disconnect from a network peer.
    DisconnectPeer {
        /// The public key of the node to disconnect from.
        #[arg()]
        public_key: String,
    },
    /// Fetch a list of channels
    ListChannels,
    /// Fetch a list of this nodes open channels.
    ListPeerChannels,
    /// Open a channel with another node.
    OpenChannel {
        /// The public key of the node to open a channel with. Optionally provide host and port [id@host:port].
        #[arg()]
        public_key: String,
        /// Amount of satoshis to commit to the channel.
        #[arg()]
        sats: String,
        /// The number of satoshis to push to the other node side of the channel.
        #[arg(short, long)]
        push_msat: Option<String>,
        /// Whether to announce the channel to the rest of the network (public - default) or not (private).
        #[arg(short, long)]
        announce: Option<bool>,
        /// Fee rate [urgent/normal/slow/<sats>perkw/<sats>perkb]
        #[arg(short, long)]
        fee_rate: Option<String>,
    },
    /// Set channel fees.
    SetChannelFee {
        /// Channel ID, short channel ID or "all" for all channels.
        #[arg()]
        id: String,
        /// Optional value in msats added as base fee to any routed payment.
        #[arg(short, long)]
        base_fee: Option<u32>,
        /// Optional value that is added proportionally per-millionths to any routed payment volume in satoshi
        #[arg(short, long)]
        ppm_fee: Option<u32>,
    },
    /// Close a channel.
    CloseChannel {
        /// Channel ID or short channel ID to close.
        #[arg()]
        id: String,

        /// Close with fee rate in sats per 1000 weight.
        /// This option do not work with `force_close` option
        #[arg(short, long)]
        fee_rate: Option<u32>,

        /// Force closes a channel with or without broadcasting the latest local transaction(s) .
        /// If `broadcast-flag` is `broadcast`, it will immediately broadcasting the latest local transaction(s) and rejecting new HTLCs on the given channel.
        /// If `broadcast-flag` is `no-broadcast`, it will rejecting new HTLCs on the given channel but skips broadcasting the latest local transaction(s).
        #[arg(long, name = "broadcast-flag")]
        force_close: Option<String>,
    },
    /// Get node information from the network graph.
    NetworkNodes {
        /// Provide Node ID to get info about a single node.
        #[arg(short, long)]
        id: Option<String>,
    },
    /// Get channel information from the network graph.
    NetworkChannels {
        /// Provide short channel ID to get info about a single channel.
        #[arg(short, long)]
        id: Option<String>,
    },
    /// Return feerate estimates, either satoshi-per-kw or satoshi-per-kb.
    FeeRates {
        /// perkb (default) or perkw
        #[arg(short, long)]
        style: Option<String>,
    },
    /// Pay a node without an invoice.
    Keysend {
        /// Node ID of the payee.
        #[arg()]
        public_key: String,
        /// Amount to pay in millisats.
        #[arg()]
        amount: u64,
    },
    /// Generate a bolt11 invoice for receiving a payment.
    GenerateInvoice {
        /// Amount in millisats
        #[arg()]
        amount: u64,
        /// Unique label for the invoice
        #[arg()]
        label: String,
        /// Description for the invoice
        #[arg()]
        description: String,
        /// Expiry time period for the invoice (seconds)
        #[arg(short, long)]
        expiry: Option<u32>,
    },
    /// List all invoices
    ListInvoices {
        /// Label of the invoice
        #[arg(short, long)]
        label: Option<String>,
    },
    /// Pay an invoice
    PayInvoice {
        /// The invoice to pay
        #[arg()]
        bolt11: String,
        /// Label for the payment
        #[arg(short, long)]
        label: Option<String>,
    },
    /// List all payments
    ListPayments {
        /// Bolt11 invoice of payment
        #[arg(short, long)]
        bolt11: Option<String>,
        /// Direction (inbound/outbound)
        #[arg(short, long)]
        direction: Option<String>,
    },
    /// Estimate channel liquidity to a target node
    EstimateChannelLiquidity {
        /// Short channel ID
        #[arg()]
        scid: u64,
        /// Bolt11 invoice of payment
        #[arg()]
        target: String,
    },
    /// Fetch the aggregate local and remote channel balances (msat) of the node
    LocalRemoteBalance,
    /// Get node routing fees.
    GetFees,
    /// Fetch a list of the forwarded htlcs.
    ListForwards {
        /// The status of the forwards (succeeded, failed)
        #[arg(short, long)]
        status: Option<String>,
    },
    /// Fetch a list of historic (closed) channels
    ListChannelHistory,
    /// Decode invoice
    Decode { invoice: String },

    /// Download scorer to the path, if unspecific, will use `scorer.bin` as default
    Scorer { path: Option<PathBuf> },
}

'''
'''--- kld/src/cli/main.rs ---
mod client;
mod commands;

use crate::client::Api;
use anyhow::{bail, Result};
use clap::Parser;
use commands::{KldCliCommand, KldCliSubCommand};

fn main() {
    let args = KldCliCommand::parse();

    if let Err(e) = run_command(args) {
        eprintln!("Error executing command: {e}");
        std::process::exit(1);
    }
}

fn run_command(args: KldCliCommand) -> Result<()> {
    let api = Api::new(args.target, args.cert_path, args.macaroon_path)?;

    let output = match args.command {
        KldCliSubCommand::Sign { message } => api.sign(message)?,
        KldCliSubCommand::GetInfo => api.get_info()?,
        KldCliSubCommand::GetBalance => api.get_balance()?,
        KldCliSubCommand::NewAddress => api.new_address()?,
        KldCliSubCommand::Withdraw {
            address,
            amount: satoshis,
            fee_rate,
        } => api.withdraw(address, satoshis, fee_rate)?,
        KldCliSubCommand::ListFunds => api.list_funds()?,
        KldCliSubCommand::ListPeerChannels => api.list_peer_channels()?,
        KldCliSubCommand::ListPeers => api.list_peers()?,
        KldCliSubCommand::ConnectPeer { public_key } => api.connect_peer(public_key)?,
        KldCliSubCommand::DisconnectPeer { public_key } => api.disconnect_peer(public_key)?,
        KldCliSubCommand::OpenChannel {
            public_key,
            sats: satoshis,
            push_msat,
            announce,
            fee_rate,
        } => api.open_channel(public_key, satoshis, push_msat, announce, fee_rate)?,
        KldCliSubCommand::SetChannelFee {
            id,
            base_fee,
            ppm_fee,
        } => api.set_channel_fee(id, base_fee, ppm_fee)?,
        KldCliSubCommand::CloseChannel {
            id,
            force_close: None,
            fee_rate,
        } => api.close_channel(id, fee_rate)?,
        KldCliSubCommand::CloseChannel {
            id,
            force_close: Some(broadcast_flag),
            ..
        } => {
            let need_broadcast = match broadcast_flag.as_str() {
                "broadcast" => true,
                "no-broadcast" => false,
                _ => bail!("the broadcast-flag need to `broadcast` or `no-broadcast`"),
            };
            api.force_close_channel(id, need_broadcast)?
        }
        KldCliSubCommand::NetworkNodes { id } => api.list_network_nodes(id)?,
        KldCliSubCommand::NetworkChannels { id } => api.list_network_channels(id)?,
        KldCliSubCommand::FeeRates { style } => api.fee_rates(style)?,
        KldCliSubCommand::Keysend { public_key, amount } => api.keysend(public_key, amount)?,
        KldCliSubCommand::GenerateInvoice {
            amount,
            label,
            description,
            expiry,
        } => api.generate_invoice(amount, label, description, expiry)?,
        KldCliSubCommand::ListInvoices { label } => api.list_invoices(label)?,
        KldCliSubCommand::PayInvoice { bolt11, label } => api.pay_invoice(bolt11, label)?,
        KldCliSubCommand::ListPayments { bolt11, direction } => {
            api.list_payments(bolt11, direction)?
        }
        KldCliSubCommand::EstimateChannelLiquidity { scid, target } => {
            api.estimate_channel_liquidity(scid, target)?
        }
        KldCliSubCommand::LocalRemoteBalance => api.local_remote_balance()?,
        KldCliSubCommand::GetFees => api.get_fees()?,
        KldCliSubCommand::ListForwards { status } => api.list_forwards(status)?,
        KldCliSubCommand::ListChannelHistory => api.channel_history()?,
        KldCliSubCommand::Decode { invoice } => api.decode(invoice)?,
        KldCliSubCommand::Scorer { path } => api.scorer(path.unwrap_or("scorer.bin".into()))?,
        KldCliSubCommand::ListChannels => api.list_channels()?,
    };
    if output != "null" {
        println!("{output}");
    }
    Ok(())
}

'''
'''--- kld/src/database/forward.rs ---
use crate::MillisatAmount;

use lightning::events::HTLCDestination;
use lightning::ln::ChannelId;
use postgres_types::{FromSql, ToSql};
use time::OffsetDateTime;
use tokio_postgres::Row;
use uuid::Uuid;

use super::{microsecond_timestamp, RowExt};

#[derive(Debug, PartialEq, Clone)]
pub struct Forward {
    pub id: Uuid,
    pub inbound_channel_id: ChannelId,
    pub outbound_channel_id: Option<ChannelId>,
    pub amount: Option<MillisatAmount>,
    pub fee: Option<MillisatAmount>,
    pub status: ForwardStatus,
    pub htlc_destination: Option<HTLCDestination>,
    pub timestamp: OffsetDateTime,
}

impl Forward {
    pub fn success(
        inbound_channel_id: ChannelId,
        outbound_channel_id: ChannelId,
        amount: MillisatAmount,
        fee: MillisatAmount,
    ) -> Forward {
        Forward {
            id: Uuid::new_v4(),
            inbound_channel_id,
            outbound_channel_id: Some(outbound_channel_id),
            amount: Some(amount),
            fee: Some(fee),
            status: ForwardStatus::Succeeded,
            htlc_destination: None,
            timestamp: microsecond_timestamp(),
        }
    }

    pub fn failure(inbound_channel_id: ChannelId, htlc_destination: HTLCDestination) -> Forward {
        Forward {
            id: Uuid::new_v4(),
            inbound_channel_id,
            outbound_channel_id: None,
            amount: None,
            fee: None,
            status: ForwardStatus::Failed,
            htlc_destination: Some(htlc_destination),
            timestamp: microsecond_timestamp(),
        }
    }
}

impl TryFrom<Row> for Forward {
    type Error = anyhow::Error;

    fn try_from(row: Row) -> std::result::Result<Self, Self::Error> {
        let outbound_channel_id: Option<[u8; 32]> = row
            .get::<&str, Option<&[u8]>>("outbound_channel_id")
            .map(|x| x.try_into())
            .transpose()?;
        Ok(Forward {
            id: row.get("id"),
            inbound_channel_id: ChannelId::from_bytes(
                row.get::<&str, &[u8]>("inbound_channel_id").try_into()?,
            ),
            outbound_channel_id: outbound_channel_id.map(ChannelId::from_bytes),
            amount: row
                .get::<&str, Option<i64>>("amount")
                .map(|x| x as MillisatAmount),
            fee: row
                .get::<&str, Option<i64>>("fee")
                .map(|x| x as MillisatAmount),
            status: row.get("status"),
            htlc_destination: row.read_optional("htlc_destination")?,
            timestamp: row.get_timestamp("timestamp"),
        })
    }
}

#[derive(Debug, ToSql, FromSql, PartialEq, Clone, Copy)]
#[postgres(name = "forward_status")]
pub enum ForwardStatus {
    #[postgres(name = "succeeded")]
    Succeeded,
    #[postgres(name = "failed")]
    Failed,
}

impl From<Row> for TotalForwards {
    fn from(row: Row) -> Self {
        TotalForwards {
            count: row.get::<&str, i64>("count") as MillisatAmount,
            amount: row.get::<&str, i64>("amount") as MillisatAmount,
            fee: row.get::<&str, i64>("fee") as MillisatAmount,
        }
    }
}

pub struct TotalForwards {
    pub count: u64,
    pub amount: MillisatAmount,
    pub fee: MillisatAmount,
}

'''
'''--- kld/src/database/invoice.rs ---
use std::{str::FromStr, time::SystemTime};

use anyhow::{anyhow, Result};
use bitcoin::{hashes::Hash, secp256k1::PublicKey};
use lightning::ln::PaymentHash;

use crate::MillisatAmount;

use super::payment::Payment;

#[derive(Clone, Debug, PartialEq)]
pub struct Invoice {
    pub payment_hash: PaymentHash,
    // User generated id for the invoice.
    pub label: Option<String>,
    pub bolt11: lightning_invoice::Bolt11Invoice,
    // None if we are the payee.
    pub payee_pub_key: PublicKey,
    pub expiry: Option<u64>,
    pub amount: Option<MillisatAmount>,
    // The time that the invoice was generated.
    pub timestamp: SystemTime,
    // Payments with the payment_hash of the bolt11 invoice.
    pub payments: Vec<Payment>,
}

impl TryFrom<String> for Invoice {
    type Error = anyhow::Error;

    fn try_from(value: String) -> std::result::Result<Self, Self::Error> {
        let bolt11 = lightning_invoice::Bolt11Invoice::from_str(&value)?;
        bolt11.check_signature()?;
        Invoice::new(None, bolt11)
    }
}

impl Invoice {
    pub fn new(label: Option<String>, bolt11: lightning_invoice::Bolt11Invoice) -> Result<Self> {
        let raw = bolt11.clone().into_signed_raw();
        let expiry = raw.expiry_time().map(|t| t.as_seconds());
        let payee_pub_key = raw.recover_payee_pub_key()?.0;
        let amount = raw.amount_pico_btc().map(|a| a / 10);
        let timestamp = bolt11.timestamp();
        Ok(Invoice {
            payment_hash: PaymentHash(
                raw.payment_hash()
                    .ok_or_else(|| anyhow!("missing payment hash"))?
                    .0
                    .to_byte_array(),
            ),
            label,
            bolt11,
            payee_pub_key,
            expiry,
            amount,
            timestamp,
            payments: vec![],
        })
    }

    pub fn deserialize(
        payment_hash: PaymentHash,
        label: Option<String>,
        bolt11: String,
        payee_pub_key: Vec<u8>,
        expiry: Option<u64>,
        amount: Option<i64>,
        timestamp: SystemTime,
    ) -> Result<Self> {
        Ok(Invoice {
            payment_hash,
            label,
            bolt11: lightning_invoice::Bolt11Invoice::from_str(&bolt11)?,
            payee_pub_key: PublicKey::from_slice(&payee_pub_key)?,
            expiry,
            amount: amount.map(|a| a as u64),
            timestamp,
            payments: vec![],
        })
    }
}

'''
'''--- kld/src/database/ldk_database.rs ---
use crate::database::{microsecond_timestamp, to_primitive, RowExt};
use crate::ldk::{ldk_error, ChainMonitor};
use crate::logger::KldLogger;
use crate::settings::Settings;
use bitcoin_hashes::Hash;

use super::forward::{Forward, ForwardStatus, TotalForwards};
use super::invoice::Invoice;
use super::payment::{Payment, PaymentDirection};
use super::{DurableConnection, Params};
use anyhow::bail;
use anyhow::{anyhow, Result};
use bitcoin::secp256k1::PublicKey;
use bitcoin::BlockHash;
use bitcoin::Txid;
use lightning::chain::chaininterface::{BroadcasterInterface, FeeEstimator};
use lightning::chain::chainmonitor::MonitorUpdateId;
use lightning::chain::channelmonitor::{ChannelMonitor, ChannelMonitorUpdate};
use lightning::chain::transaction::OutPoint;
use lightning::chain::{self, ChannelMonitorUpdateStatus, Watch};
use lightning::ln::channelmanager::{ChannelDetails, ChannelManager, ChannelManagerReadArgs};
use lightning::ln::msgs::SocketAddress;
use lightning::ln::ChannelId;
use lightning::ln::PaymentHash;
use lightning::routing::gossip::{NetworkGraph, NodeId};
use lightning::routing::router::Router;
use lightning::routing::scoring::{
    ProbabilisticScorer, ProbabilisticScoringDecayParameters, WriteableScore,
};
use lightning::sign::{
    ecdsa::WriteableEcdsaChannelSigner, EntropySource, NodeSigner, SignerProvider,
    SpendableOutputDescriptor,
};
use lightning::util::logger::Logger;
use lightning::util::persist::Persister;
use lightning::util::ser::ReadableArgs;
use lightning::util::ser::Writeable;
use log::{debug, error};

use super::peer::Peer;
use super::{ChannelRecord, SpendableOutputRecord};
use std::collections::HashMap;
use std::convert::{AsRef, TryInto};
use std::io::Cursor;
use std::ops::Deref;
use std::sync::{Arc, OnceLock};
use std::time::SystemTime;
use std::{fs, io};
use tokio::runtime::Handle;

pub struct LdkDatabase {
    settings: Arc<Settings>,
    durable_connection: Arc<DurableConnection>,
    // Persist graph/scorer gets called from a background thread in LDK so need a handle to the runtime.
    runtime: Handle,
    chain_monitor: OnceLock<Arc<ChainMonitor>>,
}

impl LdkDatabase {
    pub fn new(settings: Arc<Settings>, durable_connection: Arc<DurableConnection>) -> LdkDatabase {
        LdkDatabase {
            settings,
            durable_connection,
            runtime: Handle::current(),
            chain_monitor: OnceLock::new(),
        }
    }

    pub fn set_chain_monitor(&self, chain_monitor: Arc<ChainMonitor>) {
        self.chain_monitor
            .set(chain_monitor)
            .map_err(|_| ())
            .expect("Incorrect initialisation");
    }

    pub async fn is_first_start(&self) -> Result<bool> {
        Ok(self
            .durable_connection
            .get()
            .await
            .query_opt("SELECT true FROM channel_manager", &[])
            .await?
            .is_none())
    }

    pub async fn persist_peer(&self, peer: &Peer) -> Result<()> {
        self.durable_connection
            .get()
            .await
            .execute(
                "UPSERT INTO peers (public_key, address) \
            VALUES ($1, $2)",
                &[&peer.public_key.encode(), &peer.address.encode()],
            )
            .await?;
        Ok(())
    }

    pub async fn fetch_peer(&self, public_key: &PublicKey) -> Result<Option<Peer>> {
        debug!("Fetching peer from database");
        self.durable_connection
            .get()
            .await
            .query_opt(
                "SELECT * FROM peers WHERE public_key = $1",
                &[&public_key.encode()],
            )
            .await?
            .map(|row| {
                let public_key: Vec<u8> = row.get("public_key");
                let net_address: Vec<u8> = row.get("address");
                Peer::deserialize(public_key, net_address)
            })
            .transpose()
    }

    pub async fn fetch_peers(&self) -> Result<HashMap<PublicKey, SocketAddress>> {
        debug!("Fetching peers from database");
        let mut peers = HashMap::new();
        for row in self
            .durable_connection
            .get()
            .await
            .query("SELECT * FROM peers", &[])
            .await?
        {
            let public_key: Vec<u8> = row.get("public_key");
            let address: Vec<u8> = row.get("address");
            let peer = Peer::deserialize(public_key, address)?;
            peers.insert(peer.public_key, peer.address);
        }
        debug!("Fetched {} peers", peers.len());
        Ok(peers)
    }

    pub async fn delete_peer(&self, public_key: &PublicKey) -> Result<()> {
        debug!("Delete peer");
        self.durable_connection
            .get()
            .await
            .execute(
                "DELETE FROM peers \
            WHERE public_key = $1",
                &[&public_key.encode()],
            )
            .await?;
        Ok(())
    }

    pub async fn persist_initializing_channel(
        &self,
        initializing_channel_id: &ChannelId,
        is_public: bool,
        counterparty: &PublicKey,
        txid: &Txid,
    ) -> Result<()> {
        debug!(
            "Initial record for initial channel {}",
            hex::encode(initializing_channel_id.0),
        );
        // let initializing_channel_id: &[u8; 32] = initializing_channel_id.0.as_ref();
        self.durable_connection
            .get()
            .await
            .execute(
                "INSERT INTO initializing_channels (
                    initializing_channel_id,
                    counterparty,
                    is_public,
                    txid
                ) VALUES ( $1, $2, $3, $4 )",
                &[
                    &initializing_channel_id.0.to_vec(),
                    &counterparty.encode(),
                    &is_public,
                    &txid.encode(),
                ],
            )
            .await?;
        Ok(())
    }

    pub async fn update_initializing_channel(
        &self,
        initializing_channel_id: &ChannelId,
        channel_id_with_vout: Option<(&ChannelId, u32)>,
        status: Option<impl AsRef<str>>,
    ) -> Result<()> {
        debug!(
            "Update record for initial channel {}",
            hex::encode(initializing_channel_id.0),
        );
        if let Some((channel_id, vout)) = channel_id_with_vout {
            let status = if let Some(status) = status {
                status.as_ref().to_string()
            } else {
                "Updated by ChannelPending Event".to_string()
            };
            self.durable_connection
                .get()
                .await
                .execute(
                    "UPDATE initializing_channels SET channel_id = $1, vout = $2, update_timestamp = $3, status = $4 WHERE initializing_channel_id= $5",
                    &[
                        &channel_id.0.to_vec(),
                        &(vout as i32),
                        &to_primitive(&microsecond_timestamp()),
                        &status.as_bytes(),
                        &initializing_channel_id.0.to_vec(),
                    ],
                )
                .await?;
        } else if let Some(status) = status {
            self.durable_connection
                .get()
                .await
                .execute(
                    "UPDATE initializing_channels SET status = $1, update_timestamp = $2 WHERE initializing_channel_id= $3",
                    &[
                        &status.as_ref().as_bytes(),
                        &to_primitive(&microsecond_timestamp()),
                        &initializing_channel_id.0.to_vec(),
                    ],
                )
                .await?;
        } else {
            error!(
                "Update initial channel {} with nothing",
                hex::encode(initializing_channel_id.0),
            );
        }
        Ok(())
    }

    /// Create a record for channel which is not usable and without channel detail
    pub async fn create_channel(
        &self,
        channel_id: &ChannelId,
        is_public: bool,
        counterparty: &PublicKey,
    ) -> Result<()> {
        debug!(
            "Create record for channel {} without detail",
            hex::encode(channel_id.0),
        );
        self.durable_connection
            .get()
            .await
            .execute(
                "INSERT INTO channels (
                    channel_id,
                    counterparty,
                    is_usable,
                    is_public
                ) VALUES ( $1, $2, false, $3 )",
                &[&channel_id.0.to_vec(), &counterparty.encode(), &is_public],
            )
            .await?;
        Ok(())
    }

    pub async fn persist_channel(&self, channel: &ChannelDetails) -> Result<()> {
        debug!("Persist channel {}", channel.channel_id);
        if let Some(scid) = &channel.short_channel_id {
            self.durable_connection
                .get()
                .await
                .execute(
                    "UPSERT INTO channels (
                        channel_id,
                        counterparty,
                        short_channel_id,
                        is_usable,
                        is_public,
                        data,
                        update_timestamp
                    ) VALUES ( $1, $2, $3, $4, $5, $6, $7)",
                    &[
                        &channel.channel_id.0.to_vec(),
                        &NodeId::from_pubkey(&channel.counterparty.node_id).encode(),
                        &(*scid as i64),
                        &channel.is_usable,
                        &channel.is_public,
                        &channel.encode(),
                        &to_primitive(&microsecond_timestamp()),
                    ],
                )
                .await?;
        } else {
            self.durable_connection
                .get()
                .await
                .execute(
                    "UPSERT INTO channels (
                        channel_id,
                        counterparty,
                        is_usable,
                        is_public,
                        data,
                        update_timestamp
                    ) VALUES ( $1, $2, $3, $4, $5, $6 )",
                    &[
                        &channel.channel_id.0.to_vec(),
                        &NodeId::from_pubkey(&channel.counterparty.node_id).encode(),
                        &channel.is_usable,
                        &channel.is_public,
                        &channel.encode(),
                        &to_primitive(&microsecond_timestamp()),
                    ],
                )
                .await?;
        }
        Ok(())
    }

    pub async fn close_channel(
        &self,
        channel_id: &ChannelId,
        closure_reason: impl AsRef<str>,
    ) -> Result<()> {
        debug!("Close channel {}", hex::encode(channel_id.0));
        self.durable_connection
            .get()
            .await
            .execute(
                "UPDATE channels SET is_usable = false, update_timestamp = $1, closure_reason = $2 WHERE channel_id = $3",
                &[
                    &to_primitive(&microsecond_timestamp()),
                    &closure_reason.as_ref().as_bytes(),
                    &channel_id.0.to_vec(),
                ],
            )
            .await?;
        Ok(())
    }

    pub async fn fetch_channel_history(&self) -> Result<Vec<ChannelRecord>> {
        let rows = self
            .durable_connection
            .get()
            .await
            .query(
                "SELECT
                    data,
                    open_timestamp,
                    update_timestamp,
                    closure_reason
            FROM
                channels
            WHERE is_usable = false",
                &[],
            )
            .await?;

        let mut outputs = vec![];
        for row in rows {
            let detail: Option<ChannelDetails> = row.read_optional("data")?;
            if let Some(mut detail) = detail {
                detail.is_usable = false;
                outputs.push(ChannelRecord {
                    channel_id: detail.channel_id.to_string(),
                    counterparty: detail.counterparty.node_id.to_string(),
                    open_timestamp: row.get_timestamp("open_timestamp"),
                    update_timestamp: row.get_timestamp("update_timestamp"),
                    closure_reason: row
                        .get::<&str, Option<&[u8]>>("closure_reason")
                        .map(|b| String::from_utf8_lossy(b).to_string()),
                    detail: Some(detail),
                });
            }
        }
        Ok(outputs)
    }

    pub async fn fetch_channels(&self) -> Result<Vec<ChannelRecord>> {
        let rows = self
            .durable_connection
            .get()
            .await
            .query(
                "SELECT
                    channel_id,
                    counterparty,
                    data,
                    is_usable,
                    open_timestamp,
                    update_timestamp,
                    closure_reason
                FROM
                    channels",
                &[],
            )
            .await?;

        let mut outputs = vec![];
        for row in rows {
            let mut detail: Option<ChannelDetails> = row.read_optional("data")?;
            if let Some(ref mut detail) = detail {
                detail.is_usable = row.get::<&str, bool>("is_usable");
            }
            let counterparty: PublicKey = row.read("counterparty")?;
            outputs.push(ChannelRecord {
                channel_id: ChannelId::from_bytes(row.read("channel_id")?).to_string(),
                counterparty: counterparty.to_string(),
                open_timestamp: row.get_timestamp("open_timestamp"),
                update_timestamp: row.get_timestamp("update_timestamp"),
                closure_reason: row
                    .get::<&str, Option<&[u8]>>("closure_reason")
                    .map(|b| String::from_utf8_lossy(b).to_string()),
                detail,
            });
        }
        Ok(outputs)
    }

    pub async fn persist_spendable_output(
        &self,
        descriptor: &SpendableOutputDescriptor,
        channel_id: Option<&ChannelId>,
        is_spent: bool,
    ) -> Result<()> {
        let (txid, index, value) = match descriptor {
            SpendableOutputDescriptor::StaticOutput {
                outpoint, output, ..
            } => (outpoint.txid, outpoint.index, output.value),
            SpendableOutputDescriptor::DelayedPaymentOutput(descriptor) => (
                descriptor.outpoint.txid,
                descriptor.outpoint.index,
                descriptor.output.value,
            ),
            SpendableOutputDescriptor::StaticPaymentOutput(descriptor) => (
                descriptor.outpoint.txid,
                descriptor.outpoint.index,
                descriptor.output.value,
            ),
        };
        debug!("Persist spendable output {}:{}", txid, index);
        let mut data = vec![];
        descriptor.write(&mut data)?;

        let txid: &[u8] = txid.as_ref();
        if let Some(channel_id) = channel_id {
            self.durable_connection
                .get()
                .await
                .execute(
                    r#"UPSERT INTO spendable_outputs (
                        txid,
                        "index",
                        value,
                        channel_id,
                        data,
                        is_spent
                    ) VALUES ($1, $2, $3, $4, $5, $6)"#,
                    &[
                        &txid,
                        &(index as i16),
                        &(value as i64),
                        &channel_id.0.to_vec(),
                        &data,
                        &is_spent,
                    ],
                )
                .await?;
        } else {
            self.durable_connection
                .get()
                .await
                .execute(
                    r#"UPSERT INTO spendable_outputs (
                        txid,
                        "index",
                        value,
                        data,
                        is_spent
                    ) VALUES ($1, $2, $3, $4, $5)"#,
                    &[&txid, &(index as i16), &(value as i64), &data, &is_spent],
                )
                .await?;
        }
        Ok(())
    }

    pub async fn fetch_spendable_outputs(&self) -> Result<Vec<SpendableOutputRecord>> {
        let rows = self
            .durable_connection
            .get()
            .await
            .query(
                r#"SELECT
                data,
                is_spent
            FROM
                spendable_outputs"#,
                &[],
            )
            .await?;

        let mut outputs = vec![];
        for row in rows {
            outputs.push(SpendableOutputRecord {
                descriptor: row.read("data")?,
                is_spent: row.get::<&str, bool>("is_spent"),
            });
        }
        Ok(outputs)
    }

    pub async fn persist_invoice(&self, invoice: &Invoice) -> Result<()> {
        debug!(
            "Persist invoice with hash: {}",
            hex::encode(invoice.payment_hash.0)
        );

        let payment_hash: &[u8] = invoice.payment_hash.0.as_ref();
        self.durable_connection
            .get()
            .await
            .execute(
                "UPSERT INTO invoices (
                    payment_hash,
                    label,
                    bolt11,
                    payee_pub_key,
                    expiry,
                    amount,
                    timestamp
                ) VALUES ($1, $2, $3, $4, $5, $6, $7)",
                &[
                    &payment_hash,
                    &invoice.label,
                    &invoice.bolt11.to_string(),
                    &invoice.payee_pub_key.encode(),
                    &(invoice.bolt11.expiry_time().as_secs() as i64),
                    &invoice.amount.map(|a| a as i64),
                    &invoice.timestamp,
                ],
            )
            .await?;
        Ok(())
    }

    pub async fn fetch_invoices(&self, label: Option<String>) -> Result<Vec<Invoice>> {
        debug!("Fetching invoices from database");
        let connection = self.durable_connection.get().await;
        let mut params = Params::default();
        let mut query = "
            SELECT
                i.label as invoice_label,
                i.payment_hash,
                i.bolt11,
                i.expiry,
                i.amount as invoice_amount,
                i.payee_pub_key,
                i.timestamp as invoice_timestamp,
                p.id,
                p.hash,
                p.preimage,
                p.secret,
                p.status,
                p.amount,
                p.fee,
                p.direction,
                p.timestamp,
                p.label
            FROM invoices i
            LEFT OUTER JOIN payments p ON i.payment_hash = p.hash"
            .to_string();
        if let Some(label) = &label {
            params.push(label);
            query.push_str(&format!("\nWHERE i.label = ${}", params.count()));
        }
        let mut invoices: HashMap<PaymentHash, Invoice> = HashMap::new();
        for row in connection.query(&query, &params.to_params()).await? {
            let payment_hash: Vec<u8> = row.get("payment_hash");
            let payment_hash = PaymentHash(payment_hash.as_slice().try_into()?);
            let payment = if row.try_get::<&str, PaymentDirection>("direction").is_ok() {
                Some(Payment::try_from(&row)?)
            } else {
                None
            };
            if let Some(invoice) = invoices.get_mut(&payment_hash) {
                if let Some(payment) = payment {
                    invoice.payments.push(payment);
                }
            } else {
                let label: Option<String> = row.get("invoice_label");
                let bolt11: String = row.get("bolt11");
                let expiry: Option<i64> = row.get("expiry");
                let payee_pub_key: Vec<u8> = row.get("payee_pub_key");
                let amount: Option<i64> = row.get("invoice_amount");
                let timestamp: SystemTime = row.get("invoice_timestamp");
                let mut invoice = Invoice::deserialize(
                    payment_hash,
                    label,
                    bolt11,
                    payee_pub_key,
                    expiry.map(|i| i as u64),
                    amount,
                    timestamp,
                )?;
                if let Some(payment) = payment {
                    invoice.payments.push(payment);
                }
                invoices.insert(invoice.payment_hash, invoice);
            }
        }
        Ok(Vec::from_iter(invoices.into_values()))
    }

    pub async fn persist_payment(&self, payment: &Payment) -> Result<()> {
        debug!("Persist payment id: {}", hex::encode(payment.id.0));
        self.durable_connection
            .get()
            .await
            .execute(
                "UPSERT INTO payments (
                    id,
                    hash,
                    preimage,
                    secret,
                    label,
                    status,
                    amount,
                    fee,
                    direction,
                    timestamp
                ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10)",
                &[
                    &payment.id.0.to_vec(),
                    &payment.hash.as_ref().map(|x| x.0.to_vec()),
                    &payment.preimage.as_ref().map(|x| x.0.to_vec()),
                    &payment.secret.as_ref().map(|s| s.0.to_vec()),
                    &payment.label,
                    &payment.status,
                    &(payment.amount as i64),
                    &payment.fee.map(|f| f as i64).as_ref(),
                    &payment.direction,
                    &to_primitive(&payment.timestamp),
                ],
            )
            .await?;
        Ok(())
    }

    pub async fn fetch_payments(
        &self,
        payment_hash: Option<PaymentHash>,
        direction: Option<PaymentDirection>,
    ) -> Result<Vec<Payment>> {
        let connection = self.durable_connection.get().await;
        let mut payments = vec![];
        let mut params = Params::default();
        let mut query = "
            SELECT
                p.id,
                p.hash,
                p.preimage,
                p.secret,
                p.label,
                p.status,
                p.amount,
                p.fee,
                p.direction,
                p.timestamp,
                i.bolt11
            FROM payments as p
            LEFT OUTER JOIN invoices i ON p.hash = i.payment_hash
            WHERE 1 = 1"
            .to_string();
        if let Some(hash) = &payment_hash {
            params.push(hash.0.to_vec());
            query.push_str(&format!("AND p.hash = ${}", params.count()));
        }
        if let Some(direction) = direction {
            params.push(direction);
            query.push_str(&format!("AND p.direction = ${}", params.count()));
        }
        for row in connection
            .query(&query.to_string(), &params.to_params())
            .await?
        {
            payments.push(Payment::try_from(&row)?);
        }
        Ok(payments)
    }

    pub async fn persist_forward(&self, forward: Forward) -> Result<()> {
        debug!("Persist forward with ID {}", forward.id);

        let htlc_destination = if let Some(htlc_destination) = forward.htlc_destination {
            let mut bytes = vec![];
            htlc_destination.write(&mut bytes)?;
            Some(bytes)
        } else {
            None
        };
        self.durable_connection
            .get()
            .await
            .execute(
                "UPSERT INTO forwards (
                    id,
                    inbound_channel_id,
                    outbound_channel_id,
                    amount,
                    fee,
                    status,
                    htlc_destination,
                    timestamp
                ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8)",
                &[
                    &forward.id,
                    &forward.inbound_channel_id.0.to_vec(),
                    &forward.outbound_channel_id.as_ref().map(|x| x.0.to_vec()),
                    &(forward.amount.map(|x| x as i64)),
                    &(forward.fee.map(|x| x as i64)),
                    &forward.status,
                    &htlc_destination,
                    &to_primitive(&forward.timestamp),
                ],
            )
            .await?;
        Ok(())
    }

    pub async fn fetch_forwards(&self, status: Option<ForwardStatus>) -> Result<Vec<Forward>> {
        let mut statement = "
            SELECT
                id,
                inbound_channel_id,
                outbound_channel_id,
                amount,
                fee,
                status,
                htlc_destination,
                timestamp
            FROM
                forwards
            "
        .to_string();
        let mut params = Params::default();
        if let Some(status) = status {
            statement.push_str("WHERE status = $1");
            params.push(status);
        }
        statement.push_str("ORDER BY timestamp ASC");
        let mut forwards = vec![];
        let rows = self
            .durable_connection
            .get()
            .await
            .query(&statement, &params.to_params())
            .await?;

        for row in rows {
            forwards.push(row.try_into()?);
        }
        Ok(forwards)
    }

    pub async fn fetch_total_forwards(&self) -> Result<TotalForwards> {
        Ok(self
            .durable_connection
            .get()
            .await
            .query_one(
                "SELECT
                    count(*) AS count,
                    COALESCE(CAST(sum(amount) AS INT), 0) AS amount,
                    COALESCE(CAST(sum(fee) AS INT), 0) AS fee
                FROM forwards
                WHERE status = 'succeeded';",
                &[],
            )
            .await?
            .into())
    }

    pub async fn fetch_channel_monitors<T: EntropySource + SignerProvider>(
        &self,
        source: &T,
    ) -> Result<
        Vec<(
            BlockHash,
            ChannelMonitor<<T as SignerProvider>::EcdsaSigner>,
        )>,
    > {
        let rows = self
            .durable_connection
            .wait()
            .await
            .query(
                "SELECT out_point, monitor \
            FROM channel_monitors",
                &[],
            )
            .await?;
        let mut monitors: Vec<(
            BlockHash,
            ChannelMonitor<<T as SignerProvider>::EcdsaSigner>,
        )> = vec![];
        for row in rows {
            let out_point: Vec<u8> = row.get("out_point");

            let (txid_bytes, index_bytes) = out_point.split_at(32);
            let txid = Txid::from_raw_hash(bitcoin_hashes::sha256d::Hash::from_slice(txid_bytes)?);
            let index = u16::from_be_bytes(index_bytes.try_into().unwrap());

            let monitor: Vec<u8> = row.get("monitor");
            let mut buffer = Cursor::new(&monitor);
            match <(
                BlockHash,
                ChannelMonitor<<T as SignerProvider>::EcdsaSigner>,
            )>::read(&mut buffer, (source, source))
            {
                Ok((blockhash, channel_monitor)) => {
                    if channel_monitor.get_funding_txo().0.txid != txid
                        || channel_monitor.get_funding_txo().0.index != index
                    {
                        bail!("Unable to find ChannelMonitor for: {}:{}", txid, index);
                    }
                    monitors.push((blockhash, channel_monitor));
                }
                Err(e) => bail!("Failed to deserialize ChannelMonitor: {}", e),
            }
        }
        Ok(monitors)
    }

    pub async fn fetch_channel_manager<
        M: Deref,
        T: Deref,
        ES: Deref,
        NS: Deref,
        SP: Deref,
        F: Deref,
        R: Deref,
        L: Deref,
    >(
        &self,
        read_args: ChannelManagerReadArgs<'_, M, T, ES, NS, SP, F, R, L>,
    ) -> Result<(BlockHash, ChannelManager<M, T, ES, NS, SP, F, R, L>)>
    where
        <M as Deref>::Target: Watch<<SP::Target as SignerProvider>::EcdsaSigner>,
        <T as Deref>::Target: BroadcasterInterface,
        <ES as Deref>::Target: EntropySource,
        <NS as Deref>::Target: NodeSigner,
        <SP as Deref>::Target: SignerProvider,
        <F as Deref>::Target: FeeEstimator,
        <R as Deref>::Target: Router,
        <L as Deref>::Target: Logger,
    {
        let row = self
            .durable_connection
            .get()
            .await
            .query_one(
                "SELECT manager \
            FROM channel_manager",
                &[],
            )
            .await?;
        let manager: Vec<u8> = row.get("manager");
        <(BlockHash, ChannelManager<M, T, ES, NS, SP, F, R, L>)>::read(
            &mut Cursor::new(manager),
            read_args,
        )
        .map_err(|e| anyhow!(e.to_string()))
    }

    pub async fn fetch_graph(&self) -> Result<Option<NetworkGraph<Arc<KldLogger>>>> {
        match fs::read(format!("{}/network_graph", self.settings.data_dir)) {
            Ok(bytes) => {
                let graph = NetworkGraph::read(&mut Cursor::new(bytes), KldLogger::global())
                    .map_err(|e| anyhow!(e))?;
                Ok(Some(graph))
            }
            Err(e) if e.kind() == io::ErrorKind::NotFound => Ok(None),
            Err(e) => Err(anyhow!(e)),
        }
    }

    pub async fn fetch_scorer(
        &self,
        params: ProbabilisticScoringDecayParameters,
        graph: Arc<NetworkGraph<Arc<KldLogger>>>,
    ) -> Result<
        Option<(
            ProbabilisticScorer<Arc<NetworkGraph<Arc<KldLogger>>>, Arc<KldLogger>>,
            SystemTime,
        )>,
    > {
        let scorer = self
            .durable_connection
            .wait()
            .await
            .query_opt("SELECT scorer, timestamp FROM scorer", &[])
            .await?
            .map(|row| {
                let bytes: Vec<u8> = row.get(0);
                let timestamp: SystemTime = row.get(1);
                let scorer = ProbabilisticScorer::read(
                    &mut Cursor::new(bytes),
                    (params, graph.clone(), KldLogger::global()),
                )
                .expect("Unable to deserialize scorer");
                (scorer, timestamp)
            });
        Ok(scorer)
    }

    pub async fn fetch_scorer_binary(&self) -> Result<Vec<u8>> {
        let row = self
            .durable_connection
            .wait()
            .await
            .query_one("SELECT scorer FROM scorer;", &[])
            .await?;
        Ok(row.get("scorer"))
    }
}

impl<'a, M: Deref, T: Deref, ES: Deref, NS: Deref, SP: Deref, F: Deref, R: Deref, L: Deref, S>
    Persister<'a, M, T, ES, NS, SP, F, R, L, S> for LdkDatabase
where
    M::Target: 'static + Watch<<SP::Target as SignerProvider>::EcdsaSigner>,
    T::Target: 'static + BroadcasterInterface,
    ES::Target: 'static + EntropySource,
    NS::Target: 'static + NodeSigner,
    SP::Target: 'static + SignerProvider,
    F::Target: 'static + FeeEstimator,
    R::Target: 'static + Router,
    L::Target: 'static + Logger,
    S: 'static + WriteableScore<'a>,
{
    fn persist_manager(
        &self,
        channel_manager: &ChannelManager<M, T, ES, NS, SP, F, R, L>,
    ) -> Result<(), io::Error> {
        let mut buf = vec![];
        channel_manager.write(&mut buf)?;
        let durable_connection = self.durable_connection.clone();
        self.runtime.spawn_blocking(async move || {
            if let Err(e) = durable_connection
                .get()
                .await
                .execute(
                    "UPSERT INTO channel_manager (id, manager, timestamp) \
                        VALUES ('manager', $1, CURRENT_TIMESTAMP)",
                    &[&buf],
                )
                .await
            {
                error!("Failed to persist channel manager: {e}");
            }
        });
        Ok(())
    }

    // Network graph could get very large so just write it to disk for now.
    fn persist_graph(
        &self,
        network_graph: &lightning::routing::gossip::NetworkGraph<L>,
    ) -> Result<(), io::Error> {
        let mut buf = vec![];
        network_graph.write(&mut buf)?;
        if let Err(e) = fs::write(format!("{}/network_graph", self.settings.data_dir), &buf) {
            error!("Failed to persist graph: {e}");
        }
        Ok(())
    }

    fn persist_scorer(&self, scorer: &S) -> Result<(), io::Error> {
        let mut buf = vec![];
        scorer.write(&mut buf)?;
        let durable_connection = self.durable_connection.clone();
        self.runtime.spawn(async move {
            if let Err(e) = durable_connection
                .get()
                .await
                .execute(
                    "UPSERT INTO scorer (id, scorer, timestamp)
                        VALUES ('scorer', $1, CURRENT_TIMESTAMP)",
                    &[&buf],
                )
                .await
            {
                error!("Failed to persist scorer: {e}");
            }
        });
        Ok(())
    }
}

impl<ChannelSigner: WriteableEcdsaChannelSigner> chain::chainmonitor::Persist<ChannelSigner>
    for LdkDatabase
{
    // The CHANNEL_MONITORS table stores the latest monitor and its update_id.
    fn persist_new_channel(
        &self,
        funding_txo: OutPoint,
        monitor: &ChannelMonitor<ChannelSigner>,
        update_id: MonitorUpdateId,
    ) -> ChannelMonitorUpdateStatus {
        debug!(
            "Persisting channel: {:?} {}",
            funding_txo,
            monitor.get_latest_update_id()
        );
        let mut out_point_buf = vec![];
        funding_txo.write(&mut out_point_buf).unwrap();

        let mut monitor_buf = vec![];
        monitor.write(&mut monitor_buf).unwrap();
        let latest_update_id = monitor.get_latest_update_id();

        let durable_connection = self.durable_connection.clone();
        let chain_monitor = self
            .chain_monitor
            .get()
            .expect("bad initialisation")
            .clone();
        tokio::spawn(async move {
            let result = durable_connection
                .get()
                .await
                .execute(
                    "UPSERT INTO channel_monitors (out_point, monitor, update_id) \
                VALUES ($1, $2, $3)",
                    &[&out_point_buf, &monitor_buf, &(latest_update_id as i64)],
                )
                .await;
            match result {
                Ok(_) => {
                    debug!(
                        "Stored channel: {}:{} with update id: {}",
                        funding_txo.txid, funding_txo.index, latest_update_id
                    );
                    if let Err(e) = chain_monitor.channel_monitor_updated(funding_txo, update_id) {
                        error!("Failed to update chain monitor: {}", ldk_error(e));
                    }
                }
                Err(e) => {
                    error!("Failed to persist channel update: {e}");
                }
            }
        });
        ChannelMonitorUpdateStatus::InProgress
    }

    // Updates are applied to the monitor when fetched from database.
    fn update_persisted_channel(
        &self,
        funding_txo: OutPoint,
        _update: Option<&ChannelMonitorUpdate>,
        monitor: &ChannelMonitor<ChannelSigner>,
        update_id: MonitorUpdateId,
    ) -> ChannelMonitorUpdateStatus {
        self.persist_new_channel(funding_txo, monitor, update_id)

        // Hope we can enable this soon. Probably after https://github.com/lightningdevkit/rust-lightning/issues/1426
        /*
                let mut out_point_buf = vec![];
                funding_txo.write(&mut out_point_buf).unwrap();

                // If its the last update then store the last monitor and delete the updates.
                if update.as_ref().map_or(true, |x| x.update_id == CLOSED_CHANNEL_UPDATE_ID) {
                    let mut monitor_buf = vec![];
                    monitor.write(&mut monitor_buf).unwrap();
                    let ciphertext = self.cipher.encrypt(&monitor_buf);

                    tokio::task::block_in_place(move || {
                        Handle::current().block_on(async move {
                            let mut lock = self.client.write().await;
                            let tx = lock.transaction().await.unwrap();
                            tx.execute(
                                "UPSERT INTO channel_monitors (out_point, monitor, update_id) VALUES ($1, $2, $3)",
                                &[
                                    &out_point_buf,
                                    &ciphertext,
                                    &(monitor.get_latest_update_id() as i64),
                                ],
                            )
                            .await
                            .unwrap();
                            let deleted = tx
                                .execute(
                                    "DELETE FROM channel_monitor_updates WHERE out_point = $1",
                                    &[&out_point_buf],
                                )
                                .await
                                .unwrap();
                            tx.commit().await.unwrap();
                            debug!("Stored latest monitor and deleted {} updates.", deleted);
                        })
                    })
                } else {
                    let update = update.as_ref().unwrap();
                    let mut update_buf = vec![];
                    update.write(&mut update_buf).unwrap();
                    let ciphertext = self.cipher.encrypt(&update_buf);

                    block_in_place!(
                        "UPSERT INTO channel_monitor_updates (out_point, update, update_id) \
                        VALUES ($1, $2, $3)",
                        &[&out_point_buf, &ciphertext, &(update.update_id as i64)],
                        self
                    );
                }
                ChannelMonitorUpdateStatus::Completed
        */
    }
}

'''
'''--- kld/src/database/mod.rs ---
pub mod forward;
pub mod invoice;
mod ldk_database;
pub mod payment;
pub mod peer;
mod wallet_database;

use std::{
    sync::{Arc, RwLock},
    time::Duration,
};

use async_trait::async_trait;
pub use ldk_database::LdkDatabase;
use lightning::ln::channelmanager::ChannelDetails;
use lightning::sign::SpendableOutputDescriptor;
use lightning::util::ser::MaybeReadable;
use postgres_types::ToSql;
use time::{OffsetDateTime, PrimitiveDateTime};
use tokio::{sync::OwnedRwLockReadGuard, task::JoinHandle};
pub use wallet_database::WalletDatabase;

use anyhow::{Context, Result};
use log::{error, info};
use openssl::ssl::{SslConnector, SslFiletype, SslMethod};
use postgres_openssl::MakeTlsConnector;
use tokio::sync::RwLock as AsyncRwLock;
use tokio_postgres::{Client, Row};

use crate::{ldk::decode_error, settings::Settings};

use crate::{log_error, Service};

pub struct ChannelRecord {
    pub channel_id: String,
    pub counterparty: String,
    pub open_timestamp: OffsetDateTime,
    pub update_timestamp: OffsetDateTime,
    pub closure_reason: Option<String>,
    pub detail: Option<ChannelDetails>,
}

pub struct SpendableOutputRecord {
    pub descriptor: SpendableOutputDescriptor,
    pub is_spent: bool,
}

pub struct DurableConnection {
    client: Arc<AsyncRwLock<Client>>, // Used across await points.
    connection_task: Arc<RwLock<JoinHandle<()>>>,
    reconnect_task: JoinHandle<()>,
}

#[async_trait]
impl Service for DurableConnection {
    async fn is_connected(&self) -> bool {
        !self.get().await.is_closed()
    }

    async fn is_synchronised(&self) -> bool {
        true
    }
}

#[async_trait]
pub trait DBConnection: Service {
    async fn open_channel_count(&self) -> Result<i64>;
    async fn fetch_scorer_update_time(&self) -> Result<OffsetDateTime>;
}

#[async_trait]
impl DBConnection for DurableConnection {
    async fn open_channel_count(&self) -> Result<i64> {
        let row = self
            .get()
            .await
            .query_one("SELECT COUNT(*) FROM channels WHERE is_usable = true;", &[])
            .await?;
        let count: i64 = row.get("count");
        Ok(count)
    }

    async fn fetch_scorer_update_time(&self) -> Result<OffsetDateTime> {
        let row = self
            .get()
            .await
            .query_one("SELECT timestamp FROM scorer;", &[])
            .await?;
        Ok(row.get_timestamp("timestamp"))
    }
}

impl DurableConnection {
    pub async fn new_migrate(settings: Arc<Settings>) -> DurableConnection {
        info!(
            "Connecting to Cockroach database {} at {}:{}",
            settings.database_name, settings.database_host, settings.database_port
        );
        // The service cannot start properly without the database so we wait here.
        let (mut client, connection_task) = loop {
            match DurableConnection::create_connection(settings.clone()).await {
                Ok(client) => break client,
                Err(e) => {
                    log_error(&e);
                    tokio::time::sleep(Duration::from_secs(2)).await;
                }
            }
        };
        info!("Running database migrations for {}", settings.database_name);
        embedded::migrations::runner()
            .run_async(&mut client)
            .await
            .expect("failed to run migrations");

        let client = Arc::new(AsyncRwLock::new(client));
        let connection_task = Arc::new(RwLock::new(connection_task));
        let reconnect_task = DurableConnection::keep_connected(
            settings.clone(),
            client.clone(),
            connection_task.clone(),
        );
        DurableConnection {
            client,
            connection_task,
            reconnect_task,
        }
    }

    pub fn disconnect(&self) {
        info!("Disconnecting from database");
        self.reconnect_task.abort();
        match self.connection_task.write() {
            Ok(guard) => guard.abort(),
            Err(e) => error!("{e}"),
        }
    }

    async fn create_connection(settings: Arc<Settings>) -> Result<(Client, JoinHandle<()>)> {
        let log_safe_params = format!(
            "host={} port={} user={} dbname={}",
            settings.database_host,
            settings.database_port,
            settings.database_user,
            settings.database_name
        );
        let mut builder = SslConnector::builder(SslMethod::tls()).expect("TLS initialisation");
        builder.set_ca_file(&settings.database_ca_cert_path)?;
        builder
            .set_certificate_file(&settings.database_client_cert_path, SslFiletype::PEM)
            .expect("Database certificate");
        builder
            .set_private_key_file(&settings.database_client_key_path, SslFiletype::PEM)
            .expect("Database private key");
        let connector = MakeTlsConnector::new(builder.build());
        let (client, connection) = tokio_postgres::connect(&log_safe_params, connector)
            .await
            .with_context(|| format!("Cannot connect to database ({log_safe_params})"))?;
        let connection_task = tokio::spawn(async move {
            if let Err(e) = connection.await {
                error!("{e}");
            }
        });
        Ok((client, connection_task))
    }

    // Get the current connection no matter what state it is in (may error when used).
    async fn get(&self) -> OwnedRwLockReadGuard<Client> {
        self.client.clone().read_owned().await
    }

    /// Block on trying to reconnect to the database if the connection has been dropped.
    /// This can probably only be used during start up when we have to wait. Take care not to block async tasks.
    async fn wait(&self) -> OwnedRwLockReadGuard<Client> {
        loop {
            let client = self.get().await;
            if !client.is_closed() {
                return client;
            } else {
                drop(client);
                tokio::time::sleep(Duration::from_secs(3)).await;
            }
        }
    }

    fn keep_connected(
        settings: Arc<Settings>,
        client: Arc<AsyncRwLock<Client>>,
        connection_task: Arc<RwLock<JoinHandle<()>>>,
    ) -> JoinHandle<()> {
        tokio::spawn(async move {
            loop {
                if client.read().await.is_closed() {
                    let mut client_guard = client.write().await;
                    match DurableConnection::create_connection(settings.clone()).await {
                        Ok((client, connect_task)) => {
                            *client_guard = client;
                            match connection_task.write() {
                                Ok(mut task_guard) => *task_guard = connect_task,
                                Err(e) => error!("{e}"),
                            }
                        }
                        Err(e) => {
                            error!("{e}");
                        }
                    }
                }
                tokio::time::sleep(Duration::from_secs(2)).await;
            }
        })
    }
}

impl Drop for DurableConnection {
    fn drop(&mut self) {
        self.disconnect()
    }
}

mod embedded {
    use refinery::embed_migrations;
    embed_migrations!("src/database/sql");
}

#[derive(Default)]
pub struct Params<'a> {
    vec: Vec<Box<(dyn ToSql + Sync + Send + 'a)>>,
}

impl<'a> Params<'a> {
    pub fn push(&mut self, x: impl ToSql + Sync + Send + 'a) {
        self.vec.push(Box::new(x))
    }

    pub fn count(&self) -> usize {
        self.vec.len()
    }

    pub fn to_params(&self) -> Vec<&(dyn ToSql + Sync)> {
        self.vec
            .iter()
            .map(|x| x.as_ref() as &(dyn ToSql + Sync))
            .collect()
    }
}

pub fn microsecond_timestamp() -> OffsetDateTime {
    let timestamp = OffsetDateTime::now_utc();
    timestamp
        .replace_nanosecond(timestamp.microsecond() * 1000)
        .unwrap()
}

pub fn to_primitive(offset: &OffsetDateTime) -> PrimitiveDateTime {
    PrimitiveDateTime::new(offset.date(), offset.time())
}

pub trait RowExt {
    fn get_timestamp(&self, column: &str) -> OffsetDateTime;
    fn get_timestamp_optional(&self, column: &str) -> Option<OffsetDateTime>;
    fn read<T: MaybeReadable>(&self, column: &str) -> Result<T>;
    fn read_optional<T: MaybeReadable>(&self, column: &str) -> Result<Option<T>>;
}

impl RowExt for Row {
    fn read<T: MaybeReadable>(&self, column: &str) -> Result<T> {
        T::read(&mut self.get::<&str, &[u8]>(column))
            .map_err(decode_error)?
            .context(format!("expected readable value for column {column}"))
    }

    fn read_optional<T: MaybeReadable>(&self, column: &str) -> Result<Option<T>> {
        self.get::<&str, Option<&[u8]>>(column)
            .map(|mut bytes| {
                T::read(&mut bytes)
                    .map_err(decode_error)?
                    .context(format!("expected readable value for column {column}"))
            })
            .transpose()
    }

    fn get_timestamp(&self, column: &str) -> OffsetDateTime {
        self.get::<&str, PrimitiveDateTime>(column).assume_utc()
    }

    fn get_timestamp_optional(&self, column: &str) -> Option<OffsetDateTime> {
        self.get::<&str, Option<PrimitiveDateTime>>(column)
            .map(|time| time.assume_utc())
    }
}

'''
'''--- kld/src/database/payment.rs ---
use anyhow::{Context, Result};
use bitcoin::hashes::Hash;
use lightning::{
    events::PaymentFailureReason,
    ln::{channelmanager::PaymentId, PaymentHash, PaymentPreimage, PaymentSecret},
};
use lightning_invoice::Bolt11Invoice;
use postgres_types::{FromSql, ToSql};
use rand::random;
use std::{
    fmt::{self, Display},
    str::FromStr,
};
use thiserror::Error;
use time::OffsetDateTime;
use tokio_postgres::Row;

use crate::MillisatAmount;

use super::{invoice::Invoice, microsecond_timestamp, RowExt};

#[derive(Debug, ToSql, FromSql, PartialEq, Clone, Copy)]
#[postgres(name = "payment_status")]
pub enum PaymentStatus {
    #[postgres(name = "pending")]
    Pending,
    #[postgres(name = "succeeded")]
    Succeeded,
    #[postgres(name = "recipient_rejected")]
    RecipientRejected,
    #[postgres(name = "user_abandoned")]
    UserAbandoned,
    #[postgres(name = "retries_exhausted")]
    RetriesExhausted,
    #[postgres(name = "expired")]
    Expired,
    #[postgres(name = "route_not_found")]
    RouteNotFound,
    #[postgres(name = "error")]
    Error,
}

impl Display for PaymentStatus {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        match self {
            PaymentStatus::Pending => f.write_str("pending"),
            PaymentStatus::Succeeded => f.write_str("succeeded"),
            PaymentStatus::RecipientRejected => f.write_str("recipient rejected"),
            PaymentStatus::UserAbandoned => f.write_str("user abandoned"),
            PaymentStatus::RetriesExhausted => f.write_str("retries exhausted"),
            PaymentStatus::Expired => f.write_str("expired"),
            PaymentStatus::RouteNotFound => f.write_str("route not found"),
            PaymentStatus::Error => f.write_str("error"),
        }
    }
}

#[derive(Debug, ToSql, FromSql, PartialEq, Clone, Copy)]
#[postgres(name = "payment_direction")]
pub enum PaymentDirection {
    #[postgres(name = "inbound")]
    Inbound,
    #[postgres(name = "outbound")]
    Outbound,
}

#[derive(Error, Debug)]
pub enum DeserializeError {
    #[error("unable to deserialize {0}")]
    PaymentDirection(String),
}

impl Display for PaymentDirection {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        match self {
            PaymentDirection::Inbound => f.write_str("inbound"),
            PaymentDirection::Outbound => f.write_str("outbound"),
        }
    }
}

impl FromStr for PaymentDirection {
    type Err = DeserializeError;

    fn from_str(s: &str) -> Result<Self, Self::Err> {
        match s {
            "inbound" => Ok(PaymentDirection::Inbound),
            "outbound" => Ok(PaymentDirection::Outbound),
            _ => Err(DeserializeError::PaymentDirection(s.to_string())),
        }
    }
}

#[derive(Clone, Debug, PartialEq)]
pub struct Payment {
    pub id: PaymentId,
    // Hash of the premimage.
    pub hash: Option<PaymentHash>,
    pub preimage: Option<PaymentPreimage>,
    // No secret indicates a spontaneous payment.
    pub secret: Option<PaymentSecret>,
    pub label: Option<String>,
    pub status: PaymentStatus,
    pub amount: MillisatAmount,
    pub fee: Option<MillisatAmount>,
    pub direction: PaymentDirection,
    // The time that the payment was sent/received.
    pub timestamp: OffsetDateTime,
    // The bolt11 invoice with corresponding payment hash. Useful when querying payments.
    pub bolt11: Option<Bolt11Invoice>,
}

impl Payment {
    pub fn new_id() -> PaymentId {
        PaymentId(random())
    }

    pub fn spontaneous_inbound(
        hash: PaymentHash,
        preimage: PaymentPreimage,
        amount: MillisatAmount,
    ) -> Self {
        Payment {
            id: PaymentId(random()),
            hash: Some(hash),
            preimage: Some(preimage),
            secret: None,
            label: None,
            status: PaymentStatus::Pending,
            amount,
            fee: None,
            direction: PaymentDirection::Inbound,
            timestamp: microsecond_timestamp(),
            bolt11: None,
        }
    }

    pub fn spontaneous_outbound(id: PaymentId, amount: MillisatAmount) -> Self {
        Payment {
            id,
            hash: None,
            preimage: None,
            secret: None,
            label: None,
            status: PaymentStatus::Pending,
            amount,
            fee: None,
            direction: PaymentDirection::Outbound,
            timestamp: microsecond_timestamp(),
            bolt11: None,
        }
    }

    pub fn of_invoice_inbound(
        hash: PaymentHash,
        preimage: Option<PaymentPreimage>,
        secret: PaymentSecret,
        amount: MillisatAmount,
    ) -> Self {
        Payment {
            id: PaymentId(random()),
            hash: Some(hash),
            preimage,
            secret: Some(secret),
            label: None,
            status: PaymentStatus::Succeeded,
            amount,
            fee: None,
            direction: PaymentDirection::Inbound,
            timestamp: microsecond_timestamp(),
            bolt11: None,
        }
    }

    pub fn of_invoice_outbound(invoice: &Invoice, label: Option<String>) -> Self {
        Payment {
            id: PaymentId(random()),
            hash: Some(PaymentHash(invoice.bolt11.payment_hash().to_byte_array())),
            preimage: None,
            secret: Some(*invoice.bolt11.payment_secret()),
            label,
            status: PaymentStatus::Pending,
            amount: invoice.bolt11.amount_milli_satoshis().unwrap_or_default(),
            fee: None,
            direction: PaymentDirection::Outbound,
            timestamp: microsecond_timestamp(),
            bolt11: Some(invoice.bolt11.clone()),
        }
    }

    pub fn succeeded(
        &mut self,
        hash: PaymentHash,
        preimage: PaymentPreimage,
        fee: Option<MillisatAmount>,
    ) {
        self.hash = Some(hash);
        self.preimage = Some(preimage);
        self.fee = fee;
        self.status = PaymentStatus::Succeeded;
    }

    pub fn failed(&mut self, reason: Option<PaymentFailureReason>) {
        self.status = match reason {
            Some(PaymentFailureReason::RecipientRejected) => PaymentStatus::RecipientRejected,
            Some(PaymentFailureReason::UserAbandoned) => PaymentStatus::UserAbandoned,
            Some(PaymentFailureReason::RetriesExhausted) => PaymentStatus::RetriesExhausted,
            Some(PaymentFailureReason::PaymentExpired) => PaymentStatus::Expired,
            Some(PaymentFailureReason::RouteNotFound) => PaymentStatus::RouteNotFound,
            _ => PaymentStatus::Error,
        };
    }
}

impl TryFrom<&Row> for Payment {
    type Error = anyhow::Error;

    fn try_from(row: &Row) -> std::result::Result<Self, Self::Error> {
        let id: &[u8] = row.get("id");
        let hash: Option<&[u8]> = row.get("hash");
        let preimage: Option<&[u8]> = row.get("preimage");
        let secret: Option<&[u8]> = row.get("secret");
        let label: Option<String> = row.get("label");

        let hash = match hash {
            Some(bytes) => Some(PaymentHash(bytes.try_into().context("bad hash")?)),
            None => None,
        };
        let preimage = match preimage {
            Some(bytes) => Some(PaymentPreimage(bytes.try_into().context("bad preimage")?)),
            None => None,
        };
        let secret = match secret {
            Some(bytes) => Some(PaymentSecret(bytes.try_into().context("bad secret")?)),
            None => None,
        };

        Ok(Payment {
            id: PaymentId(id.try_into().context("bad ID")?),
            hash,
            preimage,
            secret,
            label,
            status: row.get("status"),
            amount: row.get::<&str, i64>("amount") as MillisatAmount,
            fee: row
                .get::<&str, Option<i64>>("fee")
                .map(|f| f as MillisatAmount),
            direction: row.get("direction"),
            timestamp: row.get_timestamp("timestamp"),
            bolt11: Bolt11Invoice::from_str(row.get("bolt11")).ok(),
        })
    }
}

'''
'''--- kld/src/database/peer.rs ---
use anyhow::{anyhow, Result};
use bitcoin::secp256k1::PublicKey;
use lightning::{ln::msgs::SocketAddress, util::ser::MaybeReadable};

#[derive(PartialEq, Eq, Debug)]
pub struct Peer {
    pub public_key: PublicKey,
    pub address: SocketAddress,
}

impl Peer {
    pub fn deserialize(public_key: Vec<u8>, net_address: Vec<u8>) -> Result<Peer> {
        let public_key = PublicKey::from_slice(&public_key)?;
        let address = SocketAddress::read(&mut net_address.as_slice())
            .map_err(|e| anyhow!("{}", e))?
            .ok_or(anyhow!("Error parsing address"))?;

        Ok(Peer {
            public_key,
            address,
        })
    }
}

'''
'''--- kld/src/database/sql/V10__initial_channels.sql ---
CREATE TABLE initializing_channels (
    initializing_channel_id                BYTES NOT NULL,
    counterparty                      BYTES NOT NULL,
    is_public                         BOOLEAN NOT NULL,
    channel_id                        BYTES,
    status                            BYTES,
    txid                              BYTES NOT NULL,
    vout                              INT4,
    open_timestamp                    TIMESTAMP NOT NULL DEFAULT current_timestamp(),
    update_timestamp                  TIMESTAMP NOT NULL DEFAULT current_timestamp(),
    PRIMARY KEY ( initializing_channel_id )
);

'''
'''--- kld/src/database/sql/V1__ldk.sql ---
CREATE TABLE channel_manager (
    id              BYTES PRIMARY KEY,
    manager         BYTES NOT NULL,
    timestamp       TIMESTAMP NOT NULL DEFAULT current_timestamp()
);

CREATE TABLE channel_monitors (
    out_point       BYTES NOT NULL,
    update_id       INT NOT NULL,
    monitor         BYTES NOT NULL,
    timestamp       TIMESTAMP NOT NULL DEFAULT current_timestamp(),
    PRIMARY KEY ( out_point )
);

CREATE TABLE channel_monitor_updates (
    out_point       BYTES NOT NULL,
    update          BYTES NOT NULL,
    update_id       INT NOT NULL,
    timestamp       TIMESTAMP NOT NULL DEFAULT current_timestamp(),
    PRIMARY KEY ( out_point, update_id )
);

ALTER TABLE channel_monitor_updates CONFIGURE ZONE USING gc.ttlseconds = 600;

CREATE TABLE scorer (
    id              BYTES PRIMARY KEY,
    scorer          BYTES NOT NULL,
    timestamp       TIMESTAMP NOT NULL DEFAULT current_timestamp()
);

CREATE TABLE peers (
    public_key      BYTES NOT NULL,
    address         BYTES NOT NULL,
    PRIMARY KEY ( public_key, address )
);

'''
'''--- kld/src/database/sql/V2__wallet.sql ---
CREATE TABLE wallet_version (
	version INT
);

INSERT INTO wallet_version VALUES (1);

CREATE TABLE wallet_script_pubkeys (
	keychain TEXT,
	child INT4,
	script BLOB,
	INDEX (keychain, child),
	INDEX (script)
);

CREATE TABLE wallet_utxos (
	value INT,
	keychain TEXT,
	vout INT4,
	txid BLOB,
	script BLOB,
	is_spent BOOL,
	PRIMARY KEY (txid, vout)
);

CREATE TABLE wallet_transactions (
	txid BLOB,
	raw_tx BLOB,
	INDEX (txid)
);

CREATE TABLE wallet_transaction_details (
	txid BLOB,
	timestamp INT,
	received INT,
	sent INT,
	fee INT,
	height INT,
	INDEX (txid)
);

CREATE TABLE wallet_last_derivation_indices (
	keychain TEXT PRIMARY KEY,
	value INT
);

CREATE TABLE wallet_checksums (
	keychain TEXT,
	checksum BLOB,
	INDEX (keychain)
);

CREATE TABLE wallet_sync_time (
	id INT PRIMARY KEY,
	height INT,
	timestamp INT
);

'''
'''--- kld/src/database/sql/V3__payments.sql ---
CREATE TYPE payment_status AS ENUM ('pending', 'succeeded', 'recipient_rejected', 'user_abandoned', 'retries_exhausted', 'expired', 'route_not_found', 'error');

CREATE TYPE payment_direction AS ENUM ('inbound', 'outbound');

CREATE TABLE payments (
    id              BYTES NOT NULL,
    hash            BYTES NOT NULL,
    preimage        BYTES,
    secret          BYTES,
    status          payment_status NOT NULL,
    amount          INT NOT NULL,
    fee             INT,
    metadata        BYTES,
    direction       payment_direction NOT NULL,
    channel_id      BYTES,
    counterparty_id BYTES,
    timestamp       TIMESTAMP NOT NULL DEFAULT current_timestamp(),
    PRIMARY KEY ( id ),
    INDEX (hash)
);

'''
'''--- kld/src/database/sql/V4__invoices.sql ---
CREATE TABLE invoices (
    payment_hash    BYTES NOT NULL,
    label           VARCHAR,
    expiry          INT,
    payee_pub_key   BYTES,
    amount          INT,
    bolt11          VARCHAR NOT NULL,
    timestamp       TIMESTAMP NOT NULL DEFAULT current_timestamp(),
    PRIMARY KEY ( payment_hash ),
    INDEX ( label )
);

ALTER TABLE payments ADD COLUMN label VARCHAR;

'''
'''--- kld/src/database/sql/V5__invoice_label.sql ---
ALTER TABLE invoices ADD CONSTRAINT unique_label UNIQUE (label);

'''
'''--- kld/src/database/sql/V6__spendable_outputs.sql ---
CREATE TABLE spendable_outputs (
    txid            BYTES NOT NULL,
    "index"         INT2 NOT NULL,
    value           INT NOT NULL,
    channel_id      BYTES,

    /* The data of SpendableOutputDescriptor */
    data            BYTES NOT NULL,

    is_spent        BOOL NOT NULL,
    timestamp       TIMESTAMP NOT NULL DEFAULT current_timestamp(),
    PRIMARY KEY ( txid, "index" )
);

'''
'''--- kld/src/database/sql/V7__forwards.sql ---
CREATE TYPE forward_status AS ENUM ('succeeded', 'failed');

CREATE TABLE forwards (
    id                   UUID NOT NULL,
    inbound_channel_id   BYTES NOT NULL,
    outbound_channel_id  BYTES,
    amount               INT,
    fee                  INT,
    status               forward_status NOT NULL,
    htlc_destination     BYTES,
    timestamp            TIMESTAMP NOT NULL DEFAULT current_timestamp(),
    PRIMARY KEY ( id )
);

'''
'''--- kld/src/database/sql/V8__channels.sql ---
CREATE TABLE channels (
    channel_id                        BYTES NOT NULL,
    counterparty                      BYTES NOT NULL,

    /* The default channel config may not be consistent in the future
       So we need to keep recording the data version */
    data_version                      INT DEFAULT 0,
    /* 0 - lightning 0.0.118 */

    short_channel_id                  INT,
    is_usable                         BOOLEAN NOT NULL,
    is_public                         BOOLEAN NOT NULL,

    /* The data of ChannelDetails */
    data                              BYTES,

    /* Kuutamo customized fields */
    open_timestamp                    TIMESTAMP NOT NULL DEFAULT current_timestamp(),
    update_timestamp                  TIMESTAMP NOT NULL DEFAULT current_timestamp(),
    closure_reason                    BYTES,

    PRIMARY KEY ( channel_id )
);

'''
'''--- kld/src/database/sql/V9__payment_hash.sql ---
ALTER TABLE payments ALTER COLUMN hash DROP NOT NULL;

'''
'''--- kld/src/database/wallet_database.rs ---
use std::sync::Arc;

use super::DurableConnection;
use crate::settings::Settings;
use anyhow::Result;
use bdk::{
    database::{BatchDatabase, BatchOperations, Database, SyncTime},
    BlockTime, Error, KeychainKind, LocalUtxo, TransactionDetails,
};
use bitcoin::consensus::encode::{deserialize, serialize};
use bitcoin::{OutPoint, Script, ScriptBuf, Transaction, TxOut, Txid};
use tokio::runtime::Handle;

macro_rules! execute_blocking {
    ($statement: literal, $params: expr, $self: expr) => {
        tokio::task::block_in_place(move || {
            Handle::current().block_on(async move {
                $self
                    .durable_connection
                    .get()
                    .await
                    .execute($statement, $params)
                    .await
                    .map_err(|e| Error::Generic(e.to_string()))
            })
        })
    };
}

macro_rules! query_blocking {
    ($statement: literal, $params: expr, $self: expr) => {
        tokio::task::block_in_place(move || {
            Handle::current().block_on(async move {
                $self
                    .durable_connection
                    .get()
                    .await
                    .query($statement, $params)
                    .await
                    .map_err(|e| Error::Generic(e.to_string()))
            })
        })
    };
}

#[derive(Clone)]
pub struct WalletDatabase {
    settings: Arc<Settings>,
    durable_connection: Arc<DurableConnection>,
}

impl WalletDatabase {
    pub fn new(
        settings: Arc<Settings>,
        durable_connection: Arc<DurableConnection>,
    ) -> WalletDatabase {
        WalletDatabase {
            settings,
            durable_connection,
        }
    }

    fn insert_script_pubkey(
        &self,
        keychain: String,
        child: u32,
        script: &[u8],
    ) -> Result<i64, Error> {
        execute_blocking!(
            "INSERT INTO wallet_script_pubkeys (keychain, child, script) VALUES ($1, $2, $3)",
            &[&keychain, &(child as i32), &script],
            self
        )
        .map(|_| 0)
    }

    fn insert_utxo(
        &self,
        value: u64,
        keychain: String,
        vout: u32,
        txid: &[u8],
        script: &[u8],
        is_spent: bool,
    ) -> Result<i64, Error> {
        execute_blocking!(
			"UPSERT INTO wallet_utxos (value, keychain, vout, txid, script, is_spent) VALUES ($1, $2, $3, $4, $5, $6)",
			&[&(value as i64), &keychain, &(vout as i32), &txid, &script, &is_spent],
			self
		)
		.map(|_| 0)
    }

    fn insert_transaction(&self, txid: &[u8], raw_tx: &[u8]) -> Result<i64, Error> {
        execute_blocking!(
            "INSERT INTO wallet_transactions (txid, raw_tx) VALUES ($1, $2)",
            &[&txid, &raw_tx],
            self
        )
        .map(|_| 0)
    }

    fn update_transaction(&self, txid: &[u8], raw_tx: &[u8]) -> Result<(), Error> {
        execute_blocking!(
            "UPDATE wallet_transactions SET raw_tx=$1 WHERE txid=$2",
            &[&txid, &raw_tx],
            self
        )
        .map(|_| ())
    }

    fn insert_transaction_details(&self, transaction: &TransactionDetails) -> Result<i64, Error> {
        let (timestamp, height) = match &transaction.confirmation_time {
            Some(confirmation_time) => (
                Some(confirmation_time.timestamp),
                Some(confirmation_time.height),
            ),
            None => (None, None),
        };

        let txid: &[u8] = transaction.txid.as_ref();

        execute_blocking!(
			"INSERT INTO wallet_transaction_details (txid, timestamp, received, sent, fee, height) VALUES ($1, $2, $3, $4, $5, $6)",
			&[
				&txid,
				&timestamp.map(|x| x as i64),
				&(transaction.received as i64),
				&(transaction.sent as i64),
				&transaction.fee.map(|x| x as i64),
				&height.map(|x| x as i64)
			],
			self
		)
		.map(|_| 0)
    }

    fn update_transaction_details(&self, transaction: &TransactionDetails) -> Result<(), Error> {
        let (timestamp, height) = match &transaction.confirmation_time {
            Some(confirmation_time) => (
                Some(confirmation_time.timestamp),
                Some(confirmation_time.height),
            ),
            None => (None, None),
        };

        let txid: &[u8] = transaction.txid.as_ref();

        execute_blocking!(
			"UPDATE wallet_transaction_details SET timestamp=$1, received=$2, sent=$3, fee=$4, height=$5 WHERE txid=$6",
			&[
				&timestamp.map(|x| x as i64),
				&(transaction.received as i64),
				&(transaction.sent as i64),
				&transaction.fee.map(|x| x as i64),
				&height.map(|x| x as i64),
				&txid,
			],
			self
		)
		.map(|_| ())
    }

    fn insert_last_derivation_index(&self, keychain: String, value: u32) -> Result<i64, Error> {
        execute_blocking!(
            "INSERT INTO wallet_last_derivation_indices (keychain, value) VALUES ($1, $2)",
            &[&keychain, &(value as i64)],
            self
        )
        .map(|_| 0)
    }

    fn insert_checksum(&self, keychain: String, checksum: &[u8]) -> Result<i64, Error> {
        execute_blocking!(
            "INSERT INTO wallet_checksums (keychain, checksum) VALUES ($1, $2)",
            &[&keychain, &checksum],
            self
        )
        .map(|_| 0)
    }

    fn update_last_derivation_index(&self, keychain: String, value: u32) -> Result<(), Error> {
        execute_blocking!(
            "UPSERT INTO wallet_last_derivation_indices (keychain, value) VALUES ($1, $2)",
            &[&keychain, &(value as i64)],
            self
        )
        .map(|_| ())
    }

    fn update_sync_time(&self, data: SyncTime) -> Result<i64, Error> {
        execute_blocking!(
            "UPSERT INTO wallet_sync_time (id, height, timestamp) VALUES (0, $1, $2)",
            &[
                &(data.block_time.height as i64),
                &(data.block_time.timestamp as i64)
            ],
            self
        )
        .map(|_| 0)
    }

    fn select_script_pubkeys(&self) -> Result<Vec<ScriptBuf>, Error> {
        let rows = query_blocking!("SELECT script FROM wallet_script_pubkeys", &[], self)?;
        let mut scripts: Vec<ScriptBuf> = vec![];
        for row in rows {
            let raw_script: Vec<u8> = row.get(0);
            scripts.push(raw_script.into());
        }
        Ok(scripts)
    }

    fn select_script_pubkeys_by_keychain(&self, keychain: String) -> Result<Vec<ScriptBuf>, Error> {
        let rows = query_blocking!(
            "SELECT script FROM wallet_script_pubkeys WHERE keychain=$1",
            &[&keychain],
            self
        )?;
        let mut scripts: Vec<ScriptBuf> = vec![];
        for row in rows {
            let raw_script: Vec<u8> = row.get(0);
            scripts.push(raw_script.into());
        }
        Ok(scripts)
    }

    fn select_script_pubkey_by_path(
        &self,
        keychain: String,
        child: u32,
    ) -> Result<Option<ScriptBuf>, Error> {
        let rows = query_blocking!(
            "SELECT script FROM wallet_script_pubkeys WHERE keychain=$1 AND child=$2",
            &[&keychain, &(child as i32)],
            self
        )?;

        match rows.first() {
            Some(row) => {
                let script: Vec<u8> = row.get(0);
                Ok(Some(script.into()))
            }
            None => Ok(None),
        }
    }

    fn select_script_pubkey_by_script(
        &self,
        script: &[u8],
    ) -> Result<Option<(KeychainKind, u32)>, Error> {
        let rows = query_blocking!(
            "SELECT keychain, child FROM wallet_script_pubkeys WHERE script=$1",
            &[&script],
            self
        )?;
        match rows.first() {
            Some(row) => {
                let keychain: String = row.get(0);
                let keychain: KeychainKind = serde_json::from_str(&keychain)?;
                let child = row.get::<usize, i32>(1) as u32;
                Ok(Some((keychain, child)))
            }
            None => Ok(None),
        }
    }

    fn select_utxos(&self) -> Result<Vec<LocalUtxo>, Error> {
        let rows = query_blocking!(
            "SELECT value, keychain, vout, txid, script, is_spent FROM wallet_utxos",
            &[],
            self
        )?;
        let mut utxos: Vec<LocalUtxo> = vec![];
        for row in rows {
            let value: u64 = row.get::<usize, i64>(0).try_into().unwrap();
            let keychain: String = row.get(1);
            let vout = row.get::<usize, i32>(2) as u32;
            let txid: Vec<u8> = row.get(3);
            let script: Vec<u8> = row.get(4);
            let is_spent: bool = row.get(5);

            let keychain: KeychainKind = serde_json::from_str(&keychain)?;

            utxos.push(LocalUtxo {
                outpoint: OutPoint::new(deserialize(&txid)?, vout),
                txout: TxOut {
                    value,
                    script_pubkey: script.into(),
                },
                keychain,
                is_spent,
            })
        }
        Ok(utxos)
    }

    fn select_utxo_by_outpoint(&self, txid: &[u8], vout: u32) -> Result<Option<LocalUtxo>, Error> {
        let rows = query_blocking!(
            "SELECT value, keychain, script, is_spent FROM wallet_utxos WHERE txid=$1 AND vout=$2",
            &[&txid, &(vout as i32)],
            self
        )?;
        match rows.first() {
            Some(row) => {
                let value: u64 = row.get::<usize, i64>(0).try_into().unwrap();
                let keychain: String = row.get(1);
                let keychain: KeychainKind = serde_json::from_str(&keychain)?;
                let script_pubkey = ScriptBuf::from_bytes(row.get(2));
                let is_spent: bool = row.get(3);

                Ok(Some(LocalUtxo {
                    outpoint: OutPoint::new(deserialize(txid)?, vout),
                    txout: TxOut {
                        value,
                        script_pubkey,
                    },
                    keychain,
                    is_spent,
                }))
            }
            None => Ok(None),
        }
    }

    fn select_transactions(&self) -> Result<Vec<Transaction>, Error> {
        let rows = query_blocking!("SELECT raw_tx FROM wallet_transactions", &[], self)?;
        let mut txs: Vec<Transaction> = vec![];
        for row in rows {
            let raw_tx: Vec<u8> = row.get(0);
            let tx: Transaction = deserialize(&raw_tx)?;
            txs.push(tx);
        }
        Ok(txs)
    }

    fn select_transaction_by_txid(&self, txid: &[u8]) -> Result<Option<Transaction>, Error> {
        let rows = query_blocking!(
            "SELECT raw_tx FROM wallet_transactions WHERE txid=$1",
            &[&txid],
            self
        )?;
        match rows.first() {
            Some(row) => {
                let raw_tx: Vec<u8> = row.get(0);
                let tx: Transaction = deserialize(&raw_tx)?;
                Ok(Some(tx))
            }
            None => Ok(None),
        }
    }

    fn select_transaction_details_with_raw(&self) -> Result<Vec<TransactionDetails>, Error> {
        let rows = query_blocking!("SELECT wtd.txid, wtd.timestamp, wtd.received, wtd.sent, wtd.fee, wtd.height, wt.raw_tx FROM wallet_transaction_details wtd, wallet_transactions wt WHERE wtd.txid = wt.txid", &[], self)?;
        let mut transaction_details: Vec<TransactionDetails> = vec![];
        for row in rows {
            let txid: Vec<u8> = row.get(0);
            let txid: Txid = deserialize(&txid)?;
            let timestamp: Option<u64> = row
                .get::<usize, Option<i64>>(1)
                .map(|x| x.try_into().unwrap());
            let received: u64 = row.get::<usize, i64>(2).try_into().unwrap();
            let sent: u64 = row.get::<usize, i64>(3).try_into().unwrap();
            let fee: Option<u64> = row
                .get::<usize, Option<i64>>(4)
                .map(|x| x.try_into().unwrap());
            let height: Option<u32> = row
                .get::<usize, Option<i64>>(5)
                .map(|x| x.try_into().unwrap());
            let raw_tx: Option<Vec<u8>> = row.get(6);
            let tx: Option<Transaction> = match raw_tx {
                Some(raw_tx) => {
                    let tx: Transaction = deserialize(&raw_tx)?;
                    Some(tx)
                }
                None => None,
            };

            let confirmation_time = match (height, timestamp) {
                (Some(height), Some(timestamp)) => Some(BlockTime { height, timestamp }),
                _ => None,
            };

            transaction_details.push(TransactionDetails {
                transaction: tx,
                txid,
                received,
                sent,
                fee,
                confirmation_time,
            });
        }
        Ok(transaction_details)
    }

    fn select_transaction_details(&self) -> Result<Vec<TransactionDetails>, Error> {
        let rows = query_blocking!(
            "SELECT txid, timestamp, received, sent, fee, height FROM wallet_transaction_details",
            &[],
            self
        )?;
        let mut transaction_details: Vec<TransactionDetails> = vec![];
        for row in rows {
            let txid: Vec<u8> = row.get(0);
            let txid: Txid = deserialize(&txid)?;
            let timestamp: Option<u64> = row
                .get::<usize, Option<i64>>(1)
                .map(|x| x.try_into().unwrap());
            let received: u64 = row.get::<usize, i64>(2).try_into().unwrap();
            let sent: u64 = row.get::<usize, i64>(3).try_into().unwrap();
            let fee: Option<u64> = row
                .get::<usize, Option<i64>>(4)
                .map(|x| x.try_into().unwrap());
            let height: Option<u32> = row
                .get::<usize, Option<i64>>(5)
                .map(|x| x.try_into().unwrap());

            let confirmation_time = match (height, timestamp) {
                (Some(height), Some(timestamp)) => Some(BlockTime { height, timestamp }),
                _ => None,
            };

            transaction_details.push(TransactionDetails {
                transaction: None,
                txid,
                received,
                sent,
                fee,
                confirmation_time,
            });
        }
        Ok(transaction_details)
    }

    fn select_transaction_details_by_txid(
        &self,
        txid: &[u8],
    ) -> Result<Option<TransactionDetails>, Error> {
        let rows = query_blocking!("SELECT wtd.timestamp, wtd.received, wtd.sent, wtd.fee, wtd.height, wt.raw_tx FROM wallet_transaction_details wtd, wallet_transactions wt WHERE wtd.txid=wt.txid AND wtd.txid=$1", &[&txid], self)?;

        match rows.first() {
            Some(row) => {
                let timestamp: Option<u64> = row
                    .get::<usize, Option<i64>>(0)
                    .map(|x| x.try_into().unwrap());
                let received: u64 = row.get::<usize, i64>(1).try_into().unwrap();
                let sent: u64 = row.get::<usize, i64>(2).try_into().unwrap();
                let fee: Option<u64> = row
                    .get::<usize, Option<i64>>(3)
                    .map(|x| x.try_into().unwrap());
                let height: Option<u32> = row
                    .get::<usize, Option<i64>>(4)
                    .map(|x| x.try_into().unwrap());

                let raw_tx: Option<Vec<u8>> = row.get(5);
                let tx: Option<Transaction> = match raw_tx {
                    Some(raw_tx) => {
                        let tx: Transaction = deserialize(&raw_tx)?;
                        Some(tx)
                    }
                    None => None,
                };

                let confirmation_time = match (height, timestamp) {
                    (Some(height), Some(timestamp)) => Some(BlockTime { height, timestamp }),
                    _ => None,
                };

                Ok(Some(TransactionDetails {
                    transaction: tx,
                    txid: deserialize(txid)?,
                    received,
                    sent,
                    fee,
                    confirmation_time,
                }))
            }
            None => Ok(None),
        }
    }

    fn select_last_derivation_index_by_keychain(
        &self,
        keychain: String,
    ) -> Result<Option<u32>, Error> {
        let rows = query_blocking!(
            "SELECT value FROM wallet_last_derivation_indices WHERE keychain=$1",
            &[&keychain],
            self
        )?;
        match rows.first() {
            Some(row) => {
                let value: u32 = row.get::<usize, i64>(0).try_into().unwrap();
                Ok(Some(value))
            }
            None => Ok(None),
        }
    }

    fn select_sync_time(&self) -> Result<Option<SyncTime>, Error> {
        let rows = query_blocking!(
            "SELECT height, timestamp FROM wallet_sync_time WHERE id = 0",
            &[],
            self
        )?;

        if let Some(row) = rows.first() {
            Ok(Some(SyncTime {
                block_time: BlockTime {
                    height: row.get::<usize, i64>(0).try_into().unwrap(),
                    timestamp: row.get::<usize, i64>(1).try_into().unwrap(),
                },
            }))
        } else {
            Ok(None)
        }
    }

    fn select_checksum_by_keychain(&self, keychain: String) -> Result<Option<Vec<u8>>, Error> {
        let rows = query_blocking!(
            "SELECT checksum FROM wallet_checksums WHERE keychain=$1",
            &[&keychain],
            self
        )?;

        match rows.first() {
            Some(row) => {
                let checksum: Vec<u8> = row.get(0);
                Ok(Some(checksum))
            }
            None => Ok(None),
        }
    }

    fn delete_script_pubkey_by_path(&self, keychain: String, child: u32) -> Result<(), Error> {
        execute_blocking!(
            "DELETE FROM wallet_script_pubkeys WHERE keychain=$1 AND child=$2",
            &[&keychain, &(child as i32)],
            self
        )
        .map(|_| ())
    }

    fn delete_script_pubkey_by_script(&self, script: &[u8]) -> Result<(), Error> {
        execute_blocking!(
            "DELETE FROM wallet_script_pubkeys WHERE script=$1",
            &[&script],
            self
        )
        .map(|_| ())
    }

    fn delete_utxo_by_outpoint(&self, txid: &[u8], vout: u32) -> Result<(), Error> {
        execute_blocking!(
            "DELETE FROM wallet_utxos WHERE txid=$1 AND vout=$2",
            &[&txid, &(vout as i32)],
            self
        )
        .map(|_| ())
    }

    fn delete_transaction_by_txid(&self, txid: &[u8]) -> Result<(), Error> {
        execute_blocking!(
            "DELETE FROM wallet_transactions WHERE txid=$1",
            &[&txid],
            self
        )
        .map(|_| ())
    }

    fn delete_transaction_details_by_txid(&self, txid: &[u8]) -> Result<(), Error> {
        execute_blocking!(
            "DELETE FROM wallet_transaction_details WHERE txid=$1",
            &[&txid],
            self
        )
        .map(|_| ())
    }

    fn delete_last_derivation_index_by_keychain(&self, keychain: String) -> Result<(), Error> {
        execute_blocking!(
            "DELETE FROM wallet_last_derivation_indices WHERE keychain=$1",
            &[&keychain],
            self
        )
        .map(|_| ())
    }

    fn delete_sync_time(&self) -> Result<(), Error> {
        execute_blocking!("DELETE FROM wallet_sync_time WHERE id = 0", &[], self).map(|_| ())
    }
}

impl BatchOperations for WalletDatabase {
    fn set_script_pubkey(
        &mut self,
        script: &Script,
        keychain: KeychainKind,
        child: u32,
    ) -> Result<(), Error> {
        let keychain = serde_json::to_string(&keychain)?;
        self.insert_script_pubkey(keychain, child, script.as_bytes())?;
        Ok(())
    }

    fn set_utxo(&mut self, utxo: &LocalUtxo) -> Result<(), Error> {
        self.insert_utxo(
            utxo.txout.value,
            serde_json::to_string(&utxo.keychain)?,
            utxo.outpoint.vout,
            utxo.outpoint.txid.as_ref(),
            utxo.txout.script_pubkey.as_bytes(),
            utxo.is_spent,
        )?;
        Ok(())
    }

    fn set_raw_tx(&mut self, transaction: &Transaction) -> Result<(), Error> {
        let txid = transaction.txid();
        match self.select_transaction_by_txid(txid.as_ref())? {
            Some(_) => {
                self.update_transaction(txid.as_ref(), &serialize(transaction))?;
            }
            None => {
                self.insert_transaction(txid.as_ref(), &serialize(transaction))?;
            }
        }
        Ok(())
    }

    fn set_tx(&mut self, transaction: &TransactionDetails) -> Result<(), Error> {
        match self.select_transaction_details_by_txid(transaction.txid.as_ref())? {
            Some(_) => {
                self.update_transaction_details(transaction)?;
            }
            None => {
                self.insert_transaction_details(transaction)?;
            }
        }

        if let Some(tx) = &transaction.transaction {
            self.set_raw_tx(tx)?;
        }

        Ok(())
    }

    fn set_last_index(&mut self, keychain: KeychainKind, value: u32) -> Result<(), Error> {
        self.update_last_derivation_index(serde_json::to_string(&keychain)?, value)?;
        Ok(())
    }

    fn set_sync_time(&mut self, ct: SyncTime) -> Result<(), Error> {
        self.update_sync_time(ct)?;
        Ok(())
    }

    fn del_script_pubkey_from_path(
        &mut self,
        keychain: KeychainKind,
        child: u32,
    ) -> Result<Option<ScriptBuf>, Error> {
        let keychain = serde_json::to_string(&keychain)?;
        let script = self.select_script_pubkey_by_path(keychain.clone(), child)?;
        match script {
            Some(script) => {
                self.delete_script_pubkey_by_path(keychain, child)?;
                Ok(Some(script))
            }
            None => Ok(None),
        }
    }

    fn del_path_from_script_pubkey(
        &mut self,
        script: &Script,
    ) -> Result<Option<(KeychainKind, u32)>, Error> {
        match self.select_script_pubkey_by_script(script.as_bytes())? {
            Some((keychain, child)) => {
                self.delete_script_pubkey_by_script(script.as_bytes())?;
                Ok(Some((keychain, child)))
            }
            None => Ok(None),
        }
    }

    fn del_utxo(&mut self, outpoint: &OutPoint) -> Result<Option<LocalUtxo>, Error> {
        match self.select_utxo_by_outpoint(outpoint.txid.as_ref(), outpoint.vout)? {
            Some(local_utxo) => {
                self.delete_utxo_by_outpoint(outpoint.txid.as_ref(), outpoint.vout)?;
                Ok(Some(local_utxo))
            }
            None => Ok(None),
        }
    }

    fn del_raw_tx(&mut self, txid: &Txid) -> Result<Option<Transaction>, Error> {
        match self.select_transaction_by_txid(txid.as_ref())? {
            Some(tx) => {
                self.delete_transaction_by_txid(txid.as_ref())?;
                Ok(Some(tx))
            }
            None => Ok(None),
        }
    }

    fn del_tx(
        &mut self,
        txid: &Txid,
        include_raw: bool,
    ) -> Result<Option<TransactionDetails>, Error> {
        match self.select_transaction_details_by_txid(txid.as_ref())? {
            Some(transaction_details) => {
                self.delete_transaction_details_by_txid(txid.as_ref())?;

                if include_raw {
                    self.delete_transaction_by_txid(txid.as_ref())?;
                }
                Ok(Some(transaction_details))
            }
            None => Ok(None),
        }
    }

    fn del_last_index(&mut self, keychain: KeychainKind) -> Result<Option<u32>, Error> {
        let keychain = serde_json::to_string(&keychain)?;
        match self.select_last_derivation_index_by_keychain(keychain.clone())? {
            Some(value) => {
                self.delete_last_derivation_index_by_keychain(keychain)?;

                Ok(Some(value))
            }
            None => Ok(None),
        }
    }

    fn del_sync_time(&mut self) -> Result<Option<SyncTime>, Error> {
        match self.select_sync_time()? {
            Some(value) => {
                self.delete_sync_time()?;

                Ok(Some(value))
            }
            None => Ok(None),
        }
    }
}

impl Database for WalletDatabase {
    fn check_descriptor_checksum<B: AsRef<[u8]>>(
        &mut self,
        keychain: KeychainKind,
        bytes: B,
    ) -> Result<(), Error> {
        let keychain = serde_json::to_string(&keychain)?;

        match self.select_checksum_by_keychain(keychain.clone())? {
            Some(checksum) => {
                if checksum == bytes.as_ref().to_vec() {
                    Ok(())
                } else {
                    Err(Error::ChecksumMismatch)
                }
            }
            None => {
                self.insert_checksum(keychain, bytes.as_ref())?;
                Ok(())
            }
        }
    }

    fn iter_script_pubkeys(&self, keychain: Option<KeychainKind>) -> Result<Vec<ScriptBuf>, Error> {
        match keychain {
            Some(keychain) => {
                let keychain = serde_json::to_string(&keychain)?;
                self.select_script_pubkeys_by_keychain(keychain)
            }
            None => self.select_script_pubkeys(),
        }
    }

    fn iter_utxos(&self) -> Result<Vec<LocalUtxo>, Error> {
        self.select_utxos()
    }

    fn iter_raw_txs(&self) -> Result<Vec<Transaction>, Error> {
        self.select_transactions()
    }

    fn iter_txs(&self, include_raw: bool) -> Result<Vec<TransactionDetails>, Error> {
        match include_raw {
            true => self.select_transaction_details_with_raw(),
            false => self.select_transaction_details(),
        }
    }

    fn get_script_pubkey_from_path(
        &self,
        keychain: KeychainKind,
        child: u32,
    ) -> Result<Option<ScriptBuf>, Error> {
        let keychain = serde_json::to_string(&keychain)?;
        match self.select_script_pubkey_by_path(keychain, child)? {
            Some(script) => Ok(Some(script)),
            None => Ok(None),
        }
    }

    fn get_path_from_script_pubkey(
        &self,
        script: &Script,
    ) -> Result<Option<(KeychainKind, u32)>, Error> {
        match self.select_script_pubkey_by_script(script.as_bytes())? {
            Some((keychain, child)) => Ok(Some((keychain, child))),
            None => Ok(None),
        }
    }

    fn get_utxo(&self, outpoint: &OutPoint) -> Result<Option<LocalUtxo>, Error> {
        self.select_utxo_by_outpoint(outpoint.txid.as_ref(), outpoint.vout)
    }

    fn get_raw_tx(&self, txid: &Txid) -> Result<Option<Transaction>, Error> {
        match self.select_transaction_by_txid(txid.as_ref())? {
            Some(tx) => Ok(Some(tx)),
            None => Ok(None),
        }
    }

    fn get_tx(&self, txid: &Txid, include_raw: bool) -> Result<Option<TransactionDetails>, Error> {
        match self.select_transaction_details_by_txid(txid.as_ref())? {
            Some(mut transaction_details) => {
                if !include_raw {
                    transaction_details.transaction = None;
                }
                Ok(Some(transaction_details))
            }
            None => Ok(None),
        }
    }

    fn get_last_index(&self, keychain: KeychainKind) -> Result<Option<u32>, Error> {
        let keychain = serde_json::to_string(&keychain)?;
        let value = self.select_last_derivation_index_by_keychain(keychain)?;
        Ok(value)
    }

    fn get_sync_time(&self) -> Result<Option<SyncTime>, Error> {
        self.select_sync_time()
    }

    fn increment_last_index(&mut self, keychain: KeychainKind) -> Result<u32, Error> {
        let keychain_string = serde_json::to_string(&keychain)?;
        match self.get_last_index(keychain)? {
            Some(value) => {
                self.update_last_derivation_index(keychain_string, value + 1)?;
                Ok(value + 1)
            }
            None => {
                self.insert_last_derivation_index(keychain_string, 0)?;
                Ok(0)
            }
        }
    }
}

impl BatchDatabase for WalletDatabase {
    type Batch = WalletDatabase;

    fn begin_batch(&self) -> Result<Self::Batch, Error> {
        tokio::task::block_in_place(move || {
            Handle::current().block_on(async move {
                let database = WalletDatabase {
                    settings: self.settings.clone(),
                    durable_connection: self.durable_connection.clone(),
                };
                database
                    .durable_connection
                    .get()
                    .await
                    .batch_execute("BEGIN")
                    .await
                    .map_err(|e| Error::Generic(format!("Failed to begin SQL transaction: {e}")))?;
                Ok(database)
            })
        })
    }

    fn commit_batch(&mut self, batch: Self::Batch) -> Result<(), Error> {
        tokio::task::block_in_place(move || {
            Handle::current().block_on(async move {
                batch
                    .durable_connection
                    .get()
                    .await
                    .batch_execute("COMMIT")
                    .await
                    .map_err(|e| Error::Generic(format!("Failed to commit SQL transaction: {e}")))
            })
        })
    }
}

'''
'''--- kld/src/key_generator.rs ---
#[cfg(not(test))]
use std::fs;
#[cfg(test)]
use test_utils::fake_fs as fs;

use anyhow::{anyhow, Context, Result};
use bdk::keys::bip39::{Language, Mnemonic, WordCount};
use bdk::keys::GeneratableKey;
use bdk::miniscript::Tap;
use bitcoin::hashes::{sha256, Hash, HashEngine};
use log::info;

// To start lets have only one primary seed to backup and derive everything else from that.
pub struct KeyGenerator {
    mnemonic: Mnemonic,
}

impl KeyGenerator {
    pub fn init(mnemonic_path: &str) -> Result<KeyGenerator> {
        let mnemonic = if let Ok(words) = fs::read_to_string(mnemonic_path) {
            info!("Loading mnemonic from {mnemonic_path}");
            Mnemonic::parse(words)?
        } else {
            let mnemonic: bdk::keys::GeneratedKey<_, Tap> =
                Mnemonic::generate((WordCount::Words24, Language::English))
                    .map_err(|_| anyhow!("Mnemonic generation error"))?;

            fs::write(mnemonic_path, mnemonic.to_string())
                .with_context(|| format!("Cannot write to {mnemonic_path}"))?;
            info!("Generated a new mnemonic: {}", mnemonic_path);
            mnemonic.into_key()
        };
        Ok(KeyGenerator { mnemonic })
    }

    pub fn wallet_seed(&self) -> [u8; 32] {
        // The seed can be loaded into any regular wallet and the on chain funds will be available.
        self.generate_key("")
    }

    pub fn lightning_seed(&self) -> [u8; 32] {
        self.generate_key("lightning/0")
    }

    pub fn macaroon_seed(&self) -> [u8; 32] {
        self.generate_key("macaroon/0")
    }

    pub fn promise_seed(&self) -> [u8; 32] {
        self.generate_key("promise_seed")
    }

    fn generate_key(&self, extra_input: &str) -> [u8; 32] {
        let mut engine = sha256::HashEngine::default();
        engine.input(&self.mnemonic.to_seed(""));
        engine.input(extra_input.as_bytes());
        let hash = sha256::Hash::from_engine(engine);
        hash.to_byte_array()
    }
}

#[test]
fn test_key_generator() -> Result<()> {
    let key_generator = KeyGenerator::init("")?;
    let wallet_seed = key_generator.wallet_seed();
    let lightning_seed = key_generator.lightning_seed();
    let macaroon_seed = key_generator.macaroon_seed();

    assert_eq!(wallet_seed, key_generator.wallet_seed());
    assert_eq!(lightning_seed, key_generator.lightning_seed());
    assert_eq!(macaroon_seed, key_generator.macaroon_seed());

    assert_ne!(wallet_seed, lightning_seed);
    assert_ne!(lightning_seed, macaroon_seed);
    Ok(())
}

'''
'''--- kld/src/kld/main.rs ---
use anyhow::{Context, Result};
use futures::FutureExt;
use kld::api::{bind_api_server, MacaroonAuth};
use kld::bitcoind::BitcoindClient;
use kld::database::{DurableConnection, WalletDatabase};
use kld::key_generator::KeyGenerator;
use kld::ldk::Controller;
use kld::logger::KldLogger;
use kld::prometheus::start_prometheus_exporter;
use kld::settings::Settings;
use kld::wallet::Wallet;
use kld::{log_error, quit_signal, VERSION};
use log::{error, info};
use prometheus::IntCounter;
use std::sync::Arc;
use std::sync::OnceLock;
use std::time::Duration;

static PROBE_TOTAL_COUNT: OnceLock<IntCounter> = OnceLock::new();
static PROBE_SUCCESSFUL_COUNT: OnceLock<IntCounter> = OnceLock::new();
static PROBE_FAILED_COUNT: OnceLock<IntCounter> = OnceLock::new();

pub fn main() {
    let settings = Arc::new(Settings::load());
    KldLogger::init(
        &settings.node_id,
        settings.log_level.parse().expect("Invalid log level"),
    );

    info!("Starting {VERSION}");

    let runtime = tokio::runtime::Builder::new_multi_thread()
        .enable_io()
        .enable_time()
        .build()
        .expect("could not create runtime");

    let exit_code = if let Err(e) = runtime.block_on(run_kld(settings)) {
        error!("Fatal error encountered: {e}");
        log_error(&e);
        error!("{}", e.backtrace());
        1
    } else {
        0
    };

    info!("Shutting down");
    runtime.shutdown_timeout(Duration::from_secs(30));
    info!("Stopped all threads. Process finished.");
    std::process::exit(exit_code);
}

async fn run_kld(settings: Arc<Settings>) -> Result<()> {
    let quit_signal = quit_signal().shared();

    let durable_connection = Arc::new(DurableConnection::new_migrate(settings.clone()).await);

    let key_generator = Arc::new(
        KeyGenerator::init(&settings.mnemonic_path).context("cannot initialize key generator")?,
    );

    let wallet_database = WalletDatabase::new(settings.clone(), durable_connection.clone());

    let bitcoind_client = Arc::new(BitcoindClient::new(&settings).await?);

    // Hot fix the fee rate, due to Signet
    // bitcoind_client.poll_for_fee_estimates();
    bitcoind_client.set_lowest_fee_estimates();

    let wallet = Arc::new(
        Wallet::new(
            &key_generator.wallet_seed(),
            settings.clone(),
            bitcoind_client.clone(),
            wallet_database,
        )
        .context("Cannot create wallet")?,
    );

    let controller = Controller::start_ldk(
        settings.clone(),
        durable_connection.clone(),
        bitcoind_client.clone(),
        wallet.clone(),
        &key_generator,
        quit_signal.clone(),
        (
            &PROBE_TOTAL_COUNT,
            &PROBE_SUCCESSFUL_COUNT,
            &PROBE_FAILED_COUNT,
        ),
    )
    .await
    .context("Failed to start ldk controller")?;
    let controller = Arc::new(controller);

    let macaroon_auth = Arc::new(MacaroonAuth::init(
        &key_generator.macaroon_seed(),
        &settings.data_dir,
    )?);

    let server = bind_api_server(
        settings.rest_api_address.clone(),
        settings.certs_dir.clone(),
    )
    .await?;

    tokio::select!(
        _ = quit_signal.clone() => {
            info!("Received quit signal. Will shtudwon after {} seconds graceful period", settings.shutdown_graceful_sec);
            tokio::time::sleep(Duration::from_secs(settings.shutdown_graceful_sec)).await;
            info!("Force shutdown");
            Ok(())
        },
        result = start_prometheus_exporter(settings.exporter_address.clone(), controller.clone(), durable_connection.clone(), bitcoind_client.clone(), quit_signal.clone(),
                                           (&PROBE_TOTAL_COUNT, &PROBE_SUCCESSFUL_COUNT, &PROBE_FAILED_COUNT)) => {
            result.context("Prometheus exporter failed")
        },
        result = server.serve(bitcoind_client.clone(), controller.clone(), wallet.clone(), macaroon_auth, quit_signal) => {
            result.context("REST API failed")
        }
    )
}

'''
'''--- kld/src/ldk/channel_utils.rs ---
/// Maximum transaction index that can be used in a `short_channel_id`.
/// This value is based on the 3-bytes available for tx index.
pub const MAX_SCID_TX_INDEX: u64 = 0x00ffffff;

/// Maximum vout index that can be used in a `short_channel_id`. This
/// value is based on the 2-bytes available for the vout index.
pub const MAX_SCID_VOUT_INDEX: u64 = 0xffff;

/// Extracts the block height (most significant 3-bytes) from the `short_channel_id`
pub fn block_from_scid(short_channel_id: &u64) -> u32 {
    (short_channel_id >> 40) as u32
}

/// Extracts the tx index (bytes [2..4]) from the `short_channel_id`
pub fn tx_index_from_scid(short_channel_id: &u64) -> u32 {
    ((short_channel_id >> 16) & MAX_SCID_TX_INDEX) as u32
}

/// Extracts the vout (bytes [0..2]) from the `short_channel_id`
pub fn vout_from_scid(short_channel_id: &u64) -> u16 {
    ((short_channel_id) & MAX_SCID_VOUT_INDEX) as u16
}

'''
'''--- kld/src/ldk/controller.rs ---
use crate::bitcoind::bitcoind_interface::BitcoindInterface;
use crate::bitcoind::{BitcoindClient, BitcoindUtxoLookup};
use crate::database::forward::{Forward, ForwardStatus, TotalForwards};
use crate::database::invoice::Invoice;
use crate::database::payment::{Payment, PaymentDirection};
use crate::database::ChannelRecord;
use crate::key_generator::KeyGenerator;
use crate::wallet::{Wallet, WalletInterface};
use crate::{log_error, MillisatAmount, Service};

use crate::api::payloads::FeeRate;
use crate::api::SocketAddress;
use crate::database::{DurableConnection, LdkDatabase, WalletDatabase};
use anyhow::{anyhow, bail, Context, Result};
use async_trait::async_trait;
use bitcoin::secp256k1::PublicKey;
use bitcoin::{BlockHash, Network, Transaction};
use lightning::chain;
use lightning::chain::channelmonitor::ChannelMonitor;
use lightning::chain::BestBlock;
use lightning::chain::Watch;
use lightning::ln::channelmanager::ChainParameters;
use lightning::ln::channelmanager::ChannelManagerReadArgs;
use lightning::ln::channelmanager::{
    self, ChannelDetails, PaymentId, PaymentSendFailure, RecipientOnionFields,
};
use lightning::ln::peer_handler::{IgnoringMessageHandler, MessageHandler};
use lightning::ln::ChannelId;
use lightning::routing::gossip::{ChannelInfo, NodeId, NodeInfo, P2PGossipSync};
use lightning::routing::router::{
    DefaultRouter, Path, PaymentParameters, RouteParameters, Router,
    ScorerAccountingForInFlightHtlcs,
};
use lightning::routing::scoring::ScoreUpdate;
use lightning::routing::scoring::{
    ProbabilisticScorer, ProbabilisticScoringDecayParameters, ProbabilisticScoringFeeParameters,
};
use lightning::sign::{InMemorySigner, KeysManager};
use lightning::util::config::UserConfig;
use lightning::util::errors::APIError;

use crate::ldk::peer_manager::KuutamoPeerManger;
use crate::logger::KldLogger;
use crate::settings::Settings;
use chrono::DateTime;
use lightning::util::indexed_map::IndexedMap;
use lightning_background_processor::{process_events_async, GossipSync};
use lightning_block_sync::poll;
use lightning_block_sync::SpvClient;
use lightning_block_sync::UnboundedCache;
use lightning_block_sync::{init, BlockSourceResult};
use lightning_invoice::DEFAULT_EXPIRY_TIME;
use lightning_liquidity::events::Event::LSPS2Service;
use lightning_liquidity::lsps2::event::LSPS2ServiceEvent;
use lightning_liquidity::lsps2::msgs::RawOpeningFeeParams;
use lightning_liquidity::lsps2::service::LSPS2ServiceConfig;
use lightning_liquidity::LiquidityServiceConfig;
use log::{debug, error, info, trace, warn};
use prometheus::IntCounter;
use rand::random;
use std::collections::{HashMap, HashSet};
use std::sync::Arc;
use std::sync::OnceLock;
use std::thread::sleep;
use std::time::{Duration, SystemTime};

use futures::{future::Shared, Future};
use tokio::sync::oneshot::{self, Receiver, Sender};
use tokio::sync::RwLock;

use super::event_handler::EventHandler;
use super::peer_manager::PeerManager;
use super::{
    ldk_error, lightning_error, payment_send_failure, retryable_send_failure,
    sign_or_creation_error, ChainMonitor, ChannelManager, KldRouter, KuutamoCustomMessageHandler,
    LightningInterface, LiquidityManager, NetworkGraph, OnionMessenger, OpenChannelResult, Peer,
    PeerStatus, Scorer,
};

#[async_trait]
impl LightningInterface for Controller {
    fn identity_pubkey(&self) -> PublicKey {
        self.channel_manager.get_our_node_id()
    }

    async fn synced(&self) -> Result<bool> {
        Ok(self.bitcoind_client.is_synchronised().await && self.wallet.synced().await)
    }

    fn sign(&self, message: &[u8]) -> Result<String> {
        let secret_key = self.keys_manager.get_node_secret_key();
        let signature = lightning::util::message_signing::sign(message, &secret_key)?;
        Ok(signature)
    }

    fn graph_num_nodes(&self) -> usize {
        self.network_graph.read_only().nodes().len()
    }

    fn graph_num_channels(&self) -> usize {
        self.network_graph.read_only().channels().len()
    }

    fn num_peers(&self) -> usize {
        self.peer_manager.get_connected_peers().len()
    }

    fn wallet_balance(&self) -> u64 {
        match self.wallet.balance() {
            Ok(balance) => balance.confirmed,
            Err(e) => {
                error!("Unable to get wallet balance for metrics: {}", e);
                0
            }
        }
    }

    fn alias(&self) -> String {
        self.settings.node_alias.clone()
    }

    fn color(&self) -> String {
        self.settings.node_alias_color.clone()
    }

    fn network(&self) -> bitcoin::Network {
        self.settings.bitcoin_network
    }

    fn num_active_channels(&self) -> usize {
        self.channel_manager
            .list_channels()
            .iter()
            .filter(|c| c.is_usable)
            .count()
    }

    fn num_inactive_channels(&self) -> usize {
        self.channel_manager
            .list_channels()
            .iter()
            .filter(|c| c.is_channel_ready && !c.is_usable)
            .count()
    }

    fn num_pending_channels(&self) -> usize {
        self.channel_manager
            .list_channels()
            .iter()
            .filter(|c| !c.is_channel_ready)
            .count()
    }

    fn list_active_channels(&self) -> Vec<ChannelDetails> {
        self.channel_manager.list_channels()
    }

    async fn list_channels(&self) -> Result<Vec<ChannelRecord>> {
        self.database.fetch_channels().await
    }

    async fn open_channel(
        &self,
        their_network_key: PublicKey,
        channel_value_satoshis: u64,
        push_msat: Option<u64>,
        fee_rate: Option<FeeRate>,
        override_config: Option<UserConfig>,
    ) -> Result<OpenChannelResult> {
        if !self.bitcoind_client.is_synchronised().await {
            bail!("Bitcoind is synchronising blockchain")
        }
        if !self.peer_manager.is_connected(&their_network_key) {
            return Err(anyhow!("Peer not connected"));
        }
        let user_channel_id: u64 = random::<u64>() / 2; // To fit into the database INT
        let is_public = override_config
            .map(|c| c.channel_handshake_config.announced_channel)
            .unwrap_or_default();
        let counterparty = their_network_key;
        let channel_id = self
            .channel_manager
            .create_channel(
                their_network_key,
                channel_value_satoshis,
                push_msat.unwrap_or_default(),
                user_channel_id as u128,
                None,
                override_config,
            )
            .map_err(ldk_error)?;
        let receiver = self
            .async_api_requests
            .funding_transactions
            .insert(user_channel_id, fee_rate.unwrap_or_default())
            .await;
        let transaction = receiver.await??;
        let txid = transaction.txid();
        if let Err(e) = self
            .database
            .persist_initializing_channel(&channel_id, is_public, &counterparty, &txid)
            .await
        {
            // This failure should not cause issues, the channel detail update will be retried later,
            // triggered on the next event, so we do not retry and only log the error but not raise it here.
            log_error(&e);
        }
        Ok(OpenChannelResult {
            transaction,
            txid,
            channel_id,
        })
    }

    async fn close_channel(
        &self,
        channel_id: &ChannelId,
        counterparty_node_id: &PublicKey,
        fee_rate: Option<u32>,
    ) -> Result<()> {
        if !self.bitcoind_client.is_synchronised().await {
            bail!("Bitcoind is synchronising blockchain")
        }
        if fee_rate.is_some() {
            self.channel_manager
                .close_channel_with_feerate_and_script(
                    channel_id,
                    counterparty_node_id,
                    fee_rate,
                    None,
                )
                .map_err(ldk_error)
        } else {
            self.channel_manager
                .close_channel(channel_id, counterparty_node_id)
                .map_err(ldk_error)
        }
    }

    async fn force_close_channel(
        &self,
        channel_id: &ChannelId,
        counterparty_node_id: &PublicKey,
        with_broadcast: bool,
    ) -> Result<()> {
        if !self.bitcoind_client.is_synchronised().await {
            bail!("Bitcoind is synchronising blockchain")
        }
        if with_broadcast {
            self.channel_manager
                .force_close_broadcasting_latest_txn(channel_id, counterparty_node_id)
        } else {
            self.channel_manager
                .force_close_without_broadcasting_txn(channel_id, counterparty_node_id)
        }
        .map_err(ldk_error)
    }

    fn set_channel_fee(
        &self,
        counterparty_node_id: &PublicKey,
        channel_ids: &[ChannelId],
        forwarding_fee_proportional_millionths: Option<u32>,
        forwarding_fee_base_msat: Option<u32>,
    ) -> Result<(u32, u32)> {
        let mut channel_config = self.user_config().channel_config;
        if let Some(fee) = forwarding_fee_proportional_millionths {
            channel_config.forwarding_fee_proportional_millionths = fee;
        }
        if let Some(fee) = forwarding_fee_base_msat {
            channel_config.forwarding_fee_base_msat = fee;
        }
        self.channel_manager
            .update_channel_config(counterparty_node_id, channel_ids, &channel_config)
            .map_err(ldk_error)?;
        Ok((
            channel_config.forwarding_fee_base_msat,
            channel_config.forwarding_fee_proportional_millionths,
        ))
    }

    fn alias_of(&self, public_key: &PublicKey) -> Option<String> {
        self.network_graph
            .read_only()
            .node(&NodeId::from_pubkey(public_key))
            .and_then(|n| n.announcement_info.as_ref().map(|a| a.alias.to_string()))
    }

    /// List all the peers that we have channels with along with their connection status.
    async fn list_peers(&self) -> Result<Vec<Peer>> {
        let connected_peers = self.peer_manager.get_connected_peers();
        let channel_peers: Vec<PublicKey> = self
            .channel_manager
            .list_channels()
            .iter()
            .map(|c| c.counterparty.node_id)
            .collect();
        let persistent_peers = self.database.fetch_peers().await?;

        let mut response = vec![];

        let mut all_pub_keys: HashSet<PublicKey> = HashSet::from_iter(
            connected_peers
                .iter()
                .map(|p| p.0)
                .collect::<Vec<PublicKey>>(),
        );
        all_pub_keys.extend(channel_peers);
        all_pub_keys.extend(persistent_peers.keys());

        for public_key in all_pub_keys {
            let net_address = connected_peers
                .iter()
                .find(|p| p.0 == public_key)
                .and_then(|p| p.1.clone());
            let status = if net_address.is_some() {
                PeerStatus::Connected
            } else {
                PeerStatus::Disconnected
            };
            response.push(Peer {
                public_key,
                net_address,
                status,
                alias: self.alias_of(&public_key).unwrap_or_default(),
            });
        }
        Ok(response)
    }

    async fn connect_peer(
        &self,
        public_key: PublicKey,
        peer_address: Option<SocketAddress>,
    ) -> Result<()> {
        if let Some(net_address) = peer_address {
            self.peer_manager
                .connect_peer(self.database.clone(), public_key, net_address)
                .await
        } else {
            let addresses: Vec<SocketAddress> = self
                .network_graph
                .read_only()
                .get_addresses(&public_key)
                .context("No addresses found for node")?
                .into_iter()
                .map(|a| a.into())
                .filter(|a: &SocketAddress| a.is_ipv4())
                .collect();
            for address in addresses {
                if let Err(e) = self
                    .peer_manager
                    .connect_peer(self.database.clone(), public_key, address.clone())
                    .await
                {
                    info!("Could not connect to {public_key}@{address}. {}", e);
                } else {
                    return Ok(());
                }
            }
            Err(anyhow!("Could not connect to any peer addresses."))
        }
    }

    async fn disconnect_peer(&self, public_key: PublicKey) -> Result<()> {
        self.peer_manager
            .disconnect_and_drop_by_node_id(self.database.clone(), public_key)
            .await
    }

    fn public_addresses(&self) -> Vec<SocketAddress> {
        self.settings.public_addresses.clone()
    }

    fn get_node(&self, node_id: &NodeId) -> Option<NodeInfo> {
        self.network_graph.read_only().node(node_id).cloned()
    }

    fn nodes(&self) -> IndexedMap<NodeId, NodeInfo> {
        self.network_graph.read_only().nodes().clone()
    }

    fn get_channel(&self, channel_id: u64) -> Option<ChannelInfo> {
        self.network_graph.read_only().channel(channel_id).cloned()
    }

    fn channels(&self) -> IndexedMap<u64, ChannelInfo> {
        self.network_graph.read_only().channels().clone()
    }

    // Use this to override the default/startup config.
    fn user_config(&self) -> UserConfig {
        *self.channel_manager.get_current_default_configuration()
    }

    async fn generate_invoice(
        &self,
        label: String,
        amount: Option<u64>,
        description: String,
        expiry: Option<u32>,
    ) -> Result<Invoice> {
        let bolt11 = lightning_invoice::utils::create_invoice_from_channelmanager(
            &self.channel_manager,
            self.keys_manager.clone(),
            KldLogger::global(),
            self.network().into(),
            amount,
            description,
            expiry.unwrap_or(DEFAULT_EXPIRY_TIME as u32),
            None,
        )
        .map_err(sign_or_creation_error)?;
        let invoice = Invoice::new(Some(label), bolt11)?;
        info!(
            "Generated invoice with payment hash {}",
            hex::encode(invoice.payment_hash.0)
        );
        self.database.persist_invoice(&invoice).await?;
        Ok(invoice)
    }

    async fn list_invoices(&self, label: Option<String>) -> Result<Vec<Invoice>> {
        self.database.fetch_invoices(label).await
    }

    async fn pay_invoice(&self, invoice: Invoice, label: Option<String>) -> Result<Payment> {
        let payment = Payment::of_invoice_outbound(&invoice, label);

        let route_params = RouteParameters {
            payment_params: PaymentParameters::from_node_id(invoice.payee_pub_key, 40),
            final_value_msat: invoice.amount.context("amount missing from invoice")?,
            // TODO: configurable, when opening a channel or starting kld
            max_total_routing_fee_msat: None,
        };
        self.channel_manager
            .send_payment(
                payment.hash.context("expected payment hash")?,
                RecipientOnionFields::secret_only(*invoice.bolt11.payment_secret()),
                payment.id,
                route_params,
                channelmanager::Retry::Timeout(Duration::from_secs(60)),
            )
            .map_err(retryable_send_failure)?;
        info!(
            "Initiated payment of invoice with hash {}",
            hex::encode(invoice.payment_hash.0)
        );
        self.database.persist_invoice(&invoice).await?;
        self.database.persist_payment(&payment).await?;
        let receiver = self
            .async_api_requests
            .payments
            .insert(payment.id, payment)
            .await;
        let payment = receiver.await??;
        self.database.persist_payment(&payment).await?;
        Ok(payment)
    }

    async fn keysend_payment(&self, payee: NodeId, amount: MillisatAmount) -> Result<Payment> {
        let payment_id = Payment::new_id();
        let inflight_htlcs = self.channel_manager.compute_inflight_htlcs();
        let route_params = RouteParameters {
            payment_params: PaymentParameters::for_keysend(payee.as_pubkey()?, 40, false),
            final_value_msat: amount,
            // TODO: configurable, when opening a channel or starting kld
            max_total_routing_fee_msat: None,
        };
        let route = self
            .router
            .find_route(&self.identity_pubkey(), &route_params, None, inflight_htlcs)
            .map_err(lightning_error)?;
        match self.channel_manager.send_spontaneous_payment(
            &route,
            None,
            RecipientOnionFields::spontaneous_empty(),
            payment_id,
        ) {
            Ok(_hash) => (),
            Err(e) => {
                match &e {
                    PaymentSendFailure::PartialFailure {
                        results,
                        failed_paths_retry: _,
                        payment_id: _,
                    } => {
                        // Monitor updates are persisted async so continue if MonitorUpdateInProgress is the only "error" we get.
                        if !results.iter().all(|result| {
                            result.is_ok()
                                || result
                                    .as_ref()
                                    .is_err_and(|f| matches!(f, APIError::MonitorUpdateInProgress))
                        }) {
                            return Err(payment_send_failure(e));
                        }
                    }
                    _ => return Err(payment_send_failure(e)),
                };
            }
        };
        let payment = Payment::spontaneous_outbound(payment_id, amount);
        info!(
            "Initiated keysend payment with id {}",
            hex::encode(payment_id.0)
        );
        self.database.persist_payment(&payment).await?;
        let receiver = self
            .async_api_requests
            .payments
            .insert(payment_id, payment)
            .await;
        let payment = receiver.await??;
        self.database.persist_payment(&payment).await?;
        Ok(payment)
    }

    async fn list_payments(
        &self,
        invoice: Option<Invoice>,
        direction: Option<PaymentDirection>,
    ) -> Result<Vec<Payment>> {
        self.database
            .fetch_payments(invoice.map(|i| i.payment_hash), direction)
            .await
    }

    async fn estimated_channel_liquidity_range(
        &self,
        scid: u64,
        target: &NodeId,
    ) -> Result<Option<(u64, u64)>> {
        Ok(self
            .scorer
            .try_read()
            .map_err(|e| anyhow!("failed to acquire lock on scorer {}", e))?
            .estimated_channel_liquidity_range(scid, target))
    }

    async fn fetch_total_forwards(&self) -> Result<TotalForwards> {
        self.database.fetch_total_forwards().await
    }

    async fn fetch_forwards(&self, status: Option<ForwardStatus>) -> Result<Vec<Forward>> {
        self.database.fetch_forwards(status).await
    }

    async fn channel_history(&self) -> Result<Vec<ChannelRecord>> {
        self.database.fetch_channel_history().await
    }

    async fn scorer(&self) -> Result<Vec<u8>> {
        self.database.fetch_scorer_binary().await
    }

    async fn update_channels(&self, channels: &[ChannelDetails]) {
        for channel in channels {
            if let Err(e) = self.database.persist_channel(channel).await {
                // This failure should not cause issues, the channel detail update will be retried later,
                // triggered on the next event, so we do not retry and only log the error but not raise it here.
                log_error(&e);
            }
        }
    }
}

pub(crate) struct AsyncAPIRequests {
    pub funding_transactions: AsyncSenders<u64, FeeRate, Result<Transaction>>,
    pub payments: AsyncSenders<PaymentId, Payment, Result<Payment>>,
}

impl AsyncAPIRequests {
    fn new() -> AsyncAPIRequests {
        AsyncAPIRequests {
            funding_transactions: AsyncSenders::new(),
            payments: AsyncSenders::new(),
        }
    }
}

pub(crate) struct AsyncSenders<K, V, RV> {
    senders: RwLock<HashMap<K, (V, Sender<RV>)>>,
}

impl<K: Eq + std::hash::Hash, V: Clone, RV> AsyncSenders<K, V, RV> {
    fn new() -> AsyncSenders<K, V, RV> {
        AsyncSenders {
            senders: RwLock::new(HashMap::new()),
        }
    }

    async fn insert(&self, k: K, v: V) -> Receiver<RV> {
        let (tx, rx) = oneshot::channel::<RV>();
        self.senders.write().await.insert(k, (v, tx));
        rx
    }

    pub async fn get(&self, k: &K) -> Option<(V, impl FnOnce(RV))> {
        if let Some((v, tx)) = self.senders.write().await.remove(k) {
            let respond = |rv: RV| {
                if tx.send(rv).is_err() {
                    warn!("Receiver dropped");
                }
            };
            return Some((v, respond));
        }
        None
    }

    pub async fn respond(&self, k: &K, rv: RV) {
        if let Some((_, tx)) = self.senders.write().await.remove(k) {
            if tx.send(rv).is_err() {
                warn!("Receiver dropped");
            }
        }
    }
}

pub struct Controller {
    settings: Arc<Settings>,
    database: Arc<LdkDatabase>,
    bitcoind_client: Arc<BitcoindClient>,
    channel_manager: Arc<ChannelManager>,
    peer_manager: Arc<PeerManager>,
    keys_manager: Arc<KeysManager>,
    network_graph: Arc<NetworkGraph>,
    router: Arc<KldRouter>,
    scorer: Arc<std::sync::RwLock<Scorer>>,
    wallet: Arc<Wallet<WalletDatabase, BitcoindClient>>,
    async_api_requests: Arc<AsyncAPIRequests>,
}

impl Controller {
    pub fn stop(&self) {
        // Disconnect our peers and stop accepting new connections. This ensures we don't continue
        // updating our channel data after we've stopped the background processor.
        self.peer_manager.disconnect_all_peers();
    }

    pub async fn start_ldk(
        settings: Arc<Settings>,
        durable_connection: Arc<DurableConnection>,
        bitcoind_client: Arc<BitcoindClient>,
        wallet: Arc<Wallet<WalletDatabase, BitcoindClient>>,
        key_generator: &KeyGenerator,
        quit_signal: Shared<impl Future<Output = ()> + Send + 'static>,
        probe_metrics: (
            &'static OnceLock<IntCounter>,
            &'static OnceLock<IntCounter>,
            &'static OnceLock<IntCounter>,
        ),
    ) -> Result<Controller> {
        let database = Arc::new(LdkDatabase::new(
            settings.clone(),
            durable_connection.clone(),
        ));

        // BitcoindClient implements the FeeEstimator trait, so it'll act as our fee estimator.
        let fee_estimator = bitcoind_client.clone();

        // BitcoindClient implements the BroadcasterInterface trait, so it'll act as our transaction broadcaster.
        let broadcaster = bitcoind_client.clone();

        let network = settings.bitcoin_network;

        let chain_monitor: Arc<ChainMonitor> = Arc::new(ChainMonitor::new(
            None,
            broadcaster.clone(),
            KldLogger::global(),
            fee_estimator.clone(),
            database.clone(),
        ));
        database.set_chain_monitor(chain_monitor.clone());

        let is_first_start = database
            .is_first_start()
            .await
            .context("could not check if database has been initialized")?;
        // Initialize the KeysManager
        // The key seed that we use to derive the node privkey (that corresponds to the node pubkey) and
        // other secret key material.
        let current_time = SystemTime::now()
            .duration_since(SystemTime::UNIX_EPOCH)
            .unwrap();
        let keys_manager = Arc::new(KeysManager::new(
            &key_generator.lightning_seed(),
            current_time.as_secs(),
            current_time.subsec_nanos(),
        ));

        let network_graph = Arc::new(
            database
                .fetch_graph()
                .await
                .context("Could not query network graph from database")?
                .unwrap_or_else(|| NetworkGraph::new(network, KldLogger::global())),
        );
        let scorer = Arc::new(std::sync::RwLock::new(
            database
                .fetch_scorer(
                    ProbabilisticScoringDecayParameters::default(),
                    network_graph.clone(),
                )
                .await?
                .map(|s| s.0)
                .unwrap_or_else(|| {
                    ProbabilisticScorer::new(
                        ProbabilisticScoringDecayParameters::default(),
                        network_graph.clone(),
                        KldLogger::global(),
                    )
                }),
        ));
        let random_seed_bytes: [u8; 32] = random();
        let router = Arc::new(DefaultRouter::new(
            network_graph.clone(),
            KldLogger::global(),
            random_seed_bytes,
            scorer.clone(),
            ProbabilisticScoringFeeParameters::default(),
        ));

        let mut channel_monitors = database
            .fetch_channel_monitors(keys_manager.as_ref())
            .await?;
        let mut user_config = UserConfig::default();
        user_config
            .channel_handshake_limits
            .force_announced_channel_preference = false;
        user_config.channel_handshake_config.announced_channel = true;
        user_config.channel_handshake_config.our_max_accepted_htlcs = 200;
        user_config
            .channel_handshake_config
            .max_inbound_htlc_value_in_flight_percent_of_channel = 100;
        user_config.channel_handshake_limits.max_funding_satoshis = u64::MAX;
        user_config
            .channel_handshake_limits
            .force_announced_channel_preference = false;
        user_config.accept_intercept_htlcs = true;

        let getinfo_resp = bitcoind_client.get_blockchain_info().await?;
        let chain_params = ChainParameters {
            network,
            best_block: BestBlock::new(getinfo_resp.best_block_hash, getinfo_resp.blocks as u32),
        };
        let (channel_manager_blockhash, channel_manager) = {
            if is_first_start {
                let new_channel_manager = channelmanager::ChannelManager::new(
                    fee_estimator.clone(),
                    chain_monitor.clone(),
                    broadcaster.clone(),
                    router.clone(),
                    KldLogger::global(),
                    keys_manager.clone(),
                    keys_manager.clone(),
                    keys_manager.clone(),
                    user_config,
                    chain_params,
                    0,
                );
                (getinfo_resp.best_block_hash, new_channel_manager)
            } else {
                let channel_monitor_mut_refs =
                    channel_monitors.iter_mut().map(|(_, cm)| cm).collect();
                let read_args = ChannelManagerReadArgs::new(
                    keys_manager.clone(),
                    keys_manager.clone(),
                    keys_manager.clone(),
                    fee_estimator.clone(),
                    chain_monitor.clone(),
                    broadcaster.clone(),
                    router.clone(),
                    KldLogger::global(),
                    user_config,
                    channel_monitor_mut_refs,
                );
                database
                    .fetch_channel_manager(read_args)
                    .await
                    .context("failed to query channel manager from database")?
            }
        };
        let channel_manager: Arc<ChannelManager> = Arc::new(channel_manager);

        let liquidity_manager = LiquidityManager::new(
            keys_manager.clone(),
            channel_manager.clone(),
            None,
            Some(chain_params),
            Some(LiquidityServiceConfig {
                lsps2_service_config: Some(LSPS2ServiceConfig {
                    promise_secret: key_generator.promise_seed(),
                }),
                advertise_service: false,
            }),
            None,
        );

        let gossip_sync = Arc::new_cyclic(|gossip| {
            let utxo_lookup = Arc::new(BitcoindUtxoLookup::new(
                &settings,
                bitcoind_client.clone(),
                network_graph.clone(),
                gossip.clone(),
            ));
            P2PGossipSync::new(
                network_graph.clone(),
                Some(utxo_lookup),
                KldLogger::global(),
            )
        });

        let onion_messenger: Arc<OnionMessenger> = Arc::new(OnionMessenger::new(
            keys_manager.clone(),
            keys_manager.clone(),
            KldLogger::global(),
            Arc::new(
                lightning::onion_message::messenger::DefaultMessageRouter::new(
                    network_graph.clone(),
                ),
            ),
            channel_manager.clone(),
            IgnoringMessageHandler {},
        ));
        let kuutamo_handler = Arc::new(KuutamoCustomMessageHandler { liquidity_manager });
        let ephemeral_bytes: [u8; 32] = random();
        let lightning_msg_handler = MessageHandler {
            chan_handler: channel_manager.clone(),
            route_handler: gossip_sync.clone(),
            onion_message_handler: onion_messenger,
            custom_message_handler: kuutamo_handler.clone(),
        };
        let peer_manager = Arc::new(PeerManager::new(
            lightning_msg_handler,
            current_time.as_secs().try_into().unwrap(),
            &ephemeral_bytes,
            KldLogger::global(),
            keys_manager.clone(),
        ));
        let pm_for_kuutamo_handler = peer_manager.clone();
        let process_msgs_callback = move || pm_for_kuutamo_handler.process_events();
        kuutamo_handler
            .liquidity_manager
            .set_process_msgs_callback(process_msgs_callback);
        let async_api_requests = Arc::new(AsyncAPIRequests::new());

        let event_handler = EventHandler::new(
            channel_manager.clone(),
            bitcoind_client.clone(),
            keys_manager.clone(),
            network_graph.clone(),
            wallet.clone(),
            database.clone(),
            peer_manager.clone(),
            async_api_requests.clone(),
            settings.clone(),
            kuutamo_handler.clone(),
        );
        let channel_manager_cloned = channel_manager.clone();

        tokio::spawn(async move {
            loop {
                let (result, msg_prefix) =
                    match kuutamo_handler.liquidity_manager.next_event_async().await {
                        LSPS2Service(LSPS2ServiceEvent::GetInfo {
                            request_id,
                            counterparty_node_id,
                            token,
                        }) => {
                            debug!("Response LSPS2 GetInfo to {}", counterparty_node_id);
                            let current_time = SystemTime::now()
                                .duration_since(SystemTime::UNIX_EPOCH)
                                .expect("Fail to fetch current time");
                            if token == Some("kuutamo".to_string()) {
                                // It will be happy to anyone to use this now in a small mount less than
                                // 1_000_000, when using a token "kuutamo"
                                (
                                    kuutamo_handler
                                        .liquidity_manager
                                        .lsps2_service_handler()
                                        .expect("lsps2 handler should be set")
                                        .opening_fee_params_generated(
                                            &counterparty_node_id,
                                            request_id,
                                            vec![RawOpeningFeeParams {
                                                min_fee_msat: 0,
                                                proportional: 0,
                                                valid_until: DateTime::from_timestamp(
                                                    current_time.as_secs() as i64 + 600,
                                                    0,
                                                )
                                                .unwrap_or_default(),
                                                min_lifetime: u32::MAX,
                                                max_client_to_self_delay: 3600,
                                                min_payment_size_msat: 0,
                                                max_payment_size_msat: 1_000_001,
                                            }],
                                        ),
                                    Some("Opening Generated Fee with kuutamo token"),
                                )
                            } else {
                                // A bad token here
                                (
                                    kuutamo_handler
                                        .liquidity_manager
                                        .lsps2_service_handler()
                                        .expect("lsps handler is not proper set")
                                        .invalid_token_provided(&counterparty_node_id, request_id),
                                    Some("Opening Generated Fee without kuutamo token"),
                                )
                            }
                        }
                        LSPS2Service(LSPS2ServiceEvent::BuyRequest {
                            request_id,
                            counterparty_node_id,
                            opening_fee_params: _,
                            payment_size_msat,
                        }) => {
                            debug!("Response LSPS2 GetInfo to {}", counterparty_node_id);
                            if payment_size_msat <= Some(1_000_001) {
                                let intercept_scid = channel_manager_cloned.get_intercept_scid();
                                // Based on Bolt#11 we use 9 for cltv_expiry_delta
                                let cltv_expiry_delta = 9;
                                let client_trusts_lsp = true;
                                // The JIT channel will use the user channel id after than 9223372036854775808
                                let user_channel_id =
                                    (random::<u64>() / 2 + 9223372036854775808) as u128;

                                (
                                    kuutamo_handler
                                        .liquidity_manager
                                        .lsps2_service_handler()
                                        .expect("lsps2 handler should be set")
                                        .invoice_parameters_generated(
                                            &counterparty_node_id,
                                            request_id,
                                            intercept_scid,
                                            cltv_expiry_delta,
                                            client_trusts_lsp,
                                            user_channel_id,
                                        ),
                                    Some("Generate Invoice Parameters"),
                                )
                            } else {
                                // Swallow the request because the payment is higher than
                                // expectation
                                error!("Generate Invoice with too big payment");
                                (Ok(()), None)
                            }
                        }
                        _ => (Ok(()), None),
                    };

                if let Some(prefix) = msg_prefix {
                    if let Err(e) = result {
                        error!("{} Error: {:?}", prefix, e);
                    } else {
                        info!("{} Done", prefix);
                    }
                }
            }
        });

        if settings.probe_interval > 0 && settings.probe_amt_msat > 0 {
            info!(
                "Start probing with {} every {} secs",
                settings.probe_amt_msat, settings.probe_interval
            );
            let probing_cm = channel_manager.clone();
            let probing_graph = network_graph.clone();
            let probing_scorer = scorer.clone();
            let interval = settings.probe_interval;
            let amt_msat = settings.probe_amt_msat;
            let targets = settings.probe_targets.clone();
            let shutdown_graceful_sec = settings.shutdown_graceful_sec;
            let probe_quit_signal = quit_signal.clone();
            if targets.is_empty() {
                // If no probe target is specified, we will do random probe
                tokio::spawn(async move {
                    let mut interval_timer = tokio::time::interval(Duration::from_secs(interval));
                    interval_timer.set_missed_tick_behavior(tokio::time::MissedTickBehavior::Delay);
                    loop {
                        interval_timer.tick().await;
                        let quit = probe_quit_signal.clone();
                        let rcpt = {
                            let lck = probing_graph.read_only();
                            if lck.nodes().is_empty() {
                                return;
                            }
                            let mut it = lck
                                .nodes()
                                .unordered_iter()
                                .skip(::rand::random::<usize>() % lck.nodes().len());
                            it.next().map(|n| *n.0)
                        };
                        if let Some(rcpt) = rcpt {
                            if let Ok(pk) =
                                bitcoin::secp256k1::PublicKey::from_slice(rcpt.as_slice())
                            {
                                tokio::select! (
                                    _ = quit => {
                                        tokio::time::sleep(Duration::from_secs(shutdown_graceful_sec)).await;
                                        break;
                                    },
                                    _ = send_probe(
                                        &probing_cm,
                                        &pk,
                                        &probing_graph,
                                        amt_msat,
                                        &probing_scorer,
                                        interval,
                                        probe_metrics,
                                    ) => {}
                                );
                            }
                        }
                    }
                });
            } else {
                tokio::spawn(async move {
                    let mut interval_timer = tokio::time::interval(Duration::from_secs(interval));
                    interval_timer.set_missed_tick_behavior(tokio::time::MissedTickBehavior::Delay);
                    for pk in targets.iter().cycle() {
                        interval_timer.tick().await;
                        let quit = probe_quit_signal.clone();
                        tokio::select! (
                            _ = quit => {
                                tokio::time::sleep(Duration::from_secs(shutdown_graceful_sec)).await;
                                break;
                            },
                            _ = send_probe(
                                &probing_cm,
                                pk,
                                &probing_graph,
                                amt_msat,
                                &probing_scorer,
                                interval,
                                probe_metrics,
                            ) => {}
                        );
                    }
                });
            }
        }

        let bitcoind_client_clone = bitcoind_client.clone();
        let peer_manager_clone = peer_manager.clone();
        let wallet_clone = wallet.clone();
        let peer_port = settings.peer_port;
        let database_clone = database.clone();
        let channel_manager_clone = channel_manager.clone();
        let chain_monitor_clone = chain_monitor.clone();
        let scorer_clone = scorer.clone();
        let settings_clone = settings.clone();
        tokio::spawn(async move {
            bitcoind_client_clone
                .wait_for_blockchain_synchronisation()
                .await;
            if let Err(e) = Controller::sync_to_chain_tip(
                network,
                bitcoind_client_clone,
                chain_monitor,
                channel_manager_blockhash,
                channel_manager_clone.clone(),
                channel_monitors,
            )
            .await
            {
                error!("Fatal error {}", e.into_inner());
                std::process::exit(1)
            };

            wallet_clone.keep_sync_with_chain();
            if let Err(e) = peer_manager_clone.listen(peer_port).await {
                error!("could not listen on peer port: {e}");
                std::process::exit(1)
            };
            peer_manager_clone.keep_channel_peers_connected(
                database_clone.clone(),
                channel_manager_clone.clone(),
            );

            // hourly broadcast our node to the network
            let peer_manager_clone2 = peer_manager_clone.clone();
            let settings_clone2 = settings_clone.clone();
            tokio::spawn(async move {
                info!("broadcast node");
                peer_manager_clone2.broadcast_node_announcement_from_settings(settings_clone2);
                tokio::time::sleep(Duration::from_secs(60)).await;
            });

            tokio::spawn(async move {
                if let Err(e) = process_events_async(
                    database_clone.clone(),
                    |event| async {
                        if let Err(e) = event_handler.handle_event_async(event).await {
                            log_error(&e)
                        }
                    },
                    chain_monitor_clone,
                    channel_manager_clone,
                    GossipSync::p2p(gossip_sync),
                    peer_manager_clone,
                    KldLogger::global(),
                    Some(scorer_clone),
                    |t| {
                        let quit_signal = quit_signal.clone();
                        Box::pin(async move {
                            tokio::select! {
                                _ = tokio::time::sleep(t) => false,
                                _ = quit_signal => true,
                            }
                        })
                    },
                    false,
                    || {
                        Some(
                            SystemTime::now()
                                .duration_since(SystemTime::UNIX_EPOCH)
                                .unwrap_or_default(),
                        )
                    },
                )
                .await
                {
                    error!("Fatal error {}", e);
                    std::process::exit(1)
                };
            });
        });

        Ok(Controller {
            settings,
            database,
            bitcoind_client,
            channel_manager,
            peer_manager,
            keys_manager,
            network_graph,
            router,
            scorer,
            wallet,
            async_api_requests,
        })
    }

    async fn sync_to_chain_tip(
        network: Network,
        bitcoind_client: Arc<BitcoindClient>,
        chain_monitor: Arc<ChainMonitor>,
        channel_manager_blockhash: BlockHash,
        channel_manager: Arc<ChannelManager>,
        channel_monitors: Vec<(BlockHash, ChannelMonitor<InMemorySigner>)>,
    ) -> BlockSourceResult<()> {
        info!(
            "Syncing ChannelManager and {} ChannelMonitors to chain tip",
            channel_monitors.len()
        );
        let mut chain_listener_channel_monitors = Vec::new();
        let mut cache = UnboundedCache::new();

        let mut chain_listeners = vec![(
            channel_manager_blockhash,
            channel_manager.as_ref() as &(dyn chain::Listen + Send + Sync),
        )];

        for (blockhash, channel_monitor) in channel_monitors {
            let outpoint = channel_monitor.get_funding_txo().0;
            chain_listener_channel_monitors.push((
                blockhash,
                (
                    channel_monitor,
                    bitcoind_client.clone(),
                    bitcoind_client.clone(),
                    KldLogger::global(),
                ),
                outpoint,
            ));
        }

        for monitor_listener_info in chain_listener_channel_monitors.iter_mut() {
            chain_listeners.push((
                monitor_listener_info.0,
                &monitor_listener_info.1 as &(dyn chain::Listen + Send + Sync),
            ));
        }
        let chain_tip = init::synchronize_listeners(
            bitcoind_client.clone(),
            network,
            &mut cache,
            chain_listeners,
        )
        .await?;
        info!("Chain listeners synchronised. Registering ChannelMonitors with ChainMonitor");
        for (_, (channel_monitor, _, _, _), funding_outpoint) in chain_listener_channel_monitors {
            if let Err(e) = chain_monitor.watch_channel(funding_outpoint, channel_monitor) {
                warn!("Could not sync info for channel: {e:?}");
            }
            info!("Registered {}", funding_outpoint.txid);
        }

        // Connect and Disconnect Blocks
        tokio::spawn(async move {
            let chain_poller = poll::ChainPoller::new(bitcoind_client, network);
            let chain_listener = (chain_monitor, channel_manager);
            let mut spv_client =
                SpvClient::new(chain_tip, chain_poller, &mut cache, &chain_listener);
            loop {
                if let Err(e) = spv_client.poll_best_tip().await {
                    error!("{}", e.into_inner())
                }
                tokio::time::sleep(Duration::from_secs(1)).await;
            }
        });

        Ok(())
    }
}

impl Drop for Controller {
    fn drop(&mut self) {
        self.stop()
    }
}

async fn send_probe(
    channel_manager: &ChannelManager,
    recipient: &PublicKey,
    graph: &NetworkGraph,
    amt_msat: u64,
    scorer: &std::sync::RwLock<Scorer>,
    interval: u64,
    probe_metrics: (
        &OnceLock<IntCounter>,
        &OnceLock<IntCounter>,
        &OnceLock<IntCounter>,
    ),
) {
    let chans = channel_manager.list_usable_channels();
    let chan_refs = chans.iter().collect::<Vec<_>>();
    let mut payment_params = PaymentParameters::from_node_id(*recipient, 144);
    payment_params.max_path_count = 1;
    let in_flight_htlcs = channel_manager.compute_inflight_htlcs();
    let mut scorer = match scorer.write() {
        Ok(scorer) => scorer,
        Err(e) => {
            trace!("Can not fetch write lock of scorer: {e:?}");
            return;
        }
    };
    let inflight_scorer = ScorerAccountingForInFlightHtlcs::new(&scorer, &in_flight_htlcs);
    let score_params: ProbabilisticScoringFeeParameters = Default::default();
    let route_res = lightning::routing::router::find_route(
        &channel_manager.get_our_node_id(),
        &RouteParameters::from_payment_params_and_value(payment_params, amt_msat),
        graph,
        Some(&chan_refs),
        KldLogger::global(),
        &inflight_scorer,
        &score_params,
        &[32; 32],
    );
    if let Ok(route) = route_res {
        for path in route.paths {
            trace!("Probe {amt_msat:} on {path:?}");
            if let Some(g) = probe_metrics.0.get() {
                g.inc()
            }
            let send_time = SystemTime::now();
            match channel_manager.send_probe(path.clone()) {
                Ok(_) => {
                    debug!("Probe success with {amt_msat:} on {path:?}");
                    if let Some(g) = probe_metrics.1.get() {
                        g.inc()
                    }
                    if let Ok(duration) = send_time.elapsed() {
                        scorer.probe_successful(&path, duration);
                    }
                }
                Err(_) => {
                    trace!("Probe failed with {amt_msat:} on {path:?}");
                    let Path {
                        mut hops,
                        blinded_tail,
                    } = path.clone();
                    if let Some(g) = probe_metrics.2.get() {
                        g.inc()
                    }
                    while let Some(pop_hop) = hops.pop() {
                        sleep(Duration::from_secs(interval));
                        let send_time = SystemTime::now();
                        if !hops.is_empty()
                            && channel_manager
                                .send_probe(Path {
                                    hops: hops.clone(),
                                    blinded_tail: blinded_tail.clone(),
                                })
                                .is_ok()
                        {
                            debug!("Probe failed with channel id: {}", pop_hop.short_channel_id);
                            hops.push(pop_hop.clone());
                            if let Ok(duration) = send_time.elapsed() {
                                scorer.probe_failed(
                                    &Path {
                                        hops,
                                        blinded_tail: blinded_tail.clone(),
                                    },
                                    pop_hop.short_channel_id,
                                    duration,
                                );
                            }
                            break;
                        }
                    }
                }
            }
        }
    } else {
        trace!("Can not probe, because no route to {recipient:?}");
    }
}

'''
'''--- kld/src/ldk/event_handler.rs ---
use std::sync::Arc;
use std::time::{Duration, SystemTime};

use anyhow::{anyhow, bail, Context, Result};

use bitcoin::blockdata::locktime::absolute::LockTime;
use bitcoin::secp256k1::Secp256k1;

use crate::bitcoind::bitcoind_interface::BitcoindInterface;
use crate::database::forward::Forward;
use crate::database::payment::Payment;
use crate::database::{LdkDatabase, WalletDatabase};
use crate::ldk::peer_manager::KuutamoPeerManger;
use crate::log_error;
use crate::settings::Settings;
use lightning::chain::chaininterface::{BroadcasterInterface, ConfirmationTarget, FeeEstimator};
use lightning::events::{Event, PathFailure, PaymentPurpose};
use lightning::ln::ChannelId;
use lightning::routing::gossip::NodeId;
use lightning::sign::{KeysManager, SpendableOutputDescriptor};
use log::{error, info, trace, warn};
use rand::{thread_rng, Rng};
use tokio::runtime::Handle;

use crate::bitcoind::BitcoindClient;
use crate::ldk::{htlc_destination_to_string, ldk_error};
use crate::wallet::{Wallet, WalletInterface};

use super::controller::AsyncAPIRequests;
use super::peer_manager::PeerManager;
use super::{ChannelManager, KuutamoCustomMessageHandler, NetworkGraph};

pub(crate) struct EventHandler {
    channel_manager: Arc<ChannelManager>,
    bitcoind_client: Arc<BitcoindClient>,
    keys_manager: Arc<KeysManager>,
    network_graph: Arc<NetworkGraph>,
    wallet: Arc<Wallet<WalletDatabase, BitcoindClient>>,
    ldk_database: Arc<LdkDatabase>,
    peer_manager: Arc<PeerManager>,
    async_api_requests: Arc<AsyncAPIRequests>,
    settings: Arc<Settings>,
    runtime_handle: Handle,
    kuutamo_handler: Arc<KuutamoCustomMessageHandler>,
}

impl EventHandler {
    #[allow(clippy::too_many_arguments)]
    pub fn new(
        channel_manager: Arc<ChannelManager>,
        bitcoind_client: Arc<BitcoindClient>,
        keys_manager: Arc<KeysManager>,
        network_graph: Arc<NetworkGraph>,
        wallet: Arc<Wallet<WalletDatabase, BitcoindClient>>,
        database: Arc<LdkDatabase>,
        peer_manager: Arc<PeerManager>,
        async_api_requests: Arc<AsyncAPIRequests>,
        settings: Arc<Settings>,
        kuutamo_handler: Arc<KuutamoCustomMessageHandler>,
    ) -> EventHandler {
        EventHandler {
            channel_manager,
            bitcoind_client,
            keys_manager,
            network_graph,
            wallet,
            ldk_database: database,
            peer_manager,
            async_api_requests,
            settings,
            runtime_handle: Handle::current(),
            kuutamo_handler,
        }
    }
}

impl EventHandler {
    pub async fn handle_event_async(&self, event: lightning::events::Event) -> Result<()> {
        match event {
            Event::FundingGenerationReady {
                temporary_channel_id,
                counterparty_node_id,
                channel_value_satoshis,
                output_script,
                user_channel_id,
            } => {
                let (fee_rate, respond) = self
                    .async_api_requests
                    .funding_transactions
                    .get(&(user_channel_id as u64))
                    .await
                    .context(format!(
                        "Can't find funding transaction for user_channel_id {user_channel_id}"
                    ))?;

                let funding_tx =
                    match self
                        .wallet
                        .fund_tx(&output_script, &channel_value_satoshis, fee_rate)
                    {
                        Ok(tx) => tx,
                        Err(e) => {
                            respond(Err(anyhow!("Failed funding transaction: {e}")));
                            return Err(anyhow!("Failed funding transaction: {e}"));
                        }
                    };

                // Give the funding transaction back to LDK for opening the channel.
                if let Err(e) = self
                    .channel_manager
                    .funding_transaction_generated(
                        &temporary_channel_id,
                        &counterparty_node_id,
                        funding_tx.clone(),
                    )
                    .map_err(ldk_error)
                {
                    respond(Err(anyhow!("Failed opening channel: {e}")));
                    bail!(e);
                }
                info!("EVENT: Channel with user channel id {user_channel_id} has been funded");
                if let Err(e) = self
                    .ldk_database
                    .update_initializing_channel(
                        &temporary_channel_id,
                        None,
                        Some(format!(
                            "Channel with user channel id {user_channel_id} has been funded"
                        )),
                    )
                    .await
                {
                    warn!("Fail to update initial channel funded status: {e}");
                }
                respond(Ok(funding_tx));
            }
            Event::ChannelPending {
                channel_id,
                user_channel_id,
                former_temporary_channel_id,
                counterparty_node_id,
                funding_txo,
            } => {
                info!(
                    "EVENT: Channel {} - {user_channel_id} with counterparty {counterparty_node_id} is pending. OutPoint: {funding_txo}",
                    hex::encode(channel_id.0),
                );
                if let Some(former_temporary_channel_id) = former_temporary_channel_id {
                    self.ldk_database
                        .update_initializing_channel(
                            &former_temporary_channel_id,
                            Some((&channel_id, funding_txo.vout)),
                            None::<&str>,
                        )
                        .await?;
                }

                // Insert ChannelDetails if we can list, else just create a channel record.
                if let Some(detail) = self
                    .channel_manager
                    .list_channels()
                    .iter()
                    .find(|c| c.channel_id == channel_id)
                {
                    self.ldk_database.persist_channel(detail).await?;
                } else {
                    self.ldk_database
                        .create_channel(&channel_id, true, &counterparty_node_id)
                        .await?;
                }
            }
            Event::ChannelReady {
                channel_id,
                user_channel_id,
                counterparty_node_id,
                channel_type: _,
            } => {
                // JIT Channels
                if user_channel_id > 9223372036854775808 {
                    if let Err(e) = self
                        .kuutamo_handler
                        .liquidity_manager
                        .lsps2_service_handler()
                        .expect("lsps2 handler should be set")
                        .channel_ready(user_channel_id, &channel_id, &counterparty_node_id)
                    {
                        error!("JIT Channel ready fail: {e:?}");
                    }
                }

                // LSPS2ServiceHandler::channel_ready
                info!(
                    "EVENT: Channel {} - {user_channel_id} with counterparty {counterparty_node_id} is ready to use.",
                    hex::encode(channel_id.0),
                );
                if let Some(channel_details) = self
                    .channel_manager
                    .list_channels()
                    .iter()
                    .find(|c| c.channel_id == channel_id)
                {
                    self.ldk_database.persist_channel(channel_details).await?;
                } else {
                    self.ldk_database
                        .close_channel(
                            &channel_id,
                            "Channel detail missing when receiving ChannelReady",
                        )
                        .await?;
                }
                info!("Broadcasting node announcement message");
                self.peer_manager
                    .broadcast_node_announcement_from_settings(self.settings.clone());
            }
            Event::ChannelClosed {
                channel_id,
                reason,
                user_channel_id,
                ..
            } => {
                info!("EVENT: Channel {}: {reason}.", hex::encode(channel_id.0));
                self.async_api_requests
                    .funding_transactions
                    .respond(
                        &(user_channel_id as u64),
                        Err(anyhow!("Channel closed due to {reason}")),
                    )
                    .await;
                self.ldk_database
                    .close_channel(&channel_id, format!("{reason}"))
                    .await?;
            }
            Event::DiscardFunding {
                channel_id,
                transaction,
            } => {
                info!(
                    "EVENT: Funding discarded for channel: {}, txid: {}",
                    hex::encode(channel_id.0),
                    transaction.txid()
                );
                if let Err(e) = self
                    .ldk_database
                    .close_channel(
                        &channel_id,
                        format!(
                            "Funding discarded for channel, txid: {}",
                            transaction.txid()
                        ),
                    )
                    .await
                {
                    error!("Fail to close channel which funding is discarded: {e}");
                }
            }
            Event::OpenChannelRequest { .. } => {
                unreachable!(
                    "This event will not fire as we do not manually accept inbound channels."
                )
            }
            Event::PaymentClaimable {
                payment_hash,
                purpose,
                amount_msat,
                receiver_node_id: _,
                via_channel_id,
                via_user_channel_id: _,
                onion_fields: _,
                claim_deadline,
                ..
            } => {
                info!(
                    "EVENT: Payment claimable with hash {} of {} millisatoshis {} {}",
                    hex::encode(payment_hash.0),
                    amount_msat,
                    if let Some(channel_id) = via_channel_id {
                        format!("via channel ID {} ", hex::encode(channel_id.0))
                    } else {
                        String::new()
                    },
                    if let Some(deadline) = claim_deadline {
                        format!(
                            "with deadline {:?}",
                            SystemTime::UNIX_EPOCH + Duration::from_secs(deadline as u64)
                        )
                    } else {
                        String::new()
                    }
                );
                match purpose {
                    PaymentPurpose::InvoicePayment {
                        payment_preimage, ..
                    } => {
                        if let Some(payment_preimage) = payment_preimage {
                            self.channel_manager.claim_funds(payment_preimage);
                        }
                    }
                    PaymentPurpose::SpontaneousPayment(preimage) => {
                        self.channel_manager.claim_funds(preimage);
                    }
                };
            }
            Event::PaymentClaimed {
                payment_hash,
                purpose,
                amount_msat,
                receiver_node_id: _,
                ..
            } => {
                info!(
                    "EVENT: Payment claimed with hash {} of {} millisats",
                    hex::encode(payment_hash.0),
                    amount_msat,
                );
                let payment = match purpose {
                    PaymentPurpose::InvoicePayment {
                        payment_preimage,
                        payment_secret,
                    } => Payment::of_invoice_inbound(
                        payment_hash,
                        payment_preimage,
                        payment_secret,
                        amount_msat,
                    ),
                    PaymentPurpose::SpontaneousPayment(preimage) => {
                        Payment::spontaneous_inbound(payment_hash, preimage, amount_msat)
                    }
                };
                self.ldk_database
                    .persist_payment(&payment)
                    .await
                    .context("Failed to persist payment")?;
            }
            Event::PaymentSent {
                payment_id,
                payment_preimage,
                payment_hash,
                fee_paid_msat,
            } => {
                info!(
                    "EVENT: Payment with hash {}{} sent successfully{}",
                    hex::encode(payment_hash.0),
                    if let Some(id) = payment_id {
                        format!(" and ID {}", hex::encode(id.0))
                    } else {
                        "".to_string()
                    },
                    if let Some(fee) = fee_paid_msat {
                        format!(" with fee {fee} msat")
                    } else {
                        "".to_string()
                    },
                );
                let payment_id = payment_id.context(format!(
                    "Failed to update payment with hash {}",
                    hex::encode(payment_hash.0)
                ))?;
                let (mut payment, respond) = self
                    .async_api_requests
                    .payments
                    .get(&payment_id)
                    .await
                    .context(format!(
                        "Can't find payment for {}",
                        hex::encode(payment_id.0)
                    ))?;
                payment.succeeded(payment_hash, payment_preimage, fee_paid_msat);
                respond(Ok(payment));
            }
            Event::PaymentPathSuccessful {
                payment_id,
                payment_hash,
                path,
            } => {
                info!(
                    "EVENT: Payment path with {} hops successful for payment with ID {}{}",
                    path.hops.len(),
                    hex::encode(payment_id.0),
                    payment_hash
                        .map(|h| format!(" and hash {}", hex::encode(h.0)))
                        .unwrap_or_default()
                );
            }
            Event::PaymentPathFailed {
                payment_id,
                payment_hash,
                payment_failed_permanently,
                failure,
                path,
                short_channel_id,
                ..
            } => {
                match failure {
                    PathFailure::InitialSend { err } => warn!("{}", ldk_error(err)),
                    PathFailure::OnPath { network_update } => {
                        if let Some(update) = network_update {
                            self.network_graph.handle_network_update(&update);
                        }
                    }
                };
                info!(
                    "EVENT: Payment path failed for payment with hash {}{}. Payment failed {} {}. Path: {:?}",
                    hex::encode(payment_hash.0),
                    payment_id.map(|id| format!(" and ID {}", hex::encode(id.0))).unwrap_or_default(),
                    if payment_failed_permanently {
                        "permanently"
                    } else {
                        "temporarily"
                    },
                    if let Some(short_channel_id) = short_channel_id {
                        format!("along channel {}", short_channel_id)
                    } else {
                        "".to_string()
                    },
                    path
                );
            }
            Event::PaymentFailed {
                payment_id,
                payment_hash,
                reason,
            } => {
                info!(
                    "EVENT: Failed to send payment with ID {} and hash {}{}",
                    hex::encode(payment_id.0),
                    hex::encode(payment_hash.0),
                    reason
                        .map(|r| format!(" for reason {r:?}"))
                        .unwrap_or_default()
                );
                let (mut payment, respond) = self
                    .async_api_requests
                    .payments
                    .get(&payment_id)
                    .await
                    .context(format!(
                        "Can't find payment for {}",
                        hex::encode(payment_id.0)
                    ))?;
                payment.failed(reason);
                respond(Ok(payment));
            }
            Event::PaymentForwarded {
                prev_channel_id,
                next_channel_id,
                fee_earned_msat,
                claim_from_onchain_tx,
                outbound_amount_forwarded_msat,
            } => {
                if let Some(next_channel_id) = next_channel_id {
                    if let Err(e) = self
                        .kuutamo_handler
                        .liquidity_manager
                        .lsps2_service_handler()
                        .expect("lsps2 handler should be set")
                        .payment_forwarded(next_channel_id)
                    {
                        trace!("LSPS2 payment forward fail: {e:?}");
                    }
                }

                let read_only_network_graph = self.network_graph.read_only();
                let nodes = read_only_network_graph.nodes();
                let channels = self.channel_manager.list_channels();

                let node_str = |channel_id: &Option<ChannelId>| match channel_id {
                    None => String::new(),
                    Some(channel_id) => match channels.iter().find(|c| c.channel_id == *channel_id)
                    {
                        None => String::new(),
                        Some(channel) => {
                            match nodes.get(&NodeId::from_pubkey(&channel.counterparty.node_id)) {
                                None => "private node".to_string(),
                                Some(node) => match &node.announcement_info {
                                    None => "unnamed node".to_string(),
                                    Some(announcement) => {
                                        format!("node {}", announcement.alias)
                                    }
                                },
                            }
                        }
                    },
                };
                let channel_str = |channel_id: &Option<ChannelId>| {
                    channel_id
                        .map(|channel_id| format!(" with channel {}", hex::encode(channel_id.0)))
                        .unwrap_or_default()
                };
                let from_prev_str = format!(
                    " from {}{}",
                    node_str(&prev_channel_id),
                    channel_str(&prev_channel_id)
                );
                let to_next_str = format!(
                    " to {}{}",
                    node_str(&next_channel_id),
                    channel_str(&next_channel_id)
                );

                let from_onchain_str = if claim_from_onchain_tx {
                    "from onchain downstream claim"
                } else {
                    "from HTLC fulfill message"
                };
                let amount_str = if let Some(amount) = outbound_amount_forwarded_msat {
                    format!("of amount {amount}")
                } else {
                    "of unknown amount".to_string()
                };
                let fee_str = if let Some(fee_earned) = fee_earned_msat {
                    format!(" earning {fee_earned} msat")
                } else {
                    "".to_string()
                };
                let id = if let (
                    Some(inbound_channel_id),
                    Some(outbound_channel_id),
                    Some(amount),
                    Some(fee),
                ) = (
                    prev_channel_id,
                    next_channel_id,
                    outbound_amount_forwarded_msat,
                    fee_earned_msat,
                ) {
                    let forward =
                        Forward::success(inbound_channel_id, outbound_channel_id, amount, fee);
                    let id = forward.id.to_string();
                    self.persist_forward(forward);
                    format!(" with ID {id}")
                } else {
                    "".to_string()
                };
                info!(
                    "EVENT: Forwarded payment{id}{from_prev_str}{to_next_str} {amount_str},{fee_str} {from_onchain_str}",
                );
            }
            Event::ProbeSuccessful { .. } => {}
            Event::ProbeFailed { .. } => {}
            Event::HTLCHandlingFailed {
                prev_channel_id,
                failed_next_destination,
            } => {
                if let Err(e) = self
                    .kuutamo_handler
                    .liquidity_manager
                    .lsps2_service_handler()
                    .expect("lsps2 handler should be set")
                    .htlc_handling_failed(failed_next_destination.clone())
                {
                    trace!("LSPS2 htlc handling fail: {e:?}");
                };
                let forward = Forward::failure(prev_channel_id, failed_next_destination.clone());
                let id = forward.id.to_string();
                self.persist_forward(forward);
                error!(
                    "EVENT: Failed handling HTLC with ID {id} from channel {}. {}",
                    hex::encode(prev_channel_id.0),
                    htlc_destination_to_string(&failed_next_destination)
                );
            }
            Event::PendingHTLCsForwardable { time_forwardable } => {
                let forwarding_channel_manager = self.channel_manager.clone();
                let min = time_forwardable.as_millis() as u64;
                tokio::spawn(async move {
                    let millis_to_sleep = thread_rng().gen_range(min..min * 5);
                    tokio::time::sleep(Duration::from_millis(millis_to_sleep)).await;
                    forwarding_channel_manager.process_pending_htlc_forwards();
                });
            }
            Event::SpendableOutputs {
                outputs,
                channel_id,
            } => {
                for spendable_output in outputs.iter() {
                    info!("EVENT: New {:?}", spendable_output);
                    self.persist_spendable_output(spendable_output, channel_id.as_ref(), false)
                        .await;
                }
                let destination_address = self.wallet.new_internal_address()?;
                let tx_feerate = self
                    .bitcoind_client
                    .get_est_sat_per_1000_weight(ConfirmationTarget::OnChainSweep);

                let best_block_height = self.bitcoind_client.block_height().await?;
                let spending_tx = self
                    .keys_manager
                    .spend_spendable_outputs(
                        &outputs.iter().collect::<Vec<_>>()[..],
                        Vec::new(),
                        destination_address.script_pubkey(),
                        tx_feerate,
                        Some(LockTime::from_height(best_block_height as u32)?),
                        &Secp256k1::new(),
                    )
                    .map_err(|()| anyhow!("Failed to build spending transaction"))?;
                info!(
                    "Sending spendable output to {}",
                    destination_address.address
                );
                self.bitcoind_client.broadcast_transactions(&[&spending_tx]);
                for spendable_output in outputs.iter() {
                    self.persist_spendable_output(spendable_output, channel_id.as_ref(), true)
                        .await;
                }
            }
            Event::HTLCIntercepted {
                intercept_id,
                requested_next_hop_scid,
                payment_hash,
                inbound_amount_msat: _,
                expected_outbound_amount_msat,
            } => {
                if let Err(e) = self
                    .kuutamo_handler
                    .liquidity_manager
                    .lsps2_service_handler()
                    .expect("lsps2 handler should be set")
                    .htlc_intercepted(
                        requested_next_hop_scid,
                        intercept_id,
                        expected_outbound_amount_msat,
                        payment_hash,
                    )
                {
                    error!("HTLC Intercept fail: {e:?}");
                }
            }
            Event::InvoiceRequestFailed { payment_id } => {
                // XXX Handle it
                warn!("Invoice request failed, payment id: {payment_id:}");
            }
            Event::BumpTransaction(_) => unreachable!(),
            Event::ConnectionNeeded { node_id, .. } => {
                // XXX Handle it
                warn!("Need to connect to node {node_id:} for onion message");
            }
        };
        Ok(())
    }

    async fn persist_spendable_output(
        &self,
        spendable_output: &SpendableOutputDescriptor,
        channel_id: Option<&ChannelId>,
        is_spent: bool,
    ) {
        if let Err(e) = self
            .ldk_database
            .persist_spendable_output(spendable_output, channel_id, is_spent)
            .await
        {
            log_error(&e)
        }
    }

    fn persist_forward(&self, forward: Forward) {
        let database = self.ldk_database.clone();
        self.runtime_handle.spawn(async move {
            if let Err(e) = database.persist_forward(forward).await {
                log_error(&e)
            }
        });
    }
}

'''
'''--- kld/src/ldk/lightning_interface.rs ---
use anyhow::Result;
use lightning::{
    ln::{channelmanager::ChannelDetails, ChannelId},
    routing::gossip::{ChannelInfo, NodeId, NodeInfo},
    util::{config::UserConfig, indexed_map::IndexedMap},
};

use crate::{
    database::{
        forward::{Forward, ForwardStatus, TotalForwards},
        invoice::Invoice,
        payment::{Payment, PaymentDirection},
        ChannelRecord,
    },
    MillisatAmount,
};

use crate::api::payloads::FeeRate;
use crate::api::SocketAddress;
use async_trait::async_trait;
use bitcoin::{secp256k1::PublicKey, Network, Transaction, Txid};

#[async_trait]
pub trait LightningInterface: Send + Sync {
    fn alias(&self) -> String;

    fn color(&self) -> String;

    fn identity_pubkey(&self) -> PublicKey;

    async fn synced(&self) -> Result<bool>;

    fn sign(&self, message: &[u8]) -> Result<String>;

    fn network(&self) -> Network;

    fn num_active_channels(&self) -> usize;

    fn num_inactive_channels(&self) -> usize;

    fn num_pending_channels(&self) -> usize;

    fn graph_num_nodes(&self) -> usize;

    fn graph_num_channels(&self) -> usize;

    fn num_peers(&self) -> usize;

    fn wallet_balance(&self) -> u64;

    fn list_active_channels(&self) -> Vec<ChannelDetails>;

    async fn list_channels(&self) -> Result<Vec<ChannelRecord>>;

    fn set_channel_fee(
        &self,
        counterparty_node_id: &PublicKey,
        channel_id: &[ChannelId],
        forwarding_fee_proportional_millionths: Option<u32>,
        forwarding_fee_base_msat: Option<u32>,
    ) -> Result<(u32, u32)>;

    fn alias_of(&self, node_id: &PublicKey) -> Option<String>;

    fn public_addresses(&self) -> Vec<SocketAddress>;

    async fn list_peers(&self) -> Result<Vec<Peer>>;

    async fn connect_peer(
        &self,
        public_key: PublicKey,
        socket_addr: Option<SocketAddress>,
    ) -> Result<()>;

    async fn disconnect_peer(&self, public_key: PublicKey) -> Result<()>;

    async fn open_channel(
        &self,
        their_network_key: PublicKey,
        channel_value_satoshis: u64,
        push_msat: Option<u64>,
        fee_rate: Option<FeeRate>,
        override_config: Option<UserConfig>,
    ) -> Result<OpenChannelResult>;

    async fn close_channel(
        &self,
        channel_id: &ChannelId,
        counterparty_node_id: &PublicKey,
        fee_rate: Option<u32>,
    ) -> Result<()>;

    async fn force_close_channel(
        &self,
        channel_id: &ChannelId,
        counterparty_node_id: &PublicKey,
        with_broadcast: bool,
    ) -> Result<()>;

    fn get_node(&self, node_id: &NodeId) -> Option<NodeInfo>;

    fn nodes(&self) -> IndexedMap<NodeId, NodeInfo>;

    fn get_channel(&self, channel_id: u64) -> Option<ChannelInfo>;

    fn channels(&self) -> IndexedMap<u64, ChannelInfo>;

    fn user_config(&self) -> UserConfig;

    async fn pay_invoice(&self, invoice: Invoice, label: Option<String>) -> Result<Payment>;

    async fn keysend_payment(&self, payee: NodeId, amount: MillisatAmount) -> Result<Payment>;

    async fn generate_invoice(
        &self,
        label: String,
        amount: Option<u64>,
        description: String,
        expiry: Option<u32>,
    ) -> Result<Invoice>;

    async fn list_invoices(&self, label: Option<String>) -> Result<Vec<Invoice>>;

    async fn list_payments(
        &self,
        bolt11: Option<Invoice>,
        direction: Option<PaymentDirection>,
    ) -> Result<Vec<Payment>>;

    async fn estimated_channel_liquidity_range(
        &self,
        scid: u64,
        target: &NodeId,
    ) -> Result<Option<(u64, u64)>>;

    async fn fetch_forwards(&self, status: Option<ForwardStatus>) -> Result<Vec<Forward>>;

    async fn fetch_total_forwards(&self) -> Result<TotalForwards>;

    async fn channel_history(&self) -> Result<Vec<ChannelRecord>>;

    async fn scorer(&self) -> Result<Vec<u8>>;

    async fn update_channels(&self, channels: &[ChannelDetails]);
}

pub struct Peer {
    pub public_key: PublicKey,
    pub net_address: Option<SocketAddress>,
    pub status: PeerStatus,
    pub alias: String,
}

#[derive(Copy, Clone, PartialEq, Default)]
pub enum PeerStatus {
    Connected,
    #[default]
    Disconnected,
}

impl ToString for PeerStatus {
    fn to_string(&self) -> String {
        match self {
            PeerStatus::Connected => "connected",
            PeerStatus::Disconnected => "disconnected",
        }
        .to_owned()
    }
}

pub struct OpenChannelResult {
    pub transaction: Transaction,
    pub txid: Txid,
    pub channel_id: ChannelId,
}

'''
'''--- kld/src/ldk/mod.rs ---
pub mod channel_utils;
pub mod controller;
mod event_handler;
pub mod lightning_interface;
mod peer_manager;

use std::sync::{Arc, RwLock};

use crate::database::LdkDatabase;
use crate::logger::KldLogger;
use anyhow::anyhow;
use bitcoin::secp256k1::PublicKey;
use lightning::ln::peer_handler::CustomMessageHandler;
use lightning::{
    chain::{chainmonitor, Filter},
    events::HTLCDestination,
    ln::{
        channelmanager::{PaymentSendFailure, RetryableSendFailure, SimpleArcChannelManager},
        features::{InitFeatures, NodeFeatures},
        msgs::{DecodeError, LightningError},
        wire::CustomMessageReader,
    },
    onion_message::messenger::SimpleArcOnionMessenger,
    routing::{
        gossip,
        router::DefaultRouter,
        scoring::{ProbabilisticScorer, ProbabilisticScoringFeeParameters},
    },
    sign::{InMemorySigner, KeysManager},
    util::errors::APIError,
};
use lightning_invoice::SignOrCreationError;

pub use controller::Controller;
pub use lightning_interface::{LightningInterface, OpenChannelResult, Peer, PeerStatus};
use log::warn;

use crate::bitcoind::BitcoindClient;

/// The minimum feerate we are allowed to send, as specify by LDK (sats/kwu).
pub static MIN_FEERATE: u32 = 2000;

pub type NetworkGraph = gossip::NetworkGraph<Arc<KldLogger>>;

pub(crate) type ChainMonitor = chainmonitor::ChainMonitor<
    InMemorySigner,
    Arc<dyn Filter + Send + Sync>,
    Arc<BitcoindClient>,
    Arc<BitcoindClient>,
    Arc<KldLogger>,
    Arc<LdkDatabase>,
>;

pub(crate) type LiquidityManager = lightning_liquidity::LiquidityManager<
    Arc<KeysManager>,
    Arc<ChannelManager>,
    Arc<dyn Filter + Send + Sync>,
>;

pub(crate) struct KuutamoCustomMessageHandler {
    liquidity_manager: LiquidityManager,
}

impl lightning::ln::wire::CustomMessageReader for KuutamoCustomMessageHandler {
    type CustomMessage = <LiquidityManager as CustomMessageReader>::CustomMessage;
    fn read<RD: lightning::io::Read>(
        &self,
        message_type: u16,
        buffer: &mut RD,
    ) -> Result<Option<Self::CustomMessage>, lightning::ln::msgs::DecodeError> {
        self.liquidity_manager.read(message_type, buffer)
    }
}

impl CustomMessageHandler for KuutamoCustomMessageHandler {
    fn handle_custom_message(
        &self,
        msg: Self::CustomMessage,
        sender_node_id: &PublicKey,
    ) -> Result<(), LightningError> {
        self.liquidity_manager
            .handle_custom_message(msg, sender_node_id)
    }

    fn get_and_clear_pending_msg(&self) -> Vec<(PublicKey, Self::CustomMessage)> {
        self.liquidity_manager.get_and_clear_pending_msg()
    }

    fn provided_node_features(&self) -> NodeFeatures {
        self.liquidity_manager.provided_node_features()
    }

    fn provided_init_features(&self, their_node_id: &PublicKey) -> InitFeatures {
        self.liquidity_manager.provided_init_features(their_node_id)
    }
}

pub(crate) type ChannelManager =
    SimpleArcChannelManager<ChainMonitor, BitcoindClient, BitcoindClient, KldLogger>;

pub(crate) type OnionMessenger =
    SimpleArcOnionMessenger<ChainMonitor, BitcoindClient, BitcoindClient, KldLogger>;

pub type Scorer = ProbabilisticScorer<Arc<NetworkGraph>, Arc<KldLogger>>;

pub(crate) type KldRouter = DefaultRouter<
    Arc<NetworkGraph>,
    Arc<KldLogger>,
    Arc<RwLock<Scorer>>,
    ProbabilisticScoringFeeParameters,
    Scorer,
>;

pub fn ldk_error(error: APIError) -> anyhow::Error {
    anyhow::Error::msg(match error {
        APIError::APIMisuseError { ref err } => format!("Misuse error: {err}"),
        APIError::FeeRateTooHigh {
            ref err,
            ref feerate,
        } => format!("{err} feerate: {feerate}"),
        APIError::InvalidRoute { ref err } => format!("Invalid route provided: {err}"),
        APIError::ChannelUnavailable { ref err } => format!("Channel unavailable: {err}"),
        APIError::MonitorUpdateInProgress => {
            "Client indicated a channel monitor update is in progress but not yet complete"
                .to_string()
        }
        APIError::IncompatibleShutdownScript { ref script } => {
            format!("Provided a scriptpubkey format not accepted by peer: {script}")
        }
    })
}

pub fn lightning_error(error: LightningError) -> anyhow::Error {
    anyhow!(error.err)
}

pub fn retryable_send_failure(error: RetryableSendFailure) -> anyhow::Error {
    match error {
        RetryableSendFailure::PaymentExpired => {
            anyhow!("Payment failure: payment has expired")
        }
        RetryableSendFailure::RouteNotFound => {
            anyhow!("Payment failure: route not found")
        }
        RetryableSendFailure::DuplicatePayment => {
            anyhow!("Payment failure: duplicate payment")
        }
    }
}

pub fn sign_or_creation_error(error: SignOrCreationError) -> anyhow::Error {
    match error {
        SignOrCreationError::SignError(()) => anyhow!("Error signing invoice"),
        SignOrCreationError::CreationError(e) => anyhow!("Error creating invoice: {e}"),
    }
}

pub fn payment_send_failure(error: PaymentSendFailure) -> anyhow::Error {
    match error {
        PaymentSendFailure::ParameterError(api_error) => ldk_error(api_error),
        PaymentSendFailure::PathParameterError(results) => {
            for result in results {
                if let Err(e) = result {
                    warn!("{}", ldk_error(e));
                }
            }
            anyhow!("Payment failure: Path parameter error. Check logs for more details.")
        }
        PaymentSendFailure::AllFailedResendSafe(errors) => {
            for e in errors {
                warn!("{}", ldk_error(e));
            }
            anyhow!("Payment failure: All failed, resend safe. Check logs for more details.")
        }
        PaymentSendFailure::DuplicatePayment => anyhow!("Payment failed: Duplicate Payment"),
        PaymentSendFailure::PartialFailure {
            results,
            failed_paths_retry: _,
            payment_id: _,
        } => {
            for result in results {
                if let Err(e) = result {
                    warn!("{}", ldk_error(e));
                }
            }
            anyhow!("Payment failed: Partial failure. Check logs for more details.")
        }
    }
}

pub fn decode_error(error: DecodeError) -> anyhow::Error {
    match error {
        DecodeError::UnknownVersion => anyhow!("Unknown version"),
        DecodeError::UnknownRequiredFeature => anyhow!("Unknown required feature"),
        DecodeError::InvalidValue => anyhow!("Invalid value"),
        DecodeError::ShortRead => anyhow!("Short read"),
        DecodeError::BadLengthDescriptor => anyhow!("Bad length descriptor"),
        DecodeError::Io(e) => anyhow!(e),
        DecodeError::UnsupportedCompression => anyhow!("Unsupported compression"),
    }
}

pub fn htlc_destination_to_string(destination: &HTLCDestination) -> String {
    match destination {
        HTLCDestination::NextHopChannel {
            node_id: _,
            channel_id,
        } => format!("Next hop channel ID {}", hex::encode(channel_id.0)),
        HTLCDestination::UnknownNextHop {
            requested_forward_scid,
        } => format!(
            "Unknown next hop to requested SCID {}",
            requested_forward_scid
        ),
        HTLCDestination::InvalidForward {
            requested_forward_scid,
        } => format!(
            "Invalid forward to requested SCID {}",
            requested_forward_scid
        ),
        HTLCDestination::FailedPayment { payment_hash } => {
            format!("Failed payment with hash {}", hex::encode(payment_hash.0))
        }
    }
}

'''
'''--- kld/src/ldk/peer_manager.rs ---
use std::{net::SocketAddr, sync::Arc, time::Duration};

use crate::api::SocketAddress;
use crate::bitcoind::{BitcoindClient, BitcoindUtxoLookup};
use crate::database::{peer::Peer, LdkDatabase};
use crate::logger::KldLogger;
use crate::settings::Settings;
use anyhow::{anyhow, Context, Result};
use async_trait::async_trait;
use bitcoin::secp256k1::PublicKey;
use hex::FromHex;
use lightning::sign::KeysManager;
use lightning::{
    ln::{channelmanager::SimpleArcChannelManager, peer_handler},
    onion_message::messenger::SimpleArcOnionMessenger,
    routing::gossip,
};
use lightning_net_tokio::SocketDescriptor;
use log::{error, info, warn};
use tokio::task::JoinHandle;

use super::{ChainMonitor, ChannelManager, KuutamoCustomMessageHandler};

pub(crate) type PeerManager = peer_handler::PeerManager<
    SocketDescriptor,
    Arc<SimpleArcChannelManager<ChainMonitor, BitcoindClient, BitcoindClient, KldLogger>>,
    Arc<
        gossip::P2PGossipSync<
            Arc<gossip::NetworkGraph<Arc<KldLogger>>>,
            Arc<BitcoindUtxoLookup>,
            Arc<KldLogger>,
        >,
    >,
    Arc<SimpleArcOnionMessenger<ChainMonitor, BitcoindClient, BitcoindClient, KldLogger>>,
    Arc<KldLogger>,
    Arc<KuutamoCustomMessageHandler>,
    Arc<KeysManager>,
>;

#[async_trait]
pub trait KuutamoPeerManger {
    async fn listen(&self, port: u16) -> Result<()>;
    async fn connect_peer(
        &self,
        database: Arc<LdkDatabase>,
        public_key: PublicKey,
        peer_addr: SocketAddress,
    ) -> Result<()>;

    fn keep_channel_peers_connected(
        &self,
        database: Arc<LdkDatabase>,
        channel_manager: Arc<ChannelManager>,
    );

    fn get_connected_peers(&self) -> Vec<(PublicKey, Option<SocketAddress>)>;

    fn is_connected(&self, public_key: &PublicKey) -> bool;

    async fn disconnect_and_drop_by_node_id(
        &self,
        database: Arc<LdkDatabase>,
        node_id: PublicKey,
    ) -> Result<()>;

    /// broadcast the node alias and public addresses of current setting
    fn broadcast_node_announcement_from_settings(&self, settings: Arc<Settings>);
}

#[async_trait]
impl KuutamoPeerManger for Arc<PeerManager> {
    async fn listen(&self, port: u16) -> Result<()> {
        let listener = tokio::net::TcpListener::bind(format!("0.0.0.0:{port:}"))
            .await
            .context("Failed to bind to listen port")?;
        let peer_manager = self.clone();
        tokio::spawn(async move {
            loop {
                let peer_mgr = peer_manager.clone();
                match listener.accept().await {
                    Ok((tcp_stream, socket_addr)) => {
                        if let Ok(tcp_stream) = tcp_stream.into_std() {
                            tokio::spawn(async move {
                                let disconnected = lightning_net_tokio::setup_inbound(
                                    peer_mgr.clone(),
                                    tcp_stream,
                                );
                                info!("Inbound peer connection from {socket_addr}");
                                disconnected.await;
                                info!("Inbound peer disconnected from {socket_addr}");
                            });
                        } else {
                            warn!("tokio tcp stream fail into standard stream")
                        }
                    }
                    Err(e) => warn!("fail to accept peer socket {e}"),
                }
            }
        });
        Ok(())
    }
    async fn connect_peer(
        &self,
        database: Arc<LdkDatabase>,
        public_key: PublicKey,
        peer_addr: SocketAddress,
    ) -> Result<()> {
        if self.is_connected(&public_key) {
            return Ok(());
        }
        let handle = connect_peer(self.clone(), database, public_key, peer_addr).await?;
        loop {
            if self.is_connected(&public_key) {
                return Ok(());
            }
            if handle.is_finished() {
                return Err(anyhow!("Peer disconnected"));
            }
            tokio::time::sleep(Duration::from_secs(1)).await
        }
    }
    fn keep_channel_peers_connected(
        &self,
        database: Arc<LdkDatabase>,
        channel_manager: Arc<ChannelManager>,
    ) {
        let peer_manager = self.clone();
        tokio::spawn(async move {
            loop {
                let connected_node_ids = peer_manager.get_peer_node_ids();
                for unconnected_node_id in channel_manager
                    .list_channels()
                    .iter()
                    .map(|chan| chan.counterparty.node_id)
                    .filter(|id| !connected_node_ids.iter().any(|(pk, _)| pk == id))
                {
                    match database.fetch_peer(&unconnected_node_id).await {
                        Ok(Some(peer)) => {
                            let _ = connect_peer(
                                peer_manager.clone(),
                                database.clone(),
                                peer.public_key,
                                peer.address.into(),
                            )
                            .await;
                        }
                        Err(e) => error!("{}", e),
                        _ => (),
                    }
                }
                tokio::time::sleep(Duration::from_secs(1)).await;
            }
        });
    }

    fn get_connected_peers(&self) -> Vec<(PublicKey, Option<SocketAddress>)> {
        self.get_peer_node_ids()
            .into_iter()
            .map(|(k, a)| (k, a.map(SocketAddress::from)))
            .collect()
    }

    fn is_connected(&self, public_key: &PublicKey) -> bool {
        self.get_peer_node_ids().iter().any(|p| p.0 == *public_key)
    }

    async fn disconnect_and_drop_by_node_id(
        &self,
        database: Arc<LdkDatabase>,
        node_id: PublicKey,
    ) -> Result<()> {
        self.disconnect_by_node_id(node_id);
        database.delete_peer(&node_id).await
    }

    fn broadcast_node_announcement_from_settings(&self, settings: Arc<Settings>) {
        let mut alias = [0; 32];
        alias[..settings.node_alias.len()].copy_from_slice(settings.node_alias.as_bytes());
        let addresses: Vec<lightning::ln::msgs::SocketAddress> = settings
            .public_addresses
            .clone()
            .into_iter()
            .map(|a| a.inner())
            .collect();

        let color = <[u8; 3]>::from_hex(&settings.node_alias_color).unwrap_or([110, 44, 247]);
        self.broadcast_node_announcement(color, alias, addresses);
    }
}

async fn connect_peer(
    peer_manager: Arc<PeerManager>,
    database: Arc<LdkDatabase>,
    public_key: PublicKey,
    address: SocketAddress,
) -> Result<JoinHandle<()>> {
    let socket_addr = SocketAddr::try_from(address.clone())?;
    let connection_closed =
        lightning_net_tokio::connect_outbound(peer_manager, public_key, socket_addr)
            .await
            .context("Could not connect to peer {public_key}@{peer_addr}")?;
    database
        .persist_peer(&Peer {
            public_key,
            address: address.0,
        })
        .await?;
    info!("Connected to peer {public_key}@{socket_addr}");
    Ok(tokio::spawn(async move {
        connection_closed.await;
        info!("Disconnected from peer {public_key}@{socket_addr}");
    }))
}

'''
'''--- kld/src/lib.rs ---
#![feature(async_closure)]
#![feature(trait_alias)]
use async_trait::async_trait;
use tokio::signal::unix::SignalKind;

pub mod api;
pub mod bitcoind;
pub mod database;
pub mod key_generator;
pub mod ldk;
pub mod logger;
pub mod prometheus;
pub mod settings;
pub mod wallet;

// For api codegen
#[macro_use]
extern crate serde;

pub const VERSION: &str = concat!("KLD v", env!("CARGO_PKG_VERSION"));

pub type MillisatAmount = u64;

pub async fn quit_signal() {
    let _ = tokio::signal::unix::signal(SignalKind::quit())
        .unwrap()
        .recv()
        .await;
}

#[async_trait]
pub trait Service: Send + Sync {
    async fn is_connected(&self) -> bool;
    async fn is_synchronised(&self) -> bool;
}

pub fn log_error(e: &anyhow::Error) {
    for cause in e.chain() {
        log::error!("{}", cause);
    }
}

'''
'''--- kld/src/logger.rs ---
use lightning::util::logger::{Level, Logger};
use log::{logger, LevelFilter, Log, Metadata, MetadataBuilder, Record};
use std::{
    process,
    sync::{Arc, OnceLock},
};

/// A logger instance for logfmt format (https://www.brandur.org/logfmt)
#[derive(Debug)]
pub struct KldLogger {
    node_id: String,
}

// LDK requires the Arc so may as well be global.
static KLD_LOGGER: OnceLock<Arc<KldLogger>> = OnceLock::new();

impl KldLogger {
    pub fn init(node_id: &str, level_filter: LevelFilter) {
        let logger = KLD_LOGGER.get_or_init(|| {
            Arc::new(KldLogger {
                node_id: node_id.to_string(),
            })
        });
        // This function gets called multiple times by the tests so ignore the error.
        let _ = log::set_logger(logger).map(|()| log::set_max_level(level_filter));
    }

    pub fn global() -> Arc<KldLogger> {
        KLD_LOGGER.get().expect("logger is not initialized").clone()
    }
}

impl Log for KldLogger {
    fn enabled(&self, metadata: &Metadata) -> bool {
        metadata.level() <= log::max_level()
    }

    fn log(&self, record: &Record) {
        if self.enabled(record.metadata()) {
            if record.args().as_str().is_some_and(|s| s == "A Channel Monitor sync is still in progress, refusing to provide monitor events!") {
                return;
            }
            let level = record.level().to_string().to_lowercase();
            print!("level={level}");
            print!(" pid={}", process::id());
            print!(" message=\"{}\"", record.args());
            print!(" target=\"{}\"", record.target());
            if let Some(line) = record.line() {
                print!(" line=\"{}\"", line);
            }
            print!(" node_id={}", self.node_id);
            println!();
        }
    }

    fn flush(&self) {}
}

impl Logger for KldLogger {
    fn log(&self, record: lightning::util::logger::Record) {
        logger().log(
            &log::RecordBuilder::new()
                .args(record.args)
                .file(Some(record.file))
                .line(Some(record.line))
                .metadata(
                    MetadataBuilder::new()
                        .level(match record.level {
                            Level::Gossip => log::Level::Trace,
                            Level::Trace => log::Level::Trace,
                            Level::Debug => log::Level::Debug,
                            Level::Info => log::Level::Info,
                            Level::Warn => log::Level::Warn,
                            Level::Error => log::Level::Error,
                        })
                        .target(record.module_path)
                        .build(),
                )
                .module_path(Some(record.module_path))
                .build(),
        );
    }
}

#[test]
pub fn test_log() {
    let node_id = "one";
    KldLogger::init(node_id, LevelFilter::Info);
    assert_eq!(node_id, KldLogger::global().node_id);

    let metadata = MetadataBuilder::new().level(log::Level::Debug).build();
    assert!(!KldLogger::global().enabled(&metadata));

    let metadata = MetadataBuilder::new().level(log::Level::Info).build();
    assert!(KldLogger::global().enabled(&metadata));

    let metadata = MetadataBuilder::new().level(log::Level::Warn).build();
    assert!(KldLogger::global().enabled(&metadata));
}

'''
'''--- kld/src/prometheus.rs ---
//! Prometheus http exporter

use std::process;
use std::sync::{Arc, OnceLock};
use std::time::Instant;

use anyhow::{Context, Result};
use futures::future::Shared;
use futures::Future;
use hyper::service::{make_service_fn, service_fn};
use hyper::{Body, Method, Request, Response, Server, StatusCode};
use lightning::chain::chaininterface::ConfirmationTarget;
use log::info;
use prometheus::{
    self, register_gauge, register_int_counter, register_int_gauge, Encoder, Gauge, IntCounter,
    IntGauge, TextEncoder,
};

use crate::bitcoind::BitcoindMetrics;
use crate::database::DBConnection;
use crate::ldk::LightningInterface;

static START: OnceLock<Instant> = OnceLock::new();
static UPTIME: OnceLock<Gauge> = OnceLock::new();
/// The free balance without any channel setting
static WALLET_BALANCE: OnceLock<Gauge> = OnceLock::new();
/// The balance already used in channel and bond in our side
static CHANNEL_BALANCE: OnceLock<Gauge> = OnceLock::new();
static FEE: OnceLock<Gauge> = OnceLock::new();
static BLOCK_HEIGHT: OnceLock<IntGauge> = OnceLock::new();

static ON_CHAIN_SWEEP_FEE: OnceLock<IntGauge> = OnceLock::new();
static NON_ANCHOR_CHANNEL_FEE: OnceLock<IntGauge> = OnceLock::new();
static CHANNEL_CLOSE_MINIMUM_FEE: OnceLock<IntGauge> = OnceLock::new();
static ANCHOR_CHANNEL_FEE: OnceLock<IntGauge> = OnceLock::new();
static MIN_ALLOWED_ANCHOR_CHANNEL_REMOTE_FEE: OnceLock<IntGauge> = OnceLock::new();
static MIN_ALLOWED_NON_ANCHOR_CHANNEL_REMOTE_FEE: OnceLock<IntGauge> = OnceLock::new();
static SCORER_UPDATE_TIMESTAMP: OnceLock<IntGauge> = OnceLock::new();

// NOTE:
// Gauge will slow down about 20%~30%, unleast the count reach the limit, else we
// should use IntGauge
static NODE_COUNT: OnceLock<IntGauge> = OnceLock::new();
static NETWORK_CHANNEL_COUNT: OnceLock<IntGauge> = OnceLock::new();
static CHANNEL_COUNT: OnceLock<IntGauge> = OnceLock::new();
static PEER_COUNT: OnceLock<IntGauge> = OnceLock::new();

async fn response_examples(
    lightning_metrics: Arc<dyn LightningInterface>,
    database: Arc<dyn DBConnection>,
    bitcoind: Arc<dyn BitcoindMetrics>,
    req: Request<Body>,
) -> hyper::Result<Response<Body>> {
    match (req.method(), req.uri().path()) {
        (&Method::GET, "/health") => {
            let health = if database.is_synchronised().await && bitcoind.is_synchronised().await {
                "OK"
            } else if database.is_connected().await && bitcoind.is_connected().await {
                "SYNCING"
            } else {
                "ERROR"
            };
            Ok(Response::new(Body::from(health)))
        }
        (&Method::GET, "/pid") => Ok(Response::new(Body::from(process::id().to_string()))),
        (&Method::GET, "/metrics") => {
            if let Some(g) = UPTIME.get() {
                g.set(START.get_or_init(Instant::now).elapsed().as_millis() as f64)
            }
            if let Some(g) = NODE_COUNT.get() {
                g.set(
                    lightning_metrics
                        .graph_num_nodes()
                        .try_into()
                        .unwrap_or(i64::MAX),
                )
            }
            if let Some(g) = NETWORK_CHANNEL_COUNT.get() {
                g.set(
                    lightning_metrics
                        .graph_num_channels()
                        .try_into()
                        .unwrap_or(i64::MAX),
                )
            }
            if let (Some(g), Ok(i)) = (CHANNEL_COUNT.get(), database.open_channel_count().await) {
                g.set(i);
            }
            if let Some(g) = PEER_COUNT.get() {
                g.set(lightning_metrics.num_peers().try_into().unwrap_or(i64::MAX))
            }
            if let Some(g) = WALLET_BALANCE.get() {
                g.set(lightning_metrics.wallet_balance() as f64)
            }
            if let Some(g) = CHANNEL_BALANCE.get() {
                let mut total_channel_balance = 0;
                let channels = lightning_metrics.list_active_channels();
                for channel in channels {
                    total_channel_balance += channel.balance_msat;
                }
                g.set((total_channel_balance as f64) / 1000.0)
            }
            // XXX better from dbconnection not lightning_metrics, if the fee is get from database
            if let (Some(g), Ok(total_fee)) =
                (FEE.get(), lightning_metrics.fetch_total_forwards().await)
            {
                g.set(total_fee.fee as f64)
            }
            if let (Some(g), Ok(h)) = (BLOCK_HEIGHT.get(), bitcoind.block_height().await) {
                g.set(h.into())
            }

            if let Some(g) = ON_CHAIN_SWEEP_FEE.get() {
                g.set(bitcoind.fee_for(ConfirmationTarget::OnChainSweep).into())
            }
            if let Some(g) = NON_ANCHOR_CHANNEL_FEE.get() {
                g.set(
                    bitcoind
                        .fee_for(ConfirmationTarget::NonAnchorChannelFee)
                        .into(),
                )
            }
            if let Some(g) = CHANNEL_CLOSE_MINIMUM_FEE.get() {
                g.set(
                    bitcoind
                        .fee_for(ConfirmationTarget::ChannelCloseMinimum)
                        .into(),
                )
            }
            if let Some(g) = ANCHOR_CHANNEL_FEE.get() {
                g.set(
                    bitcoind
                        .fee_for(ConfirmationTarget::AnchorChannelFee)
                        .into(),
                )
            }
            if let Some(g) = MIN_ALLOWED_ANCHOR_CHANNEL_REMOTE_FEE.get() {
                g.set(
                    bitcoind
                        .fee_for(ConfirmationTarget::MinAllowedAnchorChannelRemoteFee)
                        .into(),
                )
            }
            if let Some(g) = MIN_ALLOWED_NON_ANCHOR_CHANNEL_REMOTE_FEE.get() {
                g.set(
                    bitcoind
                        .fee_for(ConfirmationTarget::MinAllowedNonAnchorChannelRemoteFee)
                        .into(),
                )
            }
            if let (Some(g), Ok(ts)) = (
                SCORER_UPDATE_TIMESTAMP.get(),
                database.fetch_scorer_update_time().await,
            ) {
                g.set(ts.unix_timestamp());
            }

            let metric_families = prometheus::gather();
            let mut buffer = vec![];
            let encoder = TextEncoder::new();
            encoder.encode(&metric_families, &mut buffer).unwrap();
            Ok(Response::new(Body::from(buffer)))
        }
        _ => Ok(not_found()),
    }
}

static NOTFOUND: &[u8] = b"Not Found";
/// HTTP status code 404
fn not_found() -> Response<Body> {
    Response::builder()
        .status(StatusCode::NOT_FOUND)
        .body(NOTFOUND.into())
        .unwrap()
}

/// Starts an prometheus exporter backend
pub async fn start_prometheus_exporter(
    address: String,
    lightning_metrics: Arc<dyn LightningInterface>,
    database: Arc<dyn DBConnection>,
    bitcoind: Arc<dyn BitcoindMetrics>,
    quit_signal: Shared<impl Future<Output = ()>>,
    probe_metrics: (
        &OnceLock<IntCounter>,
        &OnceLock<IntCounter>,
        &OnceLock<IntCounter>,
    ),
) -> Result<()> {
    UPTIME
        .set(register_gauge!(
            "uptime",
            "Time in milliseconds how long daemon is running"
        )?)
        .unwrap_or_default();
    NODE_COUNT
        .set(register_int_gauge!(
            "node_count",
            "The number of nodes in the lightning graph"
        )?)
        .unwrap_or_default();
    NETWORK_CHANNEL_COUNT
        .set(register_int_gauge!(
            "network_channel_count",
            "The number of channels in the lightning network"
        )?)
        .unwrap_or_default();
    CHANNEL_COUNT
        .set(register_int_gauge!(
            "channel_count",
            "The number of channels opened by us"
        )?)
        .unwrap_or_default();
    PEER_COUNT
        .set(register_int_gauge!(
            "peer_count",
            "The number of peers this node has"
        )?)
        .unwrap_or_default();
    WALLET_BALANCE
        .set(register_gauge!(
            "wallet_balance",
            "The bitcoin wallet balance"
        )?)
        .unwrap_or_default();
    CHANNEL_BALANCE
        .set(register_gauge!(
            "channel_balance",
            "The bitcoin balance in channel and in our side"
        )?)
        .unwrap_or_default();
    FEE.set(register_gauge!(
        "fee",
        "The total fee from successful channels"
    )?)
    .unwrap_or_default();
    BLOCK_HEIGHT
        .set(register_int_gauge!(
            "block_height",
            "The block height kld observed"
        )?)
        .unwrap_or_default();
    ON_CHAIN_SWEEP_FEE
        .set(register_int_gauge!(
            "on_chain_sweep_fee",
            "The fee for ConfirmationTarget::OnChainSweep"
        )?)
        .unwrap_or_default();
    NON_ANCHOR_CHANNEL_FEE
        .set(register_int_gauge!(
            "non_anchor_channel_fee",
            "The fee for ConfirmationTarget::NonAnchorChannelFee"
        )?)
        .unwrap_or_default();
    CHANNEL_CLOSE_MINIMUM_FEE
        .set(register_int_gauge!(
            "channel_close_minimum_fee",
            "The fee for ConfirmationTarget::ChannelCloseMinimum"
        )?)
        .unwrap_or_default();
    ANCHOR_CHANNEL_FEE
        .set(register_int_gauge!(
            "anchor_channel_fee",
            "The fee for ConfirmationTarget::AnchorChannelFee"
        )?)
        .unwrap_or_default();
    MIN_ALLOWED_ANCHOR_CHANNEL_REMOTE_FEE
        .set(register_int_gauge!(
            "min_allowed_anchor_channel_remote_fee",
            "The fee for ConfirmationTarget::MinAllowedAnchorChannelRemoteFee"
        )?)
        .unwrap_or_default();
    MIN_ALLOWED_NON_ANCHOR_CHANNEL_REMOTE_FEE
        .set(register_int_gauge!(
            "min_allowed_non_anchor_channel_remote_fee",
            "The fee for ConfirmationTarget::MinAllowedNonAnchorChannelRemoteFee"
        )?)
        .unwrap_or_default();
    SCORER_UPDATE_TIMESTAMP
        .set(register_int_gauge!(
            "scorer_update_timestamp",
            "The update time of scorer"
        )?)
        .unwrap_or_default();
    probe_metrics
        .0
        .set(register_int_counter!(
            "probe_total_count",
            "The total count of probe has tried"
        )?)
        .unwrap_or_default();
    probe_metrics
        .1
        .set(register_int_counter!(
            "probe_successful_count",
            "The total successful count of probe"
        )?)
        .unwrap_or_default();
    probe_metrics
        .2
        .set(register_int_counter!(
            "probe_failed_count",
            "The total failed count of probe"
        )?)
        .unwrap_or_default();
    let addr = address.parse().context("Failed to parse exporter")?;
    let make_service = make_service_fn(move |_| {
        let lightning_metrics_clone = lightning_metrics.clone();
        let bitcoind_clone = bitcoind.clone();
        let database_clone = database.clone();
        let service = service_fn(move |req| {
            response_examples(
                lightning_metrics_clone.clone(),
                database_clone.clone(),
                bitcoind_clone.clone(),
                req,
            )
        });
        async move { Ok::<_, hyper::Error>(service) }
    });

    let server = Server::bind(&addr)
        .serve(make_service)
        .with_graceful_shutdown(quit_signal);

    info!("Prometheus exporter listening on http://{}", addr);

    server.await.context("Failed to start server")
}

'''
'''--- kld/src/settings/bitcoin_network.rs ---
use std::{fmt, str::FromStr};

// Implement me the traits needed for clap to deserialize the following struct:

/// Blockchain to use
#[derive(Copy, PartialEq, Eq, PartialOrd, Ord, Clone, Debug)]
pub enum Network {
    /// Classic Bitcoin
    Main,
    /// Bitcoin's testnet
    Testnet,
    /// Bitcoin's signet
    Signet,
    /// Bitcoin's regtest
    Regtest,
}

impl fmt::Display for Network {
    fn fmt(&self, formatter: &mut fmt::Formatter) -> fmt::Result {
        write!(
            formatter,
            "{}",
            match self {
                Network::Main => "main",
                Network::Testnet => "testnet",
                Network::Signet => "signet",
                Network::Regtest => "regtest",
            }
        )
    }
}

impl From<Network> for bitcoin::Network {
    fn from(network: Network) -> Self {
        match network {
            Network::Main => bitcoin::Network::Bitcoin,
            Network::Testnet => bitcoin::Network::Testnet,
            Network::Signet => bitcoin::Network::Signet,
            Network::Regtest => bitcoin::Network::Regtest,
        }
    }
}

impl FromStr for Network {
    type Err = &'static str;

    fn from_str(input: &str) -> Result<Network, Self::Err> {
        match input {
            "main" => Ok(Network::Main),
            "testnet" => Ok(Network::Testnet),
            "signet" => Ok(Network::Signet),
            "regtest" => Ok(Network::Regtest),
            _ => Err("not a valid value, must be one of: main, testnet, signet or regtest"),
        }
    }
}

'''
'''--- kld/src/settings/mod.rs ---
mod bitcoin_network;

use crate::api::SocketAddress;
pub use bitcoin::network::constants::Network;
use bitcoin::secp256k1::PublicKey;
use clap::{builder::OsStr, Parser};

#[derive(Parser, Debug, Clone)]
#[command(author, version, about, long_about = None)]
pub struct Settings {
    #[arg(long, default_value = "localhost", env = "KLD_BITCOIN_RPC_HOST")]
    pub bitcoind_rpc_host: String,
    #[arg(long, default_value = "8333", env = "KLD_BITCOIN_RPC_PORT")]
    pub bitcoind_rpc_port: u16,
    #[arg(long, default_value = "regtest", env = "KLD_BITCOIN_NETWORK")]
    pub bitcoin_network: Network,
    #[arg(
        long,
        default_value = "/var/lib/bitcoind-testnet/.cookie",
        env = "KLD_BITCOIN_COOKIE_PATH"
    )]
    pub bitcoin_cookie_path: String,

    #[arg(long, default_value = "/var/lib/kld", env = "KLD_DATA_DIR")]
    pub data_dir: String,
    #[arg(long, default_value = "/var/lib/kld/certs", env = "KLD_CERTS_DIR")]
    pub certs_dir: String,
    #[arg(
        long,
        default_value = "/var/lib/kld/mnemonic",
        env = "KLD_MNEMONIC_PATH"
    )]
    pub mnemonic_path: String,
    #[arg(long, default_value = "one", env = "KLD_NODE_ID")]
    pub node_id: String,
    #[arg(long, default_value = "kld-wallet", env = "KLD_WALLET_NAME")]
    pub wallet_name: String,
    #[arg(long, default_value = "info", env = "KLD_LOG_LEVEL")]
    pub log_level: String,
    #[arg(long, default_value = "test", env = "KLD_ENV")]
    pub env: String,
    /// The port to listen to new peer connections on.
    #[arg(long, default_value = "9234", env = "KLD_PEER_PORT")]
    pub peer_port: u16,
    /// The node alias on the lightning network.
    #[arg(long, default_value = "", env = "KLD_NODE_ALIAS")]
    pub node_alias: String,
    /// The node alias color on the lightning network.
    #[arg(long, default_value = "6e2cf7", env = "KLD_NODE_ALIAS_COLOR")]
    pub node_alias_color: String,
    /// Public addresses to broadcast to the lightning network.
    #[arg(long, value_delimiter = ',', env = "KLD_PUBLIC_ADDRESSES")]
    pub public_addresses: Vec<SocketAddress>,

    #[arg(long, default_value = "127.0.0.1:2233", env = "KLD_EXPORTER_ADDRESS")]
    pub exporter_address: String,
    #[arg(long, default_value = "127.0.0.1:2244", env = "KLD_REST_API_ADDRESS")]
    pub rest_api_address: String,

    #[arg(long, default_value = "127.0.0.1:60001", env = "KLD_ELECTRS_URL")]
    pub electrs_url: String,

    #[arg(long, default_value = "127.0.0.1", env = "KLD_DATABASE_HOST")]
    pub database_host: String,
    #[arg(long, default_value = "10000", env = "KLD_DATABASE_PORT")]
    pub database_port: u16,
    #[arg(long, default_value = "root", env = "KLD_DATABASE_USER")]
    pub database_user: String,
    #[arg(long, default_value = "defaultdb", env = "KLD_DATABASE_NAME")]
    pub database_name: String,
    #[arg(long, default_value = "", env = "KLD_DATABASE_CA_CERT_PATH")]
    pub database_ca_cert_path: String,
    #[arg(long, default_value = "", env = "KLD_DATABASE_CLIENT_CERT_PATH")]
    pub database_client_cert_path: String,
    #[arg(long, default_value = "", env = "KLD_DATABASE_CLIENT_KEY_PATH")]
    pub database_client_key_path: String,

    /// The time interval to do random probe, 0 will disable the feature
    #[arg(long, default_value = "0", env = "KLD_PROBE_INTERVAL")]
    pub probe_interval: u64,
    /// The amount in million satoshis is used to probe
    #[arg(long, default_value = "0", env = "KLD_PROBE_AMT_MSAT")]
    pub probe_amt_msat: u64,
    /// The targets to probe
    #[arg(long, value_delimiter = ',', env = "KLD_PROBE_TARGETS")]
    pub probe_targets: Vec<PublicKey>,

    /// The graceful period in seconds when a shutdown signal is received
    #[arg(long, default_value = "5", env = "KLD_SHUTDOWN_GRACEFUL_SEC")]
    pub shutdown_graceful_sec: u64,
}

impl Settings {
    pub fn load() -> Settings {
        Settings::parse()
    }
}

impl Default for Settings {
    fn default() -> Self {
        Settings::parse_from::<Vec<OsStr>, OsStr>(vec![])
    }
}

#[cfg(test)]
mod test {
    use crate::settings::Settings;
    use std::env::set_var;

    #[test]
    pub fn test_parse_settings() {
        set_var("KLD_PUBLIC_ADDRESSES", "127.0.0.1:2312,[2001:db8::1]:1212");
        let settings = Settings::load();
        assert_eq!(settings.public_addresses.len(), 2);
    }
}

'''
'''--- kld/src/wallet/bdk_wallet.rs ---
use std::{
    sync::{Arc, Mutex, OnceLock},
    time::Duration,
};

use crate::settings::Settings;
use anyhow::{anyhow, bail, Context, Result};
use async_trait::async_trait;
use bdk::{
    bitcoin::bip32::ExtendedPrivKey,
    blockchain::{log_progress, ElectrumBlockchain, GetHeight},
    database::{BatchDatabase, BatchOperations, Database},
    electrum_client::Client,
    template::Bip84,
    wallet::AddressInfo,
    Balance, FeeRate, KeychainKind, LocalUtxo, SignOptions, SyncOptions, TransactionDetails,
};
use bitcoin::address::NetworkUnchecked;
use bitcoin::{Address, OutPoint, Script, Transaction};
use lightning::chain::chaininterface::{BroadcasterInterface, ConfirmationTarget, FeeEstimator};
use lightning_block_sync::BlockSource;
use log::{error, info, warn};

use crate::Service;

use super::WalletInterface;

pub struct Wallet<
    D: Database + BatchDatabase + BatchOperations,
    B: BlockSource + FeeEstimator + Service + 'static,
> {
    // bdk::Wallet uses a RefCell to hold the database which is not thread safe so we use a mutex here.
    wallet: Arc<Mutex<bdk::Wallet<D>>>,
    bitcoind_client: Arc<B>,
    settings: Arc<Settings>,
    blockchain: Arc<OnceLock<ElectrumBlockchain>>,
    network: bitcoin::network::constants::Network,
}

#[async_trait]
impl<
        D: Database + BatchDatabase + BatchOperations + Send + 'static,
        B: BlockSource + FeeEstimator + BroadcasterInterface + Service,
    > WalletInterface for Wallet<D, B>
{
    fn balance(&self) -> Result<Balance> {
        match self.wallet.try_lock() {
            Ok(wallet) => Ok(wallet.get_balance()?),
            Err(_) => {
                warn!("Wallet was locked when trying to get balance");
                Ok(Balance::default())
            }
        }
    }

    async fn transfer(
        &self,
        address: Address<NetworkUnchecked>,
        amount: u64,
        fee_rate: Option<crate::api::payloads::FeeRate>,
        min_conf: Option<u8>,
        utxos: Vec<OutPoint>,
    ) -> Result<(Transaction, TransactionDetails)> {
        if !self.bitcoind_client.is_synchronised().await {
            bail!("Bitcoind is synchronising the blockchain")
        }
        let height = match self.bitcoind_client.get_best_block().await {
            Ok((_, Some(height))) => height,
            _ => {
                bail!("Failed to fetch best block")
            }
        };

        let address = address.require_network(self.network)?;
        let script_pubkey = address.script_pubkey();

        match self.wallet.lock() {
            Ok(wallet) => {
                let mut tx_builder = wallet.build_tx();
                if amount == u64::MAX {
                    tx_builder.drain_wallet().drain_to(script_pubkey);
                } else {
                    tx_builder
                        .add_recipient(script_pubkey, amount)
                        .drain_wallet()
                        .add_utxos(&utxos)?;
                };
                tx_builder.current_height(
                    min_conf.map_or_else(|| height, |min_conf| height - min_conf as u32),
                );
                if let Some(fee_rate) = fee_rate {
                    tx_builder.fee_rate(self.to_bdk_fee_rate(fee_rate));
                }
                let (mut psbt, tx_details) = tx_builder.finish()?;
                let _finalized = wallet.sign(&mut psbt, SignOptions::default())?;
                let tx = psbt.extract_tx();

                info!(
                    "Transferring {} sats to {address} with txid {}",
                    tx_details.sent, tx_details.txid
                );
                self.bitcoind_client.broadcast_transactions(&[&tx]);
                Ok((tx, tx_details))
            }
            Err(_) => bail!("Wallet is still syncing with chain"),
        }
    }

    fn new_external_address(&self) -> Result<AddressInfo> {
        let address = self
            .wallet
            .lock()
            .unwrap()
            .get_address(bdk::wallet::AddressIndex::LastUnused)?;
        Ok(address)
    }

    fn new_internal_address(&self) -> Result<AddressInfo> {
        let address = self
            .wallet
            .lock()
            .unwrap()
            .get_internal_address(bdk::wallet::AddressIndex::LastUnused)?;
        Ok(address)
    }
    fn list_utxos(&self) -> Result<Vec<(LocalUtxo, TransactionDetails)>> {
        let mut result = vec![];
        match self.wallet.try_lock() {
            Ok(wallet) => {
                let utxos = wallet.list_unspent()?;
                for utxo in utxos {
                    if let Some(tx) = wallet.get_tx(&utxo.outpoint.txid, false)? {
                        result.push((utxo, tx));
                    }
                }
            }
            Err(_) => {
                warn!("Wallet was locked when trying to list utxos");
            }
        }
        Ok(result)
    }
}

impl<
        D: Database + BatchDatabase + BatchOperations + Send + 'static,
        B: BlockSource + FeeEstimator + Service,
    > Wallet<D, B>
{
    pub fn new(
        seed: &[u8; 32],
        settings: Arc<Settings>,
        bitcoind_client: Arc<B>,
        database: D,
    ) -> Result<Wallet<D, B>> {
        let xprivkey = ExtendedPrivKey::new_master(settings.bitcoin_network, seed)?;

        let bdk_wallet = Arc::new(Mutex::new(bdk::Wallet::new(
            Bip84(xprivkey, KeychainKind::External),
            Some(Bip84(xprivkey, KeychainKind::Internal)),
            settings.bitcoin_network,
            database,
        )?));
        let network = settings.bitcoin_network;
        Ok(Wallet {
            wallet: bdk_wallet,
            bitcoind_client,
            settings,
            blockchain: Arc::new(OnceLock::new()),
            network,
        })
    }

    pub async fn synced(&self) -> bool {
        if let Ok((_, Some(height))) = self.bitcoind_client.get_best_block().await {
            if let Ok(wallet) = self.wallet.try_lock() {
                if let Ok(Some(sync_time)) = wallet.database().get_sync_time() {
                    return sync_time.block_time.height == height;
                }
            }
        }
        false
    }

    pub fn keep_sync_with_chain(&self) {
        let wallet_clone = self.wallet.clone();
        let blockchain = self.blockchain.clone();
        let electrs_url = self.settings.electrs_url.clone();
        tokio::task::spawn_blocking(move || loop {
            let sync = || -> Result<()> {
                // ElectrumBlockchain will not be instantiated if electrs is down. So within this loop we can keep trying to connect and get in sync.
                if blockchain.get().is_none() {
                    let client = Client::new(&electrs_url)?;
                    blockchain
                        .set(ElectrumBlockchain::from(client))
                        .map_err(|_| anyhow!("ElectrumBlockchain already set"))?;
                }
                let blockchain = blockchain
                    .get()
                    .context("ElectrumBlockchain should be set")?;
                let height = blockchain.get_height()?;
                let guard = wallet_clone
                    .lock()
                    .map_err(|_| anyhow!("wallet lock is poisened"))?;
                let database = guard.database();
                let synctime = database.get_sync_time()?;
                let sync_height = synctime
                    .map(|time| time.block_time.height as u64)
                    .unwrap_or_default();
                if sync_height < height as u64 {
                    drop(database);
                    info!("Starting wallet sync from {sync_height} to {height}");
                    guard.sync(
                        blockchain,
                        SyncOptions {
                            progress: Some(Box::new(log_progress())),
                        },
                    )?;
                    info!("Wallet is synchronised with electrs");
                }
                Ok(())
            };
            if let Err(e) = sync() {
                error!("Failed to sync wallet: {e}");
            };

            std::thread::sleep(Duration::from_secs(10));
        });
    }

    pub fn fund_tx(
        &self,
        output_script: &Script,
        channel_value_satoshis: &u64,
        fee_rate: crate::api::payloads::FeeRate,
    ) -> Result<Transaction> {
        let wallet = self.wallet.lock().unwrap();

        let mut tx_builder = wallet.build_tx();

        tx_builder
            .add_recipient(output_script.into(), *channel_value_satoshis)
            .fee_rate(self.to_bdk_fee_rate(fee_rate))
            .enable_rbf();

        let (mut psbt, _tx_details) = tx_builder.finish()?;

        let _finalized = wallet.sign(&mut psbt, SignOptions::default())?;

        let funding_tx = psbt.extract_tx();
        Ok(funding_tx)
    }

    fn to_bdk_fee_rate(&self, fee_rate: crate::api::payloads::FeeRate) -> FeeRate {
        match fee_rate {
            crate::api::payloads::FeeRate::Urgent => FeeRate::from_sat_per_kwu(
                self.bitcoind_client
                    .get_est_sat_per_1000_weight(ConfirmationTarget::OnChainSweep)
                    as f32,
            ),
            crate::api::payloads::FeeRate::Normal => FeeRate::from_sat_per_kwu(
                self.bitcoind_client
                    .get_est_sat_per_1000_weight(ConfirmationTarget::NonAnchorChannelFee)
                    as f32,
            ),
            crate::api::payloads::FeeRate::Slow => FeeRate::from_sat_per_kwu(
                self.bitcoind_client
                    .get_est_sat_per_1000_weight(ConfirmationTarget::ChannelCloseMinimum)
                    as f32,
            ),
            crate::api::payloads::FeeRate::PerKw(s) => FeeRate::from_sat_per_kwu(s as f32),
            crate::api::payloads::FeeRate::PerKb(s) => FeeRate::from_sat_per_kvb(s as f32),
        }
    }
}

#[cfg(test)]
mod test {
    use std::{
        str::FromStr,
        sync::{Arc, Mutex, OnceLock},
    };

    use crate::settings::Settings;
    use anyhow::Result;
    use bdk::{database::MemoryDatabase, wallet::get_funded_wallet, Balance};
    use bitcoin::Address;
    use test_utils::{TEST_ADDRESS, TEST_WPKH};

    use crate::{bitcoind::MockBitcoindClient, wallet::WalletInterface};

    use super::Wallet;

    #[test]
    fn test_fee_rate() -> Result<()> {
        let wallet = Wallet::new(
            &[0u8; 32],
            Arc::new(Settings::default()),
            Arc::new(MockBitcoindClient::default()),
            MemoryDatabase::new(),
        )?;

        let balance = wallet.balance()?;
        assert_eq!(balance, Balance::default());

        let urgent_fee_rate = wallet.to_bdk_fee_rate(crate::api::payloads::FeeRate::Urgent);
        assert_eq!(40f32, urgent_fee_rate.as_sat_per_vb());

        let normal_fee_rate = wallet.to_bdk_fee_rate(crate::api::payloads::FeeRate::Normal);
        assert_eq!(8f32, normal_fee_rate.as_sat_per_vb());

        let slow_fee_rate = wallet.to_bdk_fee_rate(crate::api::payloads::FeeRate::Slow);
        assert_eq!(2f32, slow_fee_rate.as_sat_per_vb());

        let perkw_fee_rate = wallet.to_bdk_fee_rate(crate::api::payloads::FeeRate::PerKw(4000));
        assert_eq!(16f32, perkw_fee_rate.as_sat_per_vb());

        let perkb_fee_rate = wallet.to_bdk_fee_rate(crate::api::payloads::FeeRate::PerKb(1000));
        assert_eq!(1f32, perkb_fee_rate.as_sat_per_vb());

        Ok(())
    }

    #[tokio::test]
    async fn test_cannot_transfer_while_synchronising() -> Result<()> {
        let mut bitcoind_client = MockBitcoindClient::default();
        bitcoind_client.set_synchronised(false);
        let (bdk_wallet, _, _) = get_funded_wallet(TEST_WPKH);
        let bitcoind_client = Arc::new(bitcoind_client);
        let wallet = Wallet {
            bitcoind_client: bitcoind_client.clone(),
            wallet: Arc::new(Mutex::new(bdk_wallet)),
            settings: Arc::new(Settings::default()),
            blockchain: Arc::new(OnceLock::new()),
            network: bitcoin::network::constants::Network::Testnet,
        };

        let res = wallet
            .transfer(
                Address::from_str(TEST_ADDRESS)?,
                u64::MAX,
                None,
                None,
                vec![],
            )
            .await;
        assert!(res.is_err());
        Ok(())
    }

    #[tokio::test]
    async fn test_transfer() -> Result<()> {
        let bitcoind_client = MockBitcoindClient::default();
        let (bdk_wallet, _, _) = get_funded_wallet(TEST_WPKH);
        let bitcoind_client = Arc::new(bitcoind_client);
        let wallet = Wallet {
            bitcoind_client: bitcoind_client.clone(),
            wallet: Arc::new(Mutex::new(bdk_wallet)),
            settings: Arc::new(Settings::default()),
            blockchain: Arc::new(OnceLock::new()),
            network: bitcoin::network::constants::Network::Testnet,
        };

        let (tx, tx_details) = wallet
            .transfer(
                Address::from_str(TEST_ADDRESS)?,
                u64::MAX,
                None,
                None,
                vec![],
            )
            .await?;

        assert!(!tx.input.is_empty());
        for input in &tx.input {
            assert!(!input.witness.is_empty());
        }
        assert!(!tx.output.is_empty());
        assert!(bitcoind_client.has_broadcast(tx_details.txid));

        Ok(())
    }
}

'''
'''--- kld/src/wallet/mod.rs ---
mod bdk_wallet;
mod wallet_interface;

pub use bdk_wallet::Wallet;
pub use wallet_interface::WalletInterface;

'''
'''--- kld/src/wallet/wallet_interface.rs ---
use crate::api::payloads::FeeRate;
use anyhow::Result;
use async_trait::async_trait;
use bdk::{wallet::AddressInfo, Balance, LocalUtxo, TransactionDetails};
use bitcoin::address::NetworkUnchecked;
use bitcoin::{Address, OutPoint, Transaction};

#[async_trait]
pub trait WalletInterface {
    fn balance(&self) -> Result<Balance>;

    /// Set amount to u64::MAX to drain the wallet.
    async fn transfer(
        &self,
        address: Address<NetworkUnchecked>,
        amount: u64,
        fee_rate: Option<FeeRate>,
        min_conf: Option<u8>,
        utxos: Vec<OutPoint>,
    ) -> Result<(Transaction, TransactionDetails)>;

    fn new_external_address(&self) -> Result<AddressInfo>;

    fn new_internal_address(&self) -> Result<AddressInfo>;

    fn list_utxos(&self) -> Result<Vec<(LocalUtxo, TransactionDetails)>>;
}

'''
'''--- kld/tests/api/cli.rs ---
use std::{
    process::{Command, Output},
    time::{SystemTime, UNIX_EPOCH},
};

use anyhow::{bail, Result};
use kld::api::codegen::{
    get_kld_channel_response::GetKldChannelResponseItem,
    get_v1_channel_history_response::GetV1ChannelHistoryResponseItem,
    get_v1_channel_list_forwards_response::GetV1ChannelListForwardsResponseItem,
    get_v1_channel_list_peer_channels_response::GetV1ChannelListPeerChannelsResponse,
    get_v1_channel_localremotebal_response::GetV1ChannelLocalremotebalResponse,
    get_v1_estimate_channel_liquidity_response::GetV1EstimateChannelLiquidityResponse,
    get_v1_get_fees_response::GetV1GetFeesResponse, get_v1_newaddr_response::GetV1NewaddrResponse,
    get_v1_pay_list_payments_response::GetV1PayListPaymentsResponse,
    post_v1_peer_connect_response::PostV1PeerConnectResponse,
};
use kld::api::payloads::{
    FeeRatesResponse, FundChannelResponse, GenerateInvoiceResponse, GetInfo, Invoice, ListFunds,
    NetworkChannel, NetworkNode, PaymentResponse, Peer, SetChannelFeeResponse, SignResponse,
    WalletBalance, WalletTransferResponse,
};

use super::rest::create_api_server;
use crate::api::rest::mock_lightning;
use serde::de;
use test_utils::{TEST_ADDRESS, TEST_PUBLIC_KEY, TEST_SHORT_CHANNEL_ID};

#[tokio::test]
async fn test_cli_get_info() -> Result<()> {
    let output = run_cli("get-info", &[]).await?;
    let _: GetInfo = deserialize(&output.stdout)?;
    Ok(())
}

#[tokio::test]
async fn test_sign() -> Result<()> {
    let output = run_cli("sign", &["testmessage"]).await?;
    let _: SignResponse = deserialize(&output.stdout)?;
    Ok(())
}

#[tokio::test]
async fn test_cli_get_balance() -> Result<()> {
    let output = run_cli("get-balance", &[]).await?;
    let _: WalletBalance = deserialize(&output.stdout)?;
    Ok(())
}

#[tokio::test]
async fn test_cli_new_address() -> Result<()> {
    let output = run_cli("new-address", &[]).await?;
    let _: GetV1NewaddrResponse = deserialize(&output.stdout)?;
    Ok(())
}

#[tokio::test]
async fn test_cli_withdraw() -> Result<()> {
    let output = run_cli(
        "withdraw",
        &[TEST_ADDRESS, "1000", "--fee-rate", "3000perkw"],
    )
    .await?;
    let _: WalletTransferResponse = deserialize(&output.stdout)?;
    Ok(())
}

#[tokio::test]
async fn test_cli_list_funds() -> Result<()> {
    let output = run_cli("list-funds", &[]).await?;
    let _: ListFunds = deserialize(&output.stdout)?;
    Ok(())
}

#[tokio::test]
async fn test_cli_list_peer_channels() -> Result<()> {
    let output = run_cli("list-peer-channels", &[]).await?;
    let _: Vec<GetV1ChannelListPeerChannelsResponse> = deserialize(&output.stdout)?;
    Ok(())
}

#[tokio::test]
async fn test_cli_list_peers() -> Result<()> {
    let output = run_cli("list-peers", &[]).await?;
    let _: Vec<Peer> = deserialize(&output.stdout)?;
    Ok(())
}

#[tokio::test]
async fn test_cli_connect_peer() -> Result<()> {
    let output = run_cli("connect-peer", &[TEST_PUBLIC_KEY]).await?;
    let _: PostV1PeerConnectResponse = deserialize(&output.stdout)?;
    Ok(())
}

#[tokio::test]
async fn test_cli_disconnect_peer() -> Result<()> {
    let output = run_cli("disconnect-peer", &[TEST_PUBLIC_KEY]).await?;

    assert!(&output.stdout.is_empty());
    Ok(())
}

#[tokio::test]
async fn test_cli_open_channel() -> Result<()> {
    let output = run_cli(
        "open-channel",
        &[
            TEST_PUBLIC_KEY,
            "1000",
            "--announce",
            "false",
            "--fee-rate",
            "urgent",
        ],
    )
    .await?;
    let _: FundChannelResponse = deserialize(&output.stdout)?;
    Ok(())
}

#[tokio::test]
async fn test_cli_set_channel_fee() -> Result<()> {
    let output = run_cli(
        "set-channel-fee",
        &[
            &TEST_SHORT_CHANNEL_ID.to_string(),
            "--base-fee",
            "1000",
            "--ppm-fee",
            "200",
        ],
    )
    .await?;
    let _: SetChannelFeeResponse = deserialize(&output.stdout)?;
    Ok(())
}

#[tokio::test]
async fn test_cli_set_channel_fee_all() -> Result<()> {
    let output = run_cli(
        "set-channel-fee",
        &["all", "--base-fee", "1000", "--ppm-fee", "200"],
    )
    .await?;
    let _: SetChannelFeeResponse = deserialize(&output.stdout)?;
    Ok(())
}

#[tokio::test]
async fn test_cli_close_channel() -> Result<()> {
    let output = run_cli("close-channel", &[&TEST_SHORT_CHANNEL_ID.to_string()]).await?;
    assert!(output.stdout.is_empty());
    Ok(())
}

#[tokio::test]
async fn test_cli_get_network_node() -> Result<()> {
    let output = run_cli("network-nodes", &["--id", TEST_PUBLIC_KEY]).await?;
    let nodes: Vec<NetworkNode> = deserialize(&output.stdout)?;
    assert!(!nodes.is_empty());
    Ok(())
}

#[tokio::test]
async fn test_cli_list_network_nodes() -> Result<()> {
    let output = run_cli("network-nodes", &[]).await?;
    let nodes: Vec<NetworkNode> = deserialize(&output.stdout)?;
    assert!(!nodes.is_empty());
    Ok(())
}

#[tokio::test]
async fn test_cli_get_network_channel() -> Result<()> {
    let output = run_cli("network-channels", &["--id", "1234"]).await?;
    let result = String::from_utf8(output.stdout)?;
    assert!(result.contains("404"));
    Ok(())
}

#[tokio::test]
async fn test_cli_list_network_channels() -> Result<()> {
    let output = run_cli("network-channels", &[]).await?;
    let channels: Vec<NetworkChannel> = deserialize(&output.stdout)?;
    assert!(channels.is_empty());
    Ok(())
}

#[tokio::test]
async fn test_cli_fee_rates() -> Result<()> {
    let output = run_cli("fee-rates", &[]).await?;
    let fee_rates: FeeRatesResponse = deserialize(&output.stdout)?;
    assert!(fee_rates.perkb.is_some());
    Ok(())
}

#[tokio::test]
async fn test_cli_keysend() -> Result<()> {
    let output = run_cli("keysend", &[TEST_PUBLIC_KEY, "102000"]).await?;
    let _: PaymentResponse = deserialize(&output.stdout)?;
    Ok(())
}

#[tokio::test]
async fn test_cli_generate_invoice() -> Result<()> {
    let output = run_cli(
        "generate-invoice",
        &[
            "1234567890",
            "test invoice",
            "test description",
            "--expiry",
            &(SystemTime::now().duration_since(UNIX_EPOCH)?.as_secs() + 3600).to_string(),
        ],
    )
    .await?;
    let _: GenerateInvoiceResponse = deserialize(&output.stdout)?;
    Ok(())
}

#[tokio::test]
async fn test_cli_list_invoices() -> Result<()> {
    let output = run_cli("list-invoices", &["--label", "a label"]).await?;
    let _: Vec<Invoice> = deserialize(&output.stdout)?;
    Ok(())
}

#[tokio::test]
async fn test_cli_pay_invoice() -> Result<()> {
    let bolt11 = mock_lightning().invoice.bolt11.to_string();
    let output = run_cli("pay-invoice", &[&bolt11, "-l", "a label"]).await?;
    let _: PaymentResponse = deserialize(&output.stdout)?;
    Ok(())
}

#[tokio::test]
async fn test_cli_list_payments() -> Result<()> {
    let output = run_cli(
        "list-payments",
        &["--bolt11", "bolt11", "--direction", "inbound"],
    )
    .await?;
    let _: GetV1PayListPaymentsResponse = deserialize(&output.stdout)?;
    Ok(())
}

#[tokio::test]
async fn test_cli_estimate_channel_liquidity() -> Result<()> {
    let output = run_cli(
        "estimate-channel-liquidity",
        &[&TEST_SHORT_CHANNEL_ID.to_string(), TEST_PUBLIC_KEY],
    )
    .await?;
    let _: GetV1EstimateChannelLiquidityResponse = deserialize(&output.stdout)?;
    Ok(())
}

#[tokio::test]
async fn test_cli_local_remote_balance() -> Result<()> {
    let output = run_cli("local-remote-balance", &[]).await?;
    let _: GetV1ChannelLocalremotebalResponse = deserialize(&output.stdout)?;
    Ok(())
}

#[tokio::test]
async fn test_cli_get_fees() -> Result<()> {
    let output = run_cli("get-fees", &[]).await?;
    let _: GetV1GetFeesResponse = deserialize(&output.stdout)?;
    Ok(())
}

#[tokio::test]
async fn test_cli_list_forwards() -> Result<()> {
    let output = run_cli("list-forwards", &["--status", "settled"]).await?;
    let _: Vec<GetV1ChannelListForwardsResponseItem> = deserialize(&output.stdout)?;
    Ok(())
}

#[tokio::test]
async fn test_cli_channel_history() -> Result<()> {
    let output = run_cli("list-channel-history", &[]).await?;
    let _: Vec<GetV1ChannelHistoryResponseItem> = deserialize(&output.stdout)?;
    Ok(())
}

#[tokio::test]
async fn test_cli_list_channels() -> Result<()> {
    let output = run_cli("list-channels", &[]).await?;
    let _: Vec<GetKldChannelResponseItem> = deserialize(&output.stdout)?;
    Ok(())
}

fn deserialize<'a, T>(bytes: &'a [u8]) -> Result<T>
where
    T: de::Deserialize<'a>,
{
    match serde_json::from_slice::<T>(bytes) {
        Ok(t) => Ok(t),
        Err(_) => {
            let s = String::from_utf8_lossy(bytes);
            bail!("Expected json output, but got: {}", s)
        }
    }
}

async fn run_cli(command: &str, extra_args: &[&str]) -> Result<Output> {
    let context = create_api_server().await?;

    let output = Command::new(env!("CARGO_BIN_EXE_kld-cli"))
        .args([
            "--target",
            &context.settings.rest_api_address,
            "--cert-path",
            &format!("{}/kld.crt", context.settings.certs_dir),
            "--macaroon-path",
            &format!("{}/macaroons/admin.macaroon", context.settings.data_dir),
            command,
        ])
        .args(extra_args)
        .output()
        .unwrap();

    if !output.status.success() {
        panic!("{}", String::from_utf8(output.stderr).unwrap());
    }
    Ok(output)
}

'''
'''--- kld/tests/api/mod.rs ---
mod cli;
mod prometheus;
mod rest;

'''
'''--- kld/tests/api/prometheus.rs ---
use anyhow::{Context, Result};
use async_trait::async_trait;
use futures::FutureExt;
use lightning::chain::chaininterface::ConfirmationTarget;
use prometheus::IntCounter;
use std::sync::Arc;
use std::sync::OnceLock;
use test_utils::{poll, ports::get_available_port};
use time::OffsetDateTime;

use crate::{mocks::mock_lightning::MockLightning, quit_signal};
use kld::{
    bitcoind::BitcoindMetrics, database::DBConnection, prometheus::start_prometheus_exporter,
    Service,
};

static PROBE_TOTAL_COUNT: OnceLock<IntCounter> = OnceLock::new();
static PROBE_SUCCESSFUL_COUNT: OnceLock<IntCounter> = OnceLock::new();
static PROBE_FAILED_COUNT: OnceLock<IntCounter> = OnceLock::new();

#[tokio::test(flavor = "multi_thread")]
pub async fn test_prometheus() -> Result<()> {
    let port = get_available_port().context("no port")?;
    let address = format!("127.0.0.1:{port}");

    let metrics = Arc::new(MockLightning::default());

    let database = Arc::new(MockService(true, true));
    let bitcoind = Arc::new(MockService(true, false));

    tokio::spawn(start_prometheus_exporter(
        address.clone(),
        metrics.clone(),
        database,
        bitcoind,
        quit_signal().shared(),
        (
            &PROBE_TOTAL_COUNT,
            &PROBE_SUCCESSFUL_COUNT,
            &PROBE_FAILED_COUNT,
        ),
    ));
    poll!(3, call_exporter(&address, "health").await.is_ok());

    let health = call_exporter(&address, "health").await?;
    assert_eq!(health, "SYNCING");

    let pid = call_exporter(&address, "pid").await?;
    assert_eq!(pid, std::process::id().to_string());

    let result = call_exporter(&address, "metrics").await?;
    assert!(get_metric(&result, "uptime").is_ok());
    assert_eq!(
        get_metric(&result, "node_count")?,
        format!("{}", metrics.num_nodes)
    );
    assert_eq!(
        get_metric(&result, "network_channel_count")?,
        format!("{}", metrics.num_channels)
    );
    assert_eq!(get_metric(&result, "channel_count")?, "1".to_string());
    assert_eq!(
        get_metric(&result, "peer_count")?,
        format!("{}", metrics.num_peers)
    );
    assert_eq!(
        get_metric(&result, "wallet_balance")?,
        format!("{}", metrics.wallet_balance)
    );
    assert_eq!(get_metric(&result, "channel_count")?, "1".to_string());
    assert_eq!(
        get_metric(&result, "channel_balance")?,
        format!("{}", metrics.channel.balance_msat / 1000)
    );
    assert_eq!(
        get_metric(&result, "fee")?,
        format!(
            "{}",
            metrics
                .forward
                .fee
                .expect("test should have fee in forward channel")
        )
    );
    assert_eq!(get_metric(&result, "block_height")?, "1000".to_string());

    let not_found = call_exporter(&address, "wrong").await?;
    assert_eq!(not_found, "Not Found");
    Ok(())
}

struct MockService(bool, bool);

#[async_trait]
impl Service for MockService {
    async fn is_connected(&self) -> bool {
        self.0
    }
    async fn is_synchronised(&self) -> bool {
        self.1
    }
}

#[async_trait]
impl DBConnection for MockService {
    async fn open_channel_count(&self) -> Result<i64> {
        Ok(1)
    }
    async fn fetch_scorer_update_time(&self) -> Result<OffsetDateTime> {
        Ok(OffsetDateTime::from_unix_timestamp(0).unwrap())
    }
}

#[async_trait]
impl BitcoindMetrics for MockService {
    async fn block_height(&self) -> Result<u32> {
        Ok(1000)
    }
    fn fee_for(&self, _target: ConfirmationTarget) -> u32 {
        0
    }
}

async fn call_exporter(address: &str, method: &str) -> Result<String, reqwest::Error> {
    reqwest::get(format!("http://{address}/{method}"))
        .await?
        .text()
        .await
}

fn get_metric<'a>(metrics: &'a str, name: &str) -> Result<&'a str> {
    metrics
        .lines()
        .find(|x| x.starts_with(name))
        .with_context(|| "Metric not found")?
        .split(' ')
        .last()
        .with_context(|| "Bad metric format")
}

'''
'''--- kld/tests/api/rest.rs ---
use std::assert_eq;
use std::net::SocketAddr;
use std::sync::OnceLock;
use std::thread::spawn;
use std::time::{SystemTime, UNIX_EPOCH};
use std::{fs, sync::Arc};

use anyhow::{Context, Result};
use futures::FutureExt;
use hyper::Method;
use kld::api::bind_api_server;
use kld::api::codegen::get_kld_channel_response::GetKldChannelResponseItem;
use kld::api::codegen::get_v1_channel_history_response::GetV1ChannelHistoryResponseItem;
use kld::api::codegen::get_v1_channel_list_forwards_response::GetV1ChannelListForwardsResponseItem;
use kld::api::codegen::get_v1_channel_list_peer_channels_response::{
    GetV1ChannelListPeerChannelsResponse, GetV1ChannelListPeerChannelsResponseState,
};
use kld::api::codegen::get_v1_channel_localremotebal_response::GetV1ChannelLocalremotebalResponse;
use kld::api::codegen::get_v1_estimate_channel_liquidity_body::GetV1EstimateChannelLiquidityBody;
use kld::api::codegen::get_v1_estimate_channel_liquidity_response::GetV1EstimateChannelLiquidityResponse;
use kld::api::codegen::get_v1_get_fees_response::GetV1GetFeesResponse;
use kld::api::codegen::get_v1_newaddr_response::GetV1NewaddrResponse;
use kld::api::codegen::get_v1_pay_list_payments_response::{
    GetV1PayListPaymentsResponse, GetV1PayListPaymentsResponsePaymentsItemStatus,
};
use kld::api::codegen::get_v1_utility_decode_invoice_string_response::{
    GetV1UtilityDecodeInvoiceStringResponse, GetV1UtilityDecodeInvoiceStringResponseType,
};
use kld::api::codegen::post_v1_peer_connect_body::PostV1PeerConnectBody;
use kld::api::codegen::post_v1_peer_connect_response::PostV1PeerConnectResponse;
use kld::api::MacaroonAuth;
use kld::database::payment::PaymentStatus;
use kld::logger::KldLogger;
use kld::settings::Settings;
use lightning::events::ClosureReason;
use reqwest::RequestBuilder;
use reqwest::StatusCode;
use serde::Serialize;
use test_utils::ports::get_available_port;
use test_utils::{
    https_client, poll, test_settings, TempDir, TEST_ADDRESS, TEST_ALIAS, TEST_PUBLIC_KEY,
    TEST_SHORT_CHANNEL_ID, TEST_TX, TEST_TX_ID,
};

use kld::api::payloads::{
    ChannelFee, ChannelState, FeeRate, FeeRatesResponse, FundChannel, FundChannelResponse,
    GenerateInvoice, GenerateInvoiceResponse, GetInfo, Invoice, InvoiceStatus, KeysendRequest,
    ListFunds, NetworkChannel, NetworkNode, OutputStatus, PayInvoice, PaymentResponse, Peer,
    SetChannelFeeResponse, SignRequest, SignResponse, WalletBalance, WalletTransfer,
    WalletTransferResponse,
};
use kld::api::routes;
use tokio::runtime::Runtime;
use tokio::sync::RwLock;

use crate::mocks::mock_bitcoind::MockBitcoind;
use crate::mocks::mock_lightning::MockLightning;
use crate::mocks::mock_wallet::MockWallet;
use crate::quit_signal;

#[tokio::test(flavor = "multi_thread")]
pub async fn test_unauthorized() -> Result<()> {
    let context = create_api_server().await?;
    let admin_functions = vec![
        (Method::POST, routes::SIGN),
        (Method::POST, routes::OPEN_CHANNEL),
        (Method::POST, routes::SET_CHANNEL_FEE),
        (Method::DELETE, routes::CLOSE_CHANNEL),
        (Method::DELETE, routes::FORCE_CLOSE_CHANNEL_WITH_BROADCAST),
        (
            Method::DELETE,
            routes::FORCE_CLOSE_CHANNEL_WITHOUT_BROADCAST,
        ),
        (Method::POST, routes::WITHDRAW),
        (Method::GET, routes::NEW_ADDR),
        (Method::POST, routes::CONNECT_PEER),
        (Method::DELETE, routes::DISCONNECT_PEER),
        (Method::POST, routes::KEYSEND),
        (Method::POST, routes::GENERATE_INVOICE),
        (Method::POST, routes::PAY_INVOICE),
    ];
    for (method, route) in &admin_functions {
        assert_eq!(
            StatusCode::UNAUTHORIZED,
            readonly_request_with_body(&context, method.clone(), route, || ())?
                .send()
                .await?
                .status()
        );
    }
    let mut readonly_functions = vec![
        (Method::GET, routes::ROOT),
        (Method::GET, routes::GET_INFO),
        (Method::GET, routes::GET_BALANCE),
        (Method::GET, routes::LIST_FUNDS),
        (Method::GET, routes::LIST_PEERS),
        (Method::GET, routes::LIST_NETWORK_NODE),
        (Method::GET, routes::LIST_NETWORK_NODES),
        (Method::GET, routes::LIST_NETWORK_CHANNEL),
        (Method::GET, routes::LIST_NETWORK_CHANNELS),
        (Method::GET, routes::FEE_RATES),
        (Method::GET, routes::LIST_INVOICES),
        (Method::GET, routes::LIST_PAYMENTS),
        (Method::GET, routes::ESTIMATE_CHANNEL_LIQUIDITY),
        (Method::GET, routes::LOCAL_REMOTE_BALANCE),
        (Method::GET, routes::GET_FEES),
        (Method::GET, routes::LIST_FORWARDS),
        (Method::GET, routes::LIST_CHANNEL_HISTORY),
        (Method::GET, routes::LIST_PEER_CHANNELS),
        (Method::GET, routes::DECODE_INVOICE),
    ];
    readonly_functions.extend(admin_functions.into_iter());
    for (method, route) in readonly_functions {
        assert_eq!(
            StatusCode::UNAUTHORIZED,
            unauthorized_request(&context, method, route)
                .unwrap()
                .send()
                .await?
                .status()
        );
    }
    Ok(())
}

#[tokio::test(flavor = "multi_thread")]
async fn test_not_found() -> Result<()> {
    let context = create_api_server().await?;
    assert_eq!(
        StatusCode::NOT_FOUND,
        admin_request(&context, Method::GET, "/x")?
            .send()
            .await?
            .status()
    );
    Ok(())
}

#[tokio::test(flavor = "multi_thread")]
async fn test_root_readonly() -> Result<()> {
    let context = create_api_server().await?;
    assert!(readonly_request(&context, Method::GET, routes::ROOT)?
        .send()
        .await?
        .status()
        .is_success());
    Ok(())
}

#[tokio::test(flavor = "multi_thread")]
async fn test_root_admin() -> Result<()> {
    let context = create_api_server().await?;
    assert!(admin_request(&context, Method::GET, routes::ROOT)?
        .send()
        .await?
        .status()
        .is_success());
    Ok(())
}

#[tokio::test(flavor = "multi_thread")]
async fn test_sign_admin() -> Result<()> {
    let context = create_api_server().await?;
    let response: SignResponse =
        admin_request_with_body(&context, Method::POST, routes::SIGN, || SignRequest {
            message: "testmessage".to_string(),
        })?
        .send()
        .await?
        .json()
        .await?;
    assert_eq!("1234abcd", response.signature);
    Ok(())
}

#[tokio::test(flavor = "multi_thread")]
async fn test_get_info_readonly() -> Result<()> {
    let context = create_api_server().await?;
    let info: GetInfo = readonly_request(&context, Method::GET, routes::GET_INFO)?
        .send()
        .await?
        .json()
        .await?;
    assert_eq!(info.address, vec!["127.0.0.1:2312", "[2001:db8::1]:8080"]);
    assert_eq!(mock_lightning().num_peers, info.num_peers);
    Ok(())
}

#[tokio::test(flavor = "multi_thread")]
async fn test_get_balance_readonly() -> Result<()> {
    let context = create_api_server().await?;
    let balance: WalletBalance = readonly_request(&context, Method::GET, routes::GET_BALANCE)?
        .send()
        .await?
        .json()
        .await?;
    assert_eq!(9, balance.total_balance);
    assert_eq!(4, balance.conf_balance);
    assert_eq!(5, balance.unconf_balance);
    Ok(())
}

#[tokio::test(flavor = "multi_thread")]
async fn test_list_funds_readonly() -> Result<()> {
    let context = create_api_server().await?;
    let funds: ListFunds = readonly_request(&context, Method::GET, routes::LIST_FUNDS)?
        .send()
        .await?
        .json()
        .await?;

    let output = funds.outputs.first().context("Missing output")?;
    assert_eq!(TEST_TX_ID, output.txid);
    assert_eq!(0, output.output);
    assert_eq!(546000, output.amount_msat);
    assert_eq!(
        "bc1prx7399hvfe8hta6lfn2qncvczxjeur5cwlrpxhwrzqssj9kuqpeqchh5xf",
        output.address
    );
    assert_eq!(93, output.scriptpubkey.len());
    assert_eq!(OutputStatus::Confirmed, output.status);
    assert_eq!(Some(600000), output.block_height);

    let channel = funds.channels.first().context("Missing channel")?;
    assert_eq!(TEST_PUBLIC_KEY, channel.peer_id);
    assert!(channel.connected);
    assert_eq!(ChannelState::Usable, channel.state);
    assert_eq!(TEST_SHORT_CHANNEL_ID.to_string(), channel.short_channel_id);
    assert_eq!(1000000, channel.channel_sat);
    assert_eq!(100000, channel.our_amount_msat);
    assert_eq!(1000000000, channel.amount_msat);
    assert_eq!(TEST_TX_ID, channel.funding_txid);
    assert_eq!(2, channel.funding_output);
    Ok(())
}

#[tokio::test(flavor = "multi_thread")]
async fn test_list_channels_readonly() -> Result<()> {
    let context = create_api_server().await?;
    let channels: Vec<GetKldChannelResponseItem> =
        readonly_request(&context, Method::GET, routes::LIST_CHANNELS)?
            .send()
            .await?
            .json()
            .await?;
    let channel = channels.first().context("Missing channel")?;
    assert_eq!(Some(TEST_SHORT_CHANNEL_ID), channel.short_channel_id);
    assert_eq!(format!("{TEST_TX_ID}:2"), channel.funding_txo);
    assert!(channel.is_public);
    assert!(channel.is_usable);
    assert_eq!(
        vec![
            "supported SCIDPrivacy".to_string(),
            "required ZeroConf".to_string()
        ],
        channel.features
    );
    Ok(())
}

#[tokio::test(flavor = "multi_thread")]
async fn test_list_peer_channels_readonly() -> Result<()> {
    let context = create_api_server().await?;
    let channels: Vec<GetV1ChannelListPeerChannelsResponse> =
        readonly_request(&context, Method::GET, routes::LIST_PEER_CHANNELS)?
            .send()
            .await?
            .json()
            .await?;
    let channel = channels.first().context("Missing channel")?;
    assert_eq!(TEST_PUBLIC_KEY, channel.peer_id);
    assert!(channel.peer_connected);
    assert_eq!(
        Some(TEST_SHORT_CHANNEL_ID.to_string()),
        channel.short_channel_id
    );
    assert_eq!(Some(TEST_TX_ID.to_string()), channel.funding_txid);
    assert!(!channel.private);
    assert!(matches!(
        channel.state,
        GetV1ChannelListPeerChannelsResponseState::ChanneldNormal
    ));
    assert_eq!(100000, channel.to_us_msat);
    assert_eq!(1000000000, channel.total_msat);
    assert_eq!(999900000, channel.to_them_msat);
    assert_eq!(5000000, channel.their_reserve_msat);
    assert_eq!(Some(10000000), channel.our_reserve_msat);
    assert_eq!(100000, channel.spendable_msat);
    assert_eq!(TEST_ALIAS, channel.alias);
    assert_eq!(5000, channel.dust_limit_msat);
    assert_eq!(
        vec![
            "supported SCIDPrivacy".to_string(),
            "required ZeroConf".to_string()
        ],
        channel.features
    );
    assert_eq!(1000, channel.fee_base_msat);
    assert_eq!(0, channel.fee_proportional_millionths);
    Ok(())
}

#[tokio::test(flavor = "multi_thread")]
async fn test_open_channel_admin() -> Result<()> {
    let context = create_api_server().await?;
    let response: FundChannelResponse = admin_request_with_body(
        &context,
        Method::POST,
        routes::OPEN_CHANNEL,
        fund_channel_request,
    )?
    .send()
    .await?
    .json()
    .await?;
    assert_eq!(TEST_TX_ID, response.txid);
    assert_eq!(
        "0101010101010101010101010101010101010101010101010101010101010101",
        response.channel_id
    );
    Ok(())
}

#[tokio::test(flavor = "multi_thread")]
async fn test_set_channel_fee_admin() -> Result<()> {
    let context = create_api_server().await?;
    let response: SetChannelFeeResponse = admin_request_with_body(
        &context,
        Method::POST,
        routes::SET_CHANNEL_FEE,
        set_channel_fee_request,
    )?
    .send()
    .await?
    .json()
    .await?;

    let fee = response.0.first().context("Bad response")?;
    assert_eq!(TEST_SHORT_CHANNEL_ID.to_string(), fee.short_channel_id);
    assert_eq!(TEST_PUBLIC_KEY, fee.peer_id);
    assert_eq!(set_channel_fee_request().base, Some(fee.base));
    assert_eq!(set_channel_fee_request().ppm, Some(fee.ppm));
    Ok(())
}

#[tokio::test(flavor = "multi_thread")]
async fn test_set_all_channel_fees_admin() -> Result<()> {
    let context = create_api_server().await?;
    let request = ChannelFee {
        id: "all".to_string(),
        base: Some(32500),
        ppm: Some(1200),
    };
    let response: SetChannelFeeResponse =
        admin_request_with_body(&context, Method::POST, routes::SET_CHANNEL_FEE, || {
            request.clone()
        })?
        .send()
        .await?
        .json()
        .await?;

    let fee = response.0.first().context("Bad response")?;
    assert_eq!(TEST_SHORT_CHANNEL_ID.to_string(), fee.short_channel_id);
    assert_eq!(TEST_PUBLIC_KEY, fee.peer_id);
    assert_eq!(request.base, Some(fee.base));
    assert_eq!(request.ppm, Some(fee.ppm));
    Ok(())
}

#[tokio::test(flavor = "multi_thread")]
async fn test_close_channel_admin() -> Result<()> {
    let context = create_api_server().await?;
    let result = admin_request(
        &context,
        Method::DELETE,
        &routes::CLOSE_CHANNEL.replace(":id", &TEST_SHORT_CHANNEL_ID.to_string()),
    )?
    .send()
    .await?;
    assert!(result.status().is_success());
    Ok(())
}

#[tokio::test(flavor = "multi_thread")]
async fn test_force_close_channel_with_broadcast_admin() -> Result<()> {
    let context = create_api_server().await?;
    let result = admin_request(
        &context,
        Method::DELETE,
        &routes::FORCE_CLOSE_CHANNEL_WITH_BROADCAST
            .replace(":id", &TEST_SHORT_CHANNEL_ID.to_string()),
    )?
    .send()
    .await?;
    assert!(result.status().is_success());
    Ok(())
}

#[tokio::test(flavor = "multi_thread")]
async fn test_force_close_channel_without_broadcast_admin() -> Result<()> {
    let context = create_api_server().await?;
    let result = admin_request(
        &context,
        Method::DELETE,
        &routes::FORCE_CLOSE_CHANNEL_WITHOUT_BROADCAST
            .replace(":id", &TEST_SHORT_CHANNEL_ID.to_string()),
    )?
    .send()
    .await?;
    assert!(result.status().is_success());
    Ok(())
}

#[tokio::test(flavor = "multi_thread")]
async fn test_withdraw_admin() -> Result<()> {
    let context = create_api_server().await?;
    let response: WalletTransferResponse =
        admin_request_with_body(&context, Method::POST, routes::WITHDRAW, withdraw_request)?
            .send()
            .await?
            .json()
            .await?;
    assert_eq!(TEST_TX, response.tx);
    assert_eq!(TEST_TX_ID, response.txid);
    Ok(())
}

#[tokio::test(flavor = "multi_thread")]
async fn test_new_address_admin() -> Result<()> {
    let context = create_api_server().await?;
    let response: GetV1NewaddrResponse = admin_request(&context, Method::GET, routes::NEW_ADDR)?
        .query(&[("addressType", "bech32")])
        .send()
        .await?
        .json()
        .await?;
    assert_eq!(TEST_ADDRESS.to_string(), response.address);
    Ok(())
}

#[tokio::test(flavor = "multi_thread")]
async fn test_list_peers_readonly() -> Result<()> {
    let context = create_api_server().await?;
    let response: Vec<Peer> = readonly_request(&context, Method::GET, routes::LIST_PEERS)?
        .send()
        .await?
        .json()
        .await?;
    let socket_addr: SocketAddr = "127.0.0.1:5555".parse().unwrap();
    let netaddr = Some(socket_addr.to_string());
    assert!(response.contains(&Peer {
        id: TEST_PUBLIC_KEY.to_string(),
        connected: true,
        netaddr,
        alias: TEST_ALIAS.to_string()
    }));
    Ok(())
}

#[tokio::test(flavor = "multi_thread")]
async fn test_connect_peer_admin() -> Result<()> {
    let context = create_api_server().await?;
    let response: PostV1PeerConnectResponse =
        admin_request_with_body(&context, Method::POST, routes::CONNECT_PEER, || {
            PostV1PeerConnectBody {
                id: format!("{}@1.0.0.0:1111", TEST_PUBLIC_KEY),
            }
        })?
        .send()
        .await?
        .json()
        .await?;
    assert_eq!(TEST_PUBLIC_KEY, response.id);
    Ok(())
}

#[tokio::test(flavor = "multi_thread")]
async fn test_disconnect_peer_admin() -> Result<()> {
    let context = create_api_server().await?;
    let response = admin_request(
        &context,
        Method::DELETE,
        &routes::DISCONNECT_PEER.replace(":id", TEST_PUBLIC_KEY),
    )?
    .send()
    .await?;
    assert!(response.status().is_success());
    Ok(())
}

#[tokio::test(flavor = "multi_thread")]
async fn test_disconnect_peer_admin_malformed_key() -> Result<()> {
    let context = create_api_server().await?;
    let response: kld::api::payloads::Error = admin_request(
        &context,
        Method::DELETE,
        &routes::DISCONNECT_PEER.replace(":id", "abcd"),
    )?
    .send()
    .await?
    .json()
    .await?;
    assert_eq!(response.status, StatusCode::BAD_REQUEST.to_string());
    Ok(())
}

#[tokio::test(flavor = "multi_thread")]
async fn test_list_network_node_readonly() -> Result<()> {
    let context = create_api_server().await?;
    let nodes: Vec<NetworkNode> = readonly_request(
        &context,
        Method::GET,
        &routes::LIST_NETWORK_NODE.replace(":id", TEST_PUBLIC_KEY),
    )?
    .send()
    .await?
    .json()
    .await?;
    let node = nodes.first().context("no node in response")?;
    assert_eq!(TEST_PUBLIC_KEY, node.node_id);
    assert_eq!(TEST_ALIAS, node.alias);
    assert_eq!("010203", node.color);
    assert_eq!(21000000, node.last_timestamp);
    assert!(!node.features.is_empty());
    Ok(())
}

#[tokio::test(flavor = "multi_thread")]
async fn test_list_network_nodes_readonly() -> Result<()> {
    let context = create_api_server().await?;
    let nodes: Vec<NetworkNode> =
        readonly_request(&context, Method::GET, routes::LIST_NETWORK_NODES)?
            .send()
            .await?
            .json()
            .await?;
    assert_eq!(
        TEST_PUBLIC_KEY,
        nodes.first().context("bad result")?.node_id
    );
    Ok(())
}

#[tokio::test(flavor = "multi_thread")]
async fn test_list_network_channel_readonly() -> Result<()> {
    let context = create_api_server().await?;
    let response = readonly_request(
        &context,
        Method::GET,
        &routes::LIST_NETWORK_CHANNEL.replace(":id", "123456789"),
    )?
    .send()
    .await?;
    assert_eq!(response.status(), StatusCode::NOT_FOUND);
    Ok(())
}

#[tokio::test(flavor = "multi_thread")]
async fn test_list_network_channels_readonly() -> Result<()> {
    let context = create_api_server().await?;
    let _channels: Vec<NetworkChannel> =
        readonly_request(&context, Method::GET, routes::LIST_NETWORK_CHANNELS)?
            .send()
            .await?
            .json()
            .await?;
    Ok(())
}

#[tokio::test(flavor = "multi_thread")]
async fn test_fee_rates() -> Result<()> {
    let context = create_api_server().await?;
    let fee_rates: FeeRatesResponse = readonly_request(
        &context,
        Method::GET,
        &routes::FEE_RATES.replace(":style", "perkb"),
    )?
    .send()
    .await?
    .json()
    .await?;
    let perkb = fee_rates.perkb.context("expected perkb fee rate")?;
    assert_eq!(1600000, perkb.urgent);
    assert_eq!(800000, perkb.normal);
    assert_eq!(400000, perkb.slow);
    assert_eq!(3101, perkb.min_acceptable);
    assert_eq!(1600000, perkb.max_acceptable);
    assert_eq!(
        121600,
        fee_rates.onchain_fee_estimates.opening_channel_satoshis
    );
    assert_eq!(
        104000,
        fee_rates.onchain_fee_estimates.mutual_close_satoshis
    );
    assert_eq!(
        120000,
        fee_rates.onchain_fee_estimates.unilateral_close_satoshis
    );

    let fee_rates: FeeRatesResponse = readonly_request(
        &context,
        Method::GET,
        &routes::FEE_RATES.replace(":style", "perkw"),
    )?
    .send()
    .await?
    .json()
    .await?;

    let perkw = fee_rates.perkw.context("expected perkw fee rate")?;
    assert_eq!(400000, perkw.urgent);
    assert_eq!(200000, perkw.normal);
    assert_eq!(100000, perkw.slow);
    assert_eq!(775, perkw.min_acceptable);
    assert_eq!(400000, perkw.max_acceptable);
    assert_eq!(
        121600,
        fee_rates.onchain_fee_estimates.opening_channel_satoshis
    );
    assert_eq!(
        104000,
        fee_rates.onchain_fee_estimates.mutual_close_satoshis
    );
    assert_eq!(
        120000,
        fee_rates.onchain_fee_estimates.unilateral_close_satoshis
    );
    Ok(())
}

#[tokio::test(flavor = "multi_thread")]
async fn test_generate_invoice() -> Result<()> {
    let context = create_api_server().await?;
    let expiry = SystemTime::now().duration_since(UNIX_EPOCH)?.as_secs() as u32;
    let invoice_request = GenerateInvoice {
        amount: 400004,
        label: "test label".to_string(),
        description: "test description".to_string(),
        expiry: Some(expiry),
        private: None,
        fallbacks: None,
        preimage: None,
    };
    let response: GenerateInvoiceResponse =
        admin_request_with_body(&context, Method::POST, routes::GENERATE_INVOICE, || {
            invoice_request.clone()
        })?
        .send()
        .await?
        .json()
        .await?;
    let bolt11 = response
        .bolt11
        .parse::<lightning_invoice::SignedRawBolt11Invoice>()
        .unwrap();
    assert_eq!(bolt11.to_string(), response.payment_hash);
    assert!(response.expires_at > expiry);
    Ok(())
}

#[tokio::test(flavor = "multi_thread")]
async fn test_list_invoice_unpaid() -> Result<()> {
    let context = create_api_server().await?;
    let invoice = &mock_lightning().invoice;
    let response: Vec<Invoice> = admin_request(&context, Method::GET, routes::LIST_INVOICES)?
        .send()
        .await?
        .json()
        .await?;
    let invoice_response = response.first().context("expected invoice")?;
    assert_eq!(invoice.label, invoice_response.label);
    assert_eq!(invoice.bolt11.to_string(), invoice_response.bolt11);
    assert_eq!(
        invoice.bolt11.payment_hash().to_string(),
        invoice_response.payment_hash
    );
    assert_eq!(InvoiceStatus::Unpaid, invoice_response.status);
    assert_eq!("test invoice description", invoice_response.description);
    assert_eq!(
        invoice.bolt11.amount_milli_satoshis(),
        invoice_response.amount_msat
    );
    assert_eq!(None, invoice_response.amount_received_msat);
    assert_eq!(
        invoice.bolt11.expires_at().map(|d| d.as_secs()),
        invoice_response.expires_at
    );
    assert!(invoice_response.paid_at.is_none());
    Ok(())
}

#[tokio::test(flavor = "multi_thread")]
async fn test_list_payments() -> Result<()> {
    let context = create_api_server().await?;
    let payment = &mock_lightning().payment;
    let response: GetV1PayListPaymentsResponse = admin_request(
        &context,
        Method::GET,
        &format!("{}?direction={}", routes::LIST_PAYMENTS, payment.direction),
    )?
    .send()
    .await?
    .json()
    .await?;
    let payment_response = response.payments.first().context("expected payment")?;
    assert_eq!(hex::encode(payment.id.0), payment_response.id);
    assert_eq!(
        payment.bolt11.as_ref().map(|b| b.to_string()),
        payment_response.bolt11
    );
    assert!(matches!(
        payment_response.status,
        GetV1PayListPaymentsResponsePaymentsItemStatus::Pending
    ));
    assert!(payment_response.payment_preimage.is_none());
    assert_eq!(payment.amount, payment_response.amount_sent_msat);
    Ok(())
}
#[tokio::test(flavor = "multi_thread")]
async fn test_pay_invoice() -> Result<()> {
    let context = create_api_server().await?;
    let invoice = &mock_lightning().invoice.bolt11;
    let request = PayInvoice {
        label: Some("test label".to_string()),
        invoice: invoice.to_string(),
    };
    let response: PaymentResponse =
        admin_request_with_body(&context, Method::POST, routes::PAY_INVOICE, || request)?
            .send()
            .await?
            .json()
            .await?;
    assert_eq!(TEST_PUBLIC_KEY, response.destination);
    assert_eq!(invoice.payment_hash().to_string(), response.payment_hash);
    assert_eq!(64, response.payment_preimage.len());
    assert_eq!(
        response.created_at,
        SystemTime::now().duration_since(UNIX_EPOCH)?.as_secs()
    );
    assert_eq!(1, response.parts);
    assert_eq!(Some(200000), response.amount_msat);
    assert_eq!(200000, response.amount_sent_msat);
    assert_eq!("succeeded", response.status);
    Ok(())
}

#[tokio::test(flavor = "multi_thread")]
async fn test_keysend_admin() -> Result<()> {
    let context = create_api_server().await?;
    let response: PaymentResponse =
        admin_request_with_body(&context, Method::POST, routes::KEYSEND, keysend_request)?
            .send()
            .await?
            .json()
            .await?;
    assert_eq!(TEST_PUBLIC_KEY, response.destination);
    assert_eq!(64, response.payment_hash.len());
    assert!(response.payment_preimage.is_empty());
    assert!(response.created_at > 0);
    assert_eq!(1, response.parts);
    assert_eq!(Some(1000), response.amount_msat);
    assert_eq!(1000000, response.amount_sent_msat);
    assert_eq!(PaymentStatus::Pending.to_string(), response.status);
    Ok(())
}

#[tokio::test(flavor = "multi_thread")]
async fn test_estimate_liquidity() -> Result<()> {
    let context = create_api_server().await?;
    let response: GetV1EstimateChannelLiquidityResponse = readonly_request_with_body(
        &context,
        Method::GET,
        routes::ESTIMATE_CHANNEL_LIQUIDITY,
        || GetV1EstimateChannelLiquidityBody {
            scid: TEST_SHORT_CHANNEL_ID,
            target: TEST_PUBLIC_KEY.to_string(),
        },
    )?
    .send()
    .await?
    .json()
    .await?;
    assert_eq!(100, response.minimum);
    assert_eq!(100000, response.maximum);
    Ok(())
}

#[tokio::test(flavor = "multi_thread")]
async fn test_local_remote_balance() -> Result<()> {
    let context = create_api_server().await?;
    let response: GetV1ChannelLocalremotebalResponse =
        readonly_request(&context, Method::GET, routes::LOCAL_REMOTE_BALANCE)?
            .send()
            .await?
            .json()
            .await?;
    assert_eq!(0, response.inactive_balance);
    assert_eq!(0, response.pending_balance);
    assert_eq!(100, response.local_balance);
    assert_eq!(999900, response.remote_balance);
    Ok(())
}

#[tokio::test(flavor = "multi_thread")]
async fn test_get_fees() -> Result<()> {
    let context = create_api_server().await?;
    let response: GetV1GetFeesResponse = readonly_request(&context, Method::GET, routes::GET_FEES)?
        .send()
        .await?
        .json()
        .await?;
    assert_eq!(3000, response.fee_collected);
    Ok(())
}

#[tokio::test(flavor = "multi_thread")]
async fn test_fetch_forwards() -> Result<()> {
    let context = create_api_server().await?;
    let response: Vec<GetV1ChannelListForwardsResponseItem> =
        readonly_request(&context, Method::GET, routes::LIST_FORWARDS)?
            .send()
            .await?
            .json()
            .await?;
    assert_eq!(1, response.len());
    let forward: &GetV1ChannelListForwardsResponseItem =
        response.first().context("expected forward")?;
    assert_eq!(Some(5000000), forward.in_msat);
    assert_eq!(Some(3000), forward.fee_msat);
    assert_eq!(
        hex::encode(mock_lightning().forward.inbound_channel_id.0),
        forward.in_channel
    );
    assert_eq!(
        mock_lightning()
            .forward
            .outbound_channel_id
            .map(|x| hex::encode(x.0)),
        forward.out_channel
    );
    assert_eq!(Some(4997000), forward.out_msat);
    assert_eq!(None, forward.payment_hash);
    assert!(forward.received_timestamp > 0);
    assert!(forward.resolved_timestamp.is_some());
    assert_eq!(None, forward.failcode);
    assert_eq!(None, forward.failreason);
    Ok(())
}

#[tokio::test(flavor = "multi_thread")]
async fn test_channel_history() -> Result<()> {
    let context = create_api_server().await?;
    let response: Vec<GetV1ChannelHistoryResponseItem> =
        readonly_request(&context, Method::GET, routes::LIST_CHANNEL_HISTORY)?
            .send()
            .await?
            .json()
            .await?;
    let channel = response.first().context("expected channel")?;
    assert_eq!(
        hex::encode(mock_lightning().channel.channel_id.0),
        channel.id
    );
    assert_eq!(
        hex::encode(mock_lightning().channel.channel_id.0),
        channel.id
    );
    assert_eq!(TEST_SHORT_CHANNEL_ID, channel.scid);
    assert_eq!(
        mock_lightning().channel.user_channel_id,
        channel.user_channel_id
    );
    assert_eq!(TEST_PUBLIC_KEY, channel.counterparty);
    assert_eq!(format!("{TEST_TX_ID}:2"), channel.funding_txo);
    assert!(channel.is_public);
    assert!(channel.is_outbound);
    assert!(channel.open_timestamp > 0);
    assert!(channel.close_timestamp > 0);
    assert_eq!(
        channel.closure_reason,
        ClosureReason::CooperativeClosure.to_string()
    );
    assert_eq!(channel.value, 1000000);
    Ok(())
}

#[tokio::test(flavor = "multi_thread")]
async fn test_decode_invoice() -> Result<()> {
    let context = create_api_server().await?;
    let invoice = &mock_lightning().invoice.bolt11;
    let response: GetV1UtilityDecodeInvoiceStringResponse = readonly_request(
        &context,
        Method::GET,
        &routes::DECODE_INVOICE.replace(":invoice", &invoice.to_string()),
    )?
    .send()
    .await?
    .json()
    .await?;
    assert!(matches!(
        response.type_,
        GetV1UtilityDecodeInvoiceStringResponseType::Bolt11
    ));
    assert!(response.valid);
    assert_eq!(response.expiry, Some(2322));
    assert_eq!(response.currency, Some("bcrt".to_string()));
    assert_eq!(response.amount_msat, Some(200000));
    assert_eq!(response.payee, Some(TEST_PUBLIC_KEY.to_string()));
    assert_eq!(response.min_final_cltv_expiry, Some(144));
    assert!(response.created_at.is_some());
    assert!(response.payment_hash.is_some());
    assert!(response.signature.is_some());
    Ok(())
}

fn withdraw_request() -> WalletTransfer {
    WalletTransfer {
        address: TEST_ADDRESS.to_string(),
        satoshis: "all".to_string(),
        fee_rate: Some(FeeRate::PerKw(4000)),
        min_conf: Some("3".to_string()),
        utxos: vec![],
    }
}

fn fund_channel_request() -> FundChannel {
    FundChannel {
        id: TEST_PUBLIC_KEY.to_string() + "@1.2.3.4:1234",
        satoshis: "2100000".to_string(),
        fee_rate: Some(kld::api::payloads::FeeRate::Urgent),
        announce: Some(false),
        push_msat: Some("10000".to_string()),
        close_to: None,
        request_amt: None,
        compact_lease: None,
        min_conf: Some(5),
        utxos: vec![],
    }
}

fn set_channel_fee_request() -> ChannelFee {
    ChannelFee {
        id: TEST_SHORT_CHANNEL_ID.to_string(),
        base: Some(32500),
        ppm: Some(1200),
    }
}

fn keysend_request() -> KeysendRequest {
    KeysendRequest {
        pubkey: TEST_PUBLIC_KEY.to_string(),
        amount: 1000,
        label: None,
        maxfeepercent: None,
        retry_for: None,
        maxdelay: None,
        exemptfee: None,
    }
}

static API_RUNTIME: OnceLock<Runtime> = OnceLock::new();

static TEST_CONTEXT: OnceLock<RwLock<Option<Arc<TestContext>>>> = OnceLock::new();

pub static LIGHTNING: OnceLock<Arc<MockLightning>> = OnceLock::new();

pub fn mock_lightning() -> Arc<MockLightning> {
    LIGHTNING
        .get_or_init(|| Arc::new(MockLightning::default()))
        .clone()
}

pub struct TestContext {
    pub settings: Settings,
    admin_macaroon: Vec<u8>,
    readonly_macaroon: Vec<u8>,
    _tmp_dir: TempDir,
}

pub async fn create_api_server() -> Result<Arc<TestContext>> {
    let mut context = TEST_CONTEXT.get_or_init(|| RwLock::new(None)).write().await;
    if context.is_some() {
        drop(context); // release lock
        return Ok(TEST_CONTEXT
            .get()
            .unwrap()
            .read()
            .await
            .as_ref()
            .unwrap()
            .clone());
    }
    KldLogger::init("test", log::LevelFilter::Info);
    let tmp_dir = TempDir::new()?;
    let rest_api_port = get_available_port().context("no port available")?;
    let rest_api_address = format!("127.0.0.1:{rest_api_port}");
    let mut settings = test_settings(&tmp_dir, "api");
    settings.rest_api_address = rest_api_address.clone();
    let certs_dir = settings.certs_dir.clone();
    let macaroon_auth = Arc::new(
        MacaroonAuth::init(&[0u8; 32], &settings.data_dir)
            .context("cannot initialize macaroon auth")?,
    );
    let admin_macaroon = admin_macaroon(&settings)?;
    let readonly_macaroon = readonly_macaroon(&settings)?;

    // Run the API with its own runtime in its own thread.
    spawn(move || {
        API_RUNTIME
            .get_or_init(|| Runtime::new().unwrap())
            .spawn(async {
                bind_api_server(rest_api_address, certs_dir)
                    .await?
                    .serve(
                        Arc::new(MockBitcoind),
                        mock_lightning(),
                        Arc::new(MockWallet::default()),
                        macaroon_auth,
                        quit_signal().shared(),
                    )
                    .await
            })
    });

    let new_context = TestContext {
        settings,
        admin_macaroon,
        readonly_macaroon,
        _tmp_dir: tmp_dir,
    };

    poll!(
        3,
        readonly_request(&new_context, Method::GET, routes::ROOT)?
            .send()
            .await
            .map(|r| r.status().is_success())
            .unwrap_or_default()
    );

    *context = Some(Arc::new(new_context));
    drop(context); // release lock
    Ok(TEST_CONTEXT
        .get()
        .unwrap()
        .read()
        .await
        .as_ref()
        .unwrap()
        .clone())
}

fn admin_macaroon(settings: &Settings) -> Result<Vec<u8>> {
    let path = format!("{}/macaroons/admin.macaroon", settings.data_dir);
    fs::read(&path).with_context(|| format!("Failed to read {path}"))
}

fn readonly_macaroon(settings: &Settings) -> Result<Vec<u8>> {
    let path = format!("{}/macaroons/readonly.macaroon", settings.data_dir);
    fs::read(&path).with_context(|| format!("Failed to read {path}"))
}

fn unauthorized_request(
    context: &TestContext,
    method: Method,
    route: &str,
) -> Result<RequestBuilder> {
    let address = &context.settings.rest_api_address;
    Ok(https_client(None)?.request(method, format!("https://{address}{route}")))
}

fn admin_request(context: &TestContext, method: Method, route: &str) -> Result<RequestBuilder> {
    let address = &context.settings.rest_api_address;
    Ok(https_client(Some(context.admin_macaroon.clone()))?
        .request(method, format!("https://{address}{route}")))
}

fn admin_request_with_body<T: Serialize, F: FnOnce() -> T>(
    context: &TestContext,
    method: Method,
    route: &str,
    f: F,
) -> Result<RequestBuilder> {
    let body = serde_json::to_string(&f())?;
    Ok(admin_request(context, method, route)?.body(body))
}

fn readonly_request(context: &TestContext, method: Method, route: &str) -> Result<RequestBuilder> {
    let address = &context.settings.rest_api_address;
    Ok(https_client(Some(context.readonly_macaroon.clone()))?
        .request(method, format!("https://{address}{route}")))
}

fn readonly_request_with_body<T: Serialize, F: FnOnce() -> T>(
    context: &TestContext,
    method: Method,
    route: &str,
    f: F,
) -> Result<RequestBuilder> {
    let body = serde_json::to_string(&f())?;
    Ok(readonly_request(context, method, route)?.body(body))
}

'''
'''--- kld/tests/apis.rs ---
use tokio::signal::unix::SignalKind;

mod api;
mod mocks;

pub async fn quit_signal() {
    let _ = tokio::signal::unix::signal(SignalKind::quit())
        .unwrap()
        .recv()
        .await;
}

'''
'''--- kld/tests/bitcoind.rs ---
use std::str::FromStr;

use anyhow::{anyhow, bail, Result};
use bitcoin::Address;
use kld::bitcoind::bitcoind_interface::BitcoindInterface;
use lightning::chain::chaininterface::{ConfirmationTarget, FeeEstimator};
use lightning_block_sync::{BlockData, BlockSource};
use test_utils::{test_settings, BitcoinManager, TempDir, TEST_ADDRESS};

#[tokio::test(flavor = "multi_thread")]
pub async fn test_bitcoind_client() -> Result<()> {
    let tmp_dir = TempDir::new()?;

    let mut settings = test_settings(&tmp_dir, "client");
    let bitcoind = BitcoinManager::new(&tmp_dir, &mut settings).await?;
    let n_blocks = 3;
    bitcoind
        .client
        .generate_to_address(n_blocks, &Address::from_str(TEST_ADDRESS)?.assume_checked())
        .await?;

    bitcoind.client.wait_for_blockchain_synchronisation().await;

    let info = bitcoind.client.get_blockchain_info().await?;
    assert_eq!(n_blocks, info.blocks);

    let best_block = bitcoind
        .client
        .get_best_block()
        .await
        .map_err(|e| anyhow!(e.into_inner()))?;
    assert_eq!(best_block.0, info.best_block_hash);
    assert_eq!(best_block.1, Some(n_blocks as u32));

    let header = bitcoind
        .client
        .get_header(&best_block.0, None)
        .await
        .map_err(|e| anyhow!(e.into_inner()))?;
    assert_eq!(header.height, n_blocks as u32);
    assert_eq!(header.chainwork.log2(), 3.0);

    let block = &bitcoind
        .client
        .get_block(&best_block.0)
        .await
        .map_err(|e| anyhow!(e.into_inner()))?;

    assert_eq!(
        2000,
        bitcoind
            .client
            .get_est_sat_per_1000_weight(ConfirmationTarget::ChannelCloseMinimum)
    );
    assert_eq!(
        5000,
        bitcoind
            .client
            .get_est_sat_per_1000_weight(ConfirmationTarget::NonAnchorChannelFee)
    );
    assert_eq!(
        10000,
        bitcoind
            .client
            .get_est_sat_per_1000_weight(ConfirmationTarget::OnChainSweep)
    );

    bitcoind.client.poll_for_fee_estimates();

    match block {
        BlockData::FullBlock(block) => assert_eq!(block.block_hash(), best_block.0),
        BlockData::HeaderOnly(_header) => bail!("Should be a full block"),
    };
    Ok(())
}

'''
'''--- kld/tests/database/ldk_database.rs ---
use std::str::FromStr;
use std::sync::{Arc, Mutex};
use std::time::Duration;

use anyhow::{anyhow, Context, Result};
use bitcoin::hashes::hex::FromHex;
use bitcoin::hashes::{sha256, Hash};
use bitcoin::secp256k1::{Secp256k1, SecretKey};
use bitcoin::{Network, TxOut, Txid};
use kld::database::forward::{Forward, ForwardStatus};
use kld::database::invoice::Invoice;
use kld::database::payment::{Payment, PaymentDirection};
use kld::database::peer::Peer;
use kld::database::ChannelRecord;
use kld::database::LdkDatabase;
use kld::ldk::Scorer;

use kld::logger::KldLogger;
use lightning::chain::chaininterface::{BroadcasterInterface, FeeEstimator};
use lightning::chain::chainmonitor::ChainMonitor;
use lightning::chain::transaction::OutPoint;
use lightning::chain::Filter;

use lightning::events::ClosureReason;
use lightning::ln::channelmanager::{
    ChannelCounterparty, ChannelDetails, CounterpartyForwardingInfo,
};
use lightning::ln::features::{ChannelTypeFeatures, InitFeatures};
use lightning::ln::msgs::SocketAddress;
use lightning::ln::ChannelId;
use lightning::ln::{PaymentHash, PaymentPreimage, PaymentSecret};
use lightning::routing::gossip::NetworkGraph;
use lightning::routing::router::DefaultRouter;
use lightning::routing::scoring::{
    ProbabilisticScorer, ProbabilisticScoringDecayParameters, ProbabilisticScoringFeeParameters,
};
use lightning::sign::{InMemorySigner, KeysManager, SpendableOutputDescriptor};
use lightning::util::persist::Persister;
use lightning_invoice::{Currency, InvoiceBuilder};
use rand::random;
use test_utils::{
    init_db_test_context, poll, random_public_key, TempDir, TEST_PRIVATE_KEY, TEST_PUBLIC_KEY,
    TEST_TX_ID,
};

#[tokio::test(flavor = "multi_thread")]
pub async fn test_peers() -> Result<()> {
    let temp_dir = TempDir::new()?;
    let (settings, _cockroach, durable_connection) = init_db_test_context(&temp_dir).await?;

    let database = LdkDatabase::new(settings.into(), durable_connection.into());

    let peer = Peer {
        public_key: random_public_key(),
        address: SocketAddress::TcpIpV4 {
            addr: [128, 23, 34, 2],
            port: 1000,
        },
    };
    let saved_peer = database.fetch_peer(&peer.public_key).await?;
    assert_eq!(None, saved_peer);

    database.persist_peer(&peer).await?;

    let saved_peer = database.fetch_peer(&peer.public_key).await?;
    assert_eq!(peer, saved_peer.unwrap());

    let peers = database.fetch_peers().await?;
    assert!(peers.contains_key(&peer.public_key));

    database.delete_peer(&peer.public_key).await?;
    let peers = database.fetch_peers().await?;
    assert!(!peers.contains_key(&peer.public_key));

    Ok(())
}

#[tokio::test(flavor = "multi_thread")]
pub async fn test_forwards() -> Result<()> {
    let temp_dir = TempDir::new()?;
    let (settings, _cockroach, durable_connection) = init_db_test_context(&temp_dir).await?;

    let database = LdkDatabase::new(settings.into(), durable_connection.into());

    let amount = 1000000;
    let fee = 100;
    let forward_success = Forward::success(
        ChannelId::from_bytes([0u8; 32]),
        ChannelId::from_bytes([1u8; 32]),
        amount,
        fee,
    );
    database.persist_forward(forward_success.clone()).await?;

    let forward_fail = Forward::failure(
        ChannelId::from_bytes([3u8; 32]),
        lightning::events::HTLCDestination::FailedPayment {
            payment_hash: PaymentHash([1u8; 32]),
        },
    );
    database.persist_forward(forward_fail.clone()).await?;

    let total = database.fetch_total_forwards().await?;
    assert_eq!(1, total.count);
    assert_eq!(amount, total.amount);
    assert_eq!(fee, total.fee);

    let forwards = database.fetch_forwards(None).await?;
    assert_eq!(
        forwards.first().context("expected success forward")?,
        &forward_success
    );
    assert_eq!(
        forwards.last().context("expected failed forward")?,
        &forward_fail
    );

    let forwards = database
        .fetch_forwards(Some(ForwardStatus::Succeeded))
        .await?;
    assert_eq!(1, forwards.len());

    Ok(())
}

#[tokio::test(flavor = "multi_thread")]
pub async fn test_invoice_payments() -> Result<()> {
    let temp_dir = TempDir::new()?;
    let (settings, _cockroach, durable_connection) = init_db_test_context(&temp_dir).await?;

    let database = LdkDatabase::new(settings.into(), durable_connection.into());

    let private_key = SecretKey::from_slice(&TEST_PRIVATE_KEY)?;
    let payment_hash = sha256::Hash::from_slice(&[1u8; 32]).unwrap();
    let payment_secret = PaymentSecret([2u8; 32]);

    let bolt11 = InvoiceBuilder::new(Currency::Regtest)
        .description("test".into())
        .amount_milli_satoshis(1000)
        .payment_hash(payment_hash)
        .payment_secret(payment_secret)
        .current_timestamp()
        .expiry_time(Duration::from_secs(3600))
        .min_final_cltv_expiry_delta(144)
        .build_signed(|hash| Secp256k1::new().sign_ecdsa_recoverable(hash, &private_key))?;

    let label = "test label".to_owned();
    let invoice = Invoice::new(Some(label.clone()), bolt11)?;
    database.persist_invoice(&invoice).await?;

    let result = database
        .fetch_invoices(Some(label.clone()))
        .await?
        .into_iter()
        .last()
        .context("expected invoice")?;
    assert_eq!(result, invoice);

    let mut payment = Payment::of_invoice_outbound(&invoice, Some("label".to_string()));
    database.persist_payment(&payment).await?;

    let result = database
        .fetch_invoices(Some(label.clone()))
        .await?
        .into_iter()
        .last()
        .context("expected invoice")?;
    assert_eq!(1, result.payments.len());

    let result = database.fetch_invoices(None).await?;
    assert_eq!(1, result.len());

    let stored_payments = database
        .fetch_payments(None, None)
        .await?
        .into_iter()
        .find(|p| p.id == payment.id)
        .context("expected payment")?;
    assert_eq!(stored_payments, payment);

    payment.succeeded(PaymentHash([1u8; 32]), PaymentPreimage(random()), Some(232));
    database.persist_payment(&payment).await?;

    let stored_payments = database
        .fetch_payments(payment.hash, Some(PaymentDirection::Outbound))
        .await?;
    assert_eq!(1, stored_payments.len());
    assert_eq!(
        stored_payments.first().context("expected payment")?,
        &payment
    );

    Ok(())
}

#[tokio::test(flavor = "multi_thread")]
pub async fn test_network_graph() -> Result<()> {
    KldLogger::init("test", log::LevelFilter::Debug);
    let temp_dir = TempDir::new()?;
    let (settings, _cockroach, durable_connection) = init_db_test_context(&temp_dir).await?;

    let database = LdkDatabase::new(settings.into(), durable_connection.into());

    let network_graph = Arc::new(NetworkGraph::new(Network::Regtest, KldLogger::global()));
    // how to make this less verbose?
    let persist = |database, network_graph| {
        <LdkDatabase as Persister<
            '_,
            Arc<KldTestChainMonitor>,
            Arc<dyn BroadcasterInterface>,
            Arc<KeysManager>,
            Arc<KeysManager>,
            Arc<KeysManager>,
            Arc<dyn FeeEstimator>,
            Arc<
                DefaultRouter<
                    Arc<NetworkGraph<Arc<KldLogger>>>,
                    Arc<KldLogger>,
                    Arc<Mutex<Scorer>>,
                    ProbabilisticScoringFeeParameters,
                    Scorer,
                >,
            >,
            Arc<KldLogger>,
            Mutex<Scorer>,
        >>::persist_graph(database, network_graph)
    };
    persist(&database, &network_graph)?;
    assert!(database.fetch_graph().await.unwrap().is_some());

    network_graph.set_last_rapid_gossip_sync_timestamp(10);
    persist(&database, &network_graph)?;
    assert!(database.fetch_graph().await.unwrap().is_some());

    Ok(())
}

#[tokio::test(flavor = "multi_thread")]
pub async fn test_scorer() -> Result<()> {
    KldLogger::init("test", log::LevelFilter::Debug);
    let temp_dir = TempDir::new()?;
    let (settings, _cockroach, durable_connection) = init_db_test_context(&temp_dir).await?;

    let database = LdkDatabase::new(settings.into(), durable_connection.into());

    let network_graph = Arc::new(NetworkGraph::new(Network::Regtest, KldLogger::global()));
    let scorer = Mutex::new(ProbabilisticScorer::new(
        ProbabilisticScoringDecayParameters::default(),
        network_graph.clone(),
        KldLogger::global(),
    ));
    let persist = |database, scorer| {
        <LdkDatabase as Persister<
            '_,
            Arc<KldTestChainMonitor>,
            Arc<dyn BroadcasterInterface>,
            Arc<KeysManager>,
            Arc<KeysManager>,
            Arc<KeysManager>,
            Arc<dyn FeeEstimator>,
            Arc<
                DefaultRouter<
                    Arc<NetworkGraph<Arc<KldLogger>>>,
                    Arc<KldLogger>,
                    Arc<Mutex<Scorer>>,
                    ProbabilisticScoringFeeParameters,
                    Scorer,
                >,
            >,
            Arc<KldLogger>,
            Mutex<Scorer>,
        >>::persist_scorer(database, scorer)
    };

    persist(&database, &scorer)?;
    poll!(
        3,
        database
            .fetch_scorer(
                ProbabilisticScoringDecayParameters::default(),
                network_graph.clone()
            )
            .await?
            .is_some()
    );

    let timestamp = database
        .fetch_scorer(
            ProbabilisticScoringDecayParameters::default(),
            network_graph.clone(),
        )
        .await?
        .map(|s| s.1)
        .ok_or(anyhow!("missing timestamp"))?;

    persist(&database, &scorer)?;
    poll!(
        3,
        database
            .fetch_scorer(
                ProbabilisticScoringDecayParameters::default(),
                network_graph.clone()
            )
            .await?
            .map(|s| s.1)
            .filter(|t| t > &timestamp)
            .is_some()
    );
    Ok(())
}

#[tokio::test(flavor = "multi_thread")]
pub async fn test_spendable_outputs() -> Result<()> {
    let temp_dir = TempDir::new()?;
    let (settings, _cockroach, durable_connection) = init_db_test_context(&temp_dir).await?;

    let database = LdkDatabase::new(settings.into(), durable_connection.into());
    let channel_id = ChannelId::from_bytes(random());

    let output = TxOut::default();
    let outpoint = OutPoint {
        txid: Txid::from_raw_hash(bitcoin_hashes::sha256d::Hash::from_slice(
            &Vec::<u8>::from_hex(TEST_TX_ID)?[..],
        )?),
        index: 2,
    };
    let descriptor = SpendableOutputDescriptor::StaticOutput {
        outpoint,
        output,
        channel_keys_id: None,
    };
    database
        .persist_spendable_output(&descriptor, Some(&channel_id), false)
        .await?;

    // Update is_spent after it spend
    database
        .persist_spendable_output(&descriptor, Some(&channel_id), true)
        .await?;

    let spendable_outputs = database.fetch_spendable_outputs().await?;
    assert_eq!(1, spendable_outputs.len());
    Ok(())
}

#[tokio::test(flavor = "multi_thread")]
pub async fn test_channels() -> Result<()> {
    let temp_dir = TempDir::new()?;
    let (settings, _cockroach, durable_connection) = init_db_test_context(&temp_dir).await?;

    let database = LdkDatabase::new(settings.into(), durable_connection.into());

    let mut type_features = ChannelTypeFeatures::empty();
    type_features.set_zero_conf_optional();
    type_features.set_scid_privacy_required();
    let mut initializing_channel_id = ChannelId::from_bytes([0; 32]);
    let mut channel_id = ChannelId::from_bytes([1; 32]);
    let counterparty = bitcoin::secp256k1::PublicKey::from_str(TEST_PUBLIC_KEY)?;
    let txid = Txid::from_raw_hash(bitcoin_hashes::sha256d::Hash::from_slice(
        &Vec::<u8>::from_hex(TEST_TX_ID)?[..],
    )?);

    let mut channel = ChannelDetails {
        channel_id,
        short_channel_id: Some(u64::MAX), // i64::MAX + 1
        user_channel_id: u128::MAX,       // u64::MAX + 1
        counterparty: ChannelCounterparty {
            node_id: counterparty,
            features: InitFeatures::empty(),
            unspendable_punishment_reserve: 0,
            forwarding_info: Some(CounterpartyForwardingInfo {
                fee_base_msat: u32::MAX,
                fee_proportional_millionths: u32::MAX,
                cltv_expiry_delta: u16::MAX,
            }),
            outbound_htlc_minimum_msat: Some(u64::MAX),
            outbound_htlc_maximum_msat: Some(u64::MAX),
        },
        funding_txo: Some(OutPoint { txid, index: 0 }),
        is_public: true,
        is_outbound: true,
        channel_value_satoshis: u64::MAX,
        channel_type: Some(ChannelTypeFeatures::empty()),
        balance_msat: u64::MAX,
        channel_shutdown_state: None,
        config: None,
        confirmations: Some(u32::MAX),
        confirmations_required: Some(u32::MAX),
        feerate_sat_per_1000_weight: Some(u32::MAX),
        force_close_spend_delay: Some(u16::MAX),
        inbound_capacity_msat: u64::MAX,
        inbound_htlc_maximum_msat: None,
        inbound_htlc_minimum_msat: None,
        inbound_scid_alias: None,
        is_channel_ready: true,
        is_usable: true,
        next_outbound_htlc_limit_msat: u64::MAX,
        next_outbound_htlc_minimum_msat: u64::MAX,
        outbound_capacity_msat: u64::MAX,
        outbound_scid_alias: Some(u64::MAX),
        unspendable_punishment_reserve: Some(u64::MAX),
    };

    database
        .persist_initializing_channel(&initializing_channel_id, true, &counterparty, &txid)
        .await?;
    database
        .update_initializing_channel(
            &initializing_channel_id,
            Some((&channel_id, 0)),
            None::<&str>,
        )
        .await?;
    let mut channels = database.fetch_channels().await?;
    assert_eq!(0, channels.len());
    channels = database.fetch_channel_history().await?;
    assert_eq!(0, channels.len());

    database.persist_channel(&channel).await?;
    channels = database.fetch_channels().await?;
    assert_eq!(1, channels.len());
    let ChannelRecord {
        closure_reason,
        detail,
        ..
    } = channels.first().context("expected channel")?;
    assert_eq!(*detail, Some(channel.clone()));
    assert!(closure_reason.is_none());
    channels = database.fetch_channel_history().await?;
    assert_eq!(0, channels.len());

    channel.is_usable = false;
    let reason = ClosureReason::CooperativeClosure;
    database
        .close_channel(&channel.channel_id, format!("{reason}"))
        .await?;
    channels = database.fetch_channels().await?;
    assert_eq!(1, channels.len());
    channels = database.fetch_channel_history().await?;
    assert_eq!(1, channels.len());
    let ChannelRecord {
        open_timestamp,
        update_timestamp,
        closure_reason,
        detail,
        ..
    } = channels.first().context("expected channel")?;
    assert!(update_timestamp > open_timestamp);
    assert_eq!(*detail, Some(channel));
    assert_eq!(*closure_reason, Some(reason.to_string()));

    //
    // Test create a channel without detail
    //
    initializing_channel_id = ChannelId::from_bytes([2; 32]);
    channel_id = ChannelId::from_bytes([3; 32]);
    channels = database.fetch_channel_history().await?;
    let previous_channel_num = channels.len();
    database
        .persist_initializing_channel(&initializing_channel_id, true, &counterparty, &txid)
        .await?;
    database
        .update_initializing_channel(
            &initializing_channel_id,
            Some((&channel_id, 0)),
            None::<&str>,
        )
        .await?;
    channels = database.fetch_channel_history().await?;
    assert_eq!(previous_channel_num, channels.len());
    channels = database.fetch_channels().await?;
    assert_eq!(previous_channel_num, channels.len());

    database
        .create_channel(&channel_id, true, &counterparty)
        .await?;
    channels = database.fetch_channel_history().await?;
    assert_eq!(previous_channel_num, channels.len());
    channels = database.fetch_channels().await?;
    assert_eq!(previous_channel_num + 1, channels.len());
    let ChannelRecord {
        closure_reason,
        detail,
        ..
    } = channels.last().context("expected channel")?;
    assert!(detail.is_none());
    assert!(closure_reason.is_none());

    let reason = ClosureReason::CooperativeClosure;
    database
        .close_channel(&channel_id, format!("{reason}"))
        .await?;
    // NOTE channel_history is not hanndle any channel without details
    channels = database.fetch_channel_history().await?;
    assert_eq!(previous_channel_num, channels.len());
    channels = database.fetch_channels().await?;
    assert_eq!(previous_channel_num + 1, channels.len());
    let ChannelRecord {
        open_timestamp,
        update_timestamp,
        closure_reason,
        detail,
        ..
    } = channels.last().context("expected channel")?;
    assert!(update_timestamp > open_timestamp);
    assert!(detail.is_none());
    assert_eq!(*closure_reason, Some(reason.to_string()));

    Ok(())
}

// XXX
// Why do we make a crate `test-utils`?
// Test utils should be collect.
type KldTestChainMonitor = ChainMonitor<
    InMemorySigner,
    Arc<dyn Filter + Send + Sync>,
    Arc<dyn BroadcasterInterface>,
    Arc<dyn FeeEstimator>,
    Arc<KldLogger>,
    Arc<LdkDatabase>,
>;

'''
'''--- kld/tests/database/main.rs ---
mod ldk_database;
mod wallet_database;

'''
'''--- kld/tests/database/wallet_database.rs ---
use std::str::FromStr;

use anyhow::Result;
use bdk::database::{BatchDatabase, BatchOperations, Database, SyncTime};
use bdk::{BlockTime, KeychainKind, LocalUtxo, TransactionDetails};
use bitcoin::consensus::encode::deserialize;
use bitcoin::hashes::hex::*;
use bitcoin::*;
use kld::database::WalletDatabase;
use test_utils::{init_db_test_context, TempDir};

#[tokio::test(flavor = "multi_thread")]
pub async fn test_script_pubkey() -> Result<()> {
    let temp_dir = TempDir::new()?;
    let (settings, _cockroach, durable_connection) = init_db_test_context(&temp_dir).await?;

    let mut wallet_database = WalletDatabase::new(settings.into(), durable_connection.into());
    let script = ScriptBuf::from_bytes(Vec::<u8>::from_hex(
        "76a91402306a7c23f3e8010de41e9e591348bb83f11daa88ac",
    )?);
    let path = 42;
    let keychain = KeychainKind::External;
    let mut batch = wallet_database.begin_batch()?;

    batch.set_script_pubkey(&script, keychain, path)?;

    // Can't read while writes to the the same table are pending with cockroach.
    // assert_eq!(database.get_script_pubkey_from_path(keychain, path).unwrap(), None);
    // assert_eq!(database.get_path_from_script_pubkey(&script).unwrap(), None);

    wallet_database.commit_batch(batch)?;

    assert_eq!(
        wallet_database
            .get_script_pubkey_from_path(keychain, path)
            .unwrap(),
        Some(script.clone())
    );
    assert_eq!(
        wallet_database
            .get_path_from_script_pubkey(&script)
            .unwrap(),
        Some((keychain, path))
    );

    assert_eq!(wallet_database.iter_script_pubkeys(None)?.len(), 1);

    wallet_database.del_script_pubkey_from_path(keychain, path)?;
    assert_eq!(wallet_database.iter_script_pubkeys(None)?.len(), 0);
    Ok(())
}

#[tokio::test(flavor = "multi_thread")]
pub async fn test_utxo() -> Result<()> {
    let temp_dir = TempDir::new()?;
    let (settings, _cockroach, durable_connection) = init_db_test_context(&temp_dir).await?;

    let mut wallet_database = WalletDatabase::new(settings.into(), durable_connection.into());
    let outpoint =
        OutPoint::from_str("5df6e0e2761359d30a8275058e299fcc0381534545f55cf43e41983f5d4c9456:0")?;
    let script = ScriptBuf::from_bytes(Vec::<u8>::from_hex(
        "76a91402306a7c23f3e8010de41e9e591348bb83f11daa88ac",
    )?);
    let txout = TxOut {
        value: 133742,
        script_pubkey: script,
    };
    let utxo = LocalUtxo {
        txout,
        outpoint,
        keychain: KeychainKind::External,
        is_spent: true,
    };

    wallet_database.set_utxo(&utxo)?;
    wallet_database.set_utxo(&utxo)?;
    assert_eq!(wallet_database.iter_utxos().unwrap().len(), 1);
    assert_eq!(wallet_database.get_utxo(&outpoint).unwrap(), Some(utxo));
    Ok(())
}

#[tokio::test(flavor = "multi_thread")]
pub async fn test_raw_tx() -> Result<()> {
    let temp_dir = TempDir::new()?;
    let (settings, _cockroach, durable_connection) = init_db_test_context(&temp_dir).await?;

    let mut wallet_database = WalletDatabase::new(settings.into(), durable_connection.into());
    let hex_tx = Vec::<u8>::from_hex("0100000001a15d57094aa7a21a28cb20b59aab8fc7d1149a3bdbcddba9c622e4f5f6a99ece010000006c493046022100f93bb0e7d8db7bd46e40132d1f8242026e045f03a0efe71bbb8e3f475e970d790221009337cd7f1f929f00cc6ff01f03729b069a7c21b59b1736ddfee5db5946c5da8c0121033b9b137ee87d5a812d6f506efdd37f0affa7ffc310711c06c7f3e097c9447c52ffffffff0100e1f505000000001976a9140389035a9225b3839e2bbf32d826a1e222031fd888ac00000000")?;
    let tx: Transaction = deserialize(&hex_tx)?;

    wallet_database.set_raw_tx(&tx)?;

    let txid = tx.txid();

    assert_eq!(wallet_database.get_raw_tx(&txid)?, Some(tx));
    Ok(())
}

#[tokio::test(flavor = "multi_thread")]
pub async fn test_tx() -> Result<()> {
    let temp_dir = TempDir::new()?;
    let (settings, _cockroach, durable_connection) = init_db_test_context(&temp_dir).await?;

    let mut wallet_database = WalletDatabase::new(settings.into(), durable_connection.into());
    let hex_tx = Vec::<u8>::from_hex("0100000001a15d57094aa7a21a28cb20b59aab8fc7d1149a3bdbcddba9c622e4f5f6a99ece010000006c493046022100f93bb0e7d8db7bd46e40132d1f8242026e045f03a0efe71bbb8e3f475e970d790221009337cd7f1f929f00cc6ff01f03729b069a7c21b59b1736ddfee5db5946c5da8c0121033b9b137ee87d5a812d6f506efdd37f0affa7ffc310711c06c7f3e097c9447c52ffffffff0100e1f505000000001976a9140389035a9225b3839e2bbf32d826a1e222031fd888ac00000000").unwrap();
    let tx: Transaction = deserialize(&hex_tx)?;
    let txid = tx.txid();
    let mut tx_details = TransactionDetails {
        transaction: Some(tx),
        txid,
        received: 1337,
        sent: 420420,
        fee: Some(140),
        confirmation_time: Some(BlockTime {
            timestamp: 123456,
            height: 1000,
        }),
    };

    wallet_database.set_tx(&tx_details)?;

    // get with raw tx too
    assert_eq!(
        wallet_database.get_tx(&tx_details.txid, true)?,
        Some(tx_details.clone())
    );
    // get only raw_tx
    assert_eq!(
        wallet_database.get_raw_tx(&tx_details.txid)?,
        tx_details.transaction
    );

    // now get without raw_tx
    tx_details.transaction = None;
    assert_eq!(
        wallet_database.get_tx(&tx_details.txid, false)?,
        Some(tx_details)
    );
    Ok(())
}

#[tokio::test(flavor = "multi_thread")]
pub async fn test_last_index() -> Result<()> {
    let temp_dir = TempDir::new()?;
    let (settings, _cockroach, durable_connection) = init_db_test_context(&temp_dir).await?;

    let mut wallet_database = WalletDatabase::new(settings.into(), durable_connection.into());
    wallet_database.set_last_index(KeychainKind::External, 1337)?;

    assert_eq!(
        wallet_database.get_last_index(KeychainKind::External)?,
        Some(1337)
    );
    assert_eq!(
        wallet_database.get_last_index(KeychainKind::Internal)?,
        None
    );

    let res = wallet_database.increment_last_index(KeychainKind::External)?;
    assert_eq!(res, 1338);
    let res = wallet_database.increment_last_index(KeychainKind::Internal)?;
    assert_eq!(res, 0);

    assert_eq!(
        wallet_database.get_last_index(KeychainKind::External)?,
        Some(1338)
    );
    assert_eq!(
        wallet_database.get_last_index(KeychainKind::Internal)?,
        Some(0)
    );
    Ok(())
}

#[tokio::test(flavor = "multi_thread")]
pub async fn test_sync_time() -> Result<()> {
    let temp_dir = TempDir::new()?;
    let (settings, _cockroach, durable_connection) = init_db_test_context(&temp_dir).await?;

    let mut wallet_database = WalletDatabase::new(settings.into(), durable_connection.into());
    assert!(wallet_database.get_sync_time()?.is_none());

    wallet_database.set_sync_time(SyncTime {
        block_time: BlockTime {
            height: 100,
            timestamp: 1000,
        },
    })?;

    let extracted = wallet_database.get_sync_time()?;
    assert!(extracted.is_some());
    assert_eq!(extracted.as_ref().unwrap().block_time.height, 100);
    assert_eq!(extracted.as_ref().unwrap().block_time.timestamp, 1000);

    wallet_database.del_sync_time()?;
    assert!(wallet_database.get_sync_time()?.is_none());
    Ok(())
}

'''
'''--- kld/tests/mocks/mock_bitcoind.rs ---
use std::{collections::HashMap, str::FromStr};

use anyhow::Result;
use async_trait::async_trait;
use bitcoin::BlockHash;
use bitcoincore_rpc_json::GetBlockchainInfoResult;
use kld::bitcoind::{bitcoind_interface::BitcoindInterface, MempoolInfo};
use kld::settings::Network;
use test_utils::TEST_BLOCK_HASH;

pub struct MockBitcoind;

#[async_trait]
impl BitcoindInterface for MockBitcoind {
    async fn get_blockchain_info(&self) -> Result<GetBlockchainInfoResult> {
        Ok(GetBlockchainInfoResult {
            chain: Network::Regtest.to_string(),
            warnings: String::new(),
            blocks: 800000,
            headers: 800000,
            median_time: 3498239394,
            size_on_disk: 100000000,
            best_block_hash: BlockHash::from_str(TEST_BLOCK_HASH)?,
            difficulty: 340932094f64,
            verification_progress: 1f64,
            initial_block_download: false,
            pruned: false,
            chain_work: vec![],
            prune_height: None,
            prune_target_size: None,
            automatic_pruning: None,
            softforks: HashMap::new(),
        })
    }

    async fn get_mempool_info(&self) -> Result<MempoolInfo> {
        Ok(MempoolInfo {
            mempool_min_fee: 0.00003101,
        })
    }

    fn fee_rates_kw(&self) -> (u32, u32, u32) {
        (400000, 200000, 100000)
    }

    async fn block_height(&self) -> Result<u64> {
        Ok(800000)
    }
}

'''
'''--- kld/tests/mocks/mock_lightning.rs ---
use std::{
    net::{SocketAddrV4, SocketAddrV6},
    str::FromStr,
    time::Duration,
};

use anyhow::{Context, Result};
use async_trait::async_trait;
use bitcoin::{
    consensus::deserialize,
    hashes::{hex::FromHex, sha256, Hash},
    secp256k1::{PublicKey, Secp256k1, SecretKey},
    Network, Txid,
};
use kld::api::payloads::FeeRate;
use kld::{
    api::SocketAddress,
    database::{
        forward::{Forward, ForwardStatus, TotalForwards},
        microsecond_timestamp, ChannelRecord,
    },
};
use kld::{
    database::{
        invoice::Invoice,
        payment::{Payment, PaymentDirection},
    },
    ldk::{LightningInterface, OpenChannelResult, Peer, PeerStatus},
    MillisatAmount,
};
use lightning::{
    chain::transaction::OutPoint,
    events::ClosureReason,
    ln::{
        channelmanager::{ChannelCounterparty, ChannelDetails},
        features::{ChannelTypeFeatures, Features, InitFeatures},
        ChannelId, PaymentPreimage, PaymentSecret,
    },
    routing::gossip::{ChannelInfo, NodeAlias, NodeAnnouncementInfo, NodeId, NodeInfo},
    util::{
        config::{ChannelConfig, UserConfig},
        indexed_map::IndexedMap,
    },
};

use lightning_invoice::{Currency, InvoiceBuilder};

use test_utils::{
    TEST_ALIAS, TEST_PRIVATE_KEY, TEST_PUBLIC_KEY, TEST_SHORT_CHANNEL_ID, TEST_TX, TEST_TX_ID,
};

pub struct MockLightning {
    pub num_peers: usize,
    pub num_nodes: usize,
    pub num_channels: usize,
    pub wallet_balance: u64,
    pub channel: ChannelDetails,
    pub public_key: PublicKey,
    pub ipv4_address: SocketAddress,
    pub invoice: Invoice,
    pub payment: Payment,
    pub forward: Forward,
}

impl Default for MockLightning {
    fn default() -> Self {
        let public_key = PublicKey::from_str(TEST_PUBLIC_KEY).unwrap();
        let mut channel_features = ChannelTypeFeatures::empty();
        channel_features.set_zero_conf_required();
        channel_features.set_scid_privacy_optional();

        let channel = ChannelDetails {
            channel_id: ChannelId::from_bytes([1u8; 32]),
            counterparty: ChannelCounterparty {
                node_id: public_key,
                features: InitFeatures::empty(),
                unspendable_punishment_reserve: 5000,
                forwarding_info: None,
                outbound_htlc_minimum_msat: Some(1000),
                outbound_htlc_maximum_msat: Some(100),
            },
            funding_txo: Some(OutPoint {
                txid: Txid::from_str(TEST_TX_ID).unwrap(),
                index: 2,
            }),
            channel_type: Some(channel_features),
            short_channel_id: Some(TEST_SHORT_CHANNEL_ID),
            outbound_scid_alias: None,
            inbound_scid_alias: None,
            channel_value_satoshis: 1000000,
            unspendable_punishment_reserve: Some(10000),
            user_channel_id: 3434232,
            balance_msat: 100000,
            outbound_capacity_msat: 100000,
            next_outbound_htlc_minimum_msat: 1,
            next_outbound_htlc_limit_msat: 500,
            inbound_capacity_msat: 999900000,
            confirmations_required: Some(3),
            confirmations: Some(10),
            force_close_spend_delay: Some(6),
            is_outbound: true,
            is_channel_ready: true,
            is_usable: true,
            is_public: true,
            inbound_htlc_minimum_msat: Some(300),
            inbound_htlc_maximum_msat: Some(300000),
            config: Some(ChannelConfig::default()),
            feerate_sat_per_1000_weight: Some(10210),
            channel_shutdown_state: None,
        };
        let socket_addr: SocketAddrV4 = "127.0.0.1:5555".parse().unwrap();
        let private_key = SecretKey::from_slice(&TEST_PRIVATE_KEY).unwrap();
        let public_key = PublicKey::from_str(TEST_PUBLIC_KEY).unwrap();
        let payment_hash = sha256::Hash::from_slice(&[1u8; 32]).unwrap();
        let payment_secret = PaymentSecret([2u8; 32]);
        let invoice = InvoiceBuilder::new(Currency::Regtest)
            .description("test invoice description".to_owned())
            .payee_pub_key(public_key)
            .payment_hash(payment_hash)
            .payment_secret(payment_secret)
            .min_final_cltv_expiry_delta(144)
            .expiry_time(Duration::from_secs(2322))
            .amount_milli_satoshis(200000)
            .current_timestamp()
            .build_signed(|hash| Secp256k1::new().sign_ecdsa_recoverable(hash, &private_key))
            .unwrap();
        let invoice =
            kld::database::invoice::Invoice::new(Some("label".to_string()), invoice).unwrap();
        let payment = Payment::of_invoice_outbound(&invoice, Some("label".to_string()));
        let forward = Forward::success(
            ChannelId::from_bytes([3u8; 32]),
            ChannelId::from_bytes([4u8; 32]),
            5000000,
            3000,
        );

        Self {
            num_peers: 5,
            num_nodes: 6,
            num_channels: 7,
            wallet_balance: 8,
            channel,
            public_key,
            ipv4_address: socket_addr.into(),
            invoice,
            payment,
            forward,
        }
    }
}

#[async_trait]
impl LightningInterface for MockLightning {
    fn alias(&self) -> String {
        "test".to_string()
    }
    fn color(&self) -> String {
        "6e2cf7".to_string()
    }
    fn identity_pubkey(&self) -> PublicKey {
        self.public_key
    }
    async fn synced(&self) -> Result<bool> {
        Ok(true)
    }

    fn sign(&self, _message: &[u8]) -> Result<String> {
        Ok("1234abcd".to_string())
    }

    fn graph_num_nodes(&self) -> usize {
        self.num_nodes
    }

    fn graph_num_channels(&self) -> usize {
        self.num_channels
    }

    fn network(&self) -> bitcoin::Network {
        Network::Bitcoin
    }
    fn num_active_channels(&self) -> usize {
        0
    }

    fn num_inactive_channels(&self) -> usize {
        0
    }

    fn num_pending_channels(&self) -> usize {
        0
    }
    fn num_peers(&self) -> usize {
        self.num_peers
    }

    fn wallet_balance(&self) -> u64 {
        self.wallet_balance
    }

    fn list_active_channels(&self) -> Vec<ChannelDetails> {
        vec![self.channel.clone()]
    }

    async fn list_channels(&self) -> Result<Vec<ChannelRecord>> {
        Ok(vec![ChannelRecord {
            channel_id: self.channel.channel_id.to_string(),
            counterparty: self.channel.counterparty.node_id.to_string(),
            open_timestamp: microsecond_timestamp(),
            update_timestamp: microsecond_timestamp(),
            closure_reason: Some(ClosureReason::CooperativeClosure.to_string()),
            detail: Some(self.channel.clone()),
        }])
    }

    fn set_channel_fee(
        &self,
        _counterparty_node_id: &PublicKey,
        _channel_id: &[ChannelId],
        forwarding_fee_proportional_millionths: Option<u32>,
        forwarding_fee_base_msat: Option<u32>,
    ) -> Result<(u32, u32)> {
        Ok((
            forwarding_fee_base_msat.unwrap_or(5000),
            forwarding_fee_proportional_millionths.unwrap_or(200),
        ))
    }

    fn alias_of(&self, _node_id: &PublicKey) -> Option<String> {
        Some(TEST_ALIAS.to_string())
    }

    fn public_addresses(&self) -> Vec<SocketAddress> {
        let addr1: SocketAddrV4 = "127.0.0.1:2312".parse().unwrap();
        let addr2: SocketAddrV6 = "[2001:db8::1]:8080".parse().unwrap();
        vec![addr1.into(), addr2.into()]
    }

    async fn open_channel(
        &self,
        _their_network_key: PublicKey,
        _channel_value_satoshis: u64,
        _push_msat: Option<u64>,
        _fee_rate: Option<FeeRate>,
        _override_config: Option<UserConfig>,
    ) -> Result<OpenChannelResult> {
        let transaction = deserialize::<bitcoin::Transaction>(&Vec::<u8>::from_hex(TEST_TX)?)?;
        let txid = transaction.txid();
        Ok(OpenChannelResult {
            transaction,
            txid,
            channel_id: ChannelId::from_bytes([1u8; 32]),
        })
    }

    async fn list_peers(&self) -> Result<Vec<Peer>> {
        Ok(vec![Peer {
            public_key: self.public_key,
            net_address: Some(self.ipv4_address.clone()),
            status: PeerStatus::Connected,
            alias: TEST_ALIAS.to_string(),
        }])
    }

    async fn connect_peer(
        &self,
        _public_key: PublicKey,
        _socket_addr: Option<SocketAddress>,
    ) -> Result<()> {
        Ok(())
    }

    async fn disconnect_peer(&self, _public_key: PublicKey) -> Result<()> {
        Ok(())
    }

    async fn close_channel(
        &self,
        _channel_id: &ChannelId,
        _counterparty_node_id: &PublicKey,
        _fee_rate: Option<u32>,
    ) -> Result<()> {
        Ok(())
    }

    async fn force_close_channel(
        &self,
        _channel_id: &ChannelId,
        _counterparty_node_id: &PublicKey,
        _may_broadcast: bool,
    ) -> Result<()> {
        Ok(())
    }

    fn get_node(&self, _node_id: &NodeId) -> Option<NodeInfo> {
        let mut alias = [0u8; 32];
        alias[..TEST_ALIAS.len()].copy_from_slice(TEST_ALIAS.as_bytes());
        let announcement = NodeAnnouncementInfo {
            features: Features::empty(),
            last_update: 21000000,
            rgb: [1, 2, 3],
            alias: NodeAlias(alias),
            announcement_message: None,
        };
        Some(NodeInfo {
            channels: vec![],
            announcement_info: Some(announcement),
        })
    }

    fn nodes(&self) -> IndexedMap<NodeId, NodeInfo> {
        let mut nodes = IndexedMap::new();
        let node_id = NodeId::from_pubkey(&self.public_key);
        nodes.insert(node_id, self.get_node(&node_id).unwrap());
        nodes
    }

    fn get_channel(&self, _channel_id: u64) -> Option<ChannelInfo> {
        None
    }

    fn channels(&self) -> IndexedMap<u64, ChannelInfo> {
        IndexedMap::new()
    }

    fn user_config(&self) -> UserConfig {
        UserConfig::default()
    }

    async fn generate_invoice(
        &self,
        _label: String,
        _amount: Option<u64>,
        _description: String,
        _expiry: Option<u32>,
    ) -> Result<Invoice> {
        Ok(self.invoice.clone())
    }

    async fn pay_invoice(&self, invoice: Invoice, label: Option<String>) -> Result<Payment> {
        let mut payment = Payment::of_invoice_outbound(&invoice, label);
        payment.succeeded(invoice.payment_hash, PaymentPreimage([1u8; 32]), Some(2323));
        Ok(payment)
    }

    async fn list_payments(
        &self,
        _bolt11: Option<Invoice>,
        _direction: Option<PaymentDirection>,
    ) -> Result<Vec<Payment>> {
        Ok(vec![self.payment.clone()])
    }

    async fn list_invoices(&self, _label: Option<String>) -> Result<Vec<Invoice>> {
        Ok(vec![self.invoice.clone()])
    }

    async fn keysend_payment(&self, _payee: NodeId, _amount: MillisatAmount) -> Result<Payment> {
        Ok(self.payment.clone())
    }

    async fn estimated_channel_liquidity_range(
        &self,
        _scid: u64,
        _target: &NodeId,
    ) -> Result<Option<(u64, u64)>> {
        Ok(Some((100, 100000)))
    }

    async fn fetch_total_forwards(&self) -> Result<TotalForwards> {
        Ok(TotalForwards {
            count: 1,
            amount: self.forward.amount.context("expected amount")?,
            fee: self.forward.fee.context("expected fee")?,
        })
    }

    async fn fetch_forwards(&self, _status: Option<ForwardStatus>) -> Result<Vec<Forward>> {
        Ok(vec![self.forward.clone()])
    }

    async fn channel_history(&self) -> Result<Vec<ChannelRecord>> {
        Ok(vec![ChannelRecord {
            channel_id: self.channel.channel_id.to_string(),
            counterparty: self.channel.counterparty.node_id.to_string(),
            open_timestamp: microsecond_timestamp(),
            update_timestamp: microsecond_timestamp(),
            closure_reason: Some(ClosureReason::CooperativeClosure.to_string()),
            detail: Some(self.channel.clone()),
        }])
    }

    async fn scorer(&self) -> Result<Vec<u8>> {
        Ok(Vec::new())
    }

    async fn update_channels(&self, _channels: &[ChannelDetails]) {}
}

'''
'''--- kld/tests/mocks/mock_wallet.rs ---
use std::{str::FromStr, vec};

use anyhow::Result;
use async_trait::async_trait;
use bdk::{wallet::AddressInfo, Balance, BlockTime, KeychainKind, LocalUtxo, TransactionDetails};
use bitcoin::address::NetworkUnchecked;
use bitcoin::{consensus::deserialize, hashes::hex::FromHex, Address, OutPoint, Transaction};
use kld::wallet::WalletInterface;

use test_utils::{TEST_ADDRESS, TEST_TX};

pub struct MockWallet {
    balance: Balance,
    transaction: Transaction,
}

#[async_trait]
impl WalletInterface for MockWallet {
    fn balance(&self) -> Result<Balance> {
        Ok(self.balance.clone())
    }

    async fn transfer(
        &self,
        _address: Address<NetworkUnchecked>,
        amount: u64,
        _fee_rate: Option<kld::api::payloads::FeeRate>,
        _min_conf: Option<u8>,
        _utxos: Vec<OutPoint>,
    ) -> Result<(Transaction, TransactionDetails)> {
        let details = TransactionDetails {
            transaction: Some(self.transaction.clone()),
            txid: self.transaction.txid(),
            received: 0,
            sent: amount,
            fee: None,
            confirmation_time: None,
        };
        Ok((self.transaction.clone(), details))
    }

    fn new_external_address(&self) -> Result<AddressInfo> {
        Ok(AddressInfo {
            address: Address::from_str(TEST_ADDRESS)?.assume_checked(),
            index: 1,
            keychain: KeychainKind::External,
        })
    }

    fn new_internal_address(&self) -> Result<AddressInfo> {
        Ok(AddressInfo {
            address: Address::from_str(TEST_ADDRESS)?.assume_checked(),
            index: 1,
            keychain: KeychainKind::Internal,
        })
    }

    fn list_utxos(&self) -> Result<Vec<(LocalUtxo, TransactionDetails)>> {
        let details = TransactionDetails {
            transaction: Some(self.transaction.clone()),
            txid: self.transaction.txid(),
            received: 10000,
            sent: 1200,
            fee: Some(20),
            confirmation_time: BlockTime::new(Some(600000), Some(23293219)),
        };
        let utxo = LocalUtxo {
            outpoint: OutPoint::new(self.transaction.txid(), 0),
            txout: self.transaction.output.first().unwrap().clone(),
            keychain: KeychainKind::External,
            is_spent: false,
        };
        Ok(vec![(utxo, details)])
    }
}

impl Default for MockWallet {
    fn default() -> Self {
        let transaction =
            deserialize::<bitcoin::Transaction>(&Vec::<u8>::from_hex(TEST_TX).unwrap()).unwrap();
        Self {
            balance: Balance {
                immature: 1,
                trusted_pending: 2,
                untrusted_pending: 3,
                confirmed: 4,
            },
            transaction,
        }
    }
}

'''
'''--- kld/tests/mocks/mod.rs ---
pub mod mock_bitcoind;
pub mod mock_lightning;
pub mod mock_wallet;

'''
'''--- kld/tests/smoke/main.rs ---
mod start;

pub const START_N_BLOCKS: u64 = 10;

'''
'''--- kld/tests/smoke/start.rs ---
use std::{str::FromStr, time::Duration};

use crate::START_N_BLOCKS;
use anyhow::{Context, Result};
use bitcoin::Address;
use hyper::Method;
use kld::api::payloads::{
    FundChannel, FundChannelResponse, GenerateInvoice, GenerateInvoiceResponse, GetInfo, Invoice,
    KeysendRequest, PayInvoice, PaymentResponse, WalletBalance,
};
use kld::api::routes;
use kld::{
    api::codegen::{
        get_v1_channel_list_peer_channels_response::{
            GetV1ChannelListPeerChannelsResponse, GetV1ChannelListPeerChannelsResponseState,
        },
        get_v1_newaddr_response::GetV1NewaddrResponse,
    },
    database::payment::PaymentStatus,
};
use test_utils::{
    poll, test_settings, BitcoinManager, CockroachManager, ElectrsManager, KldManager, TempDir,
    TEST_ADDRESS,
};
use tokio::time::{sleep_until, Instant};

#[tokio::test(flavor = "multi_thread", worker_threads = 1)]
pub async fn test_start() -> Result<()> {
    let tmp_dir = TempDir::new()?;

    let mut settings_0 = test_settings(&tmp_dir, "start");
    let cockroach = CockroachManager::builder(&tmp_dir, &mut settings_0)
        .await?
        .build()
        .await?;
    let bitcoin = BitcoinManager::new(&tmp_dir, &mut settings_0).await?;
    bitcoin
        .generate_blocks(START_N_BLOCKS, &Address::from_str(TEST_ADDRESS)?, false)
        .await?;

    settings_0.node_id = "start0".to_owned();
    settings_0.database_name = "start0".to_owned();
    let electrs_0 = ElectrsManager::new(&tmp_dir, &bitcoin, &mut settings_0).await?;
    let kld_0 = KldManager::new(
        &tmp_dir,
        env!("CARGO_BIN_EXE_kld"),
        &cockroach,
        &electrs_0,
        &mut settings_0,
    )
    .await?;
    let pid = kld_0.call_exporter("pid").await?;
    assert_eq!(pid, kld_0.pid().to_string());

    let mut settings_1 = settings_0.clone();
    settings_1.node_id = "start1".to_owned();
    settings_1.database_name = "start1".to_owned();
    let electrs_1 = ElectrsManager::new(&tmp_dir, &bitcoin, &mut settings_1).await?;
    let kld_1 = KldManager::new(
        &tmp_dir,
        env!("CARGO_BIN_EXE_kld"),
        &cockroach,
        &electrs_1,
        &mut settings_1,
    )
    .await?;

    let address: GetV1NewaddrResponse = kld_0
        .call_rest_api(Method::GET, routes::NEW_ADDR, ())
        .await?;

    bitcoin
        .generate_blocks(1, &bitcoin::Address::from_str(&address.address)?, false)
        .await?;
    bitcoin
        .generate_blocks(
            100, // Coinbase not spendable for 100 blocks.
            &Address::from_str(TEST_ADDRESS)?,
            false,
        )
        .await?;

    let balance = 5000000000;
    let channel_amount = 1000000;
    let push_amount_msat = 1000000;
    let fee_rate_kb = 1000;
    let tx_size_bytes = 153;
    let keysend_amount_msat = 20000000;
    let invoice_amount_msat = 50000000;
    let open_channel_fee = fee_rate_kb / 1000 * tx_size_bytes;
    let kld0_open_channel_expected_balance = balance - channel_amount - open_channel_fee;
    let _kld0_close_channel_expected_balance = balance
        - open_channel_fee
        - (push_amount_msat + keysend_amount_msat + invoice_amount_msat) / 1000;
    let _kld1_close_channel_expected_balance =
        push_amount_msat + keysend_amount_msat + invoice_amount_msat;
    poll!(
        7,
        kld_0
            .call_rest_api::<WalletBalance, ()>(Method::GET, routes::GET_BALANCE, ())
            .await?
            .conf_balance
            == balance
    );

    let _info_0: GetInfo = kld_0
        .call_rest_api(Method::GET, routes::GET_INFO, ())
        .await?;

    let info_1: GetInfo = kld_1
        .call_rest_api(Method::GET, routes::GET_INFO, ())
        .await?;

    poll!(
        7,
        kld_0
            .call_rest_api::<FundChannelResponse, FundChannel>(
                Method::POST,
                routes::OPEN_CHANNEL,
                FundChannel {
                    id: format!("{}@127.0.0.1:{}", info_1.id, settings_1.peer_port),
                    satoshis: channel_amount.to_string(),
                    push_msat: Some(push_amount_msat.to_string()),
                    fee_rate: Some(kld::api::payloads::FeeRate::PerKb(fee_rate_kb as u32)),
                    ..Default::default()
                }
            )
            .await
            .is_ok()
    );

    bitcoin
        .generate_blocks(10, &bitcoin::Address::from_str(TEST_ADDRESS)?, true)
        .await?;

    poll!(
        7,
        kld_0
            .call_rest_api::<WalletBalance, ()>(Method::GET, routes::GET_BALANCE, ())
            .await?
            .conf_balance
            == kld0_open_channel_expected_balance
    );
    poll!(
        7,
        matches!(
            kld_1
                .call_rest_api::<Vec<GetV1ChannelListPeerChannelsResponse>, ()>(
                    Method::GET,
                    routes::LIST_PEER_CHANNELS,
                    ()
                )
                .await?
                .first()
                .map(|c| &c.state),
            Some(&GetV1ChannelListPeerChannelsResponseState::ChanneldNormal)
        )
    );
    let channels = kld_1
        .call_rest_api::<Vec<GetV1ChannelListPeerChannelsResponse>, ()>(
            Method::GET,
            routes::LIST_PEER_CHANNELS,
            (),
        )
        .await?;
    let channel = channels.first().context("expected channel")?;

    let keysend = KeysendRequest {
        pubkey: info_1.id,
        amount: keysend_amount_msat,
        ..Default::default()
    };
    let keysend_response: PaymentResponse = kld_0
        .call_rest_api(Method::POST, routes::KEYSEND, keysend)
        .await?;
    assert_eq!(
        keysend_response.status,
        PaymentStatus::Succeeded.to_string()
    );

    let generate_invoice = GenerateInvoice {
        amount: invoice_amount_msat,
        label: "label".to_string(),
        description: "description".to_string(),
        ..Default::default()
    };
    let invoice: GenerateInvoiceResponse = kld_1
        .call_rest_api(Method::POST, routes::GENERATE_INVOICE, generate_invoice)
        .await?;
    let pay_invoice = PayInvoice {
        label: Some("payment".to_string()),
        invoice: invoice.bolt11,
    };
    let payment: PaymentResponse = kld_0
        .call_rest_api(Method::POST, routes::PAY_INVOICE, pay_invoice)
        .await?;
    assert_eq!(payment.status, PaymentStatus::Succeeded.to_string());

    let invoices: Vec<Invoice> = kld_1
        .call_rest_api(Method::GET, routes::LIST_INVOICES, ())
        .await?;
    assert_eq!(1, invoices.len());

    kld_0
        .call_rest_api(
            Method::DELETE,
            &routes::CLOSE_CHANNEL.replace(
                ":id",
                channel
                    .short_channel_id
                    .as_ref()
                    .context("expected short channel id")?,
            ),
            (),
        )
        .await?;

    bitcoin
        .generate_blocks(10, &Address::from_str(TEST_ADDRESS)?, true)
        .await?;

    poll!(
        7,
        kld_1
            .call_rest_api::<WalletBalance, ()>(Method::GET, routes::GET_BALANCE, ())
            .await?
            .total_balance
            > 0
    );

    Ok(())
}

#[tokio::test(flavor = "multi_thread")]
#[ignore = "Only run this for manual testing"]
pub async fn test_manual() -> Result<()> {
    let tmp_dir = TempDir::new()?;

    let mut settings = test_settings(&tmp_dir, "manual");
    let cockroach = CockroachManager::builder(&tmp_dir, &mut settings)
        .await?
        .build()
        .await?;
    let bitcoin = BitcoinManager::new(&tmp_dir, &mut settings).await?;
    let electrs = ElectrsManager::new(&tmp_dir, &bitcoin, &mut settings).await?;

    bitcoin
        .generate_blocks(START_N_BLOCKS, &Address::from_str(TEST_ADDRESS)?, false)
        .await?;
    let _kld = KldManager::new(
        &tmp_dir,
        env!("CARGO_BIN_EXE_kld"),
        &cockroach,
        &electrs,
        &mut settings,
    )
    .await?;

    sleep_until(Instant::now() + Duration::from_secs(10000)).await;
    Ok(())
}

'''
'''--- mgr/Cargo.toml ---
[package]
name = "mgr"
version = "0.0.1"
edition = "2021"

[[bin]]
name = "kld-mgr"
path = "src/main.rs"

[workspace]

[dependencies]
anyhow = "1.0.82"
log = { version = "0.4", features = ["std"] }
serde_json = "1.0.116"
serde_derive = "1.0.154"
# FIXME use github version for toml support
format_serde_error = { version = "0.3.0", features = [ "colored", "serde_json" ], default-features = false, git = "https://github.com/AlexanderThaller/format_serde_error" }
serde = { version = "1.0.198", features = ["derive"] }
toml = "0.8.12"
tempfile = "3"
ctrlc = { version = "3.4", features = ["termination"] }
nix = "0.28.0"
regex = "1"
clap = { version = "4.5.4", features = ["derive", "env"] }
lazy_static = "1.4.0"
reqwest = { version = "0.12.4", features = ["blocking"], default-features = false }
url = { version = "2.5", features = ["serde"] }
base64 = "0.22.0"
toml-example = { version = "0.11.1", default-features = false }
x509-parser = "0.16.0"
slice_as_array = "1.1.0"
rand = "0.8.5"
rust-bip39 = "1.0.0"
bitcoin = "0.29.2"
macaroon = "0.3.0"
hex = "0.4.3"

'''
'''--- mgr/src/certs/cockroachdb.rs ---
use crate::command::status_to_pretty_err;
use crate::Host;
use anyhow::{Context, Result};
use std::collections::BTreeMap;
use std::fs;
use std::path::Path;
use std::process::Command;

fn cockroach(args: &[&str]) -> Result<()> {
    println!("cockroach {:?}", args);
    let status = Command::new("cockroach").args(args).status();
    status_to_pretty_err(status, "cockroach", args)?;
    Ok(())
}

fn create_ca(certs_dir: &Path) -> Result<()> {
    let ca_key_path = certs_dir.join("ca.key");
    let ca_crt_path = certs_dir.join("ca.crt");

    let ca_key_exists = ca_key_path.exists();

    // create ca key
    if ca_key_exists && ca_crt_path.exists() {
        return Ok(());
    }

    if ca_key_exists {
        let old_key_path = ca_key_path.with_file_name("ca.key.old");
        fs::rename(&ca_key_path, ca_key_path.with_file_name("ca.key.old")).with_context(|| {
            format!(
                "failed to rename old ca key from {} to {}",
                ca_key_path.display(),
                old_key_path.display()
            )
        })?;
    }

    cockroach(&[
        "cert",
        "create-ca",
        "--certs-dir",
        &certs_dir.display().to_string(),
        "--ca-key",
        &ca_key_path.display().to_string(),
        "--lifetime",
        "262800h",
        "--overwrite",
    ])
    .context("failed to create ca key")
}

fn create_client_cert(certs_dir: &Path, username: &str) -> Result<()> {
    let client_key_path = certs_dir.join(format!("client.{}.key", username));
    let client_crt_path = certs_dir.join(format!("client.{}.crt", username));
    if client_key_path.exists() && client_crt_path.exists() {
        return Ok(());
    }

    cockroach(&[
        "cert",
        "create-client",
        username,
        "--certs-dir",
        &certs_dir.display().to_string(),
        "--ca-key",
        &certs_dir.join("ca.key").display().to_string(),
        "--lifetime",
        "262799h",
        "--overwrite",
    ])
    .with_context(|| format!("failed to create client cert for {}", username))
}

fn create_node_cert(certs_dir: &Path, host: &Host) -> Result<()> {
    let node_key_path = certs_dir.join(format!("{}.node.key", host.name));
    let node_crt_path = certs_dir.join(format!("{}.node.crt", host.name));

    if node_key_path.exists() && node_crt_path.exists() {
        return Ok(());
    }
    cockroach(&[
        "cert",
        "create-node",
        &host.name,
        "localhost",
        "--certs-dir",
        &certs_dir.display().to_string(),
        "--ca-key",
        &certs_dir.join("ca.key").display().to_string(),
        "--lifetime",
        "262799h",
        "--overwrite",
    ])
    .with_context(|| format!("failed to create node cert for {}", host.name))?;

    fs::rename(certs_dir.join("node.crt"), node_crt_path)
        .with_context(|| format!("failed to rename node cert for {}", host.name))?;

    fs::rename(certs_dir.join("node.key"), node_key_path)
        .with_context(|| format!("failed to rename node key for {}", host.name))?;

    Ok(())
}

pub fn create_cockroachdb_certs(certs_dir: &Path, hosts: &BTreeMap<String, Host>) -> Result<()> {
    create_ca(certs_dir)?;

    create_client_cert(certs_dir, "root")?;
    create_client_cert(certs_dir, "kld")?;

    for host in hosts.values() {
        create_node_cert(certs_dir, host)?;
    }
    Ok(())
}

#[test]
fn test_create_cockroachdb_certs() -> Result<()> {
    use crate::config::{parse_config, TEST_CONFIG};
    use tempfile::tempdir;

    let dir = tempdir().context("Failed to create temporary directory")?;
    let config = parse_config(TEST_CONFIG, Path::new("/"), false, false)
        .context("Failed to parse config")?;

    create_cockroachdb_certs(dir.path(), &config.hosts).context("Failed to create certs")?;

    let mut expected_files = ([
        "ca.crt",
        "ca.key",
        "client.root.crt",
        "client.root.key",
        "client.kld.crt",
        "client.kld.key",
    ])
    .map(|f| f.to_string())
    .into_iter()
    .collect::<Vec<_>>();

    for host in config.hosts.values() {
        expected_files.push(format!("{}.node.crt", host.name));
        expected_files.push(format!("{}.node.key", host.name));
    }

    for f in &expected_files {
        assert!(dir.path().join(f).exists(), "Expected file {} to exist", f);
    }

    Ok(())
}

'''
'''--- mgr/src/certs/lightning.rs ---
use super::openssl;
use crate::Host;

use anyhow::{Context, Result};
use slice_as_array::{slice_as_array, slice_as_array_transmute};
use std::collections::BTreeMap;
use std::collections::HashSet;
use std::fs;
use std::net::IpAddr;
use std::path::Path;
use std::str::FromStr;
use x509_parser::extensions::GeneralName;
use x509_parser::extensions::ParsedExtension;
use x509_parser::pem::Pem;

fn create_tls_key(ca_key_path: &Path) -> Result<()> {
    let p = ca_key_path.display().to_string();
    let args = ["ecparam", "-genkey", "-name", "secp384r1", "-out", &p];
    openssl(&args).context("Failed to create TLS key")?;
    Ok(())
}

fn create_ca_cert(ca_cert_path: &Path, ca_key_path: &Path) -> Result<()> {
    if !ca_cert_path.exists() {
        openssl(&[
            "req",
            "-new",
            "-x509",
            "-days",
            "10950",
            "-key",
            &ca_key_path.display().to_string(),
            "-out",
            &ca_cert_path.display().to_string(),
            "-subj",
            "/CN=Kld CA",
        ])
        .context("Failed to create CA certificate")?;
    }
    Ok(())
}

fn create_cert(
    cert_dir: &Path,
    ca_key_path: &Path,
    ca_cert_path: &Path,
    host: &Host,
) -> Result<()> {
    let key_path = cert_dir.join(format!("{}.key", host.name));
    let cert_path = cert_dir.join(format!("{}.pem", host.name));
    let current_san = san_from_cert(&cert_path)?;

    let mut has_new_ip = false;
    if let Some(ipv4) = host.ipv4_address {
        if !current_san.contains(&ipv4) && !host.api_ip_access_list.is_empty() {
            has_new_ip = true;
        }
    }
    if let Some(ipv6) = host.ipv4_address {
        if !current_san.contains(&ipv6) && !host.api_ip_access_list.is_empty() {
            has_new_ip = true;
        }
    }

    if !key_path.exists() {
        create_tls_key(&key_path).with_context(|| {
            format!(
                "Failed to create key for lightning certificate: {}",
                host.name
            )
        })?
    }

    if !has_new_ip && cert_path.exists() {
        return Ok(());
    }

    let cert_conf = cert_path.with_file_name("cert.conf");
    let mut conf = r#"[req]
req_extensions = v3_req
distinguished_name = req_distinguished_name
[req_distinguished_name]
[ v3_req ]
basicConstraints = CA:FALSE
keyUsage = nonRepudiation, digitalSignature, keyEncipherment
subjectAltName = @alt_names
[alt_names]
DNS.1 = localhost
IP.1 = 127.0.0.1
IP.2 = ::1
"#
    .to_string();
    let mut ip_num = 3;
    if let Some(ip) = host.ipv4_address {
        conf += &format!("IP.{ip_num} = {ip}\n");
        ip_num += 1;
    }
    if let Some(ip) = host.ipv6_address {
        conf += &format!("IP.{ip_num} = {ip}\n");
        ip_num += 1;
    }

    if std::net::IpAddr::from_str(&host.hostname).is_ok() {
        conf += &format!("IP.{ip_num} = {}\n", host.hostname);
    } else {
        conf += &format!("DNS.2 = {}\n", host.hostname);
    }

    std::fs::write(&cert_conf, conf)?;
    openssl(&[
        "req",
        "-new",
        "-key",
        &key_path.display().to_string(),
        "-out",
        &cert_path.display().to_string(),
        "-config",
        &cert_conf.display().to_string(),
        "-subj",
        "/CN=localhost",
    ])
    .context("Failed to create certificate request")?;
    openssl(&[
        "x509",
        "-req",
        "-days",
        "10950",
        "-in",
        &cert_path.display().to_string(),
        "-CA",
        &ca_cert_path.display().to_string(),
        "-CAkey",
        &ca_key_path.display().to_string(),
        "-set_serial",
        "01",
        "-out",
        &cert_path.display().to_string(),
        "-extensions",
        "v3_req",
        "-extfile",
        &cert_conf.display().to_string(),
    ])
    .context("Failed to create certificate")?;
    Ok(())
}

/// Create or update certificates for lightning nodes in given directory.
pub fn create_lightning_certs(cert_dir: &Path, hosts: &BTreeMap<String, Host>) -> Result<()> {
    std::fs::create_dir_all(cert_dir).with_context(|| {
        format!(
            "Failed to create directory for lightning certificates: {}",
            cert_dir.display()
        )
    })?;

    let ca_key_path = cert_dir.join("ca.key");
    let ca_cert_path = cert_dir.join("ca.pem");
    if !ca_key_path.exists() {
        create_tls_key(&ca_key_path).with_context(|| {
            format!(
                "Failed to create key for lightning CA certificate: {}",
                ca_key_path.display()
            )
        })?;
    }
    create_ca_cert(&ca_cert_path, &ca_key_path).with_context(|| {
        format!(
            "Failed to create lightning CA certificate: {}",
            ca_cert_path.display()
        )
    })?;

    for h in hosts.values() {
        create_cert(cert_dir, &ca_key_path, &ca_cert_path, h)
            .with_context(|| format!("Failed to create lightning certificate: {}", h.name))?
    }

    Ok(())
}

/// Parse subject alternative name from certificate
fn san_from_cert(cert_path: &Path) -> Result<HashSet<IpAddr>> {
    let mut sans = HashSet::new();
    if let Ok(data) = fs::read(cert_path) {
        for pem in Pem::iter_from_buffer(&data) {
            let pem = pem?;
            let x509 = pem.parse_x509()?;
            for ext in x509.extensions() {
                if let ParsedExtension::SubjectAlternativeName(san) = ext.parsed_extension() {
                    for name in san.general_names.iter() {
                        if let GeneralName::IPAddress(byte) = name {
                            #[allow(clippy::transmute_ptr_to_ref)]
                            if let Some(ipv4_byte) = slice_as_array!(byte, [u8; 4]) {
                                sans.insert(IpAddr::from(*ipv4_byte));
                            }
                            #[allow(clippy::transmute_ptr_to_ref)]
                            if let Some(ipv6_byte) = slice_as_array!(byte, [u8; 16]) {
                                sans.insert(IpAddr::from(*ipv6_byte));
                            }
                        }
                    }
                }
            }
        }
    }
    Ok(sans)
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::config::{parse_config, TEST_CONFIG};
    use std::fs;
    use tempfile::tempdir;

    #[test]
    fn test_create_lightning_certs() -> Result<()> {
        let dir = tempdir().context("Failed to create temporary directory")?;
        let cert_dir = dir.path().join("certs");

        let config = parse_config(TEST_CONFIG, Path::new("/"), false, false)
            .context("Failed to parse config")?;

        create_lightning_certs(&cert_dir, &config.hosts)
            .context("Failed to create lightning certificates")?;

        let ca_key_path = cert_dir.join("ca.key");
        let ca_cert_path = cert_dir.join("ca.pem");
        let kld_key_path = cert_dir.join("kld-00.key");
        let kld_cert_path = cert_dir.join("kld-00.pem");
        let db0_cert_path = cert_dir.join("db-00.pem");
        let db1_cert_path = cert_dir.join("db-01.pem");

        let certs = vec![
            &ca_cert_path,
            &kld_cert_path,
            &db0_cert_path,
            &db1_cert_path,
        ];
        for c in certs {
            let cert = fs::read_to_string(c)
                .with_context(|| format!("Failed to read certificate: {}", c.display()))?;
            assert!(cert.contains("BEGIN CERTIFICATE"));
            assert!(cert.contains("END CERTIFICATE"));
        }
        let ca_key_modification_time = fs::metadata(&ca_key_path)?.modified()?;
        let ca_cert_modification_time = fs::metadata(&ca_cert_path)?.modified()?;
        let kld_key_modification_time = fs::metadata(&kld_key_path)?.modified()?;

        fs::remove_file(&kld_key_path)?;

        // check if the command is idempotent
        create_lightning_certs(&cert_dir, &config.hosts)?;

        assert_eq!(
            ca_key_modification_time,
            fs::metadata(&ca_key_path)?.modified()?
        );
        assert_eq!(
            ca_cert_modification_time,
            fs::metadata(&ca_cert_path)?.modified()?
        );
        assert_ne!(
            kld_key_modification_time,
            fs::metadata(&kld_key_path)?.modified()?
        );
        Ok(())
    }
}

'''
'''--- mgr/src/certs/mod.rs ---
//! This module contains the implementation of the `openssl` command.

use crate::command::status_to_pretty_err;
use anyhow::Result;
use std::process::Command;

pub use cockroachdb::create_cockroachdb_certs;
pub use lightning::create_lightning_certs;

mod cockroachdb;
mod lightning;

/// This function is used to run the `openssl` command.
pub fn openssl(args: &[&str]) -> Result<()> {
    println!("$ openssl {}", args.join(" "));
    let status = Command::new("openssl").args(args).status();
    status_to_pretty_err(status, "openssl", args)?;
    Ok(())
}

'''
'''--- mgr/src/command.rs ---
use anyhow::{bail, Context, Result};
use std::process::ExitStatus;

/// Human-friendly error messages for failed programs
pub fn status_to_pretty_err<E>(
    res: std::result::Result<ExitStatus, E>,
    command: &str,
    args: &[&str],
) -> Result<()>
where
    E: Send + 'static,
    E: Sync,
    E: std::error::Error,
{
    let status = res.with_context(|| format!("failed to start this command: {command}"))?;
    if status.success() {
        return Ok(());
    }
    match status.code() {
        Some(code) => bail!(
            "command {command} failed ({command} {}) with exit code: {code}",
            args.join(" ")
        ),
        None => bail!(
            "command {command} ({command} {}) was terminated by a signal",
            args.join(" ")
        ),
    }
}

'''
'''--- mgr/src/config.rs ---
use anyhow::{anyhow, bail, Context, Result};
use base64::{engine::general_purpose, Engine as _};
use bitcoin::secp256k1::PublicKey;
use hex::FromHex;
use log::warn;
use regex::Regex;
use reqwest::blocking::Client;
use serde::Serialize;
use serde_derive::Deserialize;
use std::collections::hash_map::DefaultHasher;
use std::collections::BTreeMap;
use std::collections::HashMap;
use std::env::var;
use std::fs;
use std::hash::{Hash, Hasher};
use std::net::IpAddr;
use std::path::{Path, PathBuf};
use std::process::Command;
use std::str::FromStr;
use toml_example::TomlExample;
use url::Url;

use super::secrets::Secrets;
use super::NixosFlake;

/// IpV6String allows prefix only address format and normal ipv6 address
///
/// Some providers include the subnet in their address shown in the webinterface i.e. 2607:5300:203:5cdf::/64
/// This format is rejected by IpAddr in Rust and we store subnets in a different configuration option.
/// This struct detects such cashes in the kuutamo.toml file and converting it to 2607:5300:203:5cdf:: with a warning message, providing a more user-friendly experience.
type IpV6String = String;

trait AsIpAddr {
    /// Handle ipv6 subnet identifier and normalize to a valid ip address and a mask.
    fn normalize(&self) -> Result<(IpAddr, Option<u8>)>;
}

impl AsIpAddr for IpV6String {
    fn normalize(&self) -> Result<(IpAddr, Option<u8>)> {
        if let Some(idx) = self.find('/') {
            let mask = self
                .get(idx + 1..self.len())
                .map(|i| i.parse::<u8>())
                .with_context(|| {
                    format!("ipv6_address contains invalid subnet identifier: {self}")
                })?
                .ok();

            match self.get(0..idx) {
                Some(addr_str) if mask.is_some() => {
                    if let Ok(addr) = addr_str.parse::<IpAddr>() {
                        warn!("{self:} contains a ipv6 subnet identifier... will use {addr:} for ipv6_address and {:} for ipv6_cidr", mask.unwrap_or_default());
                        Ok((addr, mask))
                    } else {
                        Err(anyhow!("ipv6_address is not invalid"))
                    }
                }
                _ => Err(anyhow!("ipv6_address is not invalid")),
            }
        } else {
            Ok((self.parse::<IpAddr>()?, None))
        }
    }
}

#[derive(TomlExample, Debug, Deserialize)]
pub struct ConfigFile {
    #[serde(default)]
    #[toml_example(nesting)]
    global: Global,

    /// The default values of host will use if any corresponding value is not provided in following hosts
    #[serde(default)]
    #[toml_example(nesting)]
    host_defaults: HostDefaultConfig,

    /// The configuration for the host, if any field not provided will use from host_defaults
    /// For general use case, following fields is needed
    /// - one of network should be configured (ipv4 or ipv6)
    /// - the disk information of the node
    #[serde(default)]
    #[toml_example(nesting)]
    hosts: HashMap<String, HostConfig>,
}

fn default_secret_directory() -> PathBuf {
    PathBuf::from("secrets")
}

fn default_knd_flake() -> String {
    "github:kuutamolabs/lightning-knd".to_string()
}

#[derive(Debug, Deserialize, Serialize, Clone, PartialEq, Eq)]
pub struct CockroachPeer {
    pub name: String,
    pub ipv4_address: Option<IpAddr>,
    pub ipv6_address: Option<IpAddr>,
}

#[derive(Debug, PartialEq, Eq, Clone, Serialize, Deserialize)]
pub enum LogLevel {
    #[serde(rename = "error")]
    Error,
    #[serde(rename = "warn")]
    Warn,
    #[serde(rename = "info")]
    Info,
    #[serde(rename = "debug")]
    Debug,
    #[serde(rename = "trace")]
    Trace,
}

/// Kuutamo monitor
#[derive(Debug, PartialEq, Eq, Clone, Serialize, Deserialize, Hash)]
pub struct KmonitorConfig {
    /// config for telegraf
    pub telegraf: Option<TelegrafConfig>,
    /// Promtail client endpoint with auth
    pub promtail: Option<String>,
}

#[derive(Debug, PartialEq, Eq, Clone, Serialize, Deserialize, Hash)]
pub struct TelegrafConfig {
    /// self host url for monitoring, None for kuutamo monitoring
    pub url: Option<Url>,
    /// username for kuutamo monitor
    pub username: String,
    /// password for kuutamo monitor
    pub password: String,
}

pub fn calculate_hash<T: Hash>(t: &T) -> u64 {
    let mut s = DefaultHasher::new();
    t.hash(&mut s);
    s.finish()
}

#[derive(Debug, Default, Deserialize, TomlExample)]
struct HostDefaultConfig {
    /// The default Ipv4 gateway of all node
    #[serde(default)]
    #[toml_example(default = "192.168.0.254")]
    ipv4_gateway: Option<IpAddr>,
    /// The default Ipv4 CIDR for all node
    #[serde(default)]
    #[toml_example(default = 24)]
    ipv4_cidr: Option<u8>,
    /// The default Ipv6 gateway of all node
    #[serde(default)]
    ipv6_gateway: Option<IpAddr>,
    /// The default Ipv6 CIDR of all node
    #[serde(default)]
    ipv6_cidr: Option<u8>,

    /// The default ssh public keys of the user
    /// After installation the user could login as root with the corresponding ssh private key
    #[serde(default)]
    #[toml_example(default = [ "ssh-ed25519 AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA...", ])]
    public_ssh_keys: Vec<String>,

    /// The default admin user for install,
    /// Please use `ubuntu` when you use OVH to install at first time,
    /// Ubuntu did not allow `root` login
    #[serde(default)]
    #[toml_example(default = "ubuntu")]
    install_ssh_user: Option<String>,

    /// Extra nixos module will deploy to the node
    #[serde(default)]
    #[toml_example(default = [ ])]
    extra_nixos_modules: Vec<String>,

    /// Default disk configure on all node
    #[serde(default)]
    #[toml_example(default = [ "/dev/vdb", ])]
    pub disks: Option<Vec<PathBuf>>,

    /// The default Token file for monitoring, default is "kuutamo-monitoring.token"
    /// Provide this if you have a different file
    #[serde(default)]
    #[toml_example(default = "kuutamo-monitoring.token")]
    kuutamo_monitoring_token_file: Option<PathBuf>,

    /// The default self monitoring server
    /// The url should implements [Prometheus's Remote Write API] (https://prometheus.io/docs/prometheus/latest/configuration/configuration/#remote_write).
    #[serde(default)]
    #[toml_example(default = "https://my.monitoring.server/api/v1/push")]
    self_monitoring_url: Option<Url>,
    /// The default http basic auth username to access self monitoring server
    #[serde(default)]
    self_monitoring_username: Option<String>,
    /// The default http basic auth password to access self monitoring server
    #[serde(default)]
    self_monitoring_password: Option<String>,

    /// The default push endpoint for the promtail client with auth to collect the journal logs for all nodes
    /// ex: https://<user_id>:<token>@<client hostname>/loki/api/vi/push
    #[serde(default)]
    promtail_client: Option<String>,

    /// The default alias color for all node
    #[toml_example(default = "6e2cf7")]
    pub kld_node_alias_color: Option<String>,

    /// The default probe interval for all node
    pub probe_interval: Option<u64>,
    /// The default probe amount in msat for all node
    pub probe_amt_msat: Option<u64>,
    /// The list of targets to probe
    #[toml_example(default = [])]
    pub probe_targets: Option<Vec<String>>,

    /// The graceful period in seconds when a shutdown signal is received
    #[toml_example(default = 5)]
    pub shutdown_graceful_sec: Option<u64>,
}

#[derive(Debug, Default, Deserialize, TomlExample)]
struct HostConfig {
    /// Ipv4 address of the node
    #[serde(default)]
    #[toml_example(default = "192.168.0.1")]
    ipv4_address: Option<IpAddr>,
    /// Ipv4 gateway of the node
    #[serde(default)]
    #[toml_example(default = "192.168.0.254")]
    ipv4_gateway: Option<IpAddr>,
    /// Ipv4 CIDR of the node
    #[serde(default)]
    #[toml_example(default = 24)]
    ipv4_cidr: Option<u8>,
    /// Nixos module will deploy to the node
    #[serde(default)]
    #[toml_example(default = "kld-node")]
    nixos_module: String,

    /// Mac address of the node
    #[toml_example(default = [ ])]
    #[serde(default)]
    #[toml_example(default = "00:0A:02:0B:03:0C")]
    pub mac_address: Option<String>,
    /// Ipv6 address of the node
    #[serde(default)]
    ipv6_address: Option<IpV6String>,
    /// Ipv6 gateway of the node
    #[serde(default)]
    ipv6_gateway: Option<IpAddr>,
    /// Ipv6 cidr of the node
    #[serde(default)]
    ipv6_cidr: Option<u8>,

    /// The ssh public keys of the user
    /// After installation the user could login as root with the corresponding ssh private key
    #[serde(default)]
    #[toml_example(skip)]
    #[toml_example(default = [ "ssh-ed25519 AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA...", ])]
    public_ssh_keys: Vec<String>,

    /// Admin user for install,
    /// Please use `ubuntu` when you use OVH to install at first time,
    /// Ubuntu did not allow `root` login
    #[serde(default)]
    #[toml_example(default = "ubuntu")]
    install_ssh_user: Option<String>,

    /// Setup host name for connection and host label on monitoring dashboard
    #[serde(default)]
    hostname: Option<String>,

    /// Disk configure on the node
    #[serde(default)]
    #[toml_example(default = [ "/dev/vdb", ])]
    pub disks: Option<Vec<PathBuf>>,

    #[serde(default)]
    pub bitcoind_disks: Option<Vec<PathBuf>>,

    /// String for node_alias, currently it only accept 32 chars ascii string for this field
    pub kld_node_alias: Option<String>,

    /// The default alias color for the node
    #[toml_example(default = "6e2cf7")]
    pub kld_node_alias_color: Option<String>,

    /// Set kld log level to `error`, `warn`, `info`, `debug`, `trace`
    #[serde(default)]
    #[toml_example(default = "info")]
    pub kld_log_level: Option<LogLevel>,

    /// Token file for monitoring, default is "kuutamo-monitoring.token"
    /// Provide this if you have a different file
    #[serde(default)]
    #[toml_example(default = "kuutamo-monitoring.token")]
    kuutamo_monitoring_token_file: Option<PathBuf>,
    /// Self monitoring server
    /// The url should implements [Prometheus's Remote Write API] (https://prometheus.io/docs/prometheus/latest/configuration/configuration/#remote_write).
    #[serde(default)]
    #[toml_example(default = "https://my.monitoring.server/api/v1/push")]
    self_monitoring_url: Option<Url>,
    /// The http basic auth username to access self monitoring server
    #[serde(default)]
    self_monitoring_username: Option<String>,
    /// The http basic auth password to access self monitoring server
    #[serde(default)]
    self_monitoring_password: Option<String>,

    /// The push endpoint for the promtail client with auth to collect the journal logs for the node
    /// ex: https://<user_id>:<token>@<client hostname>/loki/api/vi/push
    #[serde(default)]
    promtail_client: Option<String>,

    /// The communication port of kld
    #[toml_example(default = 2244)]
    #[serde(default)]
    kld_rest_api_port: Option<u16>,
    /// The ip addresses list will allow to communicate with kld, if empty, the kld-cli can only
    /// use on the node.
    #[serde(default)]
    #[toml_example(default = [])]
    kld_api_ip_access_list: Vec<IpAddr>,

    /// The interface to access network
    #[serde(default)]
    #[toml_example(default = "eth0")]
    network_interface: Option<String>,

    /// By default, the nodes in cluster will update daily, sequetially, starting at 2 AM UTC.
    /// On a per node basis you can override this with the setting below
    #[serde(default)]
    #[toml_example(default = "*-*-* 2:00:00")]
    upgrade_schedule: Option<String>,

    /// The probe interval in second for the node
    #[serde(default)]
    #[toml_example(default = 5)]
    pub probe_interval: Option<u64>,
    /// The default probe amount in msat for the node
    #[serde(default)]
    #[toml_example(default = 50000)]
    pub probe_amt_msat: Option<u64>,
    /// The list of targets to probe
    #[serde(default)]
    #[toml_example(default = [])]
    pub probe_targets: Vec<String>,

    /// The graceful period in seconds when a shutdown signal is received
    #[serde(default)]
    #[toml_example(default = 5)]
    pub shutdown_graceful_sec: Option<u64>,

    #[serde(flatten)]
    #[toml_example(skip)]
    others: BTreeMap<String, toml::Value>,
}

/// NixOS host configuration
#[derive(Debug, PartialEq, Eq, Clone, Serialize)]
pub struct Host {
    /// Name identifying the host
    pub name: String,

    /// NixOS module to use as a base for the host from the flake
    pub nixos_module: String,

    /// Extra NixOS modules to include in the system
    pub extra_nixos_modules: Vec<String>,

    /// Mac address of the public interface to use
    pub mac_address: Option<String>,

    /// Public ipv4 address of the host
    pub ipv4_address: Option<IpAddr>,
    /// Cidr of the public ipv4 address
    pub ipv4_cidr: Option<u8>,
    /// Public ipv4 gateway ip address
    pub ipv4_gateway: Option<IpAddr>,

    /// Public ipv6 address of the host
    pub ipv6_address: Option<IpAddr>,
    /// Cidr of the public ipv6 address
    pub ipv6_cidr: Option<u8>,
    /// Public ipv6 gateway address of the host
    pub ipv6_gateway: Option<IpAddr>,

    /// SSH Username used when connecting during installation
    pub install_ssh_user: String,

    /// Hostname used for connection and host label on monitoring dashboard
    pub hostname: String,

    /// Public ssh keys that will be added to the nixos configuration
    pub public_ssh_keys: Vec<String>,

    /// Block device paths to use for installing
    pub disks: Vec<PathBuf>,

    /// Block device paths to use for bitcoind's blockchain state
    pub bitcoind_disks: Vec<PathBuf>,

    /// CockroachDB nodes to connect to
    pub cockroach_peers: Vec<CockroachPeer>,

    /// alias of node in lightning
    pub kld_node_alias: Option<String>,
    /// alias color of node in lightning
    pub kld_node_alias_color: Option<String>,

    /// Log level for kld service
    pub kld_log_level: Option<LogLevel>,

    /// Setup telegraf output auth for kuutamo monitor server
    #[serde(skip_serializing)]
    pub kmonitor_config: Option<KmonitorConfig>,

    /// The communication port of kld
    pub rest_api_port: Option<u16>,
    /// The ip addresses list will allow to communicate with kld
    pub api_ip_access_list: Vec<IpAddr>,

    /// Has monitoring server or not
    pub telegraf_has_monitoring: bool,

    /// Has client for journal logs or not
    pub promtail_has_client: bool,

    /// Hash for monitoring config
    pub monitor_config_hash: String,

    /// The interface of node to access the internet
    pub network_interface: Option<String>,

    /// Is the mnemonic provided by mgr
    pub kld_preset_mnemonic: Option<bool>,

    /// By default, the nodes in cluster will update daily, sequetially, starting at 2 AM UTC.
    /// On a per node basis you can override this with the setting below
    pub upgrade_schedule: Option<String>,

    /// The probe only work with `probe_interval` and `probe_amt_msat` both set with a non-zero int
    /// The probe interval for the node
    pub probe_interval: Option<u64>,
    /// The default probe amount in msat for the node
    pub probe_amt_msat: Option<u64>,
    /// The list of targets to probe
    pub probe_targets: Vec<String>,

    /// The graceful period in seconds when a shutdown signal is received
    pub shutdown_graceful_sec: Option<u64>,
}

impl Host {
    /// Returns prepared secrets directory for host
    pub fn secrets(&self, secrets_dir: &Path, access_tokens: &String) -> Result<Secrets> {
        let lightning = secrets_dir.join("lightning");
        let cockroachdb = secrets_dir.join("cockroachdb");
        let mnemonic = secrets_dir.join("mnemonic");
        let ssh = secrets_dir.join("ssh");

        let mut secret_files = vec![
            // for kld
            (
                PathBuf::from("/var/lib/secrets/kld/ca.pem"),
                fs::read(lightning.join("ca.pem")).context("failed to read ca.pem")?,
                0o600,
            ),
            (
                PathBuf::from("/var/lib/secrets/kld/kld.pem"),
                fs::read(lightning.join(format!("{}.pem", self.name)))
                    .context("failed to read kld.pem")?,
                0o600,
            ),
            (
                PathBuf::from("/var/lib/secrets/kld/kld.key"),
                fs::read(lightning.join(format!("{}.key", self.name)))
                    .context("failed to read kld.key")?,
                0o600,
            ),
            (
                PathBuf::from("/var/lib/secrets/kld/client.kld.crt"),
                fs::read(cockroachdb.join("client.kld.crt"))
                    .context("failed to read client.kld.crt")?,
                0o600,
            ),
            (
                PathBuf::from("/var/lib/secrets/kld/client.kld.key"),
                fs::read(cockroachdb.join("client.kld.key"))
                    .context("failed to read client.kld.key")?,
                0o600,
            ),
            // for cockroachdb
            (
                PathBuf::from("/var/lib/secrets/cockroachdb/ca.crt"),
                fs::read(cockroachdb.join("ca.crt")).context("failed to read ca.crt")?,
                0o600,
            ),
            (
                PathBuf::from("/var/lib/secrets/cockroachdb/client.root.crt"),
                fs::read(cockroachdb.join("client.root.crt"))
                    .context("failed to read client.root.crt")?,
                0o600,
            ),
            (
                PathBuf::from("/var/lib/secrets/cockroachdb/client.root.key"),
                fs::read(cockroachdb.join("client.root.key"))
                    .context("failed to read client.root.key")?,
                0o600,
            ),
            (
                PathBuf::from("/var/lib/secrets/cockroachdb/node.crt"),
                fs::read(cockroachdb.join(format!("{}.node.crt", self.name)))
                    .context("failed to read node.crt")?,
                0o600,
            ),
            (
                PathBuf::from("/var/lib/secrets/cockroachdb/node.key"),
                fs::read(cockroachdb.join(format!("{}.node.key", self.name)))
                    .context("failed to read node.key")?,
                0o600,
            ),
            (
                PathBuf::from("/root/.ssh/id_ed25519"),
                fs::read(ssh.join("id_ed25519")).context("failed to read deploy key")?,
                0o600,
            ),
            (
                PathBuf::from("/root/.ssh/id_ed25519.pub"),
                fs::read(ssh.join("id_ed25519.pub")).context("failed to read deploy pub key")?,
                0o644,
            ),
            // sshd server key
            (
                PathBuf::from("/var/lib/secrets/sshd_key"),
                fs::read(secrets_dir.join("sshd").join(&self.name))
                    .context("failed to read sshd server key")?,
                0o600,
            ),
            (
                PathBuf::from("/var/lib/secrets/access-tokens"),
                format!("ACCESS_TOKENS={access_tokens:}").as_bytes().into(),
                0o600,
            ),
            (
                PathBuf::from("/var/lib/secrets/disk_encryption_key"),
                fs::read(secrets_dir.join("disk_encryption_key"))
                    .context("failed to read disk_encrypted_key")?,
                0o600,
            ),
        ];
        if mnemonic.exists() {
            secret_files.push((
                PathBuf::from("/var/lib/secrets/mnemonic"),
                fs::read(mnemonic).context("failed to read mnemonic")?,
                0o600,
            ))
        }
        if let Some(KmonitorConfig { telegraf, promtail }) = &self.kmonitor_config {
            if let Some(TelegrafConfig {
                url,
                username,
                password,
            }) = telegraf
            {
                secret_files.push((
                    PathBuf::from("/var/lib/secrets/telegraf"),
                    format!("MONITORING_URL={}\nMONITORING_USERNAME={username}\nMONITORING_PASSWORD={password}", url.as_ref().map(|u|u.to_string()).unwrap_or("https://mimir.monitoring-00-cluster.kuutamo.computer/api/v1/push".to_string())).as_bytes().into(),
                    0o600
                ));
            }
            if let Some(client) = promtail {
                secret_files.push((
                    PathBuf::from("/var/lib/secrets/promtail"),
                    format!("CLIENT_URL={client}").as_bytes().into(),
                    0o600,
                ));
            }
        }

        Secrets::new(secret_files.iter()).context("failed to prepare uploading secrets")
    }
    /// The hostname to which we will deploy
    pub fn deploy_ssh_target(&self) -> String {
        format!("root@{}", self.hostname)
    }
    /// The hostname to which we will deploy
    pub fn flake_uri(&self, flake: &NixosFlake) -> String {
        format!("{}#{}", flake.path().display(), self.name)
    }
}

/// Global configuration affecting all hosts
#[derive(Debug, PartialEq, Eq, Clone, Deserialize, Default, TomlExample)]
pub struct Global {
    /// Flake url for your deployment config
    /// Please refer https://github.com/kuutamolabs/deployment-example
    #[toml_example(default = "github:kuutamolabs/deployment-example")]
    pub deployment_flake: String,

    /// Tokens for access the deployment flake and the dependencies thereof
    /// Please make sure it is never exipired,
    /// because we can not update the token after deploy
    #[toml_example(default = "github.com=ghp_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx")]
    pub access_tokens: String,

    /// Flake url for KND
    #[serde(default = "default_knd_flake")]
    #[toml_example(default = "github:kuutamolabs/lightning-knd")]
    pub knd_flake: String,

    /// Directory where the secrets are stored i.e. certificates
    #[serde(default = "default_secret_directory")]
    #[toml_example(default = "secrets")]
    pub secret_directory: PathBuf,
}

fn validate_global(
    global: &Global,
    working_directory: &Path,
    check_deployment_repo: bool,
) -> Result<Global> {
    let mut global = global.clone();
    if global.secret_directory.is_relative() {
        global.secret_directory = working_directory.join(global.secret_directory);
    };
    if let Ok(output) = Command::new("nix")
        .args([
            "flake",
            "show",
            "--refresh",
            "--access-tokens",
            &global.access_tokens,
            &global.deployment_flake,
        ])
        .output()
    {
        if !output.status.success() && var("FLAKE_CHECK").is_err() && check_deployment_repo {
            bail!(
                r#"deployment flake {} is not accessible, please check your access token, network connection,
and the deployment repository has a flake.lock"#,
                global.deployment_flake
            );
        }
    }
    Ok(global)
}

fn validate_host(
    name: &str,
    host: &HostConfig,
    default: &HostDefaultConfig,
    preset_mnemonic: bool,
) -> Result<Host> {
    if !host.others.is_empty() {
        bail!(
            "{} are not allowed fields",
            host.others
                .clone()
                .into_keys()
                .collect::<Vec<String>>()
                .join(", ")
        );
    }

    let name = name.to_string();

    if name.is_empty() || name.len() > 63 {
        bail!(
            "a host's name must be between 1 and 63 characters long, got: '{}'",
            name
        );
    }
    let hostname_regex = Regex::new(r"^[a-z0-9][a-z0-9\-]{0,62}$").unwrap();
    if !hostname_regex.is_match(&name) {
        bail!("a host's name must only contain letters from a to z, the digits from 0 to 9, and the hyphen (-). But not starting with a hyphen. got: '{}'", name);
    }
    let mac_address = if let Some(ref a) = &host.mac_address {
        let mac_address_regex = Regex::new(r"^([0-9A-Fa-f]{2}[:-]){5}([0-9A-Fa-f]{2})$").unwrap();
        if !mac_address_regex.is_match(a) {
            bail!("mac address does match a valid format: {} (valid example value: 02:42:34:d1:18:7a)", a);
        }
        Some(a.clone())
    } else {
        None
    };

    let ipv4_address = if let Some(address) = host.ipv4_address {
        if !address.is_ipv4() {
            bail!("ipv4_address provided for hosts.{name} is not an ipv4 address: {address}");
        }
        // FIXME: this is currently an unstable feature
        //if address.is_global() {
        //    warn!("ipv4_address provided for hosts.{} is not a public ipv4 address: {}.", name, address);
        //}
        Some(address)
    } else {
        None
    };

    let ipv4_cidr = if let Some(cidr) = host.ipv4_cidr.or(default.ipv4_cidr) {
        if !(0..33_u8).contains(&cidr) {
            bail!("ipv4_cidr for hosts.{name} is not between 0 and 32: {cidr}")
        }
        Some(cidr)
    } else {
        None
    };

    let mut extra_nixos_modules = vec![];
    extra_nixos_modules.extend_from_slice(&default.extra_nixos_modules);

    let ipv4_gateway = host.ipv4_gateway.or(default.ipv4_gateway);

    let ipv6_cidr = host.ipv6_cidr.or(default.ipv6_cidr);

    let ipv6_gateway = host.ipv6_gateway.or(default.ipv6_gateway);

    let (ipv6_address, mask) = if let Some(ipv6_address) = host.ipv6_address.as_ref() {
        let (ipv6_address, mask) = ipv6_address
            .normalize()
            .with_context(|| format!("ipv6_address provided for host.{name:} is not valid"))?;
        if !ipv6_address.is_ipv6() {
            bail!("value provided in ipv6_address for hosts.{name} is not an ipv6 address: {ipv6_address}");
        }

        if let Some(ipv6_cidr) = ipv6_cidr {
            if !(0..129_u8).contains(&ipv6_cidr) {
                bail!("ipv6_cidr for hosts.{name} is not between 0 and 128: {ipv6_cidr}")
            }
        } else if mask.is_none() {
            bail!("no ipv6_cidr provided for hosts.{name}");
        }

        if ipv6_gateway.is_none() {
            bail!("no ipv6_gateway provided for hosts.{name}")
        }

        // FIXME: this is currently an unstable feature
        //if ipv6_address.is_global() {
        //    warn!("ipv6_address provided for hosts.{} is not a public ipv6 address: {}.", name, ipv6_address);
        //}

        (Some(ipv6_address), mask)
    } else {
        (None, None)
    };

    let address = ipv4_address
        .or(ipv6_address)
        .with_context(|| format!("no ipv4_address or ipv6_address provided for hosts.{name}"))?;

    if ipv4_gateway.is_none() && ipv6_gateway.is_none() {
        bail!("no ipv4_gateway or ipv6_gateway provided for hosts.{name}");
    }

    let hostname = host
        .hostname
        .as_ref()
        .cloned()
        .unwrap_or_else(|| address.to_string());

    let install_ssh_user = host
        .install_ssh_user
        .as_ref()
        .or(default.install_ssh_user.as_ref())
        .cloned()
        .unwrap_or_else(|| String::from("root"));

    let mut public_ssh_keys = vec![];
    public_ssh_keys.extend_from_slice(&host.public_ssh_keys);
    public_ssh_keys.extend_from_slice(&default.public_ssh_keys);
    if public_ssh_keys.is_empty() {
        bail!("no public_ssh_keys provided for hosts.{name}");
    }

    let default_disks = vec![PathBuf::from("/dev/nvme0n1"), PathBuf::from("/dev/nvme1n1")];
    let disks = host
        .disks
        .as_ref()
        .or(default.disks.as_ref())
        .unwrap_or(&default_disks)
        .to_vec();

    if disks.is_empty() {
        bail!("no disks specified for hosts.{name}");
    }

    let default_bitcoind_disks = vec![];

    let bitcoind_disks = host
        .bitcoind_disks
        .as_ref()
        .unwrap_or(&default_bitcoind_disks)
        .to_vec();

    let telegraf_config = match (
        &host
            .self_monitoring_url
            .as_ref()
            .or(default.self_monitoring_url.as_ref()),
        &host
            .self_monitoring_username
            .as_ref()
            .or(default.self_monitoring_username.as_ref()),
        &host
            .self_monitoring_password
            .as_ref()
            .or(default.self_monitoring_password.as_ref()),
        fs::read_to_string(
            host.kuutamo_monitoring_token_file
                .as_ref()
                .or(default.kuutamo_monitoring_token_file.as_ref())
                .unwrap_or(&PathBuf::from("kuutamo-monitoring.token")),
        )
        .ok()
        .map(|s| s.trim().into())
        .and_then(|t| decode_token(t).ok()),
    ) {
        (url, Some(username), Some(password), _) if url.is_some() => Some(TelegrafConfig {
            url: url.cloned(),
            username: username.to_string(),
            password: password.to_string(),
        }),
        (url, _, _, Some((user_id, password))) if url.is_some() => Some(TelegrafConfig {
            url: url.cloned(),
            username: user_id,
            password,
        }),
        (None, _, _, Some((user_id, password))) => {
            try_verify_kuutamo_monitoring_config(user_id, password)
        }
        (None, Some(_), _, None) | (None, _, Some(_), None) => {
            bail!("The monitoring config for {name} is incomplete, please check");
        }
        _ => {
            eprintln!("auth information for monitoring is insufficient, will not set up monitoring when deploying");
            None
        }
    };
    let kmonitor_config = if telegraf_config.is_some()
        || host.promtail_client.is_some()
        || default.promtail_client.is_some()
    {
        Some(KmonitorConfig {
            telegraf: telegraf_config,
            promtail: host
                .promtail_client
                .clone()
                .or(default.promtail_client.clone()),
        })
    } else {
        None
    };

    let telegraf_has_monitoring = kmonitor_config
        .as_ref()
        .map(|c| c.telegraf.is_some())
        .unwrap_or_default();
    let promtail_has_client = kmonitor_config
        .as_ref()
        .map(|c| c.promtail.is_some())
        .unwrap_or_default();
    let monitor_config_hash = calculate_hash(&kmonitor_config).to_string();

    if let Some(alias) = &host.kld_node_alias {
        if alias.as_bytes().len() > 32 {
            bail!("alias should be less then 32 bytes");
        }
    }

    let kld_node_alias_color = host
        .kld_node_alias_color
        .as_ref()
        .or(default.kld_node_alias_color.as_ref());
    if let Some(color_code) = kld_node_alias_color {
        if <[u8; 3]>::from_hex(color_code).is_err() {
            bail!("alias color should be in hex format");
        }
    }

    // XXX Do validate timer format
    // if let Some(schedule) = host.update_schedule.as_ref() {
    //     if parse(schedule).is_err() {
    //         bail!("update schedule is not valid")
    //     }
    // }

    let probe_targets = if host.nixos_module.starts_with("kld") {
        let mut targets = default.probe_targets.clone().unwrap_or_default();
        targets.append(&mut host.probe_targets.clone());
        targets
    } else {
        Vec::new()
    };
    for target in &probe_targets {
        if PublicKey::from_str(target).is_err() {
            bail!(
                "{} is not a valid public key to be the target of probe",
                target
            );
        }
    }

    Ok(Host {
        name,
        nixos_module: host.nixos_module.clone(),
        extra_nixos_modules,
        install_ssh_user,
        hostname,
        mac_address,
        ipv4_address,
        ipv4_cidr,
        ipv4_gateway,
        ipv6_address,
        ipv6_cidr: mask.or(ipv6_cidr),
        ipv6_gateway,
        public_ssh_keys,
        disks,
        bitcoind_disks,
        cockroach_peers: vec![],
        kld_log_level: host.kld_log_level.to_owned(),
        kmonitor_config,
        telegraf_has_monitoring,
        promtail_has_client,
        monitor_config_hash,
        kld_node_alias: host.kld_node_alias.to_owned(),
        kld_node_alias_color: kld_node_alias_color.cloned(),
        api_ip_access_list: host.kld_api_ip_access_list.to_owned(),
        rest_api_port: host.kld_rest_api_port,
        network_interface: host.network_interface.to_owned(),
        kld_preset_mnemonic: Some(preset_mnemonic),
        upgrade_schedule: host.upgrade_schedule.to_owned(),
        probe_interval: if host.nixos_module.starts_with("kld") {
            host.probe_interval.or(default.probe_interval)
        } else {
            None
        },
        probe_amt_msat: if host.nixos_module.starts_with("kld") {
            host.probe_amt_msat.or(default.probe_amt_msat)
        } else {
            None
        },
        probe_targets,
        shutdown_graceful_sec: host.shutdown_graceful_sec.or(default.shutdown_graceful_sec),
    })
}

/// Try to access kuutamo monitoring , if auth is invalid the config will drop
fn try_verify_kuutamo_monitoring_config(
    user_id: String,
    password: String,
) -> Option<TelegrafConfig> {
    let client = Client::new();
    let username = format!("kld-{}", user_id);
    if let Ok(r) = client
        .get("https://mimir.monitoring-00-cluster.kuutamo.computer")
        .basic_auth(&username, Some(&password))
        .send()
    {
        if r.status() == reqwest::StatusCode::UNAUTHORIZED {
            eprintln!("token for kuutamo monitoring.token is invalid, please check, else the monitor will not work after deploy");
            return None;
        }
    } else {
        eprintln!("Could not validate kuutamo-monitoring.token (network issue)");
    }

    Some(TelegrafConfig {
        url: None,
        username,
        password,
    })
}

/// Validated configuration
#[derive(Clone)]
pub struct Config {
    /// Hosts as defined in the configuration
    pub hosts: BTreeMap<String, Host>,
    /// Configuration affecting all hosts
    pub global: Global,
}

/// Parse toml configuration
pub fn parse_config(
    content: &str,
    working_directory: &Path,
    preset_mnemonic: bool,
    check_deployment_repo: bool,
) -> Result<Config> {
    let config: ConfigFile = toml::from_str(content)?;

    let mut hosts = config
        .hosts
        .iter()
        .map(|(name, host)| {
            Ok((
                name.to_string(),
                validate_host(name, host, &config.host_defaults, preset_mnemonic)?,
            ))
        })
        .collect::<Result<BTreeMap<_, _>>>()?;
    let cockroach_peers = hosts
        .iter()
        .map(|(name, host)| CockroachPeer {
            name: name.to_string(),
            ipv4_address: host.ipv4_address,
            ipv6_address: host.ipv6_address,
        })
        .collect::<Vec<_>>();
    for host in hosts.values_mut() {
        host.cockroach_peers = cockroach_peers.clone();
    }
    let kld_nodes = hosts
        .iter()
        .filter(|(_, host)| host.nixos_module == "kld-node")
        .count();
    if kld_nodes != 1 {
        bail!("Exactly one kld-node is required, found {}", kld_nodes);
    }
    let cockroach_nodes = hosts
        .iter()
        .filter(|(_, host)| host.nixos_module == "cockroachdb-node")
        .count();
    if cockroach_nodes != 0 && cockroach_nodes < 2 {
        bail!(
            "Either zero or two cockroach-nodes are required, found {}",
            cockroach_nodes
        );
    }

    let global = validate_global(&config.global, working_directory, check_deployment_repo)?;

    Ok(Config { hosts, global })
}

/// Load configuration from path
pub fn load_configuration(
    path: &Path,
    preset_mnemonic: bool,
    check_deployment_repo: bool,
) -> Result<Config> {
    let content = fs::read_to_string(path).context("Cannot read file")?;
    let working_directory = path.parent().with_context(|| {
        format!(
            "Cannot determine working directory from path: {}",
            path.display()
        )
    })?;
    parse_config(
        &content,
        working_directory,
        preset_mnemonic,
        check_deployment_repo,
    )
}

fn decode_token(s: String) -> Result<(String, String)> {
    let binding =
        general_purpose::STANDARD_NO_PAD.decode(s.trim_matches(|c| c == '=' || c == '\n'))?;
    let decode_str = std::str::from_utf8(&binding)?;
    decode_str
        .split_once(':')
        .map(|(u, p)| (u.trim().to_string(), p.trim().to_string()))
        .ok_or(anyhow!("token should be `username: password` pair"))
}

#[cfg(test)]
pub(crate) const TEST_CONFIG: &str = r#"
[global]
knd_flake = "github:kuutamolabs/lightning-knd"
deployment_flake = "github:kuutamolabs/test-env-one"
access_tokens = "github.com=ghp_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"

[host_defaults]
public_ssh_keys = [
  '''ssh-ed25519 AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA foobar'''
]
ipv4_cidr = 24
ipv6_cidr = 48
ipv4_gateway = "199.127.64.1"
ipv6_gateway = "2605:9880:400::1"

[hosts]
[hosts.kld-00]
nixos_module = "kld-node"
ipv4_address = "199.127.64.2"
ipv6_address = "2605:9880:400::2"
ipv6_cidr = 48

[hosts.db-00]
nixos_module = "cockroachdb-node"
ipv4_address = "199.127.64.3"
ipv6_address = "2605:9880:400::3"

[hosts.db-01]
nixos_module = "cockroachdb-node"
ipv4_address = "199.127.64.4"
ipv6_address = "2605:9880:400::4"
"#;

#[test]
pub fn test_parse_config() -> Result<()> {
    use std::str::FromStr;

    let config = parse_config(TEST_CONFIG, Path::new("/"), false, false)?;
    assert_eq!(config.global.knd_flake, "github:kuutamolabs/lightning-knd");
    assert_eq!(
        config.global.deployment_flake,
        "github:kuutamolabs/test-env-one"
    );

    let hosts = &config.hosts;
    assert_eq!(hosts.len(), 3);
    assert_eq!(
        hosts["kld-00"]
            .ipv4_address
            .context("missing ipv4_address")?,
        IpAddr::from_str("199.127.64.2").unwrap()
    );
    assert_eq!(hosts["kld-00"].ipv4_cidr.context("missing ipv4_cidr")?, 24);
    assert_eq!(
        hosts["db-00"]
            .ipv4_gateway
            .context("missing ipv4_gateway")?,
        IpAddr::from_str("199.127.64.1").unwrap()
    );
    assert_eq!(
        hosts["db-00"].ipv6_address,
        IpAddr::from_str("2605:9880:400::3").ok()
    );
    assert_eq!(hosts["kld-00"].ipv6_cidr, Some(48));
    assert_eq!(
        hosts["kld-00"].ipv6_gateway,
        IpAddr::from_str("2605:9880:400::1").ok()
    );

    parse_config(TEST_CONFIG, Path::new("/"), false, false)?;

    Ok(())
}

#[test]
pub fn test_parse_config_with_redundant_filds() {
    let parse_result = parse_config(
        &format!("{}\nredundant = 111", TEST_CONFIG),
        Path::new("/"),
        false,
        false,
    );
    assert!(parse_result.is_err());
}

#[test]
fn test_valid_ip_string_for_ipv6() {
    let ip: IpV6String = "2607:5300:203:5cdf::".into();
    assert_eq!(ip.normalize().unwrap().1, None);

    let subnet_identifire: IpV6String = "2607:5300:203:5cdf::/64".into();
    assert_eq!(
        subnet_identifire.normalize().unwrap().0,
        ip.normalize().unwrap().0
    );
    assert_eq!(subnet_identifire.normalize().unwrap().1, Some(64));
}

#[test]
fn test_invalid_string_for_ipv6() {
    let mut invalid_str: IpV6String = "2607:5300:203:7cdf::/".into();
    assert!(invalid_str.normalize().is_err());

    invalid_str = "/2607:5300:203:7cdf::".into();
    assert!(invalid_str.normalize().is_err());
}

#[test]
fn test_validate_host() -> Result<()> {
    let mut config = HostConfig {
        ipv4_address: Some(
            "192.168.0.1"
                .parse::<IpAddr>()
                .context("Invalid IP address")?,
        ),
        nixos_module: "kld-node".to_string(),
        ipv4_cidr: Some(0),
        ipv4_gateway: Some(
            "192.168.255.255"
                .parse::<IpAddr>()
                .context("Invalid IP address")?,
        ),
        ipv6_address: None,
        ipv6_gateway: None,
        ipv6_cidr: None,
        public_ssh_keys: vec!["".to_string()],
        upgrade_schedule: Some("*-*-* 2:00:00".to_string()),
        ..Default::default()
    };
    assert_eq!(
        validate_host("ipv4-only", &config, &HostDefaultConfig::default(), false).unwrap(),
        Host {
            name: "ipv4-only".to_string(),
            nixos_module: "kld-node".to_string(),
            extra_nixos_modules: Vec::new(),
            mac_address: None,
            ipv4_address: Some(
                "192.168.0.1"
                    .parse::<IpAddr>()
                    .context("Invalid IP address")?
            ),
            ipv4_cidr: Some(0),
            ipv4_gateway: Some(
                "192.168.255.255"
                    .parse::<IpAddr>()
                    .context("Invalid IP address")?
            ),
            ipv6_address: None,
            ipv6_cidr: None,
            ipv6_gateway: None,
            install_ssh_user: "root".to_string(),
            hostname: "192.168.0.1".to_string(),
            public_ssh_keys: vec!["".to_string()],
            disks: vec!["/dev/nvme0n1".into(), "/dev/nvme1n1".into()],
            cockroach_peers: vec![],
            bitcoind_disks: vec![],
            kld_node_alias: None,
            kld_node_alias_color: None,
            kld_log_level: None,
            kmonitor_config: None,
            telegraf_has_monitoring: false,
            promtail_has_client: false,
            monitor_config_hash: "13646096770106105413".to_string(),
            api_ip_access_list: Vec::new(),
            rest_api_port: None,
            network_interface: None,
            kld_preset_mnemonic: Some(false),
            upgrade_schedule: Some("*-*-* 2:00:00".to_string()),
            probe_interval: None,
            probe_amt_msat: None,
            probe_targets: Vec::new(),
            shutdown_graceful_sec: None,
        }
    );

    // If `ipv6_address` is provided, the `ipv6_gateway` and `ipv6_cidr` should be provided too,
    // else the error will raise
    config.ipv6_address = Some("2607:5300:203:6cdf::".into());
    assert!(validate_host("ipv4-only", &config, &HostDefaultConfig::default(), false).is_err());

    config.ipv6_gateway = Some(
        "2607:5300:0203:6cff:00ff:00ff:00ff:00ff"
            .parse::<IpAddr>()
            .unwrap(),
    );
    assert!(validate_host("ipv4-only", &config, &HostDefaultConfig::default(), false).is_err());

    // The `ipv6_cidr` could be provided by subnet in address field
    config.ipv6_address = Some("2607:5300:203:6cdf::/64".into());
    assert!(validate_host("ipv4-only", &config, &HostDefaultConfig::default(), false).is_ok());

    Ok(())
}

#[test]
fn test_incomplete_monitoring_setting() -> Result<()> {
    let config = HostConfig {
        ipv4_address: Some(
            "192.168.0.1"
                .parse::<IpAddr>()
                .context("Invalid IP address")?,
        ),
        nixos_module: "kld-node".to_string(),
        ipv4_cidr: Some(0),
        ipv4_gateway: Some(
            "192.168.255.255"
                .parse::<IpAddr>()
                .context("Invalid IP address")?,
        ),
        ipv6_address: None,
        ipv6_gateway: None,
        ipv6_cidr: None,
        public_ssh_keys: vec!["".to_string()],
        upgrade_schedule: Some("*-*-* 2:00:00".to_string()),
        self_monitoring_username: Some("username".to_string()),
        self_monitoring_password: Some("password".to_string()),
        ..Default::default()
    };
    assert!(validate_host("ipv4-only", &config, &HostDefaultConfig::default(), false).is_err());
    Ok(())
}

'''
'''--- mgr/src/flake.rs ---
use anyhow::{Context, Result};
use std::env::var;
use std::io::Write;
use std::process::Command;
use std::{fs::File, path::Path};
use tempfile::{Builder, TempDir};

use super::command::status_to_pretty_err;
use super::Config;

/// The nixos flake
pub struct NixosFlake {
    tmp_dir: TempDir,
}

impl NixosFlake {
    /// Path to the nixos flake
    pub fn path(&self) -> &Path {
        self.tmp_dir.path()
    }

    /// This initializes the flake i.e. downloads all inputs but in a less
    /// verbose way than other `nix flake` commands that will print all inputs
    /// changed.
    pub fn show(&self) -> Result<()> {
        let args = vec![
            "flake",
            "show",
            "--extra-experimental-features",
            "flakes nix-command",
            self.path()
                .to_str()
                .context("failed to convert temporary directory path to string")?,
        ];
        let status = Command::new("nix").args(&args).status();
        status_to_pretty_err(status, "nix", &args).context("cannot show flake")
    }
}

/// Creates a flake directory
pub fn generate_nixos_flake(config: &Config) -> Result<NixosFlake> {
    let mut config = config.clone();
    let tmp_dir = Builder::new()
        .prefix("kuutamo-flake.")
        .tempdir()
        .context("cannot create temporary directory")?;

    let knd_flake = &config.global.knd_flake;
    for (order, (name, ref mut host)) in config.hosts.iter_mut().enumerate() {
        let mut global_fields = format!(
            "deployment_flake = \"{}\"\nupgrade_order = {order}\n",
            &config.global.deployment_flake,
        );

        // Default root access enabled for MutityNet and CI, mainnet defaults to no root access.
        if var("FLAKE_CHECK").is_ok() {
            global_fields += "keep_root = true\n";
        } else if var("DEBUG").is_ok() {
            global_fields += "keep_root = true\n";
            if host.nixos_module == "kld-node" {
                host.nixos_module = "kld-test".to_string();
            }
        }

        let host_path = tmp_dir.path().join(format!("{name}.toml"));
        let mut host_file = File::create(&host_path)
            .with_context(|| format!("could not create {}", host_path.display()))?;
        let mut host_toml =
            toml::to_string(&host).with_context(|| format!("cannot serialize {name} to toml"))?;
        host_toml = global_fields + &host_toml;
        host_file
            .write_all(host_toml.as_bytes())
            .with_context(|| format!("Cannot write {}", host_path.display()))?;
    }
    let configurations = config
        .hosts
        .iter()
        .map(|(name, host)| {
            let mut nixos_modules = vec![];
            nixos_modules.push(host.nixos_module.clone());
            nixos_modules.extend_from_slice(host.extra_nixos_modules.as_slice());

            let modules = nixos_modules
                .iter()
                .map(|m| format!("      lightning-knd.nixosModules.\"{m}\""))
                .collect::<Vec<_>>()
                .join("\n");

            format!(
                r#"  nixosConfigurations."{name}" = lightning-knd.inputs.nixpkgs.lib.nixosSystem {{
    system = "x86_64-linux";
    modules = [
{modules}
      {{ kuutamo.deployConfig = builtins.fromTOML (builtins.readFile (builtins.path {{ name = "node.toml"; path = ./{name}.toml; }})); }}
    ];
  }};"#
            )
        })
        .collect::<Vec<_>>()
        .join("\n");
    let configuration_path = tmp_dir.path().join("configurations.nix");
    let mut configuration_file =
        File::create(configuration_path).context("could not create configurations.nix")?;
    let configuration_content = format!(
        r#"{{ lightning-knd, ... }}: {{
{configurations}
}}
"#
    );
    configuration_file
        .write_all(configuration_content.as_bytes())
        .context("could not write configurations.nix")?;
    let flake_content = format!(
        r#"{{
  inputs.lightning-knd.url = "{knd_flake}";

  nixConfig.extra-substituters = [
    "https://cache.garnix.io"
  ];

  nixConfig.extra-trusted-public-keys = [
    "cache.garnix.io:CTFPyKSLcx5RMJKfLo5EEPUObbA78b0YQ2DTCJXqr9g="
  ];

  outputs = inputs: import ./configurations.nix inputs;
}}
"#
    );
    let flake_path = tmp_dir.path().join("flake.nix");
    let mut flake_file = File::create(flake_path).context("could not create flake.nix")?;
    flake_file
        .write_all(flake_content.as_bytes())
        .context("could not write flake.nix")?;
    Ok(NixosFlake { tmp_dir })
}

#[test]
pub fn test_nixos_flake() -> Result<()> {
    use crate::config::{parse_config, TEST_CONFIG};
    use std::process::Command;

    let config = parse_config(TEST_CONFIG, Path::new("/"), false, false)?;
    let flake = generate_nixos_flake(&config)?;
    let flake_path = flake.path();
    let flake_nix = flake_path.join("flake.nix");
    let tmp_dir = TempDir::new()?;
    let args = vec![
        "--parse",
        flake_nix.to_str().unwrap(),
        "--store",
        tmp_dir.path().to_str().unwrap(),
    ];
    let status = Command::new("nix-instantiate").args(args).status()?;
    assert_eq!(status.code(), Some(0));
    assert!(flake_path.join("kld-00.toml").exists());
    assert!(flake_path.join("db-00.toml").exists());
    assert!(flake_path.join("db-01.toml").exists());
    Ok(())
}

'''
'''--- mgr/src/generate_config.rs ---
use anyhow::{Context, Result};
use std::{
    fs,
    path::{Path, PathBuf},
};

use super::NixosFlake;

// only copies files no directories
fn copy_dir_all<A: AsRef<Path>>(src: impl AsRef<Path>, dst: A) -> Result<()> {
    fs::create_dir_all(&dst).with_context(|| {
        format!(
            "Cannot creating target directory '{}'",
            dst.as_ref().display()
        )
    })?;
    for entry in fs::read_dir(&src)? {
        let entry = entry.with_context(|| {
            format!(
                "Cannot list directory content for '{}'",
                src.as_ref().display()
            )
        })?;
        fs::copy(entry.path(), dst.as_ref().join(entry.file_name()))?;
    }
    Ok(())
}

pub fn generate_config(directory: &PathBuf, flake: &NixosFlake) -> Result<()> {
    copy_dir_all(flake.path(), directory).context("failed to copy flake")
}

'''
'''--- mgr/src/install.rs ---
use anyhow::{Context, Result};
use lazy_static::lazy_static;
use log::info;
use std::env::var;
use std::path::Path;
use std::sync::Mutex;
use std::{
    process::Command,
    sync::mpsc::{channel, Receiver},
};

use crate::{
    command::status_to_pretty_err,
    utils::{timeout_ssh, try_unlock_over_ssh},
};

use super::{Host, NixosFlake};

lazy_static! {
    static ref CTRL_WAS_PRESSED: Mutex<Receiver<()>> = {
        let (ctrlc_tx, ctrlc_rx) = channel();
        ctrlc::set_handler(move || {
            info!("received ctrl-c!. Stopping program...");
            let _ = ctrlc_tx.send(());
        })
        .expect("Error setting ctrl-C handler");
        Mutex::new(ctrlc_rx)
    };
}

/// Install a Validator on a given machine
pub fn install(
    hosts: &[Host],
    kexec_url: &str,
    flake: &NixosFlake,
    secrets_dir: &Path,
    access_tokens: &String,
    debug: bool,
    no_reboot: bool,
) -> Result<()> {
    flake.show()?;
    hosts
        .iter()
        .map(|host| {
            info!("Install {}", host.name);
            let connection_string = if host.install_ssh_user.is_empty() {
                host.hostname.clone()
            } else {
                format!("{}@{}", host.install_ssh_user, host.hostname)
            };

            let disk_encryption_key = secrets_dir.join("disk_encryption_key");
            let disk_encryption_key_path = disk_encryption_key.to_string_lossy();
            let secrets = host
                .secrets(secrets_dir, access_tokens)
                .context("Failed to get secrets")?;
            let flake_uri = format!("{}#{}", flake.path().display(), host.name);
            let extra_files = format!("{}", secrets.path().display());
            let mut args = vec![
                "--extra-files",
                &extra_files,
                "--disk-encryption-keys",
                "/var/lib/disk_encryption_key",
                &disk_encryption_key_path,
                "--kexec",
                kexec_url,
                "--flake",
                &flake_uri,
                "--option",
                "accept-flake-config",
                "true",
            ];
            if cfg!(target_os = "macos") {
                args.push("--build-on-remote")
            }
            if debug {
                args.push("--debug");
            }
            if no_reboot {
                args.push("--no-reboot");
            }
            args.push(&connection_string);
            println!("$ nixos-anywhere {}", args.join(" "));
            let status = Command::new("nixos-anywhere").args(&args).status();
            status_to_pretty_err(status, "nixos-anywhere", &args)?;

            if no_reboot {
                return Ok(());
            }

            info!(
                "Installation of {} finished. Waiting for unlock.",
                host.name
            );

            loop {
                if try_unlock_over_ssh(host, &disk_encryption_key).is_ok() {
                    info!("Unlocked {}", host.name);
                    break;
                }
            }

            // remove potential old ssh keys before adding new ones...
            let _ = Command::new("ssh-keygen")
                .args(["-R", &host.hostname])
                .status()
                .context("Failed to run ssh-keygen to remove old keys...")?;

            // With root access, we check sshd start in port 22
            while var("FLAKE_CHECK").is_ok() || var("DEBUG").is_ok() {
                if timeout_ssh(host, &["exit", "0"], true)?.status.success() {
                    break;
                }
            }

            Ok(())
        })
        .collect::<Result<Vec<_>>>()?;
    Ok(())
}

'''
'''--- mgr/src/lib.rs ---
//! A module for deploying and updating nixos-based nodes.

pub use config::{calculate_hash, load_configuration, Config, Host};
pub use flake::{generate_nixos_flake, NixosFlake};
pub use generate_config::generate_config;
pub use install::install;
pub use nixos_rebuild::nixos_rebuild;
pub use reboot::reboot;
pub use ssh::ssh;

pub mod certs;
mod command;
pub mod config;
mod flake;
mod generate_config;
mod install;
pub mod logging;
mod nixos_rebuild;
mod reboot;
pub mod secrets;
pub mod ssh;

/// utils for deploy and control remote machines
pub mod utils;

'''
'''--- mgr/src/logging.rs ---
//! A logging module for commandline usage

use log::{LevelFilter, Log, Metadata, Record, SetLoggerError};

#[derive(Default)]
/// A logger instance
pub struct Logger {}

static LOGGER: Logger = Logger {};

/// Sets global logger.
///
/// # Errors
///
/// An error is returned if a logger has already been set.
///
pub fn init() -> Result<(), SetLoggerError> {
    log::set_logger(&LOGGER).map(|()| log::set_max_level(LevelFilter::Info))
}

impl Log for Logger {
    fn enabled(&self, _metadata: &Metadata) -> bool {
        true
    }

    fn log(&self, record: &Record) {
        let level = record.level();
        let level_name = level.to_string().to_lowercase();

        println!("[{}] {}", level_name, record.args());
    }

    fn flush(&self) {}
}

'''
'''--- mgr/src/main.rs ---
//! kld-mgr - a cli for deploying kld clusters

#![deny(missing_docs)]

use anyhow::{bail, Context, Result};
use clap::Parser;
use mgr::certs::{create_cockroachdb_certs, create_lightning_certs};
use mgr::secrets::{
    create_deploy_key, generate_disk_encryption_key, generate_mnemonic_and_macaroons,
};
use mgr::ssh::generate_key_pair;
use mgr::utils::try_unlock_over_ssh;
use mgr::{config::ConfigFile, generate_nixos_flake, logging, Config, Host, NixosFlake};
use std::collections::BTreeMap;
use std::io::{self, BufRead, Write};
use std::path::PathBuf;
use toml_example::traits::TomlExample;

#[derive(clap::Args, PartialEq, Debug, Clone)]
struct InstallArgs {
    /// Comma-separated lists of hosts to perform the install
    #[clap(long, default_value = "")]
    hosts: String,

    /// Kexec-tarball url to install from
    #[clap(
        long,
        default_value = "https://github.com/nix-community/nixos-images/releases/download/nixos-22.11/nixos-kexec-installer-x86_64-linux.tar.gz"
    )]
    kexec_url: String,

    /// Enables debug output in nixos-anywhere
    #[clap(long, action)]
    debug: bool,

    /// Do not reboot after installation
    #[clap(long, action)]
    no_reboot: bool,

    /// The mnemonic phrases and macaroons will automatically generate on remote server when kld first initialize.
    /// This benefits when you own your remote server and can physically backup mnemonic phrases and macaroons without any copy through the internet
    /// When you first initialize KLD, mnemonic phrases and macaroons will automatically be
    /// generated on your remote server. This is advantageous if you own your remote server,
    /// as you can physically back up your mnemonic phrases and macaroons without the need to
    /// transmit any copies over the internet.
    #[clap(long, default_value = "false")]
    generate_secret_on_remote: bool,
}

#[derive(clap::Args, PartialEq, Debug, Clone)]
struct GenerateConfigArgs {
    /// Directory where to copy the configuration to.
    directory: PathBuf,
}

#[derive(clap::Args, PartialEq, Debug, Clone)]
struct SshArgs {
    /// Host to ssh into
    #[clap(long, default_value = "")]
    hosts: String,

    /// Additional arguments to pass to ssh
    command: Option<Vec<String>>,
}

#[derive(clap::Args, PartialEq, Debug, Clone)]
struct RebootArgs {
    /// Comma-separated lists of hosts to perform the reboot
    #[clap(long, default_value = "")]
    hosts: String,
}

#[derive(clap::Args, PartialEq, Debug, Clone)]
struct SystemInfoArgs {
    /// Comma-separated lists of hosts to perform the install
    #[clap(long, default_value = "")]
    hosts: String,
}

#[derive(clap::Args, PartialEq, Debug, Clone)]
struct UnlockArgs {
    /// Comma-separated lists of hosts to perform the unlock
    #[clap(long, default_value = "")]
    hosts: String,

    /// disk encryption key for unlock nodes
    #[clap(long)]
    key_file: Option<PathBuf>,
}

/// Subcommand to run
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(clap::Subcommand, PartialEq, Debug, Clone)]
enum Command {
    /// Generate NixOS configuration
    GenerateConfig(GenerateConfigArgs),
    /// Generate kld.toml example
    GenerateExample,
    /// Install kld cluster on given hosts. This will remove all data of the current system!
    Install(InstallArgs),
    /// SSH into a host
    Ssh(SshArgs),
    /// Reboot hosts
    Reboot(RebootArgs),
    /// Get system info from a host
    SystemInfo(SystemInfoArgs),
    /// Unlock nodes when after reboot
    Unlock(UnlockArgs),
}

#[derive(Parser)]
#[clap(author, version, about, long_about = None)]
struct Args {
    /// configuration file to load
    #[clap(long, default_value = "kld.toml", env = "KLD_CONFIG")]
    config: PathBuf,

    /// skip interactive dialogs by assuming the answer is yes
    #[clap(long, default_value = "false")]
    yes: bool,

    #[clap(subcommand)]
    action: Command,
}

fn ask_yes_no(prompt_text: &str) -> bool {
    println!("{prompt_text} ");
    let stdin = io::stdin();
    let mut line = String::new();
    if stdin.lock().read_line(&mut line).is_err() {
        return false;
    }
    let normalized = line.trim_end_matches('\n').to_string().to_ascii_lowercase();

    matches!(normalized.as_str(), "y" | "yes")
}

fn filter_hosts(host_spec: &str, hosts: &BTreeMap<String, Host>) -> Result<Vec<Host>> {
    if host_spec.is_empty() {
        return Ok(hosts.values().map(Clone::clone).collect::<Vec<_>>());
    }
    let mut filtered = vec![];
    for name in host_spec.split(',') {
        match hosts.get(name) {
            Some(v) => {
                filtered.push(v.clone());
            }
            None => {
                bail!("no host named '{}' found in configuration", name)
            }
        }
    }
    Ok(filtered)
}

fn install(
    args: &Args,
    install_args: &InstallArgs,
    config: &Config,
    flake: &NixosFlake,
) -> Result<()> {
    let hosts = filter_hosts(&install_args.hosts, &config.hosts)?;
    if !args.yes && !ask_yes_no(
            "Installing will remove any existing data from the configured hosts. Do you want to continue? (y/n)"
        ) {
        return Ok(());
    }
    mgr::install(
        &hosts,
        &install_args.kexec_url,
        flake,
        &config.global.secret_directory,
        &config.global.access_tokens,
        install_args.debug,
        install_args.no_reboot,
    )
}

fn generate_config(
    _args: &Args,
    config_args: &GenerateConfigArgs,
    _config: &Config,
    flake: &NixosFlake,
) -> Result<()> {
    mgr::generate_config(&config_args.directory, flake)
}

fn ssh(_args: &Args, ssh_args: &SshArgs, config: &Config) -> Result<()> {
    let hosts = filter_hosts(&ssh_args.hosts, &config.hosts)?;
    let command = ssh_args
        .command
        .as_ref()
        .map_or_else(|| [].as_slice(), |v| v.as_slice());
    let command = command.iter().map(|s| s.as_str()).collect::<Vec<_>>();
    mgr::ssh(&hosts, command.as_slice())
}

fn reboot(_args: &Args, reboot_args: &RebootArgs, config: &Config) -> Result<()> {
    let hosts = filter_hosts(&reboot_args.hosts, &config.hosts)?;
    mgr::reboot(&hosts)
}

fn print_host_info(host: &Host) -> Result<()> {
    println!("[{}]", host.name);
    if let Ok(output) = std::process::Command::new("ssh")
        .args([
            host.deploy_ssh_target().as_str(),
            "--",
            "kld-ctl",
            "system-info",
        ])
        .output()
    {
        if output.status.success() {
            io::stdout().write_all(&output.stdout)?;
        } else {
            println!(
                "fetch system info of {} error: {}",
                host.name,
                std::str::from_utf8(&output.stderr).unwrap_or("fail to decode stderr")
            );
        }
    } else {
        println!("Fail to fetch system info from {}", host.name);
    }
    Ok(())
}

fn system_info(args: &SystemInfoArgs, config: &Config) -> Result<()> {
    println!("kld-mgr version: {}\n", env!("CARGO_PKG_VERSION"));
    let hosts = filter_hosts(&args.hosts, &config.hosts)?;
    for host in hosts {
        print_host_info(&host)?;
        println!("\n");
    }
    Ok(())
}

/// The kuutamo program entry point
pub fn main() -> Result<()> {
    logging::init().context("failed to initialize logging")?;
    let args = Args::parse();

    let res = match args.action {
        Command::GenerateExample => Ok(println!("{}", ConfigFile::toml_example())),
        Command::Install(ref install_args) => {
            let config = mgr::load_configuration(
                &args.config,
                !install_args.generate_secret_on_remote,
                true,
            )
            .with_context(|| {
                format!(
                    "failed to parse configuration file: {}",
                    &args.config.display()
                )
            })?;
            create_deploy_key(&config.global.secret_directory)?;
            create_lightning_certs(
                &config.global.secret_directory.join("lightning"),
                &config.hosts,
            )
            .context("failed to create or update lightning certificates")?;
            create_cockroachdb_certs(
                &config.global.secret_directory.join("cockroachdb"),
                &config.hosts,
            )
            .context("failed to create or update cockroachdb certificates")?;

            // ssh server key for initrd sshd
            let sshd_dir = config.global.secret_directory.join("sshd");
            std::fs::create_dir_all(&sshd_dir)?;
            for (name, _) in config.hosts.iter() {
                let p = sshd_dir.join(name);
                if !p.exists() {
                    generate_key_pair(&p)?;
                }
            }

            let disk_encryption_key = &config.global.secret_directory.join("disk_encryption_key");
            if !disk_encryption_key.exists() {
                generate_disk_encryption_key(disk_encryption_key)?;
            }

            if !install_args.generate_secret_on_remote {
                generate_mnemonic_and_macaroons(&config.global.secret_directory)?;
            }
            let flake = generate_nixos_flake(&config).context("failed to generate flake")?;
            install(&args, install_args, &config, &flake)
        }
        Command::Unlock(ref unlock_args) => {
            let config =
                mgr::load_configuration(&args.config, false, false).with_context(|| {
                    format!(
                        "failed to parse configuration file: {}",
                        &args.config.display()
                    )
                })?;

            let disk_encryption_key = unlock_args
                .key_file
                .clone()
                .unwrap_or_else(|| config.global.secret_directory.join("disk_encryption_key"));
            for host in filter_hosts(&unlock_args.hosts, &config.hosts)? {
                try_unlock_over_ssh(&host, &disk_encryption_key)?;
            }
            Ok(())
        }
        _ => {
            let config =
                mgr::load_configuration(&args.config, false, false).with_context(|| {
                    format!(
                        "failed to parse configuration file: {}",
                        &args.config.display()
                    )
                })?;
            let flake = generate_nixos_flake(&config).context("failed to generate flake")?;
            match args.action {
                Command::GenerateConfig(ref config_args) => {
                    generate_config(&args, config_args, &config, &flake)
                }
                Command::Ssh(ref ssh_args) => ssh(&args, ssh_args, &config),
                Command::Reboot(ref reboot_args) => reboot(&args, reboot_args, &config),
                Command::SystemInfo(ref args) => system_info(args, &config),
                _ => unreachable!(),
            }
        }
    };
    res.with_context(|| format!("kuutamo failed doing: {:?}", args.action))
}

'''
'''--- mgr/src/nixos_rebuild.rs ---
use std::path::Path;
use std::process::Command;

use crate::command;

use super::{Host, NixosFlake};
use anyhow::{Context, Result};
use log::warn;

/// Runs nixos-rebuild on the given host
pub fn nixos_rebuild(
    action: &str,
    host: &Host,
    flake: &NixosFlake,
    secrets_dir: &Path,
    access_tokens: &String,
    collect_garbage: bool,
) -> Result<()> {
    let secrets = host.secrets(secrets_dir, access_tokens)?;
    let target = host.deploy_ssh_target();
    secrets
        .upload(&target)
        .context("Failed to upload secrets")?;
    let flake_uri = host.flake_uri(flake);
    let mut args = vec![
        if action == "rollback" {
            "switch"
        } else {
            action
        },
        "--flake",
        &flake_uri,
        "--option",
        "accept-flake-config",
        "true",
        "--target-host",
        &target,
        "--build-host",
        (if cfg!(target_os = "macos") {
            &target
        } else {
            ""
        }),
        "--use-substitutes",
        "--fast",
    ];
    if action == "rollback" {
        args.push("--rollback");
    }
    for i in 1..3 {
        println!("$ nixos-rebuild {}", &args.join(" "));
        let status = Command::new("nixos-rebuild").args(&args).status();
        match command::status_to_pretty_err(status, "nixos-rebuild", &args) {
            Ok(_) => break,
            Err(e) => {
                if i == 1 {
                    warn!("{}", e);
                    warn!("Retry...");
                } else {
                    return Err(e);
                }
            }
        };
    }
    if collect_garbage {
        let ssh_args = [
            &target,
            "--",
            "nix-collect-garbage",
            "--delete-older-than",
            "14d",
        ];
        println!("$ ssh {}", ssh_args.join(" "));
        let status = Command::new("ssh").args(ssh_args).status();
        if let Err(e) = command::status_to_pretty_err(status, "ssh", &ssh_args) {
            warn!("garbage collection failed, but continue...: {}", e);
        }
    }
    Ok(())
}

'''
'''--- mgr/src/reboot.rs ---
use anyhow::Result;

use super::ssh;
use super::Host;
use log::info;

pub fn reboot(hosts: &[Host]) -> Result<()> {
    ssh(hosts, &["nohup reboot &>/dev/null & exit"])?;
    info!("Note unlock is required after node reboot");
    Ok(())
}

'''
'''--- mgr/src/secrets.rs ---
use std::fs::OpenOptions;
use std::io::Write;
use std::os::unix::fs::OpenOptionsExt;
use std::path::PathBuf;
use std::process::Command;
use std::{fs, path::Path};

use anyhow::{Context, Result};
use base64::{engine::general_purpose, Engine};
use bip39::Mnemonic;
use bitcoin::hashes::{sha256, Hash, HashEngine};
use macaroon::{Macaroon, MacaroonKey};
use rand::distributions::Alphanumeric;
use rand::{thread_rng, Rng};
use tempfile::{Builder, TempDir};

use crate::command::status_to_pretty_err;

pub struct Secrets {
    tmp_dir: TempDir,
}

impl Secrets {
    pub fn new<'a, I>(secrets: I) -> Result<Self>
    where
        I: Iterator<Item = &'a (PathBuf, Vec<u8>, u32)>,
    {
        let tmp_dir = Builder::new()
            .prefix("kuutamo-secrets.")
            .tempdir()
            .context("cannot create temporary directory")?;

        let mut options = OpenOptions::new();
        options.write(true);
        options.create(true);

        for (to, content, mode) in secrets {
            options.mode(*mode);
            let secret_path = tmp_dir.path().join(to.strip_prefix("/").unwrap_or(to));
            let dir = secret_path.parent().with_context(|| {
                format!("Cannot get parent of directory: {}", secret_path.display())
            })?;
            fs::create_dir_all(dir).with_context(|| format!("cannot create {}", dir.display()))?;
            let mut file = options.open(&secret_path).with_context(|| {
                format!("Cannot open secret {} for writing.", secret_path.display())
            })?;
            file.write_all(content).with_context(|| {
                format!(
                    "cannot write secret to temporary location at {}",
                    secret_path.display()
                )
            })?;
        }
        Ok(Self { tmp_dir })
    }
    /// Path to the nixos flake
    pub fn path(&self) -> &Path {
        self.tmp_dir.path()
    }

    // rsync -vrlF -e "ssh -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no" "$extra_files" "${ssh_connection}:/mnt/"
    pub fn upload(&self, ssh_target: &str) -> Result<()> {
        // Do proper logging here?
        println!("Uploading secrets");
        let path = self
            .path()
            .to_str()
            .context("Cannot convert secrets directory to string")?;
        let rsync_target = format!("{ssh_target}:/");
        let rsync_path = format!("{path}/");
        let args = vec!["-vrlF", "-e", "ssh", &rsync_path, &rsync_target];
        let status = Command::new("rsync").args(&args).status();
        status_to_pretty_err(status, "rsync", &args)?;
        Ok(())
    }
}

pub fn create_deploy_key(secret_directory: &Path) -> Result<()> {
    let ssh_dir = secret_directory.join("ssh");
    fs::create_dir_all(&ssh_dir)?;
    Command::new("ssh-keygen")
        .args([
            "-q",
            "-t",
            "ed25519",
            "-C",
            "deploy_key",
            "-N",
            "",
            "-f",
            &format!("{}/id_ed25519", ssh_dir.display()),
        ])
        .output()?;
    Ok(())
}

pub fn generate_mnemonic_and_macaroons(secret_directory: &Path) -> Result<()> {
    let mnemonic_path = secret_directory.join("mnemonic");
    let mnemonic = if !mnemonic_path.exists() {
        let mut rng = thread_rng();
        let mnemonic = Mnemonic::generate_in_with(&mut rng, bip39::Language::English, 24)?;
        fs::write(&mnemonic_path, mnemonic.to_string())
            .with_context(|| format!("Cannot write to {}", mnemonic_path.display()))?;

        println!("Generated a new mnemonic: {}", mnemonic_path.display());
        mnemonic
    } else if let Ok(words) = fs::read_to_string(mnemonic_path) {
        Mnemonic::parse(words)?
    } else {
        panic!("mnemonic is incorrect")
    };

    let mut engine = sha256::HashEngine::default();
    engine.input(&mnemonic.to_seed(""));
    engine.input("macaroon/0".as_bytes());
    let hash = sha256::Hash::from_engine(engine);
    let seed = hash.into_inner();

    let key = MacaroonKey::generate(&seed);
    let mut admin_macaroon = Macaroon::create(None, &key, "admin".into())?;
    admin_macaroon.add_first_party_caveat("roles = admin|readonly".into());

    let mut readonly_macaroon = Macaroon::create(None, &key, "readonly".into())?;
    readonly_macaroon.add_first_party_caveat("roles = readonly".into());

    let mut buf = vec![];
    let base64 = admin_macaroon.serialize(macaroon::Format::V2)?;
    general_purpose::URL_SAFE.decode_vec(base64, &mut buf)?;

    fs::write(secret_directory.join("access.macaroon"), &buf)?;
    fs::write(
        secret_directory.join("admin.macaroon"),
        admin_macaroon.serialize(macaroon::Format::V2)?,
    )?;
    fs::write(
        secret_directory.join("readonly.macaroon"),
        readonly_macaroon.serialize(macaroon::Format::V2)?,
    )?;

    Ok(())
}

pub fn generate_disk_encryption_key(key: &Path) -> Result<()> {
    let mut rng = thread_rng();
    let secret: Vec<u8> = (&mut rng).sample_iter(Alphanumeric).take(32).collect();
    let mut file = std::fs::File::create(key)?;
    file.write_all(&secret)?;
    println!("Generate disk encryption key: {}", key.display());
    Ok(())
}

'''
'''--- mgr/src/ssh.rs ---
use anyhow::Result;
use std::path::Path;

use super::command::status_to_pretty_err;
use super::Host;

pub fn ssh(hosts: &[Host], command: &[&str]) -> Result<()> {
    for host in hosts {
        let target = host.deploy_ssh_target();
        let mut args = vec![];
        args.push(target.as_str());
        args.push("--");
        args.extend(command);
        let status = std::process::Command::new("ssh").args(&args).status();
        status_to_pretty_err(status, "ssh", &args)?;
    }
    Ok(())
}

pub fn generate_key_pair(key_path: &Path) -> Result<()> {
    let p = key_path.display().to_string();
    let args = ["-N", "", "-f", &p, "-C", "kld-mgr"];
    let status = std::process::Command::new("ssh-keygen").args(args).status();
    status_to_pretty_err(status, "ssh-keygen", &args)?;
    Ok(())
}

'''
'''--- mgr/src/utils.rs ---
//! utils for deploy and control remote machines
use anyhow::{anyhow, Context, Result};
use std::fs::File;
use std::io::BufReader;
use std::io::{Read, Write};
use std::path::PathBuf;
use std::process::{Command, Output, Stdio};

use super::Host;

/// execute remote ssh
pub fn timeout_ssh(host: &Host, command: &[&str], learn_known_host_key: bool) -> Result<Output> {
    let target = host.deploy_ssh_target();
    let mut args = vec!["-o", "ConnectTimeout=10", "-o", "StrictHostKeyChecking=no"];
    if !learn_known_host_key {
        args.push("-o");
        args.push("UserKnownHostsFile=/dev/null");
    }
    args.push(&target);
    args.push("--");
    args.extend(command);
    println!("$ ssh {}", args.join(" "));
    let output = Command::new("ssh")
        .args(args)
        .output()
        .context("Failed to run ssh...")?;
    Ok(output)
}

/// try luks unlock via ssh
pub fn try_unlock_over_ssh(host: &Host, key_file: &PathBuf) -> Result<()> {
    // The node unlocked with start sshd on 22 port, we use this to check the node is unlock or not
    // If not then we will try to pass the disk encryption key to the node via 2222 port.
    if let Ok(result) = timeout_ssh(host, &["exit"], true) {
        if result.status.success() {
            // handle a node already unlocked
            println!("{} already unlocked", host.name);
            return Ok(());
        }
    }
    unlock_over_ssh(host, key_file)
}

/// luks unlock via ssh without pre check sshd status
pub fn unlock_over_ssh(host: &Host, key_file: &PathBuf) -> Result<()> {
    let target = host.deploy_ssh_target();
    let mut args = vec![
        "-p",
        "2222",
        "-o",
        "ConnectTimeout=10",
        "-o",
        "StrictHostKeyChecking=no",
    ];
    args.push(&target);
    args.push("cryptsetup-askpass");
    let key = {
        let key_file = File::open(key_file)?;
        let mut reader = BufReader::new(key_file);
        let mut buffer = Vec::new();
        reader.read_to_end(&mut buffer)?;
        buffer
    };
    let mut ssh = Command::new("ssh")
        .args(&args)
        .stdin(Stdio::piped())
        .stdout(Stdio::piped())
        .spawn()?;

    let mut stdin = ssh.stdin.take().ok_or(anyhow!("could not pipe stdin"))?;
    let mut stdout = ssh.stdout.take().ok_or(anyhow!("could not pipe stdout"))?;
    if stdin.write_all(key.as_slice()).is_ok() {
        let _ = stdin.write(b"\n")?;
    } else {
        return Err(anyhow!("failed to enter password"));
    }
    println!("$ ssh {}", args.join(" "));

    let mut buf_string = String::new();

    // Check the `cryptsetup-askpass` is asking the disk encryption key
    if stdout.read_to_string(&mut buf_string).is_ok() && buf_string.starts_with("Passphrase for") {
        Ok(())
    } else {
        Err(anyhow!("sshd response unexpected"))
    }
}

'''
'''--- nix/modules/tests/lightning.rs ---

'''
'''--- nix/modules/tests/test-config.toml ---
[global]
# we provide this path in our nixos test
knd_flake = "/root/lightning-knd"
deployment_flake = "path:/tmp/config"
access_tokens = "github.com=ghp_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"

[host_defaults]
public_ssh_keys = [
  "ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIMziQ+DhXsMxhx64DxUhR0G/DfSAz2pqAREDy/VUYEEF"
]
disks = [ "/dev/vdb", "/dev/vdc" ]
extra_nixos_modules = [ "qemu-test-profile" ]
ipv4_cidr = 24
ipv6_cidr = 32
ipv4_gateway = "192.168.42.255"
ipv6_gateway = "2001:DB8::"

[hosts.kld-00]
nixos_module = "kld-node"
# nixos tests have predictable mac addresses and our `installed` machine has the index 01 in vlan 01
mac_address  = "52:54:00:12:01:01"
ipv4_address = "192.168.42.2"
ipv6_address = "2001:DB8::1"
kld_node_alias = "kld-00-alias"
network_interface = "eth1"

[hosts.db-00]
nixos_module = "cockroachdb-node"
# nixos tests have predictable mac addresses and our `installed` machine has the index 01 in vlan 01
mac_address  = "52:54:00:12:01:01"
ipv4_address = "192.168.42.2"
# example address
ipv6_address = "2001:DB8::2"
network_interface = "eth1"

[hosts.db-01]
nixos_module = "cockroachdb-node"
# nixos tests have predictable mac addresses and our `installed` machine has the index 01 in vlan 01
mac_address  = "52:54:00:12:01:01"
ipv4_address = "192.168.42.2"
ipv6_address = "2001:DB8::3"
network_interface = "eth1"

'''
'''--- nix/modules/tests/test-flake/db-00.toml ---
name = "db-00"
nixos_module = "cockroachdb-node"
extra_nixos_modules = ["qemu-test-profile"]
deployment_flake = "path:/tmp/config"
upgrade_order = 0
mac_address = "52:54:00:12:01:01"
ipv4_address = "192.168.42.2"
ipv4_cidr = 24
ipv4_gateway = "192.168.42.255"
ipv6_address = "2001:db8::2"
ipv6_cidr = 32
ipv6_gateway = "2001:db8::"
install_ssh_user = "root"
hostname = "192.168.42.2"
public_ssh_keys = ["ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIMziQ+DhXsMxhx64DxUhR0G/DfSAz2pqAREDy/VUYEEF"]
disks = ["/dev/vdb", "/dev/vdc"]
bitcoind_disks = []
telegraf_has_monitoring = false
telegraf_config_hash = "13646096770106105413"
network_interface = "eth1"
keep_root = true

[[cockroach_peers]]
name = "db-00"
ipv4_address = "192.168.42.2"
ipv6_address = "2001:db8::2"

[[cockroach_peers]]
name = "db-01"
ipv4_address = "192.168.42.2"
ipv6_address = "2001:db8::3"

[[cockroach_peers]]
name = "kld-00"
ipv4_address = "192.168.42.2"
ipv6_address = "2001:db8::1"

'''
'''--- nix/modules/tests/test-flake/db-01.toml ---
name = "db-01"
nixos_module = "cockroachdb-node"
extra_nixos_modules = ["qemu-test-profile"]
deployment_flake = "path:/tmp/config"
upgrade_order = 1
mac_address = "52:54:00:12:01:01"
ipv4_address = "192.168.42.2"
ipv4_cidr = 24
ipv4_gateway = "192.168.42.255"
ipv6_address = "2001:db8::3"
ipv6_cidr = 32
ipv6_gateway = "2001:db8::"
install_ssh_user = "root"
hostname = "192.168.42.2"
public_ssh_keys = ["ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIMziQ+DhXsMxhx64DxUhR0G/DfSAz2pqAREDy/VUYEEF"]
disks = ["/dev/vdb", "/dev/vdc"]
bitcoind_disks = []
telegraf_has_monitoring = false
telegraf_config_hash = "13646096770106105413"
network_interface = "eth1"
keep_root = true

[[cockroach_peers]]
name = "db-00"
ipv4_address = "192.168.42.2"
ipv6_address = "2001:db8::2"

[[cockroach_peers]]
name = "db-01"
ipv4_address = "192.168.42.2"
ipv6_address = "2001:db8::3"

[[cockroach_peers]]
name = "kld-00"
ipv4_address = "192.168.42.2"
ipv6_address = "2001:db8::1"

'''
'''--- nix/modules/tests/test-flake/kld-00.toml ---
name = "kld-00"
nixos_module = "kld-node"
extra_nixos_modules = ["qemu-test-profile"]
deployment_flake = "path:/tmp/config"
upgrade_order = 2
mac_address = "52:54:00:12:01:01"
ipv4_address = "192.168.42.2"
ipv4_cidr = 24
ipv4_gateway = "192.168.42.255"
ipv6_address = "2001:db8::1"
ipv6_cidr = 32
ipv6_gateway = "2001:db8::"
install_ssh_user = "root"
hostname = "192.168.42.2"
public_ssh_keys = ["ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIMziQ+DhXsMxhx64DxUhR0G/DfSAz2pqAREDy/VUYEEF"]
disks = ["/dev/vdb", "/dev/vdc"]
bitcoind_disks = []
telegraf_has_monitoring = false
telegraf_config_hash = "13646096770106105413"
kld_node_alias = "kld-00-alias"
network_interface = "eth1"
keep_root = true

[[cockroach_peers]]
name = "db-00"
ipv4_address = "192.168.42.2"
ipv6_address = "2001:db8::2"

[[cockroach_peers]]
name = "db-01"
ipv4_address = "192.168.42.2"
ipv6_address = "2001:db8::3"

[[cockroach_peers]]
name = "kld-00"
ipv4_address = "192.168.42.2"
ipv6_address = "2001:db8::1"

'''
'''--- test-utils/Cargo.toml ---
[package]
name = "test-utils"
version = "0.1.0"
edition = "2021"

[dependencies]
kld = { path = "../kld" }
anyhow = { version = "1.0.81", features = [ "backtrace" ] }
lightning = { version = "0.0.121", features = [ "max_level_trace" ] }
bitcoin = "0.30.2"
rand = "0.8.5"
reqwest = { version = "0.11", default-features = false, features = [ "blocking", "native-tls" ] }
tokio-postgres = { version = "0.7.9", features = ["runtime", "with-bit-vec-0_6", "with-uuid-0_8"] }
postgres-openssl = "0.5.0"
openssl = "0.10.64"
tokio = { version = "1", features = [ "full" ] }
serde = "1.0"
serde_json = "1.0"
tempfile = "3"

[lib]
doctest = false

'''
'''--- test-utils/README.md ---
Certs generated with command:
'''
openssl req -x509 -newkey rsa:4096 -sha256 -days 3650 -nodes   -keyout test.key -out test.crt -subj "/CN=localhost" -addext "subjectAltName=IP:127.0.0.1
'''

'''
'''--- test-utils/src/bitcoin_manager.rs ---
use std::marker::PhantomData;
use std::time::Duration;

use anyhow::{bail, Context, Result};
use bitcoin::address::NetworkUnchecked;
use bitcoin::Address;
use kld::bitcoind::BitcoindClient;
use kld::settings::Network;
use kld::settings::Settings;
use std::process::{Child, Command, Stdio};
use tempfile::TempDir;
use tokio::time::{sleep_until, Instant};

use crate::ports::get_available_port;

pub struct BitcoinManager<'a> {
    process: Child,
    phantom: PhantomData<&'a TempDir>,
    pub p2p_port: u16,
    pub client: BitcoindClient,
    network: Network,
}

impl<'a> BitcoinManager<'a> {
    pub async fn new(
        output_dir: &'a TempDir,
        settings: &mut Settings,
    ) -> Result<BitcoinManager<'a>> {
        let p2p_port = get_available_port()?;
        let rpc_port = get_available_port()?;
        let storage_dir = output_dir
            .path()
            .join(format!("bitcoind_{}", settings.node_id));
        std::fs::create_dir(&storage_dir)?;

        settings.bitcoind_rpc_port = rpc_port;
        settings.bitcoin_cookie_path = if settings.bitcoin_network == Network::Bitcoin {
            storage_dir.join(".cookie")
        } else {
            storage_dir
                .join(settings.bitcoin_network.to_string())
                .join(".cookie")
        }
        .into_os_string()
        .into_string()
        .expect("should not use non UTF-8 char in path");

        let mut args = vec![
            "-server".into(),
            "-noconnect".into(),
            "-rpcthreads=1".into(),
            "-listen".into(),
            format!("-chain={}", settings.bitcoin_network),
            format!("-datadir={}", storage_dir.display()),
            format!("-port={}", p2p_port),
            format!("-rpcport={}", rpc_port),
        ];
        if std::env::var("KEEP_TEST_ARTIFACTS_IN").is_ok() {
            args.push(format!(
                "-debuglogfile={}",
                storage_dir.join("bitcoind.log").display()
            ));
        }

        let mut process = Command::new("bitcoind")
            .args(args)
            .stdout(Stdio::null())
            .stderr(Stdio::null())
            .spawn()
            .with_context(|| "failed to start bitcoind")?;

        // XXX
        // Request `call` and `new` of BitcoindClient should be separate functions
        // It is not `BitcoindConnection`, so it doesn't make sense to have a hidden request in new.
        // Also the manager is hard to init the client with `bitcoind` at same time.
        let mut count = 0;
        while let Err(e) = BitcoindClient::new(settings)
            .await
            .with_context(|| "could not connect to bitcoind")
        {
            if count > 3 {
                let _ = process.kill();
                return Err(e);
            } else {
                sleep_until(Instant::now() + Duration::from_secs(1 + count * 3)).await;
                count += 1;
            }
        }

        let bitcoind = match BitcoindClient::new(settings).await {
            Ok(client) => BitcoinManager {
                process,
                phantom: PhantomData,
                p2p_port,
                client,
                network: settings.bitcoin_network,
            },
            Err(_) => {
                let _ = process.kill();
                bail!("fail to make bitcoind client")
            }
        };

        Ok(bitcoind)
    }

    pub async fn generate_blocks(
        &self,
        n_blocks: u64,
        address: &Address<NetworkUnchecked>,
        delay: bool,
    ) -> Result<()> {
        for _ in 0..n_blocks {
            // Sometimes a delay is needed to make the test more realistic which is expected by LDK.
            if delay {
                tokio::time::sleep(Duration::from_secs(1)).await;
            }
            let checked_address = address.clone().require_network(self.network)?;
            self.client.generate_to_address(1, &checked_address).await?;
        }
        self.client.wait_for_blockchain_synchronisation().await;
        Ok(())
    }
}

impl Drop for BitcoinManager<'_> {
    fn drop(&mut self) {
        // Report unexpected bitcoind close, try kill the bitcoind process and wait the log
        match self.process.try_wait() {
            Ok(Some(status)) => eprintln!("bitcoind exited unexpected, status code: {status}"),
            Ok(None) => {
                let _ = Command::new("kill")
                    .arg(self.process.id().to_string())
                    .output();
                std::thread::sleep(Duration::from_secs(1));
                if let Ok(Some(_)) = self.process.try_wait() {
                } else {
                    self.process.kill().expect("bitcoind couldn't be killed");
                }
            }
            Err(_) => panic!("error attempting bitcoind status"),
        }
    }
}

'''
'''--- test-utils/src/cockroach_manager.rs ---
use std::{fs, os::unix::prelude::PermissionsExt};

use crate::ports::get_available_port;
use anyhow::{Context, Result};
use kld::settings::Settings;
use openssl::ssl::{SslConnector, SslConnectorBuilder, SslFiletype, SslMethod};
use postgres_openssl::MakeTlsConnector;
use std::marker::PhantomData;
use std::process::{Child, Command, Stdio};
use tempfile::TempDir;
use tokio::time::{sleep_until, Duration, Instant};
use tokio_postgres::Client;

pub struct CockroachManagerBuilder<'a> {
    output_dir: &'a TempDir,
    port: u16,
    sql_port: u16,
    http_address: String,
    certs_dir: String,
    database_host: String,
    database_port: u16,
    database_user: String,
    connector_builder: SslConnectorBuilder,
}

impl<'a> CockroachManagerBuilder<'a> {
    pub async fn build(self) -> Result<CockroachManager<'a>> {
        let process = self.start().await?;
        let cockroach = CockroachManager {
            process,
            phantom: PhantomData,
            sql_port: self.sql_port,
        };

        // Make sure db connection is ready before return manager
        let log_safe_params = format!(
            "host={} port={} user={} dbname=defaultdb",
            self.database_host, self.database_port, self.database_user,
        );
        let connector = MakeTlsConnector::new(self.connector_builder.build());

        let mut count = 0;
        while let Err(e) = tokio_postgres::connect(&log_safe_params, connector.clone())
            .await
            .with_context(|| format!("could not connect to database ({log_safe_params})"))
        {
            if count > 3 {
                return Err(e);
            } else {
                sleep_until(Instant::now() + Duration::from_secs(1 + count * 3)).await;
                count += 1;
            }
        }
        Ok(cockroach)
    }

    pub async fn start(&self) -> Result<Child> {
        // Cockroach requires certs to be only read/writable by user in secure mode. Git does not track this.
        for file in fs::read_dir(&self.certs_dir)? {
            let file = file?;
            let mut perms = fs::metadata(file.path())?.permissions();
            perms.set_mode(0o600);
            fs::set_permissions(file.path(), perms)?;
        }
        let mut args = vec![
            "start-single-node".into(),
            format!("--listen-addr=127.0.0.1:{}", self.port),
            format!("--sql-addr=127.0.0.1:{}", self.sql_port),
            format!("--http-addr={}", self.http_address),
            format!("--certs-dir={}", self.certs_dir),
            "--insecure".into(),
            "--store=type=mem,size=0.25".into(),
        ];

        let working_dir = self.output_dir.path().join("cockroachdb");
        fs::create_dir(&working_dir)?;

        if std::env::var("KEEP_TEST_ARTIFACTS_IN").is_ok() {
            args.push(format!(
                r#"--log={{file-defaults: {{dir: {}}}}}"#,
                working_dir.display()
            ));
        }

        Command::new("cockroach")
            .current_dir(&working_dir)
            .args(args)
            .stdout(Stdio::null())
            .stderr(Stdio::null())
            .spawn()
            .with_context(|| "failed to start cockroach".to_string())
    }
}

pub struct CockroachManager<'a> {
    process: Child,
    phantom: PhantomData<&'a TempDir>,
    pub sql_port: u16,
}

impl<'a> CockroachManager<'a> {
    pub async fn builder(
        output_dir: &'a TempDir,
        settings: &mut Settings,
    ) -> Result<CockroachManagerBuilder<'a>> {
        let port = get_available_port()?;
        let http_port = get_available_port()?;
        let sql_port = get_available_port()?;
        let http_address = format!("127.0.0.1:{http_port}");
        let certs_dir = format!("{}/certs/cockroach", env!("CARGO_MANIFEST_DIR"));
        let mut connector_builder = SslConnector::builder(SslMethod::tls())?;
        connector_builder.set_ca_file(&settings.database_ca_cert_path)?;
        connector_builder
            .set_certificate_file(&settings.database_client_cert_path, SslFiletype::PEM)?;
        connector_builder
            .set_private_key_file(&settings.database_client_key_path, SslFiletype::PEM)?;
        settings.database_port = sql_port;
        Ok(CockroachManagerBuilder {
            output_dir,
            port,
            sql_port,
            http_address,
            certs_dir,
            database_host: settings.database_host.clone(),
            database_port: settings.database_port,
            database_user: settings.database_user.clone(),
            connector_builder,
        })
    }
}

impl Drop for CockroachManager<'_> {
    fn drop(&mut self) {
        // Report unexpected DB close, else just kill the db process without waiting because everything in under
        // memory/temp folder and is manageable
        match self.process.try_wait() {
            Ok(Some(status)) => eprintln!("cockroachdb exited unexpected, status code: {status}"),
            Ok(None) => self.process.kill().expect("cockroachdb couldn't be killed"),
            Err(_) => panic!("error attempting cockroachdb status"),
        }
    }
}

pub async fn connection(settings: &Settings) -> Result<Client> {
    let log_safe_params = format!(
        "host={} port={} user={} dbname=defaultdb",
        settings.database_host, settings.database_port, settings.database_user,
    );
    let mut builder = SslConnector::builder(SslMethod::tls())?;
    builder.set_ca_file(&settings.database_ca_cert_path)?;
    builder.set_certificate_file(&settings.database_client_cert_path, SslFiletype::PEM)?;
    builder.set_private_key_file(&settings.database_client_key_path, SslFiletype::PEM)?;
    let connector = MakeTlsConnector::new(builder.build());
    let (client, connection) = tokio_postgres::connect(&log_safe_params, connector)
        .await
        .with_context(|| format!("could not connect to database ({log_safe_params})"))?;
    tokio::spawn(async move {
        let _ = connection.await;
    });
    Ok(client)
}

pub async fn create_database(settings: &Settings) {
    let client = connection(settings).await.unwrap();
    client
        .execute(
            &format!("CREATE DATABASE IF NOT EXISTS {}", settings.database_name),
            &[],
        )
        .await
        .unwrap();
}

'''
'''--- test-utils/src/electrs_manager.rs ---
use std::fs::File;
use std::marker::PhantomData;
use std::process::{Child, Command, Stdio};
use std::time::Duration;

use anyhow::{Context, Result};
use kld::settings::Settings;
use tempfile::TempDir;
use tokio::time::{sleep_until, Instant};

use crate::{ports::get_available_port, BitcoinManager};

pub struct ElectrsManager<'a, 'b> {
    process: Child,
    phantom: PhantomData<&'a TempDir>,
    bitcoind: PhantomData<&'b BitcoinManager<'b>>,
    pub monitoring_addr: String,
}

impl<'a, 'b> ElectrsManager<'a, 'b> {
    pub async fn new(
        output_dir: &'a TempDir,
        bitcoin_manager: &'b BitcoinManager<'b>,
        settings: &mut Settings,
    ) -> Result<ElectrsManager<'a, 'b>> {
        let monitoring_port = get_available_port()?;
        let rpc_port = get_available_port()?;
        let storage_dir = output_dir
            .path()
            .join(format!("electrs_{}", settings.node_id));
        std::fs::create_dir(&storage_dir)?;

        let mut args = vec![
            "--skip-default-conf-files".into(),
            format!("--network={}", &settings.bitcoin_network),
            format!("--db-dir={}", &storage_dir.as_path().display()),
            format!("--cookie-file={}", settings.bitcoin_cookie_path),
            format!("--electrum-rpc-addr=127.0.0.1:{rpc_port}"),
            format!("--daemon-rpc-addr=127.0.0.1:{}", settings.bitcoind_rpc_port),
            format!("--daemon-p2p-addr=127.0.0.1:{}", bitcoin_manager.p2p_port),
            format!("--monitoring-addr=127.0.0.1:{monitoring_port}"),
        ];
        if std::env::var("KEEP_TEST_ARTIFACTS_IN").is_ok() {
            args.push("--log-filters=DEBUG".into());
        }
        let process = if std::env::var("KEEP_TEST_ARTIFACTS_IN").is_ok() {
            Command::new("electrs")
                .args(args)
                .stdout(Stdio::null())
                .stderr(File::create(storage_dir.join("electrs.log"))?)
                .spawn()
                .with_context(|| "failed to start electrs")?
        } else {
            Command::new("electrs")
                .args(args)
                .stdout(Stdio::null())
                .stderr(Stdio::null())
                .spawn()
                .with_context(|| "failed to start electrs")?
        };

        let electrs = ElectrsManager {
            process,
            monitoring_addr: format!("127.0.0.1:{monitoring_port}"),
            phantom: PhantomData,
            bitcoind: PhantomData,
        };
        settings.electrs_url = format!("127.0.0.1:{rpc_port}");

        let mut count = 0;
        while let Err(e) = reqwest::get(&format!("http://{}", electrs.monitoring_addr))
            .await
            .with_context(|| "could not monitor on electrs")
        {
            if count > 3 {
                return Err(e);
            } else {
                sleep_until(Instant::now() + Duration::from_secs(1)).await;
                count += 1;
            }
        }
        Ok(electrs)
    }
}

impl Drop for ElectrsManager<'_, '_> {
    fn drop(&mut self) {
        // Report unexpected close, try kill the electrs process and wait the log
        match self.process.try_wait() {
            Ok(Some(status)) => eprintln!("electrs exited unexpected, status code: {status}"),
            Ok(None) => {
                let _ = Command::new("kill")
                    .arg(self.process.id().to_string())
                    .output();
                let mut count = 0;
                while count < 5 {
                    if let Ok(Some(_)) = self.process.try_wait() {
                        return;
                    }
                    std::thread::sleep(Duration::from_secs(1 + count * 3));
                    count += 1;
                }
                self.process.kill().expect("electrs couldn't be killed");
            }
            Err(_) => panic!("error attempting electrs status"),
        }
    }
}

'''
'''--- test-utils/src/kld_manager.rs ---
use crate::cockroach_manager::{create_database, CockroachManager};
use crate::electrs_manager::ElectrsManager;
use crate::https_client;
use crate::ports::get_available_port;
use anyhow::{anyhow, bail, Context, Result};
use kld::settings::Settings;
use reqwest::Method;
use serde::de::DeserializeOwned;
use serde::Serialize;
use std::env::set_var;
use std::fs;
use std::marker::PhantomData;
use std::process::{Child, Command, Stdio};
use tempfile::TempDir;
use tokio::time::{sleep_until, Duration, Instant};

pub struct KldManager<'a> {
    process: Child,
    exporter_port: u16,
    rest_port: u16,
    rest_client: reqwest::Client,
    _electrs: PhantomData<&'a ElectrsManager<'a, 'a>>,
}

impl<'a> KldManager<'a> {
    pub async fn new(
        output_dir: &'a TempDir,
        kld_bin: &str,
        cockroach: &CockroachManager<'a>,
        _electrs: &ElectrsManager<'a, 'a>,
        settings: &mut Settings,
    ) -> Result<KldManager<'a>> {
        let exporter_port = get_available_port()?;
        let rest_port = get_available_port()?;
        settings.rest_api_address = format!("127.0.0.1:{rest_port}");
        settings.exporter_address = format!("127.0.0.1:{exporter_port}");
        settings.peer_port = get_available_port()?;
        let storage_dir = output_dir.path().join(format!("kld_{}", settings.node_id));
        std::fs::create_dir(&storage_dir)?;

        let certs_dir = format!("{}/certs", env!("CARGO_MANIFEST_DIR"));

        create_database(settings).await;

        set_var("KLD_DATA_DIR", &storage_dir);
        set_var("KLD_CERTS_DIR", &certs_dir);
        set_var(
            "KLD_MNEMONIC_PATH",
            storage_dir
                .join("mnemonic")
                .into_os_string()
                .into_string()
                .expect("should not use non UTF-8 code in the path"),
        );
        set_var(
            "KLD_WALLET_NAME",
            format!("kld-wallet-{}", &settings.node_id),
        );
        set_var("KLD_PEER_PORT", settings.peer_port.to_string());
        set_var("KLD_EXPORTER_ADDRESS", &settings.exporter_address);
        set_var("KLD_REST_API_ADDRESS", &settings.rest_api_address);
        set_var("KLD_BITCOIN_NETWORK", settings.bitcoin_network.to_string());
        set_var("KLD_BITCOIN_COOKIE_PATH", &settings.bitcoin_cookie_path);
        set_var("KLD_BITCOIN_RPC_HOST", "127.0.0.1");
        set_var(
            "KLD_BITCOIN_RPC_PORT",
            settings.bitcoind_rpc_port.to_string(),
        );
        set_var("KLD_DATABASE_PORT", cockroach.sql_port.to_string());
        set_var("KLD_DATABASE_NAME", settings.database_name.clone());
        set_var("KLD_NODE_ID", settings.node_id.clone());
        set_var(
            "KLD_DATABASE_CA_CERT_PATH",
            format!("{certs_dir}/cockroach/ca.crt"),
        );
        set_var(
            "KLD_DATABASE_CLIENT_KEY_PATH",
            format!("{certs_dir}/cockroach/client.root.key"),
        );
        set_var(
            "KLD_DATABASE_CLIENT_CERT_PATH",
            format!("{certs_dir}/cockroach/client.root.crt"),
        );
        set_var("KLD_LOG_LEVEL", "debug");
        set_var("KLD_NODE_ALIAS", "kld-00-alias");
        set_var("KLD_ELECTRS_URL", settings.electrs_url.clone());

        let mut process = if std::env::var("KEEP_TEST_ARTIFACTS_IN").is_ok() {
            Command::new(kld_bin)
                .stdout(fs::File::create(storage_dir.join("kld.log"))?)
                .stderr(Stdio::null())
                .spawn()
                .with_context(|| "failed to start kld")?
        } else {
            Command::new(kld_bin)
                .stdout(Stdio::null())
                .stderr(Stdio::null())
                .spawn()
                .with_context(|| "failed to start kld")?
        };

        let macaroon_path = storage_dir.join("macaroons").join("admin.macaroon");

        // Check macaroon for rest api and exporter api directly
        let mut count = 0;
        while !macaroon_path.exists()
            || reqwest::get(format!("http://127.0.0.1:{}/health", exporter_port))
                .await
                .is_err()
        {
            if count > 3 {
                let _ = process.kill();
                bail!("kld fail to initialize");
            } else {
                sleep_until(Instant::now() + Duration::from_secs(1 + count * 3)).await;
                count += 1;
            }
        }

        Ok(KldManager {
            process,
            rest_client: https_client(Some(fs::read(macaroon_path)?))?,
            _electrs: PhantomData,
            exporter_port,
            rest_port,
        })
    }

    pub fn pid(&self) -> u32 {
        self.process.id()
    }

    pub async fn call_exporter(&self, method: &str) -> Result<String, reqwest::Error> {
        reqwest::get(format!(
            "http://127.0.0.1:{}/{}",
            self.exporter_port, method
        ))
        .await?
        .text()
        .await
    }

    pub async fn call_rest_api<T: DeserializeOwned, B: Serialize>(
        &self,
        method: Method,
        route: &str,
        body: B,
    ) -> Result<T> {
        let res = self
            .rest_client
            .request(
                method,
                format!("https://127.0.0.1:{}{}", self.rest_port, route),
            )
            .body(serde_json::to_string(&body).unwrap())
            .send()
            .await?;
        let status = res.status();
        let text = res.text().await?;
        match serde_json::from_str::<T>(&text) {
            Ok(t) => {
                println!("API result: {text}");
                Ok(t)
            }
            Err(e) => {
                println!("Error from API: {status} {text}");
                Err(anyhow!(e))
            }
        }
    }
}

impl Drop for KldManager<'_> {
    fn drop(&mut self) {
        // Report unexpected kld close, try kill the kld process and wait the log
        match self.process.try_wait() {
            Ok(Some(status)) => eprintln!("kld exited unexpected, status code: {status}"),
            Ok(None) => self.process.kill().expect("kld couldn't be killed"),
            Err(_) => panic!("error attempting bitcoind status"),
        }
    }
}

'''
'''--- test-utils/src/lib.rs ---
use std::ops::Deref;
pub mod bitcoin_manager;
pub mod cockroach_manager;
pub mod electrs_manager;
pub mod kld_manager;
pub mod ports;

use anyhow::Result;
use kld::database::DurableConnection;
use kld::settings::Settings;
use std::{fs::File, io::Read, path::Path};

use bitcoin::secp256k1::{PublicKey, SecretKey};
pub use bitcoin_manager::BitcoinManager;
pub use cockroach_manager::CockroachManager;
pub use electrs_manager::ElectrsManager;
pub use kld_manager::KldManager;
use reqwest::header::{HeaderValue, CONTENT_TYPE};
use reqwest::{Certificate, Client};

// https://mempool.space/tx/b9deb5e0aaf6d80fe156e64b3a339b7d5f853bcf9993a8183e1eec4b6f26cf86
pub const TEST_TX_ID: &str = "b9deb5e0aaf6d80fe156e64b3a339b7d5f853bcf9993a8183e1eec4b6f26cf86";

pub const TEST_TX: &str = "02000000000101f127bd21d5188f21f623bca61cdefc443d2f8b1ffc208945321a1af0096b4bb11400000000fdffffff01220200000000000022512019bd1296ec4e4f75f75f4cd409e19811a59e0e9877c6135dc310210916dc0072034021e1157d9aa76cbc86602656c5d504957c40694182bb18bff749f6007950aab07c0915f750ea5782a69b206379387bfae97f9ec8954b1c5613e95082c376dba18320117f692257b2331233b5705ce9c682be8719ff1b2b64cbca290bd6faeb54423eac0663c05b218801750063036f7264010118746578742f706c61696e3b636861727365743d7574662d3800357b2270223a226272632d3230222c226f70223a226d696e74222c227469636b223a22574f4c56222c22616d74223a2231303030227d6821c1117f692257b2331233b5705ce9c682be8719ff1b2b64cbca290bd6faeb54423e00000000";

pub const TEST_ADDRESS: &str = "2N4eQYCbKUHCCTUjBJeHcJp9ok6J2GZsTDt";

pub const TEST_SHORT_CHANNEL_ID: u64 = 0x0102030405060708;

pub const TEST_ALIAS: &str = "test node";

pub const TEST_WPKH: &str = "wpkh(cVpPVruEDdmutPzisEsYvtST1usBR3ntr8pXSyt6D2YYqXRyPcFW)";

// https://mempool.space/block/0000000000000000000590fc0f3eba193a278534220b2b37e9849e1a770ca959
pub const TEST_BLOCK_HASH: &str =
    "0000000000000000000590fc0f3eba193a278534220b2b37e9849e1a770ca959";

pub const TEST_PRIVATE_KEY: [u8; 32] = [
    0xe1, 0x26, 0xf6, 0x8f, 0x7e, 0xaf, 0xcc, 0x8b, 0x74, 0xf5, 0x4d, 0x26, 0x9f, 0xe2, 0x06, 0xbe,
    0x71, 0x50, 0x00, 0xf9, 0x4d, 0xac, 0x06, 0x7d, 0x1c, 0x04, 0xa8, 0xca, 0x3b, 0x2d, 0xb7, 0x34,
];

// Public key of the above private key.
pub const TEST_PUBLIC_KEY: &str =
    "03e7156ae33b0a208d0744199163177e909e80176e55d97a2f221ede0f934dd9ad";

pub fn test_settings(tmp_dir: &tempfile::TempDir, name: &str) -> kld::settings::Settings {
    let mut settings = kld::settings::Settings::default();
    settings.certs_dir = format!("{}/certs", env!("CARGO_MANIFEST_DIR"));
    settings.database_ca_cert_path =
        format!("{}/certs/cockroach/ca.crt", env!("CARGO_MANIFEST_DIR"));
    settings.database_client_cert_path = format!(
        "{}/certs/cockroach/client.root.crt",
        env!("CARGO_MANIFEST_DIR")
    );
    settings.database_client_key_path = format!(
        "{}/certs/cockroach/client.root.key",
        env!("CARGO_MANIFEST_DIR")
    );
    settings.database_name = name.to_string();
    settings.node_id = name.to_string();
    settings.data_dir = format!("{}/test_{name}", tmp_dir.path().display());
    settings.mnemonic_path = format!("{}/mnemonic", settings.data_dir);
    std::fs::create_dir_all(&settings.data_dir).unwrap();
    settings
}

pub fn random_public_key() -> PublicKey {
    let rand: [u8; 32] = rand::random();
    let secp_ctx = bitcoin::secp256k1::Secp256k1::new();
    let secret_key = &SecretKey::from_slice(&rand).unwrap();
    PublicKey::from_secret_key(&secp_ctx, secret_key)
}

pub fn https_client(macaroon: Option<Vec<u8>>) -> Result<Client> {
    let mut headers = reqwest::header::HeaderMap::new();
    headers.insert(CONTENT_TYPE, HeaderValue::from_static("application/json"));
    if let Some(macaroon) = macaroon {
        headers.insert("macaroon", HeaderValue::from_bytes(&macaroon)?);
    }

    // Rustls does not support IP addresses (hostnames only) so we need to use native tls (openssl). Also turn off SNI as this requires host names as well.
    Ok(reqwest::ClientBuilder::new()
        .tls_sni(false)
        .add_root_certificate(test_cert())
        .use_native_tls()
        .default_headers(headers)
        .build()?)
}

fn test_cert() -> Certificate {
    let mut buf = Vec::new();
    File::open(format!("{}/certs/kld.crt", env!("CARGO_MANIFEST_DIR")))
        .unwrap()
        .read_to_end(&mut buf)
        .unwrap();
    Certificate::from_pem(&buf).unwrap()
}

#[macro_export]
macro_rules! poll {
    ($count: expr, $func: expr) => {
        let mut ct = 0;
        while ct < $count {
            if $func {
                break;
            };
            tokio::time::sleep(std::time::Duration::from_secs(1 + 3 * ct)).await;
            ct += 1;
        }
        if ct == $count {
            anyhow::bail!("Fail {ct:} times on polling for result");
        }
    };
}

pub mod fake_fs {
    use std::{io, path::Path};

    pub fn read<P: AsRef<Path>>(_path: P) -> io::Result<Vec<u8>> {
        Err(io::Error::from(io::ErrorKind::NotFound))
    }
    pub fn read_to_string<P: AsRef<Path>>(_path: P) -> io::Result<String> {
        Err(io::Error::from(io::ErrorKind::NotFound))
    }
    pub fn write<P: AsRef<Path>, C: AsRef<[u8]>>(_path: P, _contents: C) -> io::Result<()> {
        Ok(())
    }
    pub fn create_dir_all<P: AsRef<Path>>(_path: P) -> io::Result<()> {
        Ok(())
    }
}

/// A wrapper of tempfile::TempDir to keep temp files if env `KEEP_TEST_ARTIFACTS_IN` is set
pub struct TempDir {
    inner: Option<tempfile::TempDir>,
}

impl TempDir {
    pub fn new() -> std::io::Result<Self> {
        if let Ok(path) = std::env::var("KEEP_TEST_ARTIFACTS_IN") {
            let dir = Path::new(&path);
            if !dir.is_dir() {
                std::fs::create_dir(dir)?;
            }
            Ok(Self {
                inner: Some(tempfile::TempDir::new_in(dir)?),
            })
        } else {
            Ok(Self {
                inner: Some(tempfile::TempDir::new()?),
            })
        }
    }
}

impl Deref for TempDir {
    type Target = tempfile::TempDir;

    fn deref(&self) -> &Self::Target {
        self.inner
            .as_ref()
            .expect("TmpDir should be create with `new()`")
    }
}

impl Drop for TempDir {
    fn drop(&mut self) {
        if std::env::var("KEEP_TEST_ARTIFACTS_IN").is_ok() {
            if let Some(inner) = self.inner.take() {
                let path = inner.into_path();
                println!("test artifacts keep in {:?}", path);
            }
        }
    }
}

pub async fn init_db_test_context(
    temp_dir: &tempfile::TempDir,
) -> Result<(Settings, CockroachManager, DurableConnection)> {
    let mut settings = test_settings(temp_dir, "integration");
    let cockroach = CockroachManager::builder(temp_dir, &mut settings)
        .await?
        .build()
        .await?;
    cockroach_manager::create_database(&settings).await;
    let durable_connection = DurableConnection::new_migrate(settings.clone().into()).await;
    Ok((settings, cockroach, durable_connection))
}

'''
'''--- test-utils/src/ports.rs ---
use anyhow::{bail, Result};
use std::{
    net::{TcpListener, UdpSocket},
    sync::atomic::{AtomicUsize, Ordering},
};

static NEXT_PORT: AtomicUsize = AtomicUsize::new(10000);

/// get the next free port that has no udp/tcp bound
/// WARNING: If other applications try to acquire these ports independent from
/// our test suite, this method is unreliable and racy.
pub fn get_available_port() -> Result<u16> {
    loop {
        let port = NEXT_PORT.fetch_add(1, Ordering::SeqCst);
        if port > 65535 {
            bail!("run out ports")
        }
        let port = port as u16;
        if TcpListener::bind(("127.0.0.1", port)).is_ok()
            && UdpSocket::bind(("127.0.0.1", port)).is_ok()
        {
            return Ok(port);
        }
    }
}

'''
'''--- tui/Cargo.toml ---
[package]
name = "kld-tui"
version = "0.1.0"
edition = "2021"
description = "A Tui app interacts with kuutamo products"

[dependencies]
chrono = "0.4.37"
clap = { version = "4.5.3", features = [ "derive", "env" ] }
color-eyre = "0.6.3"
config = "0.14.0"
crossterm = { version = "0.27.0", features = ["serde", "event-stream"] }
derive_deref = "1.1.1"
directories = "5.0.1"
futures = "0.3.30"
human-panic = "1.2.3"
kld = { path = "../kld" }
lazy_static = "1.4.0"
libc = "0.2.153"
log = "0.4.21"
pretty_assertions = "1.4.0"
r2d2 = "0.8.10"
r2d2_sqlite = "0.24.0"
ratatui = { git = "https://github.com/yanganto/ratatui", branch = "table-footer", version = "0.25.0", features = ["serde", "macros"] }
reqwest = { version = "0.11.22", features = ["blocking"] }
serde = { version = "1.0.197", features = ["derive"] }
serde_json = "1.0.109"
signal-hook = "0.3.17"
strip-ansi-escapes = "0.2.0"
tokio = { version = "1.35.0", features = ["macros"] }
tokio-util = "0.7.9"
toml = "0.8.12"
tracing = "0.1.40"
tracing-error = "0.2.0"
tracing-subscriber = { version = "0.3.18", features = ["env-filter", "serde"] }
url = "2.5.0"

'''
'''--- tui/README.md ---
ðŸŒ”kuutamo lightning-knd TUI
---

A Terminal User Interface for [lightning-knd](https://github.com/kuutamolabs/lightning-knd).

Now you can try with previous version of app with `--sync` flag for all commands.

Current asynchronous app is **still under development** and already supports
default [keybinding](https://github.com/kuutamolabs/lightning-tui/blob/non-blocking/assets/keybinding.toml) is here
You can copy `assets/vim_keybinding.toml` or create anyone `keybinding.toml` in your working directory to overwrite any key bindings.

- [x] non-blocking architecture
- [x] log features
- [x] multiple mode key bindings
- [x] allow user customized key bindings
- [x] i18n support based on `LANG` setting
- [x] command list
- [x] add action inspector in debug component
- [x] helper page
- [x] command history
- [x] prompt if the command is not ready

We will do following items later.

- [ ] reimplement each command in non-blocking way
  - [x] Node information
	- [ ] NodeFees,
	- [ ] NodeEslq,
	- [ ] NodeSign,
	- [ ] NodeLsfd,
	- [ ] NetwLsnd,
	- [ ] NetwFeer,
	- [ ] PeerList,
  - [x] Connect Peer
	- [ ] PeerDisc,
	- [ ] PaymList,
	- [ ] PaymSdky,
	- [ ] PaymPayi,
	- [ ] InvoList,
	- [ ] InvoGene,
	- [ ] InvoDeco,
	- [ ] ChanList,
	- [x] Open Channel
	- [ ] ChanSetf,
	- [ ] ChanClos,
	- [ ] ChanHist,
	- [ ] ChanBala,
	- [ ] ChanLsfd,

'''
'''--- tui/assets/keybinding.toml ---
[Navigate]
"<esc>"     = "Quit"
"<tab>"     = "SwitchTab"
"<up>"      = "NavUp"
"<down>"    = "NavDown"
"<left>"    = "NavLeft"
"<right>"   = "NavRight"
"<enter>"   = "EnterCmdMode"

[Command]
"<esc>"   = "ExitCmdMode"
"<tab>"   = "SwitchInputs"
"<enter>" = "TriggerExecute"

'''
'''--- tui/assets/vim_keybinding.toml ---
[Navigate]
"q" = "Quit"
"k" = "NavUp"
"j" = "NavDown"
"h" = "NavLeft"
"l" = "NavRight"

'''
'''--- tui/assets/wordbinding.toml ---
[zh_TW]
"Command List" = "å‘½ä»¤åˆ—è¡¨"
"History" = "æ­·å²è¨˜éŒ„"
"Node" = "ç¯€é»ž"
"information" = "è³‡è¨Š"
"NodeInfo" = "ç¯€é»žè³‡è¨Š"
"fees" = "è²»ç”¨"
"NodeFees" = "ç¯€é»žè²»ç”¨"
"estimate liquidity" = "ä¼°è¨ˆæµå‹•æ€§"
"NodeEslq" = "ä¼°è¨ˆæµå‹•æ€§"
"sign" = "ç°½å"
"NodeSign" = "ç°½å"
"list funds" = "åˆ—å‡ºè³‡é‡‘"
"NodeLsfd" = "åˆ—å‡ºè³‡é‡‘"
"Network" = "ç¶²è·¯"
"list nodes" = "åˆ—å‡ºç¯€é»ž"
"NetwLsnd" = "åˆ—å‡ºç¯€é»ž"
"fee rates" = "è²»çŽ‡"
"NetwFeer" = "æŸ¥è©¢è²»çŽ‡"
"Peers" = "åŒå„•ç¯€é»ž"
"Public Key" = "å…¬é–‹é‘°åŒ™"
"list" = "åˆ—å‡º"
"PeerList" = "åˆ—å‡ºåŒå„•ç¯€é»ž"
"connect" = "é€£æŽ¥"
"PeerCont" = "é€£æŽ¥åŒå„•ç¯€é»ž"
"disconnect" = "ä¸­æ–·"
"PeerDisc" = "ä¸­æ–·é€£æŽ¥"
"Payments" = "ä»˜æ¬¾è³‡è¨Š"
"PaymList" = "åˆ—å‡ºä»˜æ¬¾è³‡è¨Š"
"send key" = "ç™¼é€å…¬é‘°"
"PaymSdky" = "ç™¼é€å…¬é‘°"
"pay invoice" = "æ”¯ä»˜ç™¼ç¥¨"
"PaymPayi" = "æ”¯ä»˜ç™¼ç¥¨"
"Invoices" = "ç™¼ç¥¨"
"InvoList" = "åˆ—å‡ºç™¼ç¥¨"
"generate" = "ç”Ÿæˆ"
"InvoGene" = "ç”Ÿæˆç™¼ç¥¨"
"decode" = "è§£ç¢¼"
"InvoDeco" = "ç™¼ç¥¨è§£ç¢¼"
"Channels" = "é€šè·¯"
"ChanList" = "åˆ—å‡ºé€šè·¯"
"open" = "æ‰“é–‹"
"ChanOpen" = "æ‰“é–‹é€šè·¯"
"set fee" = "è¨­å®šè²»ç”¨"
"ChanSetf" = "è¨­å®šè²»ç”¨"
"close" = "é—œé–‰"
"ChanClos" = "é—œé–‰é€šè·¯"
"history" = "æ­·å²è³‡è¨Š"
"ChanHist" = "é€šè·¯æ­·å²"
"balance" = "é¤˜é¡"
"ChanBala" = "é€šè·¯é¤˜é¡"
"list forwards" = "è½‰å¯„æ¸…å–®"
"ChanLsfd" = "é€šè·¯è½‰å¯„æ¸…å–®"
"Query at " = "æŸ¥è©¢æ–¼"
"Press " = "å£“ä¸‹"
"Then, press " = "å†æ¬¡å£“ä¸‹"
" to fetch again" = "ä»¥å†æ¬¡ç²å–è³‡è¨Š"
" to fetch" = "ä»¥ç²å–è³‡è¨Š"
" to input data.  " = "ä»¥è¼¸å…¥è³‡æ–™"
" again to execute.  " = "ä¾†åŸ·è¡Œ"
"On query, please wait..." = "æŸ¥è©¢ä¸­ï¼Œè«‹ç¨å¾…..."
"Can not find out previous query." = "ç„¡å…ˆå‰æŸ¥è©¢è³‡è¨Š"
"Fail to connect on DB." = "ç„¡æ³•è¯çµè³‡æ–™åº«"
"Welcome to ðŸŒ”kuutamo Tui" = "æ­¡è¿Žä½¿ç”¨ðŸŒ”kuutamo Tui"
"Following are the key setting you are using now" = "ä»¥ä¸‹æ˜¯æ‚¨ç¾åœ¨æ­£ä½¿ç”¨çš„æŒ‰éµè¨­å®š"
"If you have any suggestion please let us know on Github." = "å¦‚æžœæ‚¨æœ‰ä»»ä½•å»ºè­°æ­¡è¿Žåœ¨Githubä¸Šèˆ‡æˆ‘å€‘è¯ç¹«"
"Introduction" = "èªªæ˜Ž"
" to cancel inputs.  " = "ä»¥å–æ¶ˆè¼¸å…¥"
"Decode response error:" = "å›žæ‡‰è§£è­¯éŒ¯èª¤ï¼š"
"This command is not ready yet, please use kld-cli instead." = "æŒ‡ä»¤å°šæœªæº–å‚™å¥½ï¼Œè«‹ä½¿ç”¨ kld-cli ä»£æ›¿ã€‚"

[en_US]
"NodeInfo" = "Node Information"
"NodeFees" = "Node Fees"
"NodeEslq" = "Estimate Liquidity"
"NodeSign" = "Sign"
"NodeLsfd" = "List Funds"
"NetwLsnd" = "List Nodes"
"NetwFeer" = "Fee Rates"
"PeerList" = "List Peer"
"PeerCont" = "Connect"
"PeerDisc" = "Disconnect"
"PaymList" = "List Payments"
"PaymSdky" = "Send Key"
"PaymPayi" = "Pay Invoices"
"InvoList" = "List Invoices"
"InvoGene" = "Generate Invoice"
"InvoDeco" = "Decode invoice"
"ChanList" = "List Channels"
"ChanOpen" = "Open Channel"
"ChanSetf" = "Set Fee"
"ChanClos" = "Close Channel"
"ChanHist" = "Channel History"
"ChanBala" = "Channel Balance"
"ChanLsfd" = "List Forwards"

'''
'''--- tui/src/action.rs ---
use crate::components::command::Cmd;
use crate::utils::ts_to_string;
use std::fmt;

use serde::{
    de::{self, Deserializer, Visitor},
    Deserialize, Serialize,
};

#[derive(Debug, Clone, Hash, PartialEq, Eq, Serialize)]
pub enum Action {
    Tick,
    Render,
    Resize(u16, u16),
    Suspend,
    Resume,
    Quit,
    Refresh,
    Error(String),
    Help,
    SwitchTab,
    Tab(&'static str),
    NavUp,
    NavDown,
    NavLeft,
    NavRight,
    Command(Cmd),
    Execute(Cmd, String),
    EnterCmdMode,
    ExitCmdMode,
    SwitchInputs,
    TriggerExecute,
    History(u64),
    Input(crossterm::event::KeyEvent),
}

impl fmt::Display for Action {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        match self {
            Action::Tick => write!(f, "Tick"),
            Action::Render => write!(f, "Render"),
            Action::Resize(w, h) => write!(f, "Resize({},{})", w, h),
            Action::Suspend => write!(f, "Suspend"),
            Action::Resume => write!(f, "Resume"),
            Action::Quit => write!(f, "Quit"),
            Action::Refresh => write!(f, "Refresh"),
            Action::Error(e) => write!(f, "Error({})", e),
            Action::Help => write!(f, "Help"),
            Action::SwitchTab => write!(f, "SwitchTab"),
            Action::Tab(t) => write!(f, "Tab({})", t),
            Action::NavUp => write!(f, "NavUp"),
            Action::NavDown => write!(f, "NavDown"),
            Action::NavLeft => write!(f, "NavLeft"),
            Action::NavRight => write!(f, "NavRight"),
            Action::Command(cmd) => write!(f, "Command({:?})", cmd),
            Action::Execute(cmd, s) => write!(f, "Execute({:?}, {s:})", cmd),
            Action::EnterCmdMode => write!(f, "EnterCmdMode"),
            Action::ExitCmdMode => write!(f, "ExitCmdMode"),
            Action::SwitchInputs => write!(f, "SwitchInputs"),
            Action::TriggerExecute => write!(f, "TriggerExecute"),
            Action::History(ts) => write!(f, "History({})", ts_to_string(*ts)),
            Action::Input(key_event) => write!(f, "Input({:?})", key_event),
        }
    }
}

impl<'de> Deserialize<'de> for Action {
    fn deserialize<D>(deserializer: D) -> Result<Self, D::Error>
    where
        D: Deserializer<'de>,
    {
        struct ActionVisitor;

        impl<'de> Visitor<'de> for ActionVisitor {
            type Value = Action;

            fn expecting(&self, formatter: &mut fmt::Formatter) -> fmt::Result {
                formatter.write_str("a valid string representation of Action")
            }

            fn visit_str<E>(self, value: &str) -> Result<Action, E>
            where
                E: de::Error,
            {
                match value {
                    "Tick" => Ok(Action::Tick),
                    "Render" => Ok(Action::Render),
                    "Suspend" => Ok(Action::Suspend),
                    "Resume" => Ok(Action::Resume),
                    "Quit" => Ok(Action::Quit),
                    "Refresh" => Ok(Action::Refresh),
                    "Help" => Ok(Action::Help),
                    "SwitchTab" => Ok(Action::SwitchTab),
                    "NavUp" => Ok(Action::NavUp),
                    "NavDown" => Ok(Action::NavDown),
                    "NavLeft" => Ok(Action::NavLeft),
                    "NavRight" => Ok(Action::NavRight),
                    "EnterCmdMode" => Ok(Action::EnterCmdMode),
                    "ExitCmdMode" => Ok(Action::ExitCmdMode),
                    "SwitchInputs" => Ok(Action::SwitchInputs),
                    "TriggerExecute" => Ok(Action::TriggerExecute),
                    data if data.starts_with("Error(") => {
                        let error_msg = data.trim_start_matches("Error(").trim_end_matches(')');
                        Ok(Action::Error(error_msg.to_string()))
                    }
                    data if data.starts_with("Resize(") => {
                        let parts: Vec<&str> = data
                            .trim_start_matches("Resize(")
                            .trim_end_matches(')')
                            .split(',')
                            .collect();
                        if parts.len() == 2 {
                            let width: u16 = parts[0].trim().parse().map_err(E::custom)?;
                            let height: u16 = parts[1].trim().parse().map_err(E::custom)?;
                            Ok(Action::Resize(width, height))
                        } else {
                            Err(E::custom(format!("Invalid Resize format: {}", value)))
                        }
                    }
                    _ => Err(E::custom(format!("Unknown Action variant: {}", value))),
                }
            }
        }

        deserializer.deserialize_str(ActionVisitor)
    }
}

'''
'''--- tui/src/app.rs ---
use color_eyre::eyre::{eyre, Result};
use crossterm::event::KeyEvent;
use r2d2::Pool;
use r2d2_sqlite::SqliteConnectionManager;
use ratatui::prelude::Rect;
use std::path::PathBuf;
use std::thread;
use std::time::{SystemTime, UNIX_EPOCH};
use tokio::sync::mpsc;
use url::Url;

use crate::{
    action::Action,
    components::{
        command::list::CmdList,
        command::query,
        command::{details::CmdDetails, Cmd},
        debug::DebugComponent,
        history::details::HistoryDetails,
        history::list::HistoryList,
        tab_bar::TabBar,
        Component,
    },
    keybinding::KeyBindings,
    mode::Mode,
    tui,
};

#[derive(Clone)]
pub struct ConnectionAuth {
    pub url: Url,
    pub pem: Vec<u8>,
    pub macaroon: Vec<u8>,
}

impl ConnectionAuth {
    pub fn new(secrets: PathBuf, url: Url) -> Result<Self> {
        let pem_path = secrets.join("lightning").join("ca.pem");
        if !pem_path.exists() {
            log::error!("no pem under {}", secrets.display());
            return Err(eyre!(
                "Could not find pem under secrets, please provide a correct one with `--secrets`"
            ));
        }
        let pem = match std::fs::read(&pem_path) {
            Ok(content) => content,
            Err(e) => {
                log::error!("Could not read pem: {e}");
                return Err(eyre!("Could not read pem"));
            }
        };

        let macaroon_path = secrets.join("admin.macaroon");
        if !macaroon_path.exists() {
            log::error!("no macaroon under {}", secrets.display());
            return Err(eyre!("Could not find macaroon under secrets, please provide a correct one with `--secrets`"));
        }
        let macaroon = match std::fs::read(&macaroon_path) {
            Ok(content) => content,
            Err(e) => {
                log::error!("Could not read macaroon: {e}");
                return Err(eyre!("Could not read macaroon"));
            }
        };
        Ok(Self { pem, url, macaroon })
    }
}

pub struct App {
    pub keybindings: KeyBindings,
    pub components: Vec<Box<dyn Component>>,
    pub should_quit: bool,
    pub should_suspend: bool,
    pub mode: Mode,
    pub last_tick_key_events: Vec<KeyEvent>,
    pool: Pool<SqliteConnectionManager>,
    connection_auth: ConnectionAuth,
}

impl App {
    pub fn new(
        user_keybinding: Option<PathBuf>,
        debug: bool,
        pool: Pool<SqliteConnectionManager>,
        connection_auth: ConnectionAuth,
    ) -> Result<Self> {
        let mode = Mode::Navigate;
        let keybindings = KeyBindings::new(user_keybinding)?;
        Ok(Self {
            components: if debug {
                vec![
                    Box::<TabBar>::default(),
                    Box::<CmdList>::default(),
                    Box::new(CmdDetails::new(&keybindings, pool.clone())),
                    Box::new(HistoryList::new(pool.clone())),
                    Box::new(HistoryDetails::new(pool.clone())),
                    Box::<DebugComponent>::default(),
                ]
            } else {
                vec![
                    Box::<TabBar>::default(),
                    Box::<CmdList>::default(),
                    Box::new(CmdDetails::new(&keybindings, pool.clone())),
                    Box::new(HistoryList::new(pool.clone())),
                    Box::new(HistoryDetails::new(pool.clone())),
                ]
            },
            should_quit: false,
            should_suspend: false,
            keybindings,
            mode,
            last_tick_key_events: Vec::new(),
            pool,
            connection_auth,
        })
    }

    pub async fn run(&mut self, tick_rate: f64, frame_rate: f64) -> Result<()> {
        let (action_tx, mut action_rx) = mpsc::unbounded_channel();

        let mut tui = tui::Tui::new(Some(tick_rate), Some(frame_rate))?;
        tui.enter()?;

        for component in self.components.iter_mut() {
            component.register_action_handler(action_tx.clone())?;
        }

        for component in self.components.iter_mut() {
            component.init(tui.size()?)?;
        }

        loop {
            if let Some(e) = tui.next().await {
                match e {
                    tui::Event::Quit => action_tx.send(Action::Quit)?,
                    tui::Event::Tick => action_tx.send(Action::Tick)?,
                    tui::Event::Render => action_tx.send(Action::Render)?,
                    tui::Event::Resize(x, y) => action_tx.send(Action::Resize(x, y))?,
                    tui::Event::Key(key) => {
                        if let Some(keymap) = self.keybindings.get(&self.mode) {
                            if let Some(action) = keymap.get(&vec![key]) {
                                log::info!("Got action: {action:?}");
                                action_tx.send(action.clone())?;
                            } else {
                                // If the key was not handled as a single key action,
                                // then consider it for multi-key combinations.
                                self.last_tick_key_events.push(key);

                                // Check for multi-key combinations
                                if let Some(action) = keymap.get(&self.last_tick_key_events) {
                                    log::info!("Action triggered: {action:?}");
                                    action_tx.send(action.clone())?;
                                }
                            }
                        };
                        if self.mode == Mode::Command {
                            action_tx.send(Action::Input(key))?;
                        }
                    }
                    _ => {}
                }
                for component in self.components.iter_mut() {
                    if let Some(action) = component.handle_events(Some(e.clone()))? {
                        action_tx.send(action)?;
                    }
                }
            }

            while let Ok(action) = action_rx.try_recv() {
                if action != Action::Tick && action != Action::Render {
                    log::debug!("{action:?}");
                }
                match action {
                    Action::Tick => {
                        self.last_tick_key_events.drain(..);
                    }
                    Action::Quit => self.should_quit = true,
                    Action::Suspend => self.should_suspend = true,
                    Action::Resume => self.should_suspend = false,
                    Action::Resize(w, h) => {
                        tui.resize(Rect::new(0, 0, w, h))?;
                        tui.draw(|f| {
                            for component in self.components.iter_mut() {
                                let r = component.draw(f, f.size());
                                if let Err(e) = r {
                                    action_tx
                                        .send(Action::Error(format!("Failed to draw: {:?}", e)))
                                        .unwrap();
                                }
                            }
                        })?;
                    }
                    Action::Render => {
                        tui.draw(|f| {
                            for component in self.components.iter_mut() {
                                let r = component.draw(f, f.size());
                                if let Err(e) = r {
                                    action_tx
                                        .send(Action::Error(format!("Failed to draw: {:?}", e)))
                                        .unwrap();
                                }
                            }
                        })?;
                    }
                    Action::EnterCmdMode => self.mode = Mode::Command,
                    Action::ExitCmdMode => self.mode = Mode::Navigate,
                    Action::Execute(ref cmd, ref input) => {
                        let trigger_time = unix_timestamp();
                        if let Ok(conn) = self.pool.get() {
                            log::info!("{cmd:?} trigger at {trigger_time:}");
                            if let Err(e) = conn.execute("INSERT INTO history(timestamp, command, input, output) VALUES (?, ?, ?, '')", [&trigger_time.to_string(), &format!("{cmd:?}"), input]) {
                                log::error!("Fail to write record: {e:}");
                            }
                        } else {
                            log::error!("Fail to init {cmd:?} trigger at {trigger_time:}");
                        }

                        let pool = self.pool.clone();
                        let auth = self.connection_auth.clone();
                        let uri = cmd.get_uri().unwrap_or_default();
                        let input = input.to_string();
                        match cmd {
                            Cmd::NodeInfo | Cmd::ChanList => {
                                thread::spawn(move || {
                                    log::trace!("query for {trigger_time:}");
                                    let output = query::get(auth, uri);
                                    match pool.get() {
                                        Ok(conn) => {
                                            if let Err(e) = conn.execute("UPDATE history SET output = ? WHERE timestamp == ?;", [&output, &trigger_time.to_string()]) {
                                                log::error!("Fail to update query result for {trigger_time:}: {}", e);
                                            }
                                        }
                                        Err(e) => log::error!(
                                            "Fail to get db connection for {trigger_time:}: {}",
                                            e
                                        ),
                                    }
                                });
                                action_tx.send(Action::ExitCmdMode)?;
                            }
                            Cmd::PeerCont | Cmd::ChanOpen => {
                                thread::spawn(move || {
                                    log::trace!("query for {trigger_time:}");
                                    let output = query::post(auth, uri, input);
                                    match pool.get() {
                                        Ok(conn) => {
                                            if let Err(e) = conn.execute("UPDATE history SET output = ? WHERE timestamp == ?;", [&output, &trigger_time.to_string()]) {
                                                log::error!("Fail to update query result for {trigger_time:}: {}", e);
                                            }
                                        }
                                        Err(e) => log::error!(
                                            "Fail to get db connection for {trigger_time:}: {}",
                                            e
                                        ),
                                    }
                                });
                                action_tx.send(Action::ExitCmdMode)?;
                            }
                            _ => {}
                        }
                    }
                    _ => {}
                }
                for component in self.components.iter_mut() {
                    if let Some(action) = component.update(action.clone())? {
                        action_tx.send(action)?
                    };
                }
            }
            if self.should_suspend {
                let (tick_rate, frame_rate) = (tui.tick_rate, tui.frame_rate);
                tui.suspend()?;
                action_tx.send(Action::Resume)?;
                tui = tui::Tui::new(Some(tick_rate), Some(frame_rate))?;
                tui.enter()?;
            } else if self.should_quit {
                tui.stop()?;
                break;
            }
        }
        tui.exit()?;
        Ok(())
    }
}

fn unix_timestamp() -> u64 {
    let start = SystemTime::now();
    let since_the_epoch = start
        .duration_since(UNIX_EPOCH)
        .expect("Time went backwards");
    since_the_epoch.as_secs()
}

'''
'''--- tui/src/components/command/details.rs ---
use color_eyre::eyre::Result;
use kld::api::payloads::FundChannel;
use r2d2::Pool;
use r2d2_sqlite::SqliteConnectionManager;
use ratatui::{prelude::*, widgets::*};
use serde_json::json;
use tokio::sync::mpsc::UnboundedSender;

use crate::action::Action;
use crate::components::command::parsers::parse_channel_details;
use crate::components::command::Cmd;
use crate::components::{Component, Frame};
use crate::keybinding::{KeyBindingHelps, KeyBindings};
use crate::mode::Mode;
use crate::utils::{ts_to_string, WORD_BINDINGS};

pub struct CmdDetails {
    command_tx: Option<UnboundedSender<Action>>,
    display: bool,
    on_focus: Option<usize>,
    /// The command of items selected
    selected_command: Cmd,
    keybindings_help: KeyBindingHelps,
    pool: Pool<SqliteConnectionManager>,
    inputs: Vec<String>,
    /// The index of item in list in query result
    index: usize,
    /// The length of list in query result
    length: usize,
    error_msg: Option<String>,
}

impl CmdDetails {
    pub fn new(keybinding: &KeyBindings, pool: Pool<SqliteConnectionManager>) -> Self {
        Self {
            command_tx: None,
            display: true,
            on_focus: None,
            selected_command: Cmd::AppInfo,
            keybindings_help: keybinding.help_info(),
            pool,
            inputs: Vec::new(),
            index: 0,
            length: 0,
            error_msg: None,
        }
    }
}

struct SqlResult {
    timestamp: u64,
    input: String,
    output: String,
}

pub trait LastQuery {
    /// show the last result of a command or on query prompt
    fn last_result(&self, cmd: Cmd) -> (Option<u64>, String);
}

impl LastQuery for CmdDetails {
    fn last_result(&self, cmd: Cmd) -> (Option<u64>, String) {
        let mut last_result = String::new();
        let last_query_time = if let Ok(conn) = self.pool.get() {
            match conn.query_row(
                &format!("SELECT timestamp, input, output FROM history WHERE command == '{:?}' ORDER BY timestamp DESC LIMIT 1", cmd),
                [],
                |row|
                Ok(SqlResult{
                    timestamp: row.get(0)?,
                    input: row.get(1)?,
                    output: row.get(2)?,
                })){
                Ok(result) => {
                    if result.output.is_empty() {
                        last_result.push_str(WORD_BINDINGS.get("On query, please wait..."));
                        last_result.push('\n');
                    } else {
                        last_result.push_str(&result.input);
                        last_result.push('\n');
                        last_result.push_str(&result.output);
                        last_result.push('\n');
                    }
                    Some(result.timestamp)
                },
                Err(_) => {
                    last_result.push_str(WORD_BINDINGS.get("Can not find out previous query."));
                    last_result.push('\n');
                    None
                },
            }
        } else {
            None
        };
        (last_query_time, last_result)
    }
}

impl Component for CmdDetails {
    fn register_action_handler(&mut self, tx: UnboundedSender<Action>) -> Result<()> {
        self.command_tx = Some(tx);
        Ok(())
    }

    fn update(&mut self, action: Action) -> Result<Option<Action>> {
        match action {
            Action::Tab(t) => self.display = t == WORD_BINDINGS.get("Command List"),
            Action::Command(c) => self.selected_command = c,
            Action::NavLeft if self.length > 0 => {
                if self.index == 0 {
                    self.index = self.length - 1;
                } else {
                    self.index -= 1;
                }
            }
            Action::NavRight if self.length > 0 => {
                if self.index == self.length - 1 {
                    self.index = 0;
                } else {
                    self.index += 1;
                }
            }
            Action::EnterCmdMode => {
                self.on_focus = Some(0);
                match self.selected_command {
                    Cmd::NodeInfo => {
                        return Ok(Some(Action::Execute(Cmd::NodeInfo, String::new())))
                    }
                    Cmd::PeerCont => {
                        self.inputs = vec![String::new()];
                    }
                    Cmd::ChanOpen => {
                        self.inputs = vec![String::new(), String::new()];
                    }
                    Cmd::ChanList => {
                        self.index = 0;
                        self.length = 0;
                        return Ok(Some(Action::Execute(Cmd::ChanList, String::new())));
                    }
                    _ => {
                        // Command not implement currently, exit
                        return Ok(Some(Action::ExitCmdMode));
                    }
                }
            }
            Action::ExitCmdMode => self.on_focus = None,
            Action::TriggerExecute => {
                self.error_msg = None;
                let next_action = match self.selected_command {
                    Cmd::PeerCont => Some(Action::Execute(
                        Cmd::PeerCont,
                        json!({
                            "id": self.inputs[0],
                        })
                        .to_string(),
                    )),
                    Cmd::ChanOpen => {
                        let fund_channel = FundChannel {
                            id: self.inputs[0].clone(),
                            satoshis: self.inputs[1].clone(),
                            fee_rate: None,
                            announce: None,
                            min_conf: None,
                            utxos: Vec::new(),
                            push_msat: None,
                            close_to: None,
                            request_amt: None,
                            compact_lease: None,
                        };
                        match serde_json::to_string(&fund_channel) {
                            Ok(payload) => Some(Action::Execute(Cmd::ChanOpen, payload)),
                            Err(e) => {
                                self.error_msg = Some(format!("{e}"));
                                None
                            }
                        }
                    }
                    _ => None,
                };
                self.inputs = Vec::new();
                return Ok(next_action);
            }
            Action::SwitchInputs => {
                if let Some(on_focus) = self.on_focus {
                    let mut new_focus = on_focus + 1;
                    match self.selected_command {
                        Cmd::PeerCont => new_focus = 0,
                        Cmd::ChanOpen if new_focus > 1 => new_focus = 0,
                        _ => {}
                    }
                    self.on_focus = Some(new_focus);
                }
            }
            Action::Input(key_event) => {
                if let Some(on_focus) = self.on_focus {
                    match key_event.code {
                        crossterm::event::KeyCode::Char(c) => {
                            self.inputs[on_focus].push(c);
                        }
                        crossterm::event::KeyCode::Backspace => {
                            self.inputs[on_focus].pop();
                        }
                        _ => {}
                    }
                }
            }
            _ => {}
        }
        Ok(None)
    }

    fn draw(&mut self, f: &mut Frame<'_>, _area: Rect) -> Result<()> {
        if self.display {
            let mut size = f.size();
            // TabBar offset
            size.y += 3;
            size.height -= 3;
            // CmdList offset
            size.x += 25;
            size.width -= 25;

            match self.selected_command {
                Cmd::AppInfo => self.app_info(f, size),
                Cmd::NodeInfo => self.node_info(f, size),
                Cmd::ChanOpen => self.channel_open(f, size),
                Cmd::ChanList => self.channel_list(f, size),
                Cmd::PeerCont => self.peer_connect(f, size),
                _ => {
                    let text = Text::from(Line::from(
                        WORD_BINDINGS
                            .get("This command is not ready yet, please use kld-cli instead."),
                    ));
                    let unimplement_prompt =
                        Paragraph::new(text).block(Block::default().borders(Borders::ALL));
                    f.render_widget(unimplement_prompt, size);
                }
            }
        }
        Ok(())
    }
}

impl CmdDetails {
    fn app_info(&mut self, f: &mut Frame<'_>, area: Rect) {
        let mut help_info = WORD_BINDINGS.get("Welcome to ðŸŒ”kuutamo Tui").to_string();
        help_info += "\n";
        help_info += WORD_BINDINGS.get("Following are the key setting you are using now");
        help_info += "\n\n";
        for (m, keybinding) in &self.keybindings_help {
            help_info.push_str(&format!("[{m:?}]\n"));
            for (action, keybindings) in keybinding {
                help_info.push_str(&format!("    {action:} - {}\n", keybindings.join(",")));
            }
        }
        help_info.push('\n');
        help_info.push_str(
            WORD_BINDINGS.get("If you have any suggestion please let us know on Github."),
        );
        help_info.push('\n');
        help_info.push_str("https://github.com/kuutamolabs/lightning-tui");
        let p = Paragraph::new(help_info).block(Block::default().borders(Borders::ALL));
        f.render_widget(p, area);
    }
    fn append_execute_hint(&self, again: bool, info: &mut String) {
        if again {
            info.push_str(WORD_BINDINGS.get("Press "));
            info.push_str(
                &self
                    .keybindings_help
                    .get(&Mode::Command)
                    .and_then(|kb| kb.get(&Action::TriggerExecute))
                    .map(|kb_list| kb_list.join("/"))
                    .unwrap_or_default(),
            );
            info.push_str(WORD_BINDINGS.get(" to fetch again"));
        } else {
            info.push_str(WORD_BINDINGS.get("Press "));
            info.push_str(
                &self
                    .keybindings_help
                    .get(&Mode::Command)
                    .and_then(|kb| kb.get(&Action::TriggerExecute))
                    .map(|kb_list| kb_list.join("/"))
                    .unwrap_or_default(),
            );
            info.push_str(WORD_BINDINGS.get(" to fetch"));
        }
    }
    fn node_info(&mut self, f: &mut Frame<'_>, area: Rect) {
        let (last_query_time, mut info) = self.last_result(Cmd::NodeInfo);
        self.append_execute_hint(last_query_time.is_some(), &mut info);

        let p = Paragraph::new(info).block(if let Some(last_query_time) = last_query_time {
            Block::default()
                .title(
                    block::title::Title::from(format!(
                        "{}{}",
                        WORD_BINDINGS.get("Query at "),
                        ts_to_string(last_query_time)
                    ))
                    .position(block::title::Position::Top)
                    .alignment(Alignment::Right),
                )
                .borders(Borders::ALL)
        } else {
            Block::default().borders(Borders::ALL)
        });
        f.render_widget(p, area);
    }
    fn draw_intro(&mut self, f: &mut Frame<'_>, area: Rect) {
        let mut info = WORD_BINDINGS.get("Press ").to_string();
        info.push_str(
            &self
                .keybindings_help
                .get(&Mode::Command)
                .and_then(|kb| kb.get(&Action::TriggerExecute))
                .map(|kb_list| kb_list.join("/"))
                .unwrap_or_default(),
        );
        info.push('/');
        info.push_str(
            &self
                .keybindings_help
                .get(&Mode::Command)
                .and_then(|kb| kb.get(&Action::SwitchInputs))
                .map(|kb_list| kb_list.join("/"))
                .unwrap_or_default(),
        );
        info.push_str(WORD_BINDINGS.get(" to input data.  "));
        info.push_str(WORD_BINDINGS.get("Then, press "));
        info.push_str(
            &self
                .keybindings_help
                .get(&Mode::Command)
                .and_then(|kb| kb.get(&Action::TriggerExecute))
                .map(|kb_list| kb_list.join("/"))
                .unwrap_or_default(),
        );
        info.push_str(WORD_BINDINGS.get(" again to execute.  "));
        info += WORD_BINDINGS.get("Press ");
        info.push_str(
            &self
                .keybindings_help
                .get(&Mode::Command)
                .and_then(|kb| kb.get(&Action::ExitCmdMode))
                .map(|kb_list| kb_list.join("/"))
                .unwrap_or_default(),
        );
        info.push_str(WORD_BINDINGS.get(" to cancel inputs.  "));

        let text = Text::from(Line::from(info));
        let help_message = Paragraph::new(text).block(
            Block::default()
                .borders(Borders::ALL)
                .title(WORD_BINDINGS.get("Introduction")),
        );
        f.render_widget(help_message, area);
    }

    fn show_last_result(&mut self, f: &mut Frame<'_>, area: Rect, cmd: Cmd) {
        let (last_query_time, last_result) = self.last_result(cmd);

        let inner =
            Paragraph::new(last_result).block(if let Some(last_query_time) = last_query_time {
                Block::default()
                    .title(
                        block::title::Title::from(format!(
                            "{}{}",
                            WORD_BINDINGS.get("Query at "),
                            ts_to_string(last_query_time)
                        ))
                        .position(block::title::Position::Top)
                        .alignment(Alignment::Right),
                    )
                    .borders(Borders::ALL)
            } else {
                Block::default().borders(Borders::ALL)
            });
        f.render_widget(inner, area);
    }
    fn show_error_msg(&mut self, f: &mut Frame<'_>, area: Rect, msg: String) {
        let inner = Paragraph::new(msg)
            .block(Block::default().borders(Borders::ALL))
            .style(Style::default().red().bold());
        f.render_widget(inner, area);
    }
    fn peer_connect(&mut self, f: &mut Frame<'_>, area: Rect) {
        let chunks = Layout::default()
            .direction(Direction::Vertical)
            .constraints([
                Constraint::Length(3),
                Constraint::Length(3),
                Constraint::Min(0),
            ])
            .split(area);
        self.draw_intro(f, chunks[0]);
        if let Some(ref err_msg) = self.error_msg {
            self.show_error_msg(f, chunks[2], err_msg.to_string());
        } else {
            self.show_last_result(f, chunks[2], Cmd::ChanOpen);
        }

        let input = Paragraph::new(
            self.inputs
                .first()
                .map(|s| s.to_string())
                .unwrap_or_default(),
        )
        .block(
            Block::default()
                .borders(Borders::ALL)
                .border_style(if self.on_focus.is_some() {
                    Style::default().fg(Color::Yellow)
                } else {
                    Style::default()
                })
                .title(WORD_BINDINGS.get("Public Key")),
        );
        f.render_widget(input, chunks[1]);
    }
    fn channel_open(&mut self, f: &mut Frame<'_>, area: Rect) {
        let chunks = Layout::default()
            .direction(Direction::Vertical)
            .constraints([
                Constraint::Length(3),
                Constraint::Length(3),
                Constraint::Length(3),
                Constraint::Min(0),
            ])
            .split(area);
        self.draw_intro(f, chunks[0]);
        if let Some(ref err_msg) = self.error_msg {
            self.show_error_msg(f, chunks[3], err_msg.to_string());
        } else {
            self.show_last_result(f, chunks[3], Cmd::ChanOpen);
        }

        let pk_input = Paragraph::new(
            self.inputs
                .first()
                .map(|s| s.to_string())
                .unwrap_or_default(),
        )
        .block(
            Block::default()
                .borders(Borders::ALL)
                .border_style(if self.on_focus == Some(0) {
                    Style::default().fg(Color::Yellow)
                } else {
                    Style::default()
                })
                .title(WORD_BINDINGS.get("Public Key")),
        );
        f.render_widget(pk_input, chunks[1]);

        let amt_input = Paragraph::new(
            self.inputs
                .get(1)
                .map(|s| s.to_string())
                .unwrap_or_default(),
        )
        .block(
            Block::default()
                .borders(Borders::ALL)
                .border_style(if self.on_focus == Some(1) {
                    Style::default().fg(Color::Yellow)
                } else {
                    Style::default()
                })
                .title(WORD_BINDINGS.get("Satoshis")),
        );
        f.render_widget(amt_input, chunks[2]);
    }
    fn channel_list(&mut self, f: &mut Frame<'_>, area: Rect) {
        let (last_query_time, info) = self.last_result(Cmd::ChanList);
        if let Some(last_query_time) = last_query_time {
            let block = Block::default()
                .title(
                    block::title::Title::from(format!(
                        "{}{}",
                        WORD_BINDINGS.get("Query at "),
                        ts_to_string(last_query_time)
                    ))
                    .position(block::title::Position::Top)
                    .alignment(Alignment::Right),
                )
                .borders(Borders::ALL);
            match parse_channel_details(&info) {
                Ok(details) => {
                    self.length = details.len();
                    let widths = [Constraint::Length(30), Constraint::Max(f.size().width - 30)];
                    let table = Table::new(details[self.index].clone(), widths)
                        .block(block)
                        .footer(
                            Row::new(vec![
                                Line::raw(String::from("")),
                                Line::raw(format!(
                                    "{} ({}/{})",
                                    WORD_BINDINGS.get("Page"),
                                    self.index + 1,
                                    self.length
                                ))
                                .alignment(Alignment::Right),
                            ])
                            .style(Style::default().bold()),
                        );
                    f.render_widget(table, area);
                }
                Err(e) => {
                    let mut output = WORD_BINDINGS.get("Decode response error:").to_string();
                    output.push('\n');
                    output += &e.to_string();
                    output.push('\n');
                    output += &info;
                    self.append_execute_hint(true, &mut output);
                    f.render_widget(Paragraph::new(output).block(block), area);
                }
            }
        } else {
            let mut output = String::new();
            self.append_execute_hint(false, &mut output);
            f.render_widget(
                Paragraph::new(output).block(Block::default().borders(Borders::ALL)),
                area,
            );
        }
    }
}

'''
'''--- tui/src/components/command/list.rs ---
use color_eyre::eyre::Result;
use ratatui::{prelude::*, widgets::*};
use tokio::sync::mpsc::UnboundedSender;

use super::Cmd;
use crate::action::Action;
use crate::components::{Component, Frame};
use crate::utils::WORD_BINDINGS;

pub struct CmdList {
    command_tx: Option<UnboundedSender<Action>>,
    display: bool,
    /// The index of items selected
    selected: usize,
    /// List item and parent
    items: Vec<(&'static str, Option<Cmd>)>,
}

impl Default for CmdList {
    fn default() -> Self {
        Self {
            command_tx: None,
            selected: 1,
            items: vec![
                (WORD_BINDINGS.get("App"), None),
                (WORD_BINDINGS.get("information"), Some(Cmd::AppInfo)),
                (WORD_BINDINGS.get("Node"), None),
                (WORD_BINDINGS.get("information"), Some(Cmd::NodeInfo)),
                (WORD_BINDINGS.get("fees"), Some(Cmd::NodeFees)),
                (WORD_BINDINGS.get("estimate liquidity"), Some(Cmd::NodeEslq)),
                (WORD_BINDINGS.get("sign"), Some(Cmd::NodeSign)),
                (WORD_BINDINGS.get("list funds"), Some(Cmd::NodeLsfd)),
                (WORD_BINDINGS.get("Network"), None),
                (WORD_BINDINGS.get("list nodes"), Some(Cmd::NetwLsnd)),
                (WORD_BINDINGS.get("fee rates"), Some(Cmd::NetwFeer)),
                (WORD_BINDINGS.get("Peers"), None),
                (WORD_BINDINGS.get("list"), Some(Cmd::PeerList)),
                (WORD_BINDINGS.get("connect"), Some(Cmd::PeerCont)),
                (WORD_BINDINGS.get("disconnect"), Some(Cmd::PeerDisc)),
                (WORD_BINDINGS.get("Payments"), None),
                (WORD_BINDINGS.get("list"), Some(Cmd::PaymList)),
                (WORD_BINDINGS.get("send key"), Some(Cmd::PaymSdky)),
                (WORD_BINDINGS.get("pay invoice"), Some(Cmd::PaymPayi)),
                (WORD_BINDINGS.get("Invoices"), None),
                (WORD_BINDINGS.get("list"), Some(Cmd::InvoList)),
                (WORD_BINDINGS.get("generate"), Some(Cmd::InvoGene)),
                (WORD_BINDINGS.get("decode"), Some(Cmd::InvoDeco)),
                (WORD_BINDINGS.get("Channels"), None),
                (WORD_BINDINGS.get("list"), Some(Cmd::ChanList)),
                (WORD_BINDINGS.get("open"), Some(Cmd::ChanOpen)),
                (WORD_BINDINGS.get("set fee"), Some(Cmd::ChanSetf)),
                (WORD_BINDINGS.get("close"), Some(Cmd::ChanClos)),
                (WORD_BINDINGS.get("history"), Some(Cmd::ChanHist)),
                (WORD_BINDINGS.get("balance"), Some(Cmd::ChanBala)),
                (WORD_BINDINGS.get("list forwards"), Some(Cmd::ChanLsfd)),
            ],
            display: true,
        }
    }
}

impl CmdList {
    fn nav_up(&mut self) -> Result<Option<Action>> {
        while self.display {
            if self.selected == 0 {
                self.selected = self.items.len() - 1;
            } else {
                self.selected -= 1;
            }
            if let Some(cmd) = &self.items[self.selected].1 {
                return Ok(Some(Action::Command(cmd.clone())));
            }
        }
        Ok(None)
    }
    fn nav_down(&mut self) -> Result<Option<Action>> {
        while self.display {
            if self.selected == self.items.len() - 1 {
                self.selected = 0;
            } else {
                self.selected += 1;
            }
            if let Some(cmd) = &self.items[self.selected].1 {
                return Ok(Some(Action::Command(cmd.clone())));
            }
        }
        Ok(None)
    }
}

impl Component for CmdList {
    fn register_action_handler(&mut self, tx: UnboundedSender<Action>) -> Result<()> {
        self.command_tx = Some(tx);
        Ok(())
    }

    fn update(&mut self, action: Action) -> Result<Option<Action>> {
        match action {
            Action::Tab(t) => {
                self.display = t == WORD_BINDINGS.get("Command List");
                Ok(None)
            }
            Action::NavUp => self.nav_up(),
            Action::NavDown => self.nav_down(),
            _ => Ok(None),
        }
    }

    fn draw(&mut self, f: &mut Frame<'_>, _area: Rect) -> Result<()> {
        if self.display {
            // TabBar offset
            let mut size = f.size();
            size.y += 3;
            size.height -= 3;

            let block = Block::default();
            f.render_widget(block, size);
            let chunks = Layout::default()
                .direction(Direction::Horizontal)
                .constraints([Constraint::Length(25), Constraint::Min(0)])
                .split(size);

            let items: Vec<ListItem> = self
                .items
                .iter()
                .enumerate()
                .map(|(idx, i)| {
                    if i.1.is_some() {
                        ListItem::new(format!("  {}", i.0)).style(
                            Style::default()
                                .fg(if idx == self.selected {
                                    Color::White
                                } else {
                                    Color::Gray
                                })
                                .add_modifier(if idx == self.selected {
                                    Modifier::BOLD
                                } else {
                                    Modifier::DIM
                                }),
                        )
                    } else {
                        ListItem::new(i.0).style(Style::default().fg(Color::Gray))
                    }
                })
                .collect();

            let items = List::new(items).block(Block::default().borders(Borders::ALL));

            f.render_widget(items, chunks[0]);
        }
        Ok(())
    }
}

'''
'''--- tui/src/components/command/mod.rs ---
pub mod details;
pub mod list;
pub(crate) mod parsers;
pub mod query;
use kld::api::routes;
use serde::Serialize;

#[derive(Debug, Clone, Hash, PartialEq, Eq, Serialize)]
pub enum Cmd {
    AppInfo,
    ChanBala,
    ChanClos,
    ChanHist,
    ChanList,
    ChanLsfd,
    ChanOpen,
    ChanSetf,
    InvoDeco,
    InvoGene,
    InvoList,
    NetwFeer,
    NetwLsnd,
    NodeEslq,
    NodeFees,
    NodeInfo,
    NodeLsfd,
    NodeSign,
    PaymList,
    PaymPayi,
    PaymSdky,
    PeerCont,
    PeerDisc,
    PeerList,
}

impl Cmd {
    pub fn get_uri(&self) -> Option<&'static str> {
        match self {
            Cmd::ChanBala => Some(routes::LOCAL_REMOTE_BALANCE),
            Cmd::ChanClos => Some(routes::CLOSE_CHANNEL),
            Cmd::ChanHist => Some(routes::LIST_CHANNEL_HISTORY),
            Cmd::ChanList => Some(routes::LIST_CHANNELS),
            Cmd::ChanLsfd => Some(routes::LIST_FORWARDS),
            Cmd::ChanOpen => Some(routes::OPEN_CHANNEL),
            Cmd::ChanSetf => Some(routes::SET_CHANNEL_FEE),
            Cmd::InvoDeco => Some(routes::DECODE_INVOICE),
            Cmd::InvoGene => Some(routes::GENERATE_INVOICE),
            Cmd::InvoList => Some(routes::LIST_INVOICES),
            Cmd::NetwFeer => Some(routes::FEE_RATES),
            Cmd::NetwLsnd => Some(routes::LIST_NETWORK_NODES),
            Cmd::NodeEslq => Some(routes::ESTIMATE_CHANNEL_LIQUIDITY),
            Cmd::NodeFees => Some(routes::GET_FEES),
            Cmd::NodeInfo => Some(routes::GET_INFO),
            Cmd::NodeLsfd => Some(routes::LIST_FUNDS),
            Cmd::NodeSign => Some(routes::SIGN),
            Cmd::PaymList => Some(routes::LIST_PAYMENTS),
            Cmd::PaymPayi => Some(routes::PAY_INVOICE),
            Cmd::PaymSdky => Some(routes::KEYSEND),
            Cmd::PeerCont => Some(routes::CONNECT_PEER),
            Cmd::PeerDisc => Some(routes::DISCONNECT_PEER),
            Cmd::PeerList => Some(routes::LIST_PEERS),
            _ => None,
        }
    }
}

'''
'''--- tui/src/components/command/parsers.rs ---
use color_eyre::eyre::Result;
use kld::api::codegen::get_kld_channel_response::GetKldChannelResponseItem;
use ratatui::{prelude::*, widgets::*};

use crate::utils::{ts_to_string, WORD_BINDINGS};

pub fn parse_channel_details<'a>(
    input: impl std::convert::AsRef<str>,
) -> Result<Vec<Vec<Row<'a>>>> {
    let details: Vec<GetKldChannelResponseItem> = serde_json::from_str(input.as_ref())?;

    // XXX i18n on these fields
    let mut outputs = Vec::new();
    for detail in details.into_iter() {
        let mut output = vec![Row::new(vec![
            Cell::from(Text::from(WORD_BINDINGS.get("Channel ID"))).style(Style::default().bold()),
            Cell::from(Text::from(detail.channel_id)),
        ])];
        output.push(Row::new(vec![
            Cell::from(Text::from(WORD_BINDINGS.get("Short Channel ID")))
                .style(Style::default().bold()),
            Cell::from(Text::from(
                detail
                    .short_channel_id
                    .map(|id| id.to_string())
                    .unwrap_or("none".into()),
            )),
        ]));
        output.push(Row::new(vec![
            Cell::from(Text::from(WORD_BINDINGS.get("User Channel ID")))
                .style(Style::default().bold()),
            Cell::from(Text::from(detail.user_channel_id.to_string())),
        ]));
        output.push(Row::new(vec![
            Cell::from(Text::from(WORD_BINDINGS.get("Funding TXO"))).style(Style::default().bold()),
            Cell::from(Text::from(detail.funding_txo)),
        ]));
        output.push(Row::new(vec![
            Cell::from(Text::from(WORD_BINDINGS.get("Open At"))).style(Style::default().bold()),
            Cell::from(Text::from(ts_to_string(detail.open_timestamp as u64))),
        ]));
        output.push(Row::new(vec![
            Cell::from(Text::from(WORD_BINDINGS.get("Updated At"))).style(Style::default().bold()),
            Cell::from(Text::from(ts_to_string(detail.update_timestamp as u64))),
        ]));
        let mut states = Vec::new();
        if let Some(state) = detail.channel_shutdown_state {
            states.push(state);
        }
        if detail.has_monitor {
            states.push("has monitor".into());
        } else {
            states.push("no monitor".into());
        }
        if detail.is_channel_ready {
            states.push("is ready".into());
        } else {
            states.push("not ready".into());
        }
        if detail.is_outbound {
            states.push("outbound".into());
        } else {
            states.push("inbound".into());
        }
        if detail.is_public {
            states.push("public".into());
        } else {
            states.push("private".into());
        }
        if detail.is_usable {
            states.push("usable".into());
        } else {
            states.push("not usable".into());
        }
        output.push(Row::new(vec![
            Cell::from(Text::from(WORD_BINDINGS.get("State"))).style(Style::default().bold()),
            Cell::from(Text::from(states.join("/"))),
        ]));
        output.push(Row::new(vec![
            Cell::from(Text::from(WORD_BINDINGS.get("Closure Reason")))
                .style(Style::default().bold()),
            Cell::from(Text::from(
                detail.closure_reason.unwrap_or("none".to_string()),
            )),
        ]));
        output.push(Row::new(vec![
            Cell::from(Text::from(WORD_BINDINGS.get("Balance"))).style(Style::default().bold()),
            Cell::from(Text::from(format!("{} msats", detail.balance_msat))),
        ]));
        output.push(Row::new(vec![
            Cell::from(Text::from(WORD_BINDINGS.get("Value"))).style(Style::default().bold()),
            Cell::from(Text::from(format!(
                "{} sats",
                detail.channel_value_satoshis
            ))),
        ]));
        output.push(Row::new(vec![
            Cell::from(Text::from(WORD_BINDINGS.get("Confirmations")))
                .style(Style::default().bold()),
            Cell::from(Text::from(
                detail
                    .confirmations
                    .map(|c| format!("{} blocks", c))
                    .unwrap_or("none".into()),
            )),
        ]));
        output.push(Row::new(vec![
            Cell::from(Text::from(WORD_BINDINGS.get("Required Confirmations")))
                .style(Style::default().bold()),
            Cell::from(Text::from(
                detail
                    .confirmations_required
                    .map(|c| format!("{} blocks", c))
                    .unwrap_or("none".into()),
            )),
        ]));
        output.push(Row::new(vec![
            Cell::from(Text::from(WORD_BINDINGS.get("Features"))).style(Style::default().bold()),
            Cell::from(Text::from(detail.features.join(","))),
        ]));
        output.push(Row::new(vec![
            Cell::from(Text::from(WORD_BINDINGS.get("Feerate"))).style(Style::default().bold()),
            Cell::from(Text::from(
                detail
                    .feerate_sat_per_1000_weight
                    .map(|c| format!("{c} sats / 1000 weight"))
                    .unwrap_or("none".into()),
            )),
        ]));
        output.push(Row::new(vec![
            Cell::from(Text::from(WORD_BINDINGS.get("Force Close Spend Delay")))
                .style(Style::default().bold()),
            Cell::from(Text::from(
                detail
                    .force_close_spend_delay
                    .map(|c| format!("{c} blocks"))
                    .unwrap_or("none".into()),
            )),
        ]));
        output.push(Row::new(vec![
            Cell::from(Text::from(
                WORD_BINDINGS.get("Unspendable Punishment Reserve"),
            ))
            .style(Style::default().bold()),
            Cell::from(Text::from(
                detail
                    .unspendable_punishment_reserve
                    .map(|c| format!("{c} sats",))
                    .unwrap_or("none".into()),
            )),
        ]));
        output.push(Row::new(vec![""]));
        // Inbound
        output.push(Row::new(vec![Cell::from(Text::from(
            WORD_BINDINGS.get("Inbound"),
        ))
        .style(Style::default().bold())]));
        output.push(Row::new(vec![
            Cell::from(Text::from(WORD_BINDINGS.get("Capacity"))).style(Style::default().bold()),
            Cell::from(Text::from(format!(
                "{} msats",
                detail.inbound_capacity_msat
            ))),
        ]));
        output.push(Row::new(vec![
            Cell::from(Text::from(WORD_BINDINGS.get("HTLC Maximum")))
                .style(Style::default().bold()),
            Cell::from(Text::from(
                detail
                    .inbound_htlc_maximum_msat
                    .map(|s| format!("{s} msats"))
                    .unwrap_or("none".into()),
            )),
        ]));
        output.push(Row::new(vec![
            Cell::from(Text::from(WORD_BINDINGS.get("HTLC Minimum")))
                .style(Style::default().bold()),
            Cell::from(Text::from(
                detail
                    .inbound_htlc_minimum_msat
                    .map(|s| format!("{s} msats"))
                    .unwrap_or("none".into()),
            )),
        ]));
        output.push(Row::new(vec![
            Cell::from(Text::from(WORD_BINDINGS.get("Short Channel ID Alias")))
                .style(Style::default().bold()),
            Cell::from(Text::from(
                detail
                    .inbound_scid_alias
                    .map(|id| id.to_string())
                    .unwrap_or("none".into()),
            )),
        ]));
        output.push(Row::new(vec![""]));
        // Outbound
        output.push(Row::new(vec![Cell::from(Text::from(
            WORD_BINDINGS.get("Inbound"),
        ))
        .style(Style::default().bold())]));
        output.push(Row::new(vec![
            Cell::from(Text::from(WORD_BINDINGS.get("Capacity"))).style(Style::default().bold()),
            Cell::from(Text::from(format!(
                "{} msats",
                detail.outbound_capacity_msat
            ))),
        ]));
        output.push(Row::new(vec![
            Cell::from(Text::from(WORD_BINDINGS.get("Short Channel ID Alias")))
                .style(Style::default().bold()),
            Cell::from(Text::from(
                detail
                    .outbound_scid_alias
                    .map(|id| id.to_string())
                    .unwrap_or("none".into()),
            )),
        ]));
        output.push(Row::new(vec![
            Cell::from(Text::from(WORD_BINDINGS.get("Next HTLC Maximum")))
                .style(Style::default().bold()),
            Cell::from(Text::from(format!(
                "{} msats",
                detail.next_outbound_htlc_limit_msat
            ))),
        ]));
        output.push(Row::new(vec![
            Cell::from(Text::from(WORD_BINDINGS.get("Next HTLC Minimum")))
                .style(Style::default().bold()),
            Cell::from(Text::from(format!(
                "{} msats",
                detail.next_outbound_htlc_minimum_msat
            ))),
        ]));
        output.push(Row::new(vec![""]));
        // Config
        output.push(Row::new(vec![Cell::from(Text::from(
            WORD_BINDINGS.get("Config"),
        ))
        .style(Style::default().bold())]));
        output.push(Row::new(vec![
            Cell::from(Text::from(WORD_BINDINGS.get("Underpaying HTLC")))
                .style(Style::default().bold()),
            Cell::from(Text::from(if detail.config_accept_underpaying_htlcs {
                WORD_BINDINGS.get("Accept")
            } else {
                WORD_BINDINGS.get("Deny")
            })),
        ]));
        output.push(Row::new(vec![
            Cell::from(Text::from(WORD_BINDINGS.get("CLTV Expiry"))).style(Style::default().bold()),
            Cell::from(Text::from(format!(
                "{} blocks",
                detail.config_cltv_expiry_delta
            ))),
        ]));
        output.push(Row::new(vec![
            Cell::from(Text::from(
                WORD_BINDINGS.get("Force Close Avoidance Max Fee"),
            ))
            .style(Style::default().bold()),
            Cell::from(Text::from(format!(
                "{} sats",
                detail.config_force_close_avoidance_max_fee_satoshis
            ))),
        ]));
        output.push(Row::new(vec![
            Cell::from(Text::from(WORD_BINDINGS.get("Forwarding Fee Base")))
                .style(Style::default().bold()),
            Cell::from(Text::from(format!(
                "{} msats",
                detail.config_forwarding_fee_base_msat
            ))),
        ]));
        output.push(Row::new(vec![
            Cell::from(Text::from(WORD_BINDINGS.get("Forwarding Fee")))
                .style(Style::default().bold()),
            Cell::from(Text::from(format!(
                "{} sat/proportional millionths",
                detail.config_forwarding_fee_proportional_millionths
            ))),
        ]));
        output.push(Row::new(vec![
            Cell::from(Text::from(WORD_BINDINGS.get("Max Dust HTLC Exposure")))
                .style(Style::default().bold()),
            Cell::from(Text::from(format!(
                "{} {}",
                if detail.config_max_dust_htlc_exposure_is_fixed {
                    WORD_BINDINGS.get("fix with")
                } else {
                    WORD_BINDINGS.get("fee rate multiplied by")
                },
                detail.config_max_dust_htlc_exposure_value
            ))),
        ]));
        output.push(Row::new(vec![""]));
        // Counterparty
        output.push(Row::new(vec![Cell::from(Text::from(
            WORD_BINDINGS.get("Counterparty"),
        ))
        .style(Style::default().bold())]));
        output.push(Row::new(vec![
            Cell::from(Text::from(WORD_BINDINGS.get("Node Id"))).style(Style::default().bold()),
            Cell::from(Text::from(detail.counterparty_node_id)),
        ]));
        output.push(Row::new(vec![
            Cell::from(Text::from(WORD_BINDINGS.get("Outbound HTLC Maximum")))
                .style(Style::default().bold()),
            Cell::from(Text::from(
                detail
                    .counterparty_outbound_htlc_maximum_msat
                    .map(|c| format!("{c} msats"))
                    .unwrap_or("none".into()),
            )),
        ]));
        output.push(Row::new(vec![
            Cell::from(Text::from(WORD_BINDINGS.get("Outbound HTLC Minimum")))
                .style(Style::default().bold()),
            Cell::from(Text::from(
                detail
                    .counterparty_outbound_htlc_minimum_msat
                    .map(|c| format!("{c} msats"))
                    .unwrap_or("none".into()),
            )),
        ]));
        output.push(Row::new(vec![
            Cell::from(Text::from(
                WORD_BINDINGS.get("Unspendable Punishment Reserve"),
            ))
            .style(Style::default().bold()),
            Cell::from(Text::from(format!(
                "{} sats",
                detail.counterparty_unspendable_punishment_reserve
            ))),
        ]));
        outputs.push(output);
    }
    Ok(outputs)
}

'''
'''--- tui/src/components/command/query.rs ---
use crate::ConnectionAuth;

pub fn get(auth: ConnectionAuth, uri: &'static str) -> String {
    let client = reqwest::blocking::ClientBuilder::new()
        .add_root_certificate(reqwest::Certificate::from_pem(&auth.pem).unwrap())
        .build()
        .unwrap();
    let request = client
        .get(auth.url.join(uri).expect("get should be correct").as_str())
        .header("Macaroon", auth.macaroon)
        .send();

    match request {
        Ok(response) => {
            let status = response.status();
            let data = response.text().unwrap();
            if status.is_success() {
                data.to_string()
            } else {
                format!("{}{}", status, data)
            }
        }
        Err(request_error) => request_error.to_string(),
    }
}

pub fn post(auth: ConnectionAuth, uri: &'static str, payload: String) -> String {
    let client = reqwest::blocking::ClientBuilder::new()
        .add_root_certificate(reqwest::Certificate::from_pem(&auth.pem).unwrap())
        .build()
        .unwrap();
    let request = client
        .post(auth.url.join(uri).expect("post should be correct").as_str())
        .header("Macaroon", auth.macaroon)
        .header("Content-Type", "application/json")
        .body(payload)
        .send();

    match request {
        Ok(response) => {
            let status = response.status();
            let data = response.text().unwrap();
            if status.is_success() {
                data.to_string()
            } else {
                format!("{}{}", status, data)
            }
        }
        Err(request_error) => request_error.to_string(),
    }
}

'''
'''--- tui/src/components/debug.rs ---
use std::time::Instant;

use color_eyre::eyre::Result;
use ratatui::{prelude::*, widgets::*};

use super::Component;
use crate::{action::Action, tui::Frame};

#[derive(Debug, Clone, PartialEq)]
pub struct DebugComponent {
    app_start_time: Instant,
    app_frames: u32,
    app_fps: f64,

    render_start_time: Instant,
    render_frames: u32,
    render_fps: f64,

    last_action: String,
}

impl Default for DebugComponent {
    fn default() -> Self {
        Self::new()
    }
}

impl DebugComponent {
    pub fn new() -> Self {
        Self {
            app_start_time: Instant::now(),
            app_frames: 0,
            app_fps: 0.0,
            render_start_time: Instant::now(),
            render_frames: 0,
            render_fps: 0.0,
            last_action: "Action Inspector".into(),
        }
    }

    fn app_tick(&mut self) -> Result<()> {
        self.app_frames += 1;
        let now = Instant::now();
        let elapsed = (now - self.app_start_time).as_secs_f64();
        if elapsed >= 1.0 {
            self.app_fps = self.app_frames as f64 / elapsed;
            self.app_start_time = now;
            self.app_frames = 0;
        }
        Ok(())
    }

    fn render_tick(&mut self) -> Result<()> {
        self.render_frames += 1;
        let now = Instant::now();
        let elapsed = (now - self.render_start_time).as_secs_f64();
        if elapsed >= 1.0 {
            self.render_fps = self.render_frames as f64 / elapsed;
            self.render_start_time = now;
            self.render_frames = 0;
        }
        Ok(())
    }
}

impl Component for DebugComponent {
    fn update(&mut self, action: Action) -> Result<Option<Action>> {
        self.last_action = format!("{action:}");
        if let Action::Tick = action {
            self.app_tick()?
        };
        if let Action::Render = action {
            self.render_tick()?
        };
        Ok(None)
    }

    fn draw(&mut self, f: &mut Frame<'_>, rect: Rect) -> Result<()> {
        let rects = Layout::default()
            .direction(Direction::Vertical)
            .constraints(vec![
                Constraint::Length(1),
                Constraint::Length(f.size().height - 2),
                Constraint::Length(1),
            ])
            .split(rect);

        let s = format!(
            "{:.2} ticks per sec (app) {:.2} frames per sec (render)",
            self.app_fps, self.render_fps
        );
        let block = Block::default().title(block::Title::from(s.dim()).alignment(Alignment::Right));
        f.render_widget(block, rects[0]);

        let logger = Block::default()
            .title(block::Title::from(self.last_action.clone().dim()).alignment(Alignment::Right));
        f.render_widget(logger, rects[2]);
        Ok(())
    }
}

'''
'''--- tui/src/components/history/details.rs ---
use color_eyre::eyre::Result;
use r2d2::Pool;
use r2d2_sqlite::SqliteConnectionManager;
use ratatui::{prelude::*, widgets::*};
use tokio::sync::mpsc::UnboundedSender;

use crate::action::Action;
use crate::components::{Component, Frame};
use crate::utils::WORD_BINDINGS;

pub struct HistoryDetails {
    command_tx: Option<UnboundedSender<Action>>,
    display: bool,
    input: String,
    output: String,
    pool: Pool<SqliteConnectionManager>,
}

impl HistoryDetails {
    pub fn new(pool: Pool<SqliteConnectionManager>) -> Self {
        Self {
            command_tx: None,
            display: false,
            input: String::new(),
            output: String::new(),
            pool,
        }
    }
}

impl Component for HistoryDetails {
    fn register_action_handler(&mut self, tx: UnboundedSender<Action>) -> Result<()> {
        self.command_tx = Some(tx);
        Ok(())
    }

    fn update(&mut self, action: Action) -> Result<Option<Action>> {
        match action {
            Action::Tab(t) => self.display = t == WORD_BINDINGS.get("History"),
            Action::History(ts) if let Ok(conn) = self.pool.get() => {
                let (input, output) = conn
                    .query_row(
                        "SELECT input, output FROM history WHERE timestamp == ?",
                        [ts.to_string()],
                        |row| {
                            Ok((
                                row.get::<usize, String>(0).unwrap_or_default(),
                                row.get::<usize, String>(1).unwrap_or_default(),
                            ))
                        },
                    )
                    .unwrap_or(("".into(), "fail to fetch command history from db".into()));
                self.input = input;
                self.output = output;
            }
            _ => {}
        }
        Ok(None)
    }

    fn draw(&mut self, f: &mut Frame<'_>, _area: Rect) -> Result<()> {
        if self.display {
            let mut size = f.size();
            // TabBar offset
            size.y += 3;
            size.height -= 3;
            // CmdList offset
            size.x += 45;
            size.width -= 45;
            let mut history = self.input.clone();
            history.push('\n');
            history += &self.output;
            let p = Paragraph::new(history).block(Block::default().borders(Borders::ALL));
            f.render_widget(p, size);
        }
        Ok(())
    }
}

'''
'''--- tui/src/components/history/list.rs ---
use color_eyre::eyre::{eyre, Result};
use r2d2::Pool;
use r2d2_sqlite::SqliteConnectionManager;
use ratatui::{prelude::*, widgets::*};
use tokio::sync::mpsc::UnboundedSender;

use crate::action::Action;
use crate::components::{Component, Frame};
use crate::utils::{ts_to_string, WORD_BINDINGS};

pub struct HistoryList {
    command_tx: Option<UnboundedSender<Action>>,
    display: bool,
    /// The index of items selected
    selected: Option<usize>,
    /// List item and parent
    items: Vec<(u64, String)>,
    pool: Pool<SqliteConnectionManager>,
}

impl HistoryList {
    pub fn new(pool: Pool<SqliteConnectionManager>) -> Self {
        Self {
            command_tx: None,
            display: false,
            selected: None,
            items: Vec::new(),
            pool,
        }
    }
}

struct SqlResult {
    timestamp: u64,
    command: String,
}

impl HistoryList {
    fn nav_up(&mut self) -> Result<Option<Action>> {
        while self.display && self.selected.is_some() {
            if self.selected == Some(0) {
                self.selected = Some(self.items.len() - 1);
            } else if let Some(idx) = self.selected {
                self.selected = Some(idx - 1);
            }
            if let Some(idx) = self.selected {
                return Ok(Some(Action::History(self.items[idx].0)));
            }
        }
        Ok(None)
    }

    fn nav_down(&mut self) -> Result<Option<Action>> {
        while self.display && self.selected.is_some() {
            if self.selected == Some(self.items.len() - 1) {
                self.selected = Some(0);
            } else if let Some(idx) = self.selected {
                self.selected = Some(idx + 1);
            }
            if let Some(idx) = self.selected {
                return Ok(Some(Action::History(self.items[idx].0)));
            }
        }
        Ok(None)
    }
    fn load_items(&self) -> Result<Vec<(u64, String)>> {
        if let Ok(conn) = self.pool.get() {
            let mut stmt =
                conn.prepare("SELECT timestamp, command FROM history ORDER BY timestamp DESC")?;
            let mut items = Vec::new();
            let rows = stmt.query_map([], |row| {
                Ok(SqlResult {
                    timestamp: row.get(0)?,
                    command: row.get(1)?,
                })
            })?;
            for sql_result in rows.flatten() {
                items.push((sql_result.timestamp, sql_result.command));
            }
            return Ok(items);
        }
        Err(eyre!("Fail to connect DB"))
    }

    fn switch_tab(&mut self, t: &'static str) -> Result<Option<Action>> {
        self.display = t == WORD_BINDINGS.get("History");
        if self.display {
            let mut retry = 0;
            while retry < 3 {
                if let Ok(items) = self.load_items() {
                    self.items = items;
                    if self.items.is_empty() {
                        self.selected = None;
                    } else {
                        self.selected = Some(0);
                    }
                    break;
                }
                retry += 1;
            }
        }
        if self.items.is_empty() {
            Ok(None)
        } else {
            Ok(Some(Action::History(self.items[0].0)))
        }
    }
}

impl Component for HistoryList {
    fn register_action_handler(&mut self, tx: UnboundedSender<Action>) -> Result<()> {
        self.command_tx = Some(tx);
        Ok(())
    }

    fn update(&mut self, action: Action) -> Result<Option<Action>> {
        match action {
            Action::Tab(t) => self.switch_tab(t),
            Action::NavUp => self.nav_up(),
            Action::NavDown => self.nav_down(),
            _ => Ok(None),
        }
    }

    fn draw(&mut self, f: &mut Frame<'_>, _area: Rect) -> Result<()> {
        if self.display {
            let mut size = f.size();
            size.y += 3;
            size.height -= 3;

            let block = Block::default();
            f.render_widget(block, size);
            let chunks = Layout::default()
                .direction(Direction::Horizontal)
                .constraints([Constraint::Length(45), Constraint::Min(0)])
                .split(size);

            let items: Vec<ListItem> = self
                .items
                .iter()
                .enumerate()
                .map(|(idx, i)| {
                    ListItem::new(format!(
                        "{} - {}",
                        ts_to_string(i.0),
                        WORD_BINDINGS.get(&i.1)
                    ))
                    .style(
                        Style::default()
                            .fg(if Some(idx) == self.selected {
                                Color::White
                            } else {
                                Color::Gray
                            })
                            .add_modifier(if Some(idx) == self.selected {
                                Modifier::BOLD
                            } else {
                                Modifier::DIM
                            }),
                    )
                })
                .collect();

            let items = List::new(items).block(Block::default().borders(Borders::ALL));

            f.render_widget(items, chunks[0]);
        }
        Ok(())
    }
}

'''
'''--- tui/src/components/history/mod.rs ---
pub mod details;
pub mod list;

'''
'''--- tui/src/components/mod.rs ---
use color_eyre::eyre::Result;
use crossterm::event::{KeyEvent, MouseEvent};
use ratatui::layout::Rect;
use tokio::sync::mpsc::UnboundedSender;

use crate::{
    action::Action,
    tui::{Event, Frame},
};

pub mod command;
pub mod debug;
pub mod history;
pub mod tab_bar;

/// `Component` is a trait that represents a visual and interactive element of the user interface.
/// Implementors of this trait can be registered with the main application loop and will be able to receive events,
/// update state, and be rendered on the screen.
pub trait Component {
    /// Register an action handler that can send actions for processing if necessary.
    ///
    /// # Arguments
    ///
    /// * `tx` - An unbounded sender that can send actions.
    ///
    /// # Returns
    ///
    /// * `Result<()>` - An Ok result or an error.
    #[allow(unused_variables)]
    fn register_action_handler(&mut self, tx: UnboundedSender<Action>) -> Result<()> {
        Ok(())
    }
    /// Initialize the component with a specified area if necessary.
    ///
    /// # Arguments
    ///
    /// * `area` - Rectangular area to initialize the component within.
    ///
    /// # Returns
    ///
    /// * `Result<()>` - An Ok result or an error.
    fn init(&mut self, _area: Rect) -> Result<()> {
        Ok(())
    }
    /// Handle incoming events and produce actions if necessary.
    ///
    /// # Arguments
    ///
    /// * `event` - An optional event to be processed.
    ///
    /// # Returns
    ///
    /// * `Result<Option<Action>>` - An action to be processed or none.
    fn handle_events(&mut self, event: Option<Event>) -> Result<Option<Action>> {
        let r = match event {
            Some(Event::Key(key_event)) => self.handle_key_events(key_event)?,
            Some(Event::Mouse(mouse_event)) => self.handle_mouse_events(mouse_event)?,
            _ => None,
        };
        Ok(r)
    }
    /// Handle key events and produce actions if necessary.
    ///
    /// # Arguments
    ///
    /// * `key` - A key event to be processed.
    ///
    /// # Returns
    ///
    /// * `Result<Option<Action>>` - An action to be processed or none.
    #[allow(unused_variables)]
    fn handle_key_events(&mut self, key: KeyEvent) -> Result<Option<Action>> {
        Ok(None)
    }
    /// Handle mouse events and produce actions if necessary.
    ///
    /// # Arguments
    ///
    /// * `mouse` - A mouse event to be processed.
    ///
    /// # Returns
    ///
    /// * `Result<Option<Action>>` - An action to be processed or none.
    #[allow(unused_variables)]
    fn handle_mouse_events(&mut self, mouse: MouseEvent) -> Result<Option<Action>> {
        Ok(None)
    }
    /// Update the state of the component based on a received action. (REQUIRED)
    ///
    /// # Arguments
    ///
    /// * `action` - An action that may modify the state of the component.
    ///
    /// # Returns
    ///
    /// * `Result<Option<Action>>` - An action to be processed or none.
    #[allow(unused_variables)]
    fn update(&mut self, action: Action) -> Result<Option<Action>> {
        Ok(None)
    }
    /// Render the component on the screen. (REQUIRED)
    ///
    /// # Arguments
    ///
    /// * `f` - A frame used for rendering.
    /// * `area` - The area in which the component should be drawn.
    ///
    /// # Returns
    ///
    /// * `Result<()>` - An Ok result or an error.
    fn draw(&mut self, f: &mut Frame<'_>, area: Rect) -> Result<()>;
}

'''
'''--- tui/src/components/tab_bar.rs ---
use color_eyre::eyre::Result;
use ratatui::{prelude::*, widgets::*};
use tokio::sync::mpsc::UnboundedSender;

use super::{Component, Frame};
use crate::action::Action;
use crate::utils::WORD_BINDINGS;

pub struct TabBar {
    command_tx: Option<UnboundedSender<Action>>,
    titles: [&'static str; 2],
    index: usize,
}

impl Default for TabBar {
    fn default() -> Self {
        Self {
            command_tx: None,
            titles: [
                WORD_BINDINGS.get("Command List"),
                WORD_BINDINGS.get("History"),
            ],
            index: 0,
        }
    }
}

impl TabBar {
    pub fn next(&mut self) {
        self.index = (self.index + 1) % self.titles.len();
    }
}

impl Component for TabBar {
    fn register_action_handler(&mut self, tx: UnboundedSender<Action>) -> Result<()> {
        self.command_tx = Some(tx);
        Ok(())
    }

    fn update(&mut self, action: Action) -> Result<Option<Action>> {
        let next_action = match action {
            Action::SwitchTab => {
                self.next();
                Some(Action::Tab(self.titles[self.index]))
            }
            _ => None,
        };
        Ok(next_action)
    }

    fn draw(&mut self, f: &mut Frame<'_>, _area: Rect) -> Result<()> {
        let size = f.size();
        let block = Block::default();
        f.render_widget(block, size);
        let chunks = Layout::default()
            .direction(Direction::Vertical)
            .constraints([Constraint::Length(3), Constraint::Min(0)])
            .split(size);

        let tabs = Tabs::new(self.titles.to_vec())
            .block(
                Block::default()
                    .borders(Borders::ALL)
                    .title(block::title::Title {
                        content: Line::styled(
                            "ðŸŒ”kuutamo Tui",
                            Style::default()
                                .bold()
                                .fg(Color::Rgb(110, 44, 247))
                                .bg(Color::White),
                        ),
                        ..Default::default()
                    })
                    .border_type(BorderType::Rounded),
            )
            .select(self.index)
            .highlight_style(
                Style::default()
                    .bold()
                    .add_modifier(style::Modifier::UNDERLINED),
            );
        f.render_widget(tabs, chunks[0]);
        Ok(())
    }
}

'''
'''--- tui/src/i18n.rs ---
use std::collections::HashMap;
use std::convert::AsRef;

use color_eyre::eyre::Result;
use derive_deref::{Deref, DerefMut};
use serde::{de::Deserializer, Deserialize, Serialize};

const DEFAULT_WORD_CONFIG: &str = include_str!("../assets/wordbinding.toml");

#[derive(Clone, Debug, Default, Deref, DerefMut)]
pub struct WordBindings(pub HashMap<Lang, HashMap<String, String>>);

#[derive(Debug, Default)]
pub struct SelectedWordBindings(pub HashMap<String, String>);

#[allow(non_camel_case_types)]
#[derive(Default, Debug, Copy, Clone, PartialEq, Eq, Hash, Serialize, Deserialize)]
pub enum Lang {
    #[default]
    en_US,
    zh_TW,
}

impl Lang {
    pub fn chose_from(lang: &str) -> Self {
        if let Some((locale, _encoding)) = lang.split_once('.') {
            log::debug!("detect locale:{locale:?}");
            match locale {
                "zh_TW" => Lang::zh_TW,
                _ => Self::default(),
            }
        } else {
            match lang {
                "zh_TW" => Lang::zh_TW,
                _ => Self::default(),
            }
        }
    }
}

impl SelectedWordBindings {
    pub fn init(lang: &str) -> SelectedWordBindings {
        let wordbindings: WordBindings = toml::from_str(DEFAULT_WORD_CONFIG).unwrap();

        let selected_wordbindings = wordbindings
            .get(&Lang::chose_from(lang))
            .map(|b| SelectedWordBindings(b.clone()))
            .unwrap_or_default();
        log::debug!("Select wordbindings:\n{selected_wordbindings:#?}");

        selected_wordbindings
    }

    pub fn get<'a>(&'a self, key: &'a str) -> &'a str {
        self.0.get(key).map(|v| v.as_ref()).unwrap_or(key)
    }
}

impl<'de> Deserialize<'de> for WordBindings {
    fn deserialize<D>(deserializer: D) -> Result<Self, D::Error>
    where
        D: Deserializer<'de>,
    {
        let parsed_map = HashMap::<Lang, HashMap<String, String>>::deserialize(deserializer)?;

        let word_bindings = parsed_map.into_iter().collect();

        Ok(WordBindings(word_bindings))
    }
}

'''
'''--- tui/src/keybinding.rs ---
use std::{collections::HashMap, path::PathBuf};

use color_eyre::eyre::Result;
use crossterm::event::{KeyCode, KeyEvent, KeyModifiers};
use derive_deref::{Deref, DerefMut};
use serde::{de::Deserializer, Deserialize};

use crate::{action::Action, mode::Mode};

const DEFAULT_KEY_CONFIG: &str = include_str!("../assets/keybinding.toml");

pub type KeyBindingHelps = HashMap<Mode, HashMap<Action, Vec<String>>>;

#[derive(Clone, Debug, Default, Deref, DerefMut)]
pub struct KeyBindings(pub HashMap<Mode, HashMap<Vec<KeyEvent>, Action>>);
impl KeyBindings {
    pub fn new(user_keybinding: Option<PathBuf>) -> Result<Self, config::ConfigError> {
        let mut keybindings: KeyBindings = toml::from_str(DEFAULT_KEY_CONFIG).unwrap();

        if let Some(user_keybinding) = user_keybinding
            && let Ok(content) = std::fs::read_to_string(user_keybinding)
        {
            let mut loaded_keybindings: KeyBindings = toml::from_str(&content).unwrap();
            log::trace!("Loaded keybindings:\n{loaded_keybindings:#?}");

            for (mode, bindings) in loaded_keybindings.iter_mut() {
                let user_bindings = keybindings.entry(*mode).or_default();
                for (key, cmd) in bindings.iter() {
                    user_bindings
                        .entry(key.clone())
                        .or_insert_with(|| cmd.clone());
                }
            }
        }

        log::debug!("Final keybindings:\n{keybindings:#?}");

        Ok(keybindings)
    }
    pub fn help_info(&self) -> KeyBindingHelps {
        let mut help = KeyBindingHelps::new();
        for (m, keybinding) in self.0.iter() {
            let mut mod_keybinding = HashMap::<Action, Vec<String>>::new();
            for (key_events, value) in keybinding {
                if let Some(key_list) = mod_keybinding.get_mut(value) {
                    key_list.push(key_events_to_string(key_events));
                } else {
                    mod_keybinding.insert(value.clone(), vec![key_events_to_string(key_events)]);
                }
            }
            help.insert(*m, mod_keybinding);
        }
        help
    }
}

fn key_events_to_string(key_events: &Vec<KeyEvent>) -> String {
    let mut out = String::new();
    for key_event in key_events {
        out.push('<');
        if !key_event.modifiers.is_empty() {
            for m in key_event.modifiers.iter_names() {
                out += m.0;
                out.push('+');
            }
        }
        out += &key_event_to_string(key_event);
        out.push('>');
    }
    out
}

impl<'de> Deserialize<'de> for KeyBindings {
    fn deserialize<D>(deserializer: D) -> Result<Self, D::Error>
    where
        D: Deserializer<'de>,
    {
        let parsed_map = HashMap::<Mode, HashMap<String, Action>>::deserialize(deserializer)?;

        let keybindings = parsed_map
            .into_iter()
            .map(|(mode, inner_map)| {
                let converted_inner_map = inner_map
                    .into_iter()
                    .map(|(key_str, cmd)| (parse_key_sequence(&key_str).unwrap(), cmd))
                    .collect();
                (mode, converted_inner_map)
            })
            .collect();

        Ok(KeyBindings(keybindings))
    }
}

fn parse_key_event(raw: &str) -> Result<KeyEvent, String> {
    let raw_lower = raw.to_ascii_lowercase();
    let (remaining, modifiers) = extract_modifiers(&raw_lower);
    parse_key_code_with_modifiers(remaining, modifiers)
}

fn extract_modifiers(raw: &str) -> (&str, KeyModifiers) {
    let mut modifiers = KeyModifiers::empty();
    let mut current = raw;

    loop {
        match current {
            rest if rest.starts_with("ctrl-") => {
                modifiers.insert(KeyModifiers::CONTROL);
                current = &rest[5..];
            }
            rest if rest.starts_with("alt-") => {
                modifiers.insert(KeyModifiers::ALT);
                current = &rest[4..];
            }
            rest if rest.starts_with("shift-") => {
                modifiers.insert(KeyModifiers::SHIFT);
                current = &rest[6..];
            }
            _ => break, // break out of the loop if no known prefix is detected
        };
    }

    (current, modifiers)
}

fn parse_key_code_with_modifiers(
    raw: &str,
    mut modifiers: KeyModifiers,
) -> Result<KeyEvent, String> {
    let c = match raw {
        "esc" => KeyCode::Esc,
        "enter" => KeyCode::Enter,
        "left" => KeyCode::Left,
        "right" => KeyCode::Right,
        "up" => KeyCode::Up,
        "down" => KeyCode::Down,
        "home" => KeyCode::Home,
        "end" => KeyCode::End,
        "pageup" => KeyCode::PageUp,
        "pagedown" => KeyCode::PageDown,
        "backtab" => {
            modifiers.insert(KeyModifiers::SHIFT);
            KeyCode::BackTab
        }
        "backspace" => KeyCode::Backspace,
        "delete" => KeyCode::Delete,
        "insert" => KeyCode::Insert,
        "f1" => KeyCode::F(1),
        "f2" => KeyCode::F(2),
        "f3" => KeyCode::F(3),
        "f4" => KeyCode::F(4),
        "f5" => KeyCode::F(5),
        "f6" => KeyCode::F(6),
        "f7" => KeyCode::F(7),
        "f8" => KeyCode::F(8),
        "f9" => KeyCode::F(9),
        "f10" => KeyCode::F(10),
        "f11" => KeyCode::F(11),
        "f12" => KeyCode::F(12),
        "space" => KeyCode::Char(' '),
        "hyphen" => KeyCode::Char('-'),
        "minus" => KeyCode::Char('-'),
        "tab" => KeyCode::Tab,
        c if c.len() == 1 => {
            let mut c = c.chars().next().unwrap();
            if modifiers.contains(KeyModifiers::SHIFT) {
                c = c.to_ascii_uppercase();
            }
            KeyCode::Char(c)
        }
        _ => return Err(format!("Unable to parse {raw}")),
    };
    Ok(KeyEvent::new(c, modifiers))
}

pub fn key_event_to_string(key_event: &KeyEvent) -> String {
    let char;
    let key_code = match key_event.code {
        KeyCode::Backspace => "backspace",
        KeyCode::Enter => "enter",
        KeyCode::Left => "left",
        KeyCode::Right => "right",
        KeyCode::Up => "up",
        KeyCode::Down => "down",
        KeyCode::Home => "home",
        KeyCode::End => "end",
        KeyCode::PageUp => "pageup",
        KeyCode::PageDown => "pagedown",
        KeyCode::Tab => "tab",
        KeyCode::BackTab => "backtab",
        KeyCode::Delete => "delete",
        KeyCode::Insert => "insert",
        KeyCode::F(c) => {
            char = format!("f({c})");
            &char
        }
        KeyCode::Char(' ') => "space",
        KeyCode::Char(c) => {
            char = c.to_string();
            &char
        }
        KeyCode::Esc => "esc",
        KeyCode::Null => "",
        KeyCode::CapsLock => "",
        KeyCode::Menu => "",
        KeyCode::ScrollLock => "",
        KeyCode::Media(_) => "",
        KeyCode::NumLock => "",
        KeyCode::PrintScreen => "",
        KeyCode::Pause => "",
        KeyCode::KeypadBegin => "",
        KeyCode::Modifier(_) => "",
    };

    let mut modifiers = Vec::with_capacity(3);

    if key_event.modifiers.intersects(KeyModifiers::CONTROL) {
        modifiers.push("ctrl");
    }

    if key_event.modifiers.intersects(KeyModifiers::SHIFT) {
        modifiers.push("shift");
    }

    if key_event.modifiers.intersects(KeyModifiers::ALT) {
        modifiers.push("alt");
    }

    let mut key = modifiers.join("-");

    if !key.is_empty() {
        key.push('-');
    }
    key.push_str(key_code);

    key
}

pub fn parse_key_sequence(raw: &str) -> Result<Vec<KeyEvent>, String> {
    if raw.chars().filter(|c| *c == '>').count() != raw.chars().filter(|c| *c == '<').count() {
        return Err(format!("Unable to parse `{}`", raw));
    }
    let raw = if !raw.contains("><") {
        let raw = raw.strip_prefix('<').unwrap_or(raw);
        let raw = raw.strip_prefix('>').unwrap_or(raw);
        raw
    } else {
        raw
    };
    let sequences = raw
        .split("><")
        .map(|seq| {
            if let Some(s) = seq.strip_prefix('<') {
                s
            } else if let Some(s) = seq.strip_suffix('>') {
                s
            } else {
                seq
            }
        })
        .collect::<Vec<_>>();

    sequences.into_iter().map(parse_key_event).collect()
}
#[cfg(test)]
mod tests {
    use pretty_assertions::assert_eq;

    use super::*;

    #[test]
    fn test_config() -> Result<()> {
        let c = KeyBindings::new(None)?;
        assert_eq!(
            c.get(&Mode::Navigate)
                .and_then(|kb| kb.get(&parse_key_sequence("<esc>").unwrap_or_default())),
            Some(&Action::Quit)
        );
        Ok(())
    }

    #[test]
    fn test_simple_keys() {
        assert_eq!(
            parse_key_event("a").unwrap(),
            KeyEvent::new(KeyCode::Char('a'), KeyModifiers::empty())
        );

        assert_eq!(
            parse_key_event("enter").unwrap(),
            KeyEvent::new(KeyCode::Enter, KeyModifiers::empty())
        );

        assert_eq!(
            parse_key_event("esc").unwrap(),
            KeyEvent::new(KeyCode::Esc, KeyModifiers::empty())
        );
    }

    #[test]
    fn test_with_modifiers() {
        assert_eq!(
            parse_key_event("ctrl-a").unwrap(),
            KeyEvent::new(KeyCode::Char('a'), KeyModifiers::CONTROL)
        );

        assert_eq!(
            parse_key_event("alt-enter").unwrap(),
            KeyEvent::new(KeyCode::Enter, KeyModifiers::ALT)
        );

        assert_eq!(
            parse_key_event("shift-esc").unwrap(),
            KeyEvent::new(KeyCode::Esc, KeyModifiers::SHIFT)
        );
    }

    #[test]
    fn test_multiple_modifiers() {
        assert_eq!(
            parse_key_event("ctrl-alt-a").unwrap(),
            KeyEvent::new(
                KeyCode::Char('a'),
                KeyModifiers::CONTROL | KeyModifiers::ALT
            )
        );

        assert_eq!(
            parse_key_event("ctrl-shift-enter").unwrap(),
            KeyEvent::new(KeyCode::Enter, KeyModifiers::CONTROL | KeyModifiers::SHIFT)
        );
    }

    #[test]
    fn test_reverse_multiple_modifiers() {
        assert_eq!(
            key_event_to_string(&KeyEvent::new(
                KeyCode::Char('a'),
                KeyModifiers::CONTROL | KeyModifiers::ALT
            )),
            "ctrl-alt-a".to_string()
        );
    }

    #[test]
    fn test_invalid_keys() {
        assert!(parse_key_event("invalid-key").is_err());
        assert!(parse_key_event("ctrl-invalid-key").is_err());
    }

    #[test]
    fn test_case_insensitivity() {
        assert_eq!(
            parse_key_event("CTRL-a").unwrap(),
            KeyEvent::new(KeyCode::Char('a'), KeyModifiers::CONTROL)
        );

        assert_eq!(
            parse_key_event("AlT-eNtEr").unwrap(),
            KeyEvent::new(KeyCode::Enter, KeyModifiers::ALT)
        );
    }
}

'''
'''--- tui/src/lib.rs ---
#![feature(let_chains)]
#![feature(if_let_guard)]

use color_eyre::eyre::Result;
use r2d2::Pool;
use r2d2_sqlite::SqliteConnectionManager;
use std::path::PathBuf;

mod action;
mod app;
mod components;
mod i18n;
mod keybinding;
mod mode;
mod tui;
mod utils;

#[cfg(test)]
mod tests;

use app::{App, ConnectionAuth};

pub struct Config {
    pub tick_rate: f64,
    pub frame_rate: f64,
    pub debug: bool,
    pub log_enable: bool,
    pub log_file: Option<PathBuf>,
    pub log_level: Option<String>,
    pub pool: Pool<SqliteConnectionManager>,
    pub keybindings: Option<PathBuf>,
    pub node_url: url::Url,
    pub secrets: PathBuf,
}

pub async fn app(config: Config) -> Result<()> {
    utils::initialize_logging(
        config.log_file.or(if config.log_enable {
            Some(PathBuf::from(format!("{}.log", env!("CARGO_CRATE_NAME"))))
        } else {
            None
        }),
        config.log_level,
    )?;

    utils::initialize_panic_handler()?;

    let mut app = App::new(
        config.keybindings,
        config.debug,
        config.pool,
        ConnectionAuth::new(config.secrets, config.node_url)?,
    )?;
    app.run(config.tick_rate, config.frame_rate).await?;

    Ok(())
}

'''
'''--- tui/src/main.rs ---
use clap::Parser;
use color_eyre::eyre::Result;
use r2d2_sqlite::SqliteConnectionManager;
use std::path::PathBuf;

#[derive(Parser)]
#[command(author, version, about, long_about = None)]
struct Cli {
    /// Tick rate, i.e. number of ticks per second
    #[clap(short, long, value_name = "FLOAT", default_value_t = 4.0)]
    pub tick_rate: f64,

    /// Frame rate, i.e. number of frames per second
    #[clap(short, long, value_name = "FLOAT", default_value_t = 4.0)]
    pub frame_rate: f64,

    /// Enable debug components in tui
    #[clap(short, long, env = "DEBUG")]
    pub debug: bool,

    /// Enable log
    #[clap(short, long, env = "LOG")]
    pub log: bool,

    /// Setup log file
    #[clap(long, env = "LOG_FILE")]
    pub log_file: Option<PathBuf>,

    /// Enable log
    #[clap(long, env = "LOG_LEVEL")]
    pub log_level: Option<String>,

    /// Setup data folder or the sqllite file to store the command history
    /// If not no folder specified, it will stoe on memory for using the app
    #[clap(long, env = "DATA")]
    pub data: Option<PathBuf>,

    /// The key binding overwrite config, if unset will try `keybinding.toml`
    #[clap(short, long, default_value = "keybinding.toml")]
    pub key_binding_file: PathBuf,

    /// The secrets folder provided after node installed by kld-mgr
    #[clap(short, long, default_value = "secrets", env = "SECRETS")]
    pub secrets: PathBuf,

    /// The url endpoint to the kld node
    #[clap(
        short,
        long,
        default_value = "https://localhost:2244",
        env = "NODE_URL"
    )]
    pub node_url: url::Url,
}

#[tokio::main]
async fn main() -> Result<()> {
    let cli = Cli::parse();
    let manager = if let Some(data) = cli.data {
        log::info!("Use database at {}", data.display());
        if data.is_dir() {
            SqliteConnectionManager::file(data.join("lightning-tui.db"))
        } else {
            SqliteConnectionManager::file(data)
        }
    } else {
        log::info!("In memory database");
        SqliteConnectionManager::memory()
    };
    let pool = r2d2::Pool::new(manager).expect("Fail to init db connection pool");
    let conn = pool.get().expect("Fail to connect db");
    if conn.execute("CREATE TABLE IF NOT EXISTS history (timestamp INTEGER, command TEXT, input TEXT, output TEXT);", []).is_ok() {
        log::info!("Init database");
    }

    let config = kld_tui::Config {
        tick_rate: cli.tick_rate,
        frame_rate: cli.frame_rate,
        debug: cli.debug,
        log_enable: cli.log_file.is_some() || cli.log_level.is_some() || cli.log,
        log_file: cli.log_file,
        log_level: cli.log_level,
        pool,
        keybindings: Some(cli.key_binding_file),
        node_url: cli.node_url,
        secrets: cli.secrets,
    };
    if let Err(e) = kld_tui::app(config).await {
        Err(e)
    } else {
        Ok(())
    }
}

'''
'''--- tui/src/mod.rs ---
use color_eyre::eyre::Result;
use std::path::PathBuf;

mod action;
mod app;
mod components;
mod keybinding;
mod mode;
mod style;
mod tui;
mod utils;

use app::App;

pub struct Config {
    pub tick_rate: f64,
    pub frame_rate: f64,
    pub log_enable: bool,
    pub log_file: Option<PathBuf>,
    pub log_level: Option<String>,
    pub data_dir: Option<PathBuf>,
    pub keybindings: Option<PathBuf>,
    pub secrets: PathBuf,
    pub node_url: url::Url,
}

pub async fn app(config: Config) -> Result<()> {
    utils::initialize_logging(
        config.log_file.or(if config.log_enable {
            Some(PathBuf::from(format!("{}.log", env!("CARGO_CRATE_NAME"))))
        } else {
            None
        }),
        config.log_level,
    )?;

    utils::initialize_panic_handler()?;

    let mut app = App::new(config.keybindings, config.connection)?;
    app.run(config.tick_rate, config.frame_rate).await?;

    Ok(())
}

'''
'''--- tui/src/mode.rs ---
use serde::{Deserialize, Serialize};

#[derive(Default, Debug, Copy, Clone, PartialEq, Eq, Hash, Serialize, Deserialize)]
pub enum Mode {
    #[default]
    Navigate,
    Command,
}

'''
'''--- tui/src/style.rs ---
use std::{collections::HashMap, path::PathBuf};

use color_eyre::eyre::Result;
use crossterm::event::{KeyCode, KeyEvent, KeyModifiers};
use derive_deref::{Deref, DerefMut};
use ratatui::style::{Color, Modifier, Style};
use serde::{de::Deserializer, Deserialize};

use crate::{action::Action, mode::Mode};

#[derive(Clone, Debug, Default, Deref, DerefMut)]
pub struct Styles(pub HashMap<Mode, HashMap<String, Style>>);

impl<'de> Deserialize<'de> for Styles {
    fn deserialize<D>(deserializer: D) -> Result<Self, D::Error>
    where
        D: Deserializer<'de>,
    {
        let parsed_map = HashMap::<Mode, HashMap<String, String>>::deserialize(deserializer)?;

        let styles = parsed_map
            .into_iter()
            .map(|(mode, inner_map)| {
                let converted_inner_map = inner_map
                    .into_iter()
                    .map(|(str, style)| (str, parse_style(&style)))
                    .collect();
                (mode, converted_inner_map)
            })
            .collect();

        Ok(Styles(styles))
    }
}

pub fn parse_style(line: &str) -> Style {
    let (foreground, background) =
        line.split_at(line.to_lowercase().find("on ").unwrap_or(line.len()));
    let foreground = process_color_string(foreground);
    let background = process_color_string(&background.replace("on ", ""));

    let mut style = Style::default();
    if let Some(fg) = parse_color(&foreground.0) {
        style = style.fg(fg);
    }
    if let Some(bg) = parse_color(&background.0) {
        style = style.bg(bg);
    }
    style = style.add_modifier(foreground.1 | background.1);
    style
}

fn process_color_string(color_str: &str) -> (String, Modifier) {
    let color = color_str
        .replace("grey", "gray")
        .replace("bright ", "")
        .replace("bold ", "")
        .replace("underline ", "")
        .replace("inverse ", "");

    let mut modifiers = Modifier::empty();
    if color_str.contains("underline") {
        modifiers |= Modifier::UNDERLINED;
    }
    if color_str.contains("bold") {
        modifiers |= Modifier::BOLD;
    }
    if color_str.contains("inverse") {
        modifiers |= Modifier::REVERSED;
    }

    (color, modifiers)
}

fn parse_color(s: &str) -> Option<Color> {
    let s = s.trim_start();
    let s = s.trim_end();
    if s.contains("bright color") {
        let s = s.trim_start_matches("bright ");
        let c = s
            .trim_start_matches("color")
            .parse::<u8>()
            .unwrap_or_default();
        Some(Color::Indexed(c.wrapping_shl(8)))
    } else if s.contains("color") {
        let c = s
            .trim_start_matches("color")
            .parse::<u8>()
            .unwrap_or_default();
        Some(Color::Indexed(c))
    } else if s.contains("gray") {
        let c = 232
            + s.trim_start_matches("gray")
                .parse::<u8>()
                .unwrap_or_default();
        Some(Color::Indexed(c))
    } else if s.contains("rgb") {
        let red = (s.as_bytes()[3] as char).to_digit(10).unwrap_or_default() as u8;
        let green = (s.as_bytes()[4] as char).to_digit(10).unwrap_or_default() as u8;
        let blue = (s.as_bytes()[5] as char).to_digit(10).unwrap_or_default() as u8;
        let c = 16 + red * 36 + green * 6 + blue;
        Some(Color::Indexed(c))
    } else if s == "bold black" {
        Some(Color::Indexed(8))
    } else if s == "bold red" {
        Some(Color::Indexed(9))
    } else if s == "bold green" {
        Some(Color::Indexed(10))
    } else if s == "bold yellow" {
        Some(Color::Indexed(11))
    } else if s == "bold blue" {
        Some(Color::Indexed(12))
    } else if s == "bold magenta" {
        Some(Color::Indexed(13))
    } else if s == "bold cyan" {
        Some(Color::Indexed(14))
    } else if s == "bold white" {
        Some(Color::Indexed(15))
    } else if s == "black" {
        Some(Color::Indexed(0))
    } else if s == "red" {
        Some(Color::Indexed(1))
    } else if s == "green" {
        Some(Color::Indexed(2))
    } else if s == "yellow" {
        Some(Color::Indexed(3))
    } else if s == "blue" {
        Some(Color::Indexed(4))
    } else if s == "magenta" {
        Some(Color::Indexed(5))
    } else if s == "cyan" {
        Some(Color::Indexed(6))
    } else if s == "white" {
        Some(Color::Indexed(7))
    } else {
        None
    }
}

#[cfg(test)]
mod tests {
    use pretty_assertions::assert_eq;

    use super::*;

    #[test]
    fn test_parse_style_default() {
        let style = parse_style("");
        assert_eq!(style, Style::default());
    }

    #[test]
    fn test_parse_style_foreground() {
        let style = parse_style("red");
        assert_eq!(style.fg, Some(Color::Indexed(1)));
    }

    #[test]
    fn test_parse_style_background() {
        let style = parse_style("on blue");
        assert_eq!(style.bg, Some(Color::Indexed(4)));
    }

    #[test]
    fn test_parse_style_modifiers() {
        let style = parse_style("underline red on blue");
        assert_eq!(style.fg, Some(Color::Indexed(1)));
        assert_eq!(style.bg, Some(Color::Indexed(4)));
    }

    #[test]
    fn test_process_color_string() {
        let (color, modifiers) = process_color_string("underline bold inverse gray");
        assert_eq!(color, "gray");
        assert!(modifiers.contains(Modifier::UNDERLINED));
        assert!(modifiers.contains(Modifier::BOLD));
        assert!(modifiers.contains(Modifier::REVERSED));
    }

    #[test]
    fn test_parse_color_rgb() {
        let color = parse_color("rgb123");
        let expected = 16 + 1 * 36 + 2 * 6 + 3;
        assert_eq!(color, Some(Color::Indexed(expected)));
    }

    #[test]
    fn test_parse_color_unknown() {
        let color = parse_color("unknown");
        assert_eq!(color, None);
    }
}

'''
'''--- tui/src/tests/channel_details.rs ---
use crate::components::command::parsers::parse_channel_details;

#[test]
fn test_parse_channel_details() {
    let response = r#"[
  {
    "balance_msat": 1000000000,
    "channel_id": "11a8ad563470580fedcb6c59fbcfcc9a0593d8da3b01e08a87ce3e84a80e8737",
    "channel_shutdown_state": "NotShuttingDown",
    "channel_value_satoshis": 1000000,
    "closure_reason": "Channel closed because the ChannelManager read from disk was stale compared to ChannelMonitor(s)",
    "config_accept_underpaying_htlcs": false,
    "config_cltv_expiry_delta": 72,
    "config_force_close_avoidance_max_fee_satoshis": 1000,
    "config_forwarding_fee_base_msat": 1000,
    "config_forwarding_fee_proportional_millionths": 0,
    "config_max_dust_htlc_exposure_is_fixed": false,
    "config_max_dust_htlc_exposure_value": 5000,
    "confirmations": 4,
    "confirmations_required": 3,
    "counterparty_node_id": "03864ef025fde8fb587d989186ce6a4a186895ee44a926bfc370e2c366597a3f8f",
    "counterparty_outbound_htlc_maximum_msat": 450000000,
    "counterparty_outbound_htlc_minimum_msat": 1,
    "counterparty_unspendable_punishment_reserve": 10000,
    "features": [
      "required StaticRemoteKey"
    ],
    "feerate_sat_per_1000_weight": 40808,
    "force_close_spend_delay": 720,
    "funding_txo": "37870ea8843ece878ae0013bdad893059acccffb596ccbed0f58703456ada811:0",
    "has_monitor": false,
    "inbound_capacity_msat": 0,
    "inbound_htlc_maximum_msat": 980000000,
    "inbound_htlc_minimum_msat": 1,
    "inbound_scid_alias": 25531354448569286,
    "is_channel_ready": true,
    "is_outbound": true,
    "is_public": true,
    "is_usable": false,
    "next_outbound_htlc_limit_msat": 450000000,
    "next_outbound_htlc_minimum_msat": 1,
    "open_timestamp": 1702623814,
    "outbound_capacity_msat": 990000000,
    "outbound_scid_alias": 872848405330001923,
    "short_channel_id": 902984919605837824,
    "unspendable_punishment_reserve": 10000,
    "update_timestamp": 1702892393,
    "user_channel_id": 2631310026696697131
  }
]"#;
    let rows = parse_channel_details(response).expect("parse channel details should work");
    assert_eq!(rows.len(), 1);
}

'''
'''--- tui/src/tests/mod.rs ---
mod channel_details;

'''
'''--- tui/src/tui.rs ---
use std::{
    ops::{Deref, DerefMut},
    time::Duration,
};

use color_eyre::eyre::Result;
use crossterm::{
    cursor,
    event::{
        DisableBracketedPaste, DisableMouseCapture, EnableBracketedPaste, EnableMouseCapture,
        Event as CrosstermEvent, KeyEvent, KeyEventKind, MouseEvent,
    },
    terminal::{EnterAlternateScreen, LeaveAlternateScreen},
};
use futures::{FutureExt, StreamExt};
use ratatui::backend::CrosstermBackend as Backend;
use serde::{Deserialize, Serialize};
use tokio::{
    sync::mpsc::{self, UnboundedReceiver, UnboundedSender},
    task::JoinHandle,
};
use tokio_util::sync::CancellationToken;

pub type IO = std::io::Stdout;
pub fn io() -> IO {
    std::io::stdout()
}
pub type Frame<'a> = ratatui::Frame<'a>;

#[derive(Clone, Debug, Serialize, Deserialize)]
pub enum Event {
    Init,
    Quit,
    Error,
    Closed,
    Tick,
    Render,
    FocusGained,
    FocusLost,
    Paste(String),
    Key(KeyEvent),
    Mouse(MouseEvent),
    Resize(u16, u16),
}

pub struct Tui {
    pub terminal: ratatui::Terminal<Backend<IO>>,
    pub task: JoinHandle<()>,
    pub cancellation_token: CancellationToken,
    pub event_rx: UnboundedReceiver<Event>,
    pub event_tx: UnboundedSender<Event>,
    pub frame_rate: f64,
    pub tick_rate: f64,
    pub mouse: bool,
    pub paste: bool,
}

impl Tui {
    pub fn new(tick_rate: Option<f64>, frame_rate: Option<f64>) -> Result<Self> {
        let terminal = ratatui::Terminal::new(Backend::new(io()))?;
        let (event_tx, event_rx) = mpsc::unbounded_channel();
        let cancellation_token = CancellationToken::new();
        let task = tokio::spawn(async {});
        let mouse = false;
        let paste = false;
        Ok(Self {
            terminal,
            task,
            cancellation_token,
            event_rx,
            event_tx,
            frame_rate: tick_rate.unwrap_or(4.0),
            tick_rate: frame_rate.unwrap_or(60.0),
            mouse,
            paste,
        })
    }
    pub fn start(&mut self) {
        let tick_delay = std::time::Duration::from_secs_f64(1.0 / self.tick_rate);
        let render_delay = std::time::Duration::from_secs_f64(1.0 / self.frame_rate);
        self.cancel();
        self.cancellation_token = CancellationToken::new();
        let _cancellation_token = self.cancellation_token.clone();
        let _event_tx = self.event_tx.clone();
        self.task = tokio::spawn(async move {
            let mut reader = crossterm::event::EventStream::new();
            let mut tick_interval = tokio::time::interval(tick_delay);
            let mut render_interval = tokio::time::interval(render_delay);
            _event_tx.send(Event::Init).unwrap();
            loop {
                let tick_delay = tick_interval.tick();
                let render_delay = render_interval.tick();
                let crossterm_event = reader.next().fuse();
                tokio::select! {
                  _ = _cancellation_token.cancelled() => {
                    break;
                  }
                  maybe_event = crossterm_event => {
                    match maybe_event {
                      Some(Ok(evt)) => {
                        match evt {
                          CrosstermEvent::Key(key) => {
                            if key.kind == KeyEventKind::Press {
                              _event_tx.send(Event::Key(key)).unwrap();
                            }
                          },
                          CrosstermEvent::Mouse(mouse) => {
                            _event_tx.send(Event::Mouse(mouse)).unwrap();
                          },
                          CrosstermEvent::Resize(x, y) => {
                            _event_tx.send(Event::Resize(x, y)).unwrap();
                          },
                          CrosstermEvent::FocusLost => {
                            _event_tx.send(Event::FocusLost).unwrap();
                          },
                          CrosstermEvent::FocusGained => {
                            _event_tx.send(Event::FocusGained).unwrap();
                          },
                          CrosstermEvent::Paste(s) => {
                            _event_tx.send(Event::Paste(s)).unwrap();
                          },
                        }
                      }
                      Some(Err(_)) => {
                        _event_tx.send(Event::Error).unwrap();
                      }
                      None => {},
                    }
                  },
                  _ = tick_delay => {
                      _event_tx.send(Event::Tick).unwrap();
                  },
                  _ = render_delay => {
                      _event_tx.send(Event::Render).unwrap();
                  },
                }
            }
        });
    }

    pub fn stop(&self) -> Result<()> {
        self.cancel();
        let mut counter = 0;
        while !self.task.is_finished() {
            std::thread::sleep(Duration::from_millis(1));
            counter += 1;
            if counter > 50 {
                self.task.abort();
            }
            if counter > 100 {
                log::error!("Failed to abort task in 100 milliseconds for unknown reason");
                break;
            }
        }
        Ok(())
    }

    pub fn enter(&mut self) -> Result<()> {
        crossterm::terminal::enable_raw_mode()?;
        crossterm::execute!(io(), EnterAlternateScreen, cursor::Hide)?;
        if self.mouse {
            crossterm::execute!(io(), EnableMouseCapture)?;
        }
        if self.paste {
            crossterm::execute!(io(), EnableBracketedPaste)?;
        }
        self.start();
        Ok(())
    }

    pub fn exit(&mut self) -> Result<()> {
        self.stop()?;
        if crossterm::terminal::is_raw_mode_enabled()? {
            self.flush()?;
            if self.paste {
                crossterm::execute!(io(), DisableBracketedPaste)?;
            }
            if self.mouse {
                crossterm::execute!(io(), DisableMouseCapture)?;
            }
            crossterm::execute!(io(), LeaveAlternateScreen, cursor::Show)?;
            crossterm::terminal::disable_raw_mode()?;
        }
        Ok(())
    }

    pub fn cancel(&self) {
        self.cancellation_token.cancel();
    }

    pub fn suspend(&mut self) -> Result<()> {
        self.exit()?;
        #[cfg(not(windows))]
        signal_hook::low_level::raise(signal_hook::consts::signal::SIGTSTP)?;
        Ok(())
    }

    pub async fn next(&mut self) -> Option<Event> {
        self.event_rx.recv().await
    }
}

impl Deref for Tui {
    type Target = ratatui::Terminal<Backend<IO>>;

    fn deref(&self) -> &Self::Target {
        &self.terminal
    }
}

impl DerefMut for Tui {
    fn deref_mut(&mut self) -> &mut Self::Target {
        &mut self.terminal
    }
}

impl Drop for Tui {
    fn drop(&mut self) {
        self.exit().unwrap();
    }
}

'''
'''--- tui/src/utils.rs ---
use std::path::PathBuf;

use crate::i18n::SelectedWordBindings;
use chrono::prelude::DateTime;
use chrono::Utc;
use color_eyre::eyre::Result;
use lazy_static::lazy_static;
use tracing::error;
use tracing_error::ErrorLayer;
use tracing_subscriber::{
    self, prelude::__tracing_subscriber_SubscriberExt, util::SubscriberInitExt, Layer,
};

lazy_static! {
    pub static ref WORD_BINDINGS: SelectedWordBindings = std::env::var("LANG")
        .ok()
        .as_deref()
        .map(SelectedWordBindings::init)
        .unwrap_or_default();
}

pub fn ts_to_string(timestamp: u64) -> String {
    let dt: DateTime<Utc> =
        DateTime::<Utc>::from_timestamp(timestamp as i64, 0).expect("invalid timestamp");
    dt.to_string()
}

pub fn initialize_panic_handler() -> Result<()> {
    let (panic_hook, eyre_hook) = color_eyre::config::HookBuilder::default()
        .panic_section(format!(
            "This is a bug. Consider reporting it at {}",
            env!("CARGO_PKG_REPOSITORY")
        ))
        .capture_span_trace_by_default(false)
        .display_location_section(false)
        .display_env_section(false)
        .into_hooks();
    eyre_hook.install()?;
    std::panic::set_hook(Box::new(move |panic_info| {
        if let Ok(mut t) = crate::tui::Tui::new(None, None) {
            if let Err(r) = t.exit() {
                error!("Unable to exit Terminal: {:?}", r);
            }
        }

        #[cfg(not(debug_assertions))]
        {
            use human_panic::{handle_dump, print_msg, Metadata};
            let meta = Metadata {
                version: env!("CARGO_PKG_VERSION").into(),
                name: env!("CARGO_PKG_NAME").into(),
                authors: env!("CARGO_PKG_AUTHORS").replace(':', ", ").into(),
                homepage: env!("CARGO_PKG_HOMEPAGE").into(),
            };

            let file_path = handle_dump(&meta, panic_info);
            // prints human-panic message
            print_msg(file_path, &meta)
                .expect("human-panic: printing error message to console failed");
            eprintln!("{}", panic_hook.panic_report(panic_info)); // prints color-eyre stack trace to stderr
        }
        let msg = format!("{}", panic_hook.panic_report(panic_info));
        log::error!("Error: {}", strip_ansi_escapes::strip_str(msg));

        std::process::exit(libc::EXIT_FAILURE);
    }));
    Ok(())
}

pub fn initialize_logging(log_file: Option<PathBuf>, log_level: Option<String>) -> Result<()> {
    if let Some(log_file) = log_file {
        if let Some(parent) = log_file.parent()
            && parent != std::path::Path::new("")
        {
            std::fs::create_dir_all(parent)?;
        }
        let log_file = std::fs::File::create(&log_file)?;
        std::env::set_var(
            "RUST_LOG",
            format!(
                "{}={}",
                env!("CARGO_CRATE_NAME"),
                log_level.unwrap_or("info".into())
            ),
        );
        let file_subscriber = tracing_subscriber::fmt::layer()
            .with_file(true)
            .with_line_number(true)
            .with_writer(log_file)
            .with_target(false)
            .with_ansi(false)
            .with_filter(tracing_subscriber::filter::EnvFilter::from_default_env());
        tracing_subscriber::registry()
            .with(file_subscriber)
            .with(ErrorLayer::default())
            .init();
    }
    Ok(())
}

/// Similar to the `std::dbg!` macro, but generates `tracing` events rather
/// than printing to stdout.
///
/// By default, the verbosity level for the generated events is `DEBUG`, but
/// this can be customized.
#[macro_export]
macro_rules! trace_dbg {
    (target: $target:expr, level: $level:expr, $ex:expr) => {{
        match $ex {
            value => {
                tracing::event!(target: $target, $level, ?value, stringify!($ex));
                value
            }
        }
    }};
    (level: $level:expr, $ex:expr) => {
        trace_dbg!(target: module_path!(), level: $level, $ex)
    };
    (target: $target:expr, $ex:expr) => {
        trace_dbg!(target: $target, level: tracing::Level::DEBUG, $ex)
    };
    ($ex:expr) => {
        trace_dbg!(level: tracing::Level::DEBUG, $ex)
    };
}

'''
'''--- typos.toml ---
[default.extend-words]
lightning  = "lightning"
inh = "inh"
ratatui = "ratatui"
Clos = "Clos"

[files]
extend-exclude = [ "*.csr" ]

'''