*GitHub Repository "near/mpc-recovery"*

'''--- .github/ISSUE_TEMPLATE/epic-template.md ---
---
name: Epic Template
about: Describe this issue template's purpose here.
title: "\U0001F537 [Epic"
labels: Emerging Tech, Epic, Near BOS
assignees: ''

---

### Description

(Overview of milestone or function governed by this epic)

### Resources

(Relevant documentation, Figma links, and other reference material)

Item 1

Item 2

Item 3

```[tasklist]
### Related Issues
```

'''
'''--- .github/ISSUE_TEMPLATE/issue-template.md ---
---
name: Issue Template
about: Regular Issues like defect or task.
title: ''
labels: Emerging Tech, Near BOS
assignees: ''

---

### Description

(Summary of task, purpose, impact)

### Optional: User Story

(As a [user], I need [function, outcome, enhancement] that [provides value].)

'''
'''--- .github/workflows/deploy-multichain-dev-contract.yml ---
name: Deploy Dev Smart Contract
on:
  pull_request:
    types: [closed]
    branches:
      - develop

jobs:
  deploy-contract:
    if: github.event.pull_request.merged == true
    runs-on: ubuntu-latest
    steps:
      - name: add JSON contract
        run: mkdir -p ~/.near-credentials/testnet && echo '${{ secrets.DEV_CONTRACT_JSON }}' > ~/.near-credentials/testnet/v5.multichain-mpc-dev.testnet.json

      - uses: actions/checkout@v4
      - name: Use Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 'latest'

      - name: Install near-cli
        run: 'npm install -g near-cli'

      - name: Install Rust
        run: "curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh -s -- -y"

      - name: debug
        run: cat ~/.near-credentials/testnet/v5.multichain-mpc-dev.testnet.json

      - name: Cargo Build
        run: |
          source $HOME/.cargo/env && cd ./contract ; rustup target add wasm32-unknown-unknown && cargo build --target wasm32-unknown-unknown --release && \
          cd .. && (yes || true) | near deploy v5.multichain-mpc-dev.testnet target/wasm32-unknown-unknown/release/mpc_contract.wasm
'''
'''--- .github/workflows/deploy-prod.yml ---
name: Deploy to Prod environments.
on:
  workflow_dispatch:
    inputs:
      network:
        type: choice
        options:
          - mainnet
          - testnet
        description: mainnet or testnet network
        required: true
      version:
        description: What mainnet version number is this deployment? (e.g. v0.1.0)
        required: true

env:
  PROJECT_PROD: "pagoda-discovery-platform-prod"
  REGION: "us-east1"
  IMAGE: us-east1-docker.pkg.dev/pagoda-discovery-platform-dev/mpc-recovery/mpc-recovery:${{ github.sha }}

jobs:
  build-mpc-recovery:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
        name: "Checkout mpc-recovery"

      - name: Login to Artifact Registry
        uses: docker/login-action@v2
        with:
          registry: ${{ env.REGION }}-docker.pkg.dev
          username: _json_key
          password: ${{ secrets.GCP_CREDENTIALS_DEV }}

      - name: Build Docker image and push to Google Artifact Registry
        id: docker-push-tagged
        uses: docker/build-push-action@v4
        with:
          push: true
          file: ./Dockerfile
          tags: "${{ env.IMAGE }}:${{ github.sha }}"

  deploy-mpc-recovery-testnet:
    runs-on: ubuntu-latest
    if: github.event.inputs.network == 'testnet'
    needs: build-mpc-recovery
    env:
      name: PROD
    steps:
      - uses: actions/checkout@v3
        name: "Checkout mpc-recovery"

      - name: "Authenticate to GCloud"
        uses: "google-github-actions/auth@v1"
        with:
          credentials_json: "${{ secrets.GCP_CREDENTIALS_DEV }}"

      - name: Deploy leader to Cloud Run Testnet
        id: deploy-leader
        uses: google-github-actions/deploy-cloudrun@v1
        with:
          image: "${{ env.IMAGE }}:${{ github.sha }}"
          service: mpc-recovery-leader-testnet
          region: us-east1
          project_id: "${{ env.PROJECT_PROD }}"
          tag: "${{ github.event.inputs.version }}"

      - name: Deploy signer to Cloud Run testnet
        id: deploy-signer-0-testnet
        uses: google-github-actions/deploy-cloudrun@v1
        with:
          image: "${{ env.IMAGE }}:${{ github.sha }}"
          service: mpc-recovery-signer-0-testnet
          region: us-east1
          project_id: "${{ env.PROJECT_PROD }}"
          tag: "${{ github.event.inputs.version }}"

      - name: Deploy signer to Cloud Run testnet
        id: deploy-signer-1-testnet
        uses: google-github-actions/deploy-cloudrun@v1
        with:
          image: "${{ env.IMAGE }}:${{ github.sha }}"
          service: mpc-recovery-signer-1-testnet
          region: us-east1
          project_id: "${{ env.PROJECT_PROD }}"
          tag: "${{ github.event.inputs.version }}"
        
      - name: Deploy signer to Cloud Run testnet
        id: deploy-signer-2-testnet
        uses: google-github-actions/deploy-cloudrun@v1
        with:
          image: "${{ env.IMAGE }}:${{ github.sha }}"
          service: mpc-recovery-signer-2-testnet
          region: us-east1
          project_id: "${{ env.PROJECT_PROD }}"
          tag: "${{ github.event.inputs.version }}"

  deploy-mpc-recovery-mainnet:
    runs-on: ubuntu-latest
    if: github.event.inputs.network == 'mainnet'
    needs: build-mpc-recovery
    env:
      name: PROD
    steps:
      - uses: actions/checkout@v3
        name: "Checkout mpc-recovery"

      - name: "Authenticate to GCloud"
        uses: "google-github-actions/auth@v1"
        with:
          credentials_json: "${{ secrets.GCP_CREDENTIALS_DEV }}"

      - name: Deploy leader to Cloud Run mainnet
        id: deploy-leader
        uses: google-github-actions/deploy-cloudrun@v1
        with:
          image: "${{ env.IMAGE }}:${{ github.sha }}"
          service: mpc-recovery-leader-mainnet
          region: us-east1
          project_id: "${{ env.PROJECT_PROD }}"
          tag: "${{ github.event.inputs.version }}"

      - name: Deploy signer to Cloud Run mainnet
        id: deploy-signer-0
        uses: google-github-actions/deploy-cloudrun@v1
        with:
          image: "${{ env.IMAGE }}:${{ github.sha }}"
          service: mpc-recovery-signer-0-mainnet
          region: us-east1
          project_id: "${{ env.PROJECT_PROD }}"
          tag: "${{ github.event.inputs.version }}"

      - name: Deploy signer to Cloud Run mainnet
        id: deploy-signer-1
        uses: google-github-actions/deploy-cloudrun@v1
        with:
          image: "${{ env.IMAGE }}:${{ github.sha }}"
          service: mpc-recovery-signer-1-mainnet
          region: us-east1
          project_id: "${{ env.PROJECT_PROD }}"
          tag: "${{ github.event.inputs.version }}"
        
      - name: Deploy signer to Cloud Run mainnet
        id: deploy-signer-2
        uses: google-github-actions/deploy-cloudrun@v1
        with:
          image: "${{ env.IMAGE }}:${{ github.sha }}"
          service: mpc-recovery-signer-2-mainnet
          region: us-east1
          project_id: "${{ env.PROJECT_PROD }}"
          tag: "${{ github.event.inputs.version }}"
'''
'''--- .github/workflows/docker-image.yml ---
name: Docker Image

on:
  push:
    branches:
      - develop
  pull_request:

jobs:
  build-image:
    runs-on: ubuntu-latest
    name: Build and Push

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Login to GCP Artifact Registry
        run: echo "$GOOGLE_CREDENTIALS" | docker login -u _json_key --password-stdin https://us-east1-docker.pkg.dev
        env:
          GOOGLE_CREDENTIALS: ${{ secrets.GCP_CREDENTIALS_DEV }}

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v2

      - name: Build Docker image
        uses: docker/build-push-action@v4
        with:
          context: .
          tags: us-east1-docker.pkg.dev/pagoda-discovery-platform-dev/mpc-recovery/mpc-recovery-dev:${{ github.sha }}
          load: true
          cache-from: type=gha
          cache-to: type=gha,mode=max

      - name: Push Docker image
        run: docker push us-east1-docker.pkg.dev/pagoda-discovery-platform-dev/mpc-recovery/mpc-recovery-dev:${{ github.sha }}

'''
'''--- .github/workflows/integrations.yml ---
name: Build Image and Test

on:
  push:
    branches:
      - develop
  pull_request:
    paths:
      - integration-tests/**
      - mpc-recovery/**
      - load-tests/**
      - test-oidc-provider/**

jobs:
  integrations:
    name: Integration
    strategy:
      matrix:
        # FIXME: macos-latest-xl is disabled since colima is erroring out right now
        os: [ubuntu-latest]
    runs-on: ${{ matrix.os }}

    steps:
      - uses: actions/checkout@v3

      - name: Install Docker
        if: ${{ matrix.os == 'macos-latest-xl' }}
        run: |
          brew install docker
          colima start
          # Colima does not expose the Docker socket by default, we have to symlink it
          # https://github.com/abiosoft/colima/blob/main/docs/FAQ.md#cannot-connect-to-the-docker-daemon-at-unixvarrundockersock-is-the-docker-daemon-running
          sudo ln -sf $HOME/.colima/default/docker.sock /var/run/docker.sock

      - name: Login to GitHub Container Registry
        uses: docker/login-action@v1
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Pull Relayer & Sandbox Docker Images
        run: |
          docker pull ghcr.io/near/os-relayer:12ba6e35690df3979fce0b36a41d0ca0db9c0ab4
          docker pull ghcr.io/near/sandbox

      - name: Build OIDC Provider Dcoker Image
        run: docker build -t near/test-oidc-provider ./test-oidc-provider

      - name: Login to GCP Artifact Registry
        run: echo "$GOOGLE_CREDENTIALS" | docker login -u _json_key --password-stdin https://us-east1-docker.pkg.dev
        env:
          GOOGLE_CREDENTIALS: ${{ secrets.GCP_CREDENTIALS_DEV }}

      - name: Install stable toolchain
        uses: actions-rs/toolchain@v1
        with:
          profile: minimal
          toolchain: stable
          target: wasm32-unknown-unknown

      - uses: Swatinem/rust-cache@v1

      - name: Install Protoc
        uses: arduino/setup-protoc@v1.1.2
        with:
          repo-token: ${{ secrets.GITHUB_TOKEN }}

      - name: Compile Contract
        run: cargo build -p mpc-contract --target wasm32-unknown-unknown --release --target-dir target/seperate_wasm

      - name: Test
        run: cargo test -p mpc-recovery-integration-tests mpc --jobs 1 -- --test-threads 1
        env:
          RUST_LOG: INFO
          RUST_BACKTRACE: 1

'''
'''--- .github/workflows/multichain-contract.yml ---
name: Multichain Contract

on:
  push:
    branches:
      - develop
  pull_request:
    paths:
      - contract/**

env:
  RUSTFLAGS: -D warnings
jobs:
  test:
    name: Test
    strategy:
      matrix:
        os: [ubuntu-22.04-4core]
    runs-on: ${{ matrix.os }}

    steps:
      - uses: actions/checkout@v3

      - name: Install stable toolchain
        uses: actions-rs/toolchain@v1
        with:
          profile: minimal
          toolchain: stable
          target: wasm32-unknown-unknown

      - uses: Swatinem/rust-cache@v1

      - name: Compile Contract
        run: cargo build -p mpc-contract --target wasm32-unknown-unknown --release --target-dir target/seperate_wasm

      - name: Test Contract
        run: cd contract && cargo test --target x86_64-unknown-linux-gnu --release
        env:
          RUST_LOG: INFO
          RUST_BACKTRACE: 1

'''
'''--- .github/workflows/multichain-dev.yml ---
name: Deploy Multichain Dev.
on:
  pull_request:
    types: [closed]
    branches:
      - develop

env:
  IMAGE: "us-east1-docker.pkg.dev/pagoda-discovery-platform-dev/multichain-public/multichain-dev"
  TAG: ${{ github.sha }}

jobs:
  build-mpc-recovery:
    if: github.event.pull_request.merged == true
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
        name: "Checkout mpc-recovery"

      - name: Login to GCP Artifact Registry
        run: echo "$GOOGLE_CREDENTIALS" | docker login -u _json_key --password-stdin https://us-east1-docker.pkg.dev
        env:
          GOOGLE_CREDENTIALS: ${{ secrets.GCP_CREDENTIALS_DEV }}

      - name: Build Docker image and push to Google Artifact Registry
        id: docker-push-tagged
        uses: docker/build-push-action@v4
        with:
          push: true
          file: ./Dockerfile.multichain
          tags: "${{ env.IMAGE }}:${{ env.TAG }}"

  deploy:
    if: github.event.pull_request.merged == true
    runs-on: ubuntu-latest
    needs: build-mpc-recovery
    steps:
      - id: 'auth'
        uses: 'google-github-actions/auth@v2'
        with:
          credentials_json: '${{ secrets.GCP_CREDENTIALS_DEV }}'
  
      - name: 'Set up Cloud SDK'
        uses: 'google-github-actions/setup-gcloud@v2'
  
      - name: 'Set project'
        run: 'gcloud config set project pagoda-discovery-platform-dev'

      - name: 'Update Nodes'
        run: | 
          gcloud compute instances update-container multichain-dev-0 --zone us-central1-a --container-image=${{ env.IMAGE }}:${{ env.TAG }} & \
          gcloud compute instances update-container multichain-dev-1 --zone us-central1-a --container-image=${{ env.IMAGE }}:${{ env.TAG }} & \
          gcloud compute instances update-container multichain-dev-2 --zone us-central1-a --container-image=${{ env.IMAGE }}:${{ env.TAG }} & \
          gcloud compute instances update-container multichain-dev-3 --zone us-central1-a --container-image=${{ env.IMAGE }}:${{ env.TAG }} & \
          gcloud compute instances update-container multichain-dev-4 --zone us-central1-a --container-image=${{ env.IMAGE }}:${{ env.TAG }} & \
          gcloud compute instances update-container multichain-dev-5 --zone us-central1-a --container-image=${{ env.IMAGE }}:${{ env.TAG }} & \
          gcloud compute instances update-container multichain-dev-6 --zone us-central1-a --container-image=${{ env.IMAGE }}:${{ env.TAG }} & \
          gcloud compute instances update-container multichain-dev-7 --zone us-central1-a --container-image=${{ env.IMAGE }}:${{ env.TAG }}

'''
'''--- .github/workflows/multichain-integration.yml ---
name: Integration (Multichain)

on:
  push:
    branches:
      - develop
  pull_request:
    paths:
      - integration-tests/**
      - node/**
      - contract/**

env:
  RUSTFLAGS: -D warnings
jobs:
  test:
    name: Test
    strategy:
      matrix:
        # FIXME: macos-latest-xl is disabled since colima is erroring out right now
        os: [ubuntu-22.04-4core]
    runs-on: ${{ matrix.os }}

    steps:
      - uses: actions/checkout@v3

      - name: Install Docker
        if: ${{ matrix.os == 'macos-latest-xl' }}
        run: |
          brew install docker
          colima start
          # Colima does not expose the Docker socket by default, we have to symlink it
          # https://github.com/abiosoft/colima/blob/main/docs/FAQ.md#cannot-connect-to-the-docker-daemon-at-unixvarrundockersock-is-the-docker-daemon-running
          sudo ln -sf $HOME/.colima/default/docker.sock /var/run/docker.sock

      - name: Login to GitHub Container Registry
        uses: docker/login-action@v1
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Pull Relayer & Sandbox Docker Images
        run: |
          docker pull ghcr.io/near/os-relayer:12ba6e35690df3979fce0b36a41d0ca0db9c0ab4
          docker pull ghcr.io/near/near-lake-indexer:e6519c922435f3d18b5f2ddac5d1ec171ef4dd6b
          docker pull localstack/localstack:latest

      - name: Install stable toolchain
        uses: actions-rs/toolchain@v1
        with:
          profile: minimal
          toolchain: stable
          target: wasm32-unknown-unknown

      - uses: Swatinem/rust-cache@v1

      - name: Install Protoc
        uses: arduino/setup-protoc@v1.1.2
        with:
          repo-token: ${{ secrets.GITHUB_TOKEN }}

      - name: Configure AWS
        run: |
          # Fake AWS configuration for LocalStack
          aws configure set region us-east-1
          aws --profile default configure set aws_access_key_id "123"
          aws --profile default configure set aws_secret_access_key "456"

      - name: Compile Contract
        run: cargo build -p mpc-contract --target wasm32-unknown-unknown --release --target-dir target/seperate_wasm

      - name: Build MPC Recovery Binary Locally
        run: |
          cargo build -p mpc-recovery-node --release

      - name: Test
        run: cargo test -p mpc-recovery-integration-tests multichain --jobs 1 -- --test-threads 1
        env:
          RUST_LOG: INFO
          RUST_BACKTRACE: 1

'''
'''--- .github/workflows/multichain-prod.yml ---
name: Deploy Multichain Prod.
on:
  workflow_dispatch:
    inputs:
      network:
        type: choice
        options:
          - mainnet
          - testnet
        description: mainnet or testnet network
        required: true
      image:
        description: Full Artifact Registry image with tag (e.g. us-east1-docker.pkg.dev/pagoda-discovery-platform-prod/multichain/multichain-< testnet | mainnet >)
        required: true
      tag:
        description: Image tag that you wish to deploy, either by SHA or Version/latest
      node_group:
        type: choice
        options:
          - partner
          - internal
        description: Do you want to deploy the Parner nodes or internal Pagoda nodes?

jobs:
  build-mpc-recovery:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
        name: "Checkout mpc-recovery"

      - name: Login to GCP Artifact Registry
        run: echo "$GOOGLE_CREDENTIALS" | docker login -u _json_key --password-stdin https://us-east1-docker.pkg.dev
        env:
          GOOGLE_CREDENTIALS: ${{ secrets.GCP_CREDENTIALS_PROD }}

      - name: Build Docker image and push to internal Google Artifact Registry
        if: ${{ github.event.inputs.node_group == 'internal' }}
        id: docker-push-tagged
        uses: docker/build-push-action@v4
        with:
          push: true
          file: ./Dockerfile.multichain
          tags: "${{ github.event.inputs.image }}:${{ github.event.inputs.tag }}"
      
      - name: Build Docker image and deploy partner nodes
        if: ${{ github.event.inputs.node_group == 'partner' }}
        id: docker-push-tagged-partner
        uses: docker/build-push-action@v4
        with:
          push: true
          file: ./Dockerfile.multichain
          tags: "${{ github.event.inputs.image }}:${{ github.event.inputs.tag }}"

  deploy:
    if: ${{ github.event.inputs.node_group == 'internal' }}
    runs-on: ubuntu-latest
    needs: build-mpc-recovery
    steps:
      - id: 'auth'
        uses: 'google-github-actions/auth@v2'
        with:
          credentials_json: '${{ secrets.GCP_CREDENTIALS_PROD }}'
  
      - name: 'Set up Cloud SDK'
        uses: 'google-github-actions/setup-gcloud@v2'
  
      - name: 'Set project'
        run: 'gcloud config set project pagoda-discovery-platform-prod'

      - name: 'Update Nodes'
        run: |
          gcloud compute instances update-container multichain-${{ github.event.inputs.network }}-0 --zone us-central1-a --container-image=${{ github.event.inputs.image }}:${{ github.event.inputs.tag }} & \
          gcloud compute instances update-container multichain-${{ github.event.inputs.network }}-1 --zone us-central1-a --container-image=${{ github.event.inputs.image }}:${{ github.event.inputs.tag }} & \
          gcloud compute instances update-container multichain-${{ github.event.inputs.network }}-2 --zone us-central1-a --container-image=${{ github.event.inputs.image }}:${{ github.event.inputs.tag }}

'''
'''--- .github/workflows/terraform-dev.yml ---
name: Terraform Dev

on:
  workflow_dispatch:

jobs:
  terraform_dev:
    name: Checks & Plan
    runs-on: ubuntu-latest
    if: ${{ github.event.workflow_run.conclusion == 'success' }}
    permissions:
      contents: read
      issues: write
      pull-requests: write
    defaults:
      run:
        working-directory: ./infra/mpc-recovery-dev
    steps:
      - name: Checkout
        uses: actions/checkout@v3

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v1
        with:
          terraform_version: 1.4.6

      # Initialize a new or existing Terraform working directory by creating initial files, loading any remote state, downloading modules, etc.
      - name: Terraform Init
        id: init
        run: terraform init
        env:
          GOOGLE_CREDENTIALS: ${{ secrets.GCP_CREDENTIALS_DEV }}

      # Checks that all Terraform configuration files adhere to a canonical format
      - name: Terraform Format
        id: fmt
        run: terraform fmt -check -diff -recursive
        env:
          GOOGLE_CREDENTIALS: ${{ secrets.GCP_CREDENTIALS_DEV }}

      # Validates the TF configuration files, referring only to the configuration and not accessing any remote services such as remote state.
      # Runs checks that verify whether a configuration is syntactically valid and internally consistent, regardless of any provided variables or existing state.
      - name: Terraform Validate
        id: validate
        run: terraform validate -no-color

      # Select the relevant Terraform workspace.
      - name: Terraform Select Workspace
        id: select
        run: terraform workspace select dev
        env:
          GOOGLE_CREDENTIALS: ${{ secrets.GCP_CREDENTIALS_DEV }}

      # Generates an execution plan for Terraform
      - name: Terraform Plan
        id: plan
        run: |
          terraform plan -input=false -no-color -lock-timeout=1h -var-file terraform-dev.tfvars \
            -var "credentials=$GOOGLE_CREDENTIALS" \
            -var docker_image=us-east1-docker.pkg.dev/pagoda-discovery-platform-dev/mpc-recovery/mpc-recovery-dev:${{ github.sha }}
        env:
          GOOGLE_CREDENTIALS: ${{ secrets.GCP_CREDENTIALS_DEV }}

      - uses: actions/github-script@v6
        if: github.event_name == 'pull_request'
        env:
          PLAN: "${{ steps.plan.outputs.stdout }}"
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            // 1. Retrieve existing bot comments for the PR
            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
            })
            const botComment = comments.find(comment => {
              return comment.user.type === 'Bot' && comment.body.includes('Terraform Format and Style')
            })

            // 2. Prepare format of the comment
            const output = `### Terraform Dev Environment
            #### Terraform Format and Style üñå\`${{ steps.fmt.outcome }}\`
            <details><summary>Format Check Output</summary>

            \`\`\`\n
            ${{ steps.fmt.outputs.stdout }}
            \`\`\`

            </details>

            #### Terraform Initialization ‚öôÔ∏è\`${{ steps.init.outcome }}\`
            #### Terraform Validation ü§ñ\`${{ steps.validate.outcome }}\`
            <details><summary>Validation Output</summary>

            \`\`\`\n
            ${{ steps.validate.outputs.stdout }}
            \`\`\`

            </details>

            #### Terraform Plan üìñ\`${{ steps.plan.outcome }}\`

            <details><summary>Show Plan</summary>

            \`\`\`\n
            ${process.env.PLAN}
            \`\`\`

            </details>

            *Pusher: @${{ github.actor }}, Action: \`${{ github.event_name }}\`, Working Directory: \`${{ env.tf_actions_working_dir }}\`, Workflow: \`${{ github.workflow }}\`*`;

            // 3. If we have a comment, update it, otherwise create a new one
            if (botComment) {
              github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: botComment.id,
                body: output
              })
            } else {
              github.rest.issues.createComment({
                issue_number: context.issue.number,
                owner: context.repo.owner,
                repo: context.repo.repo,
                body: output
              })
            }

        # On push to "develop", build or change infrastructure according to Terraform configuration files
      - name: Terraform Apply
        if: github.ref == 'refs/heads/develop'
        run: |
          terraform apply -auto-approve -input=false -lock-timeout=1h -var-file terraform-dev.tfvars \
            -var "credentials=$GOOGLE_CREDENTIALS" \
            -var docker_image=us-east1-docker.pkg.dev/pagoda-discovery-platform-dev/mpc-recovery/mpc-recovery-dev:${{ github.sha }}
        env:
          GOOGLE_CREDENTIALS: ${{ secrets.GCP_CREDENTIALS_DEV }}

'''
'''--- .github/workflows/terraform-feature-env-destroy.yml ---
name: Terraform Feature Env (Destroy)

on:
  pull_request:
    types: [closed]

jobs:
  terraform_destroy:
    name: Destroy
    runs-on: ubuntu-latest
    permissions:
      contents: read
      issues: write
      pull-requests: write
    defaults:
      run:
        working-directory: ./infra/mpc-recovery-dev
    env:
      PR_NUMBER: ${{ github.event.number }}
    steps:
      - name: Checkout
        uses: actions/checkout@v3

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v1
        with:
          terraform_version: 1.4.6

      # Initialize a new or existing Terraform working directory by creating initial files, loading any remote state, downloading modules, etc.
      - name: Terraform Init
        id: init
        run: terraform init
        env:
          GOOGLE_CREDENTIALS: ${{ secrets.GCP_CREDENTIALS_DEV }}

      # Select the relevant Terraform workspace.
      - name: Terraform Select Workspace
        id: select
        run: terraform workspace select -or-create dev-$PR_NUMBER
        env:
          GOOGLE_CREDENTIALS: ${{ secrets.GCP_CREDENTIALS_DEV }}
          PR_NUMBER: ${{ env.PR_NUMBER }}

      # Destroy Terraform configuration in the temporary environment. Wait up to 1 hour for the lock (other workflows might still be executing).
      - name: Terraform Destroy
        id: destroy
        run: terraform destroy -auto-approve -input=false -no-color -lock-timeout=1h -var-file terraform-dev.tfvars -var "credentials=$GOOGLE_CREDENTIALS" -var "env=dev-$PR_NUMBER"
        env:
          GOOGLE_CREDENTIALS: ${{ secrets.GCP_CREDENTIALS_DEV }}
          PR_NUMBER: ${{ env.PR_NUMBER }}

      - uses: actions/github-script@v6
        if: github.event_name == 'pull_request'
        env:
          DESTROY_PLAN: "${{ steps.destroy.outputs.stdout }}"
          PR_NUMBER: ${{ env.PR_NUMBER }}
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            // 1. Prepare format of the comment
            const output = `### Terraform Feature Environment Destroy (**dev-${process.env.PR_NUMBER}**)
            #### Terraform Initialization ‚öôÔ∏è\`${{ steps.init.outcome }}\`

            #### Terraform Destroy \`${{ steps.destroy.outcome }}\`

            <details><summary>Show Destroy Plan</summary>

            \`\`\`\n
            ${process.env.DESTROY_PLAN}
            \`\`\`

            </details>

            *Pusher: @${{ github.actor }}, Action: \`${{ github.event_name }}\`, Working Directory: \`${{ env.tf_actions_working_dir }}\`, Workflow: \`${{ github.workflow }}\`*`;

            // 3. Create the comment
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: output
            })

'''
'''--- .github/workflows/terraform-feature-env.yml ---
name: Terraform Feature Env

on:
  workflow_dispatch:

jobs:
  terraform_apply:
    name: Apply
    runs-on: ubuntu-latest
    permissions:
      contents: read
      issues: write
      pull-requests: write
      checks: read
    defaults:
      run:
        working-directory: ./infra/mpc-recovery-dev
    env:
      PR_NUMBER: ${{ github.event.number }}
    steps:
      - name: Checkout
        uses: actions/checkout@v3

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v1
        with:
          terraform_version: 1.4.6

      # Initialize a new or existing Terraform working directory by creating initial files, loading any remote state, downloading modules, etc.
      - name: Terraform Init
        id: init
        run: terraform init
        env:
          GOOGLE_CREDENTIALS: ${{ secrets.GCP_CREDENTIALS_DEV }}

      # Select the relevant Terraform workspace.
      - name: Terraform Select Workspace
        id: select
        run: terraform workspace select -or-create dev-$PR_NUMBER
        env:
          GOOGLE_CREDENTIALS: ${{ secrets.GCP_CREDENTIALS_DEV }}
          PR_NUMBER: ${{ env.PR_NUMBER }}

      - name: Wait for Docker Image to be Ready
        uses: lewagon/wait-on-check-action@v1.3.1
        with:
          ref: ${{ github.event.pull_request.head.sha }}
          check-name: 'Build and Push'
          repo-token: ${{ secrets.GITHUB_TOKEN }}
          wait-interval: 10

      # Applies Terraform configuration to the temporary environment
      - name: Terraform Apply
        id: apply
        run: |
          terraform apply -auto-approve -input=false -no-color -lock-timeout=1h -var-file terraform-dev.tfvars \
            -var "credentials=$GOOGLE_CREDENTIALS" \
            -var "env=dev-$PR_NUMBER" \
            -var docker_image=us-east1-docker.pkg.dev/pagoda-discovery-platform-dev/mpc-recovery/mpc-recovery-dev:${{ github.sha }}
        env:
          GOOGLE_CREDENTIALS: ${{ secrets.GCP_CREDENTIALS_DEV }}
          PR_NUMBER: ${{ env.PR_NUMBER }}

      - name: Terraform Output
        id: output
        run: terraform output -raw leader_node
        env:
          GOOGLE_CREDENTIALS: ${{ secrets.GCP_CREDENTIALS_DEV }}

      - uses: actions/github-script@v6
        if: github.event_name == 'pull_request'
        env:
          APPLY_PLAN: "${{ steps.apply.outputs.stdout }}"
          LEADER_NODE: ${{ steps.output.outputs.stdout }}
          PR_NUMBER: ${{ env.PR_NUMBER }}
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            // 1. Retrieve existing bot comments for the PR
            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
            })
            const botComment = comments.find(comment => {
              return comment.user.type === 'Bot' && comment.body.includes('Terraform Feature Environment')
            })

            // 2. Prepare format of the comment
            const output = `### Terraform Feature Environment (**dev-${process.env.PR_NUMBER}**)
            #### Terraform Initialization ‚öôÔ∏è\`${{ steps.init.outcome }}\`

            #### Terraform Apply \`${{ steps.apply.outcome }}\`

            <details><summary>Show Apply Plan</summary>

            \`\`\`\n
            ${process.env.APPLY_PLAN}
            \`\`\`

            </details>

            *Pusher: @${{ github.actor }}, Action: \`${{ github.event_name }}\`, Working Directory: \`${{ env.tf_actions_working_dir }}\`, Workflow: \`${{ github.workflow }}\`*

            **URL**: \`${process.env.LEADER_NODE}\``;

            // 3. If we have a comment, update it, otherwise create a new one
            if (botComment) {
              github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: botComment.id,
                body: output
              })
            } else {
              github.rest.issues.createComment({
                issue_number: context.issue.number,
                owner: context.repo.owner,
                repo: context.repo.repo,
                body: output
              })
            }

'''
'''--- .github/workflows/unit.yml ---
name: Unit
on:
  push:
    branches:
      - main
      - develop
  pull_request:
env:
  RUSTFLAGS: -D warnings
jobs:
  test:
    runs-on: ubuntu-latest
    name: Check & Test
    steps:
      - uses: actions/checkout@v3
      - name: Install stable toolchain
        uses: actions-rs/toolchain@v1
        with:
          profile: minimal
          toolchain: stable
          target: wasm32-unknown-unknown
      - uses: Swatinem/rust-cache@v1
      - name: Install Protoc
        uses: arduino/setup-protoc@v1.1.2
        with:
          repo-token: ${{ secrets.GITHUB_TOKEN }}
      - name: Compile Contract
        run: cargo build -p mpc-contract --target wasm32-unknown-unknown --release --target-dir target/seperate_wasm
      - name: Compile
        run: cargo check
      - name: Test format
        run: cargo fmt -- --check
      - name: Unit tests
        run: cargo test -p mpc-recovery
      - name: Test clippy
        run: cargo clippy --tests -- -Dclippy::all
  audit:
    name: Audit
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Install stable toolchain
        uses: actions-rs/toolchain@v1
        with:
          profile: minimal
          toolchain: stable
      - uses: Swatinem/rust-cache@v1
      - name: Install Audit
        run: cargo install cargo-audit
      - name: Run Audit
        uses: actions-rs/cargo@v1
        with:
          command: audit
          args: --ignore RUSTSEC-2020-0071 --ignore RUSTSEC-2023-0052 --ignore RUSTSEC-2022-0093 --ignore RUSTSEC-2023-0071 --ignore RUSTSEC-2024-0019

'''
'''--- Cargo.toml ---
[workspace]
members = [
    "mpc-recovery",
    "contract",
    "node",
    "integration-tests",
    "load-tests",
    "keys",
    "test-oidc-provider",
]

[profile.flamegraph]
inherits = "release"
debug = true

'''
'''--- DEPLOY.md ---
# Manually Deploying mpc-recovery to GCP

## Requirements

This guide assumes you have access to GCP console and the administrative ability to enable services, create service accounts and grant IAM roles if necessary.

It is assumed that you have chosen a region to use throughout this guide. This can be any region, but we recommend something close to our leader node in `us-east1` if you are deploying production nodes. This region of your choosing will be referred to as `GCP_REGION`.

[TODO]: <> (Rewrite below to use gcloud CLI instead of GCP Console UI)

Make sure that:
* You have a GCP Project (its ID will be referred to as `GCP_PROJECT_ID` below, should look something like `pagoda-discovery-platform-dev`)
* `GCP_PROJECT_ID` has the following services enabled:
    * `Artifact Registry`
    * `Cloud Run Admin API` (can be enabled by trying to create a Cloud Run instance, no need to proceed with creation after you pressed the `CREATE SERVICE` button)
    * `Datastore` (should also be initialized with the `default` database)
    * `Secret Manager`
* You have a service account dedicated to mpc-recovery (will be referred to as `GCP_SERVICE_ACCOUNT` below, should look something like `mpc-recovery@pagoda-discovery-platform-dev.iam.gserviceaccount.com`).
* `GCP_SERVICE_ACCOUNT` should have the following roles granted to it (change in `https://console.cloud.google.com/iam-admin/iam?project=<GCP_PROJECT_ID>`):
    * `Artifact Registry Administrator`
    * `Cloud Datastore Owner`
    * `Cloud Run Admin`
    * `Secret Manager Admin`
    * `Security Admin`
    * `Service Account Admin`
* JSON service account keys for `GCP_SERVICE_ACCOUNT`. If you don't have any, then follow the steps below:
    1. Go to the service account page (`https://console.cloud.google.com/iam-admin/serviceaccounts?project=<GCP_PROJECT_ID>`)
    2. Select your `GCP_SERVICE_ACCOUNT` in the list
    3. Open `KEYS` tab
    4. Press `ADD KEY` and then `Create new key`.
    5. Choose `JSON` and press `CREATE`.
    6. Save the keys somewhere to your filesystem, we will refer to its location as `GCP_SERVICE_ACCOUNT_KEY_PATH`.

## Requirements

‚ö†Ô∏è **Warning: You must use an x86 machine, M1 will not work**

You need Rust 1.68 or later. Update your `rustc` by running:

```
$ rustup install stable
```

## Create Secrets
### Secret Key Share

[TODO]: <> (Change key serialization format to a more conventional format so that users can generate it outside of mpc-recovery)

You need a Ed25519 key pair that you can generate by running `RUST_LOG=info cargo run --bin mpc-recovery -- generate 1` in this directory. Grab JSON object after `Secret key share 0:`; it should look like this:
```json
{"public_key":{"curve":"ed25519","point":[120,153,87,73,144,228,107,221,163,76,41,132,123,208,73,71,110,235,204,191,174,106,225,69,38,145,165,76,132,201,55,152]},"expanded_private_key":{"prefix":{"curve":"ed25519","scalar":[180,110,118,232,35,24,127,100,6,137,244,195,8,154,150,22,214,43,134,73,234,67,255,249,99,157,120,6,163,88,178,12]},"private_key":{"curve":"ed25519","scalar":[160,85,170,73,186,103,158,30,156,142,160,162,253,246,210,214,173,162,39,244,145,241,58,148,63,211,218,241,11,70,235,89]}}}
```

Now save it to GCP Secret Manager under the name of your choosing (e.g. `mpc-recovery-key-prod`). This name will be referred to as `GCP_SK_SHARE_SECRET_ID`.

### Cipher

You also need to grab the AES cipher key that was printed after `Cipher 0:`; it should like this:

```
23855bcee709c32e98fdbf2a44f0e86fb122b87774394f77ed31c1875244dcd7
```

Save it to GCP Secret Manager under the name of your choosing (e.g. `mpc-recovery-cipher-prod`). This name will be referred to as `GCP_CIPHER_SECRET_ID`.

## Building Docker Image

Build the mpc-recovery docker image from this folder and make sure to tag it for convenience:

```bash
$ docker build . -t near/mpc-recovery
```

## Configure Terraform Variables

Go to `infra/partner` and copy `template.tfvars` as `prod.tfvars`. Edit `prod.tfvars` to match your environment:

* Set `env` to `prod`
* Set `project` to `<GCP_PROJECT_ID>`
* Set `node_id` to whatever your point of contact with Pagoda has given you (ask them if they did not). It is very important you use this specific ID for your node's configuration
* Set `cipher_key_secret_id` to `<GCP_CIPHER_SECRET_ID>`
* Set `sk_share_secret_id` to `<GCP_SK_SHARE_SECRET_ID>`

## Apply Terraform Configuration

Run `terraform apply -var-file prod.tfvars -var credentials_file=<GCP_SERVICE_ACCOUNT_KEY_PATH>` and if deploy ends successfully it will give you your node's URL, share it with your Pagoda point of contact.

'''
'''--- README.md ---
# MPC Account Recovery (WIP)
The aim of this project is to offer NEAR users the opportunity to create and restore their accounts by utilizing OIDC protocol. By linking their NEAR account to `near.org` or other authentication provider, they can then add a new Full Access key, which will be managed by the trusted network of servers. Should they lose all the keys they possess, they can reauthorize themselves, create a new key, and add it into their NEAR account using a transaction that will be signed by MPC servers through their recovery key. All the transaction cost will be covered by a relayer server and metatransactions.

## How the MPC system will work
- The system consists of 3 trusted signing nodes and a leader node
- Each node holds a unique secret key
- Each action must be signed by all 3 nodes
- Nodes signatures are then combined into a single signature on the leader node

In the future we are planning to get rid  of the leader node to make the system more decentralized.

## External API

The recovery service is currently hosted at https://near.org

### Claim OIDC Id Token ownership

    URL: /claim_oidc
    Request parameters: {
        oidc_token_hash: [u8; 32],
        frp_public_key: String,
        frp_signature: [u8; 64],
    }
    Response: Ok {
        mpc_signature: String,
    } / Err {
        msg: String
    }

The frp_signature you send must be an Ed22519 signature of the hash:

    SALT = 3177899144
    sha256.hash(Borsh.serialize<u32>(SALT + 0) ++ Borsh.serialize<[u8]>(oidc_token_hash) ++ [0] ++ Borsh.serialize<[u8]>(frp_public_key))

signed with your on device public key.

The constant 3177899144 is a random number between 2^31 and 2^32 which as described [here](https://github.com/gutsyphilip/NEPs/blob/8b0b05c3727f0a90b70c6f88791152f54bf5b77f/neps/nep-0413.md#example) prevents collisions with legitimate on chain transactions.

If you successfully claim the token you will receive a signature in return of:

    sha256.hash(Borsh.serialize<u32>(SALT + 1) ++ Borsh.serialize<[u8]>(signature))

This will be signed by the nodes combined Ed22519 signature.

### MPC Public Key

    URL: /mpc_public_key
    Request parameters: {}
    Response: Ok {
        mpc_pk: String,
    } / Err {
        msg: String
    }

Returns the MPC public key that is used to sign the OIDC claiming response. Should not be used in production environment, as the MPC PK should be hardcoded in the client.

### User Credentials

    URL: /user_credentials
    Request parameters: {
        oidc_token: String,
        frp_signature: Signature,
        frp_public_key: String,
    }
    Response: Ok {
        public_key: String,
    } / Err {
        msg: String
    }

Returns the recovery public key associated with the provided OIDC token.
The frp_signature you send must be an Ed22519 signature of the hash:

    sha256.hash(Borsh.serialize<u32>(SALT + 2) ++ Borsh.serialize<[u8]>(oidc_token) ++ [0] ++ Borsh.serialize<[u8]>(frp_public_key))

### Create New Account

    URL: /new_account
    Request parameters: {
        near_account_id: String,
        create_account_options: CreateAccountOptions,
        oidc_token: String,
        user_credentials_frp_signature: Signature,
        frp_public_key: String,
    }
    Response:
    Ok {
        create_account_options: CreateAccountOptions,
        recovery_public_key: String,
        near_account_id: String,
    } /
    Err {
        msg: String
    }

This creates an account with account Id provided in `near_account_id`. If this name is already taken then this operation will fail with no action having been taken.

This service will send a `create_account` transaction to the relayer signed by `account_creator.near` account. If this operation is successful relayer will make an allowance for the created account.

Newly created NEAR account will have two full access keys. One that was provided by the user, and the recovery one that is controlled by the MPC system.

In the future, MPC Service will disallow creating account with ID Tokes that were not claimed first. It is expected, that PK that client wants to use for the account creation is the same as the one that was used to claim the ID Token.

The user_credentials_frp_signature you send must be an Ed22519 signature of the hash:

    sha256.hash(Borsh.serialize<u32>(SALT + 2) ++ Borsh.serialize<[u8]>(oidc_token) ++ [0] ++ Borsh.serialize<[u8]>(frp_public_key))

signed by the key you used to claim the oidc token. This does not have to be the same as the key in the public key field. This digest is the same as the one used in the user_credentials endpoint, because new_account request needs to get the recovery public key of the user that is creating the account.

### Sign

    URL: /sign
    Request parameters: {
        delegate_action: String, // Base64-encoded borsh serialization of DelegateAction
        oidc_token: String,
        frp_signature: Signature,
        user_credentials_frp_signature: Signature,
        frp_public_key: String,
    }
    Response:
    Ok {
        signature: Signature,
    } /
    Err {
        msg: String
    }

This endpoint can be used to sign a delegate action that can then be sent to the relayer. The delegate action is signed by user recovery key.

The frp_signature you send must be an Ed22519 signature of the hash:

    sha256.hash(Borsh.serialize<u32>(SALT + 3) ++
    Borsh.serialize<[u8]>(delegate_action) ++
    Borsh.serialize<[u8]>(oidc_token) ++
    [0] ++ Borsh.serialize<[u8]>(frp_public_key))

The user_credentials_frp_signature is needed to get user recovery PK. It is the same as in user_credentials endpoint.

## OIDC (OAuth 2.0) authentication

We are using OpenID Connect (OIDC) standard to authenticate users (built on top of OAuth 2.0).
Check OIDC standard docs [here](https://openid.net/specs/openid-connect-core-1_0.html#IDToken) and Google OIDC docs [here](https://developers.google.com/identity/protocols/oauth2/openid-connect)

## Front-runnig protection flow
Before transmitting your OIDC Id Token to the recovery service you must first claim the ownership of the token. This prevents a rogue node from taking your Id Token and using it to sign another request.

The expected flow for the client is next:
1. Client-side developer hardcodes the MPC PK in the client code. It should be provided by MPC Recovery service developers and compared to the one that is returned by `/mpc_public_key` endpoint. You MUST NOT fetch the MPC PK from the nodes themselves in production env.
2. Client generates a key pair that is stored in their device. It can be same key pair that is used to sign the transactions.
3. Client recieves an OIDC Id Token from the authentication provider.
4. Client claims the ownership of the token by sending a request to the `/claim_oidc_token` endpoint.
5. In reponce to the claim request, user recieves a signature that is signed by the MPC system.
6. User verifies that the signature is valid. It garantees that each node in the system has seen the token and will not accept it again with another key.
7. Now client can safely send their Id Token with `/sign` or other requests.
8. Once the token is expaired, client can claim a new one and continue using the MPC Recovery service.

Check our integration tests to see how it works in practice.

Registered ID Token will be added to the persistent DB on each Signing node and saved until expiration. Registered Id Tokens are tied to the provided PK.

## Sign flow
The expected flow for the client is next:
1. Client uses `/user_credentials` endpoint to get the recovery PK.
2. Client fetches latest nonce, block hash using obtained recovery PK.
3. Client creates a delegate action with desired actions, such as add or delete key.
4. Client serializes the delegate action and encodes it into Base64.
5. Client gets the signature from the MPC system using `/sign` endpoint.
6. Client sends the same delegate action to the relayer with obtained signature.

### Client integration

There are several ways to get and use the ID token. The flow that we are using is called the "server" flow, you can find more info [here](https://developers.google.com/identity/openid-connect/openid-connect#authenticatingtheuser). The system will be able to process any token that is following the core OpenID Connect standard. In order to receive the ID token from OpenID provider you will need to include the `openid` scope value to the Authorization Request.

### Server integration

Internally, we are identifying users by their issuer id (iss) and their unique ID (sub) retrieved form the ID token and separated by a colon: `<issuer_iss>:<user_sub>`. It means that each recovery method (like GitHub and Google) is separated from one another even if they have the same email.

### Contribute

In order to build the project, you will need to have `protoc` and `gmp` installed. Refer to your system's package manager on how to do this.

If you have [nix](https://nixos.org/) and [direnv](https://direnv.net/) installed, you can set up a development environment by running:

```BASH
direnv allow
```

Run unit tests with:
```BASH
cargo test -p mpc-recovery
```

'''
'''--- contract/.cargo/config.toml ---
[build]
target = "wasm32-unknown-unknown"

'''
'''--- contract/Cargo.toml ---
[package]
name = "mpc-contract"
version = "0.1.1"
edition = "2021"

[lib]
crate-type = ["cdylib", "lib"]

[dependencies]
borsh = "1.3.0"
near-sdk = "5.0.0-alpha.1"
serde = { version = "1", features = ["derive"] }
serde_json = "1"
schemars = "0.8"

[dev-dependencies]
near-workspaces = "0.10.0"
tokio = { version = "1", features = ["full"] }
anyhow = "1.0.44"

[profile.release]
codegen-units = 1
# Tell `rustc` to optimize for small code size.
opt-level = "z"
lto = true
debug = false
panic = "abort"

'''
'''--- contract/src/lib.rs ---
pub mod primitives;

use near_sdk::borsh::{self, BorshDeserialize, BorshSerialize};
use near_sdk::collections::LookupMap;
use near_sdk::serde::{Deserialize, Serialize};
use near_sdk::{env, near_bindgen, AccountId, Promise, PromiseOrValue, PublicKey};
use near_sdk::{log, Gas};
use primitives::{CandidateInfo, Candidates, ParticipantInfo, Participants, PkVotes, Votes};
use std::collections::{BTreeMap, HashSet};

const GAS_FOR_SIGN_CALL: Gas = Gas::from_tgas(250);

#[derive(BorshDeserialize, BorshSerialize, Serialize, Deserialize, Debug)]
pub struct InitializingContractState {
    pub candidates: Candidates,
    pub threshold: usize,
    pub pk_votes: PkVotes,
}

#[derive(BorshDeserialize, BorshSerialize, Serialize, Deserialize, Debug)]
pub struct RunningContractState {
    pub epoch: u64,
    pub participants: Participants,
    pub threshold: usize,
    pub public_key: PublicKey,
    pub candidates: Candidates,
    pub join_votes: Votes,
    pub leave_votes: Votes,
}

#[derive(BorshDeserialize, BorshSerialize, Serialize, Deserialize, Debug)]
pub struct ResharingContractState {
    pub old_epoch: u64,
    pub old_participants: Participants,
    // TODO: only store diff to save on storage
    pub new_participants: Participants,
    pub threshold: usize,
    pub public_key: PublicKey,
    pub finished_votes: HashSet<AccountId>,
}

#[derive(BorshDeserialize, BorshSerialize, Serialize, Deserialize, Debug)]
pub enum ProtocolContractState {
    NotInitialized,
    Initializing(InitializingContractState),
    Running(RunningContractState),
    Resharing(ResharingContractState),
}

#[near_bindgen]
#[derive(BorshDeserialize, BorshSerialize, Debug)]
pub enum VersionedMpcContract {
    V0(MpcContract),
}

impl Default for VersionedMpcContract {
    fn default() -> Self {
        env::panic_str("Calling default not allowed.");
    }
}

#[derive(BorshDeserialize, BorshSerialize, Debug)]
pub struct MpcContract {
    protocol_state: ProtocolContractState,
    pending_requests: LookupMap<[u8; 32], Option<(String, String)>>,
    request_counter: u32,
}

impl MpcContract {
    fn add_request(&mut self, payload: &[u8; 32], signature: &Option<(String, String)>) {
        if self.request_counter > 8 {
            env::panic_str("Too many pending requests. Please, try again later.");
        }
        if !self.pending_requests.contains_key(payload) {
            self.request_counter += 1;
        }
        self.pending_requests.insert(payload, signature);
    }

    fn remove_request(&mut self, payload: &[u8; 32]) {
        self.pending_requests.remove(payload);
        self.request_counter -= 1;
    }

    fn add_signature(&mut self, payload: &[u8; 32], signature: (String, String)) {
        if self.pending_requests.contains_key(payload) {
            self.pending_requests.insert(payload, &Some(signature));
        }
    }

    fn clean_payloads(&mut self, payloads: Vec<[u8; 32]>, counter: u32) {
        log!("clean_payloads");
        for payload in payloads.iter() {
            self.pending_requests.remove(payload);
        }
        self.request_counter = counter;
    }

    pub fn init(threshold: usize, candidates: BTreeMap<AccountId, CandidateInfo>) -> Self {
        MpcContract {
            protocol_state: ProtocolContractState::Initializing(InitializingContractState {
                candidates: Candidates { candidates },
                threshold,
                pk_votes: PkVotes::new(),
            }),
            pending_requests: LookupMap::new(b"m"),
            request_counter: 0,
        }
    }
}

#[near_bindgen]
impl VersionedMpcContract {
    #[init]
    pub fn init(threshold: usize, candidates: BTreeMap<AccountId, CandidateInfo>) -> Self {
        log!(
            "init: signer={}, treshhold={}, candidates={}",
            env::signer_account_id(),
            threshold,
            serde_json::to_string(&candidates).unwrap()
        );
        Self::V0(MpcContract::init(threshold, candidates))
    }

    // This function can be used to transfer the MPC network to a new contract.
    #[init]
    pub fn init_running(
        epoch: u64,
        participants: BTreeMap<AccountId, ParticipantInfo>,
        threshold: usize,
        public_key: PublicKey,
    ) -> Self {
        log!(
            "init_running: signer={}, epoch={}, participants={}, threshold={}, public_key={:?}",
            env::signer_account_id(),
            epoch,
            serde_json::to_string(&participants).unwrap(),
            threshold,
            public_key
        );
        Self::V0(MpcContract {
            protocol_state: ProtocolContractState::Running(RunningContractState {
                epoch,
                participants: Participants { participants },
                threshold,
                public_key,
                candidates: Candidates::new(),
                join_votes: Votes::new(),
                leave_votes: Votes::new(),
            }),
            pending_requests: LookupMap::new(b"m"),
            request_counter: 0,
        })
    }

    /// Key versions refer new versions of the root key that we may choose to generate on cohort changes
    /// Older key versions will always work but newer key versions were never held by older signers
    /// Newer key versions may also add new security features, like only existing within a secure enclave
    /// Currently only 0 is a valid key version
    pub const fn latest_key_version(&self) -> u32 {
        0
    }

    pub fn state(self) -> ProtocolContractState {
        match self {
            Self::V0(mpc_contract) => mpc_contract.protocol_state,
        }
    }

    fn mutable_state(&mut self) -> &mut ProtocolContractState {
        match self {
            Self::V0(ref mut mpc_contract) => &mut mpc_contract.protocol_state,
        }
    }

    pub fn join(
        &mut self,
        url: String,
        cipher_pk: primitives::hpke::PublicKey,
        sign_pk: PublicKey,
    ) {
        log!(
            "join: signer={}, url={}, cipher_pk={:?}, sign_pk={:?}",
            env::signer_account_id(),
            url,
            cipher_pk,
            sign_pk
        );
        let protocol_state = self.mutable_state();
        match protocol_state {
            ProtocolContractState::Running(RunningContractState {
                participants,
                ref mut candidates,
                ..
            }) => {
                let signer_account_id = env::signer_account_id();
                if participants.contains_key(&signer_account_id) {
                    env::panic_str("this participant is already in the participant set");
                }
                candidates.insert(
                    signer_account_id.clone(),
                    CandidateInfo {
                        account_id: signer_account_id,
                        url,
                        cipher_pk,
                        sign_pk,
                    },
                );
            }
            _ => env::panic_str("protocol state can't accept new participants right now"),
        }
    }

    pub fn vote_join(&mut self, candidate_account_id: AccountId) -> bool {
        log!(
            "vote_join: signer={}, candidate_account_id={}",
            env::signer_account_id(),
            candidate_account_id
        );
        let protocol_state = self.mutable_state();
        match protocol_state {
            ProtocolContractState::Running(RunningContractState {
                epoch,
                participants,
                threshold,
                public_key,
                candidates,
                join_votes,
                ..
            }) => {
                let signer_account_id = env::signer_account_id();
                if !participants.contains_key(&signer_account_id) {
                    env::panic_str("calling account is not in the participant set");
                }
                let candidate_info = candidates
                    .get(&candidate_account_id)
                    .unwrap_or_else(|| env::panic_str("candidate is not registered"));
                let voted = join_votes.entry(candidate_account_id.clone());
                voted.insert(signer_account_id);
                if voted.len() >= *threshold {
                    let mut new_participants = participants.clone();
                    new_participants
                        .insert(candidate_account_id.clone(), candidate_info.clone().into());
                    *protocol_state = ProtocolContractState::Resharing(ResharingContractState {
                        old_epoch: *epoch,
                        old_participants: participants.clone(),
                        new_participants,
                        threshold: *threshold,
                        public_key: public_key.clone(),
                        finished_votes: HashSet::new(),
                    });
                    true
                } else {
                    false
                }
            }
            _ => env::panic_str("protocol state can't accept new participants right now"),
        }
    }

    pub fn vote_leave(&mut self, kick: AccountId) -> bool {
        log!(
            "vote_leave: signer={}, kick={}",
            env::signer_account_id(),
            kick
        );
        let protocol_state = self.mutable_state();
        match protocol_state {
            ProtocolContractState::Running(RunningContractState {
                epoch,
                participants,
                threshold,
                public_key,
                leave_votes,
                ..
            }) => {
                let signer_account_id = env::signer_account_id();
                if !participants.contains_key(&signer_account_id) {
                    env::panic_str("calling account is not in the participant set");
                }
                if !participants.contains_key(&kick) {
                    env::panic_str("account to leave is not in the participant set");
                }
                if participants.len() <= *threshold {
                    env::panic_str("the number of participants can not go below the threshold");
                }
                let voted = leave_votes.entry(kick.clone());
                voted.insert(signer_account_id);
                if voted.len() >= *threshold {
                    let mut new_participants = participants.clone();
                    new_participants.remove(&kick);
                    *protocol_state = ProtocolContractState::Resharing(ResharingContractState {
                        old_epoch: *epoch,
                        old_participants: participants.clone(),
                        new_participants,
                        threshold: *threshold,
                        public_key: public_key.clone(),
                        finished_votes: HashSet::new(),
                    });
                    true
                } else {
                    false
                }
            }
            _ => env::panic_str("protocol state can't kick participants right now"),
        }
    }

    pub fn vote_pk(&mut self, public_key: PublicKey) -> bool {
        log!(
            "vote_pk: signer={}, public_key={:?}",
            env::signer_account_id(),
            public_key
        );
        let protocol_state = self.mutable_state();
        match protocol_state {
            ProtocolContractState::Initializing(InitializingContractState {
                candidates,
                threshold,
                pk_votes,
            }) => {
                let signer_account_id = env::signer_account_id();
                if !candidates.contains_key(&signer_account_id) {
                    env::panic_str("calling account is not in the participant set");
                }
                let voted = pk_votes.entry(public_key.clone());
                voted.insert(signer_account_id);
                if voted.len() >= *threshold {
                    *protocol_state = ProtocolContractState::Running(RunningContractState {
                        epoch: 0,
                        participants: candidates.clone().into(),
                        threshold: *threshold,
                        public_key,
                        candidates: Candidates::new(),
                        join_votes: Votes::new(),
                        leave_votes: Votes::new(),
                    });
                    true
                } else {
                    false
                }
            }
            ProtocolContractState::Running(state) if state.public_key == public_key => true,
            ProtocolContractState::Resharing(state) if state.public_key == public_key => true,
            _ => env::panic_str("can't change public key anymore"),
        }
    }

    pub fn vote_reshared(&mut self, epoch: u64) -> bool {
        log!(
            "vote_reshared: signer={}, epoch={}",
            env::signer_account_id(),
            epoch
        );
        let protocol_state = self.mutable_state();
        match protocol_state {
            ProtocolContractState::Resharing(ResharingContractState {
                old_epoch,
                old_participants,
                new_participants,
                threshold,
                public_key,
                finished_votes,
            }) => {
                if *old_epoch + 1 != epoch {
                    env::panic_str("mismatched epochs");
                }
                let signer_account_id = env::signer_account_id();
                if !old_participants.contains_key(&signer_account_id) {
                    env::panic_str("calling account is not in the old participant set");
                }
                finished_votes.insert(signer_account_id);
                if finished_votes.len() >= *threshold {
                    *protocol_state = ProtocolContractState::Running(RunningContractState {
                        epoch: *old_epoch + 1,
                        participants: new_participants.clone(),
                        threshold: *threshold,
                        public_key: public_key.clone(),
                        candidates: Candidates::new(),
                        join_votes: Votes::new(),
                        leave_votes: Votes::new(),
                    });
                    true
                } else {
                    false
                }
            }
            ProtocolContractState::Running(state) => {
                if state.epoch == epoch {
                    true
                } else {
                    env::panic_str("protocol is not resharing right now")
                }
            }
            _ => env::panic_str("protocol is not resharing right now"),
        }
    }

    fn signature_per_payload(&self, payload: [u8; 32]) -> Option<Option<(String, String)>> {
        match self {
            Self::V0(mpc_contract) => mpc_contract.pending_requests.get(&payload),
        }
    }

    fn remove_request(&mut self, payload: &[u8; 32]) {
        match self {
            Self::V0(mpc_contract) => {
                mpc_contract.remove_request(payload);
            }
        }
    }

    fn add_request(&mut self, payload: &[u8; 32], signature: &Option<(String, String)>) {
        match self {
            Self::V0(mpc_contract) => {
                mpc_contract.add_request(payload, signature);
            }
        }
    }

    fn add_signature(&mut self, payload: &[u8; 32], signature: (String, String)) {
        match self {
            Self::V0(mpc_contract) => {
                mpc_contract.add_signature(payload, signature);
            }
        }
    }

    #[private]
    pub fn sign_helper(
        &mut self,
        payload: [u8; 32],
        depth: usize,
    ) -> PromiseOrValue<(String, String)> {
        if let Some(signature) = self.signature_per_payload(payload) {
            match signature {
                Some(signature) => {
                    log!(
                        "sign_helper: signature ready: {:?}, depth: {:?}",
                        signature,
                        depth
                    );
                    self.remove_request(&payload);
                    PromiseOrValue::Value(signature)
                }
                None => {
                    // Make sure we have enough gas left to do 1 more call and clean up afterwards
                    // Observationally 30 calls < 300 TGas so 2 calls < 20 TGas
                    // We keep one call back so we can cleanup then call panic on the next call
                    // Start cleaning up if there's less than 25 teragas left regardless of how deep you are.
                    if depth > 30 || env::prepaid_gas() < Gas::from_tgas(25) {
                        self.remove_request(&payload);
                        let self_id = env::current_account_id();
                        PromiseOrValue::Promise(Self::ext(self_id).fail_helper(
                            "Signature was not provided in time. Please, try again.".to_string(),
                        ))
                    } else {
                        log!(&format!(
                            "sign_helper: signature not ready yet (depth={})",
                            depth
                        ));
                        let account_id = env::current_account_id();
                        PromiseOrValue::Promise(
                            Self::ext(account_id).sign_helper(payload, depth + 1),
                        )
                    }
                }
            }
        } else {
            env::panic_str("unexpected request")
        }
    }

    /// This allows us to return a panic, without rolling back the state from this call
    #[private]
    pub fn fail_helper(&mut self, message: String) {
        env::panic_str(&message);
    }

    #[allow(unused_variables)]
    /// `key_version` must be less than or equal to the value at `latest_key_version`
    pub fn sign(&mut self, payload: [u8; 32], path: String, key_version: u32) -> Promise {
        let latest_key_version: u32 = self.latest_key_version();
        assert!(
            key_version <= latest_key_version,
            "This version of the signer contract doesn't support versions greater than {}",
            latest_key_version,
        );
        // Make sure sign call will not run out of gas doing recursive calls because the payload will never be removed
        assert!(
            env::prepaid_gas() >= GAS_FOR_SIGN_CALL,
            "Insufficient gas provided. Provided: {} Required: {}",
            env::prepaid_gas(),
            GAS_FOR_SIGN_CALL
        );
        log!(
            "sign: signer={}, payload={:?}, path={:?}, key_version={}",
            env::signer_account_id(),
            payload,
            path,
            key_version
        );
        match self.signature_per_payload(payload) {
            None => {
                self.add_request(&payload, &None);
                log!(&serde_json::to_string(&near_sdk::env::random_seed_array()).unwrap());
                Self::ext(env::current_account_id()).sign_helper(payload, 0)
            }
            Some(_) => env::panic_str("Signature for this payload already requested"),
        }
    }

    pub fn version(&self) -> String {
        env!("CARGO_PKG_VERSION").to_string()
    }

    pub fn respond(&mut self, payload: [u8; 32], big_r: String, s: String) {
        let protocol_state = self.mutable_state();
        if let ProtocolContractState::Running(state) = protocol_state {
            let signer = env::signer_account_id();
            if state.participants.contains_key(&signer) {
                log!(
                    "respond: signer={}, payload={:?} big_r={} s={}",
                    signer,
                    payload,
                    big_r,
                    s
                );
                self.add_signature(&payload, (big_r, s));
            } else {
                env::panic_str("only participants can respond");
            }
        } else {
            env::panic_str("protocol is not in a running state");
        }
    }

    #[private]
    #[init(ignore_state)]
    pub fn clean(keys: Vec<near_sdk::json_types::Base64VecU8>) -> Self {
        log!("clean: keys={:?}", keys);
        for key in keys.iter() {
            env::storage_remove(&key.0);
        }
        Self::V0(MpcContract {
            protocol_state: ProtocolContractState::NotInitialized,
            pending_requests: LookupMap::new(b"m"),
            request_counter: 0,
        })
    }

    #[private]
    pub fn clean_payloads(&mut self, payloads: Vec<[u8; 32]>, counter: u32) {
        match self {
            Self::V0(mpc_contract) => {
                mpc_contract.clean_payloads(payloads, counter);
            }
        }
    }

    /// This is the root public key combined from all the public keys of the participants.
    pub fn public_key(self) -> PublicKey {
        match self.state() {
            ProtocolContractState::Running(state) => state.public_key.clone(),
            ProtocolContractState::Resharing(state) => state.public_key.clone(),
            _ => env::panic_str("public key not available (protocol is not running or resharing)"),
        }
    }

    #[private]
    #[init(ignore_state)]
    pub fn migrate_state_old_to_v0() -> Self {
        let old_contract: MpcContract = env::state_read().expect("Old state doesn't exist");
        Self::V0(MpcContract {
            protocol_state: old_contract.protocol_state,
            pending_requests: old_contract.pending_requests,
            request_counter: old_contract.request_counter,
        })
    }
}

'''
'''--- contract/src/primitives.rs ---
use near_sdk::borsh::{self, BorshDeserialize, BorshSerialize};
use near_sdk::serde::{Deserialize, Serialize};
use near_sdk::{AccountId, PublicKey};
use std::collections::{BTreeMap, HashSet};

pub mod hpke {
    pub type PublicKey = [u8; 32];
}

#[derive(
    Serialize,
    Deserialize,
    BorshDeserialize,
    BorshSerialize,
    Clone,
    Hash,
    PartialEq,
    Eq,
    PartialOrd,
    Ord,
    Debug,
)]
pub struct ParticipantInfo {
    pub account_id: AccountId,
    pub url: String,
    /// The public key used for encrypting messages.
    pub cipher_pk: hpke::PublicKey,
    /// The public key used for verifying messages.
    pub sign_pk: PublicKey,
}

impl From<CandidateInfo> for ParticipantInfo {
    fn from(candidate_info: CandidateInfo) -> Self {
        ParticipantInfo {
            account_id: candidate_info.account_id,
            url: candidate_info.url,
            cipher_pk: candidate_info.cipher_pk,
            sign_pk: candidate_info.sign_pk,
        }
    }
}

#[derive(
    Serialize,
    Deserialize,
    BorshDeserialize,
    BorshSerialize,
    Clone,
    Hash,
    PartialEq,
    Eq,
    PartialOrd,
    Ord,
    Debug,
)]
pub struct CandidateInfo {
    pub account_id: AccountId,
    pub url: String,
    /// The public key used for encrypting messages.
    pub cipher_pk: hpke::PublicKey,
    /// The public key used for verifying messages.
    pub sign_pk: PublicKey,
}

#[derive(BorshDeserialize, BorshSerialize, Serialize, Deserialize, Debug, Clone)]
pub struct Participants {
    pub participants: BTreeMap<AccountId, ParticipantInfo>,
}

impl Default for Participants {
    fn default() -> Self {
        Self::new()
    }
}

impl From<Candidates> for Participants {
    fn from(candidates: Candidates) -> Self {
        let mut participants = Participants::new();
        for (account_id, candidate_info) in candidates.iter() {
            participants.insert(account_id.clone(), candidate_info.clone().into());
        }
        participants
    }
}

impl Participants {
    pub fn new() -> Self {
        Participants {
            participants: BTreeMap::new(),
        }
    }

    pub fn contains_key(&self, account_id: &AccountId) -> bool {
        self.participants.contains_key(account_id)
    }

    pub fn insert(&mut self, account_id: AccountId, participant_info: ParticipantInfo) {
        self.participants.insert(account_id, participant_info);
    }

    pub fn remove(&mut self, account_id: &AccountId) {
        self.participants.remove(account_id);
    }

    pub fn get(&self, account_id: &AccountId) -> Option<&ParticipantInfo> {
        self.participants.get(account_id)
    }

    pub fn iter(&self) -> impl Iterator<Item = (&AccountId, &ParticipantInfo)> {
        self.participants.iter()
    }

    pub fn keys(&self) -> impl Iterator<Item = &AccountId> {
        self.participants.keys()
    }

    pub fn len(&self) -> usize {
        self.participants.len()
    }

    pub fn is_empty(&self) -> bool {
        self.participants.is_empty()
    }
}

#[derive(BorshDeserialize, BorshSerialize, Serialize, Deserialize, Debug, Clone)]
pub struct Candidates {
    pub candidates: BTreeMap<AccountId, CandidateInfo>,
}

impl Default for Candidates {
    fn default() -> Self {
        Self::new()
    }
}

impl Candidates {
    pub fn new() -> Self {
        Candidates {
            candidates: BTreeMap::new(),
        }
    }

    pub fn contains_key(&self, account_id: &AccountId) -> bool {
        self.candidates.contains_key(account_id)
    }

    pub fn insert(&mut self, account_id: AccountId, candidate: CandidateInfo) {
        self.candidates.insert(account_id, candidate);
    }

    pub fn remove(&mut self, account_id: &AccountId) {
        self.candidates.remove(account_id);
    }

    pub fn get(&self, account_id: &AccountId) -> Option<&CandidateInfo> {
        self.candidates.get(account_id)
    }

    pub fn iter(&self) -> impl Iterator<Item = (&AccountId, &CandidateInfo)> {
        self.candidates.iter()
    }
}

#[derive(BorshDeserialize, BorshSerialize, Serialize, Deserialize, Debug)]
pub struct Votes {
    pub votes: BTreeMap<AccountId, HashSet<AccountId>>,
}

impl Default for Votes {
    fn default() -> Self {
        Self::new()
    }
}

impl Votes {
    pub fn new() -> Self {
        Votes {
            votes: BTreeMap::new(),
        }
    }

    pub fn entry(&mut self, account_id: AccountId) -> &mut HashSet<AccountId> {
        self.votes.entry(account_id).or_default()
    }
}

#[derive(BorshDeserialize, BorshSerialize, Serialize, Deserialize, Debug)]
pub struct PkVotes {
    pub votes: BTreeMap<PublicKey, HashSet<AccountId>>,
}

impl Default for PkVotes {
    fn default() -> Self {
        Self::new()
    }
}

impl PkVotes {
    pub fn new() -> Self {
        PkVotes {
            votes: BTreeMap::new(),
        }
    }

    pub fn entry(&mut self, public_key: PublicKey) -> &mut HashSet<AccountId> {
        self.votes.entry(public_key).or_default()
    }
}

'''
'''--- contract/tests/tests.rs ---
use mpc_contract::{primitives::CandidateInfo, MpcContract, VersionedMpcContract};
use near_sdk::env;
use near_workspaces::AccountId;
use std::collections::{BTreeMap, HashMap};

const CONTRACT_FILE_PATH: &str =
    "./../target/seperate_wasm/wasm32-unknown-unknown/release/mpc_contract.wasm";

#[tokio::test]
async fn test_contract_can_not_be_reinitialized() -> anyhow::Result<()> {
    let worker = near_workspaces::sandbox().await?;
    let wasm = std::fs::read(CONTRACT_FILE_PATH)?;
    let contract = worker.dev_deploy(&wasm).await?;

    let candidates: HashMap<AccountId, CandidateInfo> = HashMap::new();

    let result1 = contract
        .call("init")
        .args_json(serde_json::json!({
            "threshold": 2,
            "candidates": candidates
        }))
        .transact()
        .await?;

    assert!(result1.is_success());

    let result2 = contract
        .call("init")
        .args_json(serde_json::json!({
            "threshold": 2,
            "candidates": candidates
        }))
        .transact()
        .await?;

    assert!(result2.is_failure());

    Ok(())
}

#[test]
fn test_old_state_can_be_migrated_to_v0() -> anyhow::Result<()> {
    let old_contract = MpcContract::init(3, BTreeMap::new());
    env::state_write(&old_contract);

    let v0_contract = VersionedMpcContract::migrate_state_old_to_v0();
    let expected_contract = VersionedMpcContract::V0(old_contract);

    assert_eq!(
        format!("{v0_contract:#?}"),
        format!("{expected_contract:#?}")
    );

    Ok(())
}

'''
'''--- infra/README.md ---
# MPC Recovery Infrastructure Overview

There are currently 3 mostly static environments for MPC
 - Mainnet (production)
 - Testnet (production)
 - Dev (development)

 ## Mainnet/Testnet

 Mainnet and Testnet infra code is in the directory `mpc-recovery-prod` and is built off of the `main` GitHub Branch
   - This environment should be deployed via the GHA pipeline `deploy-prod.yml` manually in order to prevent unwanted changes
   - Both Mainnet and Testnet are treated as production environments

 ## Dev

 The Dev environment infra code is located in the `mpc-recovery-dev` directory and is built off of the `develop` GitHub Branch
   - This should be used as the main development environment
   - Every time a pull request is opened up against the `develop` branch, a new, ephemeral environment is created with your changes
     - *Note: These environments will have the associated PR number appended to all resources*
   - When a pull request is approved and merged into the `develop` branch, a new revision is deployed to the static Dev environment with the PRs changes and the PRs ephemeral environment is destroyed
'''
'''--- infra/mpc-recovery-dev/migration.py ---
from google.oauth2 import service_account
from google.cloud import datastore

credentials_source = service_account.Credentials.from_service_account_file(
    '../source-service-keys.json')
client_source = datastore.Client(project="pagoda-discovery-platform-dev", credentials=credentials_source)

credentials_target = service_account.Credentials.from_service_account_file(
    '../target-service-keys.json')
client_target = datastore.Client(project="pagoda-discovery-platform-prod", credentials=credentials_target)

print('Fetching source entities')
query = credentials_source.query(kind="EncryptedUserCredentials-dev")
entities = []
for entity in list(query.fetch()):
    entity.key = client_target.key('EncryptedUserCredentials-mainnet').completed_key(entity.key.id_or_name)
    print(entity.key)
    print(entity)
    entities.append(entity)

print("Uploading a total of " + str(len(entities)) + " entities to target")
client_target.put_multi(entities)
'''
'''--- infra/scripts/generate_cipher_keys/Cargo.toml ---
[package]
name = "generate_cipher_keys"
version = "0.1.0"
edition = "2021"

# See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html

[dependencies]
hex = "0.4.3"
mpc-keys = { path = "../../../keys" }

[workspace]
'''
'''--- infra/scripts/generate_cipher_keys/src/main.rs ---
use mpc_keys::hpke;

fn main() {
    let (cipher_sk, cipher_pk) = hpke::generate();
    let cipher_pk = hex::encode(cipher_pk.to_bytes());
    let cipher_sk = hex::encode(cipher_sk.to_bytes());
    println!("cipher public key: {}", cipher_pk);
    println!("cipher private key: {}", cipher_sk);
}

'''
'''--- infra/scripts/get_sha.sh ---
#!/bin/bash
set -euo pipefail

echo '{"sha": "'"$(git rev-parse HEAD)"'"}'

'''
'''--- integration-tests/Cargo.toml ---
[package]
name = "mpc-recovery-integration-tests"
version = "0.1.0"
edition = "2021"
publish = false

[dependencies]
aes-gcm = "0.10"
anyhow = { version = "1.0", features = ["backtrace"] }
async-process = "1"
aws-config = "0.54.0"
aws-sdk-s3 = "0.24.0"
aws-types = "0.54.0"
bollard = "0.13"
cait-sith = { git = "https://github.com/LIT-Protocol/cait-sith.git", features = [
    "k256",
], rev = "8ad2316"}
clap = { version = "4.2", features = ["derive", "env"] }
curv = { package = "curv-kzen", version = "0.9", default-features = false }
ed25519-dalek = { version = "1.0.1", features = ["serde"] }
futures = "0.3"
hex = "0.4.3"
hyper = { version = "0.14", features = ["full"] }
k256 = { version = "0.13.1", features = ["sha256", "ecdsa", "serde"] }
multi-party-eddsa = { git = "https://github.com/DavidM-D/multi-party-eddsa.git", rev = "25ae4fdc5ff7819ae70e73ab4afacf1c24fc4da1" }
tracing = "0.1"
nix = { version = "0.27", features = ["signal"] }
once_cell = "1"
rand = "0.7"
serde = "1"
serde_json = "1"
testcontainers = { version = "0.15", features = ["experimental"] }
tokio = { version = "1.28", features = ["full"] }
tracing-subscriber = { version = "0.3", features = ["env-filter"] }
near-workspaces = { git = "https://github.com/near/near-workspaces-rs.git", branch = "main" }
toml = "0.8.1"
sha2 = "0.10.8"

near-crypto = "0.17"
near-fetch = "0.0.12"
near-jsonrpc-client = "0.6"
near-primitives = "0.17.0"
near-lake-framework = { git = "https://github.com/near/near-lake-framework-rs.git", branch = "daniyar/upgrade-sdk" }
near-lake-primitives = { git = "https://github.com/near/near-lake-framework-rs.git", branch = "daniyar/upgrade-sdk" }

mpc-contract = { path = "../contract" }
mpc-keys = { path = "../keys" }
mpc-recovery = { path = "../mpc-recovery" }
mpc-recovery-node = { path = "../node" }

elliptic-curve = { version = "0.13.5", default-features = false }
generic-array = { version = "0.14.7", default-features = false }

[dev-dependencies]
backon = "0.4"
rand = "0.7"
rand8 = { package = "rand", version = "0.8" }
test-log = { version = "0.2.12", features = ["log", "trace"] }
env_logger = "0.10.0"
tracing-log = "0.1.3"
tokio-util = { version = "0.7", features = ["full"] }
reqwest = "0.11.16"
ecdsa = "0.16.9"
web3 = "0.19.0"
secp256k1 = "0.28.2"
ethers-core = "2.0.13"

[features]
default = []
docker-test = []
flamegraph = ["mpc-recovery/disable-open-telemetry"]

'''
'''--- integration-tests/README.md ---
# Integration tests

## Basic guide

Running integration tests requires you to have relayer and sandbox docker images present on your machine:

```BASH
docker pull ghcr.io/near/os-relayer
docker pull ghcr.io/near/sandbox
```

For M1 you may want to pull the following image instead:

```BASH
docker pull ghcr.io/near/sandbox:latest-aarch64
```

In case of authorization issues make sure you have logged into docker using your [access token](https://docs.github.com/en/packages/working-with-a-github-packages-registry/working-with-the-container-registry#authenticating-with-a-personal-access-token-classic).

Build OIDC Provider test image
```bash
docker build -t near/test-oidc-provider ./test-oidc-provider
```

Set dummy AWS credentials and the correct region

``` bash
aws configure set region us-east-1
aws --profile default configure set aws_access_key_id "123"
aws --profile default configure set aws_secret_access_key "456"
```

Then run the integration tests:

```BASH
cargo test -p mpc-recovery-integration-tests
```

### Alternative: Docker Builds/Tests

If instead, we need to run docker build/tests:

```BASH
docker build . -t near/mpc-recovery
```

**Note**. You will need to re-build the Docker image each time you make a code change and want to run the integration tests.

Finally, run the integration tests with the built docker image:

```BASH
cargo test -p mpc-recovery-integration-tests --features docker-test
```

## Profiling: Flamegraphs

To profile code and get a flamegraph, run the following:

```sh
cargo flamegraph --root --profile flamegraph --test lib
```

Or for a singular test like `test_basic_action`:

```sh
cargo flamegraph --root --profile flamegraph --test lib -- test_basic_action
```

This will generate a `flamegraph.svg`. Open this on a browser and inspect each of the callstacks.

## FAQ

### I want to run a test, but keep the docker containers from being destroyed

You can pass environment variable `TESTCONTAINERS=keep` to keep all of the docker containers. For example:

```bash
$ TESTCONTAINERS=keep cargo test -p mpc-recovery-integration-tests
```

### There are no logs anymore, how do I debug?

The easiest way is to run one isolated test of your choosing while keeping the containers (see above):

```bash
$ TESTCONTAINERS=keep cargo test -p mpc-recovery-integration-tests test_basic_action
```

Now, you can do `docker ps` and it should list all of containers related to your test (the most recent ones are always at the top, so lookout for those). For example:

```bash
CONTAINER ID   IMAGE                                            COMMAND                  CREATED         STATUS         PORTS                                           NAMES
b2724d0c9530   near/mpc-recovery:latest                         "mpc-recovery start-‚Ä¶"   5 minutes ago   Up 5 minutes   0.0.0.0:32792->19985/tcp, :::32792->19985/tcp   fervent_moore
67308ab06c5d   near/mpc-recovery:latest                         "mpc-recovery start-‚Ä¶"   5 minutes ago   Up 5 minutes   0.0.0.0:32791->3000/tcp, :::32791->3000/tcp     upbeat_volhard
65ec65384af4   near/mpc-recovery:latest                         "mpc-recovery start-‚Ä¶"   5 minutes ago   Up 5 minutes   0.0.0.0:32790->3000/tcp, :::32790->3000/tcp     friendly_easley
b4f90b1546ec   near/mpc-recovery:latest                         "mpc-recovery start-‚Ä¶"   5 minutes ago   Up 5 minutes   0.0.0.0:32789->3000/tcp, :::32789->3000/tcp     vibrant_allen
934ec13d9146   ghcr.io/near/os-relayer:latest                   "/usr/local/bin/entr‚Ä¶"   5 minutes ago   Up 5 minutes   0.0.0.0:32788->16581/tcp, :::32788->16581/tcp   sleepy_grothendieck
c505ead6eb18   redis:latest                                     "docker-entrypoint.s‚Ä¶"   5 minutes ago   Up 5 minutes   0.0.0.0:32787->6379/tcp, :::32787->6379/tcp     trusting_lederberg
2843226b16a9   google/cloud-sdk:latest                          "gcloud beta emulato‚Ä¶"   5 minutes ago   Up 5 minutes   0.0.0.0:32786->15805/tcp, :::32786->15805/tcp   hungry_pasteur
3f4c70020a4c   ghcr.io/near/sandbox:latest                      "near-sandbox --home‚Ä¶"   5 minutes ago   Up 5 minutes                                                   practical_elbakyan
```

Now, you can inspect each container's logs according to your needs using `docker logs <container-id>`. You might also want to reproduce some components of the test manually by making `curl` requests to the leader node (its web port is exposed on your host machine, use `docker ps` output above as the reference).

### Re-building Docker image is way too slow, is there a way I can do a faster development feedback loop?

We have a CLI tool that can instantiate a short-lived development environment that has everything except for the leader node set up. You can then seamlessly plug in your own leader node instance that you have set up manually (the tool gives you a CLI command to use as a starting point, but you can attach debugger, enable extra logs etc). Try it out now (sets up 3 signer nodes):

```bash
$ export RUST_LOG=info
$ cargo run -p mpc-recovery-integration-tests -- setup-env 3
```

### I'm getting "Error: error trying to connect: No such file or directory (os error 2)"

It's a known issue on MacOS. Try executiong the following command:

```bash
sudo ln -s $HOME/.docker/run/docker.sock /var/run/docker.sock
```

'''
'''--- integration-tests/build.rs ---
// HACK: need this build script so that env var OUT_DIR gets set:
// https://doc.rust-lang.org/cargo/reference/environment-variables.html#environment-variables-cargo-sets-for-crates
fn main() {}

'''
'''--- integration-tests/src/env/containers.rs ---
#![allow(clippy::too_many_arguments)]

use aes_gcm::{Aes256Gcm, KeyInit};
use anyhow::anyhow;
use bollard::{container::LogsOptions, network::CreateNetworkOptions, service::Ipam, Docker};
use ed25519_dalek::ed25519::signature::digest::{consts::U32, generic_array::GenericArray};
use ed25519_dalek::{PublicKey as PublicKeyEd25519, Verifier};
use futures::{lock::Mutex, StreamExt};
use hyper::StatusCode;
use mpc_recovery::firewall::allowed::DelegateActionRelayer;
use mpc_recovery::logging;
use mpc_recovery::sign_node::oidc::OidcToken;
use mpc_recovery::{
    msg::{
        AcceptNodePublicKeysRequest, ClaimOidcRequest, ClaimOidcResponse, MpcPkRequest,
        MpcPkResponse, NewAccountRequest, NewAccountResponse, SignRequest, SignResponse,
        UserCredentialsRequest, UserCredentialsResponse,
    },
    relayer::NearRpcAndRelayerClient,
    transaction::{CreateAccountOptions, LimitedAccessKey},
    utils::{
        claim_oidc_request_digest, claim_oidc_response_digest, sign_digest, sign_request_digest,
        user_credentials_request_digest,
    },
};
use multi_party_eddsa::protocols::ExpandedKeyPair;
use near_crypto::{PublicKey, SecretKey};
use near_primitives::account::{AccessKey, AccessKeyPermission};
use near_primitives::borsh::BorshSerialize;
use near_primitives::delegate_action::{DelegateAction, SignedDelegateAction};
use near_primitives::transaction::{Action, AddKeyAction, DeleteKeyAction};
use near_primitives::views::FinalExecutionStatus;
use near_workspaces::AccountId;
use once_cell::sync::Lazy;
use testcontainers::{
    clients::Cli,
    core::{ExecCommand, WaitFor},
    Container, GenericImage, Image, RunnableImage,
};
use tokio::io::AsyncWriteExt;
use tracing;

use std::fs;

use crate::env::{Context, LeaderNodeApi, SignerNodeApi};
use crate::util::{
    self, create_key_file, create_key_file_with_filepath, create_relayer_cofig_file,
};
use bollard::exec::CreateExecOptions;

static NETWORK_MUTEX: Lazy<Mutex<i32>> = Lazy::new(|| Mutex::new(0));

pub struct DockerClient {
    pub docker: Docker,
    pub cli: Cli,
}

impl DockerClient {
    pub async fn get_network_ip_address<I: Image>(
        &self,
        container: &Container<'_, I>,
        network: &str,
    ) -> anyhow::Result<String> {
        let network_settings = self
            .docker
            .inspect_container(container.id(), None)
            .await?
            .network_settings
            .ok_or_else(|| anyhow!("missing NetworkSettings on container '{}'", container.id()))?;
        let ip_address = network_settings
            .networks
            .ok_or_else(|| {
                anyhow!(
                    "missing NetworkSettings.Networks on container '{}'",
                    container.id()
                )
            })?
            .get(network)
            .cloned()
            .ok_or_else(|| {
                anyhow!(
                    "container '{}' is not a part of network '{}'",
                    container.id(),
                    network
                )
            })?
            .ip_address
            .ok_or_else(|| {
                anyhow!(
                    "container '{}' belongs to network '{}', but is not assigned an IP address",
                    container.id(),
                    network
                )
            })?;

        Ok(ip_address)
    }

    pub async fn create_network(&self, network: &str) -> anyhow::Result<()> {
        let _lock = &NETWORK_MUTEX.lock().await;
        let list = self.docker.list_networks::<&str>(None).await?;
        if list.iter().any(|n| n.name == Some(network.to_string())) {
            return Ok(());
        }

        let create_network_options = CreateNetworkOptions {
            name: network,
            check_duplicate: true,
            driver: if cfg!(windows) {
                "transparent"
            } else {
                "bridge"
            },
            ipam: Ipam {
                config: None,
                ..Default::default()
            },
            ..Default::default()
        };
        let _response = &self.docker.create_network(create_network_options).await?;

        Ok(())
    }

    pub async fn continuously_print_logs(&self, id: &str) -> anyhow::Result<()> {
        let mut output = self.docker.logs::<String>(
            id,
            Some(LogsOptions {
                follow: true,
                stdout: true,
                stderr: true,
                ..Default::default()
            }),
        );

        // Asynchronous process that pipes docker attach output into stdout.
        // Will die automatically once Docker container output is closed.
        tokio::spawn(async move {
            let mut stdout = tokio::io::stdout();

            while let Some(Ok(output)) = output.next().await {
                stdout
                    .write_all(output.into_bytes().as_ref())
                    .await
                    .unwrap();
                stdout.flush().await.unwrap();
            }
        });

        Ok(())
    }
}

impl Default for DockerClient {
    fn default() -> Self {
        Self {
            docker: Docker::connect_with_local(
                "unix:///var/run/docker.sock",
                // 10 minutes timeout for all requests in case a lot of tests are being ran in parallel.
                600,
                bollard::API_DEFAULT_VERSION,
            )
            .unwrap(),
            cli: Default::default(),
        }
    }
}

pub struct Redis<'a> {
    pub container: Container<'a, GenericImage>,
    pub address: String,
    pub full_address: String,
    pub local_address: String,
}

impl<'a> Redis<'a> {
    const CONTAINER_PORT: u16 = 3000;

    pub async fn run(docker_client: &'a DockerClient, network: &str) -> anyhow::Result<Redis<'a>> {
        tracing::info!("Running Redis container...");
        let image = GenericImage::new("redis", "latest")
            .with_exposed_port(Self::CONTAINER_PORT)
            .with_wait_for(WaitFor::message_on_stdout("Ready to accept connections"));
        let image: RunnableImage<GenericImage> = image.into();
        let image = image.with_network(network);
        let container = docker_client.cli.run(image);
        let address = docker_client
            .get_network_ip_address(&container, network)
            .await?;

        // Note: this port is hardcoded in the Redis image
        let full_address = format!("redis://{}:{}", address, 6379);
        let host_port = container.get_host_port_ipv4(Self::CONTAINER_PORT);

        tracing::info!("Redis container is running at {}", full_address);
        Ok(Redis {
            container,
            address,
            full_address,
            local_address: format!("http://127.0.0.1:{host_port}"),
        })
    }
}

pub struct Sandbox<'a> {
    pub container: Container<'a, GenericImage>,
    pub address: String,
    pub local_address: String,
}

impl<'a> Sandbox<'a> {
    pub const CONTAINER_RPC_PORT: u16 = 3000;
    pub const CONTAINER_NETWORK_PORT: u16 = 3001;

    pub async fn run(
        docker_client: &'a DockerClient,
        network: &str,
    ) -> anyhow::Result<Sandbox<'a>> {
        tracing::info!("Running sandbox container...");
        #[cfg(all(target_os = "macos", target_arch = "aarch64"))]
        let image = GenericImage::new("ghcr.io/near/sandbox", "latest-aarch64")
            .with_wait_for(WaitFor::Nothing)
            .with_exposed_port(Self::CONTAINER_RPC_PORT);
        #[cfg(target_arch = "x86_64")]
        let image = GenericImage::new("ghcr.io/near/sandbox", "latest")
            .with_wait_for(WaitFor::Nothing)
            .with_exposed_port(Self::CONTAINER_RPC_PORT);
        let image: RunnableImage<GenericImage> = (
            image,
            vec![
                "--rpc-addr".to_string(),
                format!("0.0.0.0:{}", Self::CONTAINER_RPC_PORT),
                "--network-addr".to_string(),
                format!("0.0.0.0:{}", Self::CONTAINER_NETWORK_PORT),
            ],
        )
            .into();
        let image = image.with_network(network);
        let container = docker_client.cli.run(image);
        let address = docker_client
            .get_network_ip_address(&container, network)
            .await?;
        let host_port = container.get_host_port_ipv4(Self::CONTAINER_RPC_PORT);

        container.exec(ExecCommand {
            cmd: format!(
                "bash -c 'while [[ \"$(curl -H \"Content-type: application/json\" -X POST -s -o /dev/null -w ''%{{http_code}}'' -d ''{{
                \"jsonrpc\": \"2.0\",
                \"id\": \"dontcare\",
                \"method\": \"status\",
                \"params\": []
              }}'' localhost:{})\" != \"200\" ]]; do sleep 1; done; echo \"sandbox is ready to accept connections\"'",
                Self::CONTAINER_RPC_PORT
            ),
            ready_conditions: vec![WaitFor::StdErrMessage { message: "ready".to_string() }]
        });

        let full_address = format!("http://{}:{}", address, Self::CONTAINER_RPC_PORT);
        tracing::info!("Sandbox container is running at {}", full_address);
        Ok(Sandbox {
            container,
            address: full_address,
            local_address: format!("http://127.0.0.1:{host_port}"),
        })
    }
}

pub struct Relayer<'a> {
    pub id: String,
    pub container: Container<'a, GenericImage>,
    pub address: String,
    pub local_address: String,
}

pub struct RelayerConfig {
    pub ip_address: [u8; 4],
    pub port: u16,
    pub relayer_account_id: AccountId,
    pub keys_filenames: Vec<String>,
    pub shared_storage_account_id: AccountId,
    pub shared_storage_keys_filename: String,
    pub whitelisted_contracts: Vec<AccountId>,
    pub whitelisted_delegate_action_receiver_ids: Vec<AccountId>,
    pub redis_url: String,
    pub social_db_contract_id: AccountId,
    pub rpc_url: String,
    pub wallet_url: String,
    pub explorer_transaction_url: String,
    pub rpc_api_key: String,
}

impl<'a> Relayer<'a> {
    pub const CONTAINER_PORT: u16 = 3000;
    pub const TMP_FOLDER_PATH: &'static str = "./tmp";

    pub async fn run(
        docker_client: &'a DockerClient,
        network: &str,
        near_rpc: &str,
        redis_full_address: &str,
        relayer_account_id: &AccountId,
        relayer_account_sks: &[near_workspaces::types::SecretKey],
        creator_account_id: &AccountId,
        social_db_id: &AccountId,
        social_account_id: &AccountId,
        social_account_sk: &near_workspaces::types::SecretKey,
        relayer_id: &str,
    ) -> anyhow::Result<Relayer<'a>> {
        tracing::info!("Running relayer container...");

        // Create tmp folder to store relayer configs
        let relayer_configs_path = format!("{}/{}", Self::TMP_FOLDER_PATH, relayer_id);
        std::fs::create_dir_all(&relayer_configs_path)
            .unwrap_or_else(|_| panic!("Failed to create {relayer_configs_path} directory"));

        // Create dir for keys
        let key_dir = format!("{relayer_configs_path}/account_keys");
        std::fs::create_dir_all(&key_dir).expect("Failed to create account_keys directory");
        let keys_absolute_path =
            fs::canonicalize(&key_dir).expect("Failed to get absolute path for keys");

        // Create JSON key files
        create_key_file(social_account_id, social_account_sk, &key_dir)?;
        let mut relayer_keyfiles = Vec::with_capacity(relayer_account_sks.len());
        for (i, relayer_sk) in relayer_account_sks.iter().enumerate() {
            let filename = format!("{i}-{relayer_account_id}");
            let keypath = format!("{key_dir}/{filename}.json");
            create_key_file_with_filepath(relayer_account_id, relayer_sk, &keypath)?;
            relayer_keyfiles.push(format!("./account_keys/{filename}.json"));
        }

        // Create relayer config file
        let config_file_name = "config.toml";
        let config_absolute_path = create_relayer_cofig_file(
            RelayerConfig {
                ip_address: [0, 0, 0, 0],
                port: Self::CONTAINER_PORT,
                relayer_account_id: relayer_account_id.clone(),
                keys_filenames: relayer_keyfiles,
                shared_storage_account_id: social_account_id.clone(),
                shared_storage_keys_filename: format!("./account_keys/{}.json", social_account_id),
                whitelisted_contracts: vec![creator_account_id.clone()],
                whitelisted_delegate_action_receiver_ids: vec![creator_account_id.clone()],
                redis_url: redis_full_address.to_string(),
                social_db_contract_id: social_db_id.clone(),
                rpc_url: near_rpc.to_string(),
                wallet_url: "https://wallet.testnet.near.org".to_string(),
                explorer_transaction_url: "https://explorer.testnet.near.org/transactions/"
                    .to_string(),
                rpc_api_key: "".to_string(),
            },
            format!("{relayer_configs_path}/{config_file_name}"),
        )?;

        let image = GenericImage::new(
            "ghcr.io/near/os-relayer",
            "12ba6e35690df3979fce0b36a41d0ca0db9c0ab4",
        )
        .with_wait_for(WaitFor::message_on_stdout("listening on"))
        .with_exposed_port(Self::CONTAINER_PORT)
        .with_volume(
            config_absolute_path,
            format!("/relayer-app/{}", config_file_name),
        )
        .with_volume(
            keys_absolute_path
                .to_str()
                .expect("Failed to convert keys path to string"),
            "/relayer-app/account_keys",
        )
        .with_env_var("RUST_LOG", "DEBUG");

        let image: RunnableImage<GenericImage> = image.into();
        let image = image.with_network(network);
        let container = docker_client.cli.run(image);
        let ip_address = docker_client
            .get_network_ip_address(&container, network)
            .await?;
        let host_port = container.get_host_port_ipv4(Self::CONTAINER_PORT);

        let full_address = format!("http://{}:{}", ip_address, Self::CONTAINER_PORT);
        tracing::info!("Relayer container is running at {}", full_address);

        Ok(Relayer {
            container,
            address: full_address,
            local_address: format!("http://127.0.0.1:{host_port}"),
            id: relayer_id.to_string(),
        })
    }

    pub fn clean_tmp_files(&self) -> anyhow::Result<(), anyhow::Error> {
        std::fs::remove_dir_all(format!("{}/{}", Self::TMP_FOLDER_PATH, self.id))
            .unwrap_or_else(|_| panic!("Failed to clean tmp files for relayer {}", self.id));
        Ok(())
    }
}

pub struct OidcProvider<'a> {
    pub container: Container<'a, GenericImage>,
    pub jwt_pk_url: String,
    pub jwt_pk_local_url: String,
}

impl<'a> OidcProvider<'a> {
    pub const CONTAINER_PORT: u16 = 3000;

    pub async fn run(
        docker_client: &'a DockerClient,
        network: &str,
    ) -> anyhow::Result<OidcProvider<'a>> {
        tracing::info!("Running OIDC provider container...");
        let image = GenericImage::new("near/test-oidc-provider", "latest")
            .with_wait_for(WaitFor::Nothing)
            .with_exposed_port(Self::CONTAINER_PORT)
            .with_env_var("RUST_LOG", "DEBUG");
        let image: RunnableImage<GenericImage> = image.into();
        let image = image.with_network(network);
        let container = docker_client.cli.run(image);

        let ip_address = docker_client
            .get_network_ip_address(&container, network)
            .await?;

        let host_port = container.get_host_port_ipv4(Self::CONTAINER_PORT);
        let full_address = format!("http://{}:{}", ip_address, Self::CONTAINER_PORT);
        let jwt_pk_url = format!("{}/jwt_signature_public_keys", full_address);
        let jwt_local_url = format!("http://127.0.0.1:{}/jwt_signature_public_keys", host_port);

        tracing::info!(
            "OIDC provider container is running, jwt signature pk url: {}",
            jwt_pk_url
        );
        Ok(OidcProvider {
            container,
            jwt_pk_url,
            jwt_pk_local_url: jwt_local_url,
        })
    }
}

pub struct Datastore<'a> {
    pub container: Container<'a, GenericImage>,
    pub address: String,
    pub local_address: String,
}

impl<'a> Datastore<'a> {
    pub const CONTAINER_PORT: u16 = 3000;

    pub async fn run(
        docker_client: &'a DockerClient,
        network: &str,
        project_id: &str,
    ) -> anyhow::Result<Datastore<'a>> {
        tracing::info!("Running datastore container...");
        let image = GenericImage::new(
            "gcr.io/google.com/cloudsdktool/google-cloud-cli",
            "464.0.0-emulators",
        )
        .with_wait_for(WaitFor::message_on_stderr("Dev App Server is now running."))
        .with_exposed_port(Self::CONTAINER_PORT)
        .with_entrypoint("gcloud")
        .with_env_var(
            "DATASTORE_EMULATOR_HOST",
            format!("0.0.0.0:{}", Self::CONTAINER_PORT),
        )
        .with_env_var("DATASTORE_PROJECT_ID", project_id);
        let image: RunnableImage<GenericImage> = (
            image,
            vec![
                "beta".to_string(),
                "emulators".to_string(),
                "datastore".to_string(),
                "start".to_string(),
                format!("--project={project_id}"),
                "--host-port".to_string(),
                format!("0.0.0.0:{}", Self::CONTAINER_PORT),
                "--no-store-on-disk".to_string(),
                "--consistency=1.0".to_string(),
            ],
        )
            .into();
        let image = image.with_network(network);
        let container = docker_client.cli.run(image);
        let ip_address = docker_client
            .get_network_ip_address(&container, network)
            .await?;
        let host_port = container.get_host_port_ipv4(Self::CONTAINER_PORT);

        let full_address = format!("http://{}:{}/", ip_address, Self::CONTAINER_PORT);
        let local_address = format!("http://127.0.0.1:{}/", host_port);
        tracing::info!("Datastore container is running at {}", full_address);
        Ok(Datastore {
            container,
            local_address,
            address: full_address,
        })
    }
}

pub struct LocalStack<'a> {
    pub container: Container<'a, GenericImage>,
    pub address: String,
    pub s3_address: String,
    pub s3_host_address: String,
    pub s3_bucket: String,
    pub s3_region: String,
}

impl<'a> LocalStack<'a> {
    const S3_CONTAINER_PORT: u16 = 4566;

    pub async fn run(
        docker_client: &'a DockerClient,
        network: &str,
        s3_bucket: String,
        s3_region: String,
    ) -> anyhow::Result<LocalStack<'a>> {
        tracing::info!("running LocalStack container...");
        let image = GenericImage::new("localstack/localstack", "3.0.0")
            .with_wait_for(WaitFor::message_on_stdout("Running on"));
        let image: RunnableImage<GenericImage> = image.into();
        let image = image.with_network(network);
        let container = docker_client.cli.run(image);
        let address = docker_client
            .get_network_ip_address(&container, network)
            .await?;

        // Create the bucket
        let create_result = docker_client
            .docker
            .create_exec(
                container.id(),
                CreateExecOptions::<&str> {
                    attach_stdout: Some(true),
                    attach_stderr: Some(true),
                    cmd: Some(vec![
                        "awslocal",
                        "s3api",
                        "create-bucket",
                        "--bucket",
                        &s3_bucket,
                        "--region",
                        &s3_region,
                    ]),
                    ..Default::default()
                },
            )
            .await?;
        docker_client
            .docker
            .start_exec(&create_result.id, None)
            .await?;

        let s3_address = format!("http://{}:{}", address, Self::S3_CONTAINER_PORT);
        #[cfg(all(target_os = "macos", target_arch = "aarch64"))]
        let s3_host_address = {
            let s3_host_port = container.get_host_port_ipv4(Self::S3_CONTAINER_PORT);
            format!("http://127.0.0.1:{s3_host_port}")
        };
        #[cfg(target_arch = "x86_64")]
        let s3_host_address = {
            let s3_host_port = container.get_host_port_ipv6(Self::S3_CONTAINER_PORT);
            format!("http://[::1]:{s3_host_port}")
        };

        tracing::info!(
            s3_address,
            s3_host_address,
            "LocalStack container is running"
        );
        Ok(LocalStack {
            container,
            address,
            s3_address,
            s3_host_address,
            s3_bucket,
            s3_region,
        })
    }
}

pub struct LakeIndexer<'a> {
    pub container: Container<'a, GenericImage>,
    pub bucket_name: String,
    pub region: String,
    pub rpc_address: String,
    pub rpc_host_address: String,
}

impl<'a> LakeIndexer<'a> {
    pub const CONTAINER_RPC_PORT: u16 = 3030;

    pub async fn run(
        docker_client: &'a DockerClient,
        network: &str,
        s3_address: &str,
        bucket_name: String,
        region: String,
    ) -> anyhow::Result<LakeIndexer<'a>> {
        tracing::info!(
            network,
            s3_address,
            bucket_name,
            region,
            "running NEAR Lake Indexer container..."
        );

        let image = GenericImage::new(
            "ghcr.io/near/near-lake-indexer",
            "18ef24922fd7b5b8985ea793fdf7a939e57216ba",
        )
        .with_env_var("AWS_ACCESS_KEY_ID", "FAKE_LOCALSTACK_KEY_ID")
        .with_env_var("AWS_SECRET_ACCESS_KEY", "FAKE_LOCALSTACK_ACCESS_KEY")
        .with_wait_for(WaitFor::message_on_stderr("Starting Streamer"))
        .with_exposed_port(Self::CONTAINER_RPC_PORT);
        let image: RunnableImage<GenericImage> = (
            image,
            vec![
                "--endpoint".to_string(),
                s3_address.to_string(),
                "--bucket".to_string(),
                bucket_name.clone(),
                "--region".to_string(),
                region.clone(),
                "--stream-while-syncing".to_string(),
                "sync-from-latest".to_string(),
            ],
        )
            .into();
        let image = image.with_network(network);
        let container = docker_client.cli.run(image);
        let address = docker_client
            .get_network_ip_address(&container, network)
            .await?;
        let rpc_address = format!("http://{}:{}", address, Self::CONTAINER_RPC_PORT);
        let rpc_host_port = container.get_host_port_ipv4(Self::CONTAINER_RPC_PORT);
        let rpc_host_address = format!("http://127.0.0.1:{rpc_host_port}");

        tracing::info!(
            bucket_name,
            region,
            rpc_address,
            rpc_host_address,
            "NEAR Lake Indexer container is running"
        );
        Ok(LakeIndexer {
            container,
            bucket_name,
            region,
            rpc_address,
            rpc_host_address,
        })
    }
}

pub struct SignerNode<'a> {
    pub container: Container<'a, GenericImage>,
    pub address: String,
    pub local_address: String,

    env: String,
    node_id: usize,
    sk_share: ExpandedKeyPair,
    cipher_key: GenericArray<u8, U32>,
    gcp_project_id: String,
    gcp_datastore_local_url: String,
}

impl SignerNode<'_> {
    // Container port used for the docker network, does not have to be unique
    const CONTAINER_PORT: u16 = 3000;

    pub async fn run<'a>(
        ctx: &super::Context<'a>,
        node_id: usize,
        sk_share: &ExpandedKeyPair,
        cipher_key: &GenericArray<u8, U32>,
    ) -> anyhow::Result<SignerNode<'a>> {
        tracing::info!("Running signer node container {}...", node_id);
        let args = mpc_recovery::Cli::StartSign {
            env: ctx.env.clone(),
            node_id: node_id as u64,
            web_port: Self::CONTAINER_PORT,
            sk_share: Some(serde_json::to_string(&sk_share)?),
            cipher_key: Some(hex::encode(cipher_key)),
            gcp_project_id: ctx.gcp_project_id.clone(),
            gcp_datastore_url: Some(ctx.datastore.address.clone()),
            jwt_signature_pk_url: ctx.oidc_provider.jwt_pk_url.clone(),
            logging_options: logging::Options::default(),
        }
        .into_str_args();

        let image: GenericImage = GenericImage::new("near/mpc-recovery", "latest")
            .with_wait_for(WaitFor::Nothing)
            .with_exposed_port(Self::CONTAINER_PORT)
            .with_env_var("RUST_LOG", "mpc_recovery=DEBUG");
        let image: RunnableImage<GenericImage> = (image, args).into();
        let image = image.with_network(&ctx.docker_network);
        let container = ctx.docker_client.cli.run(image);
        let ip_address = ctx
            .docker_client
            .get_network_ip_address(&container, &ctx.docker_network)
            .await?;
        let host_port = container.get_host_port_ipv4(Self::CONTAINER_PORT);

        container.exec(ExecCommand {
            cmd: format!("bash -c 'while [[ \"$(curl -s -o /dev/null -w ''%{{http_code}}'' localhost:{})\" != \"200\" ]]; do sleep 1; done'", Self::CONTAINER_PORT),
            ready_conditions: vec![WaitFor::message_on_stderr("node is ready to accept connections")]
        });

        let full_address = format!("http://{ip_address}:{}", Self::CONTAINER_PORT);
        tracing::info!(
            "Signer node container {} is running at {}",
            node_id,
            full_address
        );
        Ok(SignerNode {
            container,
            address: full_address,
            local_address: format!("http://127.0.0.1:{host_port}"),
            env: ctx.env.clone(),
            node_id,
            sk_share: sk_share.clone(),
            cipher_key: *cipher_key,
            gcp_project_id: ctx.gcp_project_id.clone(),
            gcp_datastore_local_url: ctx.datastore.local_address.clone(),
        })
    }

    pub fn api(&self) -> SignerNodeApi {
        SignerNodeApi {
            env: self.env.clone(),
            address: self.local_address.clone(),
            node_id: self.node_id,
            sk_share: self.sk_share.clone(),
            cipher_key: self.cipher_key,
            gcp_project_id: self.gcp_project_id.clone(),
            gcp_datastore_local_url: self.gcp_datastore_local_url.clone(),
        }
    }
}

impl SignerNodeApi {
    pub async fn accept_pk_set(
        &self,
        request: AcceptNodePublicKeysRequest,
    ) -> anyhow::Result<(StatusCode, Result<String, String>)> {
        util::post(format!("{}/accept_pk_set", self.address), request).await
    }

    pub async fn run_rotate_node_key(
        &self,
        new_cipher_key: &GenericArray<u8, U32>,
    ) -> anyhow::Result<(Aes256Gcm, Aes256Gcm)> {
        let gcp_service = mpc_recovery::gcp::GcpService::new(
            self.env.clone(),
            self.gcp_project_id.clone(),
            Some(self.gcp_datastore_local_url.clone()),
        )
        .await?;

        let new_cipher = Aes256Gcm::new(new_cipher_key);
        let old_cipher = Aes256Gcm::new(&self.cipher_key);

        // Do inplace rotation of node key
        mpc_recovery::sign_node::migration::rotate_cipher(
            self.node_id,
            &old_cipher,
            &new_cipher,
            &gcp_service,
            &gcp_service,
        )
        .await?;

        Ok((old_cipher.clone(), new_cipher))
    }
}

pub struct LeaderNode<'a> {
    pub container: Container<'a, GenericImage>,
    pub address: String,
    local_address: String,
    local_rpc_url: String,
    local_relayer_url: String,
}

impl<'a> LeaderNode<'a> {
    // Container port used for the docker network, does not have to be unique
    const CONTAINER_PORT: u16 = 3000;

    pub async fn run(ctx: &Context<'a>, sign_nodes: Vec<String>) -> anyhow::Result<LeaderNode<'a>> {
        tracing::info!("Running leader node container...");
        let account_creator = &ctx.relayer_ctx.creator_account;
        let args = mpc_recovery::Cli::StartLeader {
            env: ctx.env.clone(),
            web_port: Self::CONTAINER_PORT,
            sign_nodes,
            near_rpc: ctx.relayer_ctx.sandbox.address.clone(),
            near_root_account: ctx.relayer_ctx.worker.root_account()?.id().to_string(),
            account_creator_id: account_creator.id().clone(),
            account_creator_sk: ctx
                .relayer_ctx
                .creator_account_keys
                .iter()
                .map(|k| k.to_string().parse())
                .collect::<Result<Vec<_>, _>>()?,
            fast_auth_partners: Some(
                serde_json::json!([
                    {
                        "oidc_provider": {
                            "issuer": ctx.issuer,
                            "audience": ctx.audience_id,
                        },
                        "relayer": {
                            "url": &ctx.relayer_ctx.relayer.address,
                            "api_key": serde_json::Value::Null,
                        },
                    },
                ])
                .to_string(),
            ),
            fast_auth_partners_filepath: None,
            gcp_project_id: ctx.gcp_project_id.clone(),
            gcp_datastore_url: Some(ctx.datastore.address.to_string()),
            jwt_signature_pk_url: ctx.oidc_provider.jwt_pk_url.to_string(),
            logging_options: logging::Options::default(),
        }
        .into_str_args();

        let image = GenericImage::new("near/mpc-recovery", "latest")
            .with_wait_for(WaitFor::Nothing)
            .with_exposed_port(Self::CONTAINER_PORT)
            .with_env_var("RUST_LOG", "mpc_recovery=DEBUG");
        let image: RunnableImage<GenericImage> = (image, args).into();
        let image = image.with_network(&ctx.docker_network);
        let container = ctx.docker_client.cli.run(image);
        let ip_address = ctx
            .docker_client
            .get_network_ip_address(&container, &ctx.docker_network)
            .await?;
        let host_port = container.get_host_port_ipv4(Self::CONTAINER_PORT);

        container.exec(ExecCommand {
            cmd: format!("bash -c 'while [[ \"$(curl -s -o /dev/null -w ''%{{http_code}}'' localhost:{})\" != \"200\" ]]; do sleep 1; done'", Self::CONTAINER_PORT),
            ready_conditions: vec![WaitFor::message_on_stderr("node is ready to accept connections")]
        });

        let full_address = format!("http://{ip_address}:{}", Self::CONTAINER_PORT);
        tracing::info!("Leader node container is running at {}", full_address);
        Ok(LeaderNode {
            container,
            address: full_address,
            local_address: format!("http://127.0.0.1:{host_port}"),
            local_rpc_url: ctx.relayer_ctx.sandbox.local_address.clone(),
            local_relayer_url: ctx.relayer_ctx.relayer.local_address.clone(),
        })
    }

    pub fn api(&self) -> LeaderNodeApi {
        LeaderNodeApi {
            address: self.local_address.clone(),
            client: NearRpcAndRelayerClient::connect(&self.local_rpc_url),
            relayer: DelegateActionRelayer {
                url: self.local_relayer_url.clone(),
                api_key: None,
            },
        }
    }
}

impl LeaderNodeApi {
    pub async fn claim_oidc(
        &self,
        request: ClaimOidcRequest,
    ) -> anyhow::Result<(StatusCode, ClaimOidcResponse)> {
        util::post(format!("{}/claim_oidc", self.address), request).await
    }

    pub async fn get_mpc_pk(
        &self,
        request: MpcPkRequest,
    ) -> anyhow::Result<(StatusCode, MpcPkResponse)> {
        util::post(format!("{}/mpc_public_key", self.address), request).await
    }

    pub async fn user_credentials(
        &self,
        request: UserCredentialsRequest,
    ) -> anyhow::Result<(StatusCode, UserCredentialsResponse)> {
        util::post(format!("{}/user_credentials", self.address), request).await
    }

    pub async fn sign(&self, request: SignRequest) -> anyhow::Result<(StatusCode, SignResponse)> {
        util::post(format!("{}/sign", self.address), request).await
    }

    pub async fn new_account(
        &self,
        request: NewAccountRequest,
    ) -> anyhow::Result<(StatusCode, NewAccountResponse)> {
        util::post(format!("{}/new_account", self.address), request).await
    }

    pub async fn new_account_with_helper(
        &self,
        account_id: &AccountId,
        user_fa_public_key: &PublicKey,
        user_la_public_key: Option<LimitedAccessKey>,
        user_secret_key: &SecretKey,
        oidc_token: &OidcToken,
    ) -> anyhow::Result<(StatusCode, NewAccountResponse)> {
        let user_pk = user_secret_key.public_key();

        let limited_access_keys = user_la_public_key.map(|pk| vec![pk]);

        let create_account_options = CreateAccountOptions {
            full_access_keys: Some(vec![user_fa_public_key.clone()]),
            limited_access_keys,
            contract_bytes: None,
        };

        // By signing this digest we are giving the leader node permission to get user recovery pk
        let user_credentials_request_digest =
            user_credentials_request_digest(oidc_token, &user_pk)?;

        let frp_signature = match user_secret_key.sign(&user_credentials_request_digest) {
            near_crypto::Signature::ED25519(k) => k,
            _ => anyhow::bail!("Wrong signature type"),
        };

        let new_account_request = NewAccountRequest {
            near_account_id: account_id.clone(),
            create_account_options,
            oidc_token: oidc_token.clone(),
            user_credentials_frp_signature: frp_signature,
            frp_public_key: user_pk,
        };

        self.new_account(new_account_request).await
    }

    pub async fn add_key_with_helper(
        &self,
        account_id: &AccountId,
        oidc_token: &OidcToken,
        public_key: &PublicKey,
        recovery_pk: &PublicKey,
        frp_sk: &SecretKey,
        frp_pk: &PublicKey,
    ) -> anyhow::Result<(StatusCode, SignResponse)> {
        // Prepare SignRequest with add key delegate action
        let (_, block_height, nonce) = self.client.access_key(account_id, recovery_pk).await?;

        let add_key_delegate_action = DelegateAction {
            sender_id: account_id.clone(),
            receiver_id: account_id.clone(),
            actions: vec![Action::AddKey(AddKeyAction {
                public_key: public_key.clone(),
                access_key: AccessKey {
                    nonce: 0,
                    permission: AccessKeyPermission::FullAccess,
                },
            })
            .try_into()?],
            nonce,
            max_block_height: block_height + 100,
            public_key: recovery_pk.clone(),
        };

        let (status_code, sign_response) = self
            .sign_with_helper(&add_key_delegate_action, oidc_token, frp_sk, frp_pk)
            .await?;

        // Send SignRequest to leader node
        let signature = match &sign_response {
            SignResponse::Ok { signature } => signature,
            SignResponse::Err { .. } => return Ok((status_code, sign_response)),
        };
        let response = self
            .client
            .send_meta_tx(
                SignedDelegateAction {
                    delegate_action: add_key_delegate_action,
                    signature: near_crypto::Signature::ED25519(*signature),
                },
                self.relayer.clone(),
            )
            .await?;
        if matches!(response.status, FinalExecutionStatus::SuccessValue(_)) {
            Ok((status_code, sign_response))
        } else {
            Err(anyhow::anyhow!("add_key failed with {:?}", response.status))
        }
    }

    pub async fn delete_key_with_helper(
        &self,
        account_id: &AccountId,
        oidc_token: &OidcToken,
        public_key: &PublicKey,
        recovery_pk: &PublicKey,
        frp_sk: &SecretKey,
        frp_pk: &PublicKey,
    ) -> anyhow::Result<(StatusCode, SignResponse)> {
        // Prepare SignRequest with add key delegate action
        let (_, block_height, nonce) = self.client.access_key(account_id, recovery_pk).await?;

        let delete_key_delegate_action = DelegateAction {
            sender_id: account_id.clone(),
            receiver_id: account_id.clone(),
            actions: vec![Action::DeleteKey(DeleteKeyAction {
                public_key: public_key.clone(),
            })
            .try_into()?],
            nonce,
            max_block_height: block_height + 100,
            public_key: recovery_pk.clone(),
        };

        let (status_code, sign_response) = self
            .sign_with_helper(&delete_key_delegate_action, oidc_token, frp_sk, frp_pk)
            .await?;

        // Send SignRequest to leader node
        let signature = match &sign_response {
            SignResponse::Ok { signature } => signature,
            SignResponse::Err { .. } => return Ok((status_code, sign_response)),
        };
        let response = self
            .client
            .send_meta_tx(
                SignedDelegateAction {
                    delegate_action: delete_key_delegate_action,
                    signature: near_crypto::Signature::ED25519(*signature),
                },
                self.relayer.clone(),
            )
            .await?;
        if matches!(response.status, FinalExecutionStatus::SuccessValue(_)) {
            Ok((status_code, sign_response))
        } else {
            Err(anyhow::anyhow!(
                "delete_key failed with {:?}",
                response.status
            ))
        }
    }

    pub async fn sign_with_helper(
        &self,
        delegate_action: &DelegateAction,
        oidc_token: &OidcToken,
        frp_sk: &SecretKey,
        frp_pk: &PublicKey,
    ) -> anyhow::Result<(StatusCode, SignResponse)> {
        let sign_request_digest = sign_request_digest(delegate_action, oidc_token, frp_pk)?;
        let frp_signature = sign_digest(&sign_request_digest, frp_sk)?;

        let user_credentials_request_digest = user_credentials_request_digest(oidc_token, frp_pk)?;
        let user_credentials_frp_signature = sign_digest(&user_credentials_request_digest, frp_sk)?;

        let sign_request = SignRequest {
            delegate_action: delegate_action.try_to_vec()?,
            oidc_token: oidc_token.clone(),
            frp_signature,
            user_credentials_frp_signature,
            frp_public_key: frp_pk.clone(),
        };
        // Send SignRequest to leader node
        let (status_code, sign_response): (_, SignResponse) = self.sign(sign_request).await?;
        Ok((status_code, sign_response))
    }

    pub async fn claim_oidc_with_helper(
        &self,
        oidc_token: &OidcToken,
        user_public_key: &PublicKey,
        user_secret_key: &SecretKey,
    ) -> anyhow::Result<(StatusCode, ClaimOidcResponse)> {
        let oidc_token_hash = oidc_token.digest_hash();

        let request_digest = claim_oidc_request_digest(&oidc_token_hash, user_public_key).unwrap();
        let request_digest_signature = sign_digest(&request_digest, user_secret_key)?;

        let oidc_request = ClaimOidcRequest {
            oidc_token_hash,
            frp_public_key: user_public_key.clone(),
            frp_signature: request_digest_signature,
        };

        let response = self.claim_oidc(oidc_request.clone()).await?;

        match response.1 {
            ClaimOidcResponse::Ok { mpc_signature } => {
                let mpc_pk: PublicKeyEd25519 =
                    self.get_mpc_pk(MpcPkRequest {}).await?.1.try_into()?;

                // Verify signature
                let response_digest = claim_oidc_response_digest(oidc_request.frp_signature)?;
                mpc_pk.verify(&response_digest, &mpc_signature)?;
                Ok(response)
            }
            ClaimOidcResponse::Err { .. } => Ok(response),
        }
    }

    pub async fn user_credentials_with_helper(
        &self,
        oidc_token: &OidcToken,
        client_sk: &SecretKey,
        client_pk: &PublicKey,
    ) -> anyhow::Result<(StatusCode, UserCredentialsResponse)> {
        let user_credentials_request_digest =
            user_credentials_request_digest(oidc_token, client_pk)?;

        let frp_signature = match client_sk.sign(&user_credentials_request_digest) {
            near_crypto::Signature::ED25519(k) => k,
            _ => return Err(anyhow::anyhow!("Wrong signature type")),
        };

        self.user_credentials(UserCredentialsRequest {
            oidc_token: oidc_token.clone(),
            frp_signature,
            frp_public_key: client_pk.clone(),
        })
        .await
    }
}

'''
'''--- integration-tests/src/env/local.rs ---
use crate::env::{LeaderNodeApi, SignerNodeApi};
use crate::mpc::{self, NodeProcess};
use crate::util;
use aes_gcm::aead::consts::U32;
use aes_gcm::aead::generic_array::GenericArray;
use mpc_recovery::firewall::allowed::DelegateActionRelayer;
use mpc_recovery::logging;
use mpc_recovery::relayer::NearRpcAndRelayerClient;
use multi_party_eddsa::protocols::ExpandedKeyPair;

pub struct SignerNode {
    pub address: String,
    env: String,
    node_id: usize,
    sk_share: ExpandedKeyPair,
    cipher_key: GenericArray<u8, U32>,
    gcp_project_id: String,
    gcp_datastore_url: String,

    // process held so it's not dropped. Once dropped, process will be killed.
    _process: NodeProcess,
}

impl SignerNode {
    pub async fn run(
        ctx: &super::Context<'_>,
        node_id: u64,
        sk_share: &ExpandedKeyPair,
        cipher_key: &GenericArray<u8, U32>,
    ) -> anyhow::Result<Self> {
        let web_port = util::pick_unused_port().await?;
        let cli = mpc_recovery::Cli::StartSign {
            env: ctx.env.clone(),
            node_id,
            web_port,
            sk_share: Some(serde_json::to_string(&sk_share)?),
            cipher_key: Some(hex::encode(cipher_key)),
            gcp_project_id: ctx.gcp_project_id.clone(),
            gcp_datastore_url: Some(ctx.datastore.local_address.clone()),
            jwt_signature_pk_url: ctx.oidc_provider.jwt_pk_local_url.clone(),
            logging_options: logging::Options::default(),
        };

        let sign_node_id = format!("sign-{node_id}");
        let process = mpc::spawn(ctx.release, &sign_node_id, cli).await?;
        let address = format!("http://127.0.0.1:{web_port}");
        tracing::info!("Signer node is starting at {}", address);
        util::ping_until_ok(&address, 60).await?;
        tracing::info!("Signer node started [node_id={node_id}, {address}]");

        Ok(Self {
            address,
            env: ctx.env.clone(),
            node_id: node_id as usize,
            sk_share: sk_share.clone(),
            cipher_key: *cipher_key,
            gcp_project_id: ctx.gcp_project_id.clone(),
            gcp_datastore_url: ctx.datastore.local_address.clone(),
            _process: process,
        })
    }

    pub fn api(&self) -> SignerNodeApi {
        SignerNodeApi {
            address: self.address.clone(),
            env: self.env.clone(),
            node_id: self.node_id,
            sk_share: self.sk_share.clone(),
            cipher_key: self.cipher_key,
            gcp_project_id: self.gcp_project_id.clone(),
            gcp_datastore_local_url: self.gcp_datastore_url.clone(),
        }
    }
}

pub struct LeaderNode {
    pub address: String,
    near_rpc: String,
    relayer_url: String,

    // process held so it's not dropped. Once dropped, process will be killed.
    _process: NodeProcess,
}

impl LeaderNode {
    pub async fn run(ctx: &super::Context<'_>, sign_nodes: Vec<String>) -> anyhow::Result<Self> {
        tracing::info!("Running leader node...");
        let account_creator = &ctx.relayer_ctx.creator_account;
        let web_port = util::pick_unused_port().await?;
        let cli = mpc_recovery::Cli::StartLeader {
            env: ctx.env.clone(),
            web_port,
            sign_nodes,
            near_rpc: ctx.relayer_ctx.sandbox.local_address.clone(),
            near_root_account: ctx.relayer_ctx.worker.root_account()?.id().to_string(),
            account_creator_id: account_creator.id().clone(),
            account_creator_sk: ctx
                .relayer_ctx
                .creator_account_keys
                .iter()
                .map(|k| k.to_string().parse())
                .collect::<Result<Vec<_>, _>>()?,
            fast_auth_partners_filepath: None,
            fast_auth_partners: Some(
                serde_json::json!([
                    {
                        "oidc_provider": {
                            "issuer": ctx.issuer,
                            "audience": ctx.audience_id,
                        },
                        "relayer": {
                            "url": &ctx.relayer_ctx.relayer.local_address,
                            "api_key": serde_json::Value::Null,
                        },
                    },
                ])
                .to_string(),
            ),
            gcp_project_id: ctx.gcp_project_id.clone(),
            gcp_datastore_url: Some(ctx.datastore.local_address.clone()),
            jwt_signature_pk_url: ctx.oidc_provider.jwt_pk_local_url.clone(),
            logging_options: logging::Options::default(),
        };

        let process = mpc::spawn(ctx.release, "leader", cli).await?;
        let address = format!("http://127.0.0.1:{web_port}");
        tracing::info!("Leader node container is starting at {}", address);
        util::ping_until_ok(&address, 60).await?;
        tracing::info!("Leader node running at {address}");

        Ok(Self {
            address,
            near_rpc: ctx.relayer_ctx.sandbox.local_address.clone(),
            relayer_url: ctx.relayer_ctx.relayer.local_address.clone(),
            _process: process,
        })
    }

    pub fn api(&self) -> LeaderNodeApi {
        LeaderNodeApi {
            address: self.address.clone(),
            client: NearRpcAndRelayerClient::connect(&self.near_rpc),
            relayer: DelegateActionRelayer {
                url: self.relayer_url.clone(),
                api_key: None,
            },
        }
    }
}

'''
'''--- integration-tests/src/env/mod.rs ---
pub mod containers;
pub mod local;

use aes_gcm::aead::consts::U32;
use aes_gcm::aead::generic_array::GenericArray;
use curv::elliptic::curves::{Ed25519, Point};
use multi_party_eddsa::protocols::ExpandedKeyPair;
use near_primitives::utils::generate_random_string;

use mpc_recovery::firewall::allowed::DelegateActionRelayer;
use mpc_recovery::relayer::NearRpcAndRelayerClient;
use mpc_recovery::GenerateResult;

use crate::env::containers::DockerClient;
use crate::{initialize_relayer, RelayerCtx};

const ENV: &str = "dev";
const NETWORK: &str = "mpc_it_network";
const GCP_PROJECT_ID: &str = "mpc-recovery-gcp-project";
// TODO: figure out how to instantiate and use a local firebase deployment
const FIREBASE_AUDIENCE_ID: &str = "test_audience";
const ISSUER: &str = "https://securetoken.google.com/test_audience";

pub struct SignerNodeApi {
    pub env: String,
    pub address: String,
    pub node_id: usize,
    pub sk_share: ExpandedKeyPair,
    pub cipher_key: GenericArray<u8, U32>,
    pub gcp_project_id: String,
    pub gcp_datastore_local_url: String,
}

pub struct LeaderNodeApi {
    pub address: String,
    pub relayer: DelegateActionRelayer,
    pub client: NearRpcAndRelayerClient,
}

pub enum Nodes<'a> {
    Local {
        ctx: Context<'a>,
        pk_set: Vec<Point<Ed25519>>,
        leader_node: local::LeaderNode,
        signer_nodes: Vec<local::SignerNode>,
    },
    Docker {
        ctx: Context<'a>,
        pk_set: Vec<Point<Ed25519>>,
        leader_node: containers::LeaderNode<'a>,
        signer_nodes: Vec<containers::SignerNode<'a>>,
    },
}

impl Nodes<'_> {
    pub fn ctx(&self) -> &Context {
        match self {
            Nodes::Local { ctx, .. } => ctx,
            Nodes::Docker { ctx, .. } => ctx,
        }
    }

    pub fn pk_set(&self) -> Vec<Point<Ed25519>> {
        match self {
            Nodes::Local { pk_set, .. } => pk_set.clone(),
            Nodes::Docker { pk_set, .. } => pk_set.clone(),
        }
    }

    pub fn leader_api(&self) -> LeaderNodeApi {
        match self {
            Nodes::Local { leader_node, .. } => leader_node.api(),
            Nodes::Docker { leader_node, .. } => leader_node.api(),
        }
    }

    pub fn signer_apis(&self) -> Vec<SignerNodeApi> {
        match self {
            Nodes::Local { signer_nodes, .. } => signer_nodes.iter().map(|n| n.api()).collect(),
            Nodes::Docker { signer_nodes, .. } => signer_nodes.iter().map(|n| n.api()).collect(),
        }
    }

    pub fn datastore_addr(&self) -> String {
        self.ctx().datastore.local_address.clone()
    }
}

pub struct Context<'a> {
    pub env: String,
    pub docker_client: &'a DockerClient,
    pub docker_network: String,
    pub gcp_project_id: String,
    pub audience_id: String,
    pub issuer: String,
    pub release: bool,

    pub relayer_ctx: RelayerCtx<'a>,
    pub datastore: containers::Datastore<'a>,
    pub oidc_provider: containers::OidcProvider<'a>,
}

pub async fn setup(docker_client: &DockerClient) -> anyhow::Result<Context<'_>> {
    let release = true;
    #[cfg(not(feature = "flamegraph"))]
    if !crate::mpc::build(release).await?.success() {
        anyhow::bail!("failed to prebuild MPC service");
    }

    let gcp_project_id = GCP_PROJECT_ID;
    let docker_network = NETWORK;
    docker_client.create_network(docker_network).await?;

    let relayer_id = generate_random_string(7); // used to distinguish relayer tmp files in multiple tests
    let relayer_ctx_future = initialize_relayer(docker_client, docker_network, &relayer_id);
    let datastore_future =
        containers::Datastore::run(docker_client, docker_network, gcp_project_id);
    let oidc_provider_future = containers::OidcProvider::run(docker_client, docker_network);

    let (relayer_ctx, datastore, oidc_provider) =
        futures::future::join3(relayer_ctx_future, datastore_future, oidc_provider_future).await;
    let relayer_ctx = relayer_ctx?;
    let datastore = datastore?;
    let oidc_provider = oidc_provider?;

    Ok(Context {
        env: ENV.to_string(),
        docker_client,
        docker_network: docker_network.to_string(),
        gcp_project_id: gcp_project_id.to_string(),
        audience_id: FIREBASE_AUDIENCE_ID.to_string(),
        issuer: ISSUER.to_string(),
        release,
        relayer_ctx,
        datastore,
        oidc_provider,
    })
}

pub async fn docker(nodes: usize, docker_client: &DockerClient) -> anyhow::Result<Nodes> {
    let ctx = setup(docker_client).await?;

    let GenerateResult { pk_set, secrets } = mpc_recovery::generate(nodes);
    let mut signer_node_futures = Vec::with_capacity(nodes);
    for (node_id, (share, cipher_key)) in secrets.iter().enumerate().take(nodes) {
        signer_node_futures.push(containers::SignerNode::run(
            &ctx, node_id, share, cipher_key,
        ));
    }
    let signer_nodes = futures::future::join_all(signer_node_futures)
        .await
        .into_iter()
        .collect::<Result<Vec<_>, _>>()?;
    let sign_nodes = signer_nodes.iter().map(|n| n.address.clone()).collect();
    let leader_node = containers::LeaderNode::run(&ctx, sign_nodes).await?;

    Ok(Nodes::Docker {
        ctx,
        pk_set,
        leader_node,
        signer_nodes,
    })
}

pub async fn host(nodes: usize, docker_client: &DockerClient) -> anyhow::Result<Nodes> {
    let ctx = setup(docker_client).await?;
    let GenerateResult { pk_set, secrets } = mpc_recovery::generate(nodes);
    let mut signer_node_futures = Vec::with_capacity(nodes);
    for (i, (share, cipher_key)) in secrets.iter().enumerate().take(nodes) {
        signer_node_futures.push(local::SignerNode::run(&ctx, i as u64, share, cipher_key));
    }
    let signer_nodes = futures::future::join_all(signer_node_futures)
        .await
        .into_iter()
        .collect::<Result<Vec<_>, _>>()?;

    let sign_nodes = signer_nodes.iter().map(|n| n.address.clone()).collect();
    let leader_node = local::LeaderNode::run(&ctx, sign_nodes).await?;

    Ok(Nodes::Local {
        ctx,
        pk_set,
        leader_node,
        signer_nodes,
    })
}

pub async fn run(nodes: usize, docker_client: &DockerClient) -> anyhow::Result<Nodes> {
    #[cfg(feature = "docker-test")]
    return docker(nodes, docker_client).await;

    #[cfg(not(feature = "docker-test"))]
    return host(nodes, docker_client).await;
}

'''
'''--- integration-tests/src/lib.rs ---
use bollard::exec::{CreateExecOptions, StartExecResults};
use futures::StreamExt;
use near_crypto::KeyFile;
use near_workspaces::{
    network::{Sandbox, ValidatorKey},
    types::SecretKey,
    Account, Worker,
};

use crate::env::containers::{self, LocalStack};
use near_workspaces::types::NearToken;
use testcontainers::{Container, GenericImage};

pub mod env;
pub mod mpc;
pub mod multichain;
pub mod sandbox;
pub mod util;

async fn fetch_from_validator(
    docker_client: &containers::DockerClient,
    container: &Container<'_, GenericImage>,
    path: &str,
) -> anyhow::Result<Vec<u8>> {
    tracing::info!(path, "fetching data from validator");
    let create_result = docker_client
        .docker
        .create_exec(
            container.id(),
            CreateExecOptions::<&str> {
                attach_stdout: Some(true),
                attach_stderr: Some(true),
                cmd: Some(vec!["cat", path]),
                ..Default::default()
            },
        )
        .await?;

    let start_result = docker_client
        .docker
        .start_exec(&create_result.id, None)
        .await?;

    match start_result {
        StartExecResults::Attached { mut output, .. } => {
            let mut stream_contents = Vec::new();
            while let Some(chunk) = output.next().await {
                stream_contents.extend_from_slice(&chunk?.into_bytes());
            }

            tracing::info!("data fetched");
            Ok(stream_contents)
        }
        StartExecResults::Detached => unreachable!("unexpected detached output"),
    }
}

async fn fetch_validator_keys(
    docker_client: &containers::DockerClient,
    container: &Container<'_, GenericImage>,
) -> anyhow::Result<KeyFile> {
    let _span = tracing::info_span!("fetch_validator_keys");
    let key_data =
        fetch_from_validator(docker_client, container, "/root/.near/validator_key.json").await?;
    Ok(serde_json::from_slice(&key_data)?)
}

pub struct SandboxCtx<'a> {
    pub sandbox: containers::Sandbox<'a>,
    pub worker: Worker<Sandbox>,
}

pub async fn initialize_sandbox<'a>(
    docker_client: &'a containers::DockerClient,
    network: &str,
) -> anyhow::Result<SandboxCtx<'a>> {
    tracing::info!("initializing sandbox");
    let sandbox = containers::Sandbox::run(docker_client, network).await?;

    let validator_key = fetch_validator_keys(docker_client, &sandbox.container).await?;

    tracing::info!("initializing sandbox worker");
    let worker = near_workspaces::sandbox()
        .rpc_addr(&sandbox.local_address)
        .validator_key(ValidatorKey::Known(
            validator_key.account_id.to_string().parse()?,
            validator_key.secret_key.to_string().parse()?,
        ))
        .await?;

    Ok(SandboxCtx { sandbox, worker })
}

pub struct LakeIndexerCtx<'a> {
    pub localstack: containers::LocalStack<'a>,
    pub lake_indexer: containers::LakeIndexer<'a>,
    pub worker: Worker<Sandbox>,
}

pub async fn initialize_lake_indexer<'a>(
    docker_client: &'a containers::DockerClient,
    network: &str,
) -> anyhow::Result<LakeIndexerCtx<'a>> {
    let s3_bucket = "near-lake-custom".to_string();
    let s3_region = "us-east-1".to_string();
    let localstack =
        LocalStack::run(docker_client, network, s3_bucket.clone(), s3_region.clone()).await?;

    let lake_indexer = containers::LakeIndexer::run(
        docker_client,
        network,
        &localstack.s3_address,
        s3_bucket,
        s3_region,
    )
    .await?;

    let validator_key = fetch_validator_keys(docker_client, &lake_indexer.container).await?;

    tracing::info!("initializing sandbox worker");
    let worker = near_workspaces::sandbox()
        .rpc_addr(&lake_indexer.rpc_host_address)
        .validator_key(ValidatorKey::Known(
            validator_key.account_id.to_string().parse()?,
            validator_key.secret_key.to_string().parse()?,
        ))
        .await?;

    Ok(LakeIndexerCtx {
        localstack,
        lake_indexer,
        worker,
    })
}

pub struct RelayerCtx<'a> {
    pub sandbox: containers::Sandbox<'a>,
    pub redis: containers::Redis<'a>,
    pub relayer: containers::Relayer<'a>,
    pub worker: Worker<Sandbox>,
    pub creator_account: Account,
    pub creator_account_keys: Vec<SecretKey>,
}

pub async fn initialize_relayer<'a>(
    docker_client: &'a containers::DockerClient,
    network: &str,
    relayer_id: &str,
) -> anyhow::Result<RelayerCtx<'a>> {
    let SandboxCtx {
        sandbox, worker, ..
    } = initialize_sandbox(docker_client, network).await?;

    let social_db = sandbox::initialize_social_db(&worker).await?;
    sandbox::initialize_linkdrop(&worker).await?;
    tracing::info!("Initializing relayer accounts...");
    let relayer_account =
        sandbox::create_account(&worker, "relayer", NearToken::from_near(1000)).await?;
    let relayer_account_keys = sandbox::gen_rotating_keys(&relayer_account, 5).await?;

    let creator_account =
        sandbox::create_account(&worker, "creator", NearToken::from_near(200)).await?;
    let creator_account_keys = sandbox::gen_rotating_keys(&creator_account, 5).await?;

    let social_account =
        sandbox::create_account(&worker, "social", NearToken::from_near(1000)).await?;
    tracing::info!(
        "Relayer accounts initialized. Relayer account: {}, Creator account: {}, Social account: {}",
        relayer_account.id(),
        creator_account.id(),
        social_account.id()
    );

    let redis = containers::Redis::run(docker_client, network).await?;
    let relayer = containers::Relayer::run(
        docker_client,
        network,
        &sandbox.address,
        &redis.full_address,
        relayer_account.id(),
        &relayer_account_keys,
        creator_account.id(),
        social_db.id(),
        social_account.id(),
        social_account.secret_key(),
        relayer_id,
    )
    .await?;

    Ok(RelayerCtx::<'a> {
        sandbox,
        redis,
        relayer,
        worker,
        creator_account,
        creator_account_keys,
    })
}

'''
'''--- integration-tests/src/main.rs ---
use clap::Parser;
use mpc_recovery_integration_tests::env;
use mpc_recovery_integration_tests::env::containers::DockerClient;
use tokio::io::{stdin, AsyncReadExt};
use tracing_subscriber::EnvFilter;

#[derive(Parser, Debug)]
enum Cli {
    SetupEnv { nodes: usize },
}

#[tokio::main]
async fn main() -> anyhow::Result<()> {
    let subscriber = tracing_subscriber::fmt()
        .with_thread_ids(true)
        .with_env_filter(EnvFilter::from_default_env());
    subscriber.init();
    match Cli::parse() {
        Cli::SetupEnv { nodes } => {
            println!("Setting up an environment with {} nodes...", nodes);
            let docker_client = DockerClient::default();
            let nodes = env::run(nodes, &docker_client).await?;
            let ctx = nodes.ctx();

            println!("\nEnvironment is ready:");
            println!("  docker-network: {}", ctx.docker_network);
            println!("  gcp-project-id: {}", ctx.gcp_project_id);
            println!("  audience-id:    {}", ctx.audience_id);
            println!("  issuer:         {}", ctx.issuer);
            println!("  release:        {}", ctx.release);
            println!("  env:            {}", ctx.env);

            println!("\nAccounts:");
            println!("  creator: {}", ctx.relayer_ctx.creator_account.id());
            println!("  root:    {}", ctx.relayer_ctx.worker.root_account()?.id());

            println!("\nExternal services:");
            println!("  oidc-provider: {}", ctx.oidc_provider.jwt_pk_local_url);
            println!("  datastore:     {}", nodes.datastore_addr());
            println!("  sandbox:       {}", ctx.relayer_ctx.sandbox.local_address);
            println!("  relayer:       {}", ctx.relayer_ctx.relayer.local_address);
            println!("  redis:         {}", ctx.relayer_ctx.redis.local_address);

            println!("\nNode services:");
            println!("  leader node:   {}", nodes.leader_api().address);
            println!("  signer nodes:");
            for node in nodes.signer_apis() {
                println!("    {}: {}", node.node_id, node.address);
            }

            println!("\nSigner public key set:");
            for pk in nodes.pk_set() {
                println!("  {pk:?}");
            }

            println!("\nPress any button to exit and destroy all containers...");
            while stdin().read(&mut [0]).await? == 0 {
                tokio::time::sleep(std::time::Duration::from_millis(25)).await;
            }
        }
    };

    Ok(())
}

'''
'''--- integration-tests/src/mpc.rs ---
use std::path::{Path, PathBuf};

use anyhow::Context;
use async_process::{Child, Command, ExitStatus, Stdio};
use tokio::runtime::Runtime;

use mpc_recovery::Cli;

const PACKAGE: &str = "mpc-recovery";
const PACKAGE_MULTICHAIN: &str = "mpc-recovery-node";
const PACKAGE_CONTRACT: &str = "mpc-contract";
const TARGET_CONTRACT: &str = "wasm32-unknown-unknown";
pub const TARGET_CONTRACT_DIR: &str = "../target/seperate_wasm";

/// NodeProcess holds onto the respective handles such that on drop, it will clean
/// the running process, task, or thread.
pub enum NodeProcess {
    Subprocess(async_process::Child),
    Threaded(std::thread::JoinHandle<anyhow::Result<()>>),
}

pub fn executable(release: bool, executable: &str) -> Option<PathBuf> {
    let executable = target_dir()?
        .join(if release { "release" } else { "debug" })
        .join(executable);
    Some(executable)
}

fn target_dir() -> Option<PathBuf> {
    let mut out_dir = Path::new(std::env!("OUT_DIR"));
    loop {
        if out_dir.ends_with("target") {
            break Some(out_dir.to_path_buf());
        }

        match out_dir.parent() {
            Some(parent) => out_dir = parent,
            None => break None, // We've reached the root directory and didn't find "target"
        }
    }
}

async fn build_package(
    release: bool,
    package: &str,
    target: Option<&str>,
    target_dir: Option<&str>,
) -> anyhow::Result<ExitStatus> {
    let mut cmd = Command::new("cargo");
    cmd.arg("build")
        .arg("--package")
        .arg(package)
        .envs(std::env::vars())
        .stdout(Stdio::inherit())
        .stderr(Stdio::inherit());

    if release {
        cmd.arg("--release");
    }

    if let Some(target) = target {
        cmd.arg("--target").arg(target);
    }

    if let Some(target_dir) = target_dir {
        cmd.arg("--target-dir").arg(target_dir);
    }

    Ok(cmd.spawn()?.status().await?)
}

pub async fn build(release: bool) -> anyhow::Result<ExitStatus> {
    build_package(release, PACKAGE, None, None).await
}

pub async fn build_multichain(release: bool) -> anyhow::Result<ExitStatus> {
    build_package(release, PACKAGE_MULTICHAIN, None, None).await
}

pub async fn build_multichain_contract() -> anyhow::Result<ExitStatus> {
    // We use a different target directory to stop the different rustflags between targets from clobbering the build cache
    build_package(
        true,
        PACKAGE_CONTRACT,
        Some(TARGET_CONTRACT),
        Some(TARGET_CONTRACT_DIR),
    )
    .await
}

pub async fn spawn(release: bool, node: &str, cli: Cli) -> anyhow::Result<NodeProcess> {
    if cfg!(feature = "flamegraph") {
        let handle: std::thread::JoinHandle<anyhow::Result<()>> = std::thread::spawn(|| {
            let rt = Runtime::new()?;
            rt.block_on(async move {
                mpc_recovery::run(cli).await?;
                anyhow::Result::<(), anyhow::Error>::Ok(())
            })
            .unwrap();
            Ok(())
        });

        return Ok(NodeProcess::Threaded(handle));
    }

    let executable = executable(release, PACKAGE)
        .with_context(|| format!("could not find target dir while starting {node} node"))?;
    let child = Command::new(executable)
        .args(cli.into_str_args())
        .env("RUST_LOG", "mpc_recovery=INFO")
        .envs(std::env::vars())
        .stdout(Stdio::inherit())
        .stderr(Stdio::inherit())
        .kill_on_drop(true)
        .spawn()
        .with_context(|| format!("failed to execute {node} node"))?;

    Ok(NodeProcess::Subprocess(child))
}

pub fn spawn_multichain(
    release: bool,
    node: &str,
    cli: mpc_recovery_node::cli::Cli,
) -> anyhow::Result<Child> {
    let executable = executable(release, PACKAGE_MULTICHAIN)
        .with_context(|| format!("could not find target dir while starting {node} node"))?;

    Command::new(&executable)
        .args(cli.into_str_args())
        .env("RUST_LOG", "mpc_recovery_node=INFO")
        .envs(std::env::vars())
        .stdout(Stdio::inherit())
        .stderr(Stdio::inherit())
        .kill_on_drop(true)
        .spawn()
        .with_context(|| format!("failed to run {node} node: {}", executable.display()))
}

'''
'''--- integration-tests/src/multichain/containers.rs ---
use ed25519_dalek::ed25519::signature::digest::{consts::U32, generic_array::GenericArray};
use mpc_keys::hpke;
use multi_party_eddsa::protocols::ExpandedKeyPair;
use near_workspaces::AccountId;
use testcontainers::{
    core::{ExecCommand, WaitFor},
    Container, GenericImage, RunnableImage,
};
use tracing;

use super::MultichainConfig;

pub struct Node<'a> {
    pub container: Container<'a, GenericImage>,
    pub address: String,
    pub account_id: AccountId,
    pub account_sk: near_workspaces::types::SecretKey,
    pub local_address: String,
    pub cipher_pk: hpke::PublicKey,
    pub cipher_sk: hpke::SecretKey,
    pub sign_pk: near_workspaces::types::PublicKey,
}

pub struct NodeApi {
    pub address: String,
    pub node_id: usize,
    pub sk_share: ExpandedKeyPair,
    pub cipher_key: GenericArray<u8, U32>,
    pub gcp_project_id: String,
    pub gcp_datastore_local_url: String,
}

impl<'a> Node<'a> {
    // Container port used for the docker network, does not have to be unique
    const CONTAINER_PORT: u16 = 3000;

    pub async fn run(
        ctx: &super::Context<'a>,
        account_id: &AccountId,
        account_sk: &near_workspaces::types::SecretKey,
        cfg: &MultichainConfig,
    ) -> anyhow::Result<Node<'a>> {
        tracing::info!("running node container, account_id={}", account_id);
        let (cipher_sk, cipher_pk) = hpke::generate();
        let sign_sk =
            near_crypto::SecretKey::from_seed(near_crypto::KeyType::ED25519, "integration-test");
        let sign_pk = sign_sk.public_key();
        let storage_options = ctx.storage_options.clone();
        let args = mpc_recovery_node::cli::Cli::Start {
            near_rpc: ctx.lake_indexer.rpc_host_address.clone(),
            mpc_contract_id: ctx.mpc_contract.id().clone(),
            account_id: account_id.clone(),
            account_sk: account_sk.to_string().parse()?,
            web_port: Self::CONTAINER_PORT,
            cipher_pk: hex::encode(cipher_pk.to_bytes()),
            cipher_sk: hex::encode(cipher_sk.to_bytes()),
            sign_sk: Some(sign_sk),
            indexer_options: mpc_recovery_node::indexer::Options {
                s3_bucket: ctx.localstack.s3_bucket.clone(),
                s3_region: ctx.localstack.s3_region.clone(),
                s3_url: Some(ctx.localstack.s3_host_address.clone()),
                start_block_height: 0,
            },
            my_address: None,
            storage_options: storage_options.clone(),
            min_triples: cfg.triple_cfg.min_triples,
            max_triples: cfg.triple_cfg.max_triples,
            max_concurrent_introduction: cfg.triple_cfg.max_concurrent_introduction,
            max_concurrent_generation: cfg.triple_cfg.max_concurrent_generation,
            min_presignatures: cfg.presig_cfg.min_presignatures,
            max_presignatures: cfg.presig_cfg.max_presignatures,
        }
        .into_str_args();
        let image: GenericImage = GenericImage::new("near/mpc-recovery-node", "latest")
            .with_wait_for(WaitFor::Nothing)
            .with_exposed_port(Self::CONTAINER_PORT)
            .with_env_var("RUST_LOG", "mpc_recovery_node=DEBUG")
            .with_env_var("RUST_BACKTRACE", "1");
        let image: RunnableImage<GenericImage> = (image, args).into();
        let image = image.with_network(&ctx.docker_network);
        let container = ctx.docker_client.cli.run(image);
        let ip_address = ctx
            .docker_client
            .get_network_ip_address(&container, &ctx.docker_network)
            .await?;
        let host_port = container.get_host_port_ipv4(Self::CONTAINER_PORT);

        container.exec(ExecCommand {
            cmd: format!("bash -c 'while [[ \"$(curl -s -o /dev/null -w ''%{{http_code}}'' localhost:{})\" != \"200\" ]]; do sleep 1; done'", Self::CONTAINER_PORT),
            ready_conditions: vec![WaitFor::message_on_stdout("node is ready to accept connections")]
        });

        let full_address = format!("http://{ip_address}:{}", Self::CONTAINER_PORT);
        tracing::info!(
            full_address,
            "node container is running, account_id={}",
            account_id
        );
        Ok(Node {
            container,
            address: full_address,
            account_id: account_id.clone(),
            account_sk: account_sk.clone(),
            local_address: format!("http://localhost:{host_port}"),
            cipher_pk,
            cipher_sk,
            sign_pk: sign_pk.to_string().parse()?,
        })
    }

    pub fn kill(&self) {
        self.container.stop();
    }
}

'''
'''--- integration-tests/src/multichain/local.rs ---
use crate::{mpc, util};
use async_process::Child;
use mpc_keys::hpke;
use mpc_recovery_node::storage;
use near_workspaces::AccountId;

use super::MultichainConfig;

#[allow(dead_code)]
pub struct Node {
    pub address: String,
    pub account_id: AccountId,
    pub account_sk: near_workspaces::types::SecretKey,
    pub sign_sk: near_crypto::SecretKey,
    pub cipher_pk: hpke::PublicKey,
    cipher_sk: hpke::SecretKey,
    storage_options: storage::Options,

    // process held so it's not dropped. Once dropped, process will be killed.
    process: Child,
}

impl Node {
    pub async fn run(
        ctx: &super::Context<'_>,
        account_id: &AccountId,
        account_sk: &near_workspaces::types::SecretKey,
        cfg: &MultichainConfig,
    ) -> anyhow::Result<Self> {
        let web_port = util::pick_unused_port().await?;
        let (cipher_sk, cipher_pk) = hpke::generate();
        let sign_sk =
            near_crypto::SecretKey::from_seed(near_crypto::KeyType::ED25519, "integration-test");

        let storage_options = ctx.storage_options.clone();
        let cli = mpc_recovery_node::cli::Cli::Start {
            near_rpc: ctx.lake_indexer.rpc_host_address.clone(),
            mpc_contract_id: ctx.mpc_contract.id().clone(),
            account_id: account_id.clone(),
            account_sk: account_sk.to_string().parse()?,
            web_port,
            cipher_pk: hex::encode(cipher_pk.to_bytes()),
            cipher_sk: hex::encode(cipher_sk.to_bytes()),
            sign_sk: Some(sign_sk.clone()),
            indexer_options: mpc_recovery_node::indexer::Options {
                s3_bucket: ctx.localstack.s3_bucket.clone(),
                s3_region: ctx.localstack.s3_region.clone(),
                s3_url: Some(ctx.localstack.s3_host_address.clone()),
                start_block_height: 0,
            },
            my_address: None,
            storage_options: storage_options.clone(),
            min_triples: cfg.triple_cfg.min_triples,
            max_triples: cfg.triple_cfg.max_triples,
            max_concurrent_introduction: cfg.triple_cfg.max_concurrent_introduction,
            max_concurrent_generation: cfg.triple_cfg.max_concurrent_generation,
            min_presignatures: cfg.presig_cfg.min_presignatures,
            max_presignatures: cfg.presig_cfg.max_presignatures,
        };

        let mpc_node_id = format!("multichain/{account_id}", account_id = account_id);
        let process = mpc::spawn_multichain(ctx.release, &mpc_node_id, cli)?;
        let address = format!("http://127.0.0.1:{web_port}");
        tracing::info!("node is starting at {}", address);
        util::ping_until_ok(&address, 60).await?;
        tracing::info!("node started [node_account_id={account_id}, {address}]");

        Ok(Self {
            address,
            account_id: account_id.clone(),
            account_sk: account_sk.clone(),
            sign_sk,
            cipher_pk,
            cipher_sk,
            storage_options,
            process,
        })
    }

    pub fn kill(&mut self) -> std::io::Result<()> {
        self.process.kill()?;
        tracing::info!(?self.account_id, ?self.address, "node killed");
        Ok(())
    }
}

impl Drop for Node {
    fn drop(&mut self) {
        self.kill().unwrap();
    }
}

'''
'''--- integration-tests/src/multichain/mod.rs ---
pub mod containers;
pub mod local;
pub mod utils;

use crate::env::containers::DockerClient;
use crate::mpc::TARGET_CONTRACT_DIR;
use crate::{initialize_lake_indexer, LakeIndexerCtx};
use mpc_contract::primitives::CandidateInfo;
use mpc_recovery_node::gcp::GcpService;
use mpc_recovery_node::protocol::presignature::PresignatureConfig;
use mpc_recovery_node::protocol::triple::TripleConfig;
use mpc_recovery_node::storage;
use mpc_recovery_node::storage::triple_storage::TripleNodeStorageBox;
use near_workspaces::network::Sandbox;
use near_workspaces::types::SecretKey;
use near_workspaces::{Account, AccountId, Contract, Worker};
use serde_json::json;
use std::collections::HashMap;

const NETWORK: &str = "mpc_it_network";

#[derive(Clone)]
pub struct MultichainConfig {
    pub nodes: usize,
    pub threshold: usize,
    pub triple_cfg: TripleConfig,
    pub presig_cfg: PresignatureConfig,
}

impl Default for MultichainConfig {
    fn default() -> Self {
        Self {
            nodes: 3,
            threshold: 2,
            triple_cfg: TripleConfig {
                min_triples: 8,
                max_triples: 80,
                max_concurrent_introduction: 8,
                max_concurrent_generation: 24,
            },
            presig_cfg: PresignatureConfig {
                min_presignatures: 2,
                max_presignatures: 20,
            },
        }
    }
}

pub enum Nodes<'a> {
    Local {
        ctx: Context<'a>,
        nodes: Vec<local::Node>,
    },
    Docker {
        ctx: Context<'a>,
        nodes: Vec<containers::Node<'a>>,
    },
}

impl Nodes<'_> {
    pub fn len(&self) -> usize {
        match self {
            Nodes::Local { nodes, .. } => nodes.len(),
            Nodes::Docker { nodes, .. } => nodes.len(),
        }
    }

    pub fn is_empty(&self) -> bool {
        self.len() == 0
    }

    pub fn ctx(&self) -> &Context {
        match self {
            Nodes::Local { ctx, .. } => ctx,
            Nodes::Docker { ctx, .. } => ctx,
        }
    }

    pub fn url(&self, id: usize) -> &str {
        match self {
            Nodes::Local { nodes, .. } => &nodes[id].address,
            Nodes::Docker { nodes, .. } => &nodes[id].address,
        }
    }

    pub fn near_acc_sk(&self) -> HashMap<AccountId, SecretKey> {
        let mut account_to_sk = HashMap::new();
        match self {
            Nodes::Local { nodes, .. } => {
                for node in nodes {
                    account_to_sk.insert(node.account_id.clone(), node.account_sk.clone());
                }
            }
            Nodes::Docker { nodes, .. } => {
                for node in nodes {
                    account_to_sk.insert(node.account_id.clone(), node.account_sk.clone());
                }
            }
        };
        account_to_sk
    }

    pub fn near_accounts(&self) -> Vec<Account> {
        self.near_acc_sk()
            .iter()
            .map(|(account_id, account_sk)| {
                Account::from_secret_key(account_id.clone(), account_sk.clone(), &self.ctx().worker)
            })
            .collect()
    }

    pub async fn start_node(
        &mut self,
        new_node_account_id: &AccountId,
        account_sk: &near_workspaces::types::SecretKey,
        cfg: &MultichainConfig,
    ) -> anyhow::Result<()> {
        tracing::info!(%new_node_account_id, "adding one more node");
        match self {
            Nodes::Local { ctx, nodes } => {
                nodes.push(local::Node::run(ctx, new_node_account_id, account_sk, cfg).await?)
            }
            Nodes::Docker { ctx, nodes } => {
                nodes.push(containers::Node::run(ctx, new_node_account_id, account_sk, cfg).await?)
            }
        }

        Ok(())
    }

    pub async fn kill_node(&mut self, account_id: &AccountId) -> anyhow::Result<()> {
        match self {
            Nodes::Local { nodes, .. } => {
                let (index, node) = nodes
                    .iter_mut()
                    .enumerate()
                    .find(|(_, node)| node.account_id == *account_id)
                    .unwrap();
                node.kill()?;
                nodes.remove(index);
            }
            Nodes::Docker { nodes, .. } => {
                let (index, node) = nodes
                    .iter_mut()
                    .enumerate()
                    .find(|(_, node)| node.account_id == *account_id)
                    .unwrap();
                node.kill();
                nodes.remove(index);
            }
        }

        // wait for the node to be removed from the network
        tokio::time::sleep(std::time::Duration::from_secs(1)).await;

        Ok(())
    }

    pub async fn triple_storage(
        &self,
        account_id: &AccountId,
    ) -> anyhow::Result<TripleNodeStorageBox> {
        let gcp_service = GcpService::init(account_id, &self.ctx().storage_options).await?;
        Ok(storage::triple_storage::init(
            Some(&gcp_service),
            account_id,
        ))
    }

    pub async fn gcp_services(&self) -> anyhow::Result<Vec<GcpService>> {
        let mut gcp_services = Vec::new();
        match self {
            Nodes::Local { nodes, .. } => {
                for node in nodes {
                    gcp_services.push(
                        GcpService::init(&node.account_id, &self.ctx().storage_options).await?,
                    );
                }
            }
            Nodes::Docker { nodes, .. } => {
                for node in nodes {
                    gcp_services.push(
                        GcpService::init(&node.account_id, &self.ctx().storage_options).await?,
                    );
                }
            }
        }
        Ok(gcp_services)
    }
}

pub struct Context<'a> {
    pub docker_client: &'a DockerClient,
    pub docker_network: String,
    pub release: bool,

    pub localstack: crate::env::containers::LocalStack<'a>,
    pub lake_indexer: crate::env::containers::LakeIndexer<'a>,
    pub worker: Worker<Sandbox>,
    pub mpc_contract: Contract,
    pub datastore: crate::env::containers::Datastore<'a>,
    pub storage_options: storage::Options,
}

pub async fn setup(docker_client: &DockerClient) -> anyhow::Result<Context<'_>> {
    if !crate::mpc::build_multichain_contract().await?.success() {
        anyhow::bail!("failed to prebuild multichain contract");
    }

    let release = true;
    if !crate::mpc::build_multichain(release).await?.success() {
        anyhow::bail!("failed to prebuild multichain node service");
    }

    let docker_network = NETWORK;
    docker_client.create_network(docker_network).await?;

    let LakeIndexerCtx {
        localstack,
        lake_indexer,
        worker,
    } = initialize_lake_indexer(docker_client, docker_network).await?;

    let mpc_contract = worker
        .dev_deploy(&std::fs::read(format!(
            "{}/wasm32-unknown-unknown/release/mpc_contract.wasm",
            TARGET_CONTRACT_DIR
        ))?)
        .await?;
    tracing::info!(contract_id = %mpc_contract.id(), "deployed mpc contract");

    let gcp_project_id = "multichain-integration";
    let datastore =
        crate::env::containers::Datastore::run(docker_client, docker_network, gcp_project_id)
            .await?;

    let storage_options = mpc_recovery_node::storage::Options {
        env: "local-test".to_string(),
        gcp_project_id: "multichain-integration".to_string(),
        sk_share_secret_id: None,
        gcp_datastore_url: Some(datastore.local_address.clone()),
    };
    Ok(Context {
        docker_client,
        docker_network: docker_network.to_string(),
        release,
        localstack,
        lake_indexer,
        worker,
        mpc_contract,
        datastore,
        storage_options,
    })
}

pub async fn docker(cfg: MultichainConfig, docker_client: &DockerClient) -> anyhow::Result<Nodes> {
    let ctx = setup(docker_client).await?;

    let accounts =
        futures::future::join_all((0..cfg.nodes).map(|_| ctx.worker.dev_create_account()))
            .await
            .into_iter()
            .collect::<Result<Vec<_>, _>>()?;
    let mut node_futures = Vec::new();
    for account in &accounts {
        let node = containers::Node::run(&ctx, account.id(), account.secret_key(), &cfg);
        node_futures.push(node);
    }
    let nodes = futures::future::join_all(node_futures)
        .await
        .into_iter()
        .collect::<Result<Vec<_>, _>>()?;
    let candidates: HashMap<AccountId, CandidateInfo> = accounts
        .iter()
        .cloned()
        .zip(&nodes)
        .map(|(account, node)| {
            (
                account.id().clone(),
                CandidateInfo {
                    account_id: account.id().to_string().parse().unwrap(),
                    url: node.address.clone(),
                    cipher_pk: node.cipher_pk.to_bytes(),
                    sign_pk: node.sign_pk.to_string().parse().unwrap(),
                },
            )
        })
        .collect();
    ctx.mpc_contract
        .call("init")
        .args_json(json!({
            "threshold": cfg.threshold,
            "candidates": candidates
        }))
        .transact()
        .await?
        .into_result()?;

    Ok(Nodes::Docker { ctx, nodes })
}

pub async fn host(cfg: MultichainConfig, docker_client: &DockerClient) -> anyhow::Result<Nodes> {
    let ctx = setup(docker_client).await?;

    let accounts =
        futures::future::join_all((0..cfg.nodes).map(|_| ctx.worker.dev_create_account()))
            .await
            .into_iter()
            .collect::<Result<Vec<_>, _>>()?;
    let mut node_futures = Vec::with_capacity(cfg.nodes);
    for account in accounts.iter().take(cfg.nodes) {
        node_futures.push(local::Node::run(
            &ctx,
            account.id(),
            account.secret_key(),
            &cfg,
        ));
    }
    let nodes = futures::future::join_all(node_futures)
        .await
        .into_iter()
        .collect::<Result<Vec<_>, _>>()?;
    let candidates: HashMap<AccountId, CandidateInfo> = accounts
        .iter()
        .cloned()
        .zip(&nodes)
        .map(|(account, node)| {
            (
                account.id().clone(),
                CandidateInfo {
                    account_id: account.id().to_string().parse().unwrap(),
                    url: node.address.clone(),
                    cipher_pk: node.cipher_pk.to_bytes(),
                    sign_pk: node.sign_sk.public_key().to_string().parse().unwrap(),
                },
            )
        })
        .collect();
    ctx.mpc_contract
        .call("init")
        .args_json(json!({
            "threshold": cfg.threshold,
            "candidates": candidates
        }))
        .transact()
        .await?
        .into_result()?;

    Ok(Nodes::Local { ctx, nodes })
}

pub async fn run(cfg: MultichainConfig, docker_client: &DockerClient) -> anyhow::Result<Nodes> {
    #[cfg(feature = "docker-test")]
    return docker(cfg, docker_client).await;

    #[cfg(not(feature = "docker-test"))]
    return host(cfg, docker_client).await;
}

'''
'''--- integration-tests/src/multichain/utils.rs ---
use near_workspaces::{result::ExecutionFinalResult, Account, AccountId};

pub async fn vote_join(
    accounts: Vec<Account>,
    mpc_contract: &AccountId,
    account_id: &AccountId,
) -> anyhow::Result<()> {
    let vote_futures = accounts
        .iter()
        .map(|account| {
            tracing::info!(
                "{} voting for new participant: {}",
                account.id(),
                account_id
            );
            account
                .call(mpc_contract, "vote_join")
                .args_json(serde_json::json!({
                    "candidate_account_id": account_id
                }))
                .transact()
        })
        .collect::<Vec<_>>();

    futures::future::join_all(vote_futures)
        .await
        .iter()
        .for_each(|result| {
            assert!(result.as_ref().unwrap().failures().is_empty());
        });

    Ok(())
}

pub async fn vote_leave(
    accounts: Vec<Account>,
    mpc_contract: &AccountId,
    account_id: &AccountId,
) -> Vec<Result<ExecutionFinalResult, near_workspaces::error::Error>> {
    let vote_futures = accounts
        .iter()
        .filter(|account| account.id() != account_id)
        .map(|account| {
            account
                .call(mpc_contract, "vote_leave")
                .args_json(serde_json::json!({
                    "kick": account_id
                }))
                .transact()
        })
        .collect::<Vec<_>>();

    futures::future::join_all(vote_futures).await
}

'''
'''--- integration-tests/src/sandbox.rs ---
use near_workspaces::types::NearToken;
use near_workspaces::{network::Sandbox, types::SecretKey, AccessKey, Account, Contract, Worker};

const BATCH_COUNT_LIMIT: usize = 100;

pub async fn initialize_social_db(worker: &Worker<Sandbox>) -> anyhow::Result<Contract> {
    tracing::info!("Initializing social DB contract...");
    let social_db = worker
        .import_contract(&"social.near".parse()?, &near_workspaces::mainnet().await?)
        .transact()
        .await?;
    social_db
        .call("new")
        .max_gas()
        .transact()
        .await?
        .into_result()?;

    tracing::info!("Social DB contract initialized");
    Ok(social_db)
}

// Linkdrop contains top-level account creation logic
pub async fn initialize_linkdrop(worker: &Worker<Sandbox>) -> anyhow::Result<()> {
    tracing::info!("Initializing linkdrop contract...");
    let near_root_account = worker.root_account()?;
    near_root_account
        .deploy(include_bytes!("../linkdrop.wasm"))
        .await?
        .into_result()?;
    near_root_account
        .call(near_root_account.id(), "new")
        .max_gas()
        .transact()
        .await?
        .into_result()?;

    tracing::info!("Linkdrop contract initialized");
    Ok(())
}

pub async fn create_account(
    worker: &Worker<Sandbox>,
    prefix: &str,
    initial_balance: NearToken,
) -> anyhow::Result<Account> {
    tracing::info!("Creating account with random account_id...");
    let new_account = worker
        .root_account()?
        .create_subaccount(prefix)
        .initial_balance(initial_balance)
        .transact()
        .await?
        .into_result()?;

    tracing::info!("Account created: {}", new_account.id());
    Ok(new_account)
}

pub async fn gen_rotating_keys(account: &Account, amount: usize) -> anyhow::Result<Vec<SecretKey>> {
    let mut keys = Vec::with_capacity(amount + 1);
    keys.push(account.secret_key().clone());

    // Each batch transaction has a limit of BATCH_COUNT_LIMIT actions.
    let num_batches = amount / BATCH_COUNT_LIMIT + 1;
    let rem_batches = amount % BATCH_COUNT_LIMIT;
    let batch_counts = (0..num_batches).map(|i| {
        if i == num_batches - 1 {
            rem_batches
        } else {
            BATCH_COUNT_LIMIT
        }
    });

    for batch_count in batch_counts {
        let mut batch_tx = account.batch(account.id());
        for _ in 0..batch_count {
            let sk = SecretKey::from_seed(
                near_workspaces::types::KeyType::ED25519,
                &rand::Rng::sample_iter(rand::thread_rng(), &rand::distributions::Alphanumeric)
                    .take(10)
                    .map(char::from)
                    .collect::<String>(),
            );
            batch_tx = batch_tx.add_key(sk.public_key(), AccessKey::full_access());
            keys.push(sk);
        }
        batch_tx.transact().await?.into_result()?;
    }

    Ok(keys)
}

'''
'''--- integration-tests/src/util.rs ---
use std::{
    fs::{self, File},
    io::Write,
};

use crate::containers::RelayerConfig;
use anyhow::Context;
use hyper::{Body, Client, Method, Request, StatusCode, Uri};
use near_workspaces::{types::SecretKey, AccountId};
use serde::{Deserialize, Serialize};
use toml::Value;

pub async fn post<U, Req: Serialize, Resp>(
    uri: U,
    request: Req,
) -> anyhow::Result<(StatusCode, Resp)>
where
    Uri: TryFrom<U>,
    <Uri as TryFrom<U>>::Error: Into<hyper::http::Error>,
    for<'de> Resp: Deserialize<'de>,
{
    let req = Request::builder()
        .method(Method::POST)
        .uri(uri)
        .header("content-type", "application/json")
        .body(Body::from(
            serde_json::to_string(&request).context("failed to serialize the request body")?,
        ))
        .context("failed to build the request")?;

    let client = Client::new();
    let response = client
        .request(req)
        .await
        .context("failed to send the request")?;
    let status = response.status();

    let data = hyper::body::to_bytes(response)
        .await
        .context("failed to read the response body")?;
    let response: Resp =
        serde_json::from_slice(&data).context("failed to deserialize the response body")?;

    Ok((status, response))
}

pub async fn get<U>(uri: U) -> anyhow::Result<StatusCode>
where
    Uri: TryFrom<U>,
    <Uri as TryFrom<U>>::Error: Into<hyper::http::Error>,
{
    let req = Request::builder()
        .method(Method::GET)
        .uri(uri)
        .header("content-type", "application/json")
        .body(Body::empty())
        .context("failed to build the request")?;

    let client = Client::new();
    let response = client
        .request(req)
        .await
        .context("failed to send the request")?;
    Ok(response.status())
}

#[derive(Deserialize, Serialize)]
struct KeyFile {
    account_id: String,
    public_key: String,
    private_key: String,
}

pub fn create_key_file(
    account_id: &AccountId,
    account_sk: &SecretKey,
    key_dir: &str,
) -> anyhow::Result<(), anyhow::Error> {
    create_key_file_with_filepath(
        account_id,
        account_sk,
        &format!("{key_dir}/{account_id}.json"),
    )
}

pub fn create_key_file_with_filepath(
    account_id: &AccountId,
    account_sk: &SecretKey,
    filepath: &str,
) -> anyhow::Result<(), anyhow::Error> {
    let key_file = KeyFile {
        account_id: account_id.to_string(),
        public_key: account_sk.public_key().to_string(),
        private_key: account_sk.to_string(),
    };
    let key_json_str = serde_json::to_string(&key_file).expect("Failed to serialize to JSON");
    let mut json_key_file = File::create(filepath).expect("Failed to create JSON key file");
    json_key_file
        .write_all(key_json_str.as_bytes())
        .expect("Failed to write to JSON key file");
    Ok(())
}

pub fn create_relayer_cofig_file(
    config: RelayerConfig,
    config_path: String,
) -> anyhow::Result<String, anyhow::Error> {
    let mut config_table = Value::Table(toml::value::Table::new());
    let table = config_table.as_table_mut().unwrap();

    table.insert(
        "ip_address".to_string(),
        Value::Array(
            config
                .ip_address
                .iter()
                .map(|ip| Value::Integer(i64::from(*ip)))
                .collect(),
        ),
    );
    table.insert("port".to_string(), Value::Integer(i64::from(config.port)));

    let relayer_account_id = config.relayer_account_id.to_string();

    table.insert(
        "relayer_account_id".to_string(),
        Value::String(relayer_account_id.clone()),
    );
    table.insert(
        "keys_filenames".to_string(),
        Value::Array(
            config
                .keys_filenames
                .iter()
                .map(|filename| Value::String(filename.to_string()))
                .collect(),
        ),
    );

    table.insert(
        "shared_storage_account_id".to_string(),
        Value::String(config.shared_storage_account_id.to_string()),
    );
    table.insert(
        "shared_storage_keys_filename".to_string(),
        Value::String(config.shared_storage_keys_filename),
    );

    table.insert(
        "whitelisted_contracts".to_string(),
        Value::Array(
            config
                .whitelisted_contracts
                .iter()
                .map(|account_id| Value::String(account_id.to_string()))
                .collect(),
        ),
    );
    table.insert(
        "whitelisted_delegate_action_receiver_ids".to_string(),
        Value::Array(
            config
                .whitelisted_delegate_action_receiver_ids
                .iter()
                .map(|account_id| Value::String(account_id.to_string()))
                .collect(),
        ),
    );

    table.insert(
        "redis_url".to_string(),
        Value::String(config.redis_url.to_string()),
    );
    table.insert(
        "social_db_contract_id".to_string(),
        Value::String(config.social_db_contract_id.to_string()),
    );

    table.insert(
        "rpc_url".to_string(),
        Value::String(config.rpc_url.to_string()),
    );
    table.insert(
        "wallet_url".to_string(),
        Value::String(config.wallet_url.to_string()),
    ); // not used
    table.insert(
        "explorer_transaction_url".to_string(),
        Value::String(config.explorer_transaction_url.to_string()),
    ); // not used
    table.insert("rpc_api_key".to_string(), Value::String(config.rpc_api_key)); // not used

    let mut file =
        File::create(&config_path).unwrap_or_else(|_| panic!("Failed to write to {}", config_path));
    let toml_string = toml::to_string(&config_table).expect("Failed to convert to TOML string");
    file.write_all(toml_string.as_bytes())
        .unwrap_or_else(|_| panic!("Failed to write to {}", config_path));

    let config_absolute_path = fs::canonicalize(&config_path)
        .unwrap_or_else(|_| panic!("Failed to get absolute path to {}", config_path));
    Ok(config_absolute_path
        .to_str()
        .expect("Failed to convert config file path to string")
        .to_string())
}

/// Request an unused port from the OS.
pub async fn pick_unused_port() -> anyhow::Result<u16> {
    // Port 0 means the OS gives us an unused port
    // Important to use localhost as using 0.0.0.0 leads to users getting brief firewall popups to
    // allow inbound connections on MacOS.
    let addr = std::net::SocketAddrV4::new(std::net::Ipv4Addr::LOCALHOST, 0);
    let listener = tokio::net::TcpListener::bind(addr).await?;
    let port = listener.local_addr()?.port();
    Ok(port)
}

pub async fn ping_until_ok(addr: &str, timeout: u64) -> anyhow::Result<()> {
    tokio::time::timeout(std::time::Duration::from_secs(timeout), async {
        loop {
            match get(addr).await {
                Ok(status) if status == StatusCode::OK => break,
                _ => tokio::time::sleep(std::time::Duration::from_millis(500)).await,
            }
        }
    })
    .await?;
    Ok(())
}

'''
'''--- integration-tests/tests/lib.rs ---
mod mpc;
mod multichain;

use anyhow::anyhow;
use std::str::FromStr;

use curv::elliptic::curves::{Ed25519, Point};
use futures::future::BoxFuture;
use hyper::StatusCode;
use mpc_recovery::{
    gcp::GcpService,
    msg::{
        ClaimOidcResponse, MpcPkResponse, NewAccountResponse, SignResponse, UserCredentialsResponse,
    },
};
use mpc_recovery_integration_tests::{
    env,
    multichain::utils::{vote_join, vote_leave},
};
use mpc_recovery_integration_tests::{env::containers::DockerClient, multichain::MultichainConfig};
use near_jsonrpc_client::JsonRpcClient;
use near_workspaces::{network::Sandbox, Account, AccountId, Worker};

use crate::multichain::actions::wait_for;

pub struct TestContext {
    env: String,
    leader_node: env::LeaderNodeApi,
    pk_set: Vec<Point<Ed25519>>,
    worker: Worker<Sandbox>,
    signer_nodes: Vec<env::SignerNodeApi>,
    gcp_project_id: String,
    gcp_datastore_url: String,
}

impl TestContext {
    pub async fn gcp_service(&self) -> anyhow::Result<GcpService> {
        GcpService::new(
            self.env.clone(),
            self.gcp_project_id.clone(),
            Some(self.gcp_datastore_url.clone()),
        )
        .await
    }
}

async fn with_nodes<Task, Fut, Val>(nodes: usize, f: Task) -> anyhow::Result<()>
where
    Task: FnOnce(TestContext) -> Fut,
    Fut: core::future::Future<Output = anyhow::Result<Val>>,
{
    let docker_client = DockerClient::default();
    let nodes = env::run(nodes, &docker_client).await?;

    f(TestContext {
        env: nodes.ctx().env.clone(),
        pk_set: nodes.pk_set(),
        leader_node: nodes.leader_api(),
        signer_nodes: nodes.signer_apis(),
        worker: nodes.ctx().relayer_ctx.worker.clone(),
        gcp_project_id: nodes.ctx().gcp_project_id.clone(),
        gcp_datastore_url: nodes.datastore_addr(),
    })
    .await?;

    nodes.ctx().relayer_ctx.relayer.clean_tmp_files()?;

    Ok(())
}

pub struct MultichainTestContext<'a> {
    nodes: mpc_recovery_integration_tests::multichain::Nodes<'a>,
    rpc_client: near_fetch::Client,
    jsonrpc_client: JsonRpcClient,
    http_client: reqwest::Client,
    cfg: MultichainConfig,
}

impl MultichainTestContext<'_> {
    pub async fn participant_accounts(&self) -> anyhow::Result<Vec<Account>> {
        let node_accounts: Vec<Account> = self.nodes.near_accounts();
        let state = wait_for::running_mpc(self, None).await?;
        let participant_ids = state.participants.keys().collect::<Vec<_>>();
        let participant_accounts: Vec<Account> = participant_ids
            .iter()
            .map(|id| near_workspaces::types::AccountId::from_str(id.as_ref()).unwrap())
            .map(|id| {
                node_accounts
                    .iter()
                    .find(|a| a.id() == &id)
                    .unwrap()
                    .clone()
            })
            .collect();
        Ok(participant_accounts)
    }

    pub async fn add_participant(&mut self) -> anyhow::Result<()> {
        let state = wait_for::running_mpc(self, None).await?;

        let new_node_account = self.nodes.ctx().worker.dev_create_account().await?;
        tracing::info!("Adding a new participant: {}", new_node_account.id());
        self.nodes
            .start_node(
                new_node_account.id(),
                new_node_account.secret_key(),
                &self.cfg,
            )
            .await?;

        // Wait for new node to add itself as a candidate
        tokio::time::sleep(tokio::time::Duration::from_secs(5)).await;

        // T number of participants should vote
        let participants = self.participant_accounts().await?;
        let voting_participants = participants
            .iter()
            .take(state.threshold)
            .cloned()
            .collect::<Vec<_>>();
        assert!(vote_join(
            voting_participants,
            self.nodes.ctx().mpc_contract.id(),
            new_node_account.id()
        )
        .await
        .is_ok());

        let new_state = wait_for::running_mpc(self, Some(state.epoch + 1)).await?;
        assert_eq!(new_state.participants.len(), state.participants.len() + 1);
        assert_eq!(
            state.public_key, new_state.public_key,
            "public key must stay the same"
        );

        Ok(())
    }

    pub async fn remove_participant(
        &mut self,
        leaving_account_id: Option<&AccountId>,
    ) -> anyhow::Result<()> {
        let state = wait_for::running_mpc(self, None).await?;
        let participant_accounts = self.participant_accounts().await?;
        let leaving_account_id =
            leaving_account_id.unwrap_or_else(|| participant_accounts.last().unwrap().id());
        tracing::info!("Removing participant: {}", leaving_account_id);

        let voting_accounts = participant_accounts
            .iter()
            .filter(|account| account.id() != leaving_account_id)
            .take(state.threshold)
            .cloned()
            .collect::<Vec<Account>>();

        let results = vote_leave(
            voting_accounts,
            self.nodes.ctx().mpc_contract.id(),
            leaving_account_id,
        )
        .await;

        // Check if any result has failures, and return early with an error if so
        if results
            .iter()
            .any(|result| !result.as_ref().unwrap().failures().is_empty())
        {
            return Err(anyhow!("Failed to vote_leave"));
        }

        let new_state = wait_for::running_mpc(self, Some(state.epoch + 1)).await?;
        assert_eq!(state.participants.len(), new_state.participants.len() + 1);

        assert_eq!(
            state.public_key, new_state.public_key,
            "public key must stay the same"
        );

        self.nodes.kill_node(leaving_account_id).await.unwrap();
        Ok(())
    }
}

async fn with_multichain_nodes<F>(cfg: MultichainConfig, f: F) -> anyhow::Result<()>
where
    F: for<'a> FnOnce(MultichainTestContext<'a>) -> BoxFuture<'a, anyhow::Result<()>>,
{
    let docker_client = DockerClient::default();
    let nodes =
        mpc_recovery_integration_tests::multichain::run(cfg.clone(), &docker_client).await?;

    let connector = JsonRpcClient::new_client();
    let jsonrpc_client = connector.connect(&nodes.ctx().lake_indexer.rpc_host_address);
    let rpc_client = near_fetch::Client::from_client(jsonrpc_client.clone());
    f(MultichainTestContext {
        nodes,
        rpc_client,
        jsonrpc_client,
        http_client: reqwest::Client::default(),
        cfg,
    })
    .await?;

    Ok(())
}

mod account {
    use near_workspaces::{network::Sandbox, AccountId, Worker};
    use rand::{distributions::Alphanumeric, Rng};

    pub fn random(worker: &Worker<Sandbox>) -> anyhow::Result<AccountId> {
        let account_id_rand: String = rand::thread_rng()
            .sample_iter(&Alphanumeric)
            .take(10)
            .map(char::from)
            .collect();
        Ok(format!(
            "mpc-recovery-{}.{}",
            account_id_rand.to_lowercase(),
            worker.root_account()?.id()
        )
        .parse()?)
    }

    pub fn malformed() -> String {
        let random: String = rand::thread_rng()
            .sample_iter(&Alphanumeric)
            .take(10)
            .map(char::from)
            .collect();
        format!("malformed-account-{}-!@#$%", random.to_lowercase())
    }
}

mod key {
    use near_crypto::{PublicKey, SecretKey};
    use rand::{distributions::Alphanumeric, Rng};

    pub fn random() -> (SecretKey, PublicKey) {
        let sk = random_sk();
        let pk = sk.public_key();
        (sk, pk)
    }

    pub fn random_sk() -> SecretKey {
        near_crypto::SecretKey::from_random(near_crypto::KeyType::ED25519)
    }

    pub fn random_pk() -> PublicKey {
        near_crypto::SecretKey::from_random(near_crypto::KeyType::ED25519).public_key()
    }

    #[allow(dead_code)]
    pub fn malformed_pk() -> String {
        let random: String = rand::thread_rng()
            .sample_iter(&Alphanumeric)
            .take(10)
            .map(char::from)
            .collect();
        format!("malformed-key-{}-!@#$%", random.to_lowercase())
    }
}

mod check {
    use crate::TestContext;
    use near_crypto::PublicKey;
    use near_workspaces::AccountId;

    pub async fn access_key_exists(
        ctx: &TestContext,
        account_id: &AccountId,
        public_key: &PublicKey,
    ) -> anyhow::Result<()> {
        let access_keys = ctx.worker.view_access_keys(account_id).await?;

        if access_keys
            .iter()
            .any(|ak| ak.public_key.key_data() == public_key.key_data())
        {
            Ok(())
        } else {
            Err(anyhow::anyhow!(
                "could not find access key {public_key} on account {account_id}"
            ))
        }
    }

    pub async fn access_key_does_not_exists(
        ctx: &TestContext,
        account_id: &AccountId,
        public_key: &str,
    ) -> anyhow::Result<()> {
        let access_keys = ctx.worker.view_access_keys(account_id).await?;

        if access_keys
            .iter()
            .any(|ak| ak.public_key.to_string() == public_key)
        {
            Err(anyhow::anyhow!(
                "Access key {public_key} still added to the account {account_id}"
            ))
        } else {
            Ok(())
        }
    }
}

// Kept the dead code around because it will be useful in testing and it's implemented everywhere
trait MpcCheck {
    type Response;

    fn assert_ok(self) -> anyhow::Result<Self::Response>;
    fn assert_bad_request_contains(self, expected: &str) -> anyhow::Result<Self::Response>;
    fn assert_unauthorized_contains(self, expected: &str) -> anyhow::Result<Self::Response>;
    #[allow(dead_code)]
    fn assert_internal_error_contains(self, expected: &str) -> anyhow::Result<Self::Response>;
    fn assert_dependency_error_contains(self, expected: &str) -> anyhow::Result<Self::Response>;

    #[allow(dead_code)]
    fn assert_bad_request(self) -> anyhow::Result<Self::Response>
    where
        Self: Sized,
    {
        self.assert_bad_request_contains("")
    }
    fn assert_unauthorized(self) -> anyhow::Result<Self::Response>
    where
        Self: Sized,
    {
        self.assert_unauthorized_contains("")
    }
    #[allow(dead_code)]
    fn assert_internal_error(self) -> anyhow::Result<Self::Response>
    where
        Self: Sized,
    {
        self.assert_internal_error_contains("")
    }
}

// Presumes that $response::Err has a `msg: String` field.
#[macro_export]
macro_rules! impl_mpc_check {
    ( $response:ident ) => {
        impl MpcCheck for (StatusCode, $response) {
            type Response = $response;

            fn assert_ok(self) -> anyhow::Result<Self::Response> {
                let status_code = self.0;
                let response = self.1;

                if status_code == StatusCode::OK {
                    let $response::Ok { .. } = response else {
                        anyhow::bail!("failed to get a signature from mpc-recovery");
                    };

                    Ok(response)
                } else {
                    let $response::Err { .. } = response else {
                        anyhow::bail!("unexpected Ok with a non-200 http code ({status_code})");
                    };
                    anyhow::bail!(
                        "expected 200, but got {status_code} with response: {response:?}"
                    );
                }
            }

            fn assert_bad_request_contains(self, expected: &str) -> anyhow::Result<Self::Response> {
                let status_code = self.0;
                let response = self.1;

                if status_code == StatusCode::BAD_REQUEST {
                    let $response::Err { ref msg, .. } = response else {
                        anyhow::bail!("unexpected Ok with a 400 http code");
                    };
                    assert!(msg.contains(expected), "{expected:?} not in {msg:?}");

                    Ok(response)
                } else {
                    anyhow::bail!(
                        "expected 400, but got {status_code} with response: {response:?}"
                    );
                }
            }

            fn assert_unauthorized_contains(
                self,
                expected: &str,
            ) -> anyhow::Result<Self::Response> {
                let status_code = self.0;
                let response = self.1;

                if status_code == StatusCode::UNAUTHORIZED {
                    let $response::Err { ref msg, .. } = response else {
                        anyhow::bail!("unexpected Ok with a 401 http code");
                    };
                    assert!(msg.contains(expected), "{expected:?} not in {msg:?}");

                    Ok(response)
                } else {
                    anyhow::bail!(
                        "expected 401, but got {status_code} with response: {response:?}"
                    );
                }
            }
            // ideally we should not have situations where we can get INTERNAL_SERVER_ERROR
            fn assert_internal_error_contains(
                self,
                expected: &str,
            ) -> anyhow::Result<Self::Response> {
                let status_code = self.0;
                let response = self.1;

                if status_code == StatusCode::INTERNAL_SERVER_ERROR {
                    let $response::Err { ref msg, .. } = response else {
                        anyhow::bail!("unexpected error with a 401 http code");
                    };
                    assert!(msg.contains(expected));

                    Ok(response)
                } else {
                    anyhow::bail!(
                        "expected 401, but got {status_code} with response: {response:?}"
                    );
                }
            }
            fn assert_dependency_error_contains(
                self,
                expected: &str,
            ) -> anyhow::Result<Self::Response> {
                let status_code = self.0;
                let response = self.1;

                if status_code == StatusCode::FAILED_DEPENDENCY {
                    let $response::Err { ref msg, .. } = response else {
                        anyhow::bail!("unexpected error with a 424 http code");
                    };
                    assert!(msg.contains(expected));

                    Ok(response)
                } else {
                    anyhow::bail!(
                        "expected 424, but got {status_code} with response: {response:?}"
                    );
                }
            }
        }
    };
}

impl_mpc_check!(SignResponse);
impl_mpc_check!(NewAccountResponse);
impl_mpc_check!(MpcPkResponse);
impl_mpc_check!(ClaimOidcResponse);
impl_mpc_check!(UserCredentialsResponse);

'''
'''--- integration-tests/tests/mpc/mod.rs ---
use std::time::Duration;

use mpc_recovery::msg::{NewAccountResponse, UserCredentialsResponse};
use mpc_recovery::sign_node::oidc::OidcToken;
use mpc_recovery::transaction::LimitedAccessKey;
use near_crypto::{PublicKey, SecretKey};
use near_workspaces::AccountId;

use crate::{account, check, key, MpcCheck, TestContext};

mod negative;
mod positive;

pub async fn register_account(
    ctx: &TestContext,
    user_id: &AccountId,
    user_sk: &SecretKey,
    user_pk: &PublicKey,
    user_oidc: &OidcToken,
    user_lak: Option<LimitedAccessKey>,
) -> anyhow::Result<()> {
    // Claim OIDC token
    ctx.leader_node
        .claim_oidc_with_helper(user_oidc, user_pk, user_sk)
        .await?;

    // Create account
    let new_acc_response = ctx
        .leader_node
        .new_account_with_helper(user_id, user_pk, user_lak, user_sk, user_oidc)
        .await?
        .assert_ok()?;

    assert!(matches!(new_acc_response, NewAccountResponse::Ok {
            create_account_options: _,
            user_recovery_public_key: _,
            near_account_id,
        } if &near_account_id == user_id
    ));

    tokio::time::sleep(Duration::from_millis(2000)).await;
    check::access_key_exists(ctx, user_id, user_pk).await?;

    Ok(())
}

pub async fn new_random_account(
    ctx: &TestContext,
    user_lak: Option<LimitedAccessKey>,
) -> anyhow::Result<(AccountId, SecretKey, OidcToken)> {
    let account_id = account::random(&ctx.worker)?;
    let user_secret_key = key::random_sk();
    let user_public_key = user_secret_key.public_key();
    let oidc_token = OidcToken::random_valid();

    register_account(
        ctx,
        &account_id,
        &user_secret_key,
        &user_public_key,
        &oidc_token,
        user_lak,
    )
    .await?;
    Ok((account_id, user_secret_key, oidc_token))
}

pub async fn fetch_recovery_pk(
    ctx: &TestContext,
    user_sk: &SecretKey,
    user_oidc: &OidcToken,
) -> anyhow::Result<PublicKey> {
    let recovery_pk = match ctx
        .leader_node
        .user_credentials_with_helper(user_oidc, user_sk, &user_sk.public_key())
        .await?
        .assert_ok()?
    {
        UserCredentialsResponse::Ok { recovery_pk } => recovery_pk,
        UserCredentialsResponse::Err { msg } => anyhow::bail!("error response: {}", msg),
    };
    Ok(recovery_pk)
}

/// Add a new random public key or a supplied public key.
pub async fn add_pk_and_check_validity(
    ctx: &TestContext,
    user_id: &AccountId,
    user_sk: &SecretKey,
    user_oidc: &OidcToken,
    user_recovery_pk: &PublicKey,
    pk_to_add: Option<PublicKey>,
) -> anyhow::Result<PublicKey> {
    let new_user_pk = pk_to_add.unwrap_or_else(key::random_pk);
    ctx.leader_node
        .add_key_with_helper(
            user_id,
            user_oidc,
            &new_user_pk,
            user_recovery_pk,
            user_sk,
            &user_sk.public_key(),
        )
        .await?
        .assert_ok()?;
    tokio::time::sleep(Duration::from_millis(2000)).await;
    check::access_key_exists(ctx, user_id, &new_user_pk).await?;
    Ok(new_user_pk)
}

'''
'''--- integration-tests/tests/mpc/negative.rs ---
use crate::mpc::{fetch_recovery_pk, register_account};
use crate::{account, check, key, with_nodes, MpcCheck};
use anyhow::Context;
use ed25519_dalek::{PublicKey as PublicKeyEd25519, Signature, Verifier};
use hyper::StatusCode;
use mpc_recovery::sign_node::oidc::OidcToken;
use mpc_recovery::utils::user_credentials_request_digest;
use mpc_recovery::{
    msg::{ClaimOidcRequest, MpcPkRequest, NewAccountResponse, UserCredentialsResponse},
    utils::{claim_oidc_request_digest, claim_oidc_response_digest, sign_digest},
};
use multi_party_eddsa::protocols::ExpandedKeyPair;
use near_primitives::{
    account::AccessKey,
    delegate_action::DelegateAction,
    transaction::{
        Action, AddKeyAction, CreateAccountAction, DeleteAccountAction, DeleteKeyAction,
        DeployContractAction, FunctionCallAction, StakeAction, TransferAction,
    },
};
use near_workspaces::AccountId;
use std::{str::FromStr, time::Duration};
use test_log::test;

#[test(tokio::test)]
async fn whitlisted_actions_test() -> anyhow::Result<()> {
    with_nodes(3, |ctx| async move {
        // Preparing user credentials
        let account_id = account::random(&ctx.worker)?;
        let user_secret_key = near_crypto::SecretKey::from_random(near_crypto::KeyType::ED25519);
        let user_public_key = user_secret_key.public_key();
        let oidc_token = OidcToken::random_valid();

        // Claim OIDC token
        ctx.leader_node
            .claim_oidc_with_helper(&oidc_token, &user_public_key, &user_secret_key)
            .await?;

        // Create account with claimed OIDC token
        ctx.leader_node
            .new_account_with_helper(
                &account_id,
                &user_public_key,
                None,
                &user_secret_key,
                &oidc_token,
            )
            .await?
            .assert_ok()?;

        // Performing whitelisted actions
        let whitelisted_actions = vec![ActionType::AddKey, ActionType::DeleteKey];

        for whitelisted_action in whitelisted_actions {
            ctx.leader_node
                .sign_with_helper(
                    &get_stub_delegate_action(whitelisted_action)?,
                    &oidc_token,
                    &user_secret_key,
                    &user_public_key,
                )
                .await?
                .assert_ok()?;
        }

        // Performing blacklisted actions
        let blacklisted_actions = vec![ActionType::DeleteAccount];

        for blacklisted_action in blacklisted_actions {
            ctx.leader_node
                .sign_with_helper(
                    &get_stub_delegate_action(blacklisted_action)?,
                    &oidc_token,
                    &user_secret_key,
                    &user_public_key,
                )
                .await?
                .assert_bad_request_contains("action can not be performed")?;
        }

        // Client should not be able to delete their recovery key
        let recovery_pk = match ctx
            .leader_node
            .user_credentials_with_helper(
                &oidc_token,
                &user_secret_key,
                &user_secret_key.public_key(),
            )
            .await?
            .assert_ok()?
        {
            UserCredentialsResponse::Ok { recovery_pk } => recovery_pk,
            UserCredentialsResponse::Err { msg } => {
                return Err(anyhow::anyhow!("error response: {}", msg))
            }
        };

        ctx.leader_node
            .delete_key_with_helper(
                &account_id,
                &oidc_token,
                &recovery_pk,
                &recovery_pk,
                &user_secret_key,
                &user_public_key,
            )
            .await?
            .assert_bad_request_contains("recovery key can not be deleted")?;

        tokio::time::sleep(Duration::from_millis(2000)).await;
        check::access_key_exists(&ctx, &account_id, &recovery_pk).await?;

        // Deletion of the regular key should work
        check::access_key_exists(&ctx, &account_id, &user_public_key).await?;

        ctx.leader_node
            .delete_key_with_helper(
                &account_id,
                &oidc_token,
                &user_public_key,
                &recovery_pk,
                &user_secret_key,
                &user_public_key,
            )
            .await?
            .assert_ok()?;

        tokio::time::sleep(Duration::from_millis(2000)).await;
        check::access_key_does_not_exists(&ctx, &account_id, &user_public_key.to_string()).await?;

        Ok(())
    })
    .await
}

pub enum ActionType {
    _CreateAccount,
    _DeployContract,
    _FunctionCall,
    _Transfer,
    _Stake,
    AddKey,
    DeleteKey,
    DeleteAccount,
}

fn get_stub_delegate_action(action_type: ActionType) -> anyhow::Result<DelegateAction> {
    let action: Action = match action_type {
        ActionType::_CreateAccount => Action::CreateAccount(CreateAccountAction {}),
        ActionType::_DeployContract => {
            Action::DeployContract(DeployContractAction { code: vec![] })
        }
        ActionType::_FunctionCall => Action::FunctionCall(FunctionCallAction {
            method_name: "test".to_string(),
            args: vec![],
            gas: 0,
            deposit: 0,
        }),
        ActionType::_Transfer => Action::Transfer(TransferAction { deposit: 0 }),
        ActionType::_Stake => Action::Stake(StakeAction {
            stake: 0,
            public_key: key::random_sk().public_key(),
        }),
        ActionType::AddKey => Action::AddKey(AddKeyAction {
            public_key: key::random_sk().public_key(),
            access_key: AccessKey::full_access(),
        }),
        ActionType::DeleteKey => Action::DeleteKey(DeleteKeyAction {
            public_key: key::random_sk().public_key(),
        }),
        ActionType::DeleteAccount => Action::DeleteAccount(DeleteAccountAction {
            beneficiary_id: AccountId::from_str("test.near").unwrap(),
        }),
    };
    Ok(DelegateAction {
        sender_id: AccountId::from_str("test.near").unwrap(),
        receiver_id: AccountId::from_str("test.near").unwrap(),
        actions: vec![action.try_into()?],
        nonce: 1,
        max_block_height: 1,
        public_key: key::random_sk().public_key(),
    })
}

#[test(tokio::test)]
async fn negative_front_running_protection() -> anyhow::Result<()> {
    with_nodes(3, |ctx| async move {
        // Preparing user credentials
        let account_id = account::random(&ctx.worker)?;
        let user_secret_key = near_crypto::SecretKey::from_random(near_crypto::KeyType::ED25519);
        let user_public_key = user_secret_key.public_key();
        let oidc_token_1 = OidcToken::random_valid();
        let oidc_token_2 = OidcToken::random_valid();
        let wrong_oidc_token = OidcToken::random_valid();

        // Create account before claiming OIDC token
        ctx.leader_node
            .new_account_with_helper(
                &account_id,
                &user_public_key,
                None,
                &user_secret_key,
                &oidc_token_1,
            )
            .await?
            .assert_unauthorized_contains("was not claimed")?;

        // Get user recovery PK before claiming OIDC token
        ctx.leader_node
            .user_credentials_with_helper(&oidc_token_1, &user_secret_key, &user_public_key)
            .await?
            .assert_unauthorized_contains("was not claimed")?;

        register_account(
            &ctx,
            &account_id,
            &user_secret_key,
            &user_public_key,
            &oidc_token_1,
            None,
        )
        .await?;

        // Making a sign request with unclaimed OIDC token
        let recovery_pk = fetch_recovery_pk(&ctx, &user_secret_key, &oidc_token_1).await?;

        let new_user_public_key = key::random_pk();

        ctx.leader_node
            .add_key_with_helper(
                &account_id,
                &oidc_token_2,
                &new_user_public_key,
                &recovery_pk,
                &user_secret_key,
                &user_public_key,
            )
            .await?
            .assert_unauthorized_contains("was not claimed")?;

        // Get MPC public key
        let mpc_pk: PublicKeyEd25519 = ctx
            .leader_node
            .get_mpc_pk(MpcPkRequest {})
            .await?
            .assert_ok()?
            .try_into()?;

        // Prepare the oidc claiming request
        let oidc_token_hash = oidc_token_2.digest_hash();
        let wrong_oidc_token_hash = wrong_oidc_token.digest_hash();

        let request_digest = claim_oidc_request_digest(&oidc_token_hash, &user_public_key).unwrap();
        let wrong_digest =
            claim_oidc_request_digest(&wrong_oidc_token_hash, &user_public_key).unwrap();

        let request_digest_signature = sign_digest(&request_digest, &user_secret_key)?;

        let wrong_request_digest_signature = match user_secret_key.sign(&wrong_digest) {
            near_crypto::Signature::ED25519(k) => k,
            _ => anyhow::bail!("Wrong signature type"),
        };

        let oidc_request = ClaimOidcRequest {
            oidc_token_hash: oidc_token_hash.clone(),
            frp_public_key: user_public_key.clone(),
            frp_signature: request_digest_signature,
        };

        let bad_oidc_request = ClaimOidcRequest {
            oidc_token_hash,
            frp_public_key: user_public_key,
            frp_signature: wrong_request_digest_signature,
        };

        // Make the claiming request with wrong signature
        ctx.leader_node
            .claim_oidc(bad_oidc_request.clone())
            .await?
            .assert_bad_request_contains("failed to verify signature")?;

        // Making the claiming request with correct signature
        let mpc_signature: Signature = ctx
            .leader_node
            .claim_oidc(oidc_request.clone())
            .await?
            .assert_ok()?
            .try_into()?;

        // Making the same claiming request should NOT fail
        ctx.leader_node
            .claim_oidc(oidc_request.clone())
            .await?
            .assert_ok()?;

        // Verify signature with wrong digest
        let wrong_response_digest = claim_oidc_response_digest(bad_oidc_request.frp_signature)?;
        if mpc_pk
            .verify(&wrong_response_digest, &mpc_signature)
            .is_ok()
        {
            return Err(anyhow::anyhow!(
                "Signature verification should fail with wrong digest"
            ));
        }

        // It should not be possible to make the claiming with another key
        let new_oidc_token = OidcToken::random_valid();
        let user_sk = key::random_sk();
        let user_pk = user_sk.public_key();
        let atacker_sk = key::random_sk();
        let atacker_pk = atacker_sk.public_key();

        // User claims the token
        ctx.leader_node
            .claim_oidc_with_helper(&new_oidc_token, &user_pk, &user_sk)
            .await?
            .assert_ok()?;

        // Attacker tries to claim the token
        ctx.leader_node
            .claim_oidc_with_helper(&new_oidc_token, &atacker_pk, &atacker_sk)
            .await?
            .assert_bad_request_contains("already claimed with another key")?;

        // Sign request with claimed token but wrong key should fail
        ctx.leader_node
            .add_key_with_helper(
                &account_id,
                &new_oidc_token,
                &new_user_public_key,
                &recovery_pk,
                &atacker_sk,
                &atacker_pk,
            )
            .await?
            .assert_unauthorized_contains("was claimed with another key")?;

        // User Credentials request with claimed token but wrong key should fail
        ctx.leader_node
            .user_credentials_with_helper(&new_oidc_token, &atacker_sk, &atacker_pk)
            .await?
            .assert_unauthorized_contains("was claimed with another key")?;

        Ok(())
    })
    .await
}

#[test(tokio::test)]
async fn test_invalid_token() -> anyhow::Result<()> {
    with_nodes(1, |ctx| async move {
        let account_id = account::random(&ctx.worker)?;
        let user_secret_key = key::random_sk();
        let user_public_key = user_secret_key.public_key();
        let oidc_token = OidcToken::random_valid();
        let invalid_oidc_token = OidcToken::invalid();

        // Claim OIDC token
        ctx.leader_node
            .claim_oidc_with_helper(&oidc_token, &user_public_key, &user_secret_key)
            .await?;

        // Claim invalid OIDC token to get proper errors
        ctx.leader_node
            .claim_oidc_with_helper(&invalid_oidc_token, &user_public_key, &user_secret_key)
            .await?;

        // Try to create an account with invalid token
        ctx.leader_node
            .new_account_with_helper(
                &account_id,
                &user_public_key,
                None,
                &user_secret_key,
                &invalid_oidc_token,
            )
            .await?
            .assert_unauthorized()?;

        // Try to create an account with valid token
        let new_acc_response = ctx
            .leader_node
            .new_account_with_helper(
                &account_id,
                &user_public_key,
                None,
                &user_secret_key,
                &oidc_token,
            )
            .await?
            .assert_ok()?;

        assert!(matches!(new_acc_response, NewAccountResponse::Ok {
                create_account_options: _,
                user_recovery_public_key: _,
                near_account_id: acc_id,
            } if acc_id == account_id
        ));

        tokio::time::sleep(Duration::from_millis(2000)).await;

        check::access_key_exists(&ctx, &account_id, &user_public_key).await?;

        let recovery_pk = match ctx
            .leader_node
            .user_credentials_with_helper(&oidc_token, &user_secret_key, &user_public_key)
            .await?
            .assert_ok()?
        {
            UserCredentialsResponse::Ok { recovery_pk } => recovery_pk,
            UserCredentialsResponse::Err { msg } => anyhow::bail!("error response: {}", msg),
        };

        let new_user_public_key = key::random_pk();

        // Try to add a key with invalid token
        ctx.leader_node
            .add_key_with_helper(
                &account_id,
                &invalid_oidc_token,
                &new_user_public_key,
                &recovery_pk,
                &user_secret_key,
                &user_public_key,
            )
            .await?
            .assert_unauthorized()?;

        // Try to add a key with valid token
        ctx.leader_node
            .add_key_with_helper(
                &account_id,
                &oidc_token,
                &new_user_public_key,
                &recovery_pk,
                &user_secret_key,
                &user_public_key,
            )
            .await?
            .assert_ok()?;

        tokio::time::sleep(Duration::from_millis(2000)).await;

        check::access_key_exists(&ctx, &account_id, &new_user_public_key).await?;

        Ok(())
    })
    .await
}

#[test(tokio::test)]
async fn test_reject_new_pk_set() -> anyhow::Result<()> {
    with_nodes(2, |ctx| async move {
        let mut new_pk_set = ctx.pk_set.clone();
        new_pk_set[1] = ExpandedKeyPair::create().public_key;
        // Signer node is already initialized with a pk set, so it should reject different pk set
        let (status_code, result) = ctx.signer_nodes[0]
            .accept_pk_set(mpc_recovery::msg::AcceptNodePublicKeysRequest {
                public_keys: new_pk_set,
            })
            .await?;
        assert_eq!(status_code, StatusCode::BAD_REQUEST);
        assert!(result.is_err());

        Ok(())
    })
    .await
}

#[tokio::test]
async fn test_malformed_raw_create_account() -> anyhow::Result<()> {
    let user_oidc = OidcToken::random_valid();
    let (user_sk, user_pk) = key::random();
    let digest = user_credentials_request_digest(&user_oidc, &user_pk)?;
    let near_crypto::Signature::ED25519(frp_signature) = user_sk.sign(&digest) else {
        anyhow::bail!("Wrong signature type");
    };

    let template_new_account = serde_json::json!({
        "near_account_id": "groot",
        "create_account_options": {
            "full_access_keys": Some(vec![&user_pk]),
            "limited_access_keys": serde_json::Value::Null,
            "contract_bytes": serde_json::Value::Null,
        },
        "oidc_token": user_oidc,
        "user_credentials_frp_signature": hex::encode(frp_signature),
        "frp_public_key": user_pk,
    });

    let malformed_cases = {
        let mut invalid_account_req = template_new_account.clone();
        invalid_account_req["near_account_id"] = account::malformed().into();

        let mut invalid_user_key_req = template_new_account.clone();
        let malformed_key = key::malformed_pk();
        invalid_user_key_req["create_account_options"]["full_access_keys"] =
            malformed_key.clone().into();
        invalid_user_key_req["frp_public_key"] = malformed_key.into();

        let mut invalid_oidc_token_req = template_new_account.clone();
        invalid_oidc_token_req["oidc_token"] = serde_json::to_value(OidcToken::invalid())?;

        let mut invalid_frp_signature_req = template_new_account.clone();
        // create invalid sig by having the first 16 bytes of the signature be 0:
        let mut invalid_sig = frp_signature.to_bytes();
        invalid_sig[0..16].copy_from_slice(&[0; 16]);
        invalid_frp_signature_req["user_credentials_frp_signature"] = serde_json::to_value(
            hex::encode(ed25519_dalek::Signature::from_bytes(&invalid_sig)?),
        )?;

        [
            (
                invalid_account_req,
                (StatusCode::UNPROCESSABLE_ENTITY, "Failed to deserialize the JSON body into the target type: near_account_id: invalid value:")),
            (
                invalid_user_key_req,
                (StatusCode::UNPROCESSABLE_ENTITY, "Failed to deserialize the JSON body into the target type: create_account_options.full_access_keys")
            ),
            (
                invalid_oidc_token_req,
                (StatusCode::UNAUTHORIZED, "failed to verify oidc token"),
            ),
            (
                invalid_frp_signature_req,
                (StatusCode::BAD_REQUEST, "failed to verify signature: Public key"),
            )
        ]
    };

    with_nodes(1, |ctx| async move {
        ctx.leader_node
            .claim_oidc_with_helper(&user_oidc, &user_pk, &user_sk)
            .await?;

        for (case_idx, (invalid_req, (expected_status_code, expected_msg))) in
            malformed_cases.into_iter().enumerate()
        {
            let (code, msg): (StatusCode, serde_json::Value) =
                mpc_recovery_integration_tests::util::post(
                    format!("{}/new_account", ctx.leader_node.address),
                    invalid_req,
                )
                .await
                .context("failed to send request")?;

            assert_eq!(
                code, expected_status_code,
                "wrong status code [case={case_idx}]:\n   expected: `{expected_msg}`\n     actual: `{msg}`"
            );
            assert!(
                msg.to_string().contains(expected_msg),
                "wrong error message [case={case_idx}]: `{expected_msg}` not in `{msg}`",
            );
        }

        // Check that the service is still available
        let account_id = account::random(&ctx.worker)?;
        let new_acc_response = ctx
            .leader_node
            .new_account_with_helper(
                &account_id,
                &user_pk,
                None,
                &user_sk,
                &user_oidc,
            )
            .await?
            .assert_ok()?;

        assert!(matches!(new_acc_response, NewAccountResponse::Ok {
                create_account_options: _,
                user_recovery_public_key: _,
                near_account_id,
            } if near_account_id == account_id
        ));

        tokio::time::sleep(Duration::from_millis(2000)).await;
        check::access_key_exists(&ctx, &account_id, &user_pk).await?;

        Ok(())
    })
    .await
}

#[test(tokio::test)]
async fn test_account_creation_should_work_on_second_attempt() -> anyhow::Result<()> {
    with_nodes(2, |ctx| async move {
        let account_id = account::random(&ctx.worker)?;
        let user_secret_key = key::random_sk();
        let user_public_key = user_secret_key.public_key();
        let oidc_token = OidcToken::random_valid();

        ctx.leader_node
            .new_account_with_helper(
                &account_id,
                &user_public_key,
                None,
                &user_secret_key,
                &oidc_token,
            )
            .await?
            .assert_unauthorized_contains("was not claimed")?;

        register_account(
            &ctx,
            &account_id,
            &user_secret_key,
            &user_public_key,
            &oidc_token,
            None,
        )
        .await?;

        Ok(())
    })
    .await
}

#[test(tokio::test)]
async fn test_creation_of_two_account_with_the_same_oidc_should_not_be_possible(
) -> anyhow::Result<()> {
    with_nodes(2, |ctx| async move {
        let account_id = account::random(&ctx.worker)?;
        let account_id_2 = account::random(&ctx.worker)?;
        let user_secret_key = key::random_sk();
        let user_public_key = user_secret_key.public_key();
        let oidc_token = OidcToken::random_valid();

        ctx.leader_node
            .claim_oidc_with_helper(&oidc_token, &user_public_key, &user_secret_key)
            .await?
            .assert_ok()?;

        ctx.leader_node
            .new_account_with_helper(
                &account_id,
                &user_public_key,
                None,
                &user_secret_key,
                &oidc_token,
            )
            .await?
            .assert_ok()?;

        ctx.leader_node
            .new_account_with_helper(
                &account_id_2,
                &user_public_key,
                None,
                &user_secret_key,
                &oidc_token,
            )
            .await?
            .assert_dependency_error_contains("You can only register 1 account per oauth_token")?;

        Ok(())
    })
    .await
}

'''
'''--- integration-tests/tests/mpc/positive.rs ---
use crate::mpc::{add_pk_and_check_validity, fetch_recovery_pk, new_random_account};
use crate::{account, key, with_nodes, MpcCheck, TestContext};
use futures::stream::FuturesUnordered;
use hyper::StatusCode;
use mpc_recovery::{
    gcp::value::{FromValue, IntoValue},
    sign_node::user_credentials::EncryptedUserCredentials,
    transaction::LimitedAccessKey,
};
use near_workspaces::types::AccessKeyPermission;
use std::collections::HashMap;
use test_log::test;

#[test(tokio::test)]
async fn test_basic_front_running_protection() -> anyhow::Result<()> {
    with_nodes(3, |ctx| async move {
        let (account_id, user_secret_key, oidc_token) = new_random_account(&ctx, None).await?;

        // Get recovery PK with proper FRP signature
        let recovery_pk = fetch_recovery_pk(&ctx, &user_secret_key, &oidc_token).await?;

        // Add key with bad FRP signature should fail
        let new_user_public_key = key::random_pk();
        let bad_user_sk = key::random_sk();
        ctx.leader_node
            .add_key_with_helper(
                &account_id,
                &oidc_token,
                &new_user_public_key,
                &recovery_pk,
                &bad_user_sk,
                &user_secret_key.public_key(),
            )
            .await?
            .assert_unauthorized()?;

        // Add key with proper FRP signature should succeed
        add_pk_and_check_validity(
            &ctx,
            &account_id,
            &user_secret_key,
            &oidc_token,
            &recovery_pk,
            Some(new_user_public_key),
        )
        .await?;

        Ok(())
    })
    .await
}

#[test(tokio::test)]
async fn test_basic_action() -> anyhow::Result<()> {
    with_nodes(3, |ctx| async move { basic_action(&ctx).await }).await
}

#[test(tokio::test)]
async fn test_random_recovery_keys() -> anyhow::Result<()> {
    with_nodes(3, |ctx| async move {
        let user_limited_access_key = LimitedAccessKey {
            public_key: key::random_pk(),
            allowance: "100".to_string(),
            receiver_id: account::random(&ctx.worker)?,
            method_names: "method_names".to_string(),
        };

        let (account_id, user_full_access_sk, _) =
            new_random_account(&ctx, Some(user_limited_access_key.clone())).await?;
        let user_full_access_pk = user_full_access_sk.public_key();
        let access_keys = ctx.worker.view_access_keys(&account_id).await?;

        let recovery_full_access_key1 = access_keys
            .clone()
            .into_iter()
            .find(|ak| {
                ak.public_key.key_data() != user_full_access_pk.key_data()
                    && ak.public_key.key_data() != user_limited_access_key.public_key.key_data()
            })
            .ok_or_else(|| anyhow::anyhow!("missing recovery access key"))?;

        match recovery_full_access_key1.access_key.permission {
            AccessKeyPermission::FullAccess => (),
            AccessKeyPermission::FunctionCall(_) => {
                anyhow::bail!("Got a limited access key when we expected a full access key")
            }
        };

        let la_key = access_keys
            .into_iter()
            .find(|ak| ak.public_key.key_data() == user_limited_access_key.public_key.key_data())
            .ok_or_else(|| anyhow::anyhow!("missing limited access key"))?;

        match la_key.access_key.permission {
            AccessKeyPermission::FullAccess => {
                anyhow::bail!("Got a full access key when we expected a limited access key")
            }
            AccessKeyPermission::FunctionCall(fc) => {
                assert_eq!(
                    fc.receiver_id,
                    user_limited_access_key.receiver_id.to_string()
                );
                assert_eq!(
                    fc.method_names.first().unwrap(),
                    &user_limited_access_key.method_names.to_string()
                );
            }
        };

        // Generate another user
        let (account_id, user_secret_key, _) =
            new_random_account(&ctx, Some(user_limited_access_key.clone())).await?;
        let user_public_key = user_secret_key.public_key();

        let access_keys = ctx.worker.view_access_keys(&account_id).await?;
        let recovery_full_access_key2 = access_keys
            .into_iter()
            .find(|ak| ak.public_key.key_data() != user_public_key.key_data())
            .ok_or_else(|| anyhow::anyhow!("missing recovery access key"))?;

        assert_ne!(
            recovery_full_access_key1.public_key, recovery_full_access_key2.public_key,
            "MPC recovery should generate random recovery keys for each user"
        );

        Ok(())
    })
    .await
}

#[test(tokio::test)]
async fn test_accept_existing_pk_set() -> anyhow::Result<()> {
    with_nodes(1, |ctx| async move {
        // Signer node is already initialized with the pk set, but we should be able to get a
        // positive response by providing the same pk set as it already has.
        let (status_code, result) = ctx.signer_nodes[0]
            .accept_pk_set(mpc_recovery::msg::AcceptNodePublicKeysRequest {
                public_keys: ctx.pk_set.clone(),
            })
            .await?;
        assert_eq!(status_code, StatusCode::OK);
        assert!(result.is_ok());

        Ok(())
    })
    .await
}

#[test(tokio::test)]
async fn test_rotate_node_keys() -> anyhow::Result<()> {
    with_nodes(3, |ctx| async move {
        let (account_id, user_sk, oidc_token) = new_random_account(&ctx, None).await?;

        // Add key
        let recovery_pk = fetch_recovery_pk(&ctx, &user_sk, &oidc_token).await?;
        add_pk_and_check_validity(&ctx, &account_id, &user_sk, &oidc_token, &recovery_pk, None)
            .await?;

        // Fetch current entities to be compared later.
        let gcp_service = ctx.gcp_service().await?;
        let old_entities = gcp_service
            .fetch_entities::<mpc_recovery::sign_node::user_credentials::EncryptedUserCredentials>()
            .await
            .unwrap()
            .into_iter()
            .map(|entity| {
                let entity = entity.entity.unwrap();
                (
                    entity.key.as_ref().unwrap().path.as_ref().unwrap()[0]
                        .name
                        .as_ref()
                        .unwrap()
                        .clone(),
                    entity,
                )
            })
            .collect::<HashMap<_, _>>();

        // Generate a new set of ciphers to rotate out each node:
        let mut counter = 0;
        let mpc_recovery::GenerateResult { secrets, .. } = loop {
            let result = mpc_recovery::generate(3);
            let all_diff = result
                .secrets
                .iter()
                .zip(ctx.signer_nodes.iter())
                .all(|((_, new_cipher), signer_node)| signer_node.cipher_key != *new_cipher);

            if all_diff {
                break result;
            }

            counter += 1;
            if counter == 5 {
                panic!("Failed to generate a new set of ciphers after 5 tries");
            }
        };

        let mut ciphers = HashMap::new();
        // Rotate out with new the cipher.
        for ((_sk_share, new_cipher), sign_node) in secrets.iter().zip(ctx.signer_nodes) {
            let cipher_pair = sign_node.run_rotate_node_key(new_cipher).await?;
            ciphers.insert(sign_node.node_id, cipher_pair);
        }

        // Sleep a little so that the entities are updated in the datastore.
        tokio::time::sleep(std::time::Duration::from_secs(2)).await;

        let mut new_entities = gcp_service
            .fetch_entities::<mpc_recovery::sign_node::user_credentials::EncryptedUserCredentials>()
            .await
            .unwrap()
            .into_iter()
            .map(|entity| {
                let entity = entity.entity.unwrap();
                (
                    entity.key.as_ref().unwrap().path.as_ref().unwrap()[0]
                        .name
                        .as_ref()
                        .unwrap()
                        .clone(),
                    entity,
                )
            })
            .collect::<HashMap<_, _>>();

        // Check whether node-key rotation was successful or not
        assert_eq!(old_entities.len(), new_entities.len());
        for (path, old_entity) in old_entities.into_iter() {
            let node_id = path.split('/').next().unwrap().parse::<usize>()?;
            let (old_cipher, new_cipher) = ciphers.get(&node_id).unwrap();

            let old_cred = EncryptedUserCredentials::from_value(old_entity.into_value())?;
            let new_entity = new_entities.remove(&path).unwrap();
            let new_cred = EncryptedUserCredentials::from_value(new_entity.into_value())?;

            // Once rotated, the key pairs should not be equal as they use different cipher keys:
            assert_ne!(old_cred.encrypted_key_pair, new_cred.encrypted_key_pair);

            // Make sure that the actual key pairs are still the same after cipher rotation:
            let old_key_pair = old_cred
                .decrypt_key_pair(old_cipher)
                .map_err(|e| anyhow::anyhow!(e))?;
            let new_key_pair = new_cred
                .decrypt_key_pair(new_cipher)
                .map_err(|e| anyhow::anyhow!(e))?;
            assert_eq!(old_key_pair.public_key, new_key_pair.public_key);
        }

        Ok(())
    })
    .await
}

#[test(tokio::test(flavor = "multi_thread", worker_threads = 8))]
async fn test_stress_network() -> anyhow::Result<()> {
    with_nodes(3, |ctx| {
        Box::pin(async move {
            let ctx = std::sync::Arc::new(ctx);
            let tasks = (0..30)
                .map(|_| {
                    let ctx = ctx.clone();
                    tokio::spawn(async move { basic_action(&ctx).await })
                })
                .collect::<FuturesUnordered<_>>();

            let result = futures::future::join_all(tasks)
                .await
                .into_iter()
                .collect::<Result<Vec<_>, _>>()?
                .into_iter()
                .collect::<Result<Vec<_>, _>>()?;
            tracing::debug!("{:#?}", result);
            Ok(())
        })
    })
    .await
}

async fn basic_action(ctx: &TestContext) -> anyhow::Result<()> {
    let (account_id, user_secret_key, oidc_token) = new_random_account(ctx, None).await?;

    // Add key
    let recovery_pk = fetch_recovery_pk(ctx, &user_secret_key, &oidc_token).await?;
    let new_user_public_key = add_pk_and_check_validity(
        ctx,
        &account_id,
        &user_secret_key,
        &oidc_token,
        &recovery_pk,
        None,
    )
    .await?;

    // Adding the same key should now fail
    add_pk_and_check_validity(
        ctx,
        &account_id,
        &user_secret_key,
        &oidc_token,
        &recovery_pk,
        Some(new_user_public_key),
    )
    .await?;

    Ok(())
}

'''
'''--- integration-tests/tests/multichain/actions/mod.rs ---
pub mod wait_for;

use crate::MultichainTestContext;

use cait_sith::FullSignature;
use elliptic_curve::sec1::ToEncodedPoint;
use k256::ecdsa::VerifyingKey;
use k256::elliptic_curve::ops::{Invert, Reduce};
use k256::elliptic_curve::point::AffineCoordinates;
use k256::elliptic_curve::scalar::FromUintUnchecked;
use k256::elliptic_curve::sec1::FromEncodedPoint;
use k256::elliptic_curve::ProjectivePoint;
use k256::{AffinePoint, EncodedPoint, Scalar, Secp256k1};
use mpc_contract::RunningContractState;
use mpc_recovery_node::kdf;
use mpc_recovery_node::util::ScalarExt;
use near_crypto::InMemorySigner;
use near_jsonrpc_client::methods::broadcast_tx_async::RpcBroadcastTxAsyncRequest;
use near_lake_primitives::CryptoHash;
use near_primitives::transaction::{Action, FunctionCallAction, Transaction};
use near_workspaces::Account;
use rand::Rng;
use secp256k1::XOnlyPublicKey;

use std::time::Duration;

const CHAIN_ID_ETH: u64 = 31337;

use k256::{
    ecdsa::{Signature as RecoverableSignature, Signature as K256Signature},
    PublicKey as K256PublicKey,
};

pub async fn request_sign(
    ctx: &MultichainTestContext<'_>,
) -> anyhow::Result<([u8; 32], [u8; 32], Account, CryptoHash)> {
    let worker = &ctx.nodes.ctx().worker;
    let account = worker.dev_create_account().await?;
    let payload: [u8; 32] = rand::thread_rng().gen();
    let payload_hashed = web3::signing::keccak256(&payload);

    let signer = InMemorySigner {
        account_id: account.id().clone(),
        public_key: account.secret_key().public_key().clone().into(),
        secret_key: account.secret_key().to_string().parse()?,
    };
    let (nonce, block_hash, _) = ctx
        .rpc_client
        .fetch_nonce(&signer.account_id, &signer.public_key)
        .await?;
    let tx_hash = ctx
        .jsonrpc_client
        .call(&RpcBroadcastTxAsyncRequest {
            signed_transaction: Transaction {
                nonce,
                block_hash,
                signer_id: signer.account_id.clone(),
                public_key: signer.public_key.clone(),
                receiver_id: ctx.nodes.ctx().mpc_contract.id().clone(),
                actions: vec![Action::FunctionCall(FunctionCallAction {
                    method_name: "sign".to_string(),
                    args: serde_json::to_vec(&serde_json::json!({
                        "payload": payload_hashed,
                        "path": "test",
                        "key_version": 0,
                    }))?,
                    gas: 300_000_000_000_000,
                    deposit: 0,
                })],
            }
            .sign(&signer),
        })
        .await?;
    tokio::time::sleep(Duration::from_secs(1)).await;
    Ok((payload, payload_hashed, account, tx_hash))
}

pub async fn assert_signature(
    account_id: &near_workspaces::AccountId,
    mpc_pk_bytes: &[u8],
    payload: &[u8; 32],
    signature: &FullSignature<Secp256k1>,
) {
    let mpc_point = EncodedPoint::from_bytes(mpc_pk_bytes).unwrap();
    let mpc_pk = AffinePoint::from_encoded_point(&mpc_point).unwrap();
    let epsilon = kdf::derive_epsilon(account_id, "test");
    let user_pk = kdf::derive_key(mpc_pk, epsilon);

    assert!(signature.verify(&user_pk, &Scalar::from_bytes(payload),));
}

pub async fn single_signature_production(
    ctx: &MultichainTestContext<'_>,
    state: &RunningContractState,
) -> anyhow::Result<()> {
    let (_, payload_hash, account, tx_hash) = request_sign(ctx).await?;
    let signature = wait_for::signature_responded(ctx, tx_hash).await?;

    let mut mpc_pk_bytes = vec![0x04];
    mpc_pk_bytes.extend_from_slice(&state.public_key.as_bytes()[1..]);
    assert_signature(account.id(), &mpc_pk_bytes, &payload_hash, &signature).await;

    Ok(())
}

#[tokio::test]
async fn test_proposition() {
    let big_r = "044bf886afee5a6844a25fa6831a01715e990d3d9e96b792a9da91cfbecbf8477cea57097a3db9fc1d4822afade3d1c4e6d66e99568147304ae34bcfa609d90a16";
    let s = "1f871c67139f617409067ac8a7150481e3a5e2d8a9207ffdaad82098654e95cb";
    let mpc_key = "02F2B55346FD5E4BFF1F06522561BDCD024CEA25D98A091197ACC04E22B3004DB2";

    // Create payload
    let mut payload = [0u8; 32];
    for (i, item) in payload.iter_mut().enumerate() {
        *item = i as u8;
    }

    // TODO: get hashed values on the flight
    let payload_hash: [u8; 32] = [
        99, 13, 205, 41, 102, 196, 51, 102, 145, 18, 84, 72, 187, 178, 91, 79, 244, 18, 164, 156,
        115, 45, 178, 200, 171, 193, 184, 88, 27, 215, 16, 221,
    ];
    let payload_hash_scalar = k256::Scalar::from_bytes(&payload_hash); // TODO: why do we need both reversed and not reversed versions?
    let mut payload_hash_reversed: [u8; 32] = payload_hash;
    payload_hash_reversed.reverse();

    println!("payload_hash: {payload_hash:?}");
    println!("payload_hash_scallar: {payload_hash_scalar:#?}");
    println!("payload_hash_reversed: {payload_hash_reversed:?}");

    // Derive and convert user pk
    let mpc_pk = hex::decode(mpc_key).unwrap();
    let mpc_pk = EncodedPoint::from_bytes(mpc_pk).unwrap();
    let mpc_pk = AffinePoint::from_encoded_point(&mpc_pk).unwrap();
    let account_id = "acc_mc.test.near".parse().unwrap();
    let derivation_epsilon: k256::Scalar = kdf::derive_epsilon(&account_id, "test");
    let user_pk: AffinePoint = kdf::derive_key(mpc_pk, derivation_epsilon);
    let user_pk_y_parity = match user_pk.y_is_odd().unwrap_u8() {
        0 => secp256k1::Parity::Even,
        1 => secp256k1::Parity::Odd,
        _ => unreachable!(),
    };
    let user_pk_x = x_coordinate::<k256::Secp256k1>(&user_pk);
    let user_pk_x: XOnlyPublicKey = XOnlyPublicKey::from_slice(&user_pk_x.to_bytes()).unwrap();
    let user_secp_pk: secp256k1::PublicKey =
        secp256k1::PublicKey::from_x_only_public_key(user_pk_x, user_pk_y_parity);
    let user_address_from_pk = public_key_to_address(&user_secp_pk);

    // Prepare R ans s signature values
    let big_r = hex::decode(big_r).unwrap();
    let big_r = EncodedPoint::from_bytes(big_r).unwrap();
    let big_r = AffinePoint::from_encoded_point(&big_r).unwrap();
    let big_r_y_parity = big_r.y_is_odd().unwrap_u8() as i32;
    assert!(big_r_y_parity == 0 || big_r_y_parity == 1);

    let s = hex::decode(s).unwrap();
    let s = k256::Scalar::from_uint_unchecked(k256::U256::from_be_slice(s.as_slice()));
    let r = x_coordinate::<k256::Secp256k1>(&big_r);

    let signature = cait_sith::FullSignature::<Secp256k1> { big_r, s };
    let multichain_sig = kdf::into_eth_sig(&user_pk, &signature, payload_hash_scalar).unwrap();

    println!("{multichain_sig:#?}");
    println!("R: {big_r:#?}");
    println!("r: {r:#?}");
    println!("y parity: {}", big_r_y_parity);
    println!("s: {s:#?}");

    // Check signature using cait-sith tooling
    let is_signature_valid_for_user_pk = signature.verify(&user_pk, &payload_hash_scalar);
    let is_signature_valid_for_mpc_pk = signature.verify(&mpc_pk, &payload_hash_scalar);
    let another_user_pk = kdf::derive_key(mpc_pk, derivation_epsilon + k256::Scalar::ONE);
    let is_signature_valid_for_another_user_pk =
        signature.verify(&another_user_pk, &payload_hash_scalar);
    assert!(is_signature_valid_for_user_pk);
    assert!(!is_signature_valid_for_mpc_pk);
    assert!(!is_signature_valid_for_another_user_pk);

    // Check signature using ecdsa tooling
    let k256_sig = k256::ecdsa::Signature::from_scalars(r, s).unwrap();
    let user_pk_k256: k256::elliptic_curve::PublicKey<Secp256k1> =
        k256::PublicKey::from_affine(user_pk).unwrap();

    let ecdsa_local_verify_result = verify(
        &k256::ecdsa::VerifyingKey::from(&user_pk_k256),
        &payload_hash_reversed,
        &k256_sig,
    );
    assert!(ecdsa_local_verify_result.is_ok());

    // TODO: fix
    // let ecdsa_signature: ecdsa::Signature<Secp256k1> =
    //     ecdsa::Signature::from_scalars(r, s).unwrap();
    // let ecdsa_verify_result = ecdsa::signature::Verifier::verify(
    //     &k256::ecdsa::VerifyingKey::from(&user_pk_k256),
    //     &payload_hash_reversed,
    //     &ecdsa_signature,
    // );
    // assert!(ecdsa_verify_result.is_ok());
    // let k256_verify_key = k256::ecdsa::VerifyingKey::from(&user_pk_k256);
    // let k256_verify_result = k256_verify_key.verify(&payload_hash_reversed, &k256_sig);
    // assert!(k256_verify_result.is_ok());

    // Check signature using etheres tooling
    let ethers_r = ethers_core::types::U256::from_big_endian(r.to_bytes().as_slice());
    let ethers_s = ethers_core::types::U256::from_big_endian(s.to_bytes().as_slice());
    let ethers_v = to_eip155_v(multichain_sig.recovery_id, CHAIN_ID_ETH);

    let signature = ethers_core::types::Signature {
        r: ethers_r,
        s: ethers_s,
        v: ethers_v,
    };

    let verifying_user_pk = ecdsa::VerifyingKey::from(&user_pk_k256);
    let user_address_ethers: ethers_core::types::H160 =
        ethers_core::utils::public_key_to_address(&verifying_user_pk);

    assert!(signature
        .verify(payload_hash_reversed, user_address_ethers)
        .is_ok());

    // Check if recovered address is the same as the user address
    let signature_for_recovery: [u8; 64] = {
        let mut signature = [0u8; 64]; // TODO: is there a better way to get these bytes?
        signature[..32].copy_from_slice(&r.to_bytes());
        signature[32..].copy_from_slice(&s.to_bytes());
        signature
    };

    let recovered_from_signature_address_web3 = web3::signing::recover(
        &payload_hash_reversed,
        &signature_for_recovery,
        multichain_sig.recovery_id as i32,
    )
    .unwrap();
    assert_eq!(user_address_from_pk, recovered_from_signature_address_web3);

    let recovered_from_signature_address_ethers = signature.recover(payload_hash_reversed).unwrap();
    assert_eq!(
        user_address_from_pk,
        recovered_from_signature_address_ethers
    );

    let recovered_from_signature_address_local_function =
        recover(signature, payload_hash_reversed).unwrap();
    assert_eq!(
        user_address_from_pk,
        recovered_from_signature_address_local_function
    );

    assert_eq!(user_address_from_pk, user_address_ethers);
}

/// Get the x coordinate of a point, as a scalar
pub(crate) fn x_coordinate<C: cait_sith::CSCurve>(point: &C::AffinePoint) -> C::Scalar {
    <C::Scalar as k256::elliptic_curve::ops::Reduce<<C as k256::elliptic_curve::Curve>::Uint>>::reduce_bytes(&point.x())
}

pub fn recover<M>(
    signature: ethers_core::types::Signature,
    message: M,
) -> Result<ethers_core::types::Address, ethers_core::types::SignatureError>
where
    M: Into<ethers_core::types::RecoveryMessage>,
{
    let message_hash = match message.into() {
        ethers_core::types::RecoveryMessage::Data(ref message) => {
            println!("identified as data");
            ethers_core::utils::hash_message(message)
        }
        ethers_core::types::RecoveryMessage::Hash(hash) => hash,
    };
    println!("message_hash {message_hash:#?}");

    let (recoverable_sig, recovery_id) = as_signature(signature)?;
    let verifying_key =
        VerifyingKey::recover_from_prehash(message_hash.as_ref(), &recoverable_sig, recovery_id)?;
    println!("verifying_key {verifying_key:#?}");

    let public_key = K256PublicKey::from(&verifying_key);
    //println!("ethercore public key from verifying key {public_key:#?}");

    let public_key = public_key.to_encoded_point(/* compress = */ false);
    println!("ethercore recover encoded point pk {public_key:#?}");
    let public_key = public_key.as_bytes();
    debug_assert_eq!(public_key[0], 0x04);
    let hash = ethers_core::utils::keccak256(&public_key[1..]);
    let result = ethers_core::types::Address::from_slice(&hash[12..]);
    println!("ethercore recover result {result:#?}");
    Ok(ethers_core::types::Address::from_slice(&hash[12..]))
}

/// Retrieves the recovery signature.
fn as_signature(
    signature: ethers_core::types::Signature,
) -> Result<(RecoverableSignature, k256::ecdsa::RecoveryId), ethers_core::types::SignatureError> {
    let mut recovery_id = signature.recovery_id()?;
    let mut signature = {
        let mut r_bytes = [0u8; 32];
        let mut s_bytes = [0u8; 32];
        signature.r.to_big_endian(&mut r_bytes);
        signature.s.to_big_endian(&mut s_bytes);
        let gar: &generic_array::GenericArray<u8, elliptic_curve::consts::U32> =
            generic_array::GenericArray::from_slice(&r_bytes);
        let gas: &generic_array::GenericArray<u8, elliptic_curve::consts::U32> =
            generic_array::GenericArray::from_slice(&s_bytes);
        K256Signature::from_scalars(*gar, *gas)?
    };

    // Normalize into "low S" form. See:
    // - https://github.com/RustCrypto/elliptic-curves/issues/988
    // - https://github.com/bluealloy/revm/pull/870
    if let Some(normalized) = signature.normalize_s() {
        signature = normalized;
        recovery_id = k256::ecdsa::RecoveryId::from_byte(recovery_id.to_byte() ^ 1).unwrap();
    }

    Ok((signature, recovery_id))
}

pub fn public_key_to_address(public_key: &secp256k1::PublicKey) -> web3::types::Address {
    let public_key = public_key.serialize_uncompressed();

    debug_assert_eq!(public_key[0], 0x04);
    let hash: [u8; 32] = web3::signing::keccak256(&public_key[1..]);

    web3::types::Address::from_slice(&hash[12..])
}

fn verify(
    key: &VerifyingKey,
    msg: &[u8],
    sig: &k256::ecdsa::Signature,
) -> Result<(), &'static str> {
    let q = ProjectivePoint::<Secp256k1>::from(key.as_affine());
    let z = ecdsa::hazmat::bits2field::<Secp256k1>(msg).unwrap();

    // &k256::FieldBytes::from_slice(&k256::Scalar::from_bytes(msg).to_bytes()),
    verify_prehashed(&q, &z, sig)
}

fn verify_prehashed(
    q: &ProjectivePoint<Secp256k1>,
    z: &k256::FieldBytes,
    sig: &k256::ecdsa::Signature,
) -> Result<(), &'static str> {
    // let z: Scalar = Scalar::reduce_bytes(z);
    let z =
        <Scalar as Reduce<<k256::Secp256k1 as k256::elliptic_curve::Curve>::Uint>>::reduce_bytes(z);
    let (r, s) = sig.split_scalars();
    let s_inv = *s.invert_vartime();
    let u1 = z * s_inv;
    let u2 = *r * s_inv;
    let reproduced = lincomb(&ProjectivePoint::<Secp256k1>::GENERATOR, &u1, q, &u2).to_affine();
    let x = reproduced.x();

    // println!("------------- verify_prehashed[beg] -------------");
    // println!("z: {z:#?}");
    // // println!("r: {r:#?}");
    // // println!("s: {s:#?}");
    // println!("s_inv {s_inv:#?}");
    // println!("u1 {u1:#?}");
    // println!("u2 {u2:#?}");
    // println!("reproduced {reproduced:#?}");
    // println!("reproduced_x {x:?}");
    // println!("------------- verify_prehashed[end] -------------");

    let reduced =
        <Scalar as Reduce<<k256::Secp256k1 as k256::elliptic_curve::Curve>::Uint>>::reduce_bytes(
            &x,
        );

    //println!("reduced {reduced:#?}");

    if *r == reduced {
        Ok(())
    } else {
        Err("error")
    }
}

fn lincomb(
    x: &ProjectivePoint<Secp256k1>,
    k: &Scalar,
    y: &ProjectivePoint<Secp256k1>,
    l: &Scalar,
) -> ProjectivePoint<Secp256k1> {
    (*x * k) + (*y * l)
}

pub fn to_eip155_v(recovery_id: u8, chain_id: u64) -> u64 {
    (recovery_id as u64) + 35 + chain_id * 2
}

'''
'''--- integration-tests/tests/multichain/actions/wait_for.rs ---
use crate::MultichainTestContext;
use anyhow::Context;
use backon::ExponentialBuilder;
use backon::Retryable;
use cait_sith::FullSignature;
use k256::AffinePoint;
use k256::Scalar;
use k256::Secp256k1;
use mpc_contract::ProtocolContractState;
use mpc_contract::RunningContractState;
use mpc_recovery_node::web::StateView;
use near_jsonrpc_client::methods::tx::RpcTransactionStatusRequest;
use near_jsonrpc_client::methods::tx::TransactionInfo;
use near_lake_primitives::CryptoHash;
use near_primitives::views::FinalExecutionStatus;

pub async fn running_mpc<'a>(
    ctx: &MultichainTestContext<'a>,
    epoch: Option<u64>,
) -> anyhow::Result<RunningContractState> {
    let is_running = || async {
        let state: ProtocolContractState = ctx
            .rpc_client
            .view(ctx.nodes.ctx().mpc_contract.id(), "state", ())
            .await?;

        match state {
            ProtocolContractState::Running(running) => match epoch {
                None => Ok(running),
                Some(expected_epoch) if running.epoch >= expected_epoch => Ok(running),
                Some(_) => {
                    anyhow::bail!("running with an older epoch: {}", running.epoch)
                }
            },
            _ => anyhow::bail!("not running"),
        }
    };
    let err_msg = format!(
        "mpc did not reach {} in time",
        if epoch.is_some() {
            "expected epoch"
        } else {
            "running state"
        }
    );
    is_running
        .retry(&ExponentialBuilder::default().with_max_times(6))
        .await
        .with_context(|| err_msg)
}

pub async fn has_at_least_triples<'a>(
    ctx: &MultichainTestContext<'a>,
    expected_triple_count: usize,
) -> anyhow::Result<Vec<StateView>> {
    let is_enough_triples = |id| {
        move || async move {
            let state_view: StateView = ctx
                .http_client
                .get(format!("{}/state", ctx.nodes.url(id)))
                .send()
                .await?
                .json()
                .await?;

            match state_view {
                StateView::Running { triple_count, .. }
                    if triple_count >= expected_triple_count =>
                {
                    Ok(state_view)
                }
                StateView::Running { .. } => anyhow::bail!("node does not have enough triples yet"),
                StateView::NotRunning => anyhow::bail!("node is not running"),
            }
        }
    };

    let mut state_views = Vec::new();
    for id in 0..ctx.nodes.len() {
        let state_view = is_enough_triples(id)
            .retry(&ExponentialBuilder::default().with_max_times(15))
            .await
            .with_context(|| format!("mpc node '{id}' failed to generate '{expected_triple_count}' triples before deadline"))?;
        state_views.push(state_view);
    }
    Ok(state_views)
}

pub async fn has_at_least_mine_triples<'a>(
    ctx: &MultichainTestContext<'a>,
    expected_mine_triple_count: usize,
) -> anyhow::Result<Vec<StateView>> {
    let is_enough_mine_triples = |id| {
        move || async move {
            let state_view: StateView = ctx
                .http_client
                .get(format!("{}/state", ctx.nodes.url(id)))
                .send()
                .await?
                .json()
                .await?;

            match state_view {
                StateView::Running {
                    triple_mine_count, ..
                } if triple_mine_count >= expected_mine_triple_count => Ok(state_view),
                StateView::Running { .. } => {
                    anyhow::bail!("node does not have enough mine triples yet")
                }
                StateView::NotRunning => anyhow::bail!("node is not running"),
            }
        }
    };

    let mut state_views = Vec::new();
    for id in 0..ctx.nodes.len() {
        let state_view = is_enough_mine_triples(id)
            .retry(&ExponentialBuilder::default().with_max_times(15))
            .await
            .with_context(|| format!("mpc node '{id}' failed to generate '{expected_mine_triple_count}' triples before deadline"))?;
        state_views.push(state_view);
    }
    Ok(state_views)
}

pub async fn has_at_least_presignatures<'a>(
    ctx: &MultichainTestContext<'a>,
    expected_presignature_count: usize,
) -> anyhow::Result<Vec<StateView>> {
    let is_enough_presignatures = |id| {
        move || async move {
            let state_view: StateView = ctx
                .http_client
                .get(format!("{}/state", ctx.nodes.url(id)))
                .send()
                .await?
                .json()
                .await?;

            match state_view {
                StateView::Running {
                    presignature_count, ..
                } if presignature_count >= expected_presignature_count => Ok(state_view),
                StateView::Running { .. } => {
                    anyhow::bail!("node does not have enough presignatures yet")
                }
                StateView::NotRunning => anyhow::bail!("node is not running"),
            }
        }
    };

    let mut state_views = Vec::new();
    for id in 0..ctx.nodes.len() {
        let state_view = is_enough_presignatures(id)
            .retry(&ExponentialBuilder::default().with_max_times(6))
            .await
            .with_context(|| format!("mpc node '{id}' failed to generate '{expected_presignature_count}' presignatures before deadline"))?;
        state_views.push(state_view);
    }
    Ok(state_views)
}

pub async fn has_at_least_mine_presignatures<'a>(
    ctx: &MultichainTestContext<'a>,
    expected_mine_presignature_count: usize,
) -> anyhow::Result<Vec<StateView>> {
    let is_enough_mine_presignatures = |id| {
        move || async move {
            let state_view: StateView = ctx
                .http_client
                .get(format!("{}/state", ctx.nodes.url(id)))
                .send()
                .await?
                .json()
                .await?;

            match state_view {
                StateView::Running {
                    presignature_mine_count,
                    ..
                } if presignature_mine_count >= expected_mine_presignature_count => Ok(state_view),
                StateView::Running { .. } => {
                    anyhow::bail!("node does not have enough mine presignatures yet")
                }
                StateView::NotRunning => anyhow::bail!("node is not running"),
            }
        }
    };

    let mut state_views = Vec::new();
    for id in 0..ctx.nodes.len() {
        let state_view = is_enough_mine_presignatures(id)
            .retry(&ExponentialBuilder::default().with_max_times(6))
            .await
            .with_context(|| format!("mpc node '{id}' failed to generate '{expected_mine_presignature_count}' presignatures before deadline"))?;
        state_views.push(state_view);
    }
    Ok(state_views)
}

pub async fn signature_responded(
    ctx: &MultichainTestContext<'_>,
    tx_hash: CryptoHash,
) -> anyhow::Result<FullSignature<Secp256k1>> {
    let is_tx_ready = || async {
        let outcome_view = ctx
            .jsonrpc_client
            .call(RpcTransactionStatusRequest {
                transaction_info: TransactionInfo::TransactionId {
                    hash: tx_hash,
                    account_id: ctx.nodes.ctx().mpc_contract.id().clone(),
                },
            })
            .await?;
        let FinalExecutionStatus::SuccessValue(payload) = outcome_view.status else {
            anyhow::bail!("tx finished unsuccessfully: {:?}", outcome_view.status);
        };
        let (big_r, s): (AffinePoint, Scalar) = serde_json::from_slice(&payload)?;
        let signature = cait_sith::FullSignature::<Secp256k1> { big_r, s };
        Ok(signature)
    };

    let signature = is_tx_ready
        .retry(&ExponentialBuilder::default().with_max_times(6))
        .await
        .with_context(|| "failed to wait for signature response")?;
    Ok(signature)
}

'''
'''--- integration-tests/tests/multichain/mod.rs ---
pub mod actions;

use std::str::FromStr;

use crate::with_multichain_nodes;
use actions::wait_for;
use k256::elliptic_curve::point::AffineCoordinates;
use mpc_recovery_integration_tests::env::containers::DockerClient;
use mpc_recovery_integration_tests::multichain::MultichainConfig;
use mpc_recovery_node::kdf::{self, x_coordinate};
use mpc_recovery_node::protocol::presignature::PresignatureConfig;
use mpc_recovery_node::protocol::triple::TripleConfig;
use mpc_recovery_node::test_utils;
use mpc_recovery_node::types::LatestBlockHeight;
use mpc_recovery_node::util::{NearPublicKeyExt, ScalarExt};
use test_log::test;

#[test(tokio::test)]
async fn test_multichain_reshare() -> anyhow::Result<()> {
    let config = MultichainConfig::default();
    with_multichain_nodes(config.clone(), |mut ctx| {
        Box::pin(async move {
            let state = wait_for::running_mpc(&ctx, Some(0)).await?;
            assert!(state.threshold == 2);
            assert!(state.participants.len() == 3);
            assert!(ctx.remove_participant(None).await.is_ok());
            // Going below T should error out
            assert!(ctx.remove_participant(None).await.is_err());
            assert!(ctx.add_participant().await.is_ok());
            assert!(ctx.remove_participant(None).await.is_ok());
            // make sure signing works after reshare
            let new_state = wait_for::running_mpc(&ctx, None).await?;
            wait_for::has_at_least_triples(&ctx, 2).await?;
            wait_for::has_at_least_presignatures(&ctx, 2).await?;
            actions::single_signature_production(&ctx, &new_state).await
        })
    })
    .await
}

#[test(tokio::test)]
async fn test_triples_and_presignatures() -> anyhow::Result<()> {
    with_multichain_nodes(MultichainConfig::default(), |ctx| {
        Box::pin(async move {
            let state_0 = wait_for::running_mpc(&ctx, Some(0)).await?;
            assert_eq!(state_0.participants.len(), 3);
            wait_for::has_at_least_triples(&ctx, 2).await?;
            wait_for::has_at_least_presignatures(&ctx, 2).await?;
            Ok(())
        })
    })
    .await
}

#[test(tokio::test)]
async fn test_signature_basic() -> anyhow::Result<()> {
    with_multichain_nodes(MultichainConfig::default(), |ctx| {
        Box::pin(async move {
            let state_0 = wait_for::running_mpc(&ctx, Some(0)).await?;
            assert_eq!(state_0.participants.len(), 3);
            wait_for::has_at_least_triples(&ctx, 2).await?;
            wait_for::has_at_least_presignatures(&ctx, 2).await?;
            actions::single_signature_production(&ctx, &state_0).await
        })
    })
    .await
}

#[test(tokio::test)]
async fn test_signature_offline_node() -> anyhow::Result<()> {
    with_multichain_nodes(MultichainConfig::default(), |mut ctx| {
        Box::pin(async move {
            let state_0 = wait_for::running_mpc(&ctx, Some(0)).await?;
            assert_eq!(state_0.participants.len(), 3);
            wait_for::has_at_least_triples(&ctx, 6).await?;
            wait_for::has_at_least_mine_triples(&ctx, 2).await?;

            // Kill the node then have presignature and signature generation only use the active set of nodes
            // to start generating presignatures and signatures.
            let account_id = near_workspaces::types::AccountId::from_str(
                state_0.participants.keys().last().unwrap().clone().as_ref(),
            )
            .unwrap();
            ctx.nodes.kill_node(&account_id).await?;

            // This could potentially fail and timeout the first time if the participant set picked up is the
            // one with the offline node. This is expected behavior for now if a user submits a request in between
            // a node going offline and the system hasn't detected it yet.
            let presig_res = wait_for::has_at_least_mine_presignatures(&ctx, 1).await;
            let sig_res = actions::single_signature_production(&ctx, &state_0).await;

            // Try again if the first attempt failed. This second portion should not be needed when the NEP
            // comes in for resumeable MPC.
            if presig_res.is_err() || sig_res.is_err() {
                // Retry if the first attempt failed.
                wait_for::has_at_least_mine_presignatures(&ctx, 1).await?;
                actions::single_signature_production(&ctx, &state_0).await?;
            }

            Ok(())
        })
    })
    .await
}

#[test(tokio::test)]
#[ignore = "This test is too slow to run in CI"]
async fn test_signature_large_stockpile() -> anyhow::Result<()> {
    const SIGNATURE_AMOUNT: usize = 10;
    const NODES: usize = 8;
    const THRESHOLD: usize = 4;
    const MIN_TRIPLES: usize = 10;
    const MAX_TRIPLES: usize = 2 * NODES * MIN_TRIPLES;

    let triple_cfg = TripleConfig {
        // This is the min triples required by each node.
        min_triples: MIN_TRIPLES,
        // This is the total amount of triples that will be generated by all nodes.
        max_triples: MAX_TRIPLES,
        // This is the amount each node can introduce a triple generation protocol into the system.
        max_concurrent_introduction: 4,
        // This is the maximum amount of triples that can be generated concurrently by the whole system.
        max_concurrent_generation: 24,
    };
    let presig_cfg = PresignatureConfig {
        // this is the min presignatures required by each node
        min_presignatures: 10,
        // This is the total amount of presignatures that will be generated by all nodes.
        max_presignatures: 1000,
    };

    let config = MultichainConfig {
        triple_cfg,
        presig_cfg,
        nodes: NODES,
        threshold: THRESHOLD,
    };

    with_multichain_nodes(config, |ctx| {
        Box::pin(async move {
            let state_0 = wait_for::running_mpc(&ctx, Some(0)).await?;
            assert_eq!(state_0.participants.len(), NODES);
            wait_for::has_at_least_triples(&ctx, triple_cfg.min_triples).await?;
            wait_for::has_at_least_presignatures(&ctx, SIGNATURE_AMOUNT).await?;

            for _ in 0..SIGNATURE_AMOUNT {
                actions::single_signature_production(&ctx, &state_0).await?;
            }
            Ok(())
        })
    })
    .await
}

#[test(tokio::test)]
async fn test_key_derivation() -> anyhow::Result<()> {
    with_multichain_nodes(MultichainConfig::default(), |ctx| {
        Box::pin(async move {
            let state_0 = wait_for::running_mpc(&ctx, Some(0)).await?;
            assert_eq!(state_0.participants.len(), 3);
            wait_for::has_at_least_triples(&ctx, 6).await?;
            wait_for::has_at_least_presignatures(&ctx, 3).await?;

            for _ in 0..3 {
                let mpc_pk: k256::AffinePoint = state_0.public_key.clone().into_affine_point();
                let (_, payload_hashed, account, tx_hash) = actions::request_sign(&ctx).await?;
                let payload_hashed_rev = {
                    let mut rev = payload_hashed;
                    rev.reverse();
                    rev
                };
                let sig = wait_for::signature_responded(&ctx, tx_hash).await?;

                let hd_path = "test";
                let derivation_epsilon = kdf::derive_epsilon(account.id(), hd_path);
                let user_pk = kdf::derive_key(mpc_pk, derivation_epsilon);
                let multichain_sig =
                    kdf::into_eth_sig(&user_pk, &sig, k256::Scalar::from_bytes(&payload_hashed))
                        .unwrap();

                // start recovering the address and compare them:
                let user_pk_x = kdf::x_coordinate::<k256::Secp256k1>(&user_pk);
                let user_pk_y_parity = match user_pk.y_is_odd().unwrap_u8() {
                    1 => secp256k1::Parity::Odd,
                    0 => secp256k1::Parity::Even,
                    _ => unreachable!(),
                };
                let user_pk_x =
                    secp256k1::XOnlyPublicKey::from_slice(&user_pk_x.to_bytes()).unwrap();
                let user_secp_pk =
                    secp256k1::PublicKey::from_x_only_public_key(user_pk_x, user_pk_y_parity);
                let user_addr = actions::public_key_to_address(&user_secp_pk);
                let r = x_coordinate::<k256::Secp256k1>(&multichain_sig.big_r);
                let s = multichain_sig.s;
                let signature_for_recovery: [u8; 64] = {
                    let mut signature = [0u8; 64];
                    signature[..32].copy_from_slice(&r.to_bytes());
                    signature[32..].copy_from_slice(&s.to_bytes());
                    signature
                };
                let recovered_addr = web3::signing::recover(
                    &payload_hashed_rev,
                    &signature_for_recovery,
                    multichain_sig.recovery_id as i32,
                )
                .unwrap();
                assert_eq!(user_addr, recovered_addr);
            }

            Ok(())
        })
    })
    .await
}

#[test(tokio::test)]
async fn test_triples_persistence_for_generation() -> anyhow::Result<()> {
    let docker_client = DockerClient::default();
    let gcp_project_id = "test-triple-persistence";
    let docker_network = "test-triple-persistence";
    docker_client.create_network(docker_network).await?;
    let datastore =
        crate::env::containers::Datastore::run(&docker_client, docker_network, gcp_project_id)
            .await?;
    let datastore_url = datastore.local_address.clone();
    // verifies that @triple generation, the datastore triples are in sync with local generated triples
    test_utils::test_triple_generation(Some(datastore_url.clone())).await;
    Ok(())
}

#[test(tokio::test)]
async fn test_triples_persistence_for_deletion() -> anyhow::Result<()> {
    let docker_client = DockerClient::default();
    let gcp_project_id = "test-triple-persistence";
    let docker_network = "test-triple-persistence";
    docker_client.create_network(docker_network).await?;
    let datastore =
        crate::env::containers::Datastore::run(&docker_client, docker_network, gcp_project_id)
            .await?;
    let datastore_url = datastore.local_address.clone();
    // verifies that @triple deletion, the datastore is working as expected
    test_utils::test_triple_deletion(Some(datastore_url)).await;
    Ok(())
}

#[test(tokio::test)]
async fn test_latest_block_height() -> anyhow::Result<()> {
    with_multichain_nodes(MultichainConfig::default(), |ctx| {
        Box::pin(async move {
            let state_0 = wait_for::running_mpc(&ctx, Some(0)).await?;
            assert_eq!(state_0.participants.len(), 3);
            wait_for::has_at_least_triples(&ctx, 2).await?;
            wait_for::has_at_least_presignatures(&ctx, 2).await?;

            let gcp_services = ctx.nodes.gcp_services().await?;
            for gcp_service in &gcp_services {
                let latest = LatestBlockHeight::fetch(gcp_service).await?;
                assert!(latest.block_height > 10);
            }

            // test manually updating the latest block height
            let gcp_service = gcp_services[0].clone();
            let latest = LatestBlockHeight {
                account_id: gcp_service.account_id.clone(),
                block_height: 1000,
            };
            latest.store(&gcp_service).await?;
            let new_latest = LatestBlockHeight::fetch(&gcp_service).await?;
            assert_eq!(new_latest.block_height, latest.block_height);

            Ok(())
        })
    })
    .await
}

'''
'''--- keys/Cargo.toml ---
[package]
name = "mpc-keys"
version = "0.1.0"
edition = "2021"

[lib]
crate-type = ["cdylib", "lib"]

[dependencies]
borsh = { version = "0.9.3" }
hpke = { version = "0.11", features = ["serde_impls", "std"] }
serde = { version = "1", features = ["derive"] }
rand = { version = "0.8" }

[dev-dependencies]
hex = "*"

'''
'''--- keys/src/hpke.rs ---
use borsh::{self, BorshDeserialize, BorshSerialize};
use hpke::{
    aead::{AeadTag, ChaCha20Poly1305},
    kdf::HkdfSha384,
    kem::X25519HkdfSha256,
    OpModeR,
};
use serde::{Deserialize, Serialize};

/// This can be used to customize the generated key. This will be used as a sort of
/// versioning mechanism for the key. It's additional context about who is encrypting
/// the key. This is used to prevent a key from being used in a context it was not
/// supposed to be used for.
const INFO_ENTROPY: &[u8] = b"mpc-key-v1";

// Interchangeable type parameters for the HPKE context.
pub type Kem = X25519HkdfSha256;
pub type Aead = ChaCha20Poly1305;
pub type Kdf = HkdfSha384;

#[derive(Serialize, Deserialize)]
pub struct Ciphered {
    pub encapped_key: EncappedKey,
    pub text: CipherText,
    pub tag: Tag,
}

#[derive(Serialize, Deserialize)]
pub struct Tag(AeadTag<Aead>);

#[derive(Clone, Debug, PartialEq, Eq, Serialize, Deserialize)]
pub struct PublicKey(<Kem as hpke::Kem>::PublicKey);

// NOTE: Arc is used to hack up the fact that the internal private key does not have Send constraint.
#[derive(Clone, PartialEq, Eq, Serialize, Deserialize)]
pub struct SecretKey(<Kem as hpke::Kem>::PrivateKey);

#[derive(Clone, Serialize, Deserialize)]
pub struct EncappedKey(<Kem as hpke::Kem>::EncappedKey);

// Series of bytes that have been previously encoded/encrypted.
pub type CipherText = Vec<u8>;

impl PublicKey {
    pub fn to_bytes(&self) -> [u8; 32] {
        hpke::Serializable::to_bytes(&self.0).into()
    }

    pub fn try_from_bytes(bytes: &[u8]) -> Result<Self, hpke::HpkeError> {
        Ok(Self(hpke::Deserializable::from_bytes(bytes)?))
    }

    /// Assumes the bytes are correctly formatted.
    pub fn from_bytes(bytes: &[u8]) -> Self {
        Self::try_from_bytes(bytes).expect("invalid bytes")
    }

    pub fn encrypt(&self, msg: &[u8], associated_data: &[u8]) -> Result<Ciphered, hpke::HpkeError> {
        let mut csprng = <rand::rngs::StdRng as rand::SeedableRng>::from_entropy();

        // Encapsulate a key and use the resulting shared secret to encrypt a message. The AEAD context
        // is what you use to encrypt.
        let (encapped_key, mut sender_ctx) = hpke::setup_sender::<Aead, Kdf, Kem, _>(
            &hpke::OpModeS::Base,
            &self.0,
            INFO_ENTROPY,
            &mut csprng,
        )?;

        // On success, seal_in_place_detached() will encrypt the plaintext in place
        let mut ciphertext = msg.to_vec();
        let tag = sender_ctx.seal_in_place_detached(&mut ciphertext, associated_data)?;
        Ok(Ciphered {
            encapped_key: EncappedKey(encapped_key),
            text: ciphertext,
            tag: Tag(tag),
        })
    }
}

impl BorshSerialize for PublicKey {
    fn serialize<W: std::io::Write>(&self, writer: &mut W) -> std::io::Result<()> {
        BorshSerialize::serialize(&self.to_bytes(), writer)
    }
}

impl BorshDeserialize for PublicKey {
    fn deserialize(buf: &mut &[u8]) -> std::io::Result<Self> {
        Ok(Self::from_bytes(
            &<Vec<u8> as BorshDeserialize>::deserialize(buf)?,
        ))
    }
}

impl SecretKey {
    pub fn to_bytes(&self) -> [u8; 32] {
        hpke::Serializable::to_bytes(&self.0).into()
    }

    pub fn try_from_bytes(bytes: &[u8]) -> Result<Self, hpke::HpkeError> {
        Ok(Self(hpke::Deserializable::from_bytes(bytes)?))
    }

    pub fn decrypt(
        &self,
        cipher: &Ciphered,
        associated_data: &[u8],
    ) -> Result<Vec<u8>, hpke::HpkeError> {
        // Decapsulate and derive the shared secret. This creates a shared AEAD context.
        let mut receiver_ctx = hpke::setup_receiver::<Aead, Kdf, Kem>(
            &OpModeR::Base,
            &self.0,
            &cipher.encapped_key.0,
            INFO_ENTROPY,
        )?;

        // On success, open_in_place_detached() will decrypt the ciphertext in place
        let mut plaintext = cipher.text.to_vec();
        receiver_ctx.open_in_place_detached(&mut plaintext, associated_data, &cipher.tag.0)?;
        Ok(plaintext)
    }

    /// Get the public key associated with this secret key.
    pub fn public_key(&self) -> PublicKey {
        PublicKey(<Kem as hpke::Kem>::sk_to_pk(&self.0))
    }
}

pub fn generate() -> (SecretKey, PublicKey) {
    let mut csprng = <rand::rngs::StdRng as rand::SeedableRng>::from_entropy();
    let (sk, pk) = <Kem as hpke::Kem>::gen_keypair(&mut csprng);
    (SecretKey(sk), PublicKey(pk))
}

#[cfg(test)]
mod tests {
    #[test]
    fn test_encrypt_decrypt() {
        let (sk, pk) = super::generate();
        let msg = b"hello world";
        let associated_data = b"associated data";

        let cipher = pk.encrypt(msg, associated_data).unwrap();
        let decrypted = sk.decrypt(&cipher, associated_data).unwrap();

        assert_eq!(msg, &decrypted[..]);
    }

    #[test]
    fn test_serialization_format() {
        let sk_hex = "cf3df427dc1377914349b592cfff8deb4b9f8ab1cc4baa8e8e004b6502ac1ca0";
        let pk_hex = "0e6d143bff1d67f297ac68cb9be3667e38f1dc2b244be48bf1d6c6bd7d367c3c";

        let sk = super::SecretKey::try_from_bytes(&hex::decode(sk_hex).unwrap()).unwrap();
        let pk = super::PublicKey::try_from_bytes(&hex::decode(pk_hex).unwrap()).unwrap();
        assert_eq!(sk.public_key(), pk);
    }
}

'''
'''--- keys/src/lib.rs ---
pub mod hpke;

'''
'''--- load-tests/Cargo.toml ---
[package]
name = "load-tests"
version = "0.1.0"
edition = "2021"

[dependencies]
goose = "^0.17"
goose-eggs = "0.5.1"
tokio = "^1.12"
reqwest = "^0.11"
jsonwebtoken = "8.3.0"
near-primitives = "0.17.0"
serde = "1.0.130"
serde_json = "1.0.68"
chrono = "0.4.19"
near-crypto = "0.17.0"
mpc-recovery = { path = "../mpc-recovery" }
rand = "0.8.4"
tracing = "0.1"
tracing-subscriber = { version = "0.3", features = ["env-filter"] }
near-jsonrpc-client = "0.6.0"
near-fetch = "0.2.0"
web3 = "0.19.0"
borsh = "0.10.3"
near-workspaces = "0.10.0"

'''
'''--- load-tests/README.md ---
# MPC Recovery Load Tests
This directory contains load tests for the FastAuth and Multichain services. It is build using [Goose](https://book.goose.rs/title-page.html), a load testing tool written in Rust.

## Running the tests
To run the tests, you need to have Rust installed. You can install Rust using [rustup](https://rustup.rs/).
To start the tests, run the following command:
Fastauth:
```bash
RUST_LOG=info cargo run --release -- --host <host> --report-file=load_test_results.html --test-plan "$(cat ./src/fastauth/test_plans/short.txt)" --scenarios fastAuthSimpleMpcPublicKey
```
Multichain:
```bash
RUST_LOG=info cargo run --release -- --host https://rpc.testnet.near.org --report-file=load_test_results.html --test-plan "$(cat ./src/multichain/test_plans/short.txt)" --scenarios multichainSign
```
You can run Load Tests against your local development environment (check `/integration-tests` for more info) or against the staging environment by setting the `--host` parameter.

The tests are written in Rust and can be found in the `/src` directory.
You can create your own test plan or execute one of the existing test plans from `<service>/test_plans` directory. 

'''
'''--- load-tests/src/fastauth/constants.rs ---
pub const VALID_OIDC_PROVIDER_KEY: &str = "-----BEGIN RSA PRIVATE KEY-----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-----END RSA PRIVATE KEY-----";
pub const VALID_OIDC_AUD: &str = "test_audience";
pub const VALID_OIDC_ISS: &str = "https://securetoken.google.com/test_audience";

'''
'''--- load-tests/src/fastauth/mod.rs ---
pub mod constants;
pub mod primitives;
pub mod utils;

use core::panic;
use near_workspaces::{types::NearToken, Account};
use reqwest::{header::CONTENT_TYPE, Body};
use std::{str::FromStr, time::Duration, vec};

use constants::VALID_OIDC_PROVIDER_KEY;
use goose::prelude::*;
use mpc_recovery::{
    msg::{
        ClaimOidcRequest, MpcPkRequest, NewAccountRequest, SignRequest, UserCredentialsRequest,
        UserCredentialsResponse,
    },
    sign_node::oidc::OidcToken,
    transaction::CreateAccountOptions,
    utils::{
        claim_oidc_request_digest, sign_digest, sign_request_digest,
        user_credentials_request_digest,
    },
};
use near_crypto::SecretKey;
use near_primitives::{
    account::{AccessKey, AccessKeyPermission},
    borsh::BorshSerialize,
    delegate_action::DelegateAction,
    transaction::{Action, AddKeyAction},
    types::AccountId,
};
use primitives::UserSession;
use utils::build_send_and_check_request;

pub async fn prepare_user_credentials(user: &mut GooseUser) -> TransactionResult {
    tracing::info!("prepare_user_credentials");

    let worker = near_workspaces::testnet().await.unwrap();

    let root_account = Account::from_secret_key(
        near_workspaces::types::AccountId::try_from("dev-1660670387515-45063246810397".to_string()).unwrap(),
        near_workspaces::types::SecretKey::from_str(
            "ed25519:4hc3qA3nTE8M63DB8jEZx9ZbHVUPdkMjUAoa11m4xtET7F6w4bk51TwQ3RzEcFhBtXvF6NYzFdiJduaGdJUvynAi"
        ).unwrap(),
        &worker
    );

    let subaccount = root_account
        .create_subaccount(&format!("user-{}", rand::random::<u64>()))
        .initial_balance(NearToken::from_yoctonear(200000000000000000000000u128))
        .transact()
        .await
        .unwrap()
        .into_result()
        .unwrap();

    tracing::info!(
        "Created user accountId: {}, pk: {}",
        subaccount.id(),
        subaccount.secret_key().public_key()
    );

    // Create JWT with random sub (usually done by OIDC Provider)
    let oidc_token = OidcToken::new(&utils::create_jwt_token(
        VALID_OIDC_PROVIDER_KEY,
        constants::VALID_OIDC_AUD,
        constants::VALID_OIDC_ISS,
        None,
    ));

    let session = UserSession {
        jwt_token: oidc_token,
        account: subaccount.clone(),
        root_account,
        near_account_id: AccountId::try_from(subaccount.id().to_string()).unwrap(),
        fa_sk: SecretKey::from_str(&subaccount.secret_key().to_string()).unwrap(),
        la_sk: SecretKey::from_random(near_crypto::KeyType::ED25519), // no need to actually add it ATM
        recovery_pk: None,
    };

    user.set_session_data(session);

    Ok(())
}

pub async fn delete_user_account(user: &mut GooseUser) -> TransactionResult {
    tracing::info!("delete_user_accounts");

    let session = user
        .get_session_data::<UserSession>()
        .expect("Session Data must be set");

    let _ = session
        .account
        .clone()
        .delete_account(session.root_account.id())
        .await
        .expect("Failed to delete subaccount");

    Ok(())
}

pub async fn user_credentials(user: &mut GooseUser) -> TransactionResult {
    tracing::info!("user_credentials");
    let session = user
        .get_session_data::<UserSession>()
        .expect("Session Data must be set");

    let oidc_token = session.jwt_token.clone();
    let fa_sk = session.fa_sk.clone();
    let fa_pk = fa_sk.public_key();
    let la_sk = session.la_sk.clone();
    let near_account_id = session.near_account_id.clone();
    let account = session.account.clone();
    let root_account = session.root_account.clone();

    let user_credentials_request_digest =
        user_credentials_request_digest(&oidc_token, &fa_pk).expect("Failed to create digest");

    let user_credentials_frp_signature =
        sign_digest(&user_credentials_request_digest, &fa_sk).expect("Failed to sign digest");

    let user_credentials_request = UserCredentialsRequest {
        oidc_token: oidc_token.clone(),
        frp_public_key: fa_pk,
        frp_signature: user_credentials_frp_signature,
    };

    let body_json =
        serde_json::to_string(&user_credentials_request).expect("json serialization failed");

    let body = Body::from(body_json.to_owned());
    let request_builder = user
        .get_request_builder(&GooseMethod::Post, "user_credentials")?
        .body(body)
        .header(CONTENT_TYPE, "application/json")
        .timeout(Duration::from_secs(10));

    let goose_request = GooseRequest::builder()
        .set_request_builder(request_builder)
        .build();

    let goose_responce = user.request(goose_request).await?;

    let response = goose_responce.response.expect("Expected response ... .");

    let user_credentials_response = response
        .json::<UserCredentialsResponse>()
        .await
        .expect("Failed to parse user credentials response");

    if let UserCredentialsResponse::Ok { recovery_pk } = user_credentials_response {
        tracing::info!("UserCredentialsResponce has Ok, setting session data");
        let session = UserSession {
            jwt_token: oidc_token,
            account,
            root_account,
            near_account_id,
            fa_sk,
            la_sk,
            recovery_pk: Some(recovery_pk),
        };
        user.set_session_data(session);
    } else {
        panic!(
            "UserCredentialsResponce has Error: {:?}",
            user_credentials_response
        );
    }

    Ok(())
}

pub async fn mpc_public_key(user: &mut GooseUser) -> TransactionResult {
    tracing::info!("mpc_public_key");
    let body_json = serde_json::to_string(&MpcPkRequest {}).expect("json serialization failed");
    build_send_and_check_request(user, "mpc_public_key", &body_json).await
}

pub async fn claim_oidc(user: &mut GooseUser) -> TransactionResult {
    tracing::info!("claim_oidc");
    let session = user
        .get_session_data::<UserSession>()
        .expect("Session Data must be set");
    let oidc_token_hash = session.jwt_token.digest_hash();
    let frp_secret_key = session.fa_sk.clone();
    let frp_public_key = frp_secret_key.public_key();

    let request_digest = claim_oidc_request_digest(&oidc_token_hash, &frp_public_key)
        .expect("Failed to create digest");
    let frp_signature =
        sign_digest(&request_digest, &frp_secret_key).expect("Failed to sign digest");

    let claim_oidc_request = ClaimOidcRequest {
        oidc_token_hash: oidc_token_hash.to_owned(),
        frp_public_key,
        frp_signature,
    };

    let body_json = serde_json::to_string(&claim_oidc_request).expect("json serialization failed");

    build_send_and_check_request(user, "claim_oidc", &body_json).await
}

pub async fn new_account(user: &mut GooseUser) -> TransactionResult {
    let session = user
        .get_session_data::<UserSession>()
        .expect("Session Data must be set");
    let oidc_token = session.jwt_token.clone();
    let fa_secret_key = session.fa_sk.clone();
    let fa_public_key = fa_secret_key.public_key();
    let user_account_id = session.near_account_id.clone();

    let create_account_options = CreateAccountOptions {
        full_access_keys: Some(vec![fa_public_key.clone()]),
        limited_access_keys: None,
        contract_bytes: None,
    };

    let user_credentials_request_digest =
        user_credentials_request_digest(&oidc_token, &fa_public_key)
            .expect("Failed to create digest");

    let user_credentials_frp_signature =
        sign_digest(&user_credentials_request_digest, &fa_secret_key)
            .expect("Failed to sign digest");

    let new_account_request = NewAccountRequest {
        near_account_id: user_account_id,
        create_account_options,
        oidc_token: session.jwt_token.clone(),
        user_credentials_frp_signature,
        frp_public_key: fa_public_key,
    };

    let body_json = serde_json::to_string(&new_account_request).expect("json serialization failed");
    build_send_and_check_request(user, "new_account", &body_json).await
}

pub async fn sign(user: &mut GooseUser) -> TransactionResult {
    tracing::info!("sign");
    let session = user
        .get_session_data::<UserSession>()
        .expect("Session Data must be set");
    let oidc_token = session.jwt_token.clone();
    let fa_secret_key = session.fa_sk.clone();
    let fa_public_key = fa_secret_key.public_key();
    let account_id = session.near_account_id.clone();
    let recovery_pk = session
        .recovery_pk
        .clone()
        .expect("Recovery PK must be set before calling /sign");

    let new_secret_key = SecretKey::from_random(near_crypto::KeyType::ED25519);
    let new_public_key = new_secret_key.public_key();

    let nonce = 0; // Set real nonce in case transaction is entend to be executed
    let block_height = 0; // Set real block height in case transaction is entend to be executed

    let add_key_delegate_action = DelegateAction {
        sender_id: account_id.clone(),
        receiver_id: account_id.clone(),
        actions: vec![Action::AddKey(AddKeyAction {
            public_key: new_public_key.clone(),
            access_key: AccessKey {
                nonce: 0,
                permission: AccessKeyPermission::FullAccess,
            },
        })
        .try_into()
        .unwrap()],
        nonce,
        max_block_height: block_height + 100,
        public_key: recovery_pk,
    };

    let sign_request_digest =
        sign_request_digest(&add_key_delegate_action, &oidc_token, &fa_public_key)
            .expect("Failed to create digest");
    let sign_request_frp_signature =
        sign_digest(&sign_request_digest, &fa_secret_key).expect("Failed to sign digest");

    let user_credentials_request_digest =
        user_credentials_request_digest(&oidc_token, &fa_public_key)
            .expect("Failed to create digest");
    let user_credentials_frp_signature =
        sign_digest(&user_credentials_request_digest, &fa_secret_key)
            .expect("Failed to sign digest");

    let sign_request = SignRequest {
        delegate_action: add_key_delegate_action
            .try_to_vec()
            .expect("Failed to serialize delegate action"),
        oidc_token,
        frp_signature: sign_request_frp_signature,
        user_credentials_frp_signature,
        frp_public_key: fa_public_key,
    };

    let body_json = serde_json::to_string(&sign_request).expect("json serialization failed");
    build_send_and_check_request(user, "sign", &body_json).await
}

'''
'''--- load-tests/src/fastauth/primitives.rs ---
use mpc_recovery::sign_node::oidc::OidcToken;
use near_crypto::{PublicKey, SecretKey};
use near_primitives::types::AccountId;
use near_workspaces::Account;
use serde::{Deserialize, Serialize};

#[derive(Debug, Serialize, Deserialize)]
pub struct IdTokenClaims {
    pub iss: String,
    pub sub: String,
    pub aud: String,
    pub exp: usize,
}

pub struct UserSession {
    pub jwt_token: OidcToken,
    pub account: Account,
    // account to create other account
    pub root_account: Account,
    pub near_account_id: AccountId,
    pub fa_sk: SecretKey,
    pub la_sk: SecretKey,
    pub recovery_pk: Option<PublicKey>,
}

'''
'''--- load-tests/src/fastauth/test_plans/long_with_spikes.txt ---
500,5m;500,5m;2500,45s;500,45s;500,5m;2500,45s;500,45s;500,5m;0,0s
'''
'''--- load-tests/src/fastauth/test_plans/short.txt ---
0,0s;100,20s;0,0s
'''
'''--- load-tests/src/fastauth/utils.rs ---
use chrono::Utc;
use goose::prelude::{GooseMethod, GooseRequest, GooseUser, TransactionResult};
use goose_eggs::{validate_and_load_static_assets, Validate};
use jsonwebtoken::{encode, Algorithm, EncodingKey, Header};
use near_primitives::utils::generate_random_string;
use reqwest::{header::CONTENT_TYPE, Body};
use std::time::Duration;

use super::primitives::IdTokenClaims;

// TODO: try using existing function
pub fn create_jwt_token(
    secret_rsa_pem_key: &str,
    aud: &str,
    iss: &str,
    sub: Option<&str>,
) -> String {
    let rnd_sub = generate_random_string(10);
    let sub = sub.unwrap_or_else(|| &rnd_sub);

    let my_claims = IdTokenClaims {
        iss: iss.to_owned(),
        sub: sub.to_owned(),
        aud: aud.to_owned(),
        exp: (Utc::now() + chrono::Duration::hours(1)).timestamp() as usize,
    };

    let private_key_der = secret_rsa_pem_key.as_bytes().to_vec();

    let token = encode(
        &Header::new(Algorithm::RS256),
        &my_claims,
        &EncodingKey::from_rsa_pem(&private_key_der).unwrap(),
    )
    .expect("Failed to encode jwt token");

    token.to_string()
}

pub async fn build_send_and_check_request(
    user: &mut GooseUser,
    path: &str,
    body_json: &str,
) -> TransactionResult {
    let body = Body::from(body_json.to_owned());
    let request_builder = user
        .get_request_builder(&GooseMethod::Post, path)?
        .body(body)
        .header(CONTENT_TYPE, "application/json")
        .timeout(Duration::from_secs(10));

    let goose_request = GooseRequest::builder()
        .set_request_builder(request_builder)
        .build();

    let goose_responce = user.request(goose_request).await?;

    let validate = &Validate::builder().status(200).build();
    validate_and_load_static_assets(user, goose_responce, validate).await?;

    Ok(())
}

'''
'''--- load-tests/src/main.rs ---
pub mod fastauth;
pub mod multichain;

use fastauth::{
    claim_oidc, delete_user_account, mpc_public_key, new_account, prepare_user_credentials, sign,
    user_credentials,
};
use goose::prelude::*;
use multichain::multichain_sign;
use tracing_subscriber::{filter, prelude::*};

#[tokio::main]
async fn main() -> Result<(), GooseError> {
    let stdout_log = tracing_subscriber::fmt::layer().pretty();

    tracing_subscriber::registry()
        .with(stdout_log.with_filter(filter::LevelFilter::INFO))
        .init();

    GooseAttack::initialize()?
        .register_scenario(
            scenario!("multichainSign")
                .register_transaction(transaction!(prepare_user_credentials).set_sequence(1))
                .register_transaction(transaction!(multichain_sign).set_sequence(2))
                .register_transaction(transaction!(multichain_sign).set_sequence(3))
                .register_transaction(transaction!(multichain_sign).set_sequence(4))
                .register_transaction(transaction!(multichain_sign).set_sequence(5))
                .register_transaction(transaction!(multichain_sign).set_sequence(6))
                .register_transaction(transaction!(multichain_sign).set_sequence(7))
                .register_transaction(transaction!(multichain_sign).set_sequence(8))
                .register_transaction(transaction!(multichain_sign).set_sequence(9))
                .register_transaction(transaction!(multichain_sign).set_sequence(10))
                .register_transaction(transaction!(multichain_sign).set_sequence(11))
                .register_transaction(transaction!(delete_user_account).set_sequence(12)),
        )
        .register_scenario(
            scenario!("fastAuthRegistration")
                .register_transaction(transaction!(prepare_user_credentials).set_sequence(1))
                .register_transaction(transaction!(claim_oidc).set_sequence(2))
                .register_transaction(transaction!(new_account).set_sequence(3)),
        )
        .register_scenario(
            scenario!("fastAuthRegistrationAndSign")
                .register_transaction(transaction!(prepare_user_credentials).set_sequence(1))
                .register_transaction(transaction!(claim_oidc).set_sequence(2))
                .register_transaction(transaction!(new_account).set_sequence(3))
                .register_transaction(transaction!(user_credentials).set_sequence(4))
                .register_transaction(
                    transaction!(sign)
                        .set_sequence(5)
                        .set_weight(1000) // In this scenario we are mostly testing /sign functionality
                        .expect("Failed to set weight"),
                ),
        )
        .register_scenario(
            scenario!("fastAuthSimpleClaimOidc")
                .register_transaction(transaction!(prepare_user_credentials).set_sequence(1))
                .register_transaction(
                    transaction!(claim_oidc)
                        .set_sequence(2)
                        .set_weight(100)
                        .expect("Failed to set weight"),
                ),
        )
        .register_scenario(
            scenario!("fastAuthSimpleUserCredentials")
                .register_transaction(transaction!(prepare_user_credentials).set_sequence(1))
                .register_transaction(transaction!(claim_oidc).set_sequence(2))
                .register_transaction(
                    transaction!(user_credentials)
                        .set_sequence(3)
                        .set_weight(100)
                        .expect("Failed to set weight"),
                ),
        )
        .register_scenario(
            scenario!("fastAuthSimpleMpcPublicKey")
                .register_transaction(transaction!(mpc_public_key)),
        )
        .execute()
        .await?;

    Ok(())
}

'''
'''--- load-tests/src/multichain/mod.rs ---
use std::time::Duration;

use goose::goose::{GooseMethod, GooseRequest, GooseUser, TransactionResult};
use goose_eggs::{validate_and_load_static_assets, Validate};
use near_crypto::InMemorySigner;
use near_jsonrpc_client::JsonRpcClient;
use near_primitives::{
    transaction::{Action, FunctionCallAction, Transaction},
    types::AccountId,
};
use rand::Rng;
use reqwest::header::CONTENT_TYPE;

use crate::fastauth::primitives::UserSession;

pub async fn multichain_sign(user: &mut GooseUser) -> TransactionResult {
    tracing::info!("multichain_sign");

    let session = user
        .get_session_data::<UserSession>()
        .expect("Session Data must be set");

    let multichain_contract_id =
        AccountId::try_from("v2.multichain-mpc.testnet".to_string()).unwrap();
    let testnet_rpc_url = "https://rpc.testnet.near.org".to_string();

    let signer = InMemorySigner {
        account_id: session.near_account_id.clone(),
        public_key: session.fa_sk.public_key(),
        secret_key: session.fa_sk.clone(),
    };

    let connector = JsonRpcClient::new_client();
    let jsonrpc_client = connector.connect(&testnet_rpc_url);
    let rpc_client = near_fetch::Client::from_client(jsonrpc_client.clone());

    let (nonce, block_hash, _) = rpc_client
        .fetch_nonce(&signer.account_id, &signer.public_key)
        .await
        .unwrap();

    let payload_hashed: [u8; 32] = rand::thread_rng().gen();
    tracing::info!("requesting signature for: {:?}", payload_hashed);

    let transaction = Transaction {
        signer_id: session.near_account_id.clone(),
        public_key: session.fa_sk.public_key(),
        nonce,
        receiver_id: multichain_contract_id,
        block_hash,
        actions: vec![Action::FunctionCall(FunctionCallAction {
            method_name: "sign".to_string(),
            args: serde_json::to_vec(&serde_json::json!({
                "payload": payload_hashed,
                "path": "test",
                "key_version": 0,
            }))
            .unwrap(),
            gas: 300_000_000_000_000,
            deposit: 0,
        })],
    };

    let signed_transaction = transaction.sign(&signer);

    let encoded_transaction = near_primitives::serialize::to_base64(
        &borsh::BorshSerialize::try_to_vec(&signed_transaction).unwrap(),
    );

    let payload = serde_json::json!({
        "jsonrpc": "2.0",
        "id": "dontcare",
        "method": "broadcast_tx_commit",
        "params": [
            encoded_transaction
        ]
    });

    let request_builder = user
        .get_request_builder(&GooseMethod::Post, "")?
        .json(&payload)
        .header(CONTENT_TYPE, "application/json")
        .timeout(Duration::from_secs(50));

    let goose_request = GooseRequest::builder()
        .set_request_builder(request_builder)
        .build();

    let goose_response = user.request(goose_request).await?;

    // let text = goose_response.response.unwrap().text().await.unwrap();
    // tracing::info!("goose_response: {:?}", text);

    let rsp = goose_response.response.as_ref().unwrap();

    tracing::info!("goose_response: {:?}", rsp);

    let expected_log = "sign_helper: signature ready";

    let validate = &Validate::builder()
        .status(200)
        .text(expected_log) // Naive check if the request is successful
        .build();
    validate_and_load_static_assets(user, goose_response, validate).await?;

    Ok(())
}

'''
'''--- load-tests/src/multichain/test_plans/short.txt ---
0,0s;5,30s;5,20m;0,0s
'''
'''--- mpc-recovery/Cargo.toml ---
[package]
name = "mpc-recovery"
version = "0.1.0"
edition = "2021"

[[bin]]
name = "mpc-recovery"
path = "src/main.rs"

[dependencies]
aes-gcm = "0.10"
actix-rt = "2.8"
anyhow = "1"
async-trait = "0.1"
atty = "0.2"
axum = "0.6.19"
axum-extra = "0.7"
axum-tracing-opentelemetry = "0.14.1"
base64 = "0.21"
borsh = "0.10.3"
chrono = "0.4.24"
clap = { version = "4.2", features = ["derive", "env"] }
futures = "0.3"
google-datastore1 = "5"
google-secretmanager1 = "5"
hex = "0.4.3"
hyper = { version = "0.14", features = ["full"] }
hyper-rustls = { version = "=0.23", features = ["http2"] }
jsonwebtoken = "8.3.0"
lazy_static = "1.4.0"
opentelemetry = { version = "0.20.0", features = ["rt-tokio", "trace"] }
opentelemetry-otlp = { version = "0.13.0", features = [
    "http-proto",
    "reqwest-client",
] }
opentelemetry-semantic-conventions = "0.12.0"
prometheus = { version = "0.13.3", features = ["process"] }
rand = "0.8"
reqwest = { version = "0.11.16", features = ["blocking"] }
serde = { version = "1", features = ["derive"] }
serde_json = "1"
serde_with = "3.3.0"
thiserror = "1"
tokio = { version = "1.28", features = ["full"] }
tokio-retry = "0.3"
tracing = "0.1"
tracing-appender = "0.2.2"
tracing-subscriber = { version = "0.3", features = ["env-filter"] }
tracing-opentelemetry = "0.21.0"
near-fetch = "0.0.12"
near-jsonrpc-client = "0.6"
near-jsonrpc-primitives = "0.17"
near-primitives = "0.17.0"
near-crypto = "0.17"
tower-http = { version = "0.4.0", features = ["cors"] }
yup-oauth2 = "8"
multi-party-eddsa = { git = "https://github.com/DavidM-D/multi-party-eddsa.git", rev = "25ae4fdc5ff7819ae70e73ab4afacf1c24fc4da1" }
curv = { package = "curv-kzen", version = "0.9", default-features = false }
# TODO: Update to >=2 to resolve RUSTSEC-2022-0093
ed25519-dalek = { version = "1.0.1", features = ["serde"] }
sha2 = "0.9.9"
zerocopy = "0.7.32"

[dev-dependencies]
rsa = "0.8.2"

[features]
default = []
disable-open-telemetry = []

'''
'''--- mpc-recovery/build.rs ---
// HACK: need this build script so that env var OUT_DIR gets set:
// https://doc.rust-lang.org/cargo/reference/environment-variables.html#environment-variables-cargo-sets-for-crates
fn main() {}

'''
'''--- mpc-recovery/src/error.rs ---
use axum::extract::rejection::JsonRejection;
use axum::http::StatusCode;
use axum::response::Response;
use curv::elliptic::curves::{Ed25519, Point};
use curv::BigInt;
use near_crypto::PublicKey;

use crate::relayer::error::RelayerError;
use crate::sign_node::oidc::OidcDigest;

// TODO: maybe want to flatten out the error types to be ErrorCode + ErrorData
/// This enum error type serves as one true source of all errors in mpc-recovery
/// crate. It is used to unify all errors that can happen in the application.
#[derive(Debug, thiserror::Error)]
pub enum MpcError {
    #[error(transparent)]
    JsonExtractorRejection(#[from] JsonRejection),
    #[error(transparent)]
    SignNodeRejection(#[from] SignNodeError),
    #[error(transparent)]
    LeaderNodeRejection(#[from] LeaderNodeError),
}

impl MpcError {
    pub fn status(&self) -> StatusCode {
        match self {
            Self::JsonExtractorRejection(json_rejection) => json_rejection.status(),
            Self::LeaderNodeRejection(error) => error.code(),
            Self::SignNodeRejection(error) => error.code(),
        }
    }

    pub fn safe_error_message(&self) -> String {
        if self.status().is_server_error() {
            "Internal Server Error: Unexpected issue occurred. The backend team was notified."
                .to_string()
        } else {
            match self {
                Self::JsonExtractorRejection(json_rejection) => json_rejection.body_text(),
                Self::LeaderNodeRejection(error) => error.to_string(),
                Self::SignNodeRejection(error) => error.to_string(),
            }
        }
    }
}

// We implement `IntoResponse` so MpcError can be used as a response
impl axum::response::IntoResponse for MpcError {
    fn into_response(self) -> Response {
        (self.status(), axum::Json(self.safe_error_message())).into_response()
    }
}

#[derive(Debug, thiserror::Error)]
pub enum LeaderNodeError {
    #[error("client error: {0}")]
    ClientError(String, StatusCode),
    #[error("server error: {0}")]
    ServerError(String),
    #[error("{0}")]
    DataConversionFailure(anyhow::Error),
    #[error("aggregate signing failed: {0}")]
    AggregateSigningFailed(#[from] AggregateSigningError),
    #[error("malformed delegate action: {0}")]
    MalformedDelegateAction(std::io::Error),
    #[error("failed to verify signature: {0}")]
    SignatureVerificationFailed(anyhow::Error),
    #[error("failed to verify oidc token: {0}")]
    OidcVerificationFailed(anyhow::Error),
    #[error("relayer error: {0}")]
    RelayerError(#[from] RelayerError),
    #[error("recovery key can not be deleted: {0}")]
    RecoveryKeyCanNotBeDeleted(PublicKey),
    #[error("action can not be performed, account deletion is not allowed")]
    AccountDeletionUnsupported,
    #[error("failed to retrieve recovery pk, check digest signature: {0}")]
    FailedToRetrieveRecoveryPk(anyhow::Error),
    #[error("timeout gathering sign node pks")]
    TimeoutGatheringPublicKeys,
    #[error("network error: {0}")]
    NetworkRejection(#[from] reqwest::Error),
    #[error(transparent)]
    Other(#[from] anyhow::Error),
}

impl LeaderNodeError {
    pub fn code(&self) -> StatusCode {
        match self {
            LeaderNodeError::ClientError(_, code) => *code,
            LeaderNodeError::ServerError(_) => StatusCode::INTERNAL_SERVER_ERROR,
            LeaderNodeError::DataConversionFailure(_) => StatusCode::BAD_REQUEST,
            LeaderNodeError::AggregateSigningFailed(err) => err.code(),
            LeaderNodeError::SignatureVerificationFailed(_) => StatusCode::BAD_REQUEST,
            LeaderNodeError::OidcVerificationFailed(_) => StatusCode::UNAUTHORIZED,
            LeaderNodeError::MalformedDelegateAction(_) => StatusCode::BAD_REQUEST,
            LeaderNodeError::RelayerError(_) => StatusCode::FAILED_DEPENDENCY,
            LeaderNodeError::TimeoutGatheringPublicKeys => StatusCode::INTERNAL_SERVER_ERROR,
            LeaderNodeError::RecoveryKeyCanNotBeDeleted(_) => StatusCode::BAD_REQUEST,
            LeaderNodeError::AccountDeletionUnsupported => StatusCode::BAD_REQUEST,
            LeaderNodeError::FailedToRetrieveRecoveryPk(_) => StatusCode::UNAUTHORIZED,
            LeaderNodeError::NetworkRejection(err) => {
                err.status().unwrap_or(StatusCode::REQUEST_TIMEOUT)
            }
            LeaderNodeError::Other(_) => StatusCode::INTERNAL_SERVER_ERROR,
        }
    }
}

#[derive(Debug, thiserror::Error)]
pub enum SignNodeError {
    #[error("failed to verify signature: {0}")]
    DigestSignatureVerificationFailed(anyhow::Error),
    #[error("failed to verify oidc token: {0}")]
    OidcVerificationFailed(anyhow::Error),
    #[error("oidc token {0:?} already claimed with another key")]
    OidcTokenAlreadyClaimed(OidcDigest),
    #[error("oidc token {0:?} was claimed with another key")]
    OidcTokenClaimedWithAnotherKey(OidcDigest),
    #[error("oidc token {0:?} was not claimed")]
    OidcTokenNotClaimed(OidcDigest),
    #[error("aggregate signing failed: {0}")]
    AggregateSigningFailed(#[from] AggregateSigningError),
    #[error(transparent)]
    Other(#[from] anyhow::Error),
}

impl SignNodeError {
    pub fn code(&self) -> StatusCode {
        match self {
            Self::DigestSignatureVerificationFailed(_) => StatusCode::UNAUTHORIZED,
            Self::OidcVerificationFailed(_) => StatusCode::BAD_REQUEST,
            Self::OidcTokenAlreadyClaimed(_) => StatusCode::UNAUTHORIZED,
            Self::OidcTokenClaimedWithAnotherKey(_) => StatusCode::UNAUTHORIZED,
            Self::OidcTokenNotClaimed(_) => StatusCode::UNAUTHORIZED,
            Self::AggregateSigningFailed(err) => err.code(),
            Self::Other(_) => StatusCode::INTERNAL_SERVER_ERROR,
        }
    }
}

#[derive(Debug, thiserror::Error)]
pub enum AggregateSigningError {
    #[error("invalid number of commitments: trying to fetch id={0} in {1} commitments")]
    InvalidCommitmentNumbers(usize, usize),
    #[error("invalid number of reveals: trying to fetch id={0} in {1} reveals")]
    InvalidRevealNumbers(usize, usize),
    #[error("commitment not found: {0}")]
    CommitmentNotFound(String),
    #[error("reveal not found: {0}")]
    RevealNotFound(String),
    #[error("in a commitment r={0:?}, blind={1}; expected {2} but found {3}")]
    InvalidCommitment(Point<Ed25519>, BigInt, BigInt, BigInt),
    #[error("no node public keys available to sign")]
    NodeKeysUnavailable,
    #[error("failed to verify signature: {0}")]
    SignatureVerificationFailed(anyhow::Error),
    #[error("{0}")]
    DataConversionFailure(anyhow::Error),
}

impl AggregateSigningError {
    pub fn code(&self) -> StatusCode {
        match self {
            Self::InvalidCommitmentNumbers(_, _) => StatusCode::BAD_REQUEST,
            Self::InvalidRevealNumbers(_, _) => StatusCode::BAD_REQUEST,
            Self::CommitmentNotFound(_) => StatusCode::BAD_REQUEST,
            Self::RevealNotFound(_) => StatusCode::BAD_REQUEST,
            Self::InvalidCommitment(_, _, _, _) => StatusCode::BAD_REQUEST,
            Self::NodeKeysUnavailable => StatusCode::BAD_REQUEST,
            Self::SignatureVerificationFailed(_) => StatusCode::BAD_REQUEST,
            Self::DataConversionFailure(_) => StatusCode::BAD_REQUEST,
        }
    }
}

'''
'''--- mpc-recovery/src/firewall/allowed.rs ---
use std::collections::HashSet;

use serde::{Deserialize, Serialize};

#[derive(Clone, Debug, Serialize, Deserialize, Hash, PartialEq, Eq)]
pub struct OidcProvider {
    pub issuer: String,
    pub audience: String,
}

#[derive(Clone, Debug, Serialize, Deserialize, Hash, PartialEq, Eq)]
pub struct DelegateActionRelayer {
    pub url: String,
    pub api_key: Option<String>,
}

#[derive(Clone, Debug, Serialize, Deserialize, Hash, PartialEq, Eq)]
pub struct FastAuthPartner {
    pub oidc_provider: OidcProvider,
    pub relayer: DelegateActionRelayer,
}

#[derive(Clone, Debug, Default, Serialize, Deserialize)]
pub struct OidcProviderList {
    pub entries: HashSet<OidcProvider>,
}

impl OidcProviderList {
    pub fn contains(&self, issuer: &str, audience: &str) -> bool {
        self.entries.contains(&OidcProvider {
            issuer: issuer.into(),
            audience: audience.into(),
        })
    }

    pub fn insert(&mut self, entry: OidcProvider) {
        self.entries.insert(entry);
    }
}

#[derive(Clone, Debug, Default, Serialize, Deserialize)]
pub struct PartnerList {
    pub entries: HashSet<FastAuthPartner>,
}

impl PartnerList {
    pub fn contains(&self, issuer: &str, audience: &str) -> bool {
        self.entries.iter().any(|entry| {
            entry.oidc_provider.issuer == issuer && entry.oidc_provider.audience == audience
        })
    }

    pub fn find(&self, issuer: &str, audience: &str) -> anyhow::Result<FastAuthPartner> {
        match self
            .entries
            .iter()
            .find(|entry| {
                entry.oidc_provider.issuer == issuer && entry.oidc_provider.audience == audience
            })
            .cloned()
        {
            Some(partner) => Ok(partner),
            None => Err(anyhow::anyhow!(
                "Failed to find relayer for given partner. Issuer: {}, Audience: {}",
                issuer,
                audience,
            )),
        }
    }

    pub fn oidc_providers(&self) -> OidcProviderList {
        let mut oidc_providers = OidcProviderList::default();
        for entry in self.entries.iter() {
            oidc_providers.insert(entry.oidc_provider.clone());
        }
        oidc_providers
    }
}

'''
'''--- mpc-recovery/src/firewall/mod.rs ---
pub mod allowed;

'''
'''--- mpc-recovery/src/gcp/error.rs ---
#[derive(Debug, thiserror::Error)]
pub enum ConvertError {
    #[error("expected property `{0}` was missing")]
    MissingProperty(String),
    #[error("expected property type `{expected}`, got `{got}`")]
    UnexpectedPropertyType { expected: String, got: String },
    #[error("property `{0}` is malfored")]
    MalformedProperty(String),
}

'''
'''--- mpc-recovery/src/gcp/mod.rs ---
pub mod error;
pub mod value;

use self::value::{FromValue, IntoValue};
use google_datastore1::api::{
    CommitRequest, Entity, EntityResult, Key, KindExpression, LookupRequest, Mutation, PathElement,
    Query, RunQueryRequest,
};
use google_datastore1::oauth2::AccessTokenAuthenticator;
use google_datastore1::Datastore;
use google_secretmanager1::oauth2::authenticator::ApplicationDefaultCredentialsTypes;
use google_secretmanager1::oauth2::{
    ApplicationDefaultCredentialsAuthenticator, ApplicationDefaultCredentialsFlowOpts,
};
use google_secretmanager1::SecretManager;
use hyper::client::HttpConnector;
use hyper_rustls::HttpsConnector;

#[derive(Clone)]
pub struct GcpService {
    env: String,
    project_id: String,
    datastore: Datastore<HttpsConnector<HttpConnector>>,
    secret_manager: SecretManager<HttpsConnector<HttpConnector>>,
}

pub trait KeyKind {
    fn kind() -> String;
}

impl GcpService {
    pub async fn new(
        env: String,
        project_id: String,
        gcp_datastore_url: Option<String>,
    ) -> anyhow::Result<Self> {
        let mut datastore;
        let secret_manager;
        let client = hyper::Client::builder().build(
            hyper_rustls::HttpsConnectorBuilder::new()
                .with_native_roots()
                .https_or_http()
                .enable_http1()
                .enable_http2()
                .build(),
        );
        if let Some(gcp_datastore_url) = gcp_datastore_url {
            // Assuming custom GCP URL points to an emulator, so the token does not matter
            let authenticator = AccessTokenAuthenticator::builder("TOKEN".to_string())
                .build()
                .await?;
            secret_manager = SecretManager::new(client.clone(), authenticator.clone());
            datastore = Datastore::new(client, authenticator);
            datastore.base_url(gcp_datastore_url.clone());
            datastore.root_url(gcp_datastore_url);
        } else {
            let opts = ApplicationDefaultCredentialsFlowOpts::default();
            let authenticator = match ApplicationDefaultCredentialsAuthenticator::builder(opts)
                .await
            {
                ApplicationDefaultCredentialsTypes::InstanceMetadata(auth) => auth.build().await?,
                ApplicationDefaultCredentialsTypes::ServiceAccount(auth) => auth.build().await?,
            };
            secret_manager = SecretManager::new(client.clone(), authenticator.clone());
            datastore = Datastore::new(client, authenticator);
        }

        Ok(Self {
            env,
            project_id,
            datastore,
            secret_manager,
        })
    }

    #[tracing::instrument(level = "debug", skip_all, fields(name = name.as_ref()))]
    pub async fn load_secret<T: AsRef<str>>(&self, name: T) -> anyhow::Result<Vec<u8>> {
        let (_, response) = self
            .secret_manager
            .projects()
            .secrets_versions_access(&format!(
                "projects/{}/secrets/{}",
                self.project_id,
                name.as_ref()
            ))
            .doit()
            .await?;
        let secret_payload = response
            .payload
            .ok_or_else(|| anyhow::anyhow!("secret value is missing payload"))?;
        let data = secret_payload
            .data
            .ok_or_else(|| anyhow::anyhow!("secret value payload is missing data"))?;
        tracing::debug!("loaded secret successfully");

        Ok(data)
    }

    #[tracing::instrument(level = "debug", skip_all, fields(key = name_key.to_string()))]
    pub async fn get<K: ToString, T: FromValue + KeyKind>(
        &self,
        name_key: K,
    ) -> anyhow::Result<Option<T>> {
        let request = LookupRequest {
            keys: Some(vec![Key {
                path: Some(vec![PathElement {
                    // We can't create multiple datastore databases in GCP, so we have to suffix
                    // type kinds with env (`dev`, `prod`).
                    kind: Some(format!("{}-{}", T::kind(), self.env)),
                    name: Some(name_key.to_string()),
                    id: None,
                }]),
                partition_id: None,
            }]),
            read_options: None,
            database_id: Some("".to_string()),
        };
        tracing::debug!(?request);
        let (_, response) = self
            .datastore
            .projects()
            .lookup(request, &self.project_id)
            .doit()
            .await?;
        tracing::debug!(?response, "received response");
        match response
            .found
            .and_then(|mut results| results.pop())
            .and_then(|result| result.entity)
        {
            Some(found_entity) => Ok(Some(T::from_value(found_entity.into_value())?)),
            None => Ok(None),
        }
    }

    #[tracing::instrument(level = "debug", skip_all)]
    pub async fn insert<T: IntoValue + KeyKind>(&self, value: T) -> anyhow::Result<()> {
        let mut entity = Entity::from_value(value.into_value())?;
        let path_element = entity
            .key
            .as_mut()
            .and_then(|k| k.path.as_mut())
            .and_then(|p| p.first_mut());
        if let Some(path_element) = path_element {
            // We can't create multiple datastore databases in GCP, so we have to suffix
            // type kinds with env (`dev`, `prod`).
            path_element.kind = Some(format!("{}-{}", T::kind(), self.env))
        }

        let request = CommitRequest {
            database_id: Some("".to_string()),
            mode: Some(String::from("NON_TRANSACTIONAL")),
            mutations: Some(vec![Mutation {
                insert: Some(entity),
                delete: None,
                update: None,
                base_version: None,
                upsert: None,
                update_time: None,
            }]),
            single_use_transaction: None,
            transaction: None,
        };
        tracing::debug!(?request);
        let (_, response) = self
            .datastore
            .projects()
            .commit(request, &self.project_id)
            .doit()
            .await?;
        tracing::debug!(?response, "received response");

        Ok(())
    }

    #[tracing::instrument(level = "debug", skip_all)]
    pub async fn update<T: IntoValue + KeyKind>(&self, value: T) -> anyhow::Result<()> {
        let mut entity = Entity::from_value(value.into_value())?;
        let path_element = entity
            .key
            .as_mut()
            .and_then(|k| k.path.as_mut())
            .and_then(|p| p.first_mut());
        if let Some(path_element) = path_element {
            // We can't create multiple datastore databases in GCP, so we have to suffix
            // type kinds with env (`dev`, `prod`).
            path_element.kind = Some(format!("{}-{}", T::kind(), self.env))
        }

        let request = CommitRequest {
            database_id: Some("".to_string()),
            mode: Some(String::from("NON_TRANSACTIONAL")),
            mutations: Some(vec![Mutation {
                insert: None,
                delete: None,
                update: Some(entity),
                base_version: None,
                upsert: None,
                update_time: None,
            }]),
            single_use_transaction: None,
            transaction: None,
        };
        tracing::debug!(?request);
        let (_, response) = self
            .datastore
            .projects()
            .commit(request, &self.project_id)
            .doit()
            .await?;
        tracing::debug!(?response, "received response");

        Ok(())
    }

    pub async fn upsert<T: IntoValue + KeyKind>(&self, value: T) -> anyhow::Result<()> {
        let mut entity = Entity::from_value(value.into_value())?;
        let path_element = entity
            .key
            .as_mut()
            .and_then(|k| k.path.as_mut())
            .and_then(|p| p.first_mut());
        if let Some(path_element) = path_element {
            // We can't create multiple datastore databases in GCP, so we have to suffix
            // type kinds with env (`dev`, `prod`).
            path_element.kind = Some(format!("{}-{}", T::kind(), self.env))
        }

        let request = CommitRequest {
            database_id: Some("".to_string()),
            mode: Some(String::from("NON_TRANSACTIONAL")),
            mutations: Some(vec![Mutation {
                insert: None,
                delete: None,
                update: None,
                base_version: None,
                upsert: Some(entity),
                update_time: None,
            }]),
            single_use_transaction: None,
            transaction: None,
        };

        tracing::debug!(?request);
        let (_, response) = self
            .datastore
            .projects()
            .commit(request, &self.project_id)
            .doit()
            .await?;
        tracing::debug!(?response, "received response");

        Ok(())
    }

    pub async fn fetch_entities<T: KeyKind>(&self) -> anyhow::Result<Vec<EntityResult>> {
        let kind: String = format!("{}-{}", T::kind(), self.env);
        let req = RunQueryRequest {
            database_id: Some("".to_string()),
            partition_id: Default::default(),
            read_options: Default::default(),
            query: Some(Query {
                projection: None,
                kind: Some(vec![KindExpression { name: Some(kind) }]),
                filter: None,
                order: None,
                distinct_on: Some(vec![]),
                start_cursor: None,
                end_cursor: None,
                offset: None,
                limit: None,
            }),
            gql_query: None,
        };

        let (_hyper_resp, query_resp) = self
            .datastore
            .projects()
            .run_query(req, &self.project_id)
            .doit()
            .await?;
        let batch = query_resp
            .batch
            .ok_or_else(|| anyhow::anyhow!("Could not retrieve batch while fetching entities"))?;

        batch.entity_results.ok_or_else(|| {
            anyhow::anyhow!("Could not retrieve entity results while fetching entities")
        })
    }
}

'''
'''--- mpc-recovery/src/gcp/value.rs ---
use google_datastore1::api::{ArrayValue, Entity, Key, LatLng};
use std::collections::HashMap;

use super::error::ConvertError;

#[derive(Debug, Clone)]
pub enum Value {
    BooleanValue(bool),
    IntegerValue(i64),
    DoubleValue(f64),
    KeyValue(Key),
    StringValue(String),
    BlobValue(Vec<u8>),
    GeoPointValue(f64, f64),
    EntityValue {
        key: Key,
        properties: HashMap<String, Value>,
    },
    ArrayValue(Vec<Value>),
}

impl Value {
    pub fn type_name(&self) -> &'static str {
        match self {
            Value::BooleanValue(_) => "bool",
            Value::IntegerValue(_) => "integer",
            Value::DoubleValue(_) => "double",
            Value::KeyValue(_) => "key",
            Value::StringValue(_) => "string",
            Value::BlobValue(_) => "blob",
            Value::GeoPointValue(_, _) => "geopoint",
            Value::EntityValue { .. } => "entity",
            Value::ArrayValue(_) => "array",
        }
    }
}

pub trait IntoValue {
    fn into_value(self) -> Value;
}

pub trait FromValue: Sized {
    fn from_value(value: Value) -> Result<Self, ConvertError>;
}

/*
 * IntoValue implementations
 */

impl IntoValue for Value {
    fn into_value(self) -> Value {
        self
    }
}

impl IntoValue for String {
    fn into_value(self) -> Value {
        Value::StringValue(self)
    }
}

impl IntoValue for &str {
    fn into_value(self) -> Value {
        String::from(self).into_value()
    }
}

impl IntoValue for i8 {
    fn into_value(self) -> Value {
        Value::IntegerValue(self as i64)
    }
}

impl IntoValue for i16 {
    fn into_value(self) -> Value {
        Value::IntegerValue(self as i64)
    }
}

impl IntoValue for i32 {
    fn into_value(self) -> Value {
        Value::IntegerValue(self as i64)
    }
}

impl IntoValue for i64 {
    fn into_value(self) -> Value {
        Value::IntegerValue(self)
    }
}

impl IntoValue for f32 {
    fn into_value(self) -> Value {
        Value::DoubleValue(self as f64)
    }
}

impl IntoValue for f64 {
    fn into_value(self) -> Value {
        Value::DoubleValue(self)
    }
}

impl IntoValue for bool {
    fn into_value(self) -> Value {
        Value::BooleanValue(self)
    }
}

impl IntoValue for Key {
    fn into_value(self) -> Value {
        Value::KeyValue(self)
    }
}

impl IntoValue for Vec<u8> {
    fn into_value(self) -> Value {
        Value::BlobValue(self.to_vec())
    }
}

impl<T> IntoValue for Vec<T>
where
    T: IntoValue,
{
    fn into_value(self) -> Value {
        Value::ArrayValue(self.into_iter().map(IntoValue::into_value).collect())
    }
}

impl From<google_datastore1::api::Value> for Value {
    fn from(value: google_datastore1::api::Value) -> Value {
        if let Some(val) = value.boolean_value {
            Value::BooleanValue(val)
        } else if let Some(val) = value.integer_value {
            Value::IntegerValue(val)
        } else if let Some(val) = value.double_value {
            Value::DoubleValue(val)
        } else if let Some(val) = value.key_value {
            Value::KeyValue(val)
        } else if let Some(val) = value.string_value {
            Value::StringValue(val)
        } else if let Some(val) = value.blob_value {
            Value::BlobValue(val)
        } else if let Some(val) = value.geo_point_value {
            Value::GeoPointValue(
                val.latitude.unwrap_or_default(),
                val.longitude.unwrap_or_default(),
            )
        } else if let Some(val) = value.entity_value {
            Value::EntityValue {
                key: val.key.unwrap_or_default(),
                properties: val
                    .properties
                    .unwrap_or_default()
                    .into_iter()
                    .map(|(k, v)| (k, Value::from(v)))
                    .collect(),
            }
        } else if let Some(val) = value.array_value {
            Value::ArrayValue(
                val.values
                    .unwrap_or_default()
                    .into_iter()
                    .map(Value::from)
                    .collect(),
            )
        } else {
            unimplemented!()
        }
    }
}

impl IntoValue for google_datastore1::api::Value {
    fn into_value(self) -> Value {
        self.into()
    }
}

impl IntoValue for google_datastore1::api::Entity {
    fn into_value(self) -> Value {
        Value::EntityValue {
            key: self.key.unwrap_or_default(),
            properties: self
                .properties
                .unwrap_or_default()
                .into_iter()
                .map(|(k, v)| (k, v.into_value()))
                .collect(),
        }
    }
}

/*
 * FromValue implementations
 */

impl FromValue for Value {
    fn from_value(value: Value) -> Result<Value, ConvertError> {
        Ok(value)
    }
}

impl FromValue for String {
    fn from_value(value: Value) -> Result<String, ConvertError> {
        match value {
            Value::StringValue(value) => Ok(value),
            _ => Err(ConvertError::UnexpectedPropertyType {
                expected: String::from("string"),
                got: String::from(value.type_name()),
            }),
        }
    }
}

impl FromValue for i64 {
    fn from_value(value: Value) -> Result<i64, ConvertError> {
        match value {
            Value::IntegerValue(value) => Ok(value),
            _ => Err(ConvertError::UnexpectedPropertyType {
                expected: String::from("integer"),
                got: String::from(value.type_name()),
            }),
        }
    }
}

impl FromValue for f64 {
    fn from_value(value: Value) -> Result<f64, ConvertError> {
        match value {
            Value::DoubleValue(value) => Ok(value),
            _ => Err(ConvertError::UnexpectedPropertyType {
                expected: String::from("double"),
                got: String::from(value.type_name()),
            }),
        }
    }
}

impl FromValue for bool {
    fn from_value(value: Value) -> Result<bool, ConvertError> {
        match value {
            Value::BooleanValue(value) => Ok(value),
            _ => Err(ConvertError::UnexpectedPropertyType {
                expected: String::from("bool"),
                got: String::from(value.type_name()),
            }),
        }
    }
}

impl FromValue for Key {
    fn from_value(value: Value) -> Result<Key, ConvertError> {
        match value {
            Value::KeyValue(value) => Ok(value),
            _ => Err(ConvertError::UnexpectedPropertyType {
                expected: String::from("key"),
                got: String::from(value.type_name()),
            }),
        }
    }
}

impl FromValue for Vec<u8> {
    fn from_value(value: Value) -> Result<Vec<u8>, ConvertError> {
        match value {
            Value::BlobValue(value) => Ok(value),
            _ => Err(ConvertError::UnexpectedPropertyType {
                expected: String::from("blob"),
                got: String::from(value.type_name()),
            }),
        }
    }
}

impl<T> FromValue for Vec<T>
where
    T: FromValue,
{
    fn from_value(value: Value) -> Result<Vec<T>, ConvertError> {
        match value {
            Value::ArrayValue(values) => {
                let values = values
                    .into_iter()
                    .map(FromValue::from_value)
                    .collect::<Result<Vec<T>, ConvertError>>()?;
                Ok(values)
            }
            _ => Err(ConvertError::UnexpectedPropertyType {
                expected: String::from("array"),
                got: String::from(value.type_name()),
            }),
        }
    }
}

impl FromValue for Entity {
    fn from_value(value: Value) -> Result<Entity, ConvertError> {
        match value {
            Value::EntityValue { key, properties } => {
                let properties = properties
                    .into_iter()
                    .map(|(k, v)| {
                        let v = FromValue::from_value(v)?;
                        Ok((k, v))
                    })
                    .collect::<Result<HashMap<String, google_datastore1::api::Value>, ConvertError>>()?;
                Ok(Entity {
                    key: Some(key),
                    properties: Some(properties),
                })
            }
            _ => Err(ConvertError::UnexpectedPropertyType {
                expected: String::from("entity"),
                got: String::from(value.type_name()),
            }),
        }
    }
}

impl FromValue for google_datastore1::api::Value {
    fn from_value(value: Value) -> Result<Self, ConvertError> {
        let result = match value {
            Value::BooleanValue(val) => google_datastore1::api::Value {
                boolean_value: Some(val),
                ..Default::default()
            },
            Value::IntegerValue(val) => google_datastore1::api::Value {
                integer_value: Some(val),
                ..Default::default()
            },
            Value::DoubleValue(val) => google_datastore1::api::Value {
                double_value: Some(val),
                ..Default::default()
            },
            Value::KeyValue(val) => google_datastore1::api::Value {
                key_value: Some(val),
                ..Default::default()
            },
            Value::StringValue(val) => google_datastore1::api::Value {
                string_value: Some(val),
                ..Default::default()
            },
            Value::BlobValue(val) => google_datastore1::api::Value {
                blob_value: Some(val),
                ..Default::default()
            },
            Value::GeoPointValue(latitude, longitude) => google_datastore1::api::Value {
                geo_point_value: Some(LatLng {
                    latitude: Some(latitude),
                    longitude: Some(longitude),
                }),
                ..Default::default()
            },
            Value::EntityValue { key, properties } => {
                let properties = properties
                    .into_iter()
                    .map(|(k, v)| FromValue::from_value(v).map(|v| (k, v)))
                    .collect::<Result<HashMap<String, google_datastore1::api::Value>, ConvertError>>()?;
                google_datastore1::api::Value {
                    entity_value: Some(Entity {
                        key: Some(key),
                        properties: Some(properties),
                    }),
                    ..Default::default()
                }
            }
            Value::ArrayValue(val) => {
                let values = val
                    .into_iter()
                    .map(FromValue::from_value)
                    .collect::<Result<Vec<google_datastore1::api::Value>, ConvertError>>()?;
                google_datastore1::api::Value {
                    array_value: Some(ArrayValue {
                        values: Some(values),
                    }),
                    ..Default::default()
                }
            }
        };
        Ok(result)
    }
}

'''
'''--- mpc-recovery/src/key_recovery.rs ---
use crate::{
    error::LeaderNodeError,
    msg::PublicKeyNodeRequest,
    sign_node::oidc::OidcToken,
    transaction::{call_all_nodes, to_dalek_public_key},
};
use ed25519_dalek::Signature;
use multi_party_eddsa::protocols::aggsig::KeyAgg;
use near_crypto::{ED25519PublicKey, PublicKey};

pub async fn get_user_recovery_pk(
    client: &reqwest::Client,
    sign_nodes: &[String],
    oidc_token: &OidcToken,
    frp_signature: &Signature,
    frp_public_key: &PublicKey,
) -> Result<PublicKey, LeaderNodeError> {
    let request = PublicKeyNodeRequest {
        oidc_token: oidc_token.clone(),
        frp_signature: *frp_signature,
        frp_public_key: frp_public_key.clone(),
    };
    let res = call_all_nodes(client, sign_nodes, "public_key", request).await?;

    let pk = KeyAgg::key_aggregation_n(&res, 0).apk;
    to_dalek_public_key(&pk)
        .map(|k| PublicKey::ED25519(ED25519PublicKey(*k.as_bytes())))
        .map_err(LeaderNodeError::AggregateSigningFailed)
}

'''
'''--- mpc-recovery/src/leader_node/mod.rs ---
use crate::error::{LeaderNodeError, MpcError};
use crate::firewall::allowed::PartnerList;
use crate::key_recovery::get_user_recovery_pk;
use crate::msg::{
    AcceptNodePublicKeysRequest, ClaimOidcNodeRequest, ClaimOidcRequest, ClaimOidcResponse,
    MpcPkRequest, MpcPkResponse, NewAccountRequest, NewAccountResponse, SignNodeRequest,
    SignRequest, SignResponse, UserCredentialsRequest, UserCredentialsResponse,
};
use crate::oauth::verify_oidc_token;
use crate::relayer::msg::CreateAccountAtomicRequest;
use crate::relayer::NearRpcAndRelayerClient;
use crate::transaction::{
    get_mpc_signature, new_create_account_delegate_action, sign_payload_with_mpc,
    to_dalek_combined_public_key,
};
use crate::utils::{check_digest_signature, user_credentials_request_digest};
use crate::{metrics, nar};
use anyhow::Context;
use axum::extract::MatchedPath;
use axum::middleware::{self, Next};
use axum::response::IntoResponse;
use axum::routing::get;
use axum::{
    http::{Request, StatusCode},
    routing::post,
    Extension, Json, Router,
};
use axum_extra::extract::WithRejection;
use axum_tracing_opentelemetry::middleware::{OtelAxumLayer, OtelInResponseLayer};
use borsh::BorshDeserialize;
use curv::elliptic::curves::{Ed25519, Point};
use near_fetch::signer::KeyRotatingSigner;
use near_primitives::delegate_action::{DelegateAction, NonDelegateAction};
use near_primitives::transaction::{Action, DeleteAccountAction, DeleteKeyAction};
use near_primitives::types::AccountId;
use prometheus::{Encoder, TextEncoder};
use std::net::SocketAddr;
use std::sync::Arc;
use std::time::Instant;

pub struct Config {
    pub env: String,
    pub port: u16,
    pub sign_nodes: Vec<String>,
    pub near_rpc: String,
    pub near_root_account: String,
    // TODO: temporary solution
    pub account_creator_signer: KeyRotatingSigner,
    pub partners: PartnerList,
    pub jwt_signature_pk_url: String,
}

pub async fn run(config: Config) {
    let Config {
        env,
        port,
        sign_nodes,
        near_rpc,
        near_root_account,
        account_creator_signer,
        partners,
        jwt_signature_pk_url,
    } = config;
    let _span = tracing::debug_span!("run", env, port);
    tracing::debug!(?sign_nodes, "running a leader node");

    let client = NearRpcAndRelayerClient::connect(&near_rpc);

    let state = Arc::new(LeaderState {
        env,
        sign_nodes,
        client,
        reqwest_client: reqwest::Client::new(),
        near_root_account: near_root_account.parse().unwrap(),
        account_creator_signer,
        partners,
        jwt_signature_pk_url,
    });

    // Get keys from all sign nodes, and broadcast them out as a set.
    let pk_set = match gather_sign_node_pk_shares(&state).await {
        Ok(pk_set) => pk_set,
        Err(err) => {
            tracing::error!("Unable to gather public keys: {err}");
            return;
        }
    };
    tracing::debug!(?pk_set, "Gathered public keys");
    let messages = match broadcast_pk_set(&state, pk_set).await {
        Ok(messages) => messages,
        Err(err) => {
            tracing::error!("Unable to broadcast public keys: {err}");
            Vec::new()
        }
    };
    tracing::debug!(?messages, "broadcasted public key statuses");

    // Cors layer is move to load balancer
    let cors_layer = tower_http::cors::CorsLayer::permissive();

    let app = Router::new()
        // healthcheck endpoint
        .route(
            "/",
            get(|| async move {
                tracing::info!("node is ready to accept connections");
                StatusCode::OK
            }),
        )
        .route("/mpc_public_key", post(mpc_public_key))
        .route("/claim_oidc", post(claim_oidc))
        .route("/user_credentials", post(user_credentials))
        .route("/new_account", post(new_account))
        .route("/sign", post(sign))
        .route("/metrics", get(metrics))
        .route_layer(middleware::from_fn(track_metrics))
        .layer(Extension(state))
        .layer(cors_layer)
        // Include trace context as header into the response
        .layer(OtelInResponseLayer)
        // Start OpenTelemetry trace on incoming request
        .layer(OtelAxumLayer::default());

    let addr = SocketAddr::from(([0, 0, 0, 0], port));
    tracing::debug!(?addr, "starting http server");
    axum::Server::bind(&addr)
        .serve(app.into_make_service())
        .await
        .unwrap();
}

async fn track_metrics<B>(req: Request<B>, next: Next<B>) -> impl IntoResponse {
    let timer = Instant::now();
    let path = if let Some(matched_path) = req.extensions().get::<MatchedPath>() {
        matched_path.as_str().to_owned()
    } else {
        req.uri().path().to_owned()
    };
    let method = req.method().clone();

    let response = next.run(req).await;
    let processing_time = timer.elapsed().as_secs_f64();

    metrics::HTTP_REQUEST_COUNT
        .with_label_values(&[method.as_str(), &path])
        .inc();
    metrics::HTTP_PROCESSING_TIME
        .with_label_values(&[method.as_str(), &path])
        .observe(processing_time);

    if response.status().is_client_error() {
        metrics::HTTP_CLIENT_ERROR_COUNT
            .with_label_values(&[method.as_str(), &path])
            .inc();
    }
    if response.status().is_server_error() {
        metrics::HTTP_SERVER_ERROR_COUNT
            .with_label_values(&[method.as_str(), &path])
            .inc();
    }

    response
}

async fn metrics() -> (StatusCode, String) {
    let grab_metrics = || {
        let encoder = TextEncoder::new();
        let mut buffer = vec![];
        encoder
            .encode(&prometheus::gather(), &mut buffer)
            .with_context(|| "failed to encode metrics")?;

        let response = String::from_utf8(buffer.clone())
            .with_context(|| "failed to convert bytes to string")?;
        buffer.clear();

        Ok::<String, anyhow::Error>(response)
    };

    match grab_metrics() {
        Ok(response) => (StatusCode::OK, response),
        Err(err) => {
            tracing::error!("failed to generate prometheus metrics: {err}");
            (
                StatusCode::INTERNAL_SERVER_ERROR,
                "failed to generate prometheus metrics".to_string(),
            )
        }
    }
}

struct LeaderState {
    env: String,
    sign_nodes: Vec<String>,
    client: NearRpcAndRelayerClient,
    reqwest_client: reqwest::Client,
    near_root_account: AccountId,
    // TODO: temporary solution
    account_creator_signer: KeyRotatingSigner,
    partners: PartnerList,
    jwt_signature_pk_url: String,
}

async fn mpc_public_key(
    Extension(state): Extension<Arc<LeaderState>>,
    WithRejection(Json(_), _): WithRejection<Json<MpcPkRequest>, MpcError>,
) -> (StatusCode, Json<MpcPkResponse>) {
    // Getting MPC PK from sign nodes
    let pk_set = match gather_sign_node_pk_shares(&state).await {
        Ok(pk_set) => pk_set,
        Err(err) => {
            return (
                err.code(),
                Json(MpcPkResponse::Err {
                    msg: err.to_string(),
                }),
            )
        }
    };

    let mpc_pk = match to_dalek_combined_public_key(&pk_set) {
        Ok(mpc_pk) => mpc_pk,
        Err(err) => {
            return (
                err.code(),
                Json(MpcPkResponse::Err {
                    msg: err.to_string(),
                }),
            )
        }
    };

    (StatusCode::OK, Json(MpcPkResponse::Ok { mpc_pk }))
}

#[tracing::instrument(level = "info", skip_all, fields(env = state.env))]
async fn claim_oidc(
    Extension(state): Extension<Arc<LeaderState>>,
    WithRejection(Json(claim_oidc_request), _): WithRejection<Json<ClaimOidcRequest>, MpcError>,
) -> (StatusCode, Json<ClaimOidcResponse>) {
    tracing::info!(
        oidc_hash = hex::encode(&claim_oidc_request.oidc_token_hash),
        pk = claim_oidc_request.frp_public_key.to_string(),
        sig = claim_oidc_request.frp_signature.to_string(),
        "claim_oidc request"
    );

    // Calim OIDC ID Token and get MPC signature from sign nodes
    let sig_share_request = SignNodeRequest::ClaimOidc(ClaimOidcNodeRequest {
        oidc_token_hash: claim_oidc_request.oidc_token_hash,
        public_key: claim_oidc_request.frp_public_key,
        signature: claim_oidc_request.frp_signature,
    });

    let res =
        sign_payload_with_mpc(&state.reqwest_client, &state.sign_nodes, sig_share_request).await;

    match res {
        Ok(mpc_signature) => (
            StatusCode::OK,
            Json(ClaimOidcResponse::Ok { mpc_signature }),
        ),
        Err(e) => (
            StatusCode::BAD_REQUEST,
            Json(ClaimOidcResponse::Err { msg: e.to_string() }),
        ),
    }
}

#[tracing::instrument(level = "info", skip_all, fields(env = state.env))]
async fn user_credentials(
    Extension(state): Extension<Arc<LeaderState>>,
    WithRejection(Json(request), _): WithRejection<Json<UserCredentialsRequest>, MpcError>,
) -> (StatusCode, Json<UserCredentialsResponse>) {
    tracing::info!(
        oidc_token = format!("{:.5}...", request.oidc_token),
        "user_credentials request"
    );

    match process_user_credentials(state, request).await {
        Ok(response) => {
            tracing::debug!("responding with OK");
            (StatusCode::OK, Json(response))
        }
        Err(err) => {
            tracing::error!(err = ?err, "failed to process user credentials");
            (
                err.code(),
                Json(UserCredentialsResponse::Err {
                    msg: err.to_string(),
                }),
            )
        }
    }
}

async fn process_user_credentials(
    state: Arc<LeaderState>,
    request: UserCredentialsRequest,
) -> Result<UserCredentialsResponse, LeaderNodeError> {
    verify_oidc_token(
        &request.oidc_token,
        Some(&state.partners.oidc_providers()),
        &state.reqwest_client,
        &state.jwt_signature_pk_url,
    )
    .await
    .map_err(LeaderNodeError::OidcVerificationFailed)?;

    nar::retry(|| async {
        let mpc_user_recovery_pk = get_user_recovery_pk(
            &state.reqwest_client,
            &state.sign_nodes,
            &request.oidc_token,
            &request.frp_signature,
            &request.frp_public_key,
        )
        .await?;

        Ok(UserCredentialsResponse::Ok {
            recovery_pk: mpc_user_recovery_pk,
        })
    })
    .await
}

async fn process_new_account(
    state: Arc<LeaderState>,
    request: NewAccountRequest,
) -> Result<NewAccountResponse, LeaderNodeError> {
    // Create a transaction to create new NEAR account
    let new_user_account_id = request.near_account_id;
    let oidc_token_claims = verify_oidc_token(
        &request.oidc_token,
        Some(&state.partners.oidc_providers()),
        &state.reqwest_client,
        &state.jwt_signature_pk_url,
    )
    .await
    .map_err(LeaderNodeError::OidcVerificationFailed)?;
    let internal_acc_id = oidc_token_claims.get_internal_account_id();

    // FIXME: waiting on https://github.com/near/mpc-recovery/issues/193
    // FRP check to prevent invalid PKs and Sigs from getting through. Used to circumvent the
    // atomicity of account creation between relayer and the sign nodes. The atomicity
    // part is being worked on.
    let frp_pk = &request.frp_public_key;
    let digest = user_credentials_request_digest(&request.oidc_token, frp_pk)?;
    check_digest_signature(frp_pk, &request.user_credentials_frp_signature, &digest)
        .map_err(LeaderNodeError::SignatureVerificationFailed)?;
    tracing::debug!("user credentials digest signature verified for {new_user_account_id:?}");

    // TODO: move error message from here to this place
    let partner = state
        .partners
        .find(&oidc_token_claims.iss, &oidc_token_claims.aud)?;

    let mpc_user_recovery_pk = nar::retry(|| async {
        get_user_recovery_pk(
            &state.reqwest_client,
            &state.sign_nodes,
            &request.oidc_token,
            &request.user_credentials_frp_signature,
            &request.frp_public_key,
        )
        .await
    })
    .await?;

    nar::retry(|| async {
        let account_creator = state.account_creator_signer.fetch_and_rotate_signer();

        // Get nonce and recent block hash
        let (_hash, block_height, nonce) = state
            .client
            .access_key(&account_creator.account_id, &account_creator.public_key)
            .await
            .map_err(LeaderNodeError::RelayerError)?;

        // Add recovery key to create account options
        let mut new_account_options = request.create_account_options.clone();
        match new_account_options.full_access_keys {
            Some(ref mut keys) => keys.push(mpc_user_recovery_pk.clone()),
            None => new_account_options.full_access_keys = Some(vec![mpc_user_recovery_pk.clone()]),
        }

        // We create accounts using the local key
        let signed_delegate_action = new_create_account_delegate_action(
            account_creator,
            &new_user_account_id,
            &new_account_options,
            &state.near_root_account,
            nonce,
            block_height + 100,
        )
        .map_err(LeaderNodeError::Other)?;

        // Send delegate action to relayer
        let request = CreateAccountAtomicRequest {
            account_id: new_user_account_id.clone(),
            allowance: 300_000_000_000_000,
            oauth_token: internal_acc_id.clone(),
            signed_delegate_action,
        };

        let result = state
            .client
            .create_account_atomic(request, &partner.relayer)
            .await;

        match result {
            Ok(_) => {
                tracing::info!(
                    "account creation succeeded: {new_user_account_id:?}",
                    new_user_account_id = new_user_account_id
                );
                Ok(NewAccountResponse::Ok {
                    create_account_options: new_account_options,
                    user_recovery_public_key: mpc_user_recovery_pk.clone(),
                    near_account_id: new_user_account_id.clone(),
                })
            }
            Err(err) => {
                tracing::error!("account creation failed: {err}");
                let err_str = format!("{:?}", err);
                state
                    .client
                    .invalidate_cache_if_acc_creation_failed(
                        &(
                            account_creator.account_id.clone(),
                            account_creator.public_key.clone(),
                        ),
                        &err_str,
                    )
                    .await;
                Err(LeaderNodeError::RelayerError(err))
            }
        }
    })
    .await
}

#[tracing::instrument(level = "info", skip_all, fields(env = state.env))]
async fn new_account(
    Extension(state): Extension<Arc<LeaderState>>,
    WithRejection(Json(request), _): WithRejection<Json<NewAccountRequest>, MpcError>,
) -> (StatusCode, Json<NewAccountResponse>) {
    tracing::info!(
        near_account_id = request.near_account_id.to_string(),
        create_account_options = request.create_account_options.to_string(),
        oidc_token = format!("{:.5}...", request.oidc_token),
        "new_account request"
    );

    match process_new_account(state, request).await {
        Ok(response) => {
            tracing::debug!("responding with OK");
            (StatusCode::OK, Json(response))
        }
        Err(err) => {
            tracing::error!(err = ?err);
            (err.code(), Json(NewAccountResponse::err(err.to_string())))
        }
    }
}

async fn process_sign(
    state: Arc<LeaderState>,
    request: SignRequest,
) -> Result<SignResponse, LeaderNodeError> {
    // Deserialize the included delegate action via borsh
    let delegate_action = DelegateAction::try_from_slice(&request.delegate_action)
        .map_err(LeaderNodeError::MalformedDelegateAction)?;

    // Check OIDC token
    verify_oidc_token(
        &request.oidc_token,
        Some(&state.partners.oidc_providers()),
        &state.reqwest_client,
        &state.jwt_signature_pk_url,
    )
    .await
    .map_err(LeaderNodeError::OidcVerificationFailed)?;

    // Prevent recovery key delition
    let requested_delegate_actions: &Vec<NonDelegateAction> = &delegate_action.actions;

    let requested_actions: &Vec<Action> = &requested_delegate_actions
        .iter()
        .map(|non_delegate_action| Action::from(non_delegate_action.clone()))
        .collect();

    let delete_key_actions: Vec<&DeleteKeyAction> = requested_actions
        .iter()
        .filter_map(|action| match action {
            Action::DeleteKey(delete_key_action) => Some(delete_key_action),
            _ => None,
        })
        .collect();

    let user_recovery_pk_res = nar::retry::<_, anyhow::Error, _, _>(|| async {
        let mpc_user_recovery_pk = get_user_recovery_pk(
            &state.reqwest_client,
            &state.sign_nodes,
            &request.oidc_token,
            &request.user_credentials_frp_signature,
            &request.frp_public_key,
        )
        .await?;

        Ok(mpc_user_recovery_pk)
    })
    .await;

    let user_recovery_pk = user_recovery_pk_res.map_err(|err| {
        tracing::error!("Failed to retrieve recovery pk: {err}");
        LeaderNodeError::FailedToRetrieveRecoveryPk(err)
    })?;

    for delete_key_action in delete_key_actions {
        if delete_key_action.public_key == user_recovery_pk {
            tracing::error!(
                "Recovery key can not be deleted: {:?}",
                delete_key_action.public_key
            );
            Err(LeaderNodeError::RecoveryKeyCanNotBeDeleted(
                delete_key_action.public_key.clone(),
            ))?;
        }
    }

    // Prevent account deletion
    // Note: we can allow account deletionn once we sync that with relayer. With current logic user will not be able to create another account.
    let delete_account_actions: Vec<&DeleteAccountAction> = requested_actions
        .iter()
        .filter_map(|action| match action {
            Action::DeleteAccount(delete_account_action) => Some(delete_account_action),
            _ => None,
        })
        .collect();

    if !delete_account_actions.is_empty() {
        tracing::error!("Account deletion is not allowed");
        Err(LeaderNodeError::AccountDeletionUnsupported)?;
    }

    // Get MPC signature
    nar::retry(|| async {
        let signature = get_mpc_signature(
            &state.reqwest_client,
            &state.sign_nodes,
            &request.oidc_token,
            delegate_action.clone(),
            &request.frp_signature,
            &request.frp_public_key,
        )
        .await?;

        Ok(SignResponse::Ok { signature })
    })
    .await
}

#[tracing::instrument(level = "info", skip_all, fields(env = state.env))]
async fn sign(
    Extension(state): Extension<Arc<LeaderState>>,
    WithRejection(Json(request), _): WithRejection<Json<SignRequest>, MpcError>,
) -> (StatusCode, Json<SignResponse>) {
    tracing::info!(
        oidc_token = format!("{:.5}...", request.oidc_token),
        "sign request"
    );

    match process_sign(state, request).await {
        Ok(response) => {
            tracing::debug!("responding with OK");
            (StatusCode::OK, Json(response))
        }
        Err(e) => {
            tracing::error!(err = ?e);
            (e.code(), Json(SignResponse::err(e.to_string())))
        }
    }
}

async fn gather_sign_node_pk_shares(
    state: &LeaderState,
) -> Result<Vec<Point<Ed25519>>, LeaderNodeError> {
    let fut = nar::retry_every(std::time::Duration::from_secs(1), || async {
        let mut results: Vec<(usize, Point<Ed25519>)> = crate::transaction::call_all_nodes(
            &state.reqwest_client,
            &state.sign_nodes,
            "public_key_node",
            (),
        )
        .await
        .map_err(|err| {
            tracing::debug!("failed to gather pk: {err:?}");
            err
        })?;

        results.sort_by_key(|(index, _)| *index);
        let results: Vec<Point<Ed25519>> =
            results.into_iter().map(|(_index, point)| point).collect();

        Result::<Vec<Point<Ed25519>>, LeaderNodeError>::Ok(results)
    });

    let results = tokio::time::timeout(std::time::Duration::from_secs(60), fut)
        .await
        .map_err(|_| LeaderNodeError::TimeoutGatheringPublicKeys)??;
    Ok(results)
}

async fn broadcast_pk_set(
    state: &LeaderState,
    pk_set: Vec<Point<Ed25519>>,
) -> anyhow::Result<Vec<String>> {
    let request = AcceptNodePublicKeysRequest {
        public_keys: pk_set,
    };

    let messages: Vec<String> = crate::transaction::call_all_nodes(
        &state.reqwest_client,
        &state.sign_nodes,
        "accept_pk_set",
        request,
    )
    .await?;

    Ok(messages)
}

'''
'''--- mpc-recovery/src/lib.rs ---
// TODO: FIXME: Remove this once we have a better way to handle these large errors
#![allow(clippy::result_large_err)]

use std::path::PathBuf;

use aes_gcm::aead::consts::U32;
use aes_gcm::aead::generic_array::GenericArray;
use aes_gcm::aead::OsRng;
use aes_gcm::{Aes256Gcm, KeyInit};
use clap::Parser;
use curv::elliptic::curves::Ed25519;
use curv::elliptic::curves::Point;
use multi_party_eddsa::protocols::ExpandedKeyPair;
use serde::de::DeserializeOwned;
use tracing_subscriber::EnvFilter;

use near_crypto::{InMemorySigner, SecretKey};
use near_fetch::signer::KeyRotatingSigner;
use near_primitives::types::AccountId;

use crate::firewall::allowed::PartnerList;
use crate::gcp::GcpService;
use crate::sign_node::migration;

pub mod error;
pub mod firewall;
pub mod gcp;
pub mod key_recovery;
pub mod leader_node;
pub mod logging;
pub mod metrics;
pub mod msg;
pub mod nar;
pub mod oauth;
pub mod primitives;
pub mod relayer;
pub mod sign_node;
pub mod transaction;
pub mod utils;

type NodeId = u64;

pub use leader_node::run as run_leader_node;
pub use leader_node::Config as LeaderConfig;
pub use sign_node::run as run_sign_node;
pub use sign_node::Config as SignerConfig;

pub struct GenerateResult {
    pub pk_set: Vec<Point<Ed25519>>,
    pub secrets: Vec<(ExpandedKeyPair, GenericArray<u8, U32>)>,
}

#[tracing::instrument(level = "debug", skip_all, fields(n = n))]
pub fn generate(n: usize) -> GenerateResult {
    // Let's tie this up to a deterministic RNG when we can
    let sk_set: Vec<_> = (1..=n).map(|_| ExpandedKeyPair::create()).collect();
    let cipher_keys: Vec<_> = (1..=n)
        .map(|_| Aes256Gcm::generate_key(&mut OsRng))
        .collect();
    let pk_set: Vec<_> = sk_set.iter().map(|sk| sk.public_key.clone()).collect();

    GenerateResult {
        pk_set,
        secrets: sk_set.into_iter().zip(cipher_keys.into_iter()).collect(),
    }
}

#[derive(Parser, Debug)]
pub enum Cli {
    Generate {
        n: usize,
    },
    StartLeader {
        /// Environment to run in (`dev` or `prod`)
        #[arg(long, env("MPC_RECOVERY_ENV"), default_value("dev"))]
        env: String,
        /// The web port for this server
        #[arg(long, env("MPC_RECOVERY_WEB_PORT"))]
        web_port: u16,
        /// The compute nodes to connect to
        #[arg(long, value_parser, num_args = 1.., value_delimiter = ',', env("MPC_RECOVERY_SIGN_NODES"))]
        sign_nodes: Vec<String>,
        /// NEAR RPC address
        #[arg(
            long,
            env("MPC_RECOVERY_NEAR_RPC"),
            default_value("https://rpc.testnet.near.org")
        )]
        near_rpc: String,
        /// NEAR root account that has linkdrop contract deployed on it
        #[arg(long, env("MPC_RECOVERY_NEAR_ROOT_ACCOUNT"), default_value("testnet"))]
        near_root_account: String,
        /// Account creator ID
        #[arg(long, env("MPC_RECOVERY_ACCOUNT_CREATOR_ID"))]
        account_creator_id: AccountId,
        /// Account creator's secret key(s)
        #[arg(
            long,
            value_parser = parse_json_str::<Vec<SecretKey>>,
            env("MPC_RECOVERY_ACCOUNT_CREATOR_SK"),
            default_value("[]")
        )]
        account_creator_sk: ::std::vec::Vec<SecretKey>,
        /// JSON list of related items to be used to verify OIDC tokens.
        #[arg(long, env("FAST_AUTH_PARTNERS"))]
        fast_auth_partners: Option<String>,
        /// Filepath to a JSON list of related items to be used to verify OIDC tokens.
        #[arg(long, value_parser, env("FAST_AUTH_PARTNERS_FILEPATH"))]
        fast_auth_partners_filepath: Option<PathBuf>,
        /// GCP project ID
        #[arg(long, env("MPC_RECOVERY_GCP_PROJECT_ID"))]
        gcp_project_id: String,
        /// GCP datastore URL
        #[arg(long, env("MPC_RECOVERY_GCP_DATASTORE_URL"))]
        gcp_datastore_url: Option<String>,
        /// URL to the public key used to sign JWT tokens
        #[arg(long, env("MPC_RECOVERY_JWT_SIGNATURE_PK_URL"))]
        jwt_signature_pk_url: String,
        /// Enables export of span data using opentelemetry protocol.
        #[clap(flatten)]
        logging_options: logging::Options,
    },
    StartSign {
        /// Environment to run in (`dev` or `prod`)
        #[arg(long, env("MPC_RECOVERY_ENV"), default_value("dev"))]
        env: String,
        /// Node ID
        #[arg(long, env("MPC_RECOVERY_NODE_ID"))]
        node_id: u64,
        /// Cipher key to encrypt stored user credentials, will be pulled from GCP Secret Manager if omitted
        #[arg(long, env("MPC_RECOVERY_CIPHER_KEY"))]
        cipher_key: Option<String>,
        /// Secret key share, will be pulled from GCP Secret Manager if omitted
        #[arg(long, env("MPC_RECOVERY_SK_SHARE"))]
        sk_share: Option<String>,
        /// The web port for this server
        #[arg(long, env("MPC_RECOVERY_WEB_PORT"))]
        web_port: u16,
        /// GCP project ID
        #[arg(long, env("MPC_RECOVERY_GCP_PROJECT_ID"))]
        gcp_project_id: String,
        /// GCP datastore URL
        #[arg(long, env("MPC_RECOVERY_GCP_DATASTORE_URL"))]
        gcp_datastore_url: Option<String>,
        /// URL to the public key used to sign JWT tokens
        #[arg(long, env("MPC_RECOVERY_JWT_SIGNATURE_PK_URL"))]
        jwt_signature_pk_url: String,
        /// Enables export of span data using opentelemetry protocol.
        #[clap(flatten)]
        logging_options: logging::Options,
    },
    RotateSignNodeCipher {
        /// Environment to run in (`dev` or `prod`)
        #[arg(long, env("MPC_RECOVERY_ENV"), default_value("dev"))]
        env: String,
        /// If no `new_env` is specified, the rotation will be done inplace in the current `env`.
        #[arg(long, env("MPC_RECOVERY_ROTATE_INPLACE"))]
        new_env: Option<String>,
        /// Node ID
        #[arg(long, env("MPC_RECOVERY_NODE_ID"))]
        node_id: u64,
        /// Old cipher key, will be pulled from GCP Secret Manager if omitted
        #[arg(long, env("MPC_RECOVERY_OLD_CIPHER_KEY"))]
        old_cipher_key: Option<String>,
        /// The new cipher key to replace each encrypted record with.
        #[arg(long, env("MPC_RECOVERY_NEW_CIPHER_KEY"))]
        new_cipher_key: Option<String>,
        /// GCP project ID
        #[arg(long, env("MPC_RECOVERY_GCP_PROJECT_ID"))]
        gcp_project_id: String,
        /// GCP datastore URL
        #[arg(long, env("MPC_RECOVERY_GCP_DATASTORE_URL"))]
        gcp_datastore_url: Option<String>,
        /// Enables export of span data using opentelemetry protocol.
        #[clap(flatten)]
        logging_options: logging::Options,
    },
}

pub async fn run(cmd: Cli) -> anyhow::Result<()> {
    match cmd {
        Cli::Generate { n } => {
            let GenerateResult { pk_set, secrets } = generate(n);
            println!("Public key set: {}", serde_json::to_string(&pk_set)?);
            for (i, (sk_share, cipher_key)) in secrets.iter().enumerate() {
                println!(
                    "Secret key share {}: {}",
                    i,
                    serde_json::to_string(sk_share)?
                );
                println!("Cipher {}: {}", i, hex::encode(cipher_key));
            }
        }
        Cli::StartLeader {
            env,
            web_port,
            sign_nodes,
            near_rpc,
            near_root_account,
            account_creator_id,
            account_creator_sk,
            fast_auth_partners: partners,
            fast_auth_partners_filepath: partners_filepath,
            gcp_project_id,
            gcp_datastore_url,
            jwt_signature_pk_url,
            logging_options,
        } => {
            let _subscriber_guard = logging::subscribe_global(
                EnvFilter::from_default_env(),
                &logging_options,
                env.clone(),
                "leader".to_string(),
            )
            .await;
            let gcp_service =
                GcpService::new(env.clone(), gcp_project_id, gcp_datastore_url).await?;
            let account_creator_signer =
                load_account_creator(&gcp_service, &env, &account_creator_id, account_creator_sk)
                    .await?;
            let partners = PartnerList {
                entries: load_entries(&gcp_service, &env, "leader", partners, partners_filepath)
                    .await?,
            };

            let config = LeaderConfig {
                env,
                port: web_port,
                sign_nodes,
                near_rpc,
                near_root_account,
                account_creator_signer,
                partners,
                jwt_signature_pk_url,
            };

            run_leader_node(config).await;
        }
        Cli::StartSign {
            env,
            node_id,
            sk_share,
            cipher_key,
            web_port,
            gcp_project_id,
            gcp_datastore_url,
            jwt_signature_pk_url,
            logging_options,
        } => {
            let _subscriber_guard = logging::subscribe_global(
                EnvFilter::from_default_env(),
                &logging_options,
                env.clone(),
                node_id.to_string(),
            )
            .await;
            let gcp_service =
                GcpService::new(env.clone(), gcp_project_id, gcp_datastore_url).await?;
            let cipher_key = load_cipher_key(&gcp_service, &env, node_id, cipher_key).await?;
            let cipher_key = hex::decode(cipher_key)?;
            let cipher_key = GenericArray::<u8, U32>::clone_from_slice(&cipher_key);
            let cipher = Aes256Gcm::new(&cipher_key);

            let sk_share = load_sh_skare(&gcp_service, &env, node_id, sk_share).await?;

            // TODO Import just the private key and derive the rest
            let sk_share: ExpandedKeyPair = serde_json::from_str(&sk_share).unwrap();

            let config = SignerConfig {
                gcp_service,
                our_index: node_id,
                node_key: sk_share,
                cipher,
                port: web_port,
                jwt_signature_pk_url,
            };
            run_sign_node(config).await;
        }
        Cli::RotateSignNodeCipher {
            env,
            new_env,
            node_id,
            old_cipher_key,
            new_cipher_key,
            gcp_project_id,
            gcp_datastore_url,
            logging_options,
        } => {
            let _subscriber_guard = logging::subscribe_global(
                EnvFilter::from_default_env(),
                &logging_options,
                env.clone(),
                node_id.to_string(),
            )
            .await;
            let gcp_service = GcpService::new(
                env.clone(),
                gcp_project_id.clone(),
                gcp_datastore_url.clone(),
            )
            .await?;

            let dest_gcp_service = if let Some(new_env) = new_env {
                GcpService::new(new_env, gcp_project_id, gcp_datastore_url).await?
            } else {
                gcp_service.clone()
            };

            let old_cipher_key =
                load_cipher_key(&gcp_service, &env, node_id, old_cipher_key).await?;
            let old_cipher_key = hex::decode(old_cipher_key)?;
            let old_cipher_key = GenericArray::<u8, U32>::clone_from_slice(&old_cipher_key);
            let old_cipher = Aes256Gcm::new(&old_cipher_key);

            let new_cipher_key =
                load_cipher_key(&gcp_service, &env, node_id, new_cipher_key).await?;
            let new_cipher_key = hex::decode(new_cipher_key)?;
            let new_cipher_key = GenericArray::<u8, U32>::clone_from_slice(&new_cipher_key);
            let new_cipher = Aes256Gcm::new(&new_cipher_key);

            migration::rotate_cipher(
                node_id as usize,
                &old_cipher,
                &new_cipher,
                &gcp_service,
                &dest_gcp_service,
            )
            .await?;
        }
    }

    Ok(())
}

async fn load_sh_skare(
    gcp_service: &GcpService,
    env: &str,
    node_id: u64,
    sk_share_arg: Option<String>,
) -> anyhow::Result<String> {
    match sk_share_arg {
        Some(sk_share) => Ok(sk_share),
        None => {
            let name = format!("mpc-recovery-secret-share-{node_id}-{env}/versions/latest");
            Ok(std::str::from_utf8(&gcp_service.load_secret(name).await?)?.to_string())
        }
    }
}

async fn load_cipher_key(
    gcp_service: &GcpService,
    env: &str,
    node_id: u64,
    cipher_key_arg: Option<String>,
) -> anyhow::Result<String> {
    match cipher_key_arg {
        Some(cipher_key) => Ok(cipher_key),
        None => {
            let name = format!("mpc-recovery-encryption-cipher-{node_id}-{env}/versions/latest");
            Ok(std::str::from_utf8(&gcp_service.load_secret(name).await?)?.to_string())
        }
    }
}

async fn load_account_creator(
    gcp_service: &GcpService,
    env: &str,
    account_creator_id: &AccountId,
    account_creator_sk: Vec<SecretKey>,
) -> anyhow::Result<KeyRotatingSigner> {
    let sks = if account_creator_sk.is_empty() {
        let name = format!("mpc-recovery-account-creator-sk-{env}/versions/latest");
        let data = gcp_service.load_secret(name).await?;
        serde_json::from_str(std::str::from_utf8(&data)?)?
    } else {
        account_creator_sk
    };

    Ok(KeyRotatingSigner::from_signers(sks.into_iter().map(|sk| {
        InMemorySigner::from_secret_key(account_creator_id.clone(), sk)
    })))
}

async fn load_entries<T>(
    gcp_service: &GcpService,
    env: &str,
    node_id: &str,
    data: Option<String>,
    path: Option<PathBuf>,
) -> anyhow::Result<T>
where
    T: DeserializeOwned,
{
    let entries = match (data, path) {
        (Some(data), None) => serde_json::from_str(&data)?,
        (None, Some(path)) => {
            let file = std::fs::File::open(path)?;
            let reader = std::io::BufReader::new(file);
            serde_json::from_reader(reader)?
        }
        (None, None) => {
            let name =
                format!("mpc-recovery-allowed-oidc-providers-{node_id}-{env}/versions/latest");
            let data = gcp_service.load_secret(name).await?;
            serde_json::from_str(std::str::from_utf8(&data)?)?
        }
        _ => return Err(anyhow::anyhow!("Invalid combination of data and path")),
    };

    Ok(entries)
}

impl Cli {
    pub fn into_str_args(self) -> Vec<String> {
        match self {
            Cli::Generate { n } => {
                vec!["generate".to_string(), n.to_string()]
            }
            Cli::StartLeader {
                env,
                web_port,
                sign_nodes,
                near_rpc,
                near_root_account,
                account_creator_id,
                account_creator_sk,
                fast_auth_partners,
                fast_auth_partners_filepath,
                gcp_project_id,
                gcp_datastore_url,
                jwt_signature_pk_url,
                logging_options,
            } => {
                let mut buf = vec![
                    "start-leader".to_string(),
                    "--env".to_string(),
                    env.to_string(),
                    "--web-port".to_string(),
                    web_port.to_string(),
                    "--near-rpc".to_string(),
                    near_rpc,
                    "--near-root-account".to_string(),
                    near_root_account,
                    "--account-creator-id".to_string(),
                    account_creator_id.to_string(),
                    "--gcp-project-id".to_string(),
                    gcp_project_id,
                    "--jwt-signature-pk-url".to_string(),
                    jwt_signature_pk_url,
                ];

                if let Some(partners) = fast_auth_partners {
                    buf.push("--fast-auth-partners".to_string());
                    buf.push(partners);
                }
                if let Some(partners_filepath) = fast_auth_partners_filepath {
                    buf.push("--fast-auth-partners-filepath".to_string());
                    buf.push(partners_filepath.to_str().unwrap().to_string());
                }
                if let Some(gcp_datastore_url) = gcp_datastore_url {
                    buf.push("--gcp-datastore-url".to_string());
                    buf.push(gcp_datastore_url);
                }
                for sign_node in sign_nodes {
                    buf.push("--sign-nodes".to_string());
                    buf.push(sign_node);
                }
                let account_creator_sk = serde_json::to_string(&account_creator_sk).unwrap();
                buf.push("--account-creator-sk".to_string());
                buf.push(account_creator_sk);
                buf.extend(logging_options.into_str_args());

                buf
            }
            Cli::StartSign {
                env,
                node_id,
                web_port,
                cipher_key,
                sk_share,
                gcp_project_id,
                gcp_datastore_url,
                jwt_signature_pk_url,
                logging_options,
            } => {
                let mut buf = vec![
                    "start-sign".to_string(),
                    "--env".to_string(),
                    env.to_string(),
                    "--node-id".to_string(),
                    node_id.to_string(),
                    "--web-port".to_string(),
                    web_port.to_string(),
                    "--gcp-project-id".to_string(),
                    gcp_project_id,
                    "--jwt-signature-pk-url".to_string(),
                    jwt_signature_pk_url,
                ];
                if let Some(key) = cipher_key {
                    buf.push("--cipher-key".to_string());
                    buf.push(key);
                }
                if let Some(share) = sk_share {
                    buf.push("--sk-share".to_string());
                    buf.push(share);
                }
                if let Some(gcp_datastore_url) = gcp_datastore_url {
                    buf.push("--gcp-datastore-url".to_string());
                    buf.push(gcp_datastore_url);
                }
                buf.extend(logging_options.into_str_args());

                buf
            }
            Cli::RotateSignNodeCipher {
                env,
                new_env,
                node_id,
                old_cipher_key,
                new_cipher_key,
                gcp_project_id,
                gcp_datastore_url,
                logging_options,
            } => {
                let mut buf = vec![
                    "rotate-sign-node-cipher".to_string(),
                    "--env".to_string(),
                    env.to_string(),
                    "--node-id".to_string(),
                    node_id.to_string(),
                    "--gcp-project-id".to_string(),
                    gcp_project_id,
                ];
                if let Some(new_env) = new_env {
                    buf.push("--new-env".to_string());
                    buf.push(new_env);
                }
                if let Some(old_cipher_key) = old_cipher_key {
                    buf.push("--old-cipher-key".to_string());
                    buf.push(old_cipher_key);
                }
                if let Some(new_cipher_key) = new_cipher_key {
                    buf.push("--new-cipher-key".to_string());
                    buf.push(new_cipher_key);
                }
                if let Some(gcp_datastore_url) = gcp_datastore_url {
                    buf.push("--gcp-datastore-url".to_string());
                    buf.push(gcp_datastore_url);
                }
                buf.extend(logging_options.into_str_args());

                buf
            }
        }
    }
}

fn parse_json_str<T>(val: &str) -> Result<T, String>
where
    for<'a> T: serde::Deserialize<'a>,
{
    serde_json::from_str(val).map_err(|e| e.to_string())
}

'''
'''--- mpc-recovery/src/logging.rs ---
use opentelemetry::sdk::propagation::TraceContextPropagator;
use opentelemetry::sdk::trace::{self, RandomIdGenerator, Sampler, Tracer};
use opentelemetry::sdk::Resource;
use opentelemetry::KeyValue;
use opentelemetry_otlp::WithExportConfig;
use opentelemetry_semantic_conventions::resource::SERVICE_NAME;
use std::fmt::Display;
use std::sync::OnceLock;
use tracing::subscriber::DefaultGuard;
use tracing_appender::non_blocking::NonBlocking;
use tracing_opentelemetry::OpenTelemetryLayer;
use tracing_subscriber::filter::Filtered;
use tracing_subscriber::layer::{Layered, SubscriberExt};
use tracing_subscriber::registry::LookupSpan;
use tracing_subscriber::{fmt, reload, EnvFilter, Layer, Registry};

static LOG_LAYER_RELOAD_HANDLE: OnceLock<reload::Handle<EnvFilter, Registry>> = OnceLock::new();
static OTLP_LAYER_RELOAD_HANDLE: OnceLock<reload::Handle<EnvFilter, LogLayer<Registry>>> =
    OnceLock::new();

type LogLayer<Inner> = Layered<
    Filtered<
        fmt::Layer<Inner, fmt::format::DefaultFields, fmt::format::Format, NonBlocking>,
        reload::Layer<EnvFilter, Inner>,
        Inner,
    >,
    Inner,
>;

type TracingLayer<Inner> = Layered<
    Filtered<OpenTelemetryLayer<Inner, Tracer>, reload::Layer<EnvFilter, Inner>, Inner>,
    Inner,
>;

// Records the level of opentelemetry tracing verbosity configured via command-line flags at the startup.
static DEFAULT_OTLP_LEVEL: OnceLock<OpenTelemetryLevel> = OnceLock::new();

// Doesn't define WARN and ERROR, because the highest verbosity of spans is INFO.
#[derive(Copy, Clone, Debug, Default, clap::ValueEnum, serde::Serialize, serde::Deserialize)]
pub enum OpenTelemetryLevel {
    #[default]
    OFF,
    INFO,
    DEBUG,
    TRACE,
}

impl Display for OpenTelemetryLevel {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        let str = match self {
            OpenTelemetryLevel::OFF => "off",
            OpenTelemetryLevel::INFO => "info",
            OpenTelemetryLevel::DEBUG => "debug",
            OpenTelemetryLevel::TRACE => "trace",
        };
        write!(f, "{}", str)
    }
}

/// Whether to use colored log format.
/// Option `Auto` enables color output only if the logging is done to a terminal and
/// `NO_COLOR` environment variable is not set.
#[derive(clap::ValueEnum, Debug, Clone, Default)]
pub enum ColorOutput {
    #[default]
    Auto,
    Always,
    Never,
}

impl Display for ColorOutput {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        let str = match self {
            ColorOutput::Auto => "auto",
            ColorOutput::Always => "always",
            ColorOutput::Never => "never",
        };
        write!(f, "{}", str)
    }
}

/// Configures exporter of span and trace data.
#[derive(Debug, clap::Parser)]
pub struct Options {
    /// Enables export of span data using opentelemetry exporters.
    #[clap(
        long,
        env("MPC_RECOVERY_OPENTELEMETRY_LEVEL"),
        value_enum,
        default_value = "off"
    )]
    pub opentelemetry_level: OpenTelemetryLevel,

    /// Opentelemetry gRPC collector endpoint.
    #[clap(
        long,
        env("MPC_RECOVERY_OTLP_ENDPOINT"),
        default_value = "http://localhost:4317"
    )]
    pub otlp_endpoint: String,

    /// Whether the log needs to be colored.
    #[clap(long, value_enum, default_value = "auto")]
    pub color: ColorOutput,

    /// Enable logging of spans. For instance, this prints timestamps of entering and exiting a span,
    /// together with the span duration and used/idle CPU time.
    #[clap(long)]
    pub log_span_events: bool,
}

impl Default for Options {
    fn default() -> Self {
        Self {
            opentelemetry_level: OpenTelemetryLevel::OFF,
            otlp_endpoint: "http://localhost:4317".to_string(),
            color: ColorOutput::Auto,
            log_span_events: false,
        }
    }
}

impl Options {
    pub fn into_str_args(self) -> Vec<String> {
        let mut buf = vec![
            "--opentelemetry-level".to_string(),
            self.opentelemetry_level.to_string(),
            "--otlp-endpoint".to_string(),
            self.otlp_endpoint,
            "--color".to_string(),
            self.color.to_string(),
        ];
        if self.log_span_events {
            buf.push("--log-span-events".to_string());
        }
        buf
    }
}

fn use_color_output(options: &Options) -> bool {
    fn use_color_auto() -> bool {
        std::env::var_os("NO_COLOR").is_none() && is_terminal()
    }

    fn is_terminal() -> bool {
        // Crate `atty` provides a platform-independent way of checking whether the output is a tty.
        atty::is(atty::Stream::Stderr)
    }

    match options.color {
        ColorOutput::Auto => use_color_auto(),
        ColorOutput::Always => true,
        ColorOutput::Never => false,
    }
}

fn get_fmt_span(with_span_events: bool) -> fmt::format::FmtSpan {
    if with_span_events {
        fmt::format::FmtSpan::ENTER | fmt::format::FmtSpan::CLOSE
    } else {
        fmt::format::FmtSpan::NONE
    }
}

fn add_non_blocking_log_layer<S>(
    filter: EnvFilter,
    writer: NonBlocking,
    ansi: bool,
    with_span_events: bool,
    subscriber: S,
) -> (LogLayer<S>, reload::Handle<EnvFilter, S>)
where
    S: tracing::Subscriber + for<'span> LookupSpan<'span> + Send + Sync,
{
    let (filter, handle) = reload::Layer::<EnvFilter, S>::new(filter);

    let layer = fmt::layer()
        .with_ansi(ansi)
        .with_span_events(get_fmt_span(with_span_events))
        .with_writer(writer)
        .with_line_number(true)
        .with_thread_names(true)
        .with_filter(filter);

    (subscriber.with(layer), handle)
}

/// Constructs an OpenTelemetryConfig which sends span data to an external collector.
async fn add_opentelemetry_layer<S>(
    opentelemetry_level: OpenTelemetryLevel,
    otlp_endpoint: &str,
    env: String,
    node_id: String,
    subscriber: S,
) -> (TracingLayer<S>, reload::Handle<EnvFilter, S>)
where
    S: tracing::Subscriber + for<'span> LookupSpan<'span> + Send + Sync,
{
    let filter = match opentelemetry_level {
        OpenTelemetryLevel::OFF => EnvFilter::new("off"),
        OpenTelemetryLevel::INFO => EnvFilter::new("info"),
        OpenTelemetryLevel::DEBUG => EnvFilter::new("debug"),
        OpenTelemetryLevel::TRACE => EnvFilter::new("trace"),
    };
    // `otel::tracing` should be a level info to emit opentelemetry trace & span
    // `otel::setup` set to debug to log detected resources, configuration read and infered
    let filter = filter
        .add_directive("otel::tracing=trace".parse().unwrap())
        .add_directive("otel=debug".parse().unwrap());
    let (filter, handle) = reload::Layer::<EnvFilter, S>::new(filter);

    let resource = vec![
        KeyValue::new(SERVICE_NAME, format!("mpc:{}:{}", env, node_id)),
        KeyValue::new("env", env),
        KeyValue::new("node_id", node_id),
    ];

    let tracer = opentelemetry_otlp::new_pipeline()
        .tracing()
        .with_exporter(
            opentelemetry_otlp::new_exporter()
                .http()
                .with_endpoint(otlp_endpoint),
        )
        .with_trace_config(
            trace::config()
                .with_sampler(Sampler::AlwaysOn)
                .with_id_generator(RandomIdGenerator::default())
                .with_resource(Resource::new(resource)),
        )
        .install_batch(opentelemetry::runtime::Tokio)
        .unwrap();

    init_propagator();
    let layer = tracing_opentelemetry::layer()
        .with_tracer(tracer)
        .with_filter(filter);
    (subscriber.with(layer), handle)
}

pub fn init_propagator() {
    opentelemetry::global::set_text_map_propagator(TraceContextPropagator::new());
}

fn set_default_otlp_level(options: &Options) {
    // Record the initial tracing level specified as a command-line flag. Use this recorded value to
    // reset opentelemetry filter when the LogConfig file gets deleted.
    DEFAULT_OTLP_LEVEL.set(options.opentelemetry_level).unwrap();
}

/// The resource representing a registered subscriber.
///
/// Once dropped, the subscriber is unregistered, and the output is flushed. Any messages output
/// after this value is dropped will be delivered to a previously active subscriber, if any.
pub struct DefaultSubscriberGuard<S> {
    // NB: the field order matters here. We must first drop the `local_subscriber_guard` so that
    // no new messages are delivered to this subscriber while we take care of flushing the
    // messages already in queue. If dropped the other way around, the events/spans generated
    // while the subscriber drop guard runs would be lost.
    subscriber: Option<S>,
    local_subscriber_guard: Option<DefaultGuard>,
    #[allow(dead_code)] // This field is never read, but has semantic purpose as a drop guard.
    writer_guard: Option<tracing_appender::non_blocking::WorkerGuard>,
}

impl<S: tracing::Subscriber + Send + Sync> DefaultSubscriberGuard<S> {
    /// Register this default subscriber globally , for all threads.
    ///
    /// Must not be called more than once. Mutually exclusive with `Self::local`.
    pub fn global(mut self) -> Self {
        if let Some(subscriber) = self.subscriber.take() {
            tracing::subscriber::set_global_default(subscriber)
                .expect("could not set a global subscriber");
        } else {
            panic!("trying to set a default subscriber that has been already taken")
        }
        self
    }

    /// Register this default subscriber for the current thread.
    ///
    /// Must not be called more than once. Mutually exclusive with `Self::global`.
    pub fn local(mut self) -> Self {
        if let Some(subscriber) = self.subscriber.take() {
            self.local_subscriber_guard = Some(tracing::subscriber::set_default(subscriber));
        } else {
            panic!("trying to set a default subscriber that has been already taken")
        }
        self
    }
}

pub async fn default_subscriber_with_opentelemetry(
    env_filter: EnvFilter,
    options: &Options,
    env: String,
    node_id: String,
) -> DefaultSubscriberGuard<impl tracing::Subscriber + Send + Sync> {
    let color_output = use_color_output(options);

    // Do not lock the `stderr` here to allow for things like `dbg!()` work during development.
    let stderr = std::io::stderr();
    let lined_stderr = std::io::LineWriter::new(stderr);
    let (writer, writer_guard) = tracing_appender::non_blocking(lined_stderr);

    let subscriber = tracing_subscriber::registry();

    set_default_otlp_level(options);

    let (subscriber, handle) = add_non_blocking_log_layer(
        env_filter,
        writer,
        color_output,
        options.log_span_events,
        subscriber,
    );
    LOG_LAYER_RELOAD_HANDLE
        .set(handle)
        .unwrap_or_else(|_| panic!("Failed to set Log Layer Filter"));

    let (subscriber, handle) = add_opentelemetry_layer(
        options.opentelemetry_level,
        &options.otlp_endpoint,
        env,
        node_id,
        subscriber,
    )
    .await;
    OTLP_LAYER_RELOAD_HANDLE
        .set(handle)
        .unwrap_or_else(|_| panic!("Failed to set OTLP Layer Filter"));

    DefaultSubscriberGuard {
        subscriber: Some(subscriber),
        local_subscriber_guard: None,
        writer_guard: Some(writer_guard),
    }
}

pub enum FeatureGuard<S> {
    Noop,
    Default(DefaultSubscriberGuard<S>),
}

pub async fn subscribe_global(
    env_filter: EnvFilter,
    options: &Options,
    env: String,
    node_id: String,
) -> FeatureGuard<impl tracing::Subscriber + Send + Sync> {
    if cfg!(feature = "disable-open-telemetry") {
        FeatureGuard::Noop
    } else {
        let subscriber_guard =
            default_subscriber_with_opentelemetry(env_filter, options, env, node_id)
                .await
                .global();

        FeatureGuard::Default(subscriber_guard)
    }
}

'''
'''--- mpc-recovery/src/main.rs ---
use clap::Parser;
use mpc_recovery::Cli;

#[tokio::main]
async fn main() -> anyhow::Result<()> {
    mpc_recovery::run(Cli::parse()).await
}

'''
'''--- mpc-recovery/src/metrics.rs ---
use prometheus::{register_int_counter_vec, HistogramVec, IntCounterVec};

use lazy_static::lazy_static;
use prometheus::{opts, register_histogram_vec};

const EXPONENTIAL_SECONDS: &[f64] = &[
    0.001, 0.002, 0.004, 0.008, 0.016, 0.032, 0.064, 0.128, 0.256, 0.512, 1.024, 2.048, 4.096,
    8.192, 16.384, 32.768,
];

lazy_static! {
    pub static ref HTTP_REQUEST_COUNT: IntCounterVec = register_int_counter_vec!(
        opts!(
            "mpc_http_total_count",
            "Total count of HTTP RPC requests received, by method and path"
        ),
        &["method", "path"]
    )
    .expect("can't create a metric");
    pub static ref HTTP_CLIENT_ERROR_COUNT: IntCounterVec = register_int_counter_vec!(
        opts!(
            "mpc_http_client_error_count",
            "Total count of client errors (4xx) by method and path"
        ),
        &["method", "path"]
    )
    .expect("can't create a metric");
    pub static ref HTTP_SERVER_ERROR_COUNT: IntCounterVec = register_int_counter_vec!(
        opts!(
            "mpc_http_server_error_count",
            "Total count of server errors (5xx) by method and path"
        ),
        &["method", "path"]
    )
    .expect("can't create a metric");
    pub static ref HTTP_PROCESSING_TIME: HistogramVec = register_histogram_vec!(
        "mpc_http_processing_time",
        "Time taken to process HTTP requests in seconds",
        &["method", "path"],
        EXPONENTIAL_SECONDS.to_vec(),
    )
    .expect("can't create a metric");
}

'''
'''--- mpc-recovery/src/msg.rs ---
use crate::sign_node::oidc::{OidcHash, OidcToken};
use crate::transaction::CreateAccountOptions;
use curv::elliptic::curves::{Ed25519, Point};
use ed25519_dalek::Signature;
use near_primitives::delegate_action::DelegateAction;
use near_primitives::types::AccountId;
use serde::{Deserialize, Serialize};
use serde_with::base64::Base64;
use serde_with::serde_as;

#[derive(Serialize, Deserialize, Debug, Clone)]
pub struct MpcPkRequest {}

#[derive(Serialize, Deserialize, Debug)]
#[serde(tag = "type")]
#[serde(rename_all = "snake_case")]
pub enum MpcPkResponse {
    Ok { mpc_pk: ed25519_dalek::PublicKey },
    Err { msg: String },
}

impl TryInto<ed25519_dalek::PublicKey> for MpcPkResponse {
    type Error = anyhow::Error;

    fn try_into(self) -> Result<ed25519_dalek::PublicKey, Self::Error> {
        match self {
            MpcPkResponse::Ok { mpc_pk } => Ok(mpc_pk),
            MpcPkResponse::Err { msg } => anyhow::bail!("error response: {}", msg),
        }
    }
}

#[derive(Serialize, Deserialize, Debug, Clone)]
pub struct ClaimOidcRequest {
    #[serde(with = "hex::serde")]
    pub oidc_token_hash: OidcHash,
    pub frp_public_key: near_crypto::PublicKey,
    #[serde(with = "hex_signature")]
    pub frp_signature: Signature,
}

#[derive(Serialize, Deserialize, Debug, Clone)]
#[serde(tag = "type")]
#[serde(rename_all = "snake_case")]
pub enum ClaimOidcResponse {
    Ok {
        #[serde(with = "hex_signature")]
        mpc_signature: Signature,
    },
    Err {
        msg: String,
    },
}

impl TryInto<Signature> for ClaimOidcResponse {
    type Error = anyhow::Error;

    fn try_into(self) -> Result<Signature, Self::Error> {
        let mpc_signature = match self {
            ClaimOidcResponse::Ok { mpc_signature } => mpc_signature,
            ClaimOidcResponse::Err { msg } => anyhow::bail!("error response: {}", msg),
        };

        Ok(mpc_signature)
    }
}

#[derive(Serialize, Deserialize, Debug, Clone)]
pub struct UserCredentialsRequest {
    pub oidc_token: OidcToken,
    #[serde(with = "hex_signature")]
    pub frp_signature: Signature,
    pub frp_public_key: near_crypto::PublicKey,
}

#[derive(Serialize, Deserialize, Debug, Clone)]
#[serde(tag = "type")]
#[serde(rename_all = "snake_case")]
pub enum UserCredentialsResponse {
    Ok { recovery_pk: near_crypto::PublicKey },
    Err { msg: String },
}

impl UserCredentialsResponse {
    pub fn err(msg: String) -> Self {
        UserCredentialsResponse::Err { msg }
    }
}

#[derive(Serialize, Deserialize, Debug, Clone)]
pub struct NewAccountRequest {
    pub near_account_id: AccountId,
    pub create_account_options: CreateAccountOptions,
    pub oidc_token: OidcToken,
    #[serde(with = "hex_signature")]
    pub user_credentials_frp_signature: Signature,
    pub frp_public_key: near_crypto::PublicKey,
}

#[derive(Serialize, Deserialize, Debug)]
#[serde(tag = "type")]
#[serde(rename_all = "snake_case")]
pub enum NewAccountResponse {
    Ok {
        create_account_options: CreateAccountOptions,
        user_recovery_public_key: near_crypto::PublicKey,
        near_account_id: AccountId,
    },
    Err {
        msg: String,
    },
}

impl NewAccountResponse {
    pub fn err(msg: String) -> Self {
        NewAccountResponse::Err { msg }
    }
}

#[serde_as]
#[derive(Serialize, Deserialize, Debug, Clone)]
pub struct SignRequest {
    #[serde_as(as = "Base64")]
    pub delegate_action: Vec<u8>,
    pub oidc_token: OidcToken,
    #[serde(with = "hex_signature")]
    pub frp_signature: Signature,
    #[serde(with = "hex_signature")]
    pub user_credentials_frp_signature: Signature,
    pub frp_public_key: near_crypto::PublicKey,
}

#[derive(Serialize, Deserialize, Debug)]
#[serde(tag = "type")]
#[serde(rename_all = "snake_case")]
pub enum SignResponse {
    Ok {
        #[serde(with = "hex_signature")]
        signature: Signature,
    },
    Err {
        msg: String,
    },
}

impl SignResponse {
    pub fn err(msg: String) -> Self {
        SignResponse::Err { msg }
    }
}

/// The set of actions that a user can request us to sign
#[derive(Serialize, Deserialize, Debug, Clone)]
pub enum SignNodeRequest {
    ClaimOidc(ClaimOidcNodeRequest),
    SignShare(SignShareNodeRequest),
}

#[derive(Serialize, Deserialize, Debug, Clone)]
pub struct SignShareNodeRequest {
    pub oidc_token: OidcToken,
    pub delegate_action: DelegateAction,
    #[serde(with = "hex_signature")]
    pub frp_signature: Signature,
    pub frp_public_key: near_crypto::PublicKey,
}

#[derive(Serialize, Deserialize, Debug, Clone)]
pub struct ClaimOidcNodeRequest {
    #[serde(with = "hex::serde")]
    pub oidc_token_hash: OidcHash,
    pub public_key: near_crypto::PublicKey,
    #[serde(with = "hex_signature")]
    pub signature: Signature,
}
#[derive(Serialize, Deserialize, Debug, Clone)]
pub struct PublicKeyNodeRequest {
    pub oidc_token: OidcToken,
    #[serde(with = "hex_signature")]
    pub frp_signature: Signature,
    pub frp_public_key: near_crypto::PublicKey,
}

#[derive(Serialize, Deserialize, Debug)]
pub struct AcceptNodePublicKeysRequest {
    pub public_keys: Vec<Point<Ed25519>>,
}

mod hex_signature {
    use ed25519_dalek::Signature;
    use serde::{Deserialize, Deserializer, Serializer};

    pub fn serialize<S>(sig_share: &Signature, serializer: S) -> Result<S::Ok, S::Error>
    where
        S: Serializer,
    {
        let s = hex::encode(Signature::to_bytes(*sig_share));
        serializer.serialize_str(&s)
    }

    pub fn deserialize<'de, D>(deserializer: D) -> Result<Signature, D::Error>
    where
        D: Deserializer<'de>,
    {
        let s = String::deserialize(deserializer)?;
        Signature::from_bytes(
            &<[u8; Signature::BYTE_SIZE]>::try_from(
                hex::decode(s).map_err(serde::de::Error::custom)?,
            )
            .map_err(|v: Vec<u8>| {
                serde::de::Error::custom(format!(
                    "signature has incorrect length: expected {} bytes, but got {}",
                    Signature::BYTE_SIZE,
                    v.len()
                ))
            })?,
        )
        .map_err(serde::de::Error::custom)
    }
}

'''
'''--- mpc-recovery/src/nar.rs ---
// TODO: use NAR in the future.
//! Separated away from client to distinguish functions that are common and
//! need to be moved eventually into their own separate crate. Not necessarily
//! to be used from workspaces directly even though it is imported from there.

use std::time::Duration;

use tokio_retry::strategy::{jitter, ExponentialBackoff};
use tokio_retry::Retry;

pub(crate) async fn retry_every<R, E, T, F>(interval: Duration, task: F) -> T::Output
where
    F: FnMut() -> T,
    T: core::future::Future<Output = core::result::Result<R, E>>,
{
    let retry_strategy = std::iter::repeat_with(|| interval);
    let task = Retry::spawn(retry_strategy, task);
    task.await
}

pub(crate) async fn retry<R, E, T, F>(task: F) -> T::Output
where
    F: FnMut() -> T,
    T: core::future::Future<Output = core::result::Result<R, E>>,
{
    // Exponential backoff starting w/ 5ms for maximum retry of 4 times with the following delays:
    //   5, 25, 125, 625 ms
    let retry_strategy = ExponentialBackoff::from_millis(5).map(jitter).take(4);
    Retry::spawn(retry_strategy, task).await
}

'''
'''--- mpc-recovery/src/oauth.rs ---
use jsonwebtoken::{Algorithm, DecodingKey};
use serde::{Deserialize, Serialize};
use std::collections::HashMap;

use crate::firewall::allowed::OidcProviderList;
use crate::primitives::InternalAccountId;
use crate::sign_node::oidc::OidcToken;

// Specs for ID token verification:
// Google: https://developers.google.com/identity/openid-connect/openid-connect#validatinganidtoken
// Firebase: https://firebase.google.com/docs/auth/admin/verify-id-tokens#verify_id_tokens_using_a_third-party_jwt_library
pub async fn verify_oidc_token(
    token: &OidcToken,
    oidc_providers: Option<&OidcProviderList>,
    client: &reqwest::Client,
    jwt_signature_pk_url: &str,
) -> anyhow::Result<IdTokenClaims> {
    let public_keys = get_pagoda_firebase_public_keys(client, jwt_signature_pk_url)
        .await
        .map_err(|e| anyhow::anyhow!("failed to get Firebase public key: {e}"))?;
    tracing::info!("verify_oidc_token firebase public keys: {public_keys:?}");

    let mut last_occured_error =
        anyhow::anyhow!("Unexpected error. Firebase public keys not found");
    for public_key in public_keys {
        match validate_jwt(token, public_key.as_bytes(), oidc_providers) {
            Ok(claims) => {
                tracing::info!("Access token is valid");
                return Ok(claims);
            }
            Err(e) => {
                tracing::info!("Access token verification failed: {}", e);
                last_occured_error = e;
            }
        }
    }
    Err(last_occured_error)
}

/// This function validates JWT (OIDC ID token) by checking the signature received
/// from the issuer, issuer, audience, and expiration time.
fn validate_jwt(
    token: &OidcToken,
    public_key: &[u8],
    oidc_providers: Option<&OidcProviderList>,
) -> anyhow::Result<IdTokenClaims> {
    tracing::info!(
        oidc_token = format!("{:.5}...", token),
        public_key = String::from_utf8(public_key.to_vec()).unwrap_or_default(),
        "validate_jwt call"
    );

    let decoding_key = DecodingKey::from_rsa_pem(public_key)?;
    let (header, claims, _sig) = token.decode(&decoding_key)?;
    let IdTokenClaims {
        iss: issuer,
        aud: audience,
        ..
    } = &claims;

    // If no OIDC providers are specified in the allowlist, we allow any issuer and audience.
    // Should be used in signing nodes only.
    if let Some(oidc_providers) = oidc_providers {
        if !oidc_providers.contains(issuer, audience) {
            anyhow::bail!("UnauthorizedTokenIssuerOrAudience: iss={issuer}, aud={audience}");
        }
    }

    tracing::info!(
        issuer = issuer,
        audience = audience,
        "validate_jwt call decoded"
    );

    // algorithm used by jsonwebtoken library
    if header.alg != Algorithm::RS256 {
        anyhow::bail!("InvalidAlgorithm: {:?}", header.alg);
    }

    tracing::info!(
        claims = format!("{:?}", claims),
        "validate_jwt call successful"
    );

    Ok(claims)
}

#[derive(Debug, Serialize, Deserialize)]
pub struct IdTokenClaims {
    pub iss: String,
    pub sub: String,
    pub aud: String,
    pub exp: usize,
}

impl IdTokenClaims {
    pub fn get_internal_account_id(&self) -> InternalAccountId {
        format!("{}:{}", self.iss, self.sub)
    }
}

pub async fn get_pagoda_firebase_public_keys(
    client: &reqwest::Client,
    jwt_signature_pk_url: &str,
) -> anyhow::Result<Vec<String>> {
    let response = client.get(jwt_signature_pk_url).send().await?;
    let json: HashMap<String, String> = response.json().await?;
    Ok(json.into_values().collect())
}

#[cfg(test)]
mod tests {
    use super::*;
    use chrono::{Duration, Utc};
    use jsonwebtoken::{encode, EncodingKey, Header};
    use rand::rngs::OsRng;
    use rsa::{
        pkcs1::{EncodeRsaPrivateKey, EncodeRsaPublicKey},
        RsaPrivateKey, RsaPublicKey,
    };

    #[tokio::test]
    async fn test_get_pagoda_firebase_public_key() {
        let url =
        "https://www.googleapis.com/robot/v1/metadata/x509/securetoken@system.gserviceaccount.com";
        let client = reqwest::Client::new();
        let pk = get_pagoda_firebase_public_keys(&client, url).await.unwrap();
        assert!(!pk.is_empty());
    }

    #[test]
    fn test_validate_jwt() {
        let (private_key_der, public_key_der): (Vec<u8>, Vec<u8>) = get_rsa_pem_key_pair();

        let my_claims = IdTokenClaims {
            iss: "test_issuer".to_string(),
            sub: "test_subject".to_string(),
            aud: "test_audience".to_string(),
            exp: (Utc::now() + Duration::hours(1)).timestamp() as usize,
        };
        let oidc_providers = allowlist_from_claims(&my_claims);

        let token = match encode(
            &Header::new(Algorithm::RS256),
            &my_claims,
            &EncodingKey::from_rsa_pem(&private_key_der).unwrap(),
        ) {
            Ok(t) => OidcToken::new(t.as_str()),
            Err(e) => panic!("Failed to encode token: {}", e),
        };

        // Valid token and claims
        validate_jwt(&token, &public_key_der, Some(&oidc_providers)).unwrap();

        // Invalid public key
        let (invalid_public_key, _invalid_private_key) = get_rsa_pem_key_pair();
        match validate_jwt(&token, &invalid_public_key, Some(&oidc_providers)) {
            Ok(_) => panic!("Token validation should fail"),
            Err(e) => assert_eq!(e.to_string(), "InvalidSignature"),
        }

        // Invalid issuer or audience
        let new_claims = IdTokenClaims {
            iss: "unauthorized_issuer".to_string(),
            sub: "unauthorized_subject".to_string(),
            aud: "unauthorized_audience".to_string(),
            exp: (Utc::now() + Duration::hours(1)).timestamp() as usize,
        };
        let token = match encode(
            &Header::new(Algorithm::RS256),
            &new_claims,
            &EncodingKey::from_rsa_pem(&private_key_der).unwrap(),
        ) {
            Ok(t) => OidcToken::new(t.as_str()),
            Err(e) => panic!("Failed to encode token: {}", e),
        };
        match validate_jwt(&token, &public_key_der, Some(&oidc_providers)) {
            Ok(_) => panic!("Token validation should fail on invalid issuer or audience"),
            Err(e) => assert_eq!(e.to_string(), "UnauthorizedTokenIssuerOrAudience: iss=unauthorized_issuer, aud=unauthorized_audience", "{:?}", e),
        }
    }

    #[test]
    fn test_validate_jwt_without_oidc() {
        let (private_key_der, public_key_der): (Vec<u8>, Vec<u8>) = get_rsa_pem_key_pair();

        let my_claims = IdTokenClaims {
            iss: "test_issuer".to_string(),
            sub: "test_subject".to_string(),
            aud: "test_audience".to_string(),
            exp: (Utc::now() + Duration::hours(1)).timestamp() as usize,
        };

        let token = match encode(
            &Header::new(Algorithm::RS256),
            &my_claims,
            &EncodingKey::from_rsa_pem(&private_key_der).unwrap(),
        ) {
            Ok(t) => OidcToken::new(t.as_str()),
            Err(e) => panic!("Failed to encode token: {}", e),
        };

        // Valid token and claims
        match validate_jwt(&token, &public_key_der, None) {
            Ok(_) => (),
            Err(e) => panic!("Token validation should succeed: {}", e),
        }
    }

    pub fn get_rsa_pem_key_pair() -> (Vec<u8>, Vec<u8>) {
        let mut rng = OsRng;
        let bits: usize = 2048;
        let private_key = RsaPrivateKey::new(&mut rng, bits).expect("failed to generate a key");
        let public_key = RsaPublicKey::from(&private_key);

        let private_key_der = private_key
            .to_pkcs1_pem(rsa::pkcs8::LineEnding::LF)
            .expect("Failed to encode private key")
            .as_bytes()
            .to_vec();
        let public_key_der = public_key
            .to_pkcs1_pem(rsa::pkcs8::LineEnding::LF)
            .expect("Failed to encode public key")
            .as_bytes()
            .to_vec();

        (private_key_der, public_key_der)
    }

    fn allowlist_from_claims(claims: &IdTokenClaims) -> OidcProviderList {
        let mut oidc_providers = OidcProviderList::default();
        oidc_providers.insert(crate::firewall::allowed::OidcProvider {
            issuer: claims.iss.clone(),
            audience: claims.aud.clone(),
        });
        oidc_providers
    }
}

'''
'''--- mpc-recovery/src/primitives.rs ---
pub type InternalAccountId = String; // format: "iss:sub" from the ID token

#[derive(Copy, Clone)]
pub enum HashSalt {
    ClaimOidcRequest = 0,
    ClaimOidcResponse = 1,
    UserCredentialsRequest = 2,
    SignRequest = 3,
}

// Mentioned in the readme, here to avoid collisions with legitimate transactions
// chosen by a fair dice roll.
// guaranteed to be random.
const SALT_BASE: u32 = 3177899144;
impl HashSalt {
    pub fn get_salt(&self) -> u32 {
        SALT_BASE + (*self as u32)
    }
}

'''
'''--- mpc-recovery/src/relayer/error.rs ---
use hyper::StatusCode;
use near_crypto::PublicKey;
use near_primitives::{errors::TxExecutionError, types::AccountId};

#[derive(thiserror::Error, Debug)]
pub enum RelayerError {
    #[error("unknown account `{0}`")]
    UnknownAccount(AccountId),
    #[error("unknown key `{0}`")]
    UnknownAccessKey(PublicKey),
    #[error(transparent)]
    DataConversionFailure(anyhow::Error),
    #[error(transparent)]
    NetworkFailure(anyhow::Error),
    #[error("{1}")]
    RequestFailure(StatusCode, String),
    #[error(transparent)]
    TxExecutionFailure(TxExecutionError),
    #[error("transaction is not ready yet")]
    TxNotReady,
    #[error("{0}")]
    Other(#[from] anyhow::Error),
}

'''
'''--- mpc-recovery/src/relayer/mod.rs ---
pub mod error;
pub mod msg;

use self::error::RelayerError;
use self::msg::{
    CreateAccountAtomicRequest, RegisterAccountRequest, SendMetaTxRequest, SendMetaTxResponse,
};
use crate::firewall::allowed::DelegateActionRelayer;
use anyhow::Context;
use hyper::{Body, Client, Method, Request};
use near_crypto::PublicKey;
use near_jsonrpc_client::errors::{JsonRpcError, JsonRpcServerError};
use near_jsonrpc_primitives::types::query::RpcQueryError;
use near_primitives::hash::CryptoHash;
use near_primitives::types::{AccountId, BlockHeight, Nonce};
use near_primitives::views::FinalExecutionStatus;

pub struct NearRpcAndRelayerClient {
    rpc_client: near_fetch::Client,
}

impl NearRpcAndRelayerClient {
    pub fn connect(near_rpc: &str) -> Self {
        Self {
            rpc_client: near_fetch::Client::new(near_rpc),
        }
    }

    pub async fn access_key(
        &self,
        account_id: &AccountId,
        public_key: &PublicKey,
    ) -> Result<(CryptoHash, BlockHeight, Nonce), RelayerError> {
        let (nonce, hash, height) = self
            .rpc_client
            .fetch_nonce(account_id, public_key)
            .await
            .map_err(|e| match e {
                near_fetch::error::Error::RpcQueryError(JsonRpcError::ServerError(
                    JsonRpcServerError::HandlerError(RpcQueryError::UnknownAccount {
                        requested_account_id,
                        ..
                    }),
                )) => RelayerError::UnknownAccount(requested_account_id),
                near_fetch::error::Error::RpcQueryError(JsonRpcError::ServerError(
                    JsonRpcServerError::HandlerError(RpcQueryError::UnknownAccessKey {
                        public_key,
                        ..
                    }),
                )) => RelayerError::UnknownAccessKey(public_key),
                _ => anyhow::anyhow!(e).into(),
            })?;

        Ok((hash, height, nonce))
    }

    #[tracing::instrument(level = "debug", skip_all, fields(account_id = request.account_id.to_string()))]
    pub async fn register_account_and_allowance(
        &self,
        request: RegisterAccountRequest,
        relayer: DelegateActionRelayer,
    ) -> Result<(), RelayerError> {
        let mut req = Request::builder()
            .method(Method::POST)
            .uri(format!("{}/register_account", relayer.url))
            .header("content-type", "application/json");

        if let Some(api_key) = relayer.api_key {
            req = req.header("x-api-key", api_key);
        };

        let request = req
            .body(Body::from(
                serde_json::to_vec(&request)
                    .map_err(|e| RelayerError::DataConversionFailure(e.into()))?,
            ))
            .map_err(|e| RelayerError::NetworkFailure(e.into()))?;

        tracing::debug!("constructed http request to {}", relayer.url);
        let client = Client::new();
        let response = client
            .request(request)
            .await
            .map_err(|e| RelayerError::NetworkFailure(e.into()))?;

        let status = response.status();
        let response_body = hyper::body::to_bytes(response.into_body())
            .await
            .map_err(|e| RelayerError::NetworkFailure(e.into()))?;
        let msg = std::str::from_utf8(&response_body)
            .map_err(|e| RelayerError::DataConversionFailure(e.into()))?;

        if status.is_success() {
            tracing::debug!("success: {msg}");
            Ok(())
        } else {
            Err(RelayerError::RequestFailure(status, msg.to_string()))
        }
    }

    #[tracing::instrument(level = "debug", skip_all, fields(account_id = request.account_id.to_string()))]
    pub async fn create_account_atomic(
        &self,
        request: CreateAccountAtomicRequest,
        relayer: &DelegateActionRelayer,
    ) -> Result<(), RelayerError> {
        let mut req = Request::builder()
            .method(Method::POST)
            .uri(format!("{}/create_account_atomic", relayer.url))
            .header("content-type", "application/json");

        if let Some(api_key) = &relayer.api_key {
            req = req.header("x-api-key", api_key);
        };

        let request = req
            .body(Body::from(
                serde_json::to_vec(&request)
                    .map_err(|e| RelayerError::DataConversionFailure(e.into()))?,
            ))
            .map_err(|e| RelayerError::NetworkFailure(e.into()))?;

        tracing::debug!("constructed http request to {}", relayer.url);
        let client = Client::new();
        let response = client
            .request(request)
            .await
            .map_err(|e| RelayerError::NetworkFailure(e.into()))?;

        let status = response.status();
        let response_body = hyper::body::to_bytes(response.into_body())
            .await
            .map_err(|e| RelayerError::NetworkFailure(e.into()))?;
        let msg = std::str::from_utf8(&response_body)
            .map_err(|e| RelayerError::DataConversionFailure(e.into()))?;

        if status.is_success() {
            tracing::debug!(response_body = msg, "got response");
            Ok(())
        } else {
            Err(RelayerError::RequestFailure(status, msg.to_string()))
        }
    }

    #[tracing::instrument(level = "debug", skip_all, fields(receiver_id = request.delegate_action.receiver_id.to_string()))]
    pub async fn send_meta_tx(
        &self,
        request: SendMetaTxRequest,
        relayer: DelegateActionRelayer,
    ) -> Result<SendMetaTxResponse, RelayerError> {
        let request = Request::builder()
            .method(Method::POST)
            .uri(format!("{}/send_meta_tx", relayer.url))
            .header("content-type", "application/json")
            .body(Body::from(
                serde_json::to_vec(&request)
                    .map_err(|e| RelayerError::DataConversionFailure(e.into()))?,
            ))
            .context("failed to construct send_meta_tx request")
            .map_err(RelayerError::NetworkFailure)?;

        tracing::debug!("constructed http request to {}", relayer.url);
        let client = Client::new();
        let response = client
            .request(request)
            .await
            .context("failed to send send_meta_tx request to relayer")
            .map_err(RelayerError::NetworkFailure)?;
        let status = response.status();
        let response_body = hyper::body::to_bytes(response.into_body())
            .await
            .map_err(|e| RelayerError::NetworkFailure(e.into()))?;
        let msg = std::str::from_utf8(&response_body)
            .map_err(|e| RelayerError::DataConversionFailure(e.into()))?;

        if status.is_success() {
            tracing::debug!(response_body = msg, "got response");
            let response: SendMetaTxResponse = serde_json::from_slice(&response_body)
                .map_err(|e| RelayerError::DataConversionFailure(e.into()))?;
            match response.status {
                FinalExecutionStatus::NotStarted | FinalExecutionStatus::Started => {
                    Err(RelayerError::TxNotReady)
                }
                FinalExecutionStatus::Failure(e) => Err(RelayerError::TxExecutionFailure(e)),
                FinalExecutionStatus::SuccessValue(ref value) => {
                    tracing::debug!(
                        value = std::str::from_utf8(value)
                            .map_err(|e| RelayerError::DataConversionFailure(e.into()))?,
                        "success"
                    );
                    Ok(response)
                }
            }
        } else {
            Err(RelayerError::RequestFailure(status, msg.to_string()))
        }
    }

    pub(crate) async fn invalidate_cache_if_acc_creation_failed(
        &self,
        cache_key: &(AccountId, PublicKey),
        err_str: &str,
    ) {
        // InvalidNonce, cached nonce is potentially very far behind, so invalidate it.
        if err_str.contains("InvalidNonce")
            || err_str.contains("DelegateActionInvalidNonce")
            || err_str.contains("must be larger than nonce of the used access key")
        {
            self.rpc_client.invalidate_cache(cache_key).await;
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    const TESTNET_URL: &str = "https://rpc.testnet.near.org";

    #[tokio::test]
    async fn test_access_key() -> anyhow::Result<()> {
        let testnet = NearRpcAndRelayerClient::connect(TESTNET_URL);
        let (block_hash, block_height, nonce) = testnet
            .access_key(
                &"dev-1636354824855-78504059330123".parse()?,
                &"ed25519:8n5HXTibTDtXKAnEUPFUXXJoKqa5A1c2vWXt6LbRAcGn".parse()?,
            )
            .await?;

        assert_eq!(block_hash.0.len(), 32);
        assert!(block_height > 0);
        // Assuming no one will use this account ever again
        assert_eq!(nonce, 70526114000003);
        Ok(())
    }
}

'''
'''--- mpc-recovery/src/relayer/msg.rs ---
use near_primitives::{
    delegate_action::SignedDelegateAction,
    types::AccountId,
    views::{ExecutionOutcomeWithIdView, FinalExecutionStatus},
};
use serde::{Deserialize, Serialize};

#[derive(Clone, Debug, Serialize, Deserialize)]
pub struct RegisterAccountRequest {
    pub account_id: AccountId,
    pub allowance: u64,
    // This is actually an InternalAccountId.
    // TODO: rename it to internal_account_id on the relayer side
    pub oauth_token: String,
}

#[derive(Clone, Debug, Serialize, Deserialize)]
pub struct CreateAccountAtomicRequest {
    pub account_id: AccountId,
    pub allowance: u64,
    // This is actually an InternalAccountId.
    // TODO: rename it to internal_account_id on the relayer side
    pub oauth_token: String,
    pub signed_delegate_action: SignedDelegateAction,
}

pub type SendMetaTxRequest = SignedDelegateAction;

#[derive(Clone, Debug, Serialize, Deserialize)]
pub struct SendMetaTxResponse {
    pub message: String,
    pub status: FinalExecutionStatus,
    #[serde(rename = "Transaction Outcome")]
    pub transaction_outcome: ExecutionOutcomeWithIdView,
    #[serde(rename = "Receipts Outcome")]
    pub receipts_outcome: Vec<ExecutionOutcomeWithIdView>,
}

'''
'''--- mpc-recovery/src/sign_node/aggregate_signer.rs ---
use std::collections::HashMap;
use std::hash::{Hash, Hasher};

use curv::arithmetic::Converter;
use curv::cryptographic_primitives::commitments::{
    hash_commitment::HashCommitment, traits::Commitment,
};
use curv::elliptic::curves::{Ed25519, Point};
use curv::BigInt;
use ed25519_dalek::{Sha512, Signature, Verifier};
use multi_party_eddsa::protocols;
use multi_party_eddsa::protocols::aggsig::{self, KeyAgg, SignSecondMsg};
use rand::rngs::OsRng;
use rand::Rng;
use serde::{Deserialize, Serialize};
use tokio::sync::RwLock;

use crate::error::AggregateSigningError;
use crate::transaction::{to_dalek_public_key, to_dalek_signature};

pub struct SigningState {
    committed: RwLock<HashMap<AggrCommitment, Committed>>,
    revealed: RwLock<HashMap<Reveal, Revealed>>,
}

impl Default for SigningState {
    fn default() -> Self {
        Self::new()
    }
}

impl SigningState {
    pub fn new() -> Self {
        SigningState {
            committed: RwLock::new(HashMap::new()),
            revealed: RwLock::new(HashMap::new()),
        }
    }

    pub async fn get_commitment(
        &self,
        our_key: &protocols::ExpandedKeyPair,
        node_key: &protocols::ExpandedKeyPair,
        message: Vec<u8>,
    ) -> Result<SignedCommitment, AggregateSigningError> {
        // We use OSRng on it's own instead of thread_random() for commit padding and OsRng
        self.get_commitment_with_rng(our_key, node_key, message, &mut OsRng)
            .await
    }

    /// This is for deterministic testing, don't use it in prod
    /// The whole signing process is deterministic if a deterministic rng is used
    pub(crate) async fn get_commitment_with_rng(
        &self,
        our_key: &protocols::ExpandedKeyPair,
        node_key: &protocols::ExpandedKeyPair,
        message: Vec<u8>,
        rng: &mut impl Rng,
    ) -> Result<SignedCommitment, AggregateSigningError> {
        let (commitment, state) = Committed::commit(our_key, node_key, message, rng)?;
        self.committed
            .write()
            .await
            .insert(commitment.commitment.clone(), state);
        Ok(commitment)
    }

    pub async fn get_reveal(
        &self,
        node_info: &NodeInfo,
        recieved_commitments: Vec<SignedCommitment>,
    ) -> Result<Reveal, AggregateSigningError> {
        // TODO Factor this out
        let i = node_info.our_index;
        let our_c = recieved_commitments.get(i).ok_or_else(|| {
            AggregateSigningError::InvalidCommitmentNumbers(
                node_info.our_index,
                recieved_commitments.len(),
            )
        })?;
        // Don't readd this on failure, this commitment is now burnt
        let state = self
            .committed
            .write()
            .await
            .remove(&our_c.commitment)
            .ok_or_else(|| {
                AggregateSigningError::CommitmentNotFound(format!("{:?}", our_c.commitment))
            })?;

        let (reveal, state) = state.reveal(node_info, recieved_commitments).await?;
        let reveal = Reveal(reveal);
        self.revealed.write().await.insert(reveal.clone(), state);
        Ok(reveal)
    }

    pub async fn get_signature_share(
        &self,
        node_info: &NodeInfo,
        signature_parts: Vec<Reveal>,
    ) -> Result<protocols::Signature, AggregateSigningError> {
        let i = node_info.our_index;
        let our_r = signature_parts.get(i).ok_or_else(|| {
            AggregateSigningError::InvalidRevealNumbers(node_info.our_index, signature_parts.len())
        })?;

        // Don't readd this on failure, this commitment is now burnt
        let state = self
            .revealed
            .write()
            .await
            .remove(our_r)
            .ok_or_else(|| AggregateSigningError::RevealNotFound(format!("{:?}", our_r)))?;

        let signature_parts = signature_parts.into_iter().map(|s| s.0).collect();

        state.combine(signature_parts, node_info)
    }
}

/// This represents the signers view of a single signed transaction
/// We use an minor extention of aggregate signatures to do this.
/// This extension creates a "node key" in addition to the signing keys which allows the key to verify that the information they recieves actually comes from a signer
#[derive(Clone)]
pub struct Committed {
    ephemeral_key: aggsig::EphemeralKey,
    our_signature: aggsig::SignSecondMsg,
    message: Vec<u8>,
    our_key: protocols::ExpandedKeyPair,
}

// TOOD Make this fixed size hash
#[derive(Eq, PartialEq, Clone, Debug, Serialize, Deserialize)]
pub struct AggrCommitment(pub BigInt);

impl Hash for AggrCommitment {
    fn hash<H: Hasher>(&self, hasher: &mut H) {
        self.0.to_bytes().hash(hasher);
    }
}

#[derive(PartialEq, Debug, Clone, Serialize, Deserialize)]
pub struct Reveal(pub SignSecondMsg);

impl Hash for Reveal {
    fn hash<H: Hasher>(&self, hasher: &mut H) {
        // TODO fix collision risk
        let SignSecondMsg { R, blind_factor } = self.0.clone();
        R.to_bytes(false).hash(hasher);
        AggrCommitment(blind_factor).hash(hasher)
    }
}

impl Eq for Reveal {}

impl Committed {
    pub fn commit(
        our_key: &protocols::ExpandedKeyPair,
        node_key: &protocols::ExpandedKeyPair,
        message: Vec<u8>,
        rng: &mut impl Rng,
    ) -> Result<(SignedCommitment, Self), AggregateSigningError> {
        let (ephemeral_key, commit, our_signature) =
            aggsig::create_ephemeral_key_and_commit_rng(our_key, &message, rng);
        let s = Committed {
            ephemeral_key,
            our_signature,
            message,
            our_key: our_key.clone(),
        };
        let sc = SignedCommitment::create(AggrCommitment(commit.commitment), node_key, our_key)?;
        Ok((sc, s))
    }

    pub async fn reveal(
        self,
        node_info: &NodeInfo,
        commitments: Vec<SignedCommitment>,
    ) -> Result<(SignSecondMsg, Revealed), AggregateSigningError> {
        let (commitments, signing_public_keys) = node_info
            .signed_by_every_node(commitments)
            .await?
            .into_iter()
            .unzip();
        Ok((
            self.our_signature.clone(),
            Revealed {
                commitments,
                committed: self,
                signing_public_keys,
            },
        ))
    }
}

#[derive(Clone)]
pub struct Revealed {
    commitments: Vec<AggrCommitment>,
    signing_public_keys: Vec<Point<Ed25519>>,
    committed: Committed,
}

impl Revealed {
    pub fn combine(
        self,
        signature_parts: Vec<SignSecondMsg>,
        node_info: &NodeInfo,
    ) -> Result<protocols::Signature, AggregateSigningError> {
        // Check the commitments have the correct signatures
        for (commit, partial_sig) in self.commitments.iter().zip(signature_parts.iter()) {
            check_commitment(&partial_sig.R, &partial_sig.blind_factor, &commit.0)?;
        }
        // TODO less copying
        let rs: Vec<_> = signature_parts.into_iter().map(|s| s.R).collect();
        let r_tot = aggsig::get_R_tot(&rs);

        let key_agg = KeyAgg::key_aggregation_n(&self.signing_public_keys, node_info.our_index);

        let ephemeral_key = self.committed.ephemeral_key;

        let partial_sig = aggsig::partial_sign(
            &ephemeral_key.r,
            &self.committed.our_key,
            &key_agg.hash,
            &r_tot,
            &key_agg.apk,
            &self.committed.message,
        );

        Ok(partial_sig)
    }
}

// Stores info about the other nodes we're interacting with
pub struct NodeInfo {
    pub nodes_public_keys: RwLock<Option<Vec<Point<Ed25519>>>>,
    pub our_index: usize,
}

impl NodeInfo {
    pub fn new(our_index: usize, nodes_public_keys: Option<Vec<Point<Ed25519>>>) -> Self {
        Self {
            our_index,
            nodes_public_keys: RwLock::new(nodes_public_keys),
        }
    }

    async fn signed_by_every_node(
        &self,
        signed: Vec<SignedCommitment>,
    ) -> Result<Vec<(AggrCommitment, Point<Ed25519>)>, AggregateSigningError> {
        self.nodes_public_keys
            .read()
            .await
            .as_ref()
            .ok_or(AggregateSigningError::NodeKeysUnavailable)?
            .iter()
            .zip(signed.iter())
            .map(|(public_key, signed)| signed.verify(public_key))
            .collect()
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SignedCommitment {
    pub commitment: AggrCommitment,
    /// This is the public key we're currently signing with,
    /// not the node public key that generated the signature
    pub signing_public_key: Point<Ed25519>,
    /// Signature used to verify the signing public key in case a rogue one is
    /// inserted later on.
    pub signing_public_key_sig: Signature,
    /// This is signed with the node public key
    pub signature: Signature,
}

impl SignedCommitment {
    pub fn create(
        commitment: AggrCommitment,
        node_key: &protocols::ExpandedKeyPair,
        signing_keys: &protocols::ExpandedKeyPair,
    ) -> Result<Self, AggregateSigningError> {
        let to_sign = Self::serialize(&commitment, &signing_keys.public_key)?;
        let signature = aggsig::sign_single(b"", signing_keys);
        let signing_public_key_sig = to_dalek_signature(&signature)?;

        // This is awkward, we should move more stuff over to dalek later on
        let signature = aggsig::sign_single(&to_sign, node_key);
        let signature = to_dalek_signature(&signature)?;
        Ok(SignedCommitment {
            commitment,
            signing_public_key: signing_keys.public_key.clone(),
            signature,
            signing_public_key_sig,
        })
    }

    pub fn verify(
        &self,
        public_key: &Point<Ed25519>,
    ) -> Result<(AggrCommitment, Point<Ed25519>), AggregateSigningError> {
        let public_key = to_dalek_public_key(public_key)?;
        let message = Self::serialize(&self.commitment, &self.signing_public_key)?;
        public_key
            .verify(&message, &self.signature)
            .map_err(|e| AggregateSigningError::SignatureVerificationFailed(anyhow::anyhow!(e)))?;

        let signing_public_key = to_dalek_public_key(&self.signing_public_key)?;
        signing_public_key
            .verify(b"", &self.signing_public_key_sig)
            .map_err(|e| AggregateSigningError::SignatureVerificationFailed(anyhow::anyhow!(e)))?;

        Ok((self.commitment.clone(), self.signing_public_key.clone()))
    }

    fn serialize(
        commitment: &AggrCommitment,
        pk: &Point<Ed25519>,
    ) -> Result<Vec<u8>, AggregateSigningError> {
        let content = serde_json::to_vec(&(commitment, pk))
            .map_err(|e| AggregateSigningError::DataConversionFailure(anyhow::anyhow!(e)))?;
        // Makes signature collisions less likely
        let mut message = b"SignedCommitment::serialize".to_vec();
        message.extend(content);
        Ok(message)
    }
}

pub fn check_commitment(
    r_to_test: &Point<Ed25519>,
    blind_factor: &BigInt,
    comm: &BigInt,
) -> Result<(), AggregateSigningError> {
    let computed_comm = &HashCommitment::<Sha512>::create_commitment_with_user_defined_randomness(
        &r_to_test.y_coord().unwrap(),
        blind_factor,
    );
    if computed_comm != comm {
        // TODO check this is safe to share in case of error
        // Should be because everything is provided by the caller I think
        Err(AggregateSigningError::InvalidCommitment(
            r_to_test.clone(),
            blind_factor.clone(),
            computed_comm.clone(),
            comm.clone(),
        ))
    } else {
        Ok(())
    }
}

#[cfg(test)]
mod tests {
    use crate::transaction::from_dalek_signature;

    use super::*;
    use curv::elliptic::curves::{Ed25519, Point};
    use ed25519_dalek::{SignatureError, Verifier};
    use multi_party_eddsa::protocols::ExpandedKeyPair;

    fn verify_dalek(
        pk: &Point<Ed25519>,
        sig: &protocols::Signature,
        msg: &[u8],
    ) -> Result<(), SignatureError> {
        let mut sig_bytes = [0u8; 64];
        sig_bytes[..32].copy_from_slice(&sig.R.to_bytes(true));
        sig_bytes[32..].copy_from_slice(&sig.s.to_bytes());

        let dalek_pub = ed25519_dalek::PublicKey::from_bytes(&pk.to_bytes(true)).unwrap();
        let dalek_sig = ed25519_dalek::Signature::from_bytes(&sig_bytes).unwrap();

        dalek_pub.verify(msg, &dalek_sig)
    }

    fn create_rogue_commit(message: &[u8], commitments: &[SignedCommitment]) -> SignedCommitment {
        let ks = || (ExpandedKeyPair::create(), ExpandedKeyPair::create());
        // Also generate a public key for the rogue key
        let (rogue_node_key, rogue_key) = ks();

        // Create rogue commitments to be inserted in to the list
        let rogue_pk = commitments
            .iter()
            .fold(rogue_key.public_key.clone(), |acc, c| {
                acc - &c.signing_public_key
            });

        let rogue_sig = aggsig::sign_single(b"", &rogue_key);
        let rogue_sig = commitments
            .iter()
            .map(|c| from_dalek_signature(c.signing_public_key_sig).unwrap())
            .fold(rogue_sig, |acc, s| protocols::Signature {
                R: acc.R - s.R,
                s: acc.s - s.s,
            });

        let (_ephemeral_key, commit, _our_signature) =
            aggsig::create_ephemeral_key_and_commit_rng(&rogue_key, message, &mut OsRng);
        let mut rogue_commit = SignedCommitment::create(
            AggrCommitment(commit.commitment),
            &rogue_node_key,
            &rogue_key,
        )
        .unwrap();
        rogue_commit.signing_public_key = rogue_pk;
        rogue_commit.signing_public_key_sig = to_dalek_signature(&rogue_sig).unwrap();
        rogue_commit
    }

    #[tokio::test]
    async fn rogue_attack() {
        // Generate node keys and signing keys
        let ks = || (ExpandedKeyPair::create(), ExpandedKeyPair::create());
        let (n1, k1) = ks();
        let (n2, k2) = ks();
        let (n3, k3) = ks();

        let nodes_public_keys = vec![
            n1.public_key.clone(),
            n2.public_key.clone(),
            n3.public_key.clone(),
        ];

        let ni = |n| NodeInfo::new(n, Some(nodes_public_keys.clone()));

        // Set up nodes with that config
        let s1 = SigningState::new();
        let s2 = SigningState::new();
        let s3 = SigningState::new();

        let message = b"message in a bottle".to_vec();

        let mut commitments = vec![
            s1.get_commitment(&k1, &n1, message.clone()).await.unwrap(),
            s2.get_commitment(&k2, &n2, message.clone()).await.unwrap(),
            s3.get_commitment(&k3, &n3, message.clone()).await.unwrap(),
        ];
        // Insert in the rogue key to be detected later.
        commitments.push(create_rogue_commit(&message, &commitments));

        let reveals = vec![
            s1.get_reveal(&ni(0), commitments.clone()).await.unwrap(),
            s2.get_reveal(&ni(1), commitments.clone()).await.unwrap(),
            s3.get_reveal(&ni(2), commitments.clone()).await.unwrap(),
        ];

        let sig_shares = vec![
            s1.get_signature_share(&ni(0), reveals.clone())
                .await
                .unwrap(),
            s2.get_signature_share(&ni(1), reveals.clone())
                .await
                .unwrap(),
            s3.get_signature_share(&ni(2), reveals).await.unwrap(),
        ];

        let signing_keys: Vec<_> = commitments
            .iter()
            .map(|c| c.signing_public_key.clone())
            .collect();
        let aggrigate_key = KeyAgg::key_aggregation_n(&signing_keys, 0);

        let signature = aggsig::add_signature_parts(&sig_shares);
        let verified = verify_dalek(&aggrigate_key.apk, &signature, &message);
        assert!(
            verified.is_err(),
            "Expected rogue key to be detected and create an invalid proof"
        );
    }

    #[tokio::test]
    async fn aggregate_signatures() {
        // Generate node keys and signing keys
        let ks = || (ExpandedKeyPair::create(), ExpandedKeyPair::create());
        let (n1, k1) = ks();
        let (n2, k2) = ks();
        let (n3, k3) = ks();

        let nodes_public_keys = vec![
            n1.public_key.clone(),
            n2.public_key.clone(),
            n3.public_key.clone(),
        ];

        let ni = |n| NodeInfo::new(n, Some(nodes_public_keys.clone()));

        // Set up nodes with that config
        let s1 = SigningState::new();
        let s2 = SigningState::new();
        let s3 = SigningState::new();

        let message = b"message in a bottle".to_vec();

        let commitments = vec![
            s1.get_commitment(&k1, &n1, message.clone()).await.unwrap(),
            s2.get_commitment(&k2, &n2, message.clone()).await.unwrap(),
            s3.get_commitment(&k3, &n3, message.clone()).await.unwrap(),
        ];

        let reveals = vec![
            s1.get_reveal(&ni(0), commitments.clone()).await.unwrap(),
            s2.get_reveal(&ni(1), commitments.clone()).await.unwrap(),
            s3.get_reveal(&ni(2), commitments.clone()).await.unwrap(),
        ];

        let sig_shares = vec![
            s1.get_signature_share(&ni(0), reveals.clone())
                .await
                .unwrap(),
            s2.get_signature_share(&ni(1), reveals.clone())
                .await
                .unwrap(),
            s3.get_signature_share(&ni(2), reveals).await.unwrap(),
        ];

        let signing_keys: Vec<_> = commitments
            .iter()
            .map(|c| c.signing_public_key.clone())
            .collect();
        let aggrigate_key = KeyAgg::key_aggregation_n(&signing_keys, 0);

        let signature = aggsig::add_signature_parts(&sig_shares);
        verify_dalek(&aggrigate_key.apk, &signature, &message).unwrap();
    }
}

'''
'''--- mpc-recovery/src/sign_node/migration.rs ---
//! Module that defines all the migrating logic for the sign node
//! when we want to rotate the key if our sign node gets compromised.

use aes_gcm::Aes256Gcm;
use anyhow::Context;

use crate::gcp::value::{FromValue, IntoValue};
use crate::gcp::GcpService;

use super::user_credentials::EncryptedUserCredentials;

pub async fn rotate_cipher(
    node_id: usize,
    old_cipher: &Aes256Gcm,
    new_cipher: &Aes256Gcm,
    src_gcp_service: &GcpService,
    dest_gcp_service: &GcpService,
) -> anyhow::Result<()> {
    // TODO: replace with less memory intensive method such that we don't run out of memory
    let entities = src_gcp_service
        .fetch_entities::<EncryptedUserCredentials>()
        .await?;

    for entity in entities {
        let old_entity = entity.entity.context("`entity` attr cannot be found")?;
        let entity_path = old_entity
            .key
            .as_ref()
            .context("`key` attr cannot be found")?
            .path
            .as_ref()
            .context("`path` attr cannot be found")?[0]
            .name
            .as_ref()
            .context("`name` attr cannot be found")?;
        let entity_node_id = entity_path
            .split('/')
            .next()
            .context("cannot retrieve entity node_id")?
            .parse::<usize>()?;

        // Check if this entity belongs to this node. This check is needed for integration tests as all
        // entities are stored in the same datastore instead of separate ones during test-time.
        if node_id != entity_node_id {
            continue;
        }

        let old_cred = EncryptedUserCredentials::from_value(old_entity.into_value())?;
        let key_pair = old_cred
            .decrypt_key_pair(old_cipher)
            .map_err(|e| anyhow::anyhow!(e))?;

        let new_cred = EncryptedUserCredentials::new(
            old_cred.node_id,
            old_cred.internal_account_id,
            new_cipher,
            key_pair,
        )?;

        // TODO: send all updates at once?
        dest_gcp_service.upsert(new_cred).await?;
    }

    Ok(())
}

'''
'''--- mpc-recovery/src/sign_node/mod.rs ---
use self::aggregate_signer::{NodeInfo, Reveal, SignedCommitment, SigningState};
use self::oidc::OidcDigest;
use self::user_credentials::EncryptedUserCredentials;
use crate::error::{MpcError, SignNodeError};
use crate::gcp::GcpService;
use crate::msg::{AcceptNodePublicKeysRequest, PublicKeyNodeRequest, SignNodeRequest};
use crate::oauth::verify_oidc_token;
use crate::primitives::InternalAccountId;
use crate::sign_node::pk_set::SignerNodePkSet;
use crate::utils::{
    check_digest_signature, claim_oidc_request_digest, claim_oidc_response_digest,
    sign_request_digest, user_credentials_request_digest,
};
use crate::NodeId;

use aes_gcm::Aes256Gcm;
use axum::routing::get;
use axum::{http::StatusCode, routing::post, Extension, Json, Router};
use axum_extra::extract::WithRejection;
use borsh::BorshSerialize;
use curv::elliptic::curves::{Ed25519, Point};
use multi_party_eddsa::protocols::{self, ExpandedKeyPair};

use near_primitives::hash::hash;
use near_primitives::signable_message::{SignableMessage, SignableMessageType};

use std::net::SocketAddr;
use std::sync::Arc;

pub mod aggregate_signer;
pub mod migration;
pub mod oidc;
pub mod pk_set;
pub mod user_credentials;

pub struct Config {
    pub gcp_service: GcpService,
    pub our_index: NodeId,
    pub node_key: ExpandedKeyPair,
    pub cipher: Aes256Gcm,
    pub port: u16,
    pub jwt_signature_pk_url: String,
}

pub async fn run(config: Config) {
    tracing::debug!("running a sign node");
    let Config {
        gcp_service,
        our_index,
        node_key,
        cipher,
        port,
        jwt_signature_pk_url,
    } = config;
    let our_index = usize::try_from(our_index).expect("This index is way to big");

    let pk_set = gcp_service
        .get::<_, SignerNodePkSet>(format!("{}/{}", our_index, pk_set::MAIN_KEY))
        .await
        .unwrap_or_default();

    let state = Arc::new(SignNodeState {
        gcp_service,
        reqwest_client: reqwest::Client::new(),
        node_key,
        cipher,
        signing_state: SigningState::new(),
        node_info: NodeInfo::new(our_index, pk_set.map(|set| set.public_keys)),
        jwt_signature_pk_url,
    });

    let app = Router::new()
        // healthcheck endpoint
        .route(
            "/",
            get(|| async move {
                tracing::info!("node is ready to accept connections");
                StatusCode::OK
            }),
        )
        .route("/commit", post(commit))
        .route("/reveal", post(reveal))
        .route("/signature_share", post(signature_share))
        .route("/public_key", post(public_key))
        .route("/public_key_node", post(public_key_node))
        .route("/accept_pk_set", post(accept_pk_set))
        .layer(Extension(state));

    let addr = SocketAddr::from(([0, 0, 0, 0], port));
    tracing::debug!(?addr, "starting http server");
    axum::Server::bind(&addr)
        .serve(app.into_make_service())
        .await
        .unwrap();
}

struct SignNodeState {
    gcp_service: GcpService,
    reqwest_client: reqwest::Client,
    node_key: ExpandedKeyPair,
    cipher: Aes256Gcm,
    signing_state: SigningState,
    node_info: NodeInfo,
    jwt_signature_pk_url: String,
}

async fn get_or_generate_user_creds(
    state: &SignNodeState,
    internal_account_id: InternalAccountId,
) -> anyhow::Result<EncryptedUserCredentials> {
    match state
        .gcp_service
        .get::<_, EncryptedUserCredentials>(format!(
            "{}/{}",
            state.node_info.our_index, internal_account_id
        ))
        .await
    {
        Ok(Some(user_credentials)) => {
            tracing::debug!(internal_account_id, "found an existing user");
            Ok(user_credentials)
        }
        Ok(None) => {
            let user_credentials = EncryptedUserCredentials::random(
                state.node_info.our_index,
                internal_account_id.clone(),
                &state.cipher,
            )?;
            tracing::debug!(
                internal_account_id,
                public_key = ?user_credentials.public_key,
                "generating credentials for a new user"
            );
            state.gcp_service.insert(user_credentials.clone()).await?;
            Ok(user_credentials)
        }
        Err(e) => Err(e),
    }
}

async fn process_commit(
    state: Arc<SignNodeState>,
    request: SignNodeRequest,
) -> Result<SignedCommitment, SignNodeError> {
    tracing::info!(?request, "processing commit request");
    match request {
        SignNodeRequest::ClaimOidc(request) => {
            tracing::debug!(?request, "processing oidc claim request");
            // Check ID token hash signature
            let public_key = request.public_key;
            let request_digest = claim_oidc_request_digest(&request.oidc_token_hash, &public_key)?;

            match check_digest_signature(&public_key, &request.signature, &request_digest) {
                Ok(()) => tracing::debug!("claim oidc token digest signature verified"),
                Err(e) => return Err(SignNodeError::DigestSignatureVerificationFailed(e)),
            };

            // Save info about token in the database, if it's present, throw an error
            let oidc_digest = OidcDigest {
                node_id: state.node_info.our_index,
                digest: request.oidc_token_hash,
                public_key,
            };

            match state
                .gcp_service
                .get::<_, OidcDigest>(oidc_digest.to_name())
                .await
            {
                Ok(Some(stored_digest)) => {
                    if stored_digest == oidc_digest {
                        tracing::info!(?oidc_digest, "oidc token with this key is already claimed");
                    } else {
                        tracing::error!(
                            ?oidc_digest,
                            ?stored_digest,
                            "oidc token already claimed with another key"
                        );
                        return Err(SignNodeError::OidcTokenAlreadyClaimed(oidc_digest));
                    }
                }
                Ok(None) => {
                    tracing::info!(?oidc_digest, "adding oidc token digest to the database");
                    state.gcp_service.insert(oidc_digest).await?;
                }
                Err(e) => {
                    tracing::error!(
                        ?oidc_digest,
                        "failed to get oidc token digest from the database"
                    );
                    return Err(SignNodeError::Other(e));
                }
            };

            // Returned signed commitment (signature of the signature)
            let payload = match claim_oidc_response_digest(request.signature) {
                Ok(payload) => payload,
                Err(e) => return Err(e),
            };
            let response = state
                .signing_state
                .get_commitment(&state.node_key, &state.node_key, payload)
                .await
                .map_err(|e| anyhow::anyhow!(e))?;
            tracing::info!("returning signed commitment");
            Ok(response)
        }
        SignNodeRequest::SignShare(request) => {
            tracing::debug!(?request, "processing sign share request");

            // Check OIDC Token
            let oidc_token_claims = verify_oidc_token(
                &request.oidc_token,
                None,
                &state.reqwest_client,
                &state.jwt_signature_pk_url,
            )
            .await
            .map_err(SignNodeError::OidcVerificationFailed)?;
            tracing::debug!(?oidc_token_claims, "oidc token verified");

            let frp_pk = request.frp_public_key;

            // Check request FRP signature
            let digest =
                sign_request_digest(&request.delegate_action, &request.oidc_token, &frp_pk)?;
            match check_digest_signature(&frp_pk, &request.frp_signature, &digest) {
                Ok(()) => tracing::debug!("sign request digest signature verified"),
                Err(e) => return Err(SignNodeError::DigestSignatureVerificationFailed(e)),
            };

            // Check if this OIDC token was claimed
            let oidc_hash = request.oidc_token.digest_hash();

            let oidc_digest = OidcDigest {
                node_id: state.node_info.our_index,
                digest: oidc_hash,
                public_key: frp_pk,
            };

            match state
                .gcp_service
                .get::<_, OidcDigest>(oidc_digest.to_name())
                .await
            {
                Ok(Some(stored_digest)) => {
                    if stored_digest == oidc_digest {
                        tracing::info!(?oidc_digest, "oidc token was claimed with provided pk");
                    } else {
                        tracing::error!(?oidc_digest, "oidc token was claimed with another key");
                        return Err(SignNodeError::OidcTokenClaimedWithAnotherKey(oidc_digest));
                    }
                }
                Ok(None) => {
                    tracing::info!(?oidc_digest, "oidc token was not claimed");
                    return Err(SignNodeError::OidcTokenNotClaimed(oidc_digest));
                }
                Err(e) => {
                    tracing::error!(
                        ?oidc_digest,
                        "failed to get oidc token digest from the database"
                    );
                    return Err(SignNodeError::Other(e));
                }
            };

            // Get user credentials
            let internal_account_id = oidc_token_claims.get_internal_account_id();
            let user_credentials = get_or_generate_user_creds(&state, internal_account_id).await?;
            tracing::debug!("user credentials retrieved");

            // Get commitment
            let signable_message = SignableMessage::new(
                &request.delegate_action,
                SignableMessageType::DelegateAction,
            );
            let bytes = match signable_message.try_to_vec() {
                Ok(bytes) => bytes,
                Err(e) => return Err(SignNodeError::Other(e.into())),
            };
            let hash = hash(&bytes).as_bytes().to_vec();

            let response = state
                .signing_state
                .get_commitment(
                    &user_credentials.decrypt_key_pair(&state.cipher)?,
                    &state.node_key,
                    hash,
                )
                .await
                .map_err(|e| anyhow::anyhow!(e))?;
            tracing::info!("returning signed commitment");
            Ok(response)
        }
    }
}

#[tracing::instrument(level = "debug", skip_all, fields(id = state.node_info.our_index))]
async fn commit(
    Extension(state): Extension<Arc<SignNodeState>>,
    WithRejection(Json(request), _): WithRejection<Json<SignNodeRequest>, MpcError>,
) -> (StatusCode, Json<Result<SignedCommitment, String>>) {
    if let Err(msg) = check_if_ready(&state).await {
        return (StatusCode::INTERNAL_SERVER_ERROR, Json(Err(msg)));
    }

    match process_commit(state, request).await {
        Ok(signed_commitment) => (StatusCode::OK, Json(Ok(signed_commitment))),
        Err(e) => (e.code(), Json(Err(e.to_string()))),
    }
}

#[tracing::instrument(level = "debug", skip_all, fields(id = state.node_info.our_index))]
async fn reveal(
    Extension(state): Extension<Arc<SignNodeState>>,
    WithRejection(Json(request), _): WithRejection<Json<Vec<SignedCommitment>>, MpcError>,
) -> (StatusCode, Json<Result<Reveal, String>>) {
    if let Err(msg) = check_if_ready(&state).await {
        return (StatusCode::INTERNAL_SERVER_ERROR, Json(Err(msg)));
    }

    match state
        .signing_state
        .get_reveal(&state.node_info, request)
        .await
    {
        Ok(r) => {
            tracing::debug!("Successful reveal");
            (StatusCode::OK, Json(Ok(r)))
        }
        Err(e) => {
            tracing::error!("Reveal failed: {}", e);
            (e.code(), Json(Err(e.to_string())))
        }
    }
}

#[tracing::instrument(level = "debug", skip_all, fields(id = state.node_info.our_index))]
async fn signature_share(
    Extension(state): Extension<Arc<SignNodeState>>,
    WithRejection(Json(request), _): WithRejection<Json<Vec<Reveal>>, MpcError>,
) -> (StatusCode, Json<Result<protocols::Signature, String>>) {
    if let Err(msg) = check_if_ready(&state).await {
        return (StatusCode::INTERNAL_SERVER_ERROR, Json(Err(msg)));
    }

    match state
        .signing_state
        .get_signature_share(&state.node_info, request)
        .await
    {
        Ok(r) => {
            tracing::debug!("Successful signature share");
            (StatusCode::OK, Json(Ok(r)))
        }
        Err(e) => {
            tracing::error!("Signature share failed: {}", e);
            (e.code(), Json(Err(e.to_string())))
        }
    }
}

async fn process_public_key(
    state: Arc<SignNodeState>,
    request: PublicKeyNodeRequest,
) -> Result<Point<Ed25519>, SignNodeError> {
    // Check OIDC Token
    let oidc_token_claims = verify_oidc_token(
        &request.oidc_token,
        None,
        &state.reqwest_client,
        &state.jwt_signature_pk_url,
    )
    .await
    .map_err(SignNodeError::OidcVerificationFailed)?;

    let frp_pk = request.frp_public_key;
    // Check the request signature
    let digest = user_credentials_request_digest(&request.oidc_token, &frp_pk)?;
    match check_digest_signature(&frp_pk, &request.frp_signature, &digest) {
        Ok(()) => tracing::debug!("user credentials digest signature verified"),
        Err(e) => return Err(SignNodeError::DigestSignatureVerificationFailed(e)),
    };

    // Check if this OIDC token was claimed
    let oidc_hash = request.oidc_token.digest_hash();

    let oidc_digest = OidcDigest {
        node_id: state.node_info.our_index,
        digest: oidc_hash,
        public_key: frp_pk,
    };

    match state
        .gcp_service
        .get::<_, OidcDigest>(oidc_digest.to_name())
        .await
    {
        Ok(Some(stored_digest)) => {
            if stored_digest == oidc_digest {
                tracing::info!(?oidc_digest, "oidc token was claimed with provided pk");
            } else {
                tracing::error!(?oidc_digest, "oidc token was claimed with another key");
                return Err(SignNodeError::OidcTokenClaimedWithAnotherKey(oidc_digest));
            }
        }
        Ok(None) => {
            tracing::info!(?oidc_digest, "oidc token was not claimed");
            return Err(SignNodeError::OidcTokenNotClaimed(oidc_digest));
        }
        Err(e) => {
            tracing::error!(
                ?oidc_digest,
                "failed to get oidc token digest from the database"
            );
            return Err(SignNodeError::Other(e));
        }
    };

    let internal_acc_id = oidc_token_claims.get_internal_account_id();
    match get_or_generate_user_creds(&state, internal_acc_id).await {
        Ok(user_credentials) => Ok(user_credentials.public_key().clone()),
        Err(err) => Err(SignNodeError::Other(err)),
    }
}

#[tracing::instrument(level = "debug", skip_all, fields(id = state.node_info.our_index))]
async fn public_key(
    Extension(state): Extension<Arc<SignNodeState>>,
    WithRejection(Json(request), _): WithRejection<Json<PublicKeyNodeRequest>, MpcError>,
) -> (StatusCode, Json<Result<Point<Ed25519>, String>>) {
    let result = process_public_key(state, request).await;
    match result {
        Ok(pk_point) => (StatusCode::OK, Json(Ok(pk_point))),
        Err(e) => (e.code(), Json(Err(e.to_string()))),
    }
}

#[allow(clippy::type_complexity)]
#[tracing::instrument(level = "debug", skip_all, fields(id = state.node_info.our_index))]
async fn public_key_node(
    Extension(state): Extension<Arc<SignNodeState>>,
    WithRejection(Json(_), _): WithRejection<Json<()>, MpcError>,
) -> (StatusCode, Json<Result<(usize, Point<Ed25519>), String>>) {
    (
        StatusCode::OK,
        Json(Ok((
            state.node_info.our_index,
            state.node_key.public_key.clone(),
        ))),
    )
}

#[tracing::instrument(level = "debug", skip_all, fields(id = state.node_info.our_index))]
async fn accept_pk_set(
    Extension(state): Extension<Arc<SignNodeState>>,
    WithRejection(Json(request), _): WithRejection<Json<AcceptNodePublicKeysRequest>, MpcError>,
) -> (StatusCode, Json<Result<String, String>>) {
    let index = state.node_info.our_index;
    if request.public_keys.get(index) != Some(&state.node_key.public_key) {
        tracing::error!("provided secret share does not match the node id");
        return (StatusCode::BAD_REQUEST, Json(Err(format!(
            "Sign node could not accept the public keys: current node index={index} does not match up"))));
    }

    let mut public_keys = state.node_info.nodes_public_keys.write().await;
    if let Some(pk_set) = public_keys.as_ref() {
        if pk_set == &request.public_keys {
            return (
                StatusCode::OK,
                Json(Ok(
                    "This node is already initialized with provided public keys".to_string(),
                )),
            );
        } else {
            return (
                StatusCode::BAD_REQUEST,
                Json(Err(
                    "This node is already initialized with different public keys".to_string(),
                )),
            );
        }
    }
    tracing::debug!("Setting node public keys => {:?}", request.public_keys);
    public_keys.replace(request.public_keys.clone());
    match state
        .gcp_service
        .insert(SignerNodePkSet {
            node_id: state.node_info.our_index,
            public_keys: request.public_keys,
        })
        .await
    {
        Ok(_) => (
            StatusCode::OK,
            Json(Ok("Successfully set node public keys".to_string())),
        ),
        Err(err) => {
            tracing::error!("Failed to save pk set due to GCP error: {err}");
            (
                StatusCode::INTERNAL_SERVER_ERROR,
                Json(Ok("failed to save node public keys".to_string())),
            )
        }
    }
}

/// Validate whether the current state of the sign node is useable or not.
async fn check_if_ready(state: &SignNodeState) -> Result<(), String> {
    let public_keys = state.node_info.nodes_public_keys.read().await;
    if public_keys.is_none() {
        return Err(
            "Sign node is not ready yet: waiting on all public keys from leader node".into(),
        );
    }

    Ok(())
}

'''
'''--- mpc-recovery/src/sign_node/oidc.rs ---
use std::collections::HashMap;

use borsh::{self, BorshDeserialize, BorshSerialize};
use chrono::{Duration, Utc};
use google_datastore1::api::{Key, PathElement};
use hex::FromHex;
use jsonwebtoken as jwt;
use jwt::{encode, Algorithm, DecodingKey, EncodingKey, Header};
use near_primitives::utils::generate_random_string;
use serde::{Deserialize, Serialize};

use near_crypto::PublicKey;

use crate::{
    error::MpcError,
    gcp::{
        error::ConvertError,
        value::{FromValue, IntoValue, Value},
        KeyKind,
    },
    oauth::IdTokenClaims,
};

#[derive(Clone, Debug, PartialEq, Serialize, Deserialize, BorshSerialize, BorshDeserialize)]
pub struct OidcHash([u8; 32]);

impl AsRef<[u8]> for OidcHash {
    fn as_ref(&self) -> &[u8] {
        &self.0
    }
}

impl FromHex for OidcHash {
    type Error = anyhow::Error;

    fn from_hex<T: AsRef<[u8]>>(hex: T) -> anyhow::Result<Self> {
        let bytes = <[u8; 32]>::from_hex(hex)?;
        Ok(Self(bytes))
    }
}

#[derive(Clone, Debug, PartialEq, Serialize, Deserialize, BorshSerialize, BorshDeserialize)]
#[serde(transparent)]
pub struct OidcToken {
    data: String,
}

impl OidcToken {
    pub fn new(data: &str) -> Self {
        Self { data: data.into() }
    }

    pub fn digest_hash(&self) -> OidcHash {
        let hasher = sha2::Digest::chain(sha2::Sha256::default(), self.data.as_bytes());
        let hash = <[u8; 32]>::try_from(sha2::Digest::finalize(hasher).as_slice())
            .expect("Hash is the wrong size");
        OidcHash(hash)
    }

    pub fn random_valid() -> Self {
        // This key corresponds to the public key in test-oidc-provider/src/main.rs
        let rsa_pem_key = "-----BEGIN RSA PRIVATE KEY-----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-----END RSA PRIVATE KEY-----";

        Self {
            data: create_jwt_token(rsa_pem_key),
        }
    }

    pub fn invalid() -> Self {
        // This key does not correspond to the public key in test-oidc-provider/src/main.rs
        let rsa_pem_key = "-----BEGIN RSA PRIVATE KEY-----MIIJKQIBAAKCAgEA3r9gsy3+aRIOWRNnzieBQaxHfcusXiedp/OWfWn0EkN9U1D03Jo9NVzVdoKTsCN7Z9+wpRpWzqi2uetoiqRQT2V1rsdUB0prnGd4wK/UKKxxQTzAXNFxV6BKfBIlEne25iQjS0jMuhk5DtvdYykFIgahyUj4hD5N3JxXBD+U/d1QQBXG4n6sYzM4PXyNCnvVz5Je5G+ODt5ZngntTz8LMzDfSc9SphPTkwVSGeoj+I4WyaQ5J6tfJbu4xFMlfyk0pGr79UxBMr9JABpTMu/asctp3ewp87FT9uEtfy8SKE9f9qBuAiSEl7q7poXmNg2VXV/1DCy/NC4xi4nTwopLQ5dzNevig4q7qDMtMakW5+y/ohWDHswnMzDXKCCSv6IIfR3CbFHrLPZu93Fo65aJb/TqECtddJWOXmlweyLYBoe+nJHGjFUBMMJUha+J340a05yjCZCAfoSmJJVuU3ahKnRbPDXMR9660x1ltTkD9BZ0noNqaqj101XMBgzlBvFIbiEmq3iPghCk8zVFTamNFqkeZOe/lHM94mi5Qmu1+qYOYw4ZUwSxJZ0uxt0pYRyvpjS1KmS+9wa/pZ8Br7UfSir7sA3PKdWBeJ40jsw73o3uQSpHu6qIob3sfjz1SHbOFiISJ1+H/MXlNbMs0YkgA4kH3tZghyYkAEMLf5Vc5zsCAwEAAQKCAgEAqUYuqnwtdpOuK6s/m78Rz2KpAcQiPXtFqDjJCI3YWXjIaOSA8JSWJ1NhNSqOKbENOycXCqE1jt9P3YI0dAfisDOedzArf07i8H0Bmw0D4dUKTFVqqh7QT5MUh60SVzJ63/Jej/vG+TXp0ozrdUvbBrybfmfh1D201g5JYoUfKL1jGxBxj/ZL8ycdejyIworRNWk6i8bq4gm/eQZ6PVrfnAtr5J+VY3h1tKi6d88jfuQcFSij9q2ZJQe/phK50CT0SG61AvjsIzCSvW1EBNWaELtQvMGYMAV2lYsSFDElT1TizH2mnCI8UUIrEKV5CWLRO6CMjLAErhbct/oJ3zFRd6TyCePKUJRUpmlj9FAcnr3DDPxqEuwJAU70nGryAM/h6VourKM0ncrR1tNkv7aEArp3kakkml8Twukr/ZmUFwjqj3q09NkC6HY/1tkrhuxCEeek3PgZUBV+emw/iAzM0TA5Nq5UJRKuq7pvJiFt223danb1xcZwVUl14xN4XLKgp+LGLr9xtlHYcXW2qGeiXLsolK2oF1KsCYnw55SvHa4594DhbCUJXoq+JGPO4thoMqxshxNOZbcpsvijcFFwuBtDROGVkPz2w0Mt6wTTnZTbqM5hzOd1EvgQbz8ItecMTdNfhw0PtVjwHxR8+E7hbxDf0Yaw6nXTubmsLhnrHAECggEBAPnusbzgZlppik8wQ6SOxtPciaDDxT/ttUIGHoudB45TOMEO5Gx7QflN+r1Z25c8FSqdZJ8dc/4tZzlzO+npX52GsICqFX/jllcgn2d6pRe3813D7IreI3QefLEq5eZh7dojZzajQQ1zZLyPR91QJlu/P56W60SZzZ65jWnsjp8eiuqVW9EH53FWXpj34mMNeHelNMlnVQR8dds+C45LF+MGIyJpDrcs+lXyIO6G3FdfcHySRk2JvqwpJxOHwtGqcVpN/1yOLXQPfnJyaJ0evCV+3U53nr1I0UOBENWl0rku9pbkaaIWc1mkm9ljAEp1jbhofUxx/Hf8gmSmkOTCGIECggEBAOQnu3tzlgfE2fKn9vDPMU6qFmHWJ6gqs7L0bOmTJx112hA3Oj/wQIYVu2WFAK7z6N8tYFAegve8PpGtpIQyJjiREiN4NTaoB7aDwFJJVQYgs2oobecHPuHS2Kr9+QY4IhLqwYc3PLE585ryl6C5bs1vUavkhJ0DfWOe9YPDMlZ+tSkMdhgohdE2wRz4VBI9Y+/wpVfzmT9oZUOYMmpoglinTC5CTa+0tvyo/IX8MLkAn97V36E+gh4E9Jd96MBVZt5QOJKwL1ZdRYP6VHju8WOY1OkvOuCIXDkE+jnPXNKPvUlGZsQCOtuEzOZJ96xeRfAgjQg5FqnOA6Y7xW88gbsCggEAVWTw5Y/maM3Wq+fZtMfztz+K5pr9MjKN09kzZpBonIBiy9PCyC31BLFYEoo5NRsaQE02rAbsMtRgiIiO2AUc3j2+4Lc8UU35eBt1W23UKp53UHo4v9nWUz53bDE0C9s54WZnRYvSFj5vFN3/t+ZCtOZLXmxCRlYmoyzS3HYu5L8Sx8PwcyM4OMlB2RIZD67yki6oMohTzAyaWCaC3ENcDf1y07cBiCSeA++OwPDjKBc739Q6oROHSltlNo8USX7q6+fqcD1D2nvQwFnG1KhDsKwAAWdtnU7b8SyQC+90aEFbj4LLdM4m62IKvePNnaM8oN1SsmPf1z83bhxbNU38AQKCAQEAproyU6C//qVn79+2oXuHuMiq2ow5Jrct4pSkEnyqlOjOlhMFyjuzq0iuTR3IxhEQGCd8vo/NfWRfBO4zzzcmnyfEbY8ms+5O1J2rKXbVX0j+U5F/3th4p2YBV9OI63aRz+kly74d6BVFY/HrxFQ+GHpE4Kx6DJPEScyb9dHrMzIdCQZGNplGUQEGVjlSlpGuOmVNLtyhHKkZdy/9h60fs9Ft5lAlnUUeg7yp7O/CWy+NpLX+WkLnqzBL3XjxYbwHFGbjMK73qNE4P53rpQRX+kRxMoaFLBf57OEqSpyyZF0OIkIETzCh+lEtuwxKpfeufDANX/j4Cta17AC54vQAiQKCAQAuXNcReho6YGglpsnfADw/H3L1to+JaBsEOWlwq9dbql/jo060n33rqtNYX33jOe+56J8L+poiJcDY6ZPHAeAIaBl+rT6T+m67wShaSXIC4IDwohtLgYw/sHoN7RBuh1JjNo7D0KRiBgorq9jyhqEPoXnwXBAgJhkUUwqLE+XzZsvlvZHUk0tVsN09ZraXh+CHv1jGBCp/coMLf5hZuObyuqIVQPLghvlKHhtt7q6+UuvLsIBhl+aU8CbUBLWpVYODkjadVSutfWcDTh2IVz9b38LCh2bcYCkBz6xYq+7vN82sUyzsyesviaJbCKcl3DQBwQMMi+iuP/ZPt9zoHxDq-----END RSA PRIVATE KEY-----";

        Self {
            data: create_jwt_token(rsa_pem_key),
        }
    }

    // NOTE: code taken directly from jsonwebtoken::verify_signature and modified to suit
    // our needs (i.e. not knowing audience and issuer ahead of time).
    pub fn decode(
        &self,
        key: &DecodingKey,
    ) -> anyhow::Result<(jwt::Header, IdTokenClaims, String)> {
        let mut parts = self.as_ref().rsplitn(2, '.');
        let (Some(signature), Some(message)) = (parts.next(), parts.next()) else {
            anyhow::bail!("could not split into signature and message for OIDC token");
        };
        let mut parts = message.rsplitn(2, '.');
        let (Some(payload), Some(header)) = (parts.next(), parts.next()) else {
            anyhow::bail!("could not split into payload and header for OIDC token");
        };
        let header: jwt::Header = serde_json::from_slice(&b64_decode(header)?)?;
        let claims: IdTokenClaims = serde_json::from_slice(&b64_decode(payload)?)?;

        if !jwt::crypto::verify(signature, message.as_bytes(), key, header.alg)? {
            anyhow::bail!("InvalidSignature");
        }

        Ok((header, claims, signature.into()))
    }
}

fn b64_decode<T: AsRef<[u8]>>(input: T) -> anyhow::Result<Vec<u8>> {
    base64::Engine::decode(&base64::engine::general_purpose::URL_SAFE_NO_PAD, input)
        .map_err(Into::into)
}

fn create_jwt_token(rsa_pem_key: &str) -> String {
    let private_key_der = rsa_pem_key.as_bytes().to_vec();

    let aud = "test_audience".to_string();

    let my_claims = IdTokenClaims {
        iss: format!("https://securetoken.google.com/{}", aud),
        sub: generate_random_string(7),
        aud,
        exp: (Utc::now() + Duration::hours(1)).timestamp() as usize,
    };

    let token = match encode(
        &Header::new(Algorithm::RS256),
        &my_claims,
        &EncodingKey::from_rsa_pem(&private_key_der).unwrap(),
    ) {
        Ok(t) => OidcToken::new(t.as_str()),
        Err(e) => panic!("Failed to encode token: {}", e),
    };
    token.to_string()
}

impl std::str::FromStr for OidcToken {
    type Err = MpcError;

    fn from_str(s: &str) -> Result<Self, Self::Err> {
        Ok(Self::new(s))
    }
}

impl std::fmt::Display for OidcToken {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        f.write_str(&self.data)
    }
}

impl AsRef<str> for OidcToken {
    fn as_ref(&self) -> &str {
        &self.data
    }
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct OidcDigest {
    pub node_id: usize,
    pub digest: OidcHash,
    pub public_key: PublicKey,
}

impl KeyKind for OidcDigest {
    fn kind() -> String {
        "OidcDigest".to_string()
    }
}

impl IntoValue for OidcDigest {
    fn into_value(self) -> Value {
        let mut properties = HashMap::new();
        properties.insert(
            "node_id".to_string(),
            Value::IntegerValue(self.node_id as i64),
        );
        properties.insert(
            "digest".to_string(),
            Value::StringValue(hex::encode(&self.digest)),
        );
        properties.insert(
            "public_key".to_string(),
            Value::StringValue(serde_json::to_string(&self.public_key).unwrap()),
        );

        Value::EntityValue {
            key: Key {
                path: Some(vec![PathElement {
                    kind: Some(Self::kind()),
                    name: Some(self.to_name()),
                    id: None,
                }]),
                partition_id: None,
            },
            properties,
        }
    }
}

impl FromValue for OidcDigest {
    fn from_value(value: Value) -> Result<Self, ConvertError> {
        match value {
            Value::EntityValue { mut properties, .. } => {
                let (_, node_id) = properties
                    .remove_entry("node_id")
                    .ok_or_else(|| ConvertError::MissingProperty("node_id".to_string()))?;
                let node_id = i64::from_value(node_id)? as usize;
                let (_, digest) = properties
                    .remove_entry("digest")
                    .ok_or_else(|| ConvertError::MissingProperty("digest".to_string()))?;
                let digest = hex::decode(String::from_value(digest)?)
                    .map_err(|_| ConvertError::MalformedProperty("digest".to_string()))?;
                let digest = <[u8; 32]>::try_from(digest)
                    .map_err(|_| ConvertError::MalformedProperty("digest".to_string()))?;
                let digest = OidcHash(digest);

                let (_, public_key) = properties
                    .remove_entry("public_key")
                    .ok_or_else(|| ConvertError::MissingProperty("public_key".to_string()))?;
                let public_key = String::from_value(public_key)?;
                let public_key = serde_json::from_str(&public_key)
                    .map_err(|_| ConvertError::MalformedProperty("public_key".to_string()))?;

                Ok(Self {
                    node_id,
                    digest,
                    public_key,
                })
            }
            error => Err(ConvertError::UnexpectedPropertyType {
                expected: "entity".to_string(),
                got: format!("{:?}", error),
            }),
        }
    }
}

impl OidcDigest {
    pub fn to_name(&self) -> String {
        format!("{}/{}", self.node_id, hex::encode(&self.digest))
    }
}

#[cfg(test)]
mod tests {
    use std::str::FromStr;

    use crate::utils::claim_oidc_request_digest;

    use super::*;

    #[test]
    fn test_oidc_digest_from_and_to_value() {
        let oidc_token = OidcToken::random_valid();
        let oidc_token_hash = oidc_token.digest_hash();
        let user_pk =
            PublicKey::from_str("ed25519:J75xXmF7WUPS3xCm3hy2tgwLCKdYM1iJd4BWF8sWVnae").unwrap();

        let oidc_request_digest = match claim_oidc_request_digest(&oidc_token_hash, &user_pk) {
            Ok(digest) => digest,
            Err(err) => panic!("Failed to create digest: {:?}", err),
        };

        let digest = <[u8; 32]>::try_from(oidc_request_digest).expect("Hash was wrong size");
        let digest = OidcHash(digest);

        let oidc_digest = OidcDigest {
            node_id: 1,
            digest: digest.clone(),
            public_key: user_pk,
        };

        let val = oidc_digest.clone().into_value();

        let reconstructed_oidc_digest = match OidcDigest::from_value(val) {
            Ok(oidc_digest) => oidc_digest,
            Err(err) => panic!("Failed to reconstruct OidcDigest: {:?}", err),
        };

        // Wrong digest for comparison
        let public_key_2 = "ed25519:EBNJGHctB2LuDsCyMWrfwW87QrAob2kKzoS98PR5vjJn";
        let oidc_digest_2 = OidcDigest {
            node_id: 1,
            digest,
            public_key: public_key_2.parse().expect("Failed to parse public key"),
        };

        assert_eq!(oidc_digest, reconstructed_oidc_digest);
        assert_ne!(oidc_digest_2, reconstructed_oidc_digest);
    }

    #[test]
    fn test_oidc_to_name() {
        let oidc_token = OidcToken::random_valid();
        let user_pk =
            PublicKey::from_str("ed25519:J75xXmF7WUPS3xCm3hy2tgwLCKdYM1iJd4BWF8sWVnae").unwrap();
        let oidc_token_hash = oidc_token.digest_hash();

        let digest = match claim_oidc_request_digest(&oidc_token_hash, &user_pk) {
            Ok(digest) => digest,
            Err(err) => panic!("Failed to create digest: {:?}", err),
        };

        let digest = <[u8; 32]>::try_from(digest).expect("Hash was wrong size");
        let digest = OidcHash(digest);

        let oidc_digest = OidcDigest {
            node_id: 1,
            digest,
            public_key: user_pk,
        };

        let name = oidc_digest.to_name();

        assert_eq!(
            name,
            format!(
                "{}/{}",
                oidc_digest.node_id,
                hex::encode(oidc_digest.digest)
            )
        );
    }
}

'''
'''--- mpc-recovery/src/sign_node/pk_set.rs ---
use crate::gcp::{
    error::ConvertError,
    value::{FromValue, IntoValue, Value},
    KeyKind,
};
use curv::elliptic::curves::{Ed25519, Point};
use google_datastore1::api::{Key, PathElement};
use serde::{Deserialize, Serialize};
use std::collections::HashMap;

pub const MAIN_KEY: &str = "main";

#[derive(Serialize, Deserialize, Clone)]
pub struct SignerNodePkSet {
    pub node_id: usize,
    pub public_keys: Vec<Point<Ed25519>>,
}

impl KeyKind for SignerNodePkSet {
    fn kind() -> String {
        "SignerNodePkSet".to_string()
    }
}

impl IntoValue for SignerNodePkSet {
    fn into_value(self) -> Value {
        let mut properties = HashMap::new();
        properties.insert(
            "node_id".to_string(),
            Value::IntegerValue(self.node_id as i64),
        );
        properties.insert(
            "public_keys".to_string(),
            Value::StringValue(serde_json::to_string(&self.public_keys).unwrap()),
        );
        Value::EntityValue {
            key: Key {
                path: Some(vec![PathElement {
                    kind: Some(SignerNodePkSet::kind()),
                    name: Some(format!("{}/{}", self.node_id, MAIN_KEY)),
                    id: None,
                }]),
                partition_id: None,
            },
            properties,
        }
    }
}

impl FromValue for SignerNodePkSet {
    fn from_value(value: Value) -> Result<Self, ConvertError> {
        match value {
            Value::EntityValue { mut properties, .. } => {
                let (_, node_id) = properties
                    .remove_entry("node_id")
                    .ok_or_else(|| ConvertError::MissingProperty("node_id".to_string()))?;
                let node_id = i64::from_value(node_id)? as usize;
                let (_, public_keys) = properties
                    .remove_entry("public_keys")
                    .ok_or_else(|| ConvertError::MissingProperty("public_keys".to_string()))?;
                let public_keys = String::from_value(public_keys)?;
                let public_keys = serde_json::from_str(&public_keys)
                    .map_err(|_| ConvertError::MalformedProperty("public_keys".to_string()))?;

                Ok(Self {
                    node_id,
                    public_keys,
                })
            }
            value => Err(ConvertError::UnexpectedPropertyType {
                expected: "entity".to_string(),
                got: format!("{:?}", value),
            }),
        }
    }
}

'''
'''--- mpc-recovery/src/sign_node/user_credentials.rs ---
use crate::{
    gcp::{
        error::ConvertError,
        value::{FromValue, IntoValue, Value},
        KeyKind,
    },
    primitives::InternalAccountId,
};
use aes_gcm::{aead::Aead, Aes256Gcm, Nonce};
use curv::elliptic::curves::{Ed25519, Point};
use google_datastore1::api::{Key, PathElement};
use multi_party_eddsa::protocols::ExpandedKeyPair;
use serde::{Deserialize, Serialize};
use std::collections::HashMap;

#[derive(Serialize, Deserialize, Clone)]
pub struct EncryptedUserCredentials {
    pub node_id: usize,
    pub internal_account_id: InternalAccountId,
    pub public_key: Point<Ed25519>,
    pub encrypted_key_pair: Vec<u8>,
}

impl KeyKind for EncryptedUserCredentials {
    fn kind() -> String {
        "EncryptedUserCredentials".to_string()
    }
}

impl IntoValue for EncryptedUserCredentials {
    fn into_value(self) -> Value {
        let mut properties = HashMap::new();
        properties.insert(
            "node_id".to_string(),
            Value::IntegerValue(self.node_id as i64),
        );
        properties.insert(
            "internal_account_id".to_string(),
            Value::StringValue(self.internal_account_id.clone()),
        );
        properties.insert(
            "public_key".to_string(),
            Value::StringValue(serde_json::to_string(&self.public_key).unwrap()),
        );
        properties.insert(
            "encrypted_key_pair".to_string(),
            Value::StringValue(
                serde_json::to_string(&hex::encode(self.encrypted_key_pair)).unwrap(),
            ),
        );
        Value::EntityValue {
            key: Key {
                path: Some(vec![PathElement {
                    kind: Some(EncryptedUserCredentials::kind()),
                    name: Some(format!("{}/{}", self.node_id, self.internal_account_id)),
                    id: None,
                }]),
                partition_id: None,
            },
            properties,
        }
    }
}

impl FromValue for EncryptedUserCredentials {
    fn from_value(value: Value) -> Result<Self, ConvertError> {
        match value {
            Value::EntityValue { mut properties, .. } => {
                let (_, node_id) = properties
                    .remove_entry("node_id")
                    .ok_or_else(|| ConvertError::MissingProperty("node_id".to_string()))?;
                let node_id = i64::from_value(node_id)? as usize;
                let (_, internal_account_id) = properties
                    .remove_entry("internal_account_id")
                    .ok_or_else(|| {
                        ConvertError::MissingProperty("internal_account_id".to_string())
                    })?;
                let internal_account_id = String::from_value(internal_account_id)?;

                let (_, public_key) = properties
                    .remove_entry("public_key")
                    .ok_or_else(|| ConvertError::MissingProperty("public_key".to_string()))?;
                let public_key = String::from_value(public_key)?;
                let public_key = serde_json::from_str(&public_key)
                    .map_err(|_| ConvertError::MalformedProperty("public_key".to_string()))?;

                let (_, encrypted_key_pair) = properties
                    .remove_entry("encrypted_key_pair")
                    .ok_or_else(|| {
                        ConvertError::MissingProperty("encrypted_key_pair".to_string())
                    })?;
                let encrypted_key_pair = String::from_value(encrypted_key_pair)?;
                let encrypted_key_pair = serde_json::from_str(&encrypted_key_pair)
                    .ok()
                    .and_then(|hex: String| hex::decode(hex).ok())
                    .ok_or_else(|| {
                        ConvertError::MalformedProperty("encrypted_key_pair".to_string())
                    })?;

                Ok(Self {
                    node_id,
                    internal_account_id,
                    public_key,
                    encrypted_key_pair,
                })
            }
            value => Err(ConvertError::UnexpectedPropertyType {
                expected: "entity".to_string(),
                got: format!("{:?}", value),
            }),
        }
    }
}

impl EncryptedUserCredentials {
    pub fn random(
        node_id: usize,
        internal_account_id: InternalAccountId,
        cipher: &Aes256Gcm,
    ) -> anyhow::Result<Self> {
        let key_pair = ExpandedKeyPair::create();
        Self::new(node_id, internal_account_id, cipher, key_pair)
    }

    pub fn new(
        node_id: usize,
        internal_account_id: InternalAccountId,
        cipher: &Aes256Gcm,
        key_pair: ExpandedKeyPair,
    ) -> anyhow::Result<Self> {
        let nonce = Nonce::from_slice(&[0u8; 12]);
        let encrypted_key_pair = cipher
            .encrypt(nonce, serde_json::to_vec(&key_pair)?.as_slice())
            .unwrap();
        Ok(Self {
            node_id,
            internal_account_id,
            public_key: key_pair.public_key,
            encrypted_key_pair,
        })
    }

    pub fn public_key(&self) -> &Point<Ed25519> {
        &self.public_key
    }

    pub fn decrypt_key_pair(&self, cipher: &Aes256Gcm) -> anyhow::Result<ExpandedKeyPair> {
        let nonce = Nonce::from_slice(&[0u8; 12]);
        let key_pair = cipher
            .decrypt(nonce, self.encrypted_key_pair.as_slice())
            .unwrap();
        Ok(serde_json::from_slice(&key_pair)?)
    }
}

'''
'''--- mpc-recovery/src/transaction.rs ---
use crate::error::{AggregateSigningError, LeaderNodeError};
use crate::msg::{SignNodeRequest, SignShareNodeRequest};
use crate::sign_node::aggregate_signer::{Reveal, SignedCommitment};
use crate::sign_node::oidc::OidcToken;

use anyhow::Context;
use curv::elliptic::curves::{Ed25519, Point};
use ed25519_dalek::Signature;
use futures::{future, FutureExt};
use hyper::StatusCode;
use multi_party_eddsa::protocols::aggsig::KeyAgg;
use multi_party_eddsa::protocols::{self, aggsig};
use serde::de::DeserializeOwned;
use serde::{Deserialize, Serialize};
use serde_json::json;

use near_crypto::{InMemorySigner, PublicKey};
use near_primitives::delegate_action::{DelegateAction, NonDelegateAction, SignedDelegateAction};
use near_primitives::signable_message::{SignableMessage, SignableMessageType};
use near_primitives::transaction::{Action, FunctionCallAction};
use near_primitives::types::{AccountId, Nonce};

#[derive(Serialize, Deserialize, Debug, Clone)]
pub struct CreateAccountOptions {
    pub full_access_keys: Option<Vec<PublicKey>>,
    pub limited_access_keys: Option<Vec<LimitedAccessKey>>,
    pub contract_bytes: Option<Vec<u8>>,
}

impl std::fmt::Display for CreateAccountOptions {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        let json_string = serde_json::to_string(self).map_err(|_| std::fmt::Error)?;
        write!(f, "{}", json_string)
    }
}

#[derive(Serialize, Deserialize, Debug, Clone)]
/// Information about any limited access keys that are being added to the account as part of `create_account_advanced`.
pub struct LimitedAccessKey {
    /// The public key of the limited access key.
    pub public_key: PublicKey,
    /// The amount of yoctoNEAR$ that can be spent on Gas by this key.
    pub allowance: String,
    /// Which contract should this key be allowed to call.
    pub receiver_id: AccountId,
    /// Which methods should this key be allowed to call.
    pub method_names: String,
}

#[allow(clippy::too_many_arguments)]
pub fn new_create_account_delegate_action(
    signer: &InMemorySigner,
    new_account_id: &AccountId,
    new_account_options: &CreateAccountOptions,
    near_root_account: &AccountId,
    nonce: Nonce,
    max_block_height: u64,
) -> anyhow::Result<SignedDelegateAction> {
    let create_acc_action = Action::FunctionCall(FunctionCallAction {
        method_name: "create_account_advanced".to_string(),
        args: json!({
            "new_account_id": new_account_id,
            "options": new_account_options,
        })
        .to_string()
        .into_bytes(),
        gas: 300_000_000_000_000,
        deposit: 0,
    });

    let delegate_create_acc_action = NonDelegateAction::try_from(create_acc_action)?;

    let delegate_action = DelegateAction {
        sender_id: signer.account_id.clone(),
        receiver_id: near_root_account.clone(),
        actions: vec![delegate_create_acc_action],
        nonce,
        max_block_height,
        public_key: signer.public_key.clone(),
    };

    let signable_message =
        SignableMessage::new(&delegate_action, SignableMessageType::DelegateAction);
    let signature = signable_message.sign(signer);

    Ok(SignedDelegateAction {
        delegate_action,
        signature,
    })
}

pub async fn get_mpc_signature(
    client: &reqwest::Client,
    sign_nodes: &[String],
    oidc_token: &OidcToken,
    delegate_action: DelegateAction,
    frp_signature: &Signature,
    frp_public_key: &near_crypto::PublicKey,
) -> Result<Signature, LeaderNodeError> {
    let sig_share_request = SignNodeRequest::SignShare(SignShareNodeRequest {
        oidc_token: oidc_token.clone(),
        delegate_action,
        frp_signature: *frp_signature,
        frp_public_key: frp_public_key.clone(),
    });

    let signature = sign_payload_with_mpc(client, sign_nodes, sig_share_request).await?;
    Ok(signature)
}

#[derive(thiserror::Error, Debug)]
#[allow(dead_code)]
pub enum NodeSignError {
    #[error("call error: {0}")]
    CallError(#[from] NodeCallError),
    #[error("{0}")]
    Other(#[from] anyhow::Error),
}

pub async fn sign_payload_with_mpc(
    client: &reqwest::Client,
    sign_nodes: &[String],
    sig_share_request: SignNodeRequest,
) -> Result<Signature, LeaderNodeError> {
    let commitments: Vec<SignedCommitment> =
        call_all_nodes(client, sign_nodes, "commit", sig_share_request).await?;

    let reveals: Vec<Reveal> = call_all_nodes(client, sign_nodes, "reveal", commitments).await?;

    let signature_shares: Vec<protocols::Signature> =
        call_all_nodes(client, sign_nodes, "signature_share", reveals).await?;

    let raw_sig = aggsig::add_signature_parts(&signature_shares);

    to_dalek_signature(&raw_sig).map_err(LeaderNodeError::AggregateSigningFailed)
}

#[derive(thiserror::Error, Debug)]
#[allow(dead_code)]
pub enum NodeCallError {
    #[error("client error: {0}")]
    ClientError(String, StatusCode),
    #[error("server error: {0}")]
    ServerError(String),
    #[error("{0}")]
    Other(anyhow::Error),
}

/// Call every node with an identical payload and send the response
pub async fn call_all_nodes<Req: Serialize, Res: DeserializeOwned>(
    client: &reqwest::Client,
    sign_nodes: &[String],
    path: &str,
    request: Req,
) -> Result<Vec<Res>, LeaderNodeError> {
    let responses = sign_nodes.iter().map(|sign_node| {
        client
            .post(format!("{}/{}", sign_node, path))
            .header("content-type", "application/json")
            .json(&request)
            .send()
            .then(|r| async move {
                let ok = r.map_err(LeaderNodeError::NetworkRejection)?;
                let status_code = ok.status();
                let ok = ok
                    .json::<Result<Res, String>>()
                    .await
                    .map_err(|e| LeaderNodeError::DataConversionFailure(e.into()))?;

                match ok {
                    Ok(res) => Ok(res),
                    Err(e) if status_code.is_client_error() => {
                        Err(LeaderNodeError::ClientError(e, status_code))
                    }
                    Err(e) => Err(LeaderNodeError::ServerError(e)),
                }
            })
    });

    future::join_all(responses).await.into_iter().collect()
}

pub fn from_dalek_signature(sig: ed25519_dalek::Signature) -> anyhow::Result<protocols::Signature> {
    let bytes = sig.to_bytes();
    Ok(protocols::Signature {
        R: Point::from_bytes(&bytes[..32])?,
        s: curv::elliptic::curves::Scalar::from_bytes(&bytes[32..])?,
    })
}

pub fn to_dalek_signature(
    sig: &protocols::Signature,
) -> Result<ed25519_dalek::Signature, AggregateSigningError> {
    let mut sig_bytes = [0u8; 64];
    sig_bytes[..32].copy_from_slice(&sig.R.to_bytes(true));
    sig_bytes[32..].copy_from_slice(&sig.s.to_bytes());

    // let dalek_pub = ed25519_dalek::PublicKey::from_bytes(&*pk.to_bytes(true)).unwrap();
    ed25519_dalek::Signature::from_bytes(&sig_bytes)
        .context("to dalek signature conversion failed")
        .map_err(AggregateSigningError::DataConversionFailure)
}

pub fn to_dalek_combined_public_key(
    public_keys: &[Point<Ed25519>],
) -> Result<ed25519_dalek::PublicKey, AggregateSigningError> {
    let combined = KeyAgg::key_aggregation_n(public_keys, 0).apk;
    to_dalek_public_key(&combined)
}

pub fn to_dalek_public_key(
    public_key: &Point<Ed25519>,
) -> Result<ed25519_dalek::PublicKey, AggregateSigningError> {
    ed25519_dalek::PublicKey::from_bytes(&public_key.to_bytes(true))
        .context("to dalek key conversion failed")
        .map_err(AggregateSigningError::DataConversionFailure)
}

'''
'''--- mpc-recovery/src/utils.rs ---
use anyhow::Context;
use borsh::BorshSerialize;
use ed25519_dalek::Signature;
use near_crypto::PublicKey;
use near_primitives::delegate_action::DelegateAction;
use sha2::{Digest, Sha256};

use crate::error::SignNodeError;
use crate::primitives::HashSalt;
use crate::sign_node::oidc::{OidcHash, OidcToken};

pub fn claim_oidc_request_digest(
    oidc_token_hash: &OidcHash,
    frp_public_key: &PublicKey,
) -> anyhow::Result<Vec<u8>> {
    // As per the readme
    // To verify the signature of the message verify:
    // sha256.hash(Borsh.serialize<u32>(SALT + 0) ++ Borsh.serialize<[u8]>(oidc_token_hash))
    let mut hasher = Sha256::default();
    BorshSerialize::serialize(&HashSalt::ClaimOidcRequest.get_salt(), &mut hasher)
        .context("Serialization failed")?;
    BorshSerialize::serialize(&oidc_token_hash, &mut hasher).context("Serialization failed")?;
    BorshSerialize::serialize(frp_public_key, &mut hasher).context("Serialization failed")?;
    Ok(hasher.finalize().to_vec())
}

pub fn claim_oidc_response_digest(users_signature: Signature) -> Result<Vec<u8>, SignNodeError> {
    // As per the readme
    // If you successfully claim the token you will receive a signature in return of:
    // sha256.hash(Borsh.serialize<u32>(SALT + 1) ++ Borsh.serialize<[u8]>(signature))
    let mut hasher = Sha256::default();
    BorshSerialize::serialize(&HashSalt::ClaimOidcResponse.get_salt(), &mut hasher)
        .context("Serialization failed")?;
    BorshSerialize::serialize(&users_signature.to_bytes(), &mut hasher)
        .context("Serialization failed")?;
    Ok(hasher.finalize().to_vec())
}

pub fn sign_request_digest(
    delegate_action: &DelegateAction,
    oidc_token: &OidcToken,
    frp_public_key: &PublicKey,
) -> Result<Vec<u8>, SignNodeError> {
    let mut hasher = Sha256::default();
    BorshSerialize::serialize(&HashSalt::SignRequest.get_salt(), &mut hasher)
        .context("Serialization failed")?;
    BorshSerialize::serialize(delegate_action, &mut hasher).context("Serialization failed")?;
    BorshSerialize::serialize(oidc_token, &mut hasher).context("Serialization failed")?;
    BorshSerialize::serialize(frp_public_key, &mut hasher).context("Serialization failed")?;
    Ok(hasher.finalize().to_vec())
}

pub fn user_credentials_request_digest(
    oidc_token: &OidcToken,
    frp_public_key: &PublicKey,
) -> anyhow::Result<Vec<u8>> {
    let mut hasher = Sha256::default();
    BorshSerialize::serialize(&HashSalt::UserCredentialsRequest.get_salt(), &mut hasher)
        .context("Serialization failed")?;
    BorshSerialize::serialize(oidc_token, &mut hasher).context("Serialization failed")?;
    BorshSerialize::serialize(frp_public_key, &mut hasher).context("Serialization failed")?;
    Ok(hasher.finalize().to_vec())
}

pub fn check_digest_signature(
    public_key: &PublicKey,
    signature: &Signature,
    digest: &[u8],
) -> Result<(), anyhow::Error> {
    if !near_crypto::Signature::ED25519(*signature).verify(digest, public_key) {
        Err(anyhow::anyhow!(
            "Public key {}, digest {} and signature {} don't match",
            &public_key,
            &hex::encode(digest),
            &signature
        ))
    } else {
        Ok(())
    }
}

pub fn sign_digest(
    request_digest: &[u8],
    user_secret_key: &near_crypto::SecretKey,
) -> anyhow::Result<Signature> {
    match user_secret_key.sign(request_digest) {
        near_crypto::Signature::ED25519(signature) => Ok(signature),
        _ => anyhow::bail!("Wrong signature type"),
    }
}

'''
'''--- node/Cargo.toml ---
[package]
name = "mpc-recovery-node"
version = "0.1.0"
edition = "2021"

[[bin]]
name = "mpc-recovery-node"
path = "src/main.rs"

[dependencies]
anyhow = { version = "1", features = ["backtrace"] }
async-trait = "0.1"
aws-config = "0.54.0"
aws-sdk-s3 = "0.24.0"
aws-types = "0.54.0"
axum = { version = "0.6.19" }
axum-extra = "0.7"
cait-sith = { git = "https://github.com/LIT-Protocol/cait-sith.git", features = [
    "k256",
], rev = "8ad2316"}
clap = { version = "4.2", features = ["derive", "env"] }
chrono = "0.4.24"
google-datastore1 = "5"
google-secretmanager1 = "5"
hex = "0.4.3"
hkdf = "0.12.4"
highway = "1.1.0"
hyper = { version = "0.14", features = ["full"] }
hyper-rustls = { version = "=0.23", features = ["http2"] }
k256 = { version = "0.13.1", features = ["sha256", "ecdsa", "serde"] }
local-ip-address = "0.5.4"
rand = "0.8"
reqwest = { version = "0.11.16", features = ["json"] }
sha2 = "0.10.8"
serde = { version = "1", features = ["derive"] }
serde_json = "1"
thiserror = "1"
tokio = { version = "1.28", features = ["full"] }
tokio-retry = "0.3"
tracing = "0.1"
tracing-subscriber = { version = "0.3", features = ["env-filter"] }
url = { version = "2.4.0", features = ["serde"] }

near-crypto = "0.17"
near-fetch = "0.0.12"
near-lake-framework = { git = "https://github.com/near/near-lake-framework-rs.git", rev = "dc0f1f9"} # branch = "daniyar/upgrade-sdk"
near-lake-primitives = { git = "https://github.com/near/near-lake-framework-rs.git", rev = "dc0f1f9" } # branch = "daniyar/upgrade-sdk"
near-primitives = "0.17.0"
near-sdk = "5.0.0-alpha.1"

mpc-contract = { path = "../contract" }
mpc-keys = { path = "../keys" }

itertools = "0.12.0"
prometheus = { version = "0.13.3" }
once_cell = "1.13.1"

[dev-dependencies]
itertools = "0.12.0"

'''
'''--- node/src/cli.rs ---
use crate::gcp::GcpService;
use crate::mesh::NetworkConfig;
use crate::protocol::presignature::PresignatureConfig;
use crate::protocol::triple::TripleConfig;
use crate::protocol::{Config, MpcSignProtocol, SignQueue};
use crate::storage::triple_storage::LockTripleNodeStorageBox;
use crate::{indexer, storage, web};
use clap::Parser;
use local_ip_address::local_ip;
use near_crypto::{InMemorySigner, SecretKey};
use near_primitives::types::AccountId;
use std::sync::Arc;
use tokio::sync::{mpsc, RwLock};
use tracing_subscriber::EnvFilter;
use url::Url;

use mpc_keys::hpke;

#[derive(Parser, Debug)]
pub enum Cli {
    Start {
        /// NEAR RPC address
        #[arg(
            long,
            env("MPC_RECOVERY_NEAR_RPC"),
            default_value("https://rpc.testnet.near.org")
        )]
        near_rpc: String,
        /// MPC contract id
        #[arg(
            long,
            env("MPC_RECOVERY_CONTRACT_ID"),
            default_value("v5.multichain-mpc-dev.testnet")
        )]
        mpc_contract_id: AccountId,
        /// This node's account id
        #[arg(long, env("MPC_RECOVERY_ACCOUNT_ID"))]
        account_id: AccountId,
        /// This node's account ed25519 secret key
        #[arg(long, env("MPC_RECOVERY_ACCOUNT_SK"))]
        account_sk: SecretKey,
        /// The web port for this server
        #[arg(long, env("MPC_RECOVERY_WEB_PORT"))]
        web_port: u16,
        // TODO: need to add in CipherPK type for parsing.
        /// The cipher public key used to encrypt messages between nodes.
        #[arg(long, env("MPC_RECOVERY_CIPHER_PK"))]
        cipher_pk: String,
        /// The cipher secret key used to decrypt messages between nodes.
        #[arg(long, env("MPC_RECOVERY_CIPHER_SK"))]
        cipher_sk: String,
        /// The secret key used to sign messages to be sent between nodes.
        #[arg(long, env("MPC_RECOVERY_SIGN_SK"))]
        sign_sk: Option<SecretKey>,
        /// NEAR Lake Indexer options
        #[clap(flatten)]
        indexer_options: indexer::Options,
        /// Local address that other peers can use to message this node.
        #[arg(long, env("MPC_RECOVERY_LOCAL_ADDRESS"))]
        my_address: Option<Url>,
        /// Storage options
        #[clap(flatten)]
        storage_options: storage::Options,
        /// At minimum, how many triples to stockpile on this node.
        #[arg(long, env("MPC_RECOVERY_MIN_TRIPLES"), default_value("20"))]
        min_triples: usize,
        /// At maximum, how many triples to stockpile on this node.
        #[arg(long, env("MPC_RECOVERY_MAX_TRIPLES"), default_value("640"))]
        max_triples: usize,

        /// At maximum, how many triple protocols can this current node introduce
        /// at the same time. This should be something like `max_concurrent_gen / num_nodes`
        #[arg(
            long,
            env("MPC_RECOVERY_MAX_CONCURRENT_INTRODUCTION"),
            default_value("2")
        )]
        max_concurrent_introduction: usize,

        /// At maximum, how many ongoing protocols for triples to be running
        /// at the same time. The rest will be queued up.
        #[arg(
            long,
            env("MPC_RECOVERY_MAX_CONCURRENT_GENERATION"),
            default_value("16")
        )]
        max_concurrent_generation: usize,

        /// At minimum, how many presignatures to stockpile on this node.
        #[arg(long, env("MPC_RECOVERY_MIN_PRESIGNATURES"), default_value("10"))]
        min_presignatures: usize,

        /// At maximum, how many presignatures to stockpile on the network.
        #[arg(long, env("MPC_RECOVERY_MAX_PRESIGNATURES"), default_value("320"))]
        max_presignatures: usize,
    },
}

impl Cli {
    pub fn into_str_args(self) -> Vec<String> {
        match self {
            Cli::Start {
                near_rpc,
                account_id,
                mpc_contract_id,
                account_sk,
                web_port,
                cipher_pk,
                cipher_sk,
                sign_sk,
                indexer_options,
                my_address,
                storage_options,
                min_triples,
                max_triples,
                max_concurrent_introduction,
                max_concurrent_generation,
                min_presignatures,
                max_presignatures,
            } => {
                let mut args = vec![
                    "start".to_string(),
                    "--near-rpc".to_string(),
                    near_rpc,
                    "--mpc-contract-id".to_string(),
                    mpc_contract_id.to_string(),
                    "--account-id".to_string(),
                    account_id.to_string(),
                    "--account-sk".to_string(),
                    account_sk.to_string(),
                    "--web-port".to_string(),
                    web_port.to_string(),
                    "--cipher-pk".to_string(),
                    cipher_pk,
                    "--cipher-sk".to_string(),
                    cipher_sk,
                    "--min-triples".to_string(),
                    min_triples.to_string(),
                    "--max-triples".to_string(),
                    max_triples.to_string(),
                    "--max-concurrent-introduction".to_string(),
                    max_concurrent_introduction.to_string(),
                    "--max-concurrent-generation".to_string(),
                    max_concurrent_generation.to_string(),
                    "--min-presignatures".to_string(),
                    min_presignatures.to_string(),
                    "--max-presignatures".to_string(),
                    max_presignatures.to_string(),
                ];
                if let Some(sign_sk) = sign_sk {
                    args.extend(["--sign-sk".to_string(), sign_sk.to_string()]);
                }
                if let Some(my_address) = my_address {
                    args.extend(["--my-address".to_string(), my_address.to_string()]);
                }
                args.extend(indexer_options.into_str_args());
                args.extend(storage_options.into_str_args());
                args
            }
        }
    }
}

pub fn run(cmd: Cli) -> anyhow::Result<()> {
    // Install global collector configured based on RUST_LOG env var.
    let mut subscriber = tracing_subscriber::fmt()
        .with_thread_ids(true)
        .with_env_filter(EnvFilter::from_default_env());
    // Check if running in Google Cloud Run: https://cloud.google.com/run/docs/container-contract#services-env-vars
    if std::env::var("K_SERVICE").is_ok() {
        // Disable colored logging as it messes up GCP's log formatting
        subscriber = subscriber.with_ansi(false);
    }
    subscriber.init();
    let _span = tracing::trace_span!("cli").entered();

    match cmd {
        Cli::Start {
            near_rpc,
            web_port,
            mpc_contract_id,
            account_id,
            account_sk,
            cipher_pk,
            cipher_sk,
            sign_sk,
            indexer_options,
            my_address,
            storage_options,
            min_triples,
            max_triples,
            max_concurrent_introduction,
            max_concurrent_generation,
            min_presignatures,
            max_presignatures,
        } => {
            let sign_queue = Arc::new(RwLock::new(SignQueue::new()));
            tokio::runtime::Builder::new_multi_thread()
                .enable_all()
                .build()?
                .block_on(async {
                    let (sender, receiver) = mpsc::channel(16384);
                    let gcp_service = GcpService::init(&account_id, &storage_options).await?;

                    let join_handle = std::thread::spawn({
                        let options = indexer_options.clone();
                        let mpc_id = mpc_contract_id.clone();
                        let account_id = account_id.clone();
                        let sign_queue = sign_queue.clone();
                        let gcp = gcp_service.clone();
                        move || indexer::run(options, mpc_id, account_id, sign_queue, gcp).unwrap()
                    });

                    let key_storage =
                        storage::secret_storage::init(Some(&gcp_service), &storage_options);
                    let triple_storage: LockTripleNodeStorageBox = Arc::new(RwLock::new(
                        storage::triple_storage::init(Some(&gcp_service), &account_id),
                    ));

                    let sign_sk = sign_sk.unwrap_or_else(|| account_sk.clone());
                    let my_address = my_address.unwrap_or_else(|| {
                        let my_ip = local_ip().unwrap();
                        Url::parse(&format!("http://{my_ip}:{web_port}")).unwrap()
                    });
                    tracing::info!(%my_address, "address detected");
                    let rpc_client = near_fetch::Client::new(&near_rpc);
                    tracing::debug!(rpc_addr = rpc_client.rpc_addr(), "rpc client initialized");
                    let signer = InMemorySigner::from_secret_key(account_id.clone(), account_sk);
                    let (protocol, protocol_state) = MpcSignProtocol::init(
                        my_address,
                        mpc_contract_id.clone(),
                        account_id,
                        rpc_client.clone(),
                        signer.clone(),
                        receiver,
                        sign_queue.clone(),
                        key_storage,
                        triple_storage,
                        Config {
                            triple_cfg: TripleConfig {
                                min_triples,
                                max_triples,
                                max_concurrent_introduction,
                                max_concurrent_generation,
                            },
                            presig_cfg: PresignatureConfig {
                                min_presignatures,
                                max_presignatures,
                            },
                            network_cfg: NetworkConfig {
                                cipher_pk: hpke::PublicKey::try_from_bytes(&hex::decode(
                                    cipher_pk,
                                )?)?,
                                sign_sk,
                            },
                        },
                    );
                    tracing::debug!("protocol initialized");
                    let protocol_handle = tokio::spawn(async move { protocol.run().await });
                    tracing::debug!("protocol thread spawned");
                    let cipher_sk = hpke::SecretKey::try_from_bytes(&hex::decode(cipher_sk)?)?;
                    let web_handle = tokio::spawn(async move {
                        web::run(web_port, sender, cipher_sk, protocol_state).await
                    });
                    tracing::debug!("protocol http server spawned");

                    protocol_handle.await??;
                    web_handle.await??;
                    tracing::debug!("spinning down");

                    join_handle.join().unwrap();
                    anyhow::Ok(())
                })?;
        }
    }

    Ok(())
}

'''
'''--- node/src/gcp/error.rs ---
#[derive(Debug, thiserror::Error)]
pub enum ConvertError {
    #[error("expected property `{0}` was missing")]
    MissingProperty(String),
    #[error("expected property type `{expected}`, got `{got}`")]
    UnexpectedPropertyType { expected: String, got: String },
    #[error("property `{0}` is malfored")]
    MalformedProperty(String),
    #[error("parsing integar from string erred out: `{0}`")]
    ParseInt(String),
}

#[derive(thiserror::Error, Debug)]
pub enum SecretStorageError {
    #[error("GCP error: {0}")]
    GcpError(#[from] google_secretmanager1::Error),
    #[error("IO error: {0}")]
    IoError(#[from] std::io::Error),
    #[error("(de)serialization error: {0}")]
    SerdeError(#[from] serde_json::Error),
}

#[derive(thiserror::Error, Debug)]
pub enum DatastoreStorageError {
    #[error("GCP error: {0}")]
    GcpError(#[from] google_datastore1::Error),
    #[error("IO error: {0}")]
    IoError(#[from] std::io::Error),
    #[error("(de)serialization error: {0}")]
    SerdeError(#[from] serde_json::Error),
    #[error("datastore value conversion error: {0}")]
    ConvertError(ConvertError),
    #[error("fetch_entities error: `{0}`")]
    FetchEntitiesError(String),
    #[error("could not find entity: {0}")]
    EntityNotFound(String),
}

impl From<ConvertError> for DatastoreStorageError {
    fn from(err: ConvertError) -> Self {
        DatastoreStorageError::ConvertError(err)
    }
}

'''
'''--- node/src/gcp/mod.rs ---
pub mod error;
pub mod value;

use self::value::{FromValue, IntoValue};
use crate::gcp::error::DatastoreStorageError;
use crate::storage;
use google_datastore1::api::Filter;
use google_datastore1::api::{
    CommitRequest, Entity, EntityResult, Key, KindExpression, LookupRequest, Mutation, PathElement,
    Query, RunQueryRequest,
};
use google_datastore1::oauth2::AccessTokenAuthenticator;
use google_datastore1::Datastore;
use google_secretmanager1::api::{AddSecretVersionRequest, SecretPayload};
use google_secretmanager1::oauth2::authenticator::ApplicationDefaultCredentialsTypes;
use google_secretmanager1::oauth2::{
    ApplicationDefaultCredentialsAuthenticator, ApplicationDefaultCredentialsFlowOpts,
};
use google_secretmanager1::SecretManager;
use hyper::client::HttpConnector;
use hyper_rustls::HttpsConnector;
use near_lake_primitives::AccountId;

pub type SecretResult<T> = std::result::Result<T, error::SecretStorageError>;

#[derive(Clone)]
pub struct SecretManagerService {
    secret_manager: SecretManager<HttpsConnector<HttpConnector>>,
    project_id: String,
}

impl SecretManagerService {
    #[tracing::instrument(level = "debug", skip_all, fields(name = name.as_ref()))]
    pub async fn load_secret<T: AsRef<str>>(&self, name: T) -> SecretResult<Option<Vec<u8>>> {
        let (_, response) = self
            .secret_manager
            .projects()
            .secrets_versions_access(&format!(
                "projects/{}/secrets/{}/versions/latest",
                self.project_id,
                name.as_ref()
            ))
            .doit()
            .await?;
        match response.payload {
            // GCP does not allow to upload empty secrets, so we reserve 1-byte values as a
            // placeholder for empty secrets.
            Some(SecretPayload {
                data: Some(data), ..
            }) if data.len() > 1 => Ok(Some(data)),
            _ => {
                tracing::info!("failed to load existing key share, presuming it is missing");
                Ok(None)
            }
        }
    }

    pub async fn store_secret<T: AsRef<str>>(&mut self, data: &[u8], name: T) -> SecretResult<()> {
        self.secret_manager
            .projects()
            .secrets_add_version(
                AddSecretVersionRequest {
                    payload: Some(SecretPayload {
                        data: Some(data.to_owned()),
                        ..Default::default()
                    }),
                },
                &format!("projects/{}/secrets/{}", self.project_id, name.as_ref()),
            )
            .doit()
            .await?;
        Ok(())
    }
}

#[derive(Clone)]
pub struct DatastoreService {
    datastore: Datastore<HttpsConnector<HttpConnector>>,
    project_id: String,
    env: String,
    is_emulator: bool,
}

pub type DatastoreResult<T> = std::result::Result<T, error::DatastoreStorageError>;

pub trait Keyable: KeyKind {
    fn key(&self) -> Key;
}

pub trait KeyKind {
    fn kind() -> String;
}

impl DatastoreService {
    pub fn is_emulator(&self) -> bool {
        self.is_emulator
    }

    #[tracing::instrument(level = "debug", skip_all, fields(key = name_key.to_string()))]
    pub async fn get<K: ToString, T: FromValue + KeyKind>(
        &self,
        name_key: K,
    ) -> DatastoreResult<T> {
        let request = LookupRequest {
            keys: Some(vec![Key {
                path: Some(vec![PathElement {
                    // We can't create multiple datastore databases in GCP, so we have to suffix
                    // type kinds with env (`dev`, `prod`).
                    kind: Some(format!("{}-{}", T::kind(), self.env)),
                    name: Some(name_key.to_string()),
                    id: None,
                }]),
                partition_id: None,
            }]),
            read_options: None,
            database_id: Some("".to_string()),
        };
        let (_, response) = self
            .datastore
            .projects()
            .lookup(request, &self.project_id)
            .doit()
            .await?;
        match response
            .found
            .and_then(|mut results| results.pop())
            .and_then(|result| result.entity)
        {
            Some(found_entity) => Ok(T::from_value(found_entity.into_value())?),
            None => Err(DatastoreStorageError::EntityNotFound(name_key.to_string())),
        }
    }

    #[tracing::instrument(level = "debug", skip_all)]
    pub async fn insert<T: IntoValue + KeyKind>(&self, value: T) -> DatastoreResult<()> {
        let mut entity = Entity::from_value(value.into_value())?;
        let path_element = entity
            .key
            .as_mut()
            .and_then(|k| k.path.as_mut())
            .and_then(|p| p.first_mut());
        if let Some(path_element) = path_element {
            // We can't create multiple datastore databases in GCP, so we have to suffix
            // type kinds with env (`dev`, `prod`).
            path_element.kind = Some(format!("{}-{}", T::kind(), self.env))
        }

        let request = CommitRequest {
            database_id: Some("".to_string()),
            mode: Some(String::from("NON_TRANSACTIONAL")),
            mutations: Some(vec![Mutation {
                insert: Some(entity),
                delete: None,
                update: None,
                base_version: None,
                upsert: None,
                update_time: None,
            }]),
            single_use_transaction: None,
            transaction: None,
        };
        let (_, _) = self
            .datastore
            .projects()
            .commit(request, &self.project_id)
            .doit()
            .await?;
        Ok(())
    }

    #[tracing::instrument(level = "debug", skip_all)]
    pub async fn update<T: IntoValue + KeyKind>(&self, value: T) -> DatastoreResult<()> {
        let mut entity = Entity::from_value(value.into_value())?;
        let path_element = entity
            .key
            .as_mut()
            .and_then(|k| k.path.as_mut())
            .and_then(|p| p.first_mut());
        if let Some(path_element) = path_element {
            // We can't create multiple datastore databases in GCP, so we have to suffix
            // type kinds with env (`dev`, `prod`).
            path_element.kind = Some(format!("{}-{}", T::kind(), self.env))
        }

        let request = CommitRequest {
            database_id: Some("".to_string()),
            mode: Some(String::from("NON_TRANSACTIONAL")),
            mutations: Some(vec![Mutation {
                insert: None,
                delete: None,
                update: Some(entity),
                base_version: None,
                upsert: None,
                update_time: None,
            }]),
            single_use_transaction: None,
            transaction: None,
        };
        let (_, _) = self
            .datastore
            .projects()
            .commit(request, &self.project_id)
            .doit()
            .await?;

        Ok(())
    }

    pub async fn upsert<T: IntoValue + KeyKind>(&self, value: T) -> DatastoreResult<()> {
        let mut entity = Entity::from_value(value.into_value())?;
        let path_element = entity
            .key
            .as_mut()
            .and_then(|k| k.path.as_mut())
            .and_then(|p| p.first_mut());
        if let Some(path_element) = path_element {
            // We can't create multiple datastore databases in GCP, so we have to suffix
            // type kinds with env (`dev`, `prod`).
            path_element.kind = Some(format!("{}-{}", T::kind(), self.env))
        }

        let request = CommitRequest {
            database_id: Some("".to_string()),
            mode: Some(String::from("NON_TRANSACTIONAL")),
            mutations: Some(vec![Mutation {
                insert: None,
                delete: None,
                update: None,
                base_version: None,
                upsert: Some(entity),
                update_time: None,
            }]),
            single_use_transaction: None,
            transaction: None,
        };

        let (_, _) = self
            .datastore
            .projects()
            .commit(request, &self.project_id)
            .doit()
            .await?;

        Ok(())
    }

    pub async fn fetch_entities<T: KeyKind>(
        &self,
        filter: Option<Filter>,
    ) -> DatastoreResult<Vec<EntityResult>> {
        let kind: String = format!("{}-{}", T::kind(), self.env);
        let req = RunQueryRequest {
            database_id: Some("".to_string()),
            partition_id: Default::default(),
            read_options: Default::default(),
            query: Some(Query {
                projection: None,
                kind: Some(vec![KindExpression { name: Some(kind) }]),
                filter,
                order: None,
                distinct_on: Some(vec![]),
                start_cursor: None,
                end_cursor: None,
                offset: None,
                limit: None,
            }),
            gql_query: None,
        };
        let (_hyper_resp, query_resp) = self
            .datastore
            .projects()
            .run_query(req, &self.project_id)
            .doit()
            .await?;
        let batch = query_resp.batch.ok_or_else(|| {
            DatastoreStorageError::FetchEntitiesError(
                "Could not retrieve batch while fetching entities".to_string(),
            )
        })?;

        batch.entity_results.ok_or_else(|| {
            DatastoreStorageError::FetchEntitiesError(
                "Could not retrieve entity results while fetching entities".to_string(),
            )
        })
    }

    #[tracing::instrument(level = "debug", skip_all)]
    pub async fn delete<T: Keyable>(&self, keyable: T) -> DatastoreResult<()> {
        let mut key = keyable.key();
        if let Some(path) = key.path.as_mut().and_then(|p| p.first_mut()) {
            path.kind = Some(format!("{}-{}", T::kind(), self.env));
        }

        let request = CommitRequest {
            database_id: Some("".to_string()),
            mode: Some(String::from("NON_TRANSACTIONAL")),
            mutations: Some(vec![Mutation {
                insert: None,
                delete: Some(key),
                update: None,
                base_version: None,
                upsert: None,
                update_time: None,
            }]),
            single_use_transaction: None,
            transaction: None,
        };
        let (_, _) = self
            .datastore
            .projects()
            .commit(request, &self.project_id)
            .doit()
            .await?;
        Ok(())
    }
}

#[derive(Clone)]
pub struct GcpService {
    pub project_id: String,
    pub datastore: DatastoreService,
    pub secret_manager: SecretManagerService,
    pub account_id: AccountId,
}

impl GcpService {
    pub async fn init(
        account_id: &AccountId,
        storage_options: &storage::Options,
    ) -> anyhow::Result<Self> {
        let project_id = storage_options.gcp_project_id.clone();
        let secret_manager;
        let client = hyper::Client::builder().build(
            hyper_rustls::HttpsConnectorBuilder::new()
                .with_native_roots()
                .https_or_http()
                .enable_http1()
                .enable_http2()
                .build(),
        );
        let datastore = if let Some(gcp_datastore_url) = storage_options.gcp_datastore_url.clone() {
            // Assuming custom GCP URL points to an emulator, so the token does not matter
            let authenticator = AccessTokenAuthenticator::builder("TOKEN".to_string())
                .build()
                .await?;
            secret_manager = SecretManager::new(client.clone(), authenticator.clone());
            let mut datastore = Datastore::new(client, authenticator);
            datastore.base_url(gcp_datastore_url.clone());
            datastore.root_url(gcp_datastore_url);
            datastore
        } else {
            let opts = ApplicationDefaultCredentialsFlowOpts::default();
            let authenticator = match ApplicationDefaultCredentialsAuthenticator::builder(opts)
                .await
            {
                ApplicationDefaultCredentialsTypes::InstanceMetadata(auth) => auth.build().await?,
                ApplicationDefaultCredentialsTypes::ServiceAccount(auth) => auth.build().await?,
            };
            secret_manager = SecretManager::new(client.clone(), authenticator.clone());
            Datastore::new(client, authenticator)
        };

        Ok(Self {
            account_id: account_id.clone(),
            datastore: DatastoreService {
                datastore,
                project_id: project_id.clone(),
                env: storage_options.env.clone(),
                is_emulator: storage_options.gcp_datastore_url.is_some(),
            },
            secret_manager: SecretManagerService {
                secret_manager,
                project_id: project_id.clone(),
            },
            project_id,
        })
    }
}

'''
'''--- node/src/gcp/value.rs ---
use google_datastore1::api::{ArrayValue, Entity, Key, LatLng};
use std::collections::HashMap;

use super::error::ConvertError;

#[derive(Debug, Clone)]
pub enum Value {
    BooleanValue(bool),
    IntegerValue(i64),
    DoubleValue(f64),
    KeyValue(Key),
    StringValue(String),
    BlobValue(Vec<u8>),
    GeoPointValue(f64, f64),
    EntityValue {
        key: Key,
        properties: HashMap<String, Value>,
    },
    ArrayValue(Vec<Value>),
}

impl Value {
    pub fn type_name(&self) -> &'static str {
        match self {
            Value::BooleanValue(_) => "bool",
            Value::IntegerValue(_) => "integer",
            Value::DoubleValue(_) => "double",
            Value::KeyValue(_) => "key",
            Value::StringValue(_) => "string",
            Value::BlobValue(_) => "blob",
            Value::GeoPointValue(_, _) => "geopoint",
            Value::EntityValue { .. } => "entity",
            Value::ArrayValue(_) => "array",
        }
    }
}

pub trait IntoValue {
    fn into_value(self) -> Value;
}

pub trait FromValue: Sized {
    fn from_value(value: Value) -> Result<Self, ConvertError>;
}

/*
 * IntoValue implementations
 */

impl IntoValue for Value {
    fn into_value(self) -> Value {
        self
    }
}

impl IntoValue for String {
    fn into_value(self) -> Value {
        Value::StringValue(self)
    }
}

impl IntoValue for &str {
    fn into_value(self) -> Value {
        String::from(self).into_value()
    }
}

impl IntoValue for i8 {
    fn into_value(self) -> Value {
        Value::IntegerValue(self as i64)
    }
}

impl IntoValue for i16 {
    fn into_value(self) -> Value {
        Value::IntegerValue(self as i64)
    }
}

impl IntoValue for i32 {
    fn into_value(self) -> Value {
        Value::IntegerValue(self as i64)
    }
}

impl IntoValue for i64 {
    fn into_value(self) -> Value {
        Value::IntegerValue(self)
    }
}

impl IntoValue for f32 {
    fn into_value(self) -> Value {
        Value::DoubleValue(self as f64)
    }
}

impl IntoValue for f64 {
    fn into_value(self) -> Value {
        Value::DoubleValue(self)
    }
}

impl IntoValue for bool {
    fn into_value(self) -> Value {
        Value::BooleanValue(self)
    }
}

impl IntoValue for Key {
    fn into_value(self) -> Value {
        Value::KeyValue(self)
    }
}

impl IntoValue for Vec<u8> {
    fn into_value(self) -> Value {
        Value::BlobValue(self.to_vec())
    }
}

impl<T> IntoValue for Vec<T>
where
    T: IntoValue,
{
    fn into_value(self) -> Value {
        Value::ArrayValue(self.into_iter().map(IntoValue::into_value).collect())
    }
}

impl From<google_datastore1::api::Value> for Value {
    fn from(value: google_datastore1::api::Value) -> Value {
        if let Some(val) = value.boolean_value {
            Value::BooleanValue(val)
        } else if let Some(val) = value.integer_value {
            Value::IntegerValue(val)
        } else if let Some(val) = value.double_value {
            Value::DoubleValue(val)
        } else if let Some(val) = value.key_value {
            Value::KeyValue(val)
        } else if let Some(val) = value.string_value {
            Value::StringValue(val)
        } else if let Some(val) = value.blob_value {
            Value::BlobValue(val)
        } else if let Some(val) = value.geo_point_value {
            Value::GeoPointValue(
                val.latitude.unwrap_or_default(),
                val.longitude.unwrap_or_default(),
            )
        } else if let Some(val) = value.entity_value {
            Value::EntityValue {
                key: val.key.unwrap_or_default(),
                properties: val
                    .properties
                    .unwrap_or_default()
                    .into_iter()
                    .map(|(k, v)| (k, Value::from(v)))
                    .collect(),
            }
        } else if let Some(val) = value.array_value {
            Value::ArrayValue(
                val.values
                    .unwrap_or_default()
                    .into_iter()
                    .map(Value::from)
                    .collect(),
            )
        } else {
            unimplemented!()
        }
    }
}

impl IntoValue for google_datastore1::api::Value {
    fn into_value(self) -> Value {
        self.into()
    }
}

impl IntoValue for google_datastore1::api::Entity {
    fn into_value(self) -> Value {
        Value::EntityValue {
            key: self.key.unwrap_or_default(),
            properties: self
                .properties
                .unwrap_or_default()
                .into_iter()
                .map(|(k, v)| (k, v.into_value()))
                .collect(),
        }
    }
}

/*
 * FromValue implementations
 */

impl FromValue for Value {
    fn from_value(value: Value) -> Result<Value, ConvertError> {
        Ok(value)
    }
}

impl FromValue for String {
    fn from_value(value: Value) -> Result<String, ConvertError> {
        match value {
            Value::StringValue(value) => Ok(value),
            _ => Err(ConvertError::UnexpectedPropertyType {
                expected: String::from("string"),
                got: String::from(value.type_name()),
            }),
        }
    }
}

impl FromValue for i64 {
    fn from_value(value: Value) -> Result<i64, ConvertError> {
        match value {
            Value::IntegerValue(value) => Ok(value),
            _ => Err(ConvertError::UnexpectedPropertyType {
                expected: String::from("integer"),
                got: String::from(value.type_name()),
            }),
        }
    }
}

impl FromValue for f64 {
    fn from_value(value: Value) -> Result<f64, ConvertError> {
        match value {
            Value::DoubleValue(value) => Ok(value),
            _ => Err(ConvertError::UnexpectedPropertyType {
                expected: String::from("double"),
                got: String::from(value.type_name()),
            }),
        }
    }
}

impl FromValue for bool {
    fn from_value(value: Value) -> Result<bool, ConvertError> {
        match value {
            Value::BooleanValue(value) => Ok(value),
            _ => Err(ConvertError::UnexpectedPropertyType {
                expected: String::from("bool"),
                got: String::from(value.type_name()),
            }),
        }
    }
}

impl FromValue for Key {
    fn from_value(value: Value) -> Result<Key, ConvertError> {
        match value {
            Value::KeyValue(value) => Ok(value),
            _ => Err(ConvertError::UnexpectedPropertyType {
                expected: String::from("key"),
                got: String::from(value.type_name()),
            }),
        }
    }
}

impl FromValue for Vec<u8> {
    fn from_value(value: Value) -> Result<Vec<u8>, ConvertError> {
        match value {
            Value::BlobValue(value) => Ok(value),
            _ => Err(ConvertError::UnexpectedPropertyType {
                expected: String::from("blob"),
                got: String::from(value.type_name()),
            }),
        }
    }
}

impl<T> FromValue for Vec<T>
where
    T: FromValue,
{
    fn from_value(value: Value) -> Result<Vec<T>, ConvertError> {
        match value {
            Value::ArrayValue(values) => {
                let values = values
                    .into_iter()
                    .map(FromValue::from_value)
                    .collect::<Result<Vec<T>, ConvertError>>()?;
                Ok(values)
            }
            _ => Err(ConvertError::UnexpectedPropertyType {
                expected: String::from("array"),
                got: String::from(value.type_name()),
            }),
        }
    }
}

impl FromValue for Entity {
    fn from_value(value: Value) -> Result<Entity, ConvertError> {
        match value {
            Value::EntityValue { key, properties } => {
                let properties = properties
                    .into_iter()
                    .map(|(k, v)| {
                        let v = FromValue::from_value(v)?;
                        Ok((k, v))
                    })
                    .collect::<Result<HashMap<String, google_datastore1::api::Value>, ConvertError>>()?;
                Ok(Entity {
                    key: Some(key),
                    properties: Some(properties),
                })
            }
            _ => Err(ConvertError::UnexpectedPropertyType {
                expected: String::from("entity"),
                got: String::from(value.type_name()),
            }),
        }
    }
}

impl FromValue for google_datastore1::api::Value {
    fn from_value(value: Value) -> Result<Self, ConvertError> {
        let result = match value {
            Value::BooleanValue(val) => google_datastore1::api::Value {
                boolean_value: Some(val),
                ..Default::default()
            },
            Value::IntegerValue(val) => google_datastore1::api::Value {
                integer_value: Some(val),
                ..Default::default()
            },
            Value::DoubleValue(val) => google_datastore1::api::Value {
                double_value: Some(val),
                ..Default::default()
            },
            Value::KeyValue(val) => google_datastore1::api::Value {
                key_value: Some(val),
                ..Default::default()
            },
            Value::StringValue(val) => google_datastore1::api::Value {
                string_value: Some(val),
                ..Default::default()
            },
            Value::BlobValue(val) => google_datastore1::api::Value {
                blob_value: Some(val),
                ..Default::default()
            },
            Value::GeoPointValue(latitude, longitude) => google_datastore1::api::Value {
                geo_point_value: Some(LatLng {
                    latitude: Some(latitude),
                    longitude: Some(longitude),
                }),
                ..Default::default()
            },
            Value::EntityValue { key, properties } => {
                let properties = properties
                    .into_iter()
                    .map(|(k, v)| FromValue::from_value(v).map(|v| (k, v)))
                    .collect::<Result<HashMap<String, google_datastore1::api::Value>, ConvertError>>()?;
                google_datastore1::api::Value {
                    entity_value: Some(Entity {
                        key: Some(key),
                        properties: Some(properties),
                    }),
                    ..Default::default()
                }
            }
            Value::ArrayValue(val) => {
                let values = val
                    .into_iter()
                    .map(FromValue::from_value)
                    .collect::<Result<Vec<google_datastore1::api::Value>, ConvertError>>()?;
                google_datastore1::api::Value {
                    array_value: Some(ArrayValue {
                        values: Some(values),
                    }),
                    ..Default::default()
                }
            }
        };
        Ok(result)
    }
}

'''
'''--- node/src/http_client.rs ---
use crate::protocol::contract::primitives::{ParticipantInfo, Participants};
use crate::protocol::message::SignedMessage;
use crate::protocol::MpcMessage;
use cait_sith::protocol::Participant;
use mpc_keys::hpke::Ciphered;
use reqwest::{Client, IntoUrl};
use std::collections::{HashMap, HashSet, VecDeque};
use std::str::Utf8Error;
use std::time::{Duration, Instant};
use tokio_retry::strategy::{jitter, ExponentialBackoff};
use tokio_retry::Retry;

// 5 minutes max to wait for this message to be sent by defaults
const MESSAGE_TIMEOUT: Duration = Duration::from_secs(5 * 60);

#[derive(Debug, thiserror::Error)]
pub enum SendError {
    #[error("http request was unsuccessful: {0}")]
    Unsuccessful(String),
    #[error("serialization unsuccessful: {0}")]
    DataConversionError(serde_json::Error),
    #[error("http client error: {0}")]
    ReqwestClientError(#[from] reqwest::Error),
    #[error("http response could not be parsed: {0}")]
    ReqwestBodyError(reqwest::Error),
    #[error("http response body is not valid utf-8: {0}")]
    MalformedResponse(Utf8Error),
    #[error("encryption error: {0}")]
    EncryptionError(String),
    #[error("http request timeout: {0}")]
    Timeout(String),
    #[error("participant is not alive: {0}")]
    ParticipantNotAlive(String),
}

async fn send_encrypted<U: IntoUrl>(
    from: Participant,
    client: &Client,
    url: U,
    message: Vec<Ciphered>,
) -> Result<(), SendError> {
    let _span = tracing::info_span!("message_request");
    let mut url = url.into_url()?;
    url.set_path("msg");
    tracing::debug!(?from, to = %url, "making http request: sending encrypted message");
    let action = || async {
        let response = client
            .post(url.clone())
            .header("content-type", "application/json")
            .json(&message)
            .send()
            .await
            .map_err(SendError::ReqwestClientError)?;
        let status = response.status();
        let response_bytes = response
            .bytes()
            .await
            .map_err(SendError::ReqwestBodyError)?;
        let response_str =
            std::str::from_utf8(&response_bytes).map_err(SendError::MalformedResponse)?;
        if status.is_success() {
            Ok(())
        } else {
            tracing::error!(
                "failed to send a message to {} with code {}: {}",
                url,
                status,
                response_str
            );
            Err(SendError::Unsuccessful(response_str.into()))
        }
    };

    let retry_strategy = ExponentialBackoff::from_millis(10).map(jitter).take(3);
    Retry::spawn(retry_strategy, action).await
}

// TODO: add in retry logic either in struct or at call site.
// TODO: add check for participant list to see if the messages to be sent are still valid.
#[derive(Default)]
pub struct MessageQueue {
    deque: VecDeque<(ParticipantInfo, MpcMessage, Instant)>,
    seen_counts: HashSet<String>,
}

impl MessageQueue {
    pub fn len(&self) -> usize {
        self.deque.len()
    }

    pub fn is_empty(&self) -> bool {
        self.deque.is_empty()
    }

    pub fn push(&mut self, info: ParticipantInfo, msg: MpcMessage) {
        self.deque.push_back((info, msg, Instant::now()));
    }

    pub async fn send_encrypted(
        &mut self,
        from: Participant,
        sign_sk: &near_crypto::SecretKey,
        client: &Client,
        participants: &Participants,
    ) -> Vec<SendError> {
        let mut failed = VecDeque::new();
        let mut errors = Vec::new();
        let mut participant_counter = HashMap::new();

        let outer = Instant::now();
        let uncompacted = self.deque.len();
        let mut encrypted = HashMap::new();
        while let Some((info, msg, instant)) = self.deque.pop_front() {
            if instant.elapsed() > message_type_to_timeout(&msg) {
                errors.push(SendError::Timeout(format!(
                    "{} message has timed out: {info:?}",
                    msg.typename(),
                )));
                continue;
            }

            if !participants.contains_key(&Participant::from(info.id)) {
                let counter = participant_counter.entry(info.id).or_insert(0);
                *counter += 1;
                failed.push_back((info, msg, instant));
                continue;
            }
            let encrypted_msg = match SignedMessage::encrypt(&msg, from, sign_sk, &info.cipher_pk) {
                Ok(encrypted) => encrypted,
                Err(err) => {
                    errors.push(SendError::EncryptionError(err.to_string()));
                    continue;
                }
            };
            let encrypted = encrypted.entry(info.id).or_insert_with(Vec::new);
            encrypted.push((encrypted_msg, (info, msg, instant)));
        }

        let mut compacted = 0;
        for (id, encrypted) in encrypted {
            for partition in partition_ciphered_256kb(encrypted) {
                let (encrypted_partition, msgs): (Vec<_>, Vec<_>) = partition.into_iter().unzip();
                // guaranteed to unwrap due to our previous loop check:
                let info = participants.get(&Participant::from(id)).unwrap();
                let account_id = &info.account_id;

                let start = Instant::now();
                crate::metrics::NUM_SEND_ENCRYPTED_TOTAL
                    .with_label_values(&[account_id])
                    .inc();
                if let Err(err) = send_encrypted(from, client, &info.url, encrypted_partition).await
                {
                    crate::metrics::NUM_SEND_ENCRYPTED_FAILURE
                        .with_label_values(&[account_id])
                        .inc();
                    crate::metrics::FAILED_SEND_ENCRYPTED_LATENCY
                        .with_label_values(&[account_id])
                        .observe(start.elapsed().as_millis() as f64);

                    // since we failed, put back all the messages related to this
                    failed.extend(msgs);
                    errors.push(err);
                } else {
                    compacted += msgs.len();
                    crate::metrics::SEND_ENCRYPTED_LATENCY
                        .with_label_values(&[account_id])
                        .observe(start.elapsed().as_millis() as f64);
                }
            }
        }

        if uncompacted > 0 {
            tracing::debug!(
                uncompacted,
                compacted,
                "{from:?} sent messages in {:?};",
                outer.elapsed()
            );
        }
        // only add the participant count if it hasn't been seen before.
        let counts = format!("{participant_counter:?}");
        if !participant_counter.is_empty() && self.seen_counts.insert(counts.clone()) {
            errors.push(SendError::ParticipantNotAlive(format!(
                "participants not responding: {counts:?}",
            )));
        }

        // Add back the failed attempts for next time.
        self.deque = failed;
        errors
    }
}

/// Encrypted message with a reference to the old message. Only the ciphered portion of this
/// type will be sent over the wire, while the original message is kept just in case things
/// go wrong somewhere and the message needs to be requeued to be sent later.
type EncryptedMessage = (Ciphered, (ParticipantInfo, MpcMessage, Instant));

fn partition_ciphered_256kb(encrypted: Vec<EncryptedMessage>) -> Vec<Vec<EncryptedMessage>> {
    let mut result = Vec::new();
    let mut current_partition = Vec::new();
    let mut current_size: usize = 0;

    for ciphered in encrypted {
        let bytesize = ciphered.0.text.len();
        if current_size + bytesize > 256 * 1024 {
            // If adding this byte vector exceeds 256kb, start a new partition
            result.push(current_partition);
            current_partition = Vec::new();
            current_size = 0;
        }
        current_partition.push(ciphered);
        current_size += bytesize;
    }

    if !current_partition.is_empty() {
        // Add the last partition
        result.push(current_partition);
    }

    result
}

fn message_type_to_timeout(msg: &MpcMessage) -> Duration {
    match msg {
        MpcMessage::Generating(_) => MESSAGE_TIMEOUT,
        MpcMessage::Resharing(_) => MESSAGE_TIMEOUT,
        MpcMessage::Triple(_) => crate::util::get_triple_timeout(),
        MpcMessage::Presignature(_) => crate::types::PROTOCOL_PRESIG_TIMEOUT,
        MpcMessage::Signature(_) => crate::types::PROTOCOL_SIGNATURE_TIMEOUT,
    }
}

#[cfg(test)]
mod tests {
    use crate::protocol::message::GeneratingMessage;
    use crate::protocol::MpcMessage;

    #[test]
    fn test_sending_encrypted_message() {
        let associated_data = b"";
        let (sk, pk) = mpc_keys::hpke::generate();
        let starting_message = MpcMessage::Generating(GeneratingMessage {
            from: cait_sith::protocol::Participant::from(0),
            data: vec![],
        });

        let message = serde_json::to_vec(&starting_message).unwrap();
        let message = pk.encrypt(&message, associated_data).unwrap();

        let message = serde_json::to_vec(&message).unwrap();
        let cipher = serde_json::from_slice(&message).unwrap();
        let message = sk.decrypt(&cipher, associated_data).unwrap();
        let message: MpcMessage = serde_json::from_slice(&message).unwrap();

        assert_eq!(starting_message, message);
    }
}

'''
'''--- node/src/indexer.rs ---
use crate::gcp::GcpService;
use crate::kdf;
use crate::protocol::{SignQueue, SignRequest};
use crate::types::LatestBlockHeight;
use near_lake_framework::{LakeBuilder, LakeContext};
use near_lake_primitives::actions::ActionMetaDataExt;
use near_lake_primitives::{receipts::ExecutionStatus, AccountId};
use serde::{Deserialize, Serialize};
use std::sync::Arc;
use std::time::Instant;
use tokio::sync::RwLock;

/// Configures indexer.
#[derive(Debug, Clone, clap::Parser)]
#[group(id = "indexer_options")]
pub struct Options {
    /// AWS S3 bucket name for NEAR Lake Indexer
    #[clap(
        long,
        env("MPC_RECOVERY_INDEXER_S3_BUCKET"),
        default_value = "near-lake-data-testnet"
    )]
    pub s3_bucket: String,

    /// AWS S3 region name for NEAR Lake Indexer
    #[clap(
        long,
        env("MPC_RECOVERY_INDEXER_S3_REGION"),
        default_value = "eu-central-1"
    )]
    pub s3_region: String,

    /// AWS S3 URL for NEAR Lake Indexer (can be used to point to LocalStack)
    #[clap(long, env("MPC_RECOVERY_INDEXER_S3_URL"))]
    pub s3_url: Option<String>,

    /// The block height to start indexing from.
    // Defaults to the latest block on 2023-11-14 07:40:22 AM UTC
    #[clap(
        long,
        env("MPC_RECOVERY_INDEXER_START_BLOCK_HEIGHT"),
        default_value = "145964826"
    )]
    pub start_block_height: u64,
}

impl Options {
    pub fn into_str_args(self) -> Vec<String> {
        let mut opts = vec![
            "--s3-bucket".to_string(),
            self.s3_bucket,
            "--s3-region".to_string(),
            self.s3_region,
            "--start-block-height".to_string(),
            self.start_block_height.to_string(),
        ];

        if let Some(s3_url) = self.s3_url {
            opts.extend(vec!["--s3-url".to_string(), s3_url]);
        }

        opts
    }
}

#[derive(Debug, Serialize, Deserialize)]
struct SignPayload {
    payload: [u8; 32],
    path: String,
    key_version: u32,
}

#[derive(LakeContext)]
struct Context {
    mpc_contract_id: AccountId,
    node_account_id: AccountId,
    gcp_service: GcpService,
    queue: Arc<RwLock<SignQueue>>,
    latest_block_height: Arc<RwLock<LatestBlockHeight>>,
}

async fn handle_block(
    mut block: near_lake_primitives::block::Block,
    ctx: &Context,
) -> anyhow::Result<()> {
    for action in block.actions().cloned().collect::<Vec<_>>() {
        if action.receiver_id() == ctx.mpc_contract_id {
            let receipt =
                anyhow::Context::with_context(block.receipt_by_id(&action.receipt_id()), || {
                    format!(
                        "indexer unable to find block for receipt_id={}",
                        action.receipt_id()
                    )
                })?;
            let ExecutionStatus::SuccessReceiptId(receipt_id) = receipt.status() else {
                continue;
            };
            if let Some(function_call) = action.as_function_call() {
                if function_call.method_name() == "sign" {
                    if let Ok(sign_payload) =
                        serde_json::from_slice::<'_, SignPayload>(function_call.args())
                    {
                        if receipt.logs().is_empty() {
                            tracing::warn!("`sign` did not produce entropy");
                            continue;
                        }
                        let Ok(entropy) = serde_json::from_str::<'_, [u8; 32]>(&receipt.logs()[1])
                        else {
                            tracing::warn!(
                                "`sign` did not produce entropy correctly: {:?}",
                                receipt.logs()[0]
                            );
                            continue;
                        };
                        let epsilon =
                            kdf::derive_epsilon(&action.predecessor_id(), &sign_payload.path);
                        let delta = kdf::derive_delta(receipt_id, entropy);
                        tracing::info!(
                            receipt_id = %receipt_id,
                            caller_id = receipt.predecessor_id().to_string(),
                            our_account = ctx.node_account_id.to_string(),
                            payload = hex::encode(sign_payload.payload),
                            key_version = sign_payload.key_version,
                            entropy = hex::encode(entropy),
                            "indexed new `sign` function call"
                        );
                        let mut queue = ctx.queue.write().await;
                        queue.add(SignRequest {
                            receipt_id,
                            msg_hash: sign_payload.payload,
                            epsilon,
                            delta,
                            entropy,
                            time_added: Instant::now(),
                        });
                        crate::metrics::NUM_SIGN_REQUESTS
                            .with_label_values(&[&ctx.gcp_service.account_id])
                            .inc();
                        drop(queue);
                    }
                }
            }
        }
    }

    ctx.latest_block_height
        .write()
        .await
        .set(block.block_height())
        .store(&ctx.gcp_service)
        .await?;

    crate::metrics::LATEST_BLOCK_HEIGHT
        .with_label_values(&[&ctx.gcp_service.account_id])
        .set(block.block_height() as i64);

    if block.block_height() % 1000 == 0 {
        tracing::info!(block_height = block.block_height(), "indexed block");
    }
    Ok(())
}

pub fn run(
    options: Options,
    mpc_contract_id: AccountId,
    node_account_id: AccountId,
    queue: Arc<RwLock<SignQueue>>,
    gcp_service: crate::gcp::GcpService,
) -> anyhow::Result<()> {
    tracing::info!(
        s3_bucket = options.s3_bucket,
        s3_region = options.s3_region,
        s3_url = options.s3_url,
        start_block_height = options.start_block_height,
        %mpc_contract_id,
        "starting indexer"
    );

    let rt = tokio::runtime::Builder::new_multi_thread()
        .enable_all()
        .build()
        .unwrap();

    let (lake, latest_block_height) = rt.block_on(async {
        let latest = match LatestBlockHeight::fetch(&gcp_service).await {
            Ok(latest) => latest,
            Err(err) => {
                tracing::error!(%err, "failed to fetch latest block height; using start_block_height={} instead", options.start_block_height);
                LatestBlockHeight {
                    account_id: node_account_id.clone(),
                    block_height: options.start_block_height,
                }
            }
        };

        let mut lake_builder = LakeBuilder::default()
            .s3_bucket_name(options.s3_bucket)
            .s3_region_name(options.s3_region)
            .start_block_height(latest.block_height);

        if let Some(s3_url) = options.s3_url {
            let aws_config = aws_config::from_env().load().await;
            let s3_config = aws_sdk_s3::config::Builder::from(&aws_config)
                .endpoint_url(s3_url)
                .build();
            lake_builder = lake_builder.s3_config(s3_config);
        }
        anyhow::Ok((anyhow::Context::context(lake_builder.build(), "could not build lake indexer")?, latest))
    })?;
    let context = Context {
        mpc_contract_id,
        node_account_id,
        gcp_service,
        queue,
        latest_block_height: Arc::new(RwLock::new(latest_block_height)),
    };
    lake.run_with_context(handle_block, &context)?;
    Ok(())
}

'''
'''--- node/src/kdf.rs ---
use crate::types::PublicKey;
use crate::util::ScalarExt;
use anyhow::Context;
use cait_sith::FullSignature;
use hkdf::Hkdf;
use k256::ecdsa::{RecoveryId, VerifyingKey};
use k256::elliptic_curve::point::AffineCoordinates;
use k256::elliptic_curve::sec1::ToEncodedPoint;
use k256::elliptic_curve::CurveArithmetic;
use k256::{AffinePoint, Scalar, Secp256k1};
use near_primitives::hash::CryptoHash;
use near_primitives::types::AccountId;
use sha2::{Digest, Sha256};

// Constant prefix that ensures epsilon derivation values are used specifically for
// near-mpc-recovery with key derivation protocol vX.Y.Z.
const EPSILON_DERIVATION_PREFIX: &str = "near-mpc-recovery v0.1.0 epsilon derivation:";
// Constant prefix that ensures delta derivation values are used specifically for
// near-mpc-recovery with key derivation protocol vX.Y.Z.
const DELTA_DERIVATION_PREFIX: &str = "near-mpc-recovery v0.1.0 delta derivation:";

pub fn derive_epsilon(signer_id: &AccountId, path: &str) -> Scalar {
    // TODO: Use a key derivation library instead of doing this manually.
    // https://crates.io/crates/hkdf might be a good option?
    //
    // ',' is ACCOUNT_DATA_SEPARATOR from nearcore that indicate the end
    // of the accound id in the trie key. We reuse the same constant to
    // indicate the end of the account id in derivation path.
    let derivation_path = format!("{EPSILON_DERIVATION_PREFIX}{},{}", signer_id, path);
    let mut hasher = Sha256::new();
    hasher.update(derivation_path);
    Scalar::from_bytes(&hasher.finalize())
}

// In case there are multiple requests in the same block (hence same entropy), we need to ensure
// that we generate different random scalars as delta tweaks.
// Receipt ID should be unique inside of a block, so it serves us as the request identifier.
pub fn derive_delta(receipt_id: CryptoHash, entropy: [u8; 32]) -> Scalar {
    let hk = Hkdf::<Sha256>::new(None, &entropy);
    let info = format!("{DELTA_DERIVATION_PREFIX}:{}", receipt_id);
    let mut okm = [0u8; 32];
    hk.expand(info.as_bytes(), &mut okm).unwrap();
    Scalar::from_bytes(&okm)
}

pub fn derive_key(public_key: PublicKey, epsilon: Scalar) -> PublicKey {
    (<Secp256k1 as CurveArithmetic>::ProjectivePoint::GENERATOR * epsilon + public_key).to_affine()
}

#[derive(Debug)]
pub struct MultichainSignature {
    pub big_r: AffinePoint,
    pub s: Scalar,
    pub recovery_id: u8,
}

// try to get the correct recovery id for this signature by brute force.
pub fn into_eth_sig(
    public_key: &k256::AffinePoint,
    sig: &FullSignature<Secp256k1>,
    msg_hash: Scalar,
) -> anyhow::Result<MultichainSignature> {
    let public_key = public_key.to_encoded_point(false);
    let signature =
        k256::ecdsa::Signature::from_scalars(x_coordinate::<k256::Secp256k1>(&sig.big_r), sig.s)
            .context("cannot create signature from cait_sith signature")?;
    let pk0 = VerifyingKey::recover_from_prehash(
        &msg_hash.to_bytes(),
        &signature,
        RecoveryId::try_from(0).context("cannot create recovery_id=0")?,
    )
    .context("unable to use 0 as recovery_id to recover public key")?
    .to_encoded_point(false);
    if public_key == pk0 {
        return Ok(MultichainSignature {
            big_r: sig.big_r,
            s: sig.s,
            recovery_id: 0,
        });
    }

    let pk1 = VerifyingKey::recover_from_prehash(
        &msg_hash.to_bytes(),
        &signature,
        RecoveryId::try_from(1).context("cannot create recovery_id=1")?,
    )
    .context("unable to use 1 as recovery_id to recover public key")?
    .to_encoded_point(false);
    if public_key == pk1 {
        return Ok(MultichainSignature {
            big_r: sig.big_r,
            s: sig.s,
            recovery_id: 1,
        });
    }

    anyhow::bail!("cannot use either recovery id (0 or 1) to recover pubic key")
}

/// Get the x coordinate of a point, as a scalar
pub fn x_coordinate<C: cait_sith::CSCurve>(point: &C::AffinePoint) -> C::Scalar {
    <C::Scalar as k256::elliptic_curve::ops::Reduce<<C as k256::elliptic_curve::Curve>::Uint>>::reduce_bytes(&point.x())
}

'''
'''--- node/src/lib.rs ---
pub mod cli;
pub mod gcp;
pub mod http_client;
pub mod indexer;
pub mod kdf;
pub mod mesh;
pub mod metrics;
pub mod protocol;
pub mod rpc_client;
pub mod storage;
pub mod test_utils;
pub mod types;
pub mod util;
pub mod web;

'''
'''--- node/src/main.rs ---
use clap::Parser;
use mpc_recovery_node::cli::Cli;

fn main() -> anyhow::Result<()> {
    mpc_recovery_node::cli::run(Cli::parse())
}

'''
'''--- node/src/mesh/connection.rs ---
use std::time::{Duration, Instant};

use tokio::sync::RwLock;

use crate::protocol::contract::primitives::Participants;
use crate::protocol::ProtocolState;
use crate::web::StateView;

const DEFAULT_TIMEOUT: Duration = Duration::from_secs(1);

// TODO: this is a basic connection pool and does not do most of the work yet. This is
//       mostly here just to facilitate offline node handling for now.
// TODO/NOTE: we can use libp2p to facilitate most the of low level TCP connection work.
#[derive(Default)]
pub struct Pool {
    http: reqwest::Client,
    connections: RwLock<Participants>,
    potential_connections: RwLock<Participants>,

    /// The currently active participants for this epoch.
    current_active: RwLock<Option<(Participants, Instant)>>,
    // Potentially active participants that we can use to establish a connection in the next epoch.
    potential_active: RwLock<Option<(Participants, Instant)>>,
}

impl Pool {
    pub async fn ping(&self) -> Participants {
        if let Some((ref active, timestamp)) = *self.current_active.read().await {
            if timestamp.elapsed() < DEFAULT_TIMEOUT {
                return active.clone();
            }
        }

        let connections = self.connections.read().await;

        let mut participants = Participants::default();
        for (participant, info) in connections.iter() {
            let Ok(resp) = self.http.get(format!("{}/state", info.url)).send().await else {
                continue;
            };

            let Ok(_state): Result<StateView, _> = resp.json().await else {
                continue;
            };
            participants.insert(participant, info.clone());
        }

        let mut active = self.current_active.write().await;
        *active = Some((participants.clone(), Instant::now()));
        participants
    }

    pub async fn ping_potential(&self) -> Participants {
        if let Some((ref active, timestamp)) = *self.potential_active.read().await {
            if timestamp.elapsed() < DEFAULT_TIMEOUT {
                return active.clone();
            }
        }

        let connections = self.potential_connections.read().await;

        let mut participants = Participants::default();
        for (participant, info) in connections.iter() {
            let Ok(resp) = self.http.get(format!("{}/state", info.url)).send().await else {
                continue;
            };

            let Ok(_state): Result<StateView, _> = resp.json().await else {
                continue;
            };
            participants.insert(participant, info.clone());
        }

        let mut potential_active = self.potential_active.write().await;
        *potential_active = Some((participants.clone(), Instant::now()));
        participants
    }

    pub async fn establish_participants(&self, contract_state: &ProtocolState) {
        match contract_state {
            ProtocolState::Initializing(contract_state) => {
                let participants: Participants = contract_state.candidates.clone().into();
                self.set_participants(&participants).await;
            }
            ProtocolState::Running(contract_state) => {
                self.set_participants(&contract_state.participants).await;
            }
            ProtocolState::Resharing(contract_state) => {
                self.set_participants(&contract_state.old_participants)
                    .await;
                self.set_potential_participants(&contract_state.new_participants)
                    .await;
            }
        }
    }

    async fn set_participants(&self, participants: &Participants) {
        *self.connections.write().await = participants.clone();
    }

    async fn set_potential_participants(&self, participants: &Participants) {
        *self.potential_connections.write().await = participants.clone();
    }

    pub async fn potential_participants(&self) -> Participants {
        self.potential_connections.read().await.clone()
    }
}

'''
'''--- node/src/mesh/mod.rs ---
use mpc_keys::hpke;

use crate::protocol::contract::primitives::Participants;
use crate::protocol::ProtocolState;

pub mod connection;

#[derive(Clone, Debug)]
pub struct NetworkConfig {
    pub sign_sk: near_crypto::SecretKey,
    pub cipher_pk: hpke::PublicKey,
}

#[derive(Default)]
pub struct Mesh {
    /// Pool of connections to participants. Used to check who is alive in the network.
    pub connections: connection::Pool,

    /// Participants that are active at the beginning of each protocol loop.
    pub active_participants: Participants,

    /// Potential participants that are active at the beginning of each protocol loop. This
    /// includes participants belonging to the next epoch.
    pub active_potential_participants: Participants,
}

impl Mesh {
    /// Participants that are active at the beginning of each protocol loop.
    pub fn active_participants(&self) -> &Participants {
        &self.active_participants
    }

    /// Potential participants that are active at the beginning of each protocol loop. This will
    /// be empty if not in resharing state for the protocol
    pub fn active_potential_participants(&self) -> &Participants {
        &self.active_potential_participants
    }

    /// Get all pontential participants, but they not necessarily be active.
    pub async fn potential_participants(&self) -> Participants {
        self.connections.potential_participants().await
    }

    pub fn all_active_participants(&self) -> Participants {
        let mut participants = self.active_participants.clone();
        let active = self
            .active_potential_participants
            .keys()
            .collect::<Vec<_>>();
        tracing::info!(?active, "Getting potentially active participants");
        for (participant, info) in self.active_potential_participants.iter() {
            if !participants.contains_key(participant) {
                participants.insert(participant, info.clone());
            }
        }
        participants
    }

    pub async fn establish_participants(&mut self, contract_state: &ProtocolState) {
        self.connections
            .establish_participants(contract_state)
            .await;
        self.ping().await;
    }

    /// Ping the active participants such that we can see who is alive.
    pub async fn ping(&mut self) {
        self.active_participants = self.connections.ping().await;
        self.active_potential_participants = self.connections.ping_potential().await;
    }
}

'''
'''--- node/src/metrics.rs ---
use once_cell::sync::Lazy;
pub use prometheus::{
    self, core::MetricVec, core::MetricVecBuilder, exponential_buckets, linear_buckets, Counter,
    Encoder, Gauge, GaugeVec, Histogram, HistogramOpts, HistogramVec, IntCounter, IntCounterVec,
    IntGauge, IntGaugeVec, Opts, Result, TextEncoder,
};

pub(crate) static NODE_RUNNING: Lazy<IntGaugeVec> = Lazy::new(|| {
    try_create_int_gauge_vec(
        "multichain_node_is_up",
        "whether the multichain signer node is up and running",
        &["node_account_id"],
    )
    .unwrap()
});

pub(crate) static NUM_SIGN_REQUESTS: Lazy<IntGaugeVec> = Lazy::new(|| {
    try_create_int_gauge_vec(
        "multichain_sign_requests_count",
        "number of multichain sign requests, marked by sign requests indexed",
        &["node_account_id"],
    )
    .unwrap()
});

pub(crate) static NUM_SIGN_REQUESTS_MINE: Lazy<IntGaugeVec> = Lazy::new(|| {
    try_create_int_gauge_vec(
        "multichain_sign_requests_count_mine",
        "number of multichain sign requests, marked by sign requests indexed",
        &["node_account_id"],
    )
    .unwrap()
});

pub(crate) static NUM_SIGN_SUCCESS: Lazy<IntGaugeVec> = Lazy::new(|| {
    try_create_int_gauge_vec(
        "multichain_sign_requests_success",
        "number of successful multichain sign requests, marked by publish()",
        &["node_account_id"],
    )
    .unwrap()
});

pub(crate) static SIGN_LATENCY: Lazy<HistogramVec> = Lazy::new(|| {
    try_create_histogram_vec(
        "multichain_sign_latency_sec",
        "Latency of multichain signing, start from indexing sign request, end when publish() called.",
        &["node_account_id"],
        Some(exponential_buckets(0.001, 2.0, 20).unwrap()),
    )
    .unwrap()
});

pub(crate) static LATEST_BLOCK_HEIGHT: Lazy<IntGaugeVec> = Lazy::new(|| {
    try_create_int_gauge_vec(
        "multichain_latest_block_height",
        "Latest block height seen by the node",
        &["node_account_id"],
    )
    .unwrap()
});

pub(crate) static TRIPLE_LATENCY: Lazy<HistogramVec> = Lazy::new(|| {
    try_create_histogram_vec(
        "multichain_triple_latency_sec",
        "Latency of multichain triple generation, start from starting generation, end when triple generation complete.",
        &["node_account_id"],
        Some(exponential_buckets(5.0, 1.5, 20).unwrap()),
    )
    .unwrap()
});

pub(crate) static PRESIGNATURE_LATENCY: Lazy<HistogramVec> = Lazy::new(|| {
    try_create_histogram_vec(
        "multichain_presignature_latency_sec",
        "Latency of multichain presignature generation, start from starting generation, end when presignature generation complete.",
        &["node_account_id"],
        Some(exponential_buckets(1.0, 1.5, 20).unwrap()),
    )
    .unwrap()
});

pub(crate) static SIGN_QUEUE_SIZE: Lazy<IntGaugeVec> = Lazy::new(|| {
    try_create_int_gauge_vec(
        "multichain_sign_queue_size",
        "number of requests in sign queue",
        &["node_account_id"],
    )
    .unwrap()
});

pub(crate) static SIGN_QUEUE_MINE_SIZE: Lazy<IntGaugeVec> = Lazy::new(|| {
    try_create_int_gauge_vec(
        "multichain_sign_queue_mine_size",
        "number of my requests in sign queue",
        &["node_account_id"],
    )
    .unwrap()
});

pub(crate) static NUM_TRIPLE_GENERATORS_INTRODUCED: Lazy<IntGaugeVec> = Lazy::new(|| {
    try_create_int_gauge_vec(
        "multichain_num_triple_generators_introduced",
        "number of triple generators",
        &["node_account_id"],
    )
    .unwrap()
});

pub(crate) static NUM_TRIPLE_GENERATORS_TOTAL: Lazy<IntGaugeVec> = Lazy::new(|| {
    try_create_int_gauge_vec(
        "multichain_num_triple_generators_total",
        "number of total ongoing triple generators",
        &["node_account_id"],
    )
    .unwrap()
});

pub(crate) static NUM_TRIPLES_MINE: Lazy<IntGaugeVec> = Lazy::new(|| {
    try_create_int_gauge_vec(
        "multichain_num_triples_mine",
        "number of triples of the node's own",
        &["node_account_id"],
    )
    .unwrap()
});

pub(crate) static NUM_TRIPLES_TOTAL: Lazy<IntGaugeVec> = Lazy::new(|| {
    try_create_int_gauge_vec(
        "multichain_num_triples_total",
        "number of total triples",
        &["node_account_id"],
    )
    .unwrap()
});

pub(crate) static NUM_PRESIGNATURES_MINE: Lazy<IntGaugeVec> = Lazy::new(|| {
    try_create_int_gauge_vec(
        "multichain_num_presignatures_mine",
        "number of presignatures of the node's own",
        &["node_account_id"],
    )
    .unwrap()
});

pub(crate) static NUM_PRESIGNATURES_TOTAL: Lazy<IntGaugeVec> = Lazy::new(|| {
    try_create_int_gauge_vec(
        "multichain_num_presignatures_total",
        "number of total presignatures",
        &["node_account_id"],
    )
    .unwrap()
});

pub(crate) static NUM_PRESIGNATURE_GENERATORS_TOTAL: Lazy<IntGaugeVec> = Lazy::new(|| {
    try_create_int_gauge_vec(
        "multichain_num_presignature_generators_total",
        "number of total ongoing presignature generators",
        &["node_account_id"],
    )
    .unwrap()
});

pub(crate) static MESSAGE_QUEUE_SIZE: Lazy<IntGaugeVec> = Lazy::new(|| {
    try_create_int_gauge_vec(
        "multichain_message_queue_size",
        "size of message queue of the node",
        &["node_account_id"],
    )
    .unwrap()
});

pub(crate) static NODE_VERSION: Lazy<IntGaugeVec> = Lazy::new(|| {
    try_create_int_gauge_vec(
        "multichain_node_version",
        "node semantic version",
        &["node_account_id"],
    )
    .unwrap()
});

pub(crate) static NUM_TOTAL_HISTORICAL_TRIPLE_GENERATORS: Lazy<IntGaugeVec> = Lazy::new(|| {
    try_create_int_gauge_vec(
        "multichain_num_total_historical_triple_generators",
        "number of all triple generators historically on the node",
        &["node_account_id"],
    )
    .unwrap()
});

pub(crate) static NUM_TOTAL_HISTORICAL_TRIPLE_GENERATORS_SUCCESS: Lazy<IntGaugeVec> =
    Lazy::new(|| {
        try_create_int_gauge_vec(
            "multichain_num_total_historical_triple_generators_success",
            "number of all successful triple generators historically on the node",
            &["node_account_id"],
        )
        .unwrap()
    });

pub(crate) static NUM_TOTAL_HISTORICAL_TRIPLE_GENERATIONS_MINE_SUCCESS: Lazy<IntGaugeVec> =
    Lazy::new(|| {
        try_create_int_gauge_vec(
            "multichain_num_total_historical_triple_generations_mine_success",
            "number of successful triple generators that was mine historically on the node",
            &["node_account_id"],
        )
        .unwrap()
    });

pub(crate) static NUM_TOTAL_HISTORICAL_PRESIGNATURE_GENERATORS: Lazy<IntGaugeVec> =
    Lazy::new(|| {
        try_create_int_gauge_vec(
            "multichain_num_total_historical_presignature_generators",
            "number of all presignature generators historically on the node",
            &["node_account_id"],
        )
        .unwrap()
    });

pub(crate) static NUM_TOTAL_HISTORICAL_PRESIGNATURE_GENERATORS_SUCCESS: Lazy<IntGaugeVec> =
    Lazy::new(|| {
        try_create_int_gauge_vec(
            "multichain_num_total_historical_presignature_generators_success",
            "number of all successful presignature generators historically on the node",
            &["node_account_id"],
        )
        .unwrap()
    });

pub(crate) static NUM_TOTAL_HISTORICAL_PRESIGNATURE_GENERATORS_MINE: Lazy<IntGaugeVec> =
    Lazy::new(|| {
        try_create_int_gauge_vec(
            "multichain_num_total_historical_presignature_generators_mine",
            "number of mine presignature generators historically on the node",
            &["node_account_id"],
        )
        .unwrap()
    });

pub(crate) static NUM_TOTAL_HISTORICAL_PRESIGNATURE_GENERATORS_MINE_SUCCESS: Lazy<IntGaugeVec> =
    Lazy::new(|| {
        try_create_int_gauge_vec(
            "multichain_num_total_historical_presignature_generators_mine_success",
            "number of mine presignature generators historically on the node",
            &["node_account_id"],
        )
        .unwrap()
    });

pub(crate) static NUM_SIGN_SUCCESS_30S: Lazy<IntGaugeVec> = Lazy::new(|| {
    try_create_int_gauge_vec(
            "multichain_sign_requests_success_30s",
            "number of successful multichain sign requests that finished within 30s, marked by publish()",
            &["node_account_id"],
        )
        .unwrap()
});

pub(crate) static SEND_ENCRYPTED_LATENCY: Lazy<HistogramVec> = Lazy::new(|| {
    try_create_histogram_vec(
        "multichain_send_encrypted_ms",
        "Latency of send encrypted.",
        &["node_account_id"],
        Some(exponential_buckets(0.5, 1.5, 20).unwrap()),
    )
    .unwrap()
});

pub(crate) static PROTOCOL_LATENCY_ITER_TOTAL: Lazy<HistogramVec> = Lazy::new(|| {
    try_create_histogram_vec(
        "multichain_protocol_iter_total",
        "Latency of multichain protocol iter, start of protocol till end of iteration",
        &["node_account_id"],
        Some(exponential_buckets(0.001, 3.0, 20).unwrap()),
    )
    .unwrap()
});

pub(crate) static PROTOCOL_LATENCY_ITER_CRYPTO: Lazy<HistogramVec> = Lazy::new(|| {
    try_create_histogram_vec(
        "multichain_protocol_iter_crypto",
        "Latency of multichain protocol iter, start of crypto iter till end",
        &["node_account_id"],
        Some(exponential_buckets(0.001, 2.0, 20).unwrap()),
    )
    .unwrap()
});

pub(crate) static PROTOCOL_LATENCY_ITER_CONSENSUS: Lazy<HistogramVec> = Lazy::new(|| {
    try_create_histogram_vec(
        "multichain_protocol_iter_consensus",
        "Latency of multichain protocol iter, start of consensus iter till end",
        &["node_account_id"],
        Some(exponential_buckets(0.001, 2.0, 20).unwrap()),
    )
    .unwrap()
});

pub(crate) static PROTOCOL_LATENCY_ITER_MESSAGE: Lazy<HistogramVec> = Lazy::new(|| {
    try_create_histogram_vec(
        "multichain_protocol_iter_message",
        "Latency of multichain protocol iter, start of message iter till end",
        &["node_account_id"],
        Some(exponential_buckets(0.001, 2.0, 20).unwrap()),
    )
    .unwrap()
});

pub(crate) static NUM_SEND_ENCRYPTED_FAILURE: Lazy<IntGaugeVec> = Lazy::new(|| {
    try_create_int_gauge_vec(
        "multichain_send_encrypted_failure",
        "number of successful send encrypted",
        &["node_account_id"],
    )
    .unwrap()
});

pub(crate) static NUM_SEND_ENCRYPTED_TOTAL: Lazy<IntGaugeVec> = Lazy::new(|| {
    try_create_int_gauge_vec(
        "multichain_send_encrypted_total",
        "number total send encrypted",
        &["node_account_id"],
    )
    .unwrap()
});

pub(crate) static FAILED_SEND_ENCRYPTED_LATENCY: Lazy<HistogramVec> = Lazy::new(|| {
    try_create_histogram_vec(
        "multichain_failed_send_encrypted_ms",
        "Latency of failed send encrypted.",
        &["node_account_id"],
        Some(exponential_buckets(0.5, 1.5, 20).unwrap()),
    )
    .unwrap()
});

pub fn try_create_int_gauge_vec(name: &str, help: &str, labels: &[&str]) -> Result<IntGaugeVec> {
    check_metric_multichain_prefix(name)?;
    let opts = Opts::new(name, help);
    let gauge = IntGaugeVec::new(opts, labels)?;
    prometheus::register(Box::new(gauge.clone()))?;
    Ok(gauge)
}

/// Attempts to create a `HistogramVector`, returning `Err` if the registry does not accept the counter
/// (potentially due to naming conflict).
pub fn try_create_histogram_vec(
    name: &str,
    help: &str,
    labels: &[&str],
    buckets: Option<Vec<f64>>,
) -> Result<HistogramVec> {
    check_metric_multichain_prefix(name)?;
    let mut opts = HistogramOpts::new(name, help);
    if let Some(buckets) = buckets {
        opts = opts.buckets(buckets);
    }
    let histogram = HistogramVec::new(opts, labels)?;
    prometheus::register(Box::new(histogram.clone()))?;
    Ok(histogram)
}

fn check_metric_multichain_prefix(name: &str) -> Result<()> {
    if name.starts_with("multichain_") {
        Ok(())
    } else {
        Err(prometheus::Error::Msg(format!(
            "Metrics are expected to start with 'multichain_', got {}",
            name
        )))
    }
}

'''
'''--- node/src/protocol/consensus.rs ---
use super::contract::{ProtocolState, ResharingContractState};
use super::state::{
    JoiningState, NodeState, PersistentNodeData, RunningState, StartedState,
    WaitingForConsensusState,
};
use super::{Config, SignQueue};
use crate::gcp::error::DatastoreStorageError;
use crate::gcp::error::SecretStorageError;
use crate::protocol::contract::primitives::Participants;
use crate::protocol::presignature::PresignatureManager;
use crate::protocol::signature::SignatureManager;
use crate::protocol::state::{GeneratingState, ResharingState};
use crate::protocol::triple::TripleManager;
use crate::rpc_client;
use crate::storage::secret_storage::SecretNodeStorageBox;
use crate::storage::triple_storage::LockTripleNodeStorageBox;
use crate::storage::triple_storage::TripleData;
use crate::types::{KeygenProtocol, ReshareProtocol, SecretKeyShare};
use crate::util::AffinePointExt;
use async_trait::async_trait;
use cait_sith::protocol::InitializationError;
use near_crypto::InMemorySigner;
use near_primitives::transaction::{Action, FunctionCallAction};
use near_primitives::types::AccountId;
use std::cmp::Ordering;
use std::sync::Arc;
use tokio::sync::RwLock;
use url::Url;

pub trait ConsensusCtx {
    fn my_account_id(&self) -> &AccountId;
    fn http_client(&self) -> &reqwest::Client;
    fn rpc_client(&self) -> &near_fetch::Client;
    fn signer(&self) -> &InMemorySigner;
    fn mpc_contract_id(&self) -> &AccountId;
    fn my_address(&self) -> &Url;
    fn sign_queue(&self) -> Arc<RwLock<SignQueue>>;
    fn secret_storage(&self) -> &SecretNodeStorageBox;
    fn triple_storage(&self) -> LockTripleNodeStorageBox;
    fn cfg(&self) -> &Config;
}

#[derive(thiserror::Error, Debug)]
pub enum ConsensusError {
    #[error("contract state has been rolled back")]
    ContractStateRollback,
    #[error("contract epoch has been rolled back")]
    EpochRollback,
    #[error("mismatched public key between contract state and local state")]
    MismatchedPublicKey,
    #[error("mismatched threshold between contract state and local state")]
    MismatchedThreshold,
    #[error("mismatched participant set between contract state and local state")]
    MismatchedParticipants,
    #[error("this node has been unexpectedly kicked from the participant set")]
    HasBeenKicked,
    #[error("cait-sith initialization error: {0}")]
    CaitSithInitializationError(#[from] InitializationError),
    #[error("secret storage error: {0}")]
    SecretStorageError(SecretStorageError),
    #[error("datastore storage error: {0}")]
    DatastoreStorageError(DatastoreStorageError),
}

impl From<SecretStorageError> for ConsensusError {
    fn from(err: SecretStorageError) -> Self {
        ConsensusError::SecretStorageError(err)
    }
}

impl From<DatastoreStorageError> for ConsensusError {
    fn from(err: DatastoreStorageError) -> Self {
        ConsensusError::DatastoreStorageError(err)
    }
}

#[async_trait]
pub trait ConsensusProtocol {
    async fn advance<C: ConsensusCtx + Send + Sync>(
        self,
        ctx: C,
        contract_state: ProtocolState,
    ) -> Result<NodeState, ConsensusError>;
}

#[async_trait]
impl ConsensusProtocol for StartedState {
    async fn advance<C: ConsensusCtx + Send + Sync>(
        self,
        ctx: C,
        contract_state: ProtocolState,
    ) -> Result<NodeState, ConsensusError> {
        match self.persistent_node_data {
            Some(PersistentNodeData {
                epoch,
                private_share,
                public_key,
            }) => match contract_state {
                ProtocolState::Initializing(_) => Err(ConsensusError::ContractStateRollback),
                ProtocolState::Running(contract_state) => {
                    if contract_state.public_key != public_key {
                        return Err(ConsensusError::MismatchedPublicKey);
                    }
                    match contract_state.epoch.cmp(&epoch) {
                        Ordering::Greater => {
                            tracing::warn!(
                                "started(running): our current epoch is {} while contract state's is {}, trying to rejoin as a new participant",
                                epoch,
                                contract_state.epoch
                            );
                            Ok(NodeState::Joining(JoiningState {
                                participants: contract_state.participants,
                                public_key,
                            }))
                        }
                        Ordering::Less => Err(ConsensusError::EpochRollback),
                        Ordering::Equal => {
                            let sign_queue = ctx.sign_queue();
                            match contract_state
                                .participants
                                .find_participant(ctx.my_account_id())
                            {
                                Some(me) => {
                                    tracing::info!(
                                        "started: contract state is running and we are already a participant"
                                    );
                                    let presignature_manager = PresignatureManager::new(
                                        me,
                                        contract_state.threshold,
                                        epoch,
                                        ctx.my_account_id(),
                                        &ctx.cfg().presig_cfg,
                                    );
                                    let triple_manager = TripleManager::new(
                                        me,
                                        contract_state.threshold,
                                        epoch,
                                        &ctx.cfg().triple_cfg,
                                        self.triple_data,
                                        ctx.triple_storage(),
                                        ctx.my_account_id(),
                                    );
                                    Ok(NodeState::Running(RunningState {
                                        epoch,
                                        participants: contract_state.participants,
                                        threshold: contract_state.threshold,
                                        private_share,
                                        public_key,
                                        sign_queue,
                                        triple_manager: Arc::new(RwLock::new(triple_manager)),
                                        presignature_manager: Arc::new(RwLock::new(
                                            presignature_manager,
                                        )),
                                        signature_manager: Arc::new(RwLock::new(
                                            SignatureManager::new(
                                                me,
                                                contract_state.public_key,
                                                epoch,
                                            ),
                                        )),
                                        messages: Default::default(),
                                    }))
                                }
                                None => Ok(NodeState::Joining(JoiningState {
                                    participants: contract_state.participants,
                                    public_key,
                                })),
                            }
                        }
                    }
                }
                ProtocolState::Resharing(contract_state) => {
                    if contract_state.public_key != public_key {
                        return Err(ConsensusError::MismatchedPublicKey);
                    }
                    match contract_state.old_epoch.cmp(&epoch) {
                        Ordering::Greater => {
                            tracing::warn!(
                                "started(resharing): our current epoch is {} while contract state's is {}, trying to rejoin as a new participant",
                                epoch,
                                contract_state.old_epoch
                            );
                            Ok(NodeState::Joining(JoiningState {
                                participants: contract_state.old_participants,
                                public_key,
                            }))
                        }
                        Ordering::Less => Err(ConsensusError::EpochRollback),
                        Ordering::Equal => {
                            tracing::info!(
                                "started(resharing): contract state is resharing with us, joining as a participant"
                            );
                            start_resharing(Some(private_share), ctx, contract_state).await
                        }
                    }
                }
            },
            None => match contract_state {
                ProtocolState::Initializing(contract_state) => {
                    let participants: Participants = contract_state.candidates.clone().into();
                    match participants.find_participant(ctx.my_account_id()) {
                        Some(me) => {
                            tracing::info!(
                                "started(initializing): starting key generation as a part of the participant set"
                            );
                            let protocol = KeygenProtocol::new(
                                &participants.keys().cloned().collect::<Vec<_>>(),
                                me,
                                contract_state.threshold,
                            )?;
                            Ok(NodeState::Generating(GeneratingState {
                                participants,
                                threshold: contract_state.threshold,
                                protocol,
                                messages: Default::default(),
                            }))
                        }
                        None => {
                            tracing::info!("started(initializing): we are not a part of the initial participant set, waiting for key generation to complete");
                            Ok(NodeState::Started(self))
                        }
                    }
                }
                ProtocolState::Running(contract_state) => Ok(NodeState::Joining(JoiningState {
                    participants: contract_state.participants,
                    public_key: contract_state.public_key,
                })),
                ProtocolState::Resharing(contract_state) => Ok(NodeState::Joining(JoiningState {
                    participants: contract_state.old_participants,
                    public_key: contract_state.public_key,
                })),
            },
        }
    }
}

#[async_trait]
impl ConsensusProtocol for GeneratingState {
    async fn advance<C: ConsensusCtx + Send + Sync>(
        self,
        _ctx: C,
        contract_state: ProtocolState,
    ) -> Result<NodeState, ConsensusError> {
        match contract_state {
            ProtocolState::Initializing(_) => {
                tracing::debug!("generating(initializing): continuing generation, contract state has not been finalized yet");
                Ok(NodeState::Generating(self))
            }
            ProtocolState::Running(contract_state) => {
                if contract_state.epoch > 0 {
                    tracing::warn!("generating(running): contract has already changed epochs, trying to rejoin as a new participant");
                    return Ok(NodeState::Joining(JoiningState {
                        participants: contract_state.participants,
                        public_key: contract_state.public_key,
                    }));
                }
                tracing::info!("generating(running): contract state has finished key generation, trying to catch up");
                if self.participants != contract_state.participants {
                    return Err(ConsensusError::MismatchedParticipants);
                }
                if self.threshold != contract_state.threshold {
                    return Err(ConsensusError::MismatchedThreshold);
                }
                Ok(NodeState::Generating(self))
            }
            ProtocolState::Resharing(contract_state) => {
                if contract_state.old_epoch > 0 {
                    tracing::warn!("generating(resharing): contract has already changed epochs, trying to rejoin as a new participant");
                    return Ok(NodeState::Joining(JoiningState {
                        participants: contract_state.old_participants,
                        public_key: contract_state.public_key,
                    }));
                }
                tracing::warn!("generating(resharing): contract state is resharing without us, trying to catch up");
                if self.participants != contract_state.old_participants {
                    return Err(ConsensusError::MismatchedParticipants);
                }
                if self.threshold != contract_state.threshold {
                    return Err(ConsensusError::MismatchedThreshold);
                }
                Ok(NodeState::Generating(self))
            }
        }
    }
}

#[async_trait]
impl ConsensusProtocol for WaitingForConsensusState {
    async fn advance<C: ConsensusCtx + Send + Sync>(
        self,
        ctx: C,
        contract_state: ProtocolState,
    ) -> Result<NodeState, ConsensusError> {
        match contract_state {
            ProtocolState::Initializing(contract_state) => {
                tracing::debug!("waiting(initializing): waiting for consensus, contract state has not been finalized yet");
                let public_key = self.public_key.into_near_public_key();
                let has_voted = contract_state
                    .pk_votes
                    .get(&public_key)
                    .map(|ps| ps.contains(ctx.my_account_id()))
                    .unwrap_or_default();
                if !has_voted {
                    tracing::info!("waiting(initializing): we haven't voted yet, voting for the generated public key");
                    rpc_client::vote_for_public_key(
                        ctx.rpc_client(),
                        ctx.signer(),
                        ctx.mpc_contract_id(),
                        &public_key,
                    )
                    .await
                    .unwrap();
                }
                Ok(NodeState::WaitingForConsensus(self))
            }
            ProtocolState::Running(contract_state) => match contract_state.epoch.cmp(&self.epoch) {
                Ordering::Greater => {
                    tracing::warn!(
                            "waiting(running): our current epoch is {} while contract state's is {}, trying to rejoin as a new participant",
                            self.epoch,
                            contract_state.epoch
                        );

                    Ok(NodeState::Joining(JoiningState {
                        participants: contract_state.participants,
                        public_key: contract_state.public_key,
                    }))
                }
                Ordering::Less => Err(ConsensusError::EpochRollback),
                Ordering::Equal => {
                    tracing::info!("waiting(running): contract state has reached consensus");
                    if contract_state.participants != self.participants {
                        return Err(ConsensusError::MismatchedParticipants);
                    }
                    if contract_state.threshold != self.threshold {
                        return Err(ConsensusError::MismatchedThreshold);
                    }
                    if contract_state.public_key != self.public_key {
                        return Err(ConsensusError::MismatchedPublicKey);
                    }

                    let me = contract_state
                        .participants
                        .find_participant(ctx.my_account_id())
                        .unwrap();

                    let triple_manager = TripleManager::new(
                        me,
                        self.threshold,
                        self.epoch,
                        &ctx.cfg().triple_cfg,
                        vec![],
                        ctx.triple_storage(),
                        ctx.my_account_id(),
                    );

                    Ok(NodeState::Running(RunningState {
                        epoch: self.epoch,
                        participants: self.participants,
                        threshold: self.threshold,
                        private_share: self.private_share,
                        public_key: self.public_key,
                        sign_queue: ctx.sign_queue(),
                        triple_manager: Arc::new(RwLock::new(triple_manager)),
                        presignature_manager: Arc::new(RwLock::new(PresignatureManager::new(
                            me,
                            self.threshold,
                            self.epoch,
                            ctx.my_account_id(),
                            &ctx.cfg().presig_cfg,
                        ))),
                        signature_manager: Arc::new(RwLock::new(SignatureManager::new(
                            me,
                            self.public_key,
                            self.epoch,
                        ))),
                        messages: self.messages,
                    }))
                }
            },
            ProtocolState::Resharing(contract_state) => {
                match (contract_state.old_epoch + 1).cmp(&self.epoch) {
                    Ordering::Greater if contract_state.old_epoch + 2 == self.epoch => {
                        tracing::info!("waiting(resharing): contract state is resharing, joining");
                        if contract_state.old_participants != self.participants {
                            return Err(ConsensusError::MismatchedParticipants);
                        }
                        if contract_state.threshold != self.threshold {
                            return Err(ConsensusError::MismatchedThreshold);
                        }
                        if contract_state.public_key != self.public_key {
                            return Err(ConsensusError::MismatchedPublicKey);
                        }
                        start_resharing(Some(self.private_share), ctx, contract_state).await
                    }
                    Ordering::Greater => {
                        tracing::warn!(
                            "waiting(resharing): our current epoch is {} while contract state's is {}, trying to rejoin as a new participant",
                            self.epoch,
                            contract_state.old_epoch
                        );

                        Ok(NodeState::Joining(JoiningState {
                            participants: contract_state.old_participants,
                            public_key: contract_state.public_key,
                        }))
                    }
                    Ordering::Less => Err(ConsensusError::EpochRollback),
                    Ordering::Equal => {
                        tracing::debug!(
                            "waiting(resharing): waiting for resharing consensus, contract state has not been finalized yet"
                        );
                        let has_voted = contract_state.finished_votes.contains(ctx.my_account_id());
                        match contract_state
                            .old_participants
                            .find_participant(ctx.my_account_id())
                        {
                            Some(_) => {
                                if !has_voted {
                                    tracing::info!(
                                        epoch = self.epoch,
                                        "waiting(resharing): we haven't voted yet, voting for resharing to complete"
                                    );
                                    rpc_client::vote_reshared(
                                        ctx.rpc_client(),
                                        ctx.signer(),
                                        ctx.mpc_contract_id(),
                                        self.epoch,
                                    )
                                    .await
                                    .unwrap();
                                } else {
                                    tracing::info!(
                                        epoch = self.epoch,
                                        "waiting(resharing): we have voted for resharing to complete"
                                    );
                                }
                            }
                            None => {
                                tracing::info!("waiting(resharing): we are not a part of the old participant set");
                            }
                        }
                        Ok(NodeState::WaitingForConsensus(self))
                    }
                }
            }
        }
    }
}

#[async_trait]
impl ConsensusProtocol for RunningState {
    async fn advance<C: ConsensusCtx + Send + Sync>(
        self,
        ctx: C,
        contract_state: ProtocolState,
    ) -> Result<NodeState, ConsensusError> {
        match contract_state {
            ProtocolState::Initializing(_) => Err(ConsensusError::ContractStateRollback),
            ProtocolState::Running(contract_state) => match contract_state.epoch.cmp(&self.epoch) {
                Ordering::Greater => {
                    tracing::warn!(
                            "running(running): our current epoch is {} while contract state's is {}, trying to rejoin as a new participant",
                            self.epoch,
                            contract_state.epoch
                        );

                    Ok(NodeState::Joining(JoiningState {
                        participants: contract_state.participants,
                        public_key: contract_state.public_key,
                    }))
                }
                Ordering::Less => Err(ConsensusError::EpochRollback),
                Ordering::Equal => {
                    tracing::debug!("running(running): continuing to run as normal");
                    if contract_state.participants != self.participants {
                        return Err(ConsensusError::MismatchedParticipants);
                    }
                    if contract_state.threshold != self.threshold {
                        return Err(ConsensusError::MismatchedThreshold);
                    }
                    if contract_state.public_key != self.public_key {
                        return Err(ConsensusError::MismatchedPublicKey);
                    }
                    Ok(NodeState::Running(self))
                }
            },
            ProtocolState::Resharing(contract_state) => {
                match contract_state.old_epoch.cmp(&self.epoch) {
                    Ordering::Greater => {
                        tracing::warn!(
                            "running(resharing): our current epoch is {} while contract state's is {}, trying to rejoin as a new participant",
                            self.epoch,
                            contract_state.old_epoch
                        );

                        Ok(NodeState::Joining(JoiningState {
                            participants: contract_state.old_participants,
                            public_key: contract_state.public_key,
                        }))
                    }
                    Ordering::Less => Err(ConsensusError::EpochRollback),
                    Ordering::Equal => {
                        tracing::info!("running(resharing): contract is resharing");
                        let is_in_old_participant_set = contract_state
                            .old_participants
                            .contains_account_id(ctx.my_account_id());
                        let is_in_new_participant_set = contract_state
                            .new_participants
                            .contains_account_id(ctx.my_account_id());
                        if !is_in_old_participant_set || !is_in_new_participant_set {
                            return Err(ConsensusError::HasBeenKicked);
                        }
                        if contract_state.public_key != self.public_key {
                            return Err(ConsensusError::MismatchedPublicKey);
                        }
                        start_resharing(Some(self.private_share), ctx, contract_state).await
                    }
                }
            }
        }
    }
}

#[async_trait]
impl ConsensusProtocol for ResharingState {
    async fn advance<C: ConsensusCtx + Send + Sync>(
        self,
        _ctx: C,
        contract_state: ProtocolState,
    ) -> Result<NodeState, ConsensusError> {
        match contract_state {
            ProtocolState::Initializing(_) => Err(ConsensusError::ContractStateRollback),
            ProtocolState::Running(contract_state) => {
                match contract_state.epoch.cmp(&(self.old_epoch + 1)) {
                    Ordering::Greater => {
                        tracing::warn!(
                            "resharing(running): expected epoch {} while contract state's is {}, trying to rejoin as a new participant",
                            self.old_epoch + 1,
                            contract_state.epoch
                        );

                        Ok(NodeState::Joining(JoiningState {
                            participants: contract_state.participants,
                            public_key: contract_state.public_key,
                        }))
                    }
                    Ordering::Less => Err(ConsensusError::EpochRollback),
                    Ordering::Equal => {
                        tracing::info!("resharing(running): contract state has finished resharing, trying to catch up");
                        if contract_state.participants != self.new_participants {
                            return Err(ConsensusError::MismatchedParticipants);
                        }
                        if contract_state.threshold != self.threshold {
                            return Err(ConsensusError::MismatchedThreshold);
                        }
                        if contract_state.public_key != self.public_key {
                            return Err(ConsensusError::MismatchedPublicKey);
                        }
                        Ok(NodeState::Resharing(self))
                    }
                }
            }
            ProtocolState::Resharing(contract_state) => {
                match contract_state.old_epoch.cmp(&self.old_epoch) {
                    Ordering::Greater => {
                        tracing::warn!(
                            "resharing(resharing): expected resharing from epoch {} while contract is resharing from {}, trying to rejoin as a new participant",
                            self.old_epoch,
                            contract_state.old_epoch
                        );

                        Ok(NodeState::Joining(JoiningState {
                            participants: contract_state.old_participants,
                            public_key: contract_state.public_key,
                        }))
                    }
                    Ordering::Less => Err(ConsensusError::EpochRollback),
                    Ordering::Equal => {
                        tracing::debug!("resharing(resharing): continue to reshare as normal");
                        if contract_state.old_participants != self.old_participants {
                            return Err(ConsensusError::MismatchedParticipants);
                        }
                        if contract_state.new_participants != self.new_participants {
                            return Err(ConsensusError::MismatchedParticipants);
                        }
                        if contract_state.threshold != self.threshold {
                            return Err(ConsensusError::MismatchedThreshold);
                        }
                        if contract_state.public_key != self.public_key {
                            return Err(ConsensusError::MismatchedPublicKey);
                        }
                        Ok(NodeState::Resharing(self))
                    }
                }
            }
        }
    }
}

#[async_trait]
impl ConsensusProtocol for JoiningState {
    async fn advance<C: ConsensusCtx + Send + Sync>(
        self,
        ctx: C,
        contract_state: ProtocolState,
    ) -> Result<NodeState, ConsensusError> {
        match contract_state {
            ProtocolState::Initializing(_) => Err(ConsensusError::ContractStateRollback),
            ProtocolState::Running(contract_state) => {
                match contract_state
                    .candidates
                    .find_candidate(ctx.my_account_id())
                {
                    Some(_) => {
                        let votes = contract_state
                            .join_votes
                            .get(ctx.my_account_id())
                            .cloned()
                            .unwrap_or_default();
                        let participant_account_ids_to_vote = contract_state
                            .participants
                            .iter()
                            .map(|(_, info)| &info.account_id)
                            .filter(|id| !votes.contains(*id))
                            .collect::<Vec<_>>();
                        if !participant_account_ids_to_vote.is_empty() {
                            tracing::info!(
                                ?participant_account_ids_to_vote,
                                "Some participants have not voted for you to join"
                            );
                        }
                        Ok(NodeState::Joining(self))
                    }
                    None => {
                        tracing::info!(
                            "joining(running): sending a transaction to join the participant set"
                        );
                        let args = serde_json::json!({
                            "url": ctx.my_address(),
                            "cipher_pk": ctx.cfg().network_cfg.cipher_pk.to_bytes(),
                            "sign_pk": ctx.cfg().network_cfg.sign_sk.public_key(),
                        });
                        ctx.rpc_client()
                            .send_tx(
                                ctx.signer(),
                                ctx.mpc_contract_id(),
                                vec![Action::FunctionCall(FunctionCallAction {
                                    method_name: "join".to_string(),
                                    args: args.to_string().into_bytes(),
                                    gas: 300_000_000_000_000,
                                    deposit: 0,
                                })],
                            )
                            .await
                            .unwrap();
                        Ok(NodeState::Joining(self))
                    }
                }
            }
            ProtocolState::Resharing(contract_state) => {
                if contract_state
                    .new_participants
                    .contains_account_id(ctx.my_account_id())
                {
                    tracing::info!("joining(resharing): joining as a new participant");
                    start_resharing(None, ctx, contract_state).await
                } else {
                    tracing::debug!("joining(resharing): network is resharing without us, waiting for them to finish");
                    Ok(NodeState::Joining(self))
                }
            }
        }
    }
}

#[async_trait]
impl ConsensusProtocol for NodeState {
    async fn advance<C: ConsensusCtx + Send + Sync>(
        self,
        ctx: C,
        contract_state: ProtocolState,
    ) -> Result<NodeState, ConsensusError> {
        match self {
            NodeState::Starting => {
                let persistent_node_data = ctx.secret_storage().load().await?;
                let triple_data = load_triples(ctx).await?;
                Ok(NodeState::Started(StartedState {
                    persistent_node_data,
                    triple_data,
                }))
            }
            NodeState::Started(state) => state.advance(ctx, contract_state).await,
            NodeState::Generating(state) => state.advance(ctx, contract_state).await,
            NodeState::WaitingForConsensus(state) => state.advance(ctx, contract_state).await,
            NodeState::Running(state) => state.advance(ctx, contract_state).await,
            NodeState::Resharing(state) => state.advance(ctx, contract_state).await,
            NodeState::Joining(state) => state.advance(ctx, contract_state).await,
        }
    }
}

async fn load_triples<C: ConsensusCtx + Send + Sync>(
    ctx: C,
) -> Result<Vec<TripleData>, ConsensusError> {
    let triple_storage = ctx.triple_storage();
    let read_lock = triple_storage.read().await;
    let mut retries = 3;
    let mut error = None;
    while retries > 0 {
        match read_lock.load().await {
            Err(DatastoreStorageError::FetchEntitiesError(_)) => {
                tracing::info!("There are no triples persisted.");
                drop(read_lock);
                return Ok(vec![]);
            }
            Err(e) => {
                retries -= 1;
                tracing::warn!(?e, "triple load failed.");
                error = Some(e);
                tokio::time::sleep(std::time::Duration::from_millis(500)).await;
            }
            Ok(loaded_triples) => {
                drop(read_lock);
                return Ok(loaded_triples);
            }
        }
    }
    drop(read_lock);
    Err(ConsensusError::DatastoreStorageError(error.unwrap()))
}

async fn start_resharing<C: ConsensusCtx>(
    private_share: Option<SecretKeyShare>,
    ctx: C,
    contract_state: ResharingContractState,
) -> Result<NodeState, ConsensusError> {
    let me = contract_state
        .new_participants
        .find_participant(ctx.my_account_id())
        .unwrap();
    let protocol = ReshareProtocol::new(private_share, me, &contract_state)?;
    Ok(NodeState::Resharing(ResharingState {
        old_epoch: contract_state.old_epoch,
        old_participants: contract_state.old_participants,
        new_participants: contract_state.new_participants,
        threshold: contract_state.threshold,
        public_key: contract_state.public_key,
        protocol,
        messages: Default::default(),
    }))
}

'''
'''--- node/src/protocol/contract/mod.rs ---
pub mod primitives;

use crate::types::PublicKey;
use crate::util::NearPublicKeyExt;
use mpc_contract::ProtocolContractState;
use near_primitives::types::AccountId;
use serde::{Deserialize, Serialize};
use std::{collections::HashSet, str::FromStr};

use self::primitives::{Candidates, Participants, PkVotes, Votes};

#[derive(Serialize, Deserialize, Debug)]
pub struct InitializingContractState {
    pub candidates: Candidates,
    pub threshold: usize,
    pub pk_votes: PkVotes,
}

impl From<mpc_contract::InitializingContractState> for InitializingContractState {
    fn from(value: mpc_contract::InitializingContractState) -> Self {
        InitializingContractState {
            candidates: value.candidates.into(),
            threshold: value.threshold,
            pk_votes: value.pk_votes.into(),
        }
    }
}

#[derive(Serialize, Deserialize, Debug)]
pub struct RunningContractState {
    pub epoch: u64,
    pub participants: Participants,
    pub threshold: usize,
    pub public_key: PublicKey,
    pub candidates: Candidates,
    pub join_votes: Votes,
    pub leave_votes: Votes,
}

impl From<mpc_contract::RunningContractState> for RunningContractState {
    fn from(value: mpc_contract::RunningContractState) -> Self {
        RunningContractState {
            epoch: value.epoch,
            participants: value.participants.into(),
            threshold: value.threshold,
            public_key: value.public_key.into_affine_point(),
            candidates: value.candidates.into(),
            join_votes: value.join_votes.into(),
            leave_votes: value.leave_votes.into(),
        }
    }
}

#[derive(Serialize, Deserialize, Debug)]
pub struct ResharingContractState {
    pub old_epoch: u64,
    pub old_participants: Participants,
    pub new_participants: Participants,
    pub threshold: usize,
    pub public_key: PublicKey,
    pub finished_votes: HashSet<AccountId>,
}

impl From<mpc_contract::ResharingContractState> for ResharingContractState {
    fn from(contract_state: mpc_contract::ResharingContractState) -> Self {
        ResharingContractState {
            old_epoch: contract_state.old_epoch,
            old_participants: contract_state.old_participants.into(),
            new_participants: contract_state.new_participants.into(),
            threshold: contract_state.threshold,
            public_key: contract_state.public_key.into_affine_point(),
            finished_votes: contract_state
                .finished_votes
                .into_iter()
                .map(|acc_id| AccountId::from_str(acc_id.as_ref()).unwrap())
                .collect(),
        }
    }
}

#[derive(Debug)]
pub enum ProtocolState {
    Initializing(InitializingContractState),
    Running(RunningContractState),
    Resharing(ResharingContractState),
}

impl ProtocolState {
    pub fn public_key(&self) -> Option<&PublicKey> {
        match self {
            ProtocolState::Initializing { .. } => None,
            ProtocolState::Running(RunningContractState { public_key, .. }) => Some(public_key),
            ProtocolState::Resharing(ResharingContractState { public_key, .. }) => Some(public_key),
        }
    }

    pub fn threshold(&self) -> usize {
        match self {
            ProtocolState::Initializing(InitializingContractState { threshold, .. }) => *threshold,
            ProtocolState::Running(RunningContractState { threshold, .. }) => *threshold,
            ProtocolState::Resharing(ResharingContractState { threshold, .. }) => *threshold,
        }
    }
}

impl TryFrom<ProtocolContractState> for ProtocolState {
    type Error = ();

    fn try_from(value: ProtocolContractState) -> Result<Self, Self::Error> {
        match value {
            ProtocolContractState::Initializing(state) => {
                Ok(ProtocolState::Initializing(state.into()))
            }
            ProtocolContractState::Running(state) => Ok(ProtocolState::Running(state.into())),
            ProtocolContractState::Resharing(state) => Ok(ProtocolState::Resharing(state.into())),
            ProtocolContractState::NotInitialized => Err(()),
        }
    }
}

'''
'''--- node/src/protocol/contract/primitives.rs ---
use cait_sith::protocol::Participant;
use mpc_keys::hpke;
use near_primitives::{borsh::BorshDeserialize, types::AccountId};
use serde::{Deserialize, Serialize};
use std::{
    collections::{BTreeMap, HashSet},
    str::FromStr,
};

type ParticipantId = u32;

#[derive(Clone, Debug, Serialize, Deserialize, PartialEq, Eq)]
pub struct ParticipantInfo {
    pub id: ParticipantId,
    pub account_id: AccountId,
    pub url: String,
    /// The public key used for encrypting messages.
    pub cipher_pk: hpke::PublicKey,
    /// The public key used for verifying messages.
    pub sign_pk: near_crypto::PublicKey,
}

impl ParticipantInfo {
    pub fn new(id: u32) -> Self {
        Self {
            id,
            account_id: format!("p-{id}").parse().unwrap(),
            url: String::default(),
            cipher_pk: hpke::PublicKey::from_bytes(&[0; 32]),
            sign_pk: near_crypto::PublicKey::empty(near_crypto::KeyType::ED25519),
        }
    }
}

#[derive(Default, Serialize, Deserialize, Debug, Clone, PartialEq)]
pub struct Participants {
    pub participants: BTreeMap<Participant, ParticipantInfo>,
}

impl From<mpc_contract::primitives::Participants> for Participants {
    fn from(contract_participants: mpc_contract::primitives::Participants) -> Self {
        Participants {
            // take position of participant in contract_participants as id for participants
            participants: contract_participants
                .participants
                .into_iter()
                .enumerate()
                .map(|(participant_id, participant)| {
                    let contract_participant_info = participant.1;
                    (
                        Participant::from(participant_id as ParticipantId),
                        ParticipantInfo {
                            id: participant_id as ParticipantId,
                            account_id: AccountId::from_str(
                                contract_participant_info.account_id.as_ref(),
                            )
                            .unwrap(),
                            url: contract_participant_info.url,
                            cipher_pk: hpke::PublicKey::from_bytes(
                                &contract_participant_info.cipher_pk,
                            ),
                            sign_pk: BorshDeserialize::try_from_slice(
                                contract_participant_info.sign_pk.as_bytes(),
                            )
                            .unwrap(),
                        },
                    )
                })
                .collect(),
        }
    }
}

impl From<Candidates> for Participants {
    fn from(candidates: Candidates) -> Self {
        Participants {
            participants: candidates
                .candidates
                .into_iter()
                .enumerate()
                .map(|(participant_id, (account_id, candidate_info))| {
                    (
                        Participant::from(participant_id as ParticipantId),
                        ParticipantInfo {
                            id: participant_id as ParticipantId,
                            account_id,
                            url: candidate_info.url,
                            cipher_pk: candidate_info.cipher_pk,
                            sign_pk: candidate_info.sign_pk,
                        },
                    )
                })
                .collect(),
        }
    }
}

impl IntoIterator for Participants {
    type Item = (Participant, ParticipantInfo);
    type IntoIter = std::collections::btree_map::IntoIter<Participant, ParticipantInfo>;

    fn into_iter(self) -> Self::IntoIter {
        self.participants.into_iter()
    }
}

impl Participants {
    pub fn len(&self) -> usize {
        self.participants.len()
    }

    pub fn is_empty(&self) -> bool {
        self.participants.is_empty()
    }

    pub fn insert(&mut self, id: &Participant, info: ParticipantInfo) {
        self.participants.insert(*id, info);
    }

    pub fn get(&self, id: &Participant) -> Option<&ParticipantInfo> {
        self.participants.get(id)
    }

    pub fn contains_key(&self, id: &Participant) -> bool {
        self.participants.contains_key(id)
    }

    pub fn keys(&self) -> impl Iterator<Item = &Participant> {
        self.participants.keys()
    }

    pub fn keys_vec(&self) -> Vec<Participant> {
        self.participants.keys().cloned().collect()
    }

    pub fn iter(&self) -> impl Iterator<Item = (&Participant, &ParticipantInfo)> {
        self.participants.iter()
    }

    pub fn find_participant(&self, account_id: &AccountId) -> Option<Participant> {
        self.participants
            .iter()
            .find(|(_, participant_info)| participant_info.account_id == *account_id)
            .map(|(participant, _)| *participant)
    }

    pub fn find_participant_info(&self, account_id: &AccountId) -> Option<&ParticipantInfo> {
        self.participants
            .values()
            .find(|participant_info| participant_info.account_id == *account_id)
    }

    pub fn contains_account_id(&self, account_id: &AccountId) -> bool {
        self.participants
            .values()
            .any(|participant_info| participant_info.account_id == *account_id)
    }

    pub fn account_ids(&self) -> Vec<&AccountId> {
        self.participants
            .values()
            .map(|participant_info| &participant_info.account_id)
            .collect()
    }

    pub fn and(&self, other: &Self) -> Self {
        let mut participants = self.participants.clone();
        for (participant, info) in &other.participants {
            participants.insert(*participant, info.clone());
        }
        Participants { participants }
    }

    pub fn intersection(&self, other: &[&[Participant]]) -> Self {
        let mut intersect = BTreeMap::new();
        let other = other
            .iter()
            .map(|participants| participants.iter().cloned().collect::<HashSet<_>>())
            .collect::<Vec<_>>();

        'outer: for (participant, info) in &self.participants {
            for participants in &other {
                if !participants.contains(participant) {
                    continue 'outer;
                }
            }
            intersect.insert(*participant, info.clone());
        }
        Participants {
            participants: intersect,
        }
    }
}

#[derive(Clone, Debug, Serialize, Deserialize, PartialEq, Eq)]
pub struct CandidateInfo {
    pub account_id: AccountId,
    pub url: String,
    /// The public key used for encrypting messages.
    pub cipher_pk: hpke::PublicKey,
    /// The public key used for verifying messages.
    pub sign_pk: near_crypto::PublicKey,
}

#[derive(Serialize, Deserialize, Debug, Clone)]
pub struct Candidates {
    pub candidates: BTreeMap<AccountId, CandidateInfo>,
}

impl Candidates {
    pub fn get(&self, id: &AccountId) -> Option<&CandidateInfo> {
        self.candidates.get(id)
    }

    pub fn contains_key(&self, id: &AccountId) -> bool {
        self.candidates.contains_key(id)
    }

    pub fn keys(&self) -> impl Iterator<Item = &AccountId> {
        self.candidates.keys()
    }

    pub fn iter(&self) -> impl Iterator<Item = (&AccountId, &CandidateInfo)> {
        self.candidates.iter()
    }

    pub fn find_candidate(&self, account_id: &AccountId) -> Option<&CandidateInfo> {
        self.candidates.get(account_id)
    }
}

impl From<mpc_contract::primitives::Candidates> for Candidates {
    fn from(contract_candidates: mpc_contract::primitives::Candidates) -> Self {
        Candidates {
            candidates: contract_candidates
                .candidates
                .into_iter()
                .map(|(account_id, candidate_info)| {
                    (
                        AccountId::from_str(account_id.as_ref()).unwrap(),
                        CandidateInfo {
                            account_id: AccountId::from_str(candidate_info.account_id.as_ref())
                                .unwrap(),
                            url: candidate_info.url,
                            cipher_pk: hpke::PublicKey::from_bytes(&candidate_info.cipher_pk),
                            sign_pk: BorshDeserialize::try_from_slice(
                                candidate_info.sign_pk.as_bytes(),
                            )
                            .unwrap(),
                        },
                    )
                })
                .collect(),
        }
    }
}

#[derive(Serialize, Deserialize, Debug, Clone)]
pub struct PkVotes {
    pub pk_votes: BTreeMap<near_crypto::PublicKey, HashSet<AccountId>>,
}

impl PkVotes {
    pub fn get(&self, id: &near_crypto::PublicKey) -> Option<&HashSet<AccountId>> {
        self.pk_votes.get(id)
    }
}

impl From<mpc_contract::primitives::PkVotes> for PkVotes {
    fn from(contract_votes: mpc_contract::primitives::PkVotes) -> Self {
        PkVotes {
            pk_votes: contract_votes
                .votes
                .into_iter()
                .map(|(pk, participants)| {
                    (
                        near_crypto::PublicKey::SECP256K1(
                            near_crypto::Secp256K1PublicKey::try_from(&pk.as_bytes()[1..]).unwrap(),
                        ),
                        participants
                            .into_iter()
                            .map(|acc_id: near_sdk::AccountId| {
                                AccountId::from_str(acc_id.as_ref()).unwrap()
                            })
                            .collect(),
                    )
                })
                .collect(),
        }
    }
}

#[derive(Serialize, Deserialize, Debug)]
pub struct Votes {
    pub votes: BTreeMap<AccountId, HashSet<AccountId>>,
}

impl Votes {
    pub fn get(&self, id: &AccountId) -> Option<&HashSet<AccountId>> {
        self.votes.get(id)
    }
}

impl From<mpc_contract::primitives::Votes> for Votes {
    fn from(contract_votes: mpc_contract::primitives::Votes) -> Self {
        Votes {
            votes: contract_votes
                .votes
                .into_iter()
                .map(|(account_id, participants)| {
                    (
                        AccountId::from_str(account_id.as_ref()).unwrap(),
                        participants
                            .into_iter()
                            .map(|acc_id: near_sdk::AccountId| {
                                AccountId::from_str(acc_id.as_ref()).unwrap()
                            })
                            .collect(),
                    )
                })
                .collect(),
        }
    }
}

'''
'''--- node/src/protocol/cryptography.rs ---
use std::sync::PoisonError;

use super::state::{GeneratingState, NodeState, ResharingState, RunningState};
use super::Config;
use crate::gcp::error::SecretStorageError;
use crate::http_client::SendError;
use crate::mesh::Mesh;
use crate::protocol::message::{GeneratingMessage, ResharingMessage};
use crate::protocol::state::{PersistentNodeData, WaitingForConsensusState};
use crate::protocol::MpcMessage;
use crate::storage::secret_storage::SecretNodeStorageBox;
use async_trait::async_trait;
use cait_sith::protocol::{Action, InitializationError, Participant, ProtocolError};
use k256::elliptic_curve::group::GroupEncoding;
use near_crypto::InMemorySigner;
use near_primitives::types::AccountId;

#[async_trait::async_trait]
pub trait CryptographicCtx {
    async fn me(&self) -> Participant;
    fn http_client(&self) -> &reqwest::Client;
    fn rpc_client(&self) -> &near_fetch::Client;
    fn signer(&self) -> &InMemorySigner;
    fn mpc_contract_id(&self) -> &AccountId;
    fn secret_storage(&mut self) -> &mut SecretNodeStorageBox;
    fn cfg(&self) -> &Config;

    /// Active participants is the active participants at the beginning of each protocol loop.
    fn mesh(&self) -> &Mesh;
}

#[derive(thiserror::Error, Debug)]
pub enum CryptographicError {
    #[error("failed to send a message: {0}")]
    SendError(#[from] SendError),
    #[error("unknown participant: {0:?}")]
    UnknownParticipant(Participant),
    #[error("rpc error: {0}")]
    RpcError(#[from] near_fetch::Error),
    #[error("cait-sith initialization error: {0}")]
    CaitSithInitializationError(#[from] InitializationError),
    #[error("cait-sith protocol error: {0}")]
    CaitSithProtocolError(#[from] ProtocolError),
    #[error("sync failed: {0}")]
    SyncError(String),
    #[error(transparent)]
    DataConversion(#[from] serde_json::Error),
    #[error("encryption failed: {0}")]
    Encryption(String),
    #[error("more than one writing to state: {0}")]
    InvalidStateHandle(String),
    #[error("secret storage error: {0}")]
    SecretStorageError(#[from] SecretStorageError),
}

impl<T> From<PoisonError<T>> for CryptographicError {
    fn from(_: PoisonError<T>) -> Self {
        let typename = std::any::type_name::<T>();
        Self::SyncError(format!("PoisonError: {typename}"))
    }
}

#[async_trait]
pub trait CryptographicProtocol {
    async fn progress<C: CryptographicCtx + Send + Sync>(
        self,
        ctx: C,
    ) -> Result<NodeState, CryptographicError>;
}

#[async_trait]
impl CryptographicProtocol for GeneratingState {
    async fn progress<C: CryptographicCtx + Send + Sync>(
        mut self,
        mut ctx: C,
    ) -> Result<NodeState, CryptographicError> {
        tracing::info!(active = ?ctx.mesh().active_participants().keys_vec(), "generating: progressing key generation");
        let mut protocol = self.protocol.write().await;
        loop {
            let action = match protocol.poke() {
                Ok(action) => action,
                Err(err) => {
                    drop(protocol);
                    if let Err(refresh_err) = self.protocol.refresh().await {
                        tracing::warn!(?refresh_err, "unable to refresh keygen protocol");
                    }
                    return Err(err)?;
                }
            };
            match action {
                Action::Wait => {
                    drop(protocol);
                    tracing::debug!("generating: waiting");
                    let failures = self
                        .messages
                        .write()
                        .await
                        .send_encrypted(
                            ctx.me().await,
                            &ctx.cfg().network_cfg.sign_sk,
                            ctx.http_client(),
                            ctx.mesh().active_participants(),
                        )
                        .await;
                    if !failures.is_empty() {
                        tracing::warn!(
                            active = ?ctx.mesh().active_participants().keys_vec(),
                            "generating(wait): failed to send encrypted message; {failures:?}"
                        );
                    }

                    return Ok(NodeState::Generating(self));
                }
                Action::SendMany(data) => {
                    tracing::debug!("generating: sending a message to many participants");
                    let mut messages = self.messages.write().await;
                    for (p, info) in ctx.mesh().active_participants().iter() {
                        if p == &ctx.me().await {
                            // Skip yourself, cait-sith never sends messages to oneself
                            continue;
                        }
                        messages.push(
                            info.clone(),
                            MpcMessage::Generating(GeneratingMessage {
                                from: ctx.me().await,
                                data: data.clone(),
                            }),
                        );
                    }
                }
                Action::SendPrivate(to, data) => {
                    tracing::debug!("generating: sending a private message to {to:?}");
                    let info = self.fetch_participant(&to)?;
                    self.messages.write().await.push(
                        info.clone(),
                        MpcMessage::Generating(GeneratingMessage {
                            from: ctx.me().await,
                            data,
                        }),
                    );
                }
                Action::Return(r) => {
                    tracing::info!(
                        public_key = hex::encode(r.public_key.to_bytes()),
                        "generating: successfully completed key generation"
                    );
                    ctx.secret_storage()
                        .store(&PersistentNodeData {
                            epoch: 0,
                            private_share: r.private_share,
                            public_key: r.public_key,
                        })
                        .await?;
                    // Send any leftover messages
                    let failures = self
                        .messages
                        .write()
                        .await
                        .send_encrypted(
                            ctx.me().await,
                            &ctx.cfg().network_cfg.sign_sk,
                            ctx.http_client(),
                            ctx.mesh().active_participants(),
                        )
                        .await;
                    if !failures.is_empty() {
                        tracing::warn!(
                            active = ?ctx.mesh().active_participants().keys_vec(),
                            "generating(return): failed to send encrypted message; {failures:?}"
                        );
                    }
                    return Ok(NodeState::WaitingForConsensus(WaitingForConsensusState {
                        epoch: 0,
                        participants: self.participants,
                        threshold: self.threshold,
                        private_share: r.private_share,
                        public_key: r.public_key,
                        messages: self.messages,
                    }));
                }
            }
        }
    }
}

#[async_trait]
impl CryptographicProtocol for WaitingForConsensusState {
    async fn progress<C: CryptographicCtx + Send + Sync>(
        mut self,
        ctx: C,
    ) -> Result<NodeState, CryptographicError> {
        let failures = self
            .messages
            .write()
            .await
            .send_encrypted(
                ctx.me().await,
                &ctx.cfg().network_cfg.sign_sk,
                ctx.http_client(),
                ctx.mesh().active_participants(),
            )
            .await;
        if !failures.is_empty() {
            tracing::warn!(
                active = ?ctx.mesh().active_participants().keys_vec(),
                "waitingForConsensus: failed to send encrypted message; {failures:?}"
            );
        }

        // Wait for ConsensusProtocol step to advance state
        Ok(NodeState::WaitingForConsensus(self))
    }
}

#[async_trait]
impl CryptographicProtocol for ResharingState {
    async fn progress<C: CryptographicCtx + Send + Sync>(
        mut self,
        ctx: C,
    ) -> Result<NodeState, CryptographicError> {
        // TODO: we are not using active potential participants here, but we should in the future.
        // Currently resharing protocol does not timeout and restart with new set of participants.
        // So if it picks up a participant that is not active, it will never be able to send a message to it.
        let active = ctx
            .mesh()
            .active_participants()
            .and(&ctx.mesh().potential_participants().await);
        tracing::info!(active = ?active.keys().collect::<Vec<_>>(), "progressing key reshare");
        let mut protocol = self.protocol.write().await;
        loop {
            let action = match protocol.poke() {
                Ok(action) => action,
                Err(err) => {
                    drop(protocol);
                    if let Err(refresh_err) = self.protocol.refresh().await {
                        tracing::warn!(?refresh_err, "unable to refresh reshare protocol");
                    }
                    return Err(err)?;
                }
            };
            match action {
                Action::Wait => {
                    drop(protocol);
                    tracing::debug!("resharing: waiting");
                    let failures = self
                        .messages
                        .write()
                        .await
                        .send_encrypted(
                            ctx.me().await,
                            &ctx.cfg().network_cfg.sign_sk,
                            ctx.http_client(),
                            &active,
                        )
                        .await;
                    if !failures.is_empty() {
                        tracing::warn!(
                            active = ?active.keys_vec(),
                            new = ?self.new_participants,
                            old = ?self.old_participants,
                            "resharing(wait): failed to send encrypted message; {failures:?}",
                        );
                    }

                    return Ok(NodeState::Resharing(self));
                }
                Action::SendMany(data) => {
                    tracing::debug!("resharing: sending a message to all participants");
                    let me = ctx.me().await;
                    let mut messages = self.messages.write().await;
                    for (p, info) in self.new_participants.iter() {
                        if p == &me {
                            // Skip yourself, cait-sith never sends messages to oneself
                            continue;
                        }

                        messages.push(
                            info.clone(),
                            MpcMessage::Resharing(ResharingMessage {
                                epoch: self.old_epoch,
                                from: me,
                                data: data.clone(),
                            }),
                        )
                    }
                }
                Action::SendPrivate(to, data) => {
                    tracing::debug!("resharing: sending a private message to {to:?}");
                    match self.new_participants.get(&to) {
                        Some(info) => self.messages.write().await.push(
                            info.clone(),
                            MpcMessage::Resharing(ResharingMessage {
                                epoch: self.old_epoch,
                                from: ctx.me().await,
                                data,
                            }),
                        ),
                        None => return Err(CryptographicError::UnknownParticipant(to)),
                    }
                }
                Action::Return(private_share) => {
                    tracing::debug!("resharing: successfully completed key reshare");

                    // Send any leftover messages.
                    let failures = self
                        .messages
                        .write()
                        .await
                        .send_encrypted(
                            ctx.me().await,
                            &ctx.cfg().network_cfg.sign_sk,
                            ctx.http_client(),
                            &active,
                        )
                        .await;
                    if !failures.is_empty() {
                        tracing::warn!(
                            active = ?active.keys_vec(),
                            new = ?self.new_participants,
                            old = ?self.old_participants,
                            "resharing(return): failed to send encrypted message; {failures:?}",
                        );
                    }

                    return Ok(NodeState::WaitingForConsensus(WaitingForConsensusState {
                        epoch: self.old_epoch + 1,
                        participants: self.new_participants,
                        threshold: self.threshold,
                        private_share,
                        public_key: self.public_key,
                        messages: self.messages,
                    }));
                }
            }
        }
    }
}

#[async_trait]
impl CryptographicProtocol for RunningState {
    async fn progress<C: CryptographicCtx + Send + Sync>(
        mut self,
        ctx: C,
    ) -> Result<NodeState, CryptographicError> {
        let active = ctx.mesh().active_participants();
        if active.len() < self.threshold {
            tracing::info!(
                active = ?active.keys_vec(),
                "running: not enough participants to progress"
            );
            return Ok(NodeState::Running(self));
        }

        let mut messages = self.messages.write().await;
        let mut triple_manager = self.triple_manager.write().await;
        let my_account_id = triple_manager.my_account_id.clone();
        crate::metrics::MESSAGE_QUEUE_SIZE
            .with_label_values(&[&my_account_id])
            .set(messages.len() as i64);
        triple_manager.stockpile(active)?;
        for (p, msg) in triple_manager.poke().await? {
            let info = self.fetch_participant(&p)?;
            messages.push(info.clone(), MpcMessage::Triple(msg));
        }

        crate::metrics::NUM_TRIPLES_MINE
            .with_label_values(&[&my_account_id])
            .set(triple_manager.mine.len() as i64);
        crate::metrics::NUM_TRIPLES_TOTAL
            .with_label_values(&[&my_account_id])
            .set(triple_manager.triples.len() as i64);
        crate::metrics::NUM_TRIPLE_GENERATORS_INTRODUCED
            .with_label_values(&[&my_account_id])
            .set(triple_manager.introduced.len() as i64);
        crate::metrics::NUM_TRIPLE_GENERATORS_TOTAL
            .with_label_values(&[&my_account_id])
            .set(triple_manager.ongoing.len() as i64);

        let mut presignature_manager = self.presignature_manager.write().await;
        presignature_manager
            .stockpile(
                active,
                &self.public_key,
                &self.private_share,
                &mut triple_manager,
            )
            .await?;
        drop(triple_manager);
        for (p, msg) in presignature_manager.poke()? {
            let info = self.fetch_participant(&p)?;
            messages.push(info.clone(), MpcMessage::Presignature(msg));
        }

        crate::metrics::NUM_PRESIGNATURES_MINE
            .with_label_values(&[&my_account_id])
            .set(presignature_manager.my_len() as i64);
        crate::metrics::NUM_PRESIGNATURES_TOTAL
            .with_label_values(&[&my_account_id])
            .set(presignature_manager.len() as i64);
        crate::metrics::NUM_PRESIGNATURE_GENERATORS_TOTAL
            .with_label_values(&[&my_account_id])
            .set(presignature_manager.potential_len() as i64 - presignature_manager.len() as i64);

        let mut sign_queue = self.sign_queue.write().await;
        crate::metrics::SIGN_QUEUE_SIZE
            .with_label_values(&[&my_account_id])
            .set(sign_queue.len() as i64);

        let mut signature_manager = self.signature_manager.write().await;
        sign_queue.organize(self.threshold, active, ctx.me().await, &my_account_id);
        let my_requests = sign_queue.my_requests(ctx.me().await);
        crate::metrics::SIGN_QUEUE_MINE_SIZE
            .with_label_values(&[&my_account_id])
            .set(my_requests.len() as i64);
        let mut failed_presigs = Vec::new();
        while presignature_manager.my_len() > 0 {
            if let Some((receipt_id, failed_generator)) = signature_manager.take_failed_generator()
            {
                // only retry the failed signature generator if the proposer of the signature is me
                if failed_generator.proposer == signature_manager.me() {
                    let Some(presignature) = presignature_manager.take_mine() else {
                        break;
                    };
                    let sig_participants = active.intersection(&[&presignature.participants]);
                    if sig_participants.len() < self.threshold {
                        tracing::debug!(
                            participants = ?sig_participants.keys_vec(),
                            "running: we don't have enough participants to generate a failed signature"
                        );
                        failed_presigs.push(presignature);
                        continue;
                    }

                    signature_manager.retry_failed_generation(
                        receipt_id,
                        &failed_generator,
                        presignature,
                        &sig_participants,
                    );
                }
            }

            let Some((receipt_id, _)) = my_requests.iter().next() else {
                break;
            };

            let Some(presignature) = presignature_manager.take_mine() else {
                break;
            };

            let receipt_id = *receipt_id;
            let sig_participants = active.intersection(&[&presignature.participants]);
            if sig_participants.len() < self.threshold {
                tracing::debug!(
                    participants = ?sig_participants.keys_vec(),
                    "running: we don't have enough participants to generate a signature"
                );
                failed_presigs.push(presignature);
                continue;
            }

            let my_request = my_requests.remove(&receipt_id).unwrap();
            signature_manager.generate(
                &sig_participants,
                receipt_id,
                presignature,
                self.public_key,
                my_request.msg_hash,
                my_request.epsilon,
                my_request.delta,
                my_request.time_added,
            )?;
        }
        drop(sign_queue);
        for presignature in failed_presigs {
            presignature_manager.insert_mine(presignature);
        }
        drop(presignature_manager);
        for (p, msg) in signature_manager.poke() {
            let info = self.fetch_participant(&p)?;
            messages.push(info.clone(), MpcMessage::Signature(msg));
        }
        signature_manager
            .publish(
                ctx.rpc_client(),
                ctx.signer(),
                ctx.mpc_contract_id(),
                &my_account_id,
            )
            .await?;
        drop(signature_manager);
        let failures = messages
            .send_encrypted(
                ctx.me().await,
                &ctx.cfg().network_cfg.sign_sk,
                ctx.http_client(),
                active,
            )
            .await;
        if !failures.is_empty() {
            tracing::warn!(
                active = ?active.keys_vec(),
                "running: failed to send encrypted message; {failures:?}"
            );
        }
        drop(messages);

        Ok(NodeState::Running(self))
    }
}

#[async_trait]
impl CryptographicProtocol for NodeState {
    async fn progress<C: CryptographicCtx + Send + Sync>(
        self,
        ctx: C,
    ) -> Result<NodeState, CryptographicError> {
        match self {
            NodeState::Generating(state) => state.progress(ctx).await,
            NodeState::Resharing(state) => state.progress(ctx).await,
            NodeState::Running(state) => state.progress(ctx).await,
            NodeState::WaitingForConsensus(state) => state.progress(ctx).await,
            _ => Ok(self),
        }
    }
}

'''
'''--- node/src/protocol/message.rs ---
use super::cryptography::CryptographicError;
use super::presignature::{self, PresignatureId};
use super::state::{GeneratingState, NodeState, ResharingState, RunningState};
use super::triple::TripleId;
use crate::gcp::error::SecretStorageError;
use crate::http_client::SendError;
use crate::mesh::Mesh;
use crate::util;

use async_trait::async_trait;
use cait_sith::protocol::{InitializationError, MessageData, Participant, ProtocolError};
use k256::Scalar;
use mpc_keys::hpke::{self, Ciphered};
use near_crypto::Signature;
use near_primitives::hash::CryptoHash;
use serde::{Deserialize, Serialize};
use std::collections::{HashMap, VecDeque};
use std::sync::Arc;
use std::time::Instant;
use tokio::sync::RwLock;

#[async_trait::async_trait]
pub trait MessageCtx {
    async fn me(&self) -> Participant;
    fn mesh(&self) -> &Mesh;
}

#[derive(Serialize, Deserialize, Debug, PartialEq, Eq)]
pub struct GeneratingMessage {
    pub from: Participant,
    pub data: MessageData,
}

#[derive(Serialize, Deserialize, Debug, PartialEq, Eq)]
pub struct ResharingMessage {
    pub epoch: u64,
    pub from: Participant,
    pub data: MessageData,
}

#[derive(Serialize, Deserialize, Debug, PartialEq, Eq)]
pub struct TripleMessage {
    pub id: u64,
    pub epoch: u64,
    pub from: Participant,
    pub data: MessageData,
    // UNIX timestamp as seconds since the epoch
    pub timestamp: u64,
}

#[derive(Serialize, Deserialize, Debug, PartialEq, Eq)]
pub struct PresignatureMessage {
    pub id: u64,
    pub triple0: TripleId,
    pub triple1: TripleId,
    pub epoch: u64,
    pub from: Participant,
    pub data: MessageData,
    // UNIX timestamp as seconds since the epoch
    pub timestamp: u64,
}

#[derive(Serialize, Deserialize, Debug, PartialEq, Eq)]
pub struct SignatureMessage {
    pub receipt_id: CryptoHash,
    pub proposer: Participant,
    pub presignature_id: PresignatureId,
    pub msg_hash: [u8; 32],
    pub epsilon: Scalar,
    pub delta: Scalar,
    pub epoch: u64,
    pub from: Participant,
    pub data: MessageData,
    // UNIX timestamp as seconds since the epoch
    pub timestamp: u64,
}

#[derive(Serialize, Deserialize, Debug, PartialEq, Eq)]
pub enum MpcMessage {
    Generating(GeneratingMessage),
    Resharing(ResharingMessage),
    Triple(TripleMessage),
    Presignature(PresignatureMessage),
    Signature(SignatureMessage),
}

impl MpcMessage {
    pub const fn typename(&self) -> &'static str {
        match self {
            MpcMessage::Generating(_) => "Generating",
            MpcMessage::Resharing(_) => "Resharing",
            MpcMessage::Triple(_) => "Triple",
            MpcMessage::Presignature(_) => "Presignature",
            MpcMessage::Signature(_) => "Signature",
        }
    }
}

#[derive(Default)]
pub struct MpcMessageQueue {
    generating: VecDeque<GeneratingMessage>,
    resharing_bins: HashMap<u64, VecDeque<ResharingMessage>>,
    triple_bins: HashMap<u64, HashMap<TripleId, VecDeque<TripleMessage>>>,
    presignature_bins: HashMap<u64, HashMap<PresignatureId, VecDeque<PresignatureMessage>>>,
    signature_bins: HashMap<u64, HashMap<CryptoHash, VecDeque<SignatureMessage>>>,
}

impl MpcMessageQueue {
    pub fn push(&mut self, message: MpcMessage) {
        match message {
            MpcMessage::Generating(message) => self.generating.push_back(message),
            MpcMessage::Resharing(message) => self
                .resharing_bins
                .entry(message.epoch)
                .or_default()
                .push_back(message),
            MpcMessage::Triple(message) => self
                .triple_bins
                .entry(message.epoch)
                .or_default()
                .entry(message.id)
                .or_default()
                .push_back(message),
            MpcMessage::Presignature(message) => self
                .presignature_bins
                .entry(message.epoch)
                .or_default()
                .entry(message.id)
                .or_default()
                .push_back(message),
            MpcMessage::Signature(message) => self
                .signature_bins
                .entry(message.epoch)
                .or_default()
                .entry(message.receipt_id)
                .or_default()
                .push_back(message),
        }
    }
}

#[derive(thiserror::Error, Debug)]
pub enum MessageHandleError {
    #[error("cait-sith initialization error: {0}")]
    CaitSithInitializationError(#[from] InitializationError),
    #[error("cait-sith protocol error: {0}")]
    CaitSithProtocolError(#[from] ProtocolError),
    #[error("sync failed: {0}")]
    SyncError(String),
    #[error("failed to send a message: {0}")]
    SendError(SendError),
    #[error("unknown participant: {0:?}")]
    UnknownParticipant(Participant),
    #[error(transparent)]
    DataConversion(#[from] serde_json::Error),
    #[error("encryption failed: {0}")]
    Encryption(String),
    #[error("invalid state")]
    InvalidStateHandle(String),
    #[error("rpc error: {0}")]
    RpcError(#[from] near_fetch::Error),
    #[error("secret storage error: {0}")]
    SecretStorageError(#[from] SecretStorageError),
}

impl From<CryptographicError> for MessageHandleError {
    fn from(value: CryptographicError) -> Self {
        match value {
            CryptographicError::CaitSithInitializationError(e) => {
                Self::CaitSithInitializationError(e)
            }
            CryptographicError::CaitSithProtocolError(e) => Self::CaitSithProtocolError(e),
            CryptographicError::SyncError(e) => Self::SyncError(e),
            CryptographicError::SendError(e) => Self::SendError(e),
            CryptographicError::UnknownParticipant(e) => Self::UnknownParticipant(e),
            CryptographicError::DataConversion(e) => Self::DataConversion(e),
            CryptographicError::Encryption(e) => Self::Encryption(e),
            CryptographicError::InvalidStateHandle(e) => Self::InvalidStateHandle(e),
            CryptographicError::RpcError(e) => Self::RpcError(e),
            CryptographicError::SecretStorageError(e) => Self::SecretStorageError(e),
        }
    }
}

#[async_trait]
pub trait MessageHandler {
    async fn handle<C: MessageCtx + Send + Sync>(
        &mut self,
        ctx: C,
        queue: &mut MpcMessageQueue,
    ) -> Result<(), MessageHandleError>;
}

#[async_trait]
impl MessageHandler for GeneratingState {
    async fn handle<C: MessageCtx + Send + Sync>(
        &mut self,
        _ctx: C,
        queue: &mut MpcMessageQueue,
    ) -> Result<(), MessageHandleError> {
        let mut protocol = self.protocol.write().await;
        while let Some(msg) = queue.generating.pop_front() {
            tracing::debug!("handling new generating message");
            protocol.message(msg.from, msg.data);
        }
        Ok(())
    }
}

#[async_trait]
impl MessageHandler for ResharingState {
    async fn handle<C: MessageCtx + Send + Sync>(
        &mut self,
        _ctx: C,
        queue: &mut MpcMessageQueue,
    ) -> Result<(), MessageHandleError> {
        let q = queue.resharing_bins.entry(self.old_epoch).or_default();
        let mut protocol = self.protocol.write().await;
        while let Some(msg) = q.pop_front() {
            protocol.message(msg.from, msg.data);
        }
        Ok(())
    }
}

#[async_trait]
impl MessageHandler for RunningState {
    async fn handle<C: MessageCtx + Send + Sync>(
        &mut self,
        ctx: C,
        queue: &mut MpcMessageQueue,
    ) -> Result<(), MessageHandleError> {
        let participants = ctx.mesh().active_participants();
        let mut triple_manager = self.triple_manager.write().await;

        // remove the triple_id that has already failed from the triple_bins
        queue
            .triple_bins
            .entry(self.epoch)
            .or_default()
            .retain(|id, _| {
                let has_failed = triple_manager.failed_triples.contains_key(id);
                if has_failed {
                    triple_manager.failed_triples.insert(*id, Instant::now());
                }
                !has_failed
            });

        for (id, queue) in queue.triple_bins.entry(self.epoch).or_default() {
            if let Some(protocol) = triple_manager.get_or_generate(*id, participants)? {
                while let Some(message) = queue.pop_front() {
                    protocol.message(message.from, message.data);
                }
            }
        }

        let mut presignature_manager = self.presignature_manager.write().await;
        for (id, queue) in queue.presignature_bins.entry(self.epoch).or_default() {
            let mut leftover_messages = Vec::new();
            while let Some(message) = queue.pop_front() {
                // Skip message if it already timed out
                if util::is_elapsed_longer_than_timeout(
                    message.timestamp,
                    crate::types::PROTOCOL_PRESIG_TIMEOUT,
                ) {
                    continue;
                }

                match presignature_manager
                    .get_or_generate(
                        participants,
                        *id,
                        message.triple0,
                        message.triple1,
                        &mut triple_manager,
                        &self.public_key,
                        &self.private_share,
                    )
                    .await
                {
                    Ok(protocol) => protocol.message(message.from, message.data),
                    Err(presignature::GenerationError::AlreadyGenerated) => {
                        tracing::info!(id, "presignature already generated, nothing left to do")
                    }
                    Err(presignature::GenerationError::TripleIsGenerating(_)) => {
                        // Store the message until triple gets generated
                        leftover_messages.push(message)
                    }
                    Err(presignature::GenerationError::TripleIsMissing(_)) => {
                        // Store the message until triple is ready
                        leftover_messages.push(message)
                    }
                    Err(presignature::GenerationError::CaitSithInitializationError(error)) => {
                        return Err(error.into())
                    }
                    Err(presignature::GenerationError::DatastoreStorageError(_)) => {
                        // Store the message until we are ready to process it
                        leftover_messages.push(message)
                    }
                }
            }
            if !leftover_messages.is_empty() {
                tracing::warn!(
                    msg_count = leftover_messages.len(),
                    "unable to process messages, storing for future"
                );
                queue.extend(leftover_messages);
            }
        }

        let mut signature_manager = self.signature_manager.write().await;
        for (receipt_id, queue) in queue.signature_bins.entry(self.epoch).or_default() {
            let mut leftover_messages = Vec::new();
            while let Some(message) = queue.pop_front() {
                // Skip message if it already timed out
                if util::is_elapsed_longer_than_timeout(
                    message.timestamp,
                    crate::types::PROTOCOL_SIGNATURE_TIMEOUT,
                ) {
                    continue;
                }
                tracing::info!(
                    presignature_id = message.presignature_id,
                    "new signature message"
                );

                // TODO: make consistent with presignature manager AlreadyGenerated.
                if signature_manager.has_completed(&message.presignature_id) {
                    tracing::info!(
                        presignature_id = message.presignature_id,
                        "signature already generated, nothing left to do"
                    );
                    continue;
                }
                // if !self
                //     .sign_queue
                //     .read()
                //     .await
                //     .contains(message.proposer, receipt_id.clone())
                // {
                //     leftover_messages.push(message);
                //     continue;
                // };
                // TODO: Validate that the message matches our sign_queue
                match signature_manager.get_or_generate(
                    participants,
                    *receipt_id,
                    message.proposer,
                    message.presignature_id,
                    message.msg_hash,
                    message.epsilon,
                    message.delta,
                    &mut presignature_manager,
                )? {
                    Some(protocol) => protocol.message(message.from, message.data),
                    None => {
                        // Store the message until we are ready to process it
                        leftover_messages.push(message)
                    }
                }
            }
            if !leftover_messages.is_empty() {
                tracing::warn!(
                    msg_count = leftover_messages.len(),
                    "unable to process messages, storing for future"
                );
                queue.extend(leftover_messages);
            }
        }
        triple_manager.clear_failed_triples();
        triple_manager.clear_taken();
        presignature_manager.clear_taken();
        Ok(())
    }
}

#[async_trait]
impl MessageHandler for NodeState {
    async fn handle<C: MessageCtx + Send + Sync>(
        &mut self,
        ctx: C,
        queue: &mut MpcMessageQueue,
    ) -> Result<(), MessageHandleError> {
        match self {
            NodeState::Generating(state) => state.handle(ctx, queue).await,
            NodeState::Resharing(state) => state.handle(ctx, queue).await,
            NodeState::Running(state) => state.handle(ctx, queue).await,
            _ => {
                tracing::debug!("skipping message processing");
                Ok(())
            }
        }
    }
}

/// A signed message that can be encrypted. Note that the message's signature is included
/// in the encrypted message to avoid from it being tampered with without first decrypting.
#[derive(Serialize, Deserialize)]
pub struct SignedMessage<T> {
    /// The message with all it's related info.
    pub msg: T,
    /// The signature used to verify the authenticity of the encrypted message.
    pub sig: Signature,
    /// From which particpant the message was sent.
    pub from: Participant,
}

impl<T> SignedMessage<T> {
    pub const ASSOCIATED_DATA: &'static [u8] = b"";
}

impl<T> SignedMessage<T>
where
    T: Serialize,
{
    pub fn encrypt(
        msg: &T,
        from: Participant,
        sign_sk: &near_crypto::SecretKey,
        cipher_pk: &hpke::PublicKey,
    ) -> Result<Ciphered, CryptographicError> {
        let msg = serde_json::to_vec(msg)?;
        let sig = sign_sk.sign(&msg);
        let msg = SignedMessage { msg, sig, from };
        let msg = serde_json::to_vec(&msg)?;
        let ciphered = cipher_pk
            .encrypt(&msg, SignedMessage::<T>::ASSOCIATED_DATA)
            .map_err(|e| CryptographicError::Encryption(e.to_string()))?;
        Ok(ciphered)
    }
}

impl<T> SignedMessage<T>
where
    T: for<'a> Deserialize<'a>,
{
    pub async fn decrypt(
        cipher_sk: &hpke::SecretKey,
        protocol_state: &Arc<RwLock<NodeState>>,
        encrypted: Ciphered,
    ) -> Result<T, CryptographicError> {
        let message = cipher_sk
            .decrypt(&encrypted, SignedMessage::<T>::ASSOCIATED_DATA)
            .map_err(|err| CryptographicError::Encryption(err.to_string()))?;
        let SignedMessage::<Vec<u8>> { msg, sig, from } = serde_json::from_slice(&message)?;
        if !sig.verify(
            &msg,
            &protocol_state
                .read()
                .await
                .fetch_participant(&from)?
                .sign_pk,
        ) {
            tracing::error!(from = ?from, "signed message erred out with invalid signature");
            return Err(CryptographicError::Encryption(
                "invalid signature while verifying authenticity of encrypted protocol message"
                    .to_string(),
            ));
        }

        Ok(serde_json::from_slice(&msg)?)
    }
}

'''
'''--- node/src/protocol/mod.rs ---
pub mod contract;
mod cryptography;
pub mod presignature;
mod signature;
pub mod triple;

pub mod consensus;
pub mod message;
pub mod state;

pub use consensus::ConsensusError;
pub use contract::primitives::ParticipantInfo;
pub use contract::ProtocolState;
pub use cryptography::CryptographicError;
pub use message::MpcMessage;
pub use signature::SignQueue;
pub use signature::SignRequest;
pub use state::NodeState;

use self::consensus::ConsensusCtx;
use self::cryptography::CryptographicCtx;
use self::message::MessageCtx;
use self::presignature::PresignatureConfig;
use self::triple::TripleConfig;
use crate::mesh::{Mesh, NetworkConfig};
use crate::protocol::consensus::ConsensusProtocol;
use crate::protocol::cryptography::CryptographicProtocol;
use crate::protocol::message::{MessageHandler, MpcMessageQueue};
use crate::rpc_client::{self};
use crate::storage::secret_storage::SecretNodeStorageBox;
use crate::storage::triple_storage::LockTripleNodeStorageBox;

use cait_sith::protocol::Participant;
use near_crypto::InMemorySigner;
use near_primitives::types::AccountId;
use reqwest::IntoUrl;
use std::time::Instant;
use std::{sync::Arc, time::Duration};
use tokio::sync::mpsc::{self, error::TryRecvError};
use tokio::sync::RwLock;
use url::Url;

#[derive(Clone, Debug)]
pub struct Config {
    pub triple_cfg: TripleConfig,
    pub presig_cfg: PresignatureConfig,
    pub network_cfg: NetworkConfig,
}

struct Ctx {
    my_address: Url,
    account_id: AccountId,
    mpc_contract_id: AccountId,
    signer: InMemorySigner,
    rpc_client: near_fetch::Client,
    http_client: reqwest::Client,
    sign_queue: Arc<RwLock<SignQueue>>,
    secret_storage: SecretNodeStorageBox,
    triple_storage: LockTripleNodeStorageBox,
    cfg: Config,
    mesh: Mesh,
}

impl ConsensusCtx for &mut MpcSignProtocol {
    fn my_account_id(&self) -> &AccountId {
        &self.ctx.account_id
    }

    fn http_client(&self) -> &reqwest::Client {
        &self.ctx.http_client
    }

    fn rpc_client(&self) -> &near_fetch::Client {
        &self.ctx.rpc_client
    }

    fn signer(&self) -> &InMemorySigner {
        &self.ctx.signer
    }

    fn mpc_contract_id(&self) -> &AccountId {
        &self.ctx.mpc_contract_id
    }

    fn my_address(&self) -> &Url {
        &self.ctx.my_address
    }

    fn sign_queue(&self) -> Arc<RwLock<SignQueue>> {
        self.ctx.sign_queue.clone()
    }

    fn secret_storage(&self) -> &SecretNodeStorageBox {
        &self.ctx.secret_storage
    }

    fn cfg(&self) -> &Config {
        &self.ctx.cfg
    }

    fn triple_storage(&self) -> LockTripleNodeStorageBox {
        self.ctx.triple_storage.clone()
    }
}

#[async_trait::async_trait]
impl CryptographicCtx for &mut MpcSignProtocol {
    async fn me(&self) -> Participant {
        get_my_participant(self).await
    }

    fn http_client(&self) -> &reqwest::Client {
        &self.ctx.http_client
    }

    fn rpc_client(&self) -> &near_fetch::Client {
        &self.ctx.rpc_client
    }

    fn signer(&self) -> &InMemorySigner {
        &self.ctx.signer
    }

    fn mpc_contract_id(&self) -> &AccountId {
        &self.ctx.mpc_contract_id
    }

    fn secret_storage(&mut self) -> &mut SecretNodeStorageBox {
        &mut self.ctx.secret_storage
    }

    fn cfg(&self) -> &Config {
        &self.ctx.cfg
    }

    fn mesh(&self) -> &Mesh {
        &self.ctx.mesh
    }
}

#[async_trait::async_trait]
impl MessageCtx for &MpcSignProtocol {
    async fn me(&self) -> Participant {
        get_my_participant(self).await
    }

    fn mesh(&self) -> &Mesh {
        &self.ctx.mesh
    }
}

pub struct MpcSignProtocol {
    ctx: Ctx,
    receiver: mpsc::Receiver<MpcMessage>,
    state: Arc<RwLock<NodeState>>,
}

impl MpcSignProtocol {
    #![allow(clippy::too_many_arguments)]
    pub fn init<U: IntoUrl>(
        my_address: U,
        mpc_contract_id: AccountId,
        account_id: AccountId,
        rpc_client: near_fetch::Client,
        signer: InMemorySigner,
        receiver: mpsc::Receiver<MpcMessage>,
        sign_queue: Arc<RwLock<SignQueue>>,
        secret_storage: SecretNodeStorageBox,
        triple_storage: LockTripleNodeStorageBox,
        cfg: Config,
    ) -> (Self, Arc<RwLock<NodeState>>) {
        let state = Arc::new(RwLock::new(NodeState::Starting));
        let ctx = Ctx {
            my_address: my_address.into_url().unwrap(),
            account_id,
            mpc_contract_id,
            rpc_client,
            http_client: reqwest::Client::new(),
            sign_queue,
            signer,
            secret_storage,
            triple_storage,
            cfg,
            mesh: Mesh::default(),
        };
        let protocol = MpcSignProtocol {
            ctx,
            receiver,
            state: state.clone(),
        };
        (protocol, state)
    }

    pub async fn run(mut self) -> anyhow::Result<()> {
        let my_account_id = self.ctx.account_id.to_string();
        let _span = tracing::info_span!("running", my_account_id);
        crate::metrics::NODE_RUNNING
            .with_label_values(&[&my_account_id])
            .set(1);
        crate::metrics::NODE_VERSION
            .with_label_values(&[&my_account_id])
            .set(node_version());
        let mut queue = MpcMessageQueue::default();
        let mut last_state_update = Instant::now();
        let mut last_pinged = Instant::now();
        loop {
            let protocol_time = Instant::now();
            tracing::debug!("trying to advance mpc recovery protocol");
            loop {
                let msg_result = self.receiver.try_recv();
                match msg_result {
                    Ok(msg) => {
                        tracing::debug!("received a new message");
                        queue.push(msg);
                    }
                    Err(TryRecvError::Empty) => {
                        tracing::debug!("no new messages received");
                        break;
                    }
                    Err(TryRecvError::Disconnected) => {
                        tracing::debug!("communication was disconnected, no more messages will be received, spinning down");
                        return Ok(());
                    }
                }
            }

            let contract_state = if last_state_update.elapsed() > Duration::from_secs(1) {
                let contract_state = match rpc_client::fetch_mpc_contract_state(
                    &self.ctx.rpc_client,
                    &self.ctx.mpc_contract_id,
                )
                .await
                {
                    Ok(contract_state) => contract_state,
                    Err(e) => {
                        tracing::error!("could not fetch contract's state: {e}");
                        tokio::time::sleep(Duration::from_secs(1)).await;
                        continue;
                    }
                };
                tracing::debug!(?contract_state);

                // Establish the participants for this current iteration of the protocol loop. This will
                // set which participants are currently active in the protocol and determines who will be
                // receiving messages.
                self.ctx.mesh.establish_participants(&contract_state).await;

                last_state_update = Instant::now();
                Some(contract_state)
            } else {
                None
            };

            if last_pinged.elapsed() > Duration::from_millis(300) {
                self.ctx.mesh.ping().await;
                last_pinged = Instant::now();
            }

            let state = {
                let guard = self.state.read().await;
                guard.clone()
            };

            let crypto_time = Instant::now();
            let mut state = match state.progress(&mut self).await {
                Ok(state) => state,
                Err(err) => {
                    tracing::info!("protocol unable to progress: {err:?}");
                    tokio::time::sleep(Duration::from_millis(100)).await;
                    continue;
                }
            };
            crate::metrics::PROTOCOL_LATENCY_ITER_CRYPTO
                .with_label_values(&[&my_account_id])
                .observe(crypto_time.elapsed().as_secs_f64());

            let consensus_time = Instant::now();
            if let Some(contract_state) = contract_state {
                state = match state.advance(&mut self, contract_state).await {
                    Ok(state) => state,
                    Err(err) => {
                        tracing::info!("protocol unable to advance: {err:?}");
                        tokio::time::sleep(Duration::from_millis(100)).await;
                        continue;
                    }
                };
            }
            crate::metrics::PROTOCOL_LATENCY_ITER_CONSENSUS
                .with_label_values(&[&my_account_id])
                .observe(consensus_time.elapsed().as_secs_f64());

            let message_time = Instant::now();
            if let Err(err) = state.handle(&self, &mut queue).await {
                tracing::info!("protocol unable to handle messages: {err:?}");
                tokio::time::sleep(Duration::from_millis(100)).await;
                continue;
            }
            crate::metrics::PROTOCOL_LATENCY_ITER_MESSAGE
                .with_label_values(&[&my_account_id])
                .observe(message_time.elapsed().as_secs_f64());

            let sleep_ms = match state {
                NodeState::Generating(_) => 500,
                NodeState::Resharing(_) => 500,
                NodeState::Running(_) => 100,

                NodeState::Starting => 1000,
                NodeState::Started(_) => 1000,
                NodeState::WaitingForConsensus(_) => 1000,
                NodeState::Joining(_) => 1000,
            };

            let mut guard = self.state.write().await;
            *guard = state;
            drop(guard);

            crate::metrics::PROTOCOL_LATENCY_ITER_TOTAL
                .with_label_values(&[&my_account_id])
                .observe(protocol_time.elapsed().as_secs_f64());
            tokio::time::sleep(Duration::from_millis(sleep_ms)).await;
        }
    }
}

async fn get_my_participant(protocol: &MpcSignProtocol) -> Participant {
    let my_near_acc_id = &protocol.ctx.account_id;
    let state = protocol.state.read().await;
    let participant_info = state
        .find_participant_info(my_near_acc_id)
        .unwrap_or_else(|| {
            tracing::error!("could not find participant info for {my_near_acc_id}");
            panic!("could not find participant info for {my_near_acc_id}");
        });
    participant_info.id.into()
}

fn node_version() -> i64 {
    env!("CARGO_PKG_VERSION")
        .split('.')
        .map(|s| s.parse::<i64>().unwrap())
        .fold(0, |acc, x| acc * 1000 + x)
}

'''
'''--- node/src/protocol/presignature.rs ---
use super::message::PresignatureMessage;
use super::triple::{Triple, TripleConfig, TripleId, TripleManager};
use crate::gcp::error::DatastoreStorageError;
use crate::protocol::contract::primitives::Participants;
use crate::types::{PresignatureProtocol, PublicKey, SecretKeyShare};
use crate::util::AffinePointExt;
use cait_sith::protocol::{Action, InitializationError, Participant, ProtocolError};
use cait_sith::{KeygenOutput, PresignArguments, PresignOutput};
use chrono::Utc;
use k256::Secp256k1;
use near_lake_primitives::AccountId;
use std::collections::hash_map::Entry;
use std::collections::{HashMap, HashSet, VecDeque};
use std::time::Instant;

/// Unique number used to identify a specific ongoing presignature generation protocol.
/// Without `PresignatureId` it would be unclear where to route incoming cait-sith presignature
/// generation messages.
pub type PresignatureId = u64;

/// A completed presignature.
pub struct Presignature {
    pub id: PresignatureId,
    pub output: PresignOutput<Secp256k1>,
    pub participants: Vec<Participant>,
}

#[derive(Copy, Clone, Debug)]
pub struct PresignatureConfig {
    pub min_presignatures: usize,
    pub max_presignatures: usize,
}

/// An ongoing presignature generator.
pub struct PresignatureGenerator {
    pub participants: Vec<Participant>,
    pub protocol: PresignatureProtocol,
    pub triple0: TripleId,
    pub triple1: TripleId,
    pub mine: bool,
    pub timestamp: Instant,
}

impl PresignatureGenerator {
    pub fn new(
        protocol: PresignatureProtocol,
        participants: Vec<Participant>,
        triple0: TripleId,
        triple1: TripleId,
        mine: bool,
    ) -> Self {
        Self {
            protocol,
            participants,
            triple0,
            triple1,
            mine,
            timestamp: Instant::now(),
        }
    }

    pub fn poke(&mut self) -> Result<Action<PresignOutput<Secp256k1>>, ProtocolError> {
        if self.timestamp.elapsed() > crate::types::PROTOCOL_PRESIG_TIMEOUT {
            tracing::info!(
                self.triple0,
                self.triple1,
                self.mine,
                "presignature protocol timed out"
            );
            return Err(ProtocolError::Other(
                anyhow::anyhow!("presignature protocol timed out").into(),
            ));
        }

        self.protocol.poke()
    }
}

#[derive(Debug, thiserror::Error)]
pub enum GenerationError {
    #[error("presignature already generated")]
    AlreadyGenerated,
    #[error("triple {0} is missing")]
    TripleIsMissing(TripleId),
    #[error("cait-sith initialization error: {0}")]
    CaitSithInitializationError(#[from] InitializationError),
    #[error("datastore storage error: {0}")]
    DatastoreStorageError(#[from] DatastoreStorageError),
    #[error("triple {0} is generating")]
    TripleIsGenerating(TripleId),
}

/// Abstracts how triples are generated by providing a way to request a new triple that will be
/// complete some time in the future and a way to take an already generated triple.
pub struct PresignatureManager {
    /// Completed unspent presignatures.
    presignatures: HashMap<PresignatureId, Presignature>,
    /// Ongoing presignature generation protocols.
    generators: HashMap<PresignatureId, PresignatureGenerator>,
    /// List of presignature ids generation of which was initiated by the current node.
    mine: VecDeque<PresignatureId>,
    /// The set of presignatures that were introduced to the system by the current node.
    introduced: HashSet<PresignatureId>,
    /// The set of presignatures that were already taken. This will be maintained for at most
    /// presignature timeout period just so messages are cycled through the system.
    taken: HashMap<PresignatureId, Instant>,
    me: Participant,
    threshold: usize,
    epoch: u64,
    my_account_id: AccountId,
    presig_cfg: PresignatureConfig,
}

impl PresignatureManager {
    pub fn new(
        me: Participant,
        threshold: usize,
        epoch: u64,
        my_account_id: &AccountId,
        presig_cfg: &PresignatureConfig,
    ) -> Self {
        Self {
            presignatures: HashMap::new(),
            generators: HashMap::new(),
            mine: VecDeque::new(),
            introduced: HashSet::new(),
            taken: HashMap::new(),
            me,
            threshold,
            epoch,
            my_account_id: my_account_id.clone(),
            presig_cfg: *presig_cfg,
        }
    }

    /// Returns the number of unspent presignatures available in the manager.
    pub fn len(&self) -> usize {
        self.presignatures.len()
    }

    /// Returns the number of unspent presignatures assigned to this node.
    pub fn my_len(&self) -> usize {
        self.mine.len()
    }

    /// Returns the number of unspent presignatures we will have in the manager once
    /// all ongoing generation protocols complete.
    pub fn potential_len(&self) -> usize {
        self.presignatures.len() + self.generators.len()
    }

    /// Returns if there are unspent presignatures available in the manager.
    pub fn is_empty(&self) -> bool {
        self.len() == 0
    }

    pub fn clear_taken(&mut self) {
        self.taken
            .retain(|_, instant| instant.elapsed() < crate::types::TAKEN_TIMEOUT);
    }

    #[allow(clippy::too_many_arguments)]
    fn generate_internal(
        participants: &Participants,
        me: Participant,
        threshold: usize,
        triple0: Triple,
        triple1: Triple,
        public_key: &PublicKey,
        private_share: &SecretKeyShare,
        mine: bool,
    ) -> Result<PresignatureGenerator, InitializationError> {
        let participants: Vec<_> = participants.keys().cloned().collect();
        let protocol = Box::new(cait_sith::presign(
            &participants,
            me,
            // These paramaters appear to be to make it easier to use different indexing schemes for triples
            // Introduced in this PR https://github.com/LIT-Protocol/cait-sith/pull/7
            &participants,
            me,
            PresignArguments {
                triple0: (triple0.share, triple0.public),
                triple1: (triple1.share, triple1.public),
                keygen_out: KeygenOutput {
                    private_share: *private_share,
                    public_key: *public_key,
                },
                threshold,
            },
        )?);
        Ok(PresignatureGenerator::new(
            protocol,
            participants,
            triple0.id,
            triple1.id,
            mine,
        ))
    }

    /// Starts a new presignature generation protocol.
    pub fn generate(
        &mut self,
        participants: &Participants,
        triple0: Triple,
        triple1: Triple,
        public_key: &PublicKey,
        private_share: &SecretKeyShare,
    ) -> Result<(), InitializationError> {
        let id = rand::random();
        tracing::info!(id, "starting protocol to generate a new presignature");
        let generator = Self::generate_internal(
            participants,
            self.me,
            self.threshold,
            triple0,
            triple1,
            public_key,
            private_share,
            true,
        )?;
        self.generators.insert(id, generator);
        self.introduced.insert(id);
        crate::metrics::NUM_TOTAL_HISTORICAL_PRESIGNATURE_GENERATORS
            .with_label_values(&[&self.my_account_id])
            .inc();
        crate::metrics::NUM_TOTAL_HISTORICAL_PRESIGNATURE_GENERATORS_MINE
            .with_label_values(&[&self.my_account_id])
            .inc();
        Ok(())
    }

    pub async fn stockpile(
        &mut self,
        active: &Participants,
        pk: &PublicKey,
        sk_share: &SecretKeyShare,
        triple_manager: &mut TripleManager,
    ) -> Result<(), InitializationError> {
        let PresignatureConfig {
            min_presignatures,
            max_presignatures,
        } = self.presig_cfg;

        let TripleConfig {
            max_concurrent_introduction,
            ..
        } = triple_manager.triple_cfg;

        let not_enough_presignatures = {
            // Stopgap to prevent too many presignatures in the system. This should be around min_presig*nodes*2
            // for good measure so that we have enough presignatures to do sig generation while also maintain
            // the minimum number of presignature where a single node can't flood the system.
            if self.potential_len() >= max_presignatures {
                false
            } else {
                // We will always try to generate a new triple if we have less than the minimum
                self.my_len() < min_presignatures
                    && self.introduced.len() < max_concurrent_introduction
            }
        };

        if not_enough_presignatures {
            // To ensure there is no contention between different nodes we are only using triples
            // that we proposed. This way in a non-BFT environment we are guaranteed to never try
            // to use the same triple as any other node.
            if let Some((triple0, triple1)) = triple_manager.take_two_mine().await {
                let presig_participants = active
                    .intersection(&[&triple0.public.participants, &triple1.public.participants]);
                if presig_participants.len() < self.threshold {
                    tracing::debug!(
                        participants = ?presig_participants.keys_vec(),
                        "running: we don't have enough participants to generate a presignature"
                    );

                    // Insert back the triples to be used later since this active set of
                    // participants were not able to make use of these triples.
                    triple_manager.insert_mine(triple0).await;
                    triple_manager.insert_mine(triple1).await;
                } else {
                    self.generate(&presig_participants, triple0, triple1, pk, sk_share)?;
                }
            } else {
                tracing::debug!("running: we don't have enough triples to generate a presignature");
            }
        }

        Ok(())
    }

    /// Ensures that the presignature with the given id is either:
    /// 1) Already generated in which case returns `None`, or
    /// 2) Is currently being generated by `protocol` in which case returns `Some(protocol)`, or
    /// 3) Has never been seen by the manager in which case start a new protocol and returns `Some(protocol)`, or
    /// 4) Depends on triples (`triple0`/`triple1`) that are unknown to the node
    // TODO: What if the presignature completed generation and is already spent?
    #[allow(clippy::too_many_arguments)]
    pub async fn get_or_generate(
        &mut self,
        participants: &Participants,
        id: PresignatureId,
        triple0: TripleId,
        triple1: TripleId,
        triple_manager: &mut TripleManager,
        public_key: &PublicKey,
        private_share: &SecretKeyShare,
    ) -> Result<&mut PresignatureProtocol, GenerationError> {
        if self.presignatures.contains_key(&id) || self.taken.contains_key(&id) {
            Err(GenerationError::AlreadyGenerated)
        } else {
            match self.generators.entry(id) {
                Entry::Vacant(entry) => {
                    tracing::info!(id, "joining protocol to generate a new presignature");
                    let (triple0, triple1) = match triple_manager.take_two(triple0, triple1).await {
                        Ok(result) => result,
                        Err(error) => match error {
                            GenerationError::TripleIsGenerating(_) => {
                                tracing::warn!(
                                        ?error,
                                        id,
                                        triple0,
                                        triple1,
                                        "could not initiate non-introduced presignature: one triple is generating"
                                    );
                                return Err(error);
                            }
                            GenerationError::TripleIsMissing(_) => {
                                tracing::warn!(
                                        ?error,
                                        id,
                                        triple0,
                                        triple1,
                                        "could not initiate non-introduced presignature: one triple is missing"
                                    );
                                return Err(error);
                            }
                            _ => {
                                return Err(error);
                            }
                        },
                    };
                    let generator = Self::generate_internal(
                        participants,
                        self.me,
                        self.threshold,
                        triple0,
                        triple1,
                        public_key,
                        private_share,
                        false,
                    )?;
                    let generator = entry.insert(generator);
                    crate::metrics::NUM_TOTAL_HISTORICAL_PRESIGNATURE_GENERATORS
                        .with_label_values(&[&self.my_account_id])
                        .inc();
                    Ok(&mut generator.protocol)
                }
                Entry::Occupied(entry) => Ok(&mut entry.into_mut().protocol),
            }
        }
    }

    pub fn take_mine(&mut self) -> Option<Presignature> {
        tracing::info!(mine = ?self.mine, "my presignatures");
        let my_presignature_id = self.mine.pop_front()?;
        self.take(my_presignature_id)
    }

    pub fn take(&mut self, id: PresignatureId) -> Option<Presignature> {
        self.taken.insert(id, Instant::now());
        self.presignatures.remove(&id)
    }

    pub fn insert_mine(&mut self, presig: Presignature) {
        // Remove from taken list if it was there
        self.taken.remove(&presig.id);
        self.mine.push_back(presig.id);
        self.presignatures.insert(presig.id, presig);
    }

    /// Pokes all of the ongoing generation protocols and returns a vector of
    /// messages to be sent to the respective participant.
    ///
    /// An empty vector means we cannot progress until we receive a new message.
    pub fn poke(&mut self) -> Result<Vec<(Participant, PresignatureMessage)>, ProtocolError> {
        let mut messages = Vec::new();
        let mut result = Ok(());
        self.generators.retain(|id, generator| {
            loop {
                let action = match generator.poke() {
                    Ok(action) => action,
                    Err(e) => {
                        self.introduced.remove(id);
                        result = Err(e);
                        break false;
                    }
                };
                match action {
                    Action::Wait => {
                        tracing::debug!("waiting");
                        // Retain protocol until we are finished
                        return true;
                    }
                    Action::SendMany(data) => {
                        for p in generator.participants.iter() {
                            messages.push((
                                *p,
                                PresignatureMessage {
                                    id: *id,
                                    triple0: generator.triple0,
                                    triple1: generator.triple1,
                                    epoch: self.epoch,
                                    from: self.me,
                                    data: data.clone(),
                                    timestamp: Utc::now().timestamp() as u64
                                },
                            ))
                        }
                    }
                    Action::SendPrivate(p, data) => messages.push((
                        p,
                        PresignatureMessage {
                            id: *id,
                            triple0: generator.triple0,
                            triple1: generator.triple1,
                            epoch: self.epoch,
                            from: self.me,
                            data,
                            timestamp: Utc::now().timestamp() as u64
                        },
                    )),
                    Action::Return(output) => {
                        tracing::info!(
                            id,
                            me = ?self.me,
                            big_r = ?output.big_r.to_base58(),
                            "completed presignature generation"
                        );
                        self.presignatures.insert(
                            *id,
                            Presignature {
                                id: *id,
                                output,
                                participants: generator.participants.clone(),
                            },
                        );
                        if generator.mine {
                            tracing::info!(id, "assigning presignature to myself");
                            self.mine.push_back(*id);
                            crate::metrics::NUM_TOTAL_HISTORICAL_PRESIGNATURE_GENERATORS_MINE_SUCCESS
                                .with_label_values(&[&self.my_account_id])
                                .inc();
                        }
                        self.introduced.remove(id);

                        crate::metrics::PRESIGNATURE_LATENCY
                            .with_label_values(&[&self.my_account_id])
                            .observe(generator.timestamp.elapsed().as_secs_f64());
                        crate::metrics::NUM_TOTAL_HISTORICAL_PRESIGNATURE_GENERATORS_SUCCESS
                            .with_label_values(&[&self.my_account_id])
                            .inc();
                        // Do not retain the protocol
                        return false;
                    }
                }
            }
        });
        result.map(|_| messages)
    }
}

'''
'''--- node/src/protocol/signature.rs ---
use super::contract::primitives::Participants;
use super::message::SignatureMessage;
use super::presignature::{Presignature, PresignatureId, PresignatureManager};
use crate::kdf;
use crate::types::{PublicKey, SignatureProtocol};
use crate::util::{AffinePointExt, ScalarExt};
use cait_sith::protocol::{Action, InitializationError, Participant, ProtocolError};
use cait_sith::{FullSignature, PresignOutput};
use chrono::Utc;
use k256::{Scalar, Secp256k1};
use near_crypto::Signer;
use near_fetch::signer::ExposeAccountId;
use near_primitives::hash::CryptoHash;
use near_primitives::transaction::FunctionCallAction;
use near_primitives::types::AccountId;
use rand::rngs::StdRng;
use rand::seq::{IteratorRandom, SliceRandom};
use rand::SeedableRng;
use std::collections::hash_map::Entry;
use std::collections::{HashMap, VecDeque};
use std::time::{Duration, Instant};

/// Duration for which completed signatures are retained.
pub const COMPLETION_EXISTENCE_TIMEOUT: Duration = Duration::from_secs(120 * 60);

pub struct SignRequest {
    pub receipt_id: CryptoHash,
    pub msg_hash: [u8; 32],
    pub epsilon: Scalar,
    pub delta: Scalar,
    pub entropy: [u8; 32],
    pub time_added: Instant,
}

#[derive(Default)]
pub struct SignQueue {
    unorganized_requests: Vec<SignRequest>,
    requests: HashMap<Participant, HashMap<CryptoHash, SignRequest>>,
}

impl SignQueue {
    pub fn new() -> Self {
        Self::default()
    }

    pub fn len(&self) -> usize {
        self.unorganized_requests.len()
    }

    pub fn is_empty(&self) -> bool {
        self.len() == 0
    }

    pub fn add(&mut self, request: SignRequest) {
        tracing::info!(
            receipt_id = %request.receipt_id,
            payload = hex::encode(request.msg_hash),
            entropy = hex::encode(request.entropy),
            "new sign request"
        );
        self.unorganized_requests.push(request);
    }

    pub fn organize(
        &mut self,
        threshold: usize,
        active: &Participants,
        me: Participant,
        my_account_id: &AccountId,
    ) {
        for request in self.unorganized_requests.drain(..) {
            let mut rng = StdRng::from_seed(request.entropy);
            let subset = active.keys().choose_multiple(&mut rng, threshold);
            let proposer = **subset.choose(&mut rng).unwrap();
            if subset.contains(&&me) {
                tracing::info!(
                    receipt_id = %request.receipt_id,
                    ?me,
                    ?subset,
                    ?proposer,
                    "saving sign request: node is in the signer subset"
                );
                let proposer_requests = self.requests.entry(proposer).or_default();
                proposer_requests.insert(request.receipt_id, request);
                crate::metrics::NUM_SIGN_REQUESTS_MINE
                    .with_label_values(&[my_account_id])
                    .inc();
            } else {
                tracing::info!(
                    receipt_id = %request.receipt_id,
                    ?me,
                    ?subset,
                    ?proposer,
                    "skipping sign request: node is NOT in the signer subset"
                );
            }
        }
    }

    pub fn contains(&self, participant: Participant, receipt_id: CryptoHash) -> bool {
        let Some(participant_requests) = self.requests.get(&participant) else {
            return false;
        };
        participant_requests.contains_key(&receipt_id)
    }

    pub fn my_requests(&mut self, me: Participant) -> &mut HashMap<CryptoHash, SignRequest> {
        self.requests.entry(me).or_default()
    }
}

/// An ongoing signature generator.
pub struct SignatureGenerator {
    pub protocol: SignatureProtocol,
    pub participants: Vec<Participant>,
    pub proposer: Participant,
    pub presignature_id: PresignatureId,
    pub msg_hash: [u8; 32],
    pub epsilon: Scalar,
    pub delta: Scalar,
    pub sign_request_timestamp: Instant,
    pub generator_timestamp: Instant,
}

impl SignatureGenerator {
    #[allow(clippy::too_many_arguments)]
    pub fn new(
        protocol: SignatureProtocol,
        participants: Vec<Participant>,
        proposer: Participant,
        presignature_id: PresignatureId,
        msg_hash: [u8; 32],
        epsilon: Scalar,
        delta: Scalar,
        sign_request_timestamp: Instant,
    ) -> Self {
        Self {
            protocol,
            participants,
            proposer,
            presignature_id,
            msg_hash,
            epsilon,
            delta,
            sign_request_timestamp,
            generator_timestamp: Instant::now(),
        }
    }

    pub fn poke(&mut self) -> Result<Action<FullSignature<Secp256k1>>, ProtocolError> {
        if self.generator_timestamp.elapsed() > crate::types::PROTOCOL_SIGNATURE_TIMEOUT {
            tracing::info!(self.presignature_id, "signature protocol timed out");
            return Err(ProtocolError::Other(
                anyhow::anyhow!("signature protocol timed out").into(),
            ));
        }

        self.protocol.poke()
    }
}

/// Generator for signature thas has failed. Only retains essential information
/// for starting up this failed signature once again.
pub struct FailedGenerator {
    pub proposer: Participant,
    pub msg_hash: [u8; 32],
    pub epsilon: Scalar,
    pub delta: Scalar,
    pub sign_request_timestamp: Instant,
}

pub struct SignatureManager {
    /// Ongoing signature generation protocols.
    generators: HashMap<CryptoHash, SignatureGenerator>,
    /// Failed signatures awaiting to be retried.
    failed_generators: VecDeque<(CryptoHash, FailedGenerator)>,
    /// Set of completed signatures
    completed: HashMap<PresignatureId, Instant>,
    /// Generated signatures assigned to the current node that are yet to be published.
    /// Vec<(receipt_id, msg_hash, timestamp, output)>
    signatures: Vec<(CryptoHash, [u8; 32], Instant, FullSignature<Secp256k1>)>,
    me: Participant,
    public_key: PublicKey,
    epoch: u64,
}

impl SignatureManager {
    pub fn new(me: Participant, public_key: PublicKey, epoch: u64) -> Self {
        Self {
            generators: HashMap::new(),
            failed_generators: VecDeque::new(),
            completed: HashMap::new(),
            signatures: Vec::new(),
            me,
            public_key,
            epoch,
        }
    }

    pub fn failed_len(&self) -> usize {
        self.failed_generators.len()
    }

    pub fn me(&self) -> Participant {
        self.me
    }

    #[allow(clippy::too_many_arguments)]
    fn generate_internal(
        participants: &Participants,
        me: Participant,
        public_key: PublicKey,
        proposer: Participant,
        presignature: Presignature,
        msg_hash: [u8; 32],
        epsilon: Scalar,
        delta: Scalar,
        sign_request_timestamp: Instant,
    ) -> Result<SignatureGenerator, InitializationError> {
        let participants: Vec<_> = participants.keys().cloned().collect();
        let PresignOutput { big_r, k, sigma } = presignature.output;
        // TODO: Check whether it is okay to use invert_vartime instead
        let output: PresignOutput<Secp256k1> = PresignOutput {
            big_r: (big_r * delta).to_affine(),
            k: k * delta.invert().unwrap(),
            sigma: (sigma + epsilon * k) * delta.invert().unwrap(),
        };
        let protocol = Box::new(cait_sith::sign(
            &participants,
            me,
            kdf::derive_key(public_key, epsilon),
            output,
            Scalar::from_bytes(&msg_hash),
        )?);
        Ok(SignatureGenerator::new(
            protocol,
            participants,
            proposer,
            presignature.id,
            msg_hash,
            epsilon,
            delta,
            sign_request_timestamp,
        ))
    }

    pub fn take_failed_generator(&mut self) -> Option<(CryptoHash, FailedGenerator)> {
        self.failed_generators.pop_front()
    }

    pub fn retry_failed_generation(
        &mut self,
        receipt_id: CryptoHash,
        failed_generator: &FailedGenerator,
        presignature: Presignature,
        participants: &Participants,
    ) -> Option<()> {
        tracing::info!(receipt_id = %receipt_id, participants = ?participants.keys().collect::<Vec<_>>(), "restarting failed protocol to generate signature");
        let generator = Self::generate_internal(
            participants,
            self.me,
            self.public_key,
            failed_generator.proposer,
            presignature,
            failed_generator.msg_hash,
            failed_generator.epsilon,
            failed_generator.delta,
            failed_generator.sign_request_timestamp,
        )
        .unwrap();
        self.generators.insert(receipt_id, generator);
        Some(())
    }

    /// Starts a new presignature generation protocol.
    #[allow(clippy::too_many_arguments)]
    pub fn generate(
        &mut self,
        participants: &Participants,
        receipt_id: CryptoHash,
        presignature: Presignature,
        public_key: PublicKey,
        msg_hash: [u8; 32],
        epsilon: Scalar,
        delta: Scalar,
        sign_request_timestamp: Instant,
    ) -> Result<(), InitializationError> {
        tracing::info!(
            %receipt_id,
            me = ?self.me,
            presignature_id = presignature.id,
            participants = ?participants.keys_vec(),
            "starting protocol to generate a new signature",
        );
        let generator = Self::generate_internal(
            participants,
            self.me,
            public_key,
            self.me,
            presignature,
            msg_hash,
            epsilon,
            delta,
            sign_request_timestamp,
        )?;
        self.generators.insert(receipt_id, generator);
        Ok(())
    }

    /// Ensures that the presignature with the given id is either:
    /// 1) Already generated in which case returns `None`, or
    /// 2) Is currently being generated by `protocol` in which case returns `Some(protocol)`, or
    /// 3) Has never been seen by the manager in which case start a new protocol and returns `Some(protocol)`, or
    /// 4) Depends on triples (`triple0`/`triple1`) that are unknown to the node
    // TODO: What if the presignature completed generation and is already spent?
    #[allow(clippy::too_many_arguments)]
    pub fn get_or_generate(
        &mut self,
        participants: &Participants,
        receipt_id: CryptoHash,
        proposer: Participant,
        presignature_id: PresignatureId,
        msg_hash: [u8; 32],
        epsilon: Scalar,
        delta: Scalar,
        presignature_manager: &mut PresignatureManager,
    ) -> Result<Option<&mut SignatureProtocol>, InitializationError> {
        match self.generators.entry(receipt_id) {
            Entry::Vacant(entry) => {
                tracing::info!(%receipt_id, me = ?self.me, presignature_id, "joining protocol to generate a new signature");
                let Some(presignature) = presignature_manager.take(presignature_id) else {
                    tracing::warn!(me = ?self.me, presignature_id, "presignature is missing, can't join");
                    return Ok(None);
                };
                tracing::info!(me = ?self.me, presignature_id, "found presignature: ready to start signature generation");
                let generator = Self::generate_internal(
                    participants,
                    self.me,
                    self.public_key,
                    proposer,
                    presignature,
                    msg_hash,
                    epsilon,
                    delta,
                    Instant::now(),
                )?;
                let generator = entry.insert(generator);
                Ok(Some(&mut generator.protocol))
            }
            Entry::Occupied(entry) => Ok(Some(&mut entry.into_mut().protocol)),
        }
    }

    /// Pokes all of the ongoing generation protocols and returns a vector of
    /// messages to be sent to the respective participant.
    ///
    /// An empty vector means we cannot progress until we receive a new message.
    pub fn poke(&mut self) -> Vec<(Participant, SignatureMessage)> {
        let mut messages = Vec::new();
        self.generators.retain(|receipt_id, generator| {
            loop {
                let action = match generator.poke() {
                    Ok(action) => action,
                    Err(err) => {
                        tracing::warn!(?err, "signature failed to be produced; pushing request back into failed queue");
                        self.failed_generators.push_back((
                            *receipt_id,
                            FailedGenerator {
                                proposer: generator.proposer,
                                msg_hash: generator.msg_hash,
                                epsilon: generator.epsilon,
                                delta: generator.delta,
                                sign_request_timestamp: generator.sign_request_timestamp
                            },
                        ));
                        break false;
                    }
                };
                match action {
                    Action::Wait => {
                        tracing::debug!("waiting");
                        // Retain protocol until we are finished
                        return true;
                    }
                    Action::SendMany(data) => {
                        for p in generator.participants.iter() {
                            messages.push((
                                *p,
                                SignatureMessage {
                                    receipt_id: *receipt_id,
                                    proposer: generator.proposer,
                                    presignature_id: generator.presignature_id,
                                    msg_hash: generator.msg_hash,
                                    epsilon: generator.epsilon,
                                    delta: generator.delta,
                                    epoch: self.epoch,
                                    from: self.me,
                                    data: data.clone(),
                                    timestamp: Utc::now().timestamp() as u64
                                },
                            ))
                        }
                    }
                    Action::SendPrivate(p, data) => messages.push((
                        p,
                        SignatureMessage {
                            receipt_id: *receipt_id,
                            proposer: generator.proposer,
                            presignature_id: generator.presignature_id,
                            msg_hash: generator.msg_hash,
                            epsilon: generator.epsilon,
                            delta: generator.delta,
                            epoch: self.epoch,
                            from: self.me,
                            data,
                            timestamp: Utc::now().timestamp() as u64
                        },
                    )),
                    Action::Return(output) => {
                        tracing::info!(
                            ?receipt_id,
                            me = ?self.me,
                            presignature_id = generator.presignature_id,
                            big_r = ?output.big_r.to_base58(),
                            s = ?output.s,
                            "completed signature generation"
                        );
                        self.completed.insert(generator.presignature_id, Instant::now());
                        if generator.proposer == self.me {
                            self.signatures
                                .push((*receipt_id, generator.msg_hash, generator.sign_request_timestamp, output));
                        }
                        // Do not retain the protocol
                        return false;
                    }
                }
            }
        });
        messages
    }

    pub async fn publish<T: Signer + ExposeAccountId>(
        &mut self,
        rpc_client: &near_fetch::Client,
        signer: &T,
        mpc_contract_id: &AccountId,
        my_account_id: &AccountId,
    ) -> Result<(), near_fetch::Error> {
        for (receipt_id, payload, time_added, signature) in self.signatures.drain(..) {
            // TODO: Figure out how to properly serialize the signature
            // let r_s = signature.big_r.x().concat(signature.s.to_bytes());
            // let tag =
            //     ConditionallySelectable::conditional_select(&2u8, &3u8, signature.big_r.y_is_odd());
            // let signature = r_s.append(tag);
            // let signature = Secp256K1Signature::try_from(signature.as_slice()).unwrap();
            // let signature = Signature::SECP256K1(signature);
            let response = rpc_client
                .send_tx(
                    signer,
                    mpc_contract_id,
                    vec![near_primitives::transaction::Action::FunctionCall(
                        FunctionCallAction {
                            method_name: "respond".to_string(),
                            args: serde_json::to_vec(&serde_json::json!({
                                "payload": payload,
                                "big_r": signature.big_r,
                                "s": signature.s
                            }))
                            .unwrap(),
                            gas: 300_000_000_000_000,
                            deposit: 0,
                        },
                    )],
                )
                .await?;
            crate::metrics::NUM_SIGN_SUCCESS
                .with_label_values(&[my_account_id])
                .inc();
            crate::metrics::SIGN_LATENCY
                .with_label_values(&[my_account_id])
                .observe(time_added.elapsed().as_secs_f64());
            if time_added.elapsed().as_secs() <= 30 {
                crate::metrics::NUM_SIGN_SUCCESS_30S
                    .with_label_values(&[my_account_id])
                    .inc();
            }
            tracing::info!(%receipt_id, big_r = signature.big_r.to_base58(), s = ?signature.s, status = ?response.status, "published signature response");
        }
        Ok(())
    }

    /// Check whether or not the signature has been completed with this presignature_id.
    pub fn has_completed(&mut self, presignature_id: &PresignatureId) -> bool {
        self.completed
            .retain(|_, timestamp| timestamp.elapsed() < COMPLETION_EXISTENCE_TIMEOUT);

        self.completed.contains_key(presignature_id)
    }
}

'''
'''--- node/src/protocol/state.rs ---
use super::contract::primitives::{ParticipantInfo, Participants};
use super::cryptography::CryptographicError;
use super::presignature::PresignatureManager;
use super::signature::SignatureManager;
use super::triple::TripleManager;
use super::SignQueue;
use crate::http_client::MessageQueue;
use crate::storage::triple_storage::TripleData;
use crate::types::{KeygenProtocol, PublicKey, ReshareProtocol, SecretKeyShare};
use cait_sith::protocol::Participant;
use near_primitives::types::AccountId;
use serde::{Deserialize, Serialize};
use std::fmt;
use std::sync::Arc;
use tokio::sync::RwLock;

#[derive(Clone, Serialize, Deserialize)]
pub struct PersistentNodeData {
    pub epoch: u64,
    pub private_share: SecretKeyShare,
    pub public_key: PublicKey,
}

impl fmt::Debug for PersistentNodeData {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        f.debug_struct("PersistentNodeData")
            .field("epoch", &self.epoch)
            .field("public_key", &self.public_key)
            .finish()
    }
}

#[derive(Debug, Clone)]
pub struct StartedState {
    pub persistent_node_data: Option<PersistentNodeData>,
    pub triple_data: Vec<TripleData>,
}

#[derive(Clone)]
pub struct GeneratingState {
    pub participants: Participants,
    pub threshold: usize,
    pub protocol: KeygenProtocol,
    pub messages: Arc<RwLock<MessageQueue>>,
}

impl GeneratingState {
    pub fn fetch_participant(
        &self,
        p: &Participant,
    ) -> Result<&ParticipantInfo, CryptographicError> {
        fetch_participant(p, &self.participants)
    }
}

#[derive(Clone)]
pub struct WaitingForConsensusState {
    pub epoch: u64,
    pub participants: Participants,
    pub threshold: usize,
    pub private_share: SecretKeyShare,
    pub public_key: PublicKey,
    pub messages: Arc<RwLock<MessageQueue>>,
}

impl fmt::Debug for WaitingForConsensusState {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        f.debug_struct("WaitingForConsensusState")
            .field("epoch", &self.epoch)
            .field("threshold", &self.threshold)
            .field("public_key", &self.public_key)
            .field("participants", &self.participants)
            .finish()
    }
}

impl WaitingForConsensusState {
    pub fn fetch_participant(
        &self,
        p: &Participant,
    ) -> Result<&ParticipantInfo, CryptographicError> {
        fetch_participant(p, &self.participants)
    }
}

#[derive(Clone)]
pub struct RunningState {
    pub epoch: u64,
    pub participants: Participants,
    pub threshold: usize,
    pub private_share: SecretKeyShare,
    pub public_key: PublicKey,
    pub sign_queue: Arc<RwLock<SignQueue>>,
    pub triple_manager: Arc<RwLock<TripleManager>>,
    pub presignature_manager: Arc<RwLock<PresignatureManager>>,
    pub signature_manager: Arc<RwLock<SignatureManager>>,
    pub messages: Arc<RwLock<MessageQueue>>,
}

impl RunningState {
    pub fn fetch_participant(
        &self,
        p: &Participant,
    ) -> Result<&ParticipantInfo, CryptographicError> {
        fetch_participant(p, &self.participants)
    }
}

#[derive(Clone)]
pub struct ResharingState {
    pub old_epoch: u64,
    pub old_participants: Participants,
    pub new_participants: Participants,
    pub threshold: usize,
    pub public_key: PublicKey,
    pub protocol: ReshareProtocol,
    pub messages: Arc<RwLock<MessageQueue>>,
}

impl ResharingState {
    pub fn fetch_participant(
        &self,
        p: &Participant,
    ) -> Result<&ParticipantInfo, CryptographicError> {
        fetch_participant(p, &self.new_participants)
            .or_else(|_| fetch_participant(p, &self.old_participants))
    }
}

#[derive(Clone)]
pub struct JoiningState {
    pub participants: Participants,
    pub public_key: PublicKey,
}

impl JoiningState {
    pub fn fetch_participant(
        &self,
        p: &Participant,
    ) -> Result<&ParticipantInfo, CryptographicError> {
        fetch_participant(p, &self.participants)
    }
}

#[derive(Clone, Default)]
#[allow(clippy::large_enum_variant)]
pub enum NodeState {
    #[default]
    Starting,
    Started(StartedState),
    Generating(GeneratingState),
    WaitingForConsensus(WaitingForConsensusState),
    Running(RunningState),
    Resharing(ResharingState),
    Joining(JoiningState),
}

impl NodeState {
    pub fn fetch_participant(
        &self,
        p: &Participant,
    ) -> Result<&ParticipantInfo, CryptographicError> {
        match self {
            NodeState::Running(state) => state.fetch_participant(p),
            NodeState::Generating(state) => state.fetch_participant(p),
            NodeState::WaitingForConsensus(state) => state.fetch_participant(p),
            NodeState::Resharing(state) => state.fetch_participant(p),
            NodeState::Joining(state) => state.fetch_participant(p),
            _ => Err(CryptographicError::UnknownParticipant(*p)),
        }
    }

    pub fn find_participant_info(&self, account_id: &AccountId) -> Option<&ParticipantInfo> {
        match self {
            NodeState::Starting => None,
            NodeState::Started(_) => None,
            NodeState::Generating(state) => state.participants.find_participant_info(account_id),
            NodeState::WaitingForConsensus(state) => {
                state.participants.find_participant_info(account_id)
            }
            NodeState::Running(state) => state.participants.find_participant_info(account_id),
            NodeState::Resharing(state) => state
                .new_participants
                .find_participant_info(account_id)
                .or_else(|| state.old_participants.find_participant_info(account_id)),
            NodeState::Joining(state) => state.participants.find_participant_info(account_id),
        }
    }
}

fn fetch_participant<'a>(
    p: &Participant,
    participants: &'a Participants,
) -> Result<&'a ParticipantInfo, CryptographicError> {
    participants
        .get(p)
        .ok_or_else(|| CryptographicError::UnknownParticipant(*p))
}

'''
'''--- node/src/protocol/triple.rs ---
use super::contract::primitives::Participants;
use super::cryptography::CryptographicError;
use super::message::TripleMessage;
use super::presignature::GenerationError;
use crate::gcp::error;
use crate::storage::triple_storage::{LockTripleNodeStorageBox, TripleData};
use crate::types::TripleProtocol;
use crate::util::AffinePointExt;
use cait_sith::protocol::{Action, InitializationError, Participant, ProtocolError};
use cait_sith::triples::{TripleGenerationOutput, TriplePub, TripleShare};
use chrono::Utc;
use highway::{HighwayHash, HighwayHasher};
use k256::elliptic_curve::group::GroupEncoding;
use k256::Secp256k1;
use near_lake_primitives::AccountId;
use serde::{Deserialize, Serialize};
use std::collections::hash_map::Entry;
use std::collections::{HashMap, HashSet, VecDeque};
use std::time::{Duration, Instant};

/// Unique number used to identify a specific ongoing triple generation protocol.
/// Without `TripleId` it would be unclear where to route incoming cait-sith triple generation
/// messages.
pub type TripleId = u64;

/// A completed triple.
#[derive(Clone, Serialize, Deserialize, Debug)]
pub struct Triple {
    pub id: TripleId,
    pub share: TripleShare<Secp256k1>,
    pub public: TriplePub<Secp256k1>,
}

pub struct TripleGenerator {
    pub id: TripleId,
    pub participants: Vec<Participant>,
    pub protocol: TripleProtocol,
    pub timestamp: Option<Instant>,
}

impl TripleGenerator {
    pub fn new(id: TripleId, participants: Vec<Participant>, protocol: TripleProtocol) -> Self {
        Self {
            id,
            participants,
            protocol,
            timestamp: None,
        }
    }

    pub fn poke(&mut self) -> Result<Action<TripleGenerationOutput<Secp256k1>>, ProtocolError> {
        let timestamp = self.timestamp.get_or_insert_with(Instant::now);
        if timestamp.elapsed() > crate::util::get_triple_timeout() {
            tracing::info!(
                id = self.id,
                elapsed = ?timestamp.elapsed(),
                "triple protocol timed out"
            );
            return Err(ProtocolError::Other(
                anyhow::anyhow!("triple protocol timed out").into(),
            ));
        }

        self.protocol.poke()
    }
}

// TODO: easy way to deserialize human readable string for CLI passable args
#[derive(Copy, Clone, Debug)]
pub struct TripleConfig {
    /// Minimum amount of triples that is owned by each node.
    pub min_triples: usize,
    /// Maximum amount of triples that is owned by each node.
    pub max_triples: usize,
    /// Maximum amount of concurrent triple generation that can be introduce by this node.
    pub max_concurrent_introduction: usize,
    /// Maximum amount of concurrent triple generation that can be done per node.
    pub max_concurrent_generation: usize,
}

/// Abstracts how triples are generated by providing a way to request a new triple that will be
/// complete some time in the future and a way to take an already generated triple.
pub struct TripleManager {
    /// Completed unspent triples
    pub triples: HashMap<TripleId, Triple>,

    /// The pool of triple protocols that have yet to be completed.
    pub generators: HashMap<TripleId, TripleGenerator>,

    /// Triples that are queued to be poked. If these generators sit for too long in
    /// the queue, they will be removed due to triple generation timeout.
    pub queued: VecDeque<TripleId>,

    /// Ongoing triple generation protocols. Once added here, they will not be removed until
    /// they are completed or timed out.
    pub ongoing: HashSet<TripleId>,

    /// The set of triples that were introduced to the system by the current node.
    pub introduced: HashSet<TripleId>,

    /// List of triple ids generation of which was initiated by the current node.
    pub mine: VecDeque<TripleId>,

    /// The set of triple ids that were already taken. This will be maintained for at most
    /// triple timeout period just so messages are cycled through the system.
    pub taken: HashMap<TripleId, Instant>,

    pub me: Participant,
    pub threshold: usize,
    pub epoch: u64,
    pub triple_cfg: TripleConfig,
    pub triple_storage: LockTripleNodeStorageBox,
    /// triple generation protocols that failed.
    pub failed_triples: HashMap<TripleId, Instant>,
    pub my_account_id: AccountId,
}

impl TripleManager {
    pub fn new(
        me: Participant,
        threshold: usize,
        epoch: u64,
        triple_cfg: &TripleConfig,
        triple_data: Vec<TripleData>,
        triple_storage: LockTripleNodeStorageBox,
        my_account_id: &AccountId,
    ) -> Self {
        let mut mine: VecDeque<TripleId> = VecDeque::new();
        let mut all_triples = HashMap::new();
        for entry in triple_data {
            tracing::debug!("the triple data loaded is {:?}", entry);
            if entry.mine {
                tracing::debug!("pushed tripleId = {} into mine.", entry.triple.id);
                mine.push_back(entry.triple.id);
            }
            all_triples.insert(entry.triple.id, entry.triple);
        }
        Self {
            triples: all_triples,
            generators: HashMap::new(),
            queued: VecDeque::new(),
            ongoing: HashSet::new(),
            introduced: HashSet::new(),
            taken: HashMap::new(),
            mine,
            me,
            threshold,
            epoch,
            triple_cfg: *triple_cfg,
            triple_storage,
            failed_triples: HashMap::new(),
            my_account_id: my_account_id.clone(),
        }
    }

    /// Returns the number of unspent triples available in the manager.
    pub fn len(&self) -> usize {
        self.triples.len()
    }

    /// Returns if there's any unspent triple in the manager.
    pub fn is_empty(&self) -> bool {
        self.len() == 0
    }

    /// Returns the number of unspent triples assigned to this node.
    pub fn my_len(&self) -> usize {
        self.mine.len()
    }

    /// Returns the number of unspent triples we will have in the manager once
    /// all ongoing generation protocols complete.
    pub fn potential_len(&self) -> usize {
        self.len() + self.generators.len()
    }

    /// Clears an entry from failed triples if that triple protocol was created more than 2 hrs ago
    pub fn clear_failed_triples(&mut self) {
        self.failed_triples
            .retain(|_, timestamp| timestamp.elapsed() < crate::types::FAILED_TRIPLES_TIMEOUT)
    }

    pub fn clear_taken(&mut self) {
        self.taken
            .retain(|_, timestamp| timestamp.elapsed() < crate::types::TAKEN_TIMEOUT)
    }

    /// Starts a new Beaver triple generation protocol.
    pub fn generate(&mut self, participants: &Participants) -> Result<(), InitializationError> {
        let id = rand::random();
        tracing::debug!(id, "starting protocol to generate a new triple");
        let participants: Vec<_> = participants.keys().cloned().collect();
        let protocol: TripleProtocol = Box::new(cait_sith::triples::generate_triple::<Secp256k1>(
            &participants,
            self.me,
            self.threshold,
        )?);
        self.generators
            .insert(id, TripleGenerator::new(id, participants, protocol));
        self.queued.push_back(id);
        self.introduced.insert(id);
        crate::metrics::NUM_TOTAL_HISTORICAL_TRIPLE_GENERATORS
            .with_label_values(&[&self.my_account_id])
            .inc();
        Ok(())
    }

    /// Stockpile triples if the amount of unspent triples is below the minimum
    /// and the maximum number of all ongoing generation protocols is below the maximum.
    pub fn stockpile(&mut self, participants: &Participants) -> Result<(), InitializationError> {
        let TripleConfig {
            min_triples,
            max_triples,
            max_concurrent_introduction,
            max_concurrent_generation,
        } = self.triple_cfg;

        let not_enough_triples = {
            // Stopgap to prevent too many triples in the system. This should be around min_triple*nodes*2
            // for good measure so that we have enough triples to do presig generation while also maintain
            // the minimum number of triples where a single node can't flood the system.
            if self.potential_len() >= max_triples {
                false
            } else {
                // We will always try to generate a new triple if we have less than the minimum
                self.my_len() < min_triples
                    && self.introduced.len() < max_concurrent_introduction
                    && self.generators.len() < max_concurrent_generation
            }
        };

        if not_enough_triples {
            self.generate(participants)?;
        }
        Ok(())
    }

    /// Take two unspent triple by theirs id with no way to return it. Only takes
    /// if both of them are present.
    /// It is very important to NOT reuse the same triple twice for two different
    /// protocols.
    pub async fn take_two(
        &mut self,
        id0: TripleId,
        id1: TripleId,
    ) -> Result<(Triple, Triple), GenerationError> {
        if !self.triples.contains_key(&id0) {
            if self.generators.contains_key(&id0) {
                Err(GenerationError::TripleIsGenerating(id0))
            } else {
                Err(GenerationError::TripleIsMissing(id0))
            }
        } else if !self.triples.contains_key(&id1) {
            if self.generators.contains_key(&id1) {
                Err(GenerationError::TripleIsGenerating(id1))
            } else {
                Err(GenerationError::TripleIsMissing(id1))
            }
        } else {
            // if we cannot find triples from storage, but we still have triples in memory, then we should still be able to take
            // them, so the following storage errors can just be handled directly and warned to our logs.
            if let Err(err) = self.delete_triple_from_storage(id0).await {
                tracing::warn!(triple_id = id0, ?err, "unable to delete triple: potentially missing from datastore; deleting from memory only");
            }
            if let Err(err) = self.delete_triple_from_storage(id1).await {
                tracing::warn!(triple_id = id1, ?err, "unable to delete triple: potentially missing from datastore; deleting from memory only");
            }

            self.taken.insert(id0, Instant::now());
            self.taken.insert(id1, Instant::now());

            // only remove the triples locally when the datastore removal was successful
            Ok((
                self.triples.remove(&id0).unwrap(),
                self.triples.remove(&id1).unwrap(),
            ))
        }
    }

    async fn delete_triple_from_storage(
        &mut self,
        id: TripleId,
    ) -> Result<(), error::DatastoreStorageError> {
        let action = || async {
            let mut triple_storage = self.triple_storage.write().await;
            if let Err(err) = triple_storage.delete(id).await {
                tracing::warn!(?err, id, "triple deletion failed.");
                return Err(err);
            }
            Ok(())
        };

        // Retry the action 3x with 500ms delay between each retry
        let retry_strategy = std::iter::repeat_with(|| Duration::from_millis(500)).take(3);
        tokio_retry::Retry::spawn(retry_strategy, action).await
    }

    /// Take two random unspent triple generated by this node. Either takes both or none.
    /// It is very important to NOT reuse the same triple twice for two different
    /// protocols.
    pub async fn take_two_mine(&mut self) -> Option<(Triple, Triple)> {
        if self.mine.len() < 2 {
            return None;
        }
        let id0 = self.mine.pop_front()?;
        let id1 = self.mine.pop_front()?;
        tracing::info!(id0, id1, me = ?self.me, "trying to take two triples");

        let take_two_result = self.take_two(id0, id1).await;
        match take_two_result {
            Err(error)
                if matches!(
                    error,
                    GenerationError::TripleIsMissing(_) | GenerationError::TripleIsGenerating(_)
                ) =>
            {
                tracing::warn!(
                    triple_id0 = id0,
                    triple_id1 = id1,
                    ?error,
                    "unable to take two triples: one or both of the triples are missing/not-generated",
                );
                self.mine.push_front(id1);
                self.mine.push_front(id0);
                None
            }
            Err(error) => {
                tracing::warn!(
                    triple_id0 = id0,
                    triple_id1 = id1,
                    ?error,
                    "unexpected error encountered while taking two triples"
                );
                None
            }
            Ok(val) => Some(val),
        }
    }

    pub async fn insert_mine(&mut self, triple: Triple) {
        self.mine.push_back(triple.id);
        self.triples.insert(triple.id, triple.clone());
        self.taken.remove(&triple.id);
        self.insert_triples_to_storage(vec![triple]).await;
    }

    /// Ensures that the triple with the given id is either:
    /// 1) Already generated in which case returns `None`, or
    /// 2) Is currently being generated by `protocol` in which case returns `Some(protocol)`, or
    /// 3) Has never been seen by the manager in which case start a new protocol and returns `Some(protocol)`
    // TODO: What if the triple completed generation and is already spent?
    pub fn get_or_generate(
        &mut self,
        id: TripleId,
        participants: &Participants,
    ) -> Result<Option<&mut TripleProtocol>, CryptographicError> {
        if self.triples.contains_key(&id) || self.taken.contains_key(&id) {
            Ok(None)
        } else {
            let potential_len = self.potential_len();
            match self.generators.entry(id) {
                Entry::Vacant(e) => {
                    if potential_len >= self.triple_cfg.max_triples {
                        // We are at the maximum amount of triples, we cannot generate more. So just in case a node
                        // sends more triple generation requests, reject them and have them tiemout.
                        return Ok(None);
                    }

                    tracing::debug!(id, "joining protocol to generate a new triple");
                    let participants = participants.keys_vec();
                    let protocol = Box::new(cait_sith::triples::generate_triple::<Secp256k1>(
                        &participants,
                        self.me,
                        self.threshold,
                    )?);
                    let generator = e.insert(TripleGenerator::new(id, participants, protocol));
                    self.queued.push_back(id);
                    crate::metrics::NUM_TOTAL_HISTORICAL_TRIPLE_GENERATORS
                        .with_label_values(&[&self.my_account_id])
                        .inc();
                    Ok(Some(&mut generator.protocol))
                }
                Entry::Occupied(e) => Ok(Some(&mut e.into_mut().protocol)),
            }
        }
    }

    /// Pokes all of the ongoing generation protocols and returns a vector of
    /// messages to be sent to the respective participant.
    ///
    /// An empty vector means we cannot progress until we receive a new message.
    pub async fn poke(&mut self) -> Result<Vec<(Participant, TripleMessage)>, ProtocolError> {
        // Add more protocols to the ongoing pool if there is space.
        let to_generate_len = self.triple_cfg.max_concurrent_generation - self.ongoing.len();
        if !self.queued.is_empty() && to_generate_len > 0 {
            for _ in 0..to_generate_len {
                self.queued.pop_front().map(|id| self.ongoing.insert(id));
            }
        }

        let mut messages = Vec::new();
        let mut result = Ok(());
        let mut triples_to_insert = Vec::new();
        self.generators.retain(|id, generator| {
            if !self.ongoing.contains(id) {
                // If the protocol is not ongoing, we should retain it for the next time
                // it is in the ongoing pool.
                return true;
            }

            loop {
                let action = match generator.poke() {
                    Ok(action) => action,
                    Err(e) => {
                        result = Err(e);
                        self.failed_triples.insert(*id, Instant::now());
                        self.ongoing.remove(id);
                        self.introduced.remove(id);
                        tracing::info!(
                            elapsed = ?generator.timestamp.unwrap().elapsed(),
                            "added {id} to failed triples"
                        );
                        break false;
                    }
                };

                match action {
                    Action::Wait => {
                        tracing::debug!("waiting");
                        // Retain protocol until we are finished
                        break true;
                    }
                    Action::SendMany(data) => {
                        for p in &generator.participants {
                            messages.push((
                                *p,
                                TripleMessage {
                                    id: *id,
                                    epoch: self.epoch,
                                    from: self.me,
                                    data: data.clone(),
                                    timestamp: Utc::now().timestamp() as u64,
                                },
                            ))
                        }
                    }
                    Action::SendPrivate(p, data) => messages.push((
                        p,
                        TripleMessage {
                            id: *id,
                            epoch: self.epoch,
                            from: self.me,
                            data,
                            timestamp: Utc::now().timestamp() as u64,
                        },
                    )),
                    Action::Return(output) => {
                        tracing::info!(
                            id,
                            me = ?self.me,
                            elapsed = ?generator.timestamp.unwrap().elapsed(),
                            big_a = ?output.1.big_a.to_base58(),
                            big_b = ?output.1.big_b.to_base58(),
                            big_c = ?output.1.big_c.to_base58(),
                            "completed triple generation"
                        );

                        if let Some(start_time) = generator.timestamp {
                            crate::metrics::TRIPLE_LATENCY
                                .with_label_values(&[&self.my_account_id])
                                .observe(start_time.elapsed().as_secs_f64());
                        }

                        crate::metrics::NUM_TOTAL_HISTORICAL_TRIPLE_GENERATORS_SUCCESS
                            .with_label_values(&[&self.my_account_id])
                            .inc();

                        let triple = Triple {
                            id: *id,
                            share: output.0,
                            public: output.1,
                        };

                        // After creation the triple is assigned to a random node, which is NOT necessarily the one that initiated it's creation
                        let triple_is_mine = {
                            // This is an entirely unpredictable value to all participants because it's a combination of big_c_i
                            // It is the same value across all participants
                            let big_c = triple.public.big_c;

                            // We turn this into a u64 in a way not biased to the structure of the byte serialisation so we hash it
                            // We use Highway Hash because the DefaultHasher doesn't guarantee a consistent output across versions
                            let entropy =
                                HighwayHasher::default().hash64(&big_c.to_bytes()) as usize;

                            let num_participants = generator.participants.len();
                            // This has a *tiny* bias towards lower indexed participants, they're up to (1 + num_participants / u64::MAX)^2 times more likely to be selected
                            // This is acceptably small that it will likely never result in a biased selection happening
                            let triple_owner = generator.participants[entropy % num_participants];

                            triple_owner == self.me
                        };

                        if triple_is_mine {
                            self.mine.push_back(*id);
                            crate::metrics::NUM_TOTAL_HISTORICAL_TRIPLE_GENERATIONS_MINE_SUCCESS
                                .with_label_values(&[&self.my_account_id])
                                .inc();
                        }

                        self.triples.insert(*id, triple.clone());
                        triples_to_insert.push(triple);

                        // Protocol done, remove it from the ongoing pool.
                        self.ongoing.remove(id);
                        self.introduced.remove(id);
                        // Do not retain the protocol
                        break false;
                    }
                }
            }
        });
        self.insert_triples_to_storage(triples_to_insert).await;
        result.map(|_| messages)
    }

    async fn insert_triples_to_storage(&mut self, triples_to_insert: Vec<Triple>) {
        for triple in triples_to_insert {
            let mine = self.mine.contains(&triple.id);
            let action = || async {
                let mut triple_storage = self.triple_storage.write().await;
                if let Err(e) = triple_storage.insert(triple.clone(), mine).await {
                    tracing::warn!(?e, id = triple.id, "triple insertion failed.");
                    return Err(e);
                }
                Ok(())
            };

            // Retry the action 3x with 500ms delay between each retry
            let retry_strategy = std::iter::repeat_with(|| Duration::from_millis(500)).take(3);
            let _ = tokio_retry::Retry::spawn(retry_strategy, action).await;
        }
    }
}

#[cfg(test)]
mod test {
    // TODO: This test currently takes 22 seconds on my machine, which is much slower than it should be
    // Improve this before we make more similar tests
    #[tokio::test]
    async fn test_happy_triple_generation_locally() {
        crate::test_utils::test_triple_generation(None).await
    }

    #[tokio::test]
    async fn test_triple_deletion_locally() {
        crate::test_utils::test_triple_deletion(None).await
    }
}

'''
'''--- node/src/rpc_client.rs ---
use crate::protocol::ProtocolState;
use near_crypto::InMemorySigner;
use near_primitives::transaction::{Action, FunctionCallAction};
use near_primitives::types::AccountId;
use near_primitives::views::FinalExecutionStatus;
use serde_json::json;

pub async fn fetch_mpc_contract_state(
    rpc_client: &near_fetch::Client,
    mpc_contract_id: &AccountId,
) -> anyhow::Result<ProtocolState> {
    let protocol_state: mpc_contract::ProtocolContractState =
        rpc_client.view(mpc_contract_id, "state", ()).await?;
    protocol_state
        .try_into()
        .map_err(|_| anyhow::anyhow!("protocol state has not been initialized yet"))
}

pub async fn vote_for_public_key(
    rpc_client: &near_fetch::Client,
    signer: &InMemorySigner,
    mpc_contract_id: &AccountId,
    public_key: &near_crypto::PublicKey,
) -> anyhow::Result<bool> {
    tracing::info!(%public_key, "voting for public key");
    let args = json!({
        "public_key": public_key
    });
    let result = rpc_client
        .send_tx(
            signer,
            mpc_contract_id,
            vec![Action::FunctionCall(FunctionCallAction {
                method_name: "vote_pk".to_string(),
                args: serde_json::to_vec(&args)?,
                gas: 300_000_000_000_000,
                deposit: 0,
            })],
        )
        .await?;

    match result.status {
        FinalExecutionStatus::SuccessValue(value) => Ok(serde_json::from_slice(&value)?),
        status => anyhow::bail!("unexpected status: {:?}", status),
    }
}

pub async fn vote_reshared(
    rpc_client: &near_fetch::Client,
    signer: &InMemorySigner,
    mpc_contract_id: &AccountId,
    epoch: u64,
) -> anyhow::Result<bool> {
    let args = json!({
        "epoch": epoch
    });
    let result = rpc_client
        .send_tx(
            signer,
            mpc_contract_id,
            vec![Action::FunctionCall(FunctionCallAction {
                method_name: "vote_reshared".to_string(),
                args: serde_json::to_vec(&args)?,
                gas: 300_000_000_000_000,
                deposit: 0,
            })],
        )
        .await?;

    match result.status {
        FinalExecutionStatus::SuccessValue(value) => Ok(serde_json::from_slice(&value)?),
        status => anyhow::bail!("unexpected status: {:?}", status),
    }
}

'''
'''--- node/src/storage/mod.rs ---
pub mod secret_storage;
pub mod triple_storage;

/// Configures storage.
#[derive(Debug, Clone, clap::Parser)]
#[group(id = "storage_options")]
pub struct Options {
    /// env used to suffix datastore table names to differentiate among environments.
    #[clap(long, env("MPC_RECOVERY_ENV"))]
    pub env: String,
    /// GCP project ID.
    #[clap(long, env("MPC_RECOVERY_GCP_PROJECT_ID"))]
    pub gcp_project_id: String,
    /// GCP Secret Manager ID that will be used to load/store the node's secret key share.
    #[clap(long, env("MPC_RECOVERY_SK_SHARE_SECRET_ID"), requires_all=["gcp_project_id"])]
    pub sk_share_secret_id: Option<String>,
    /// Mostly for integration tests.
    /// GCP Datastore URL that will be used to load/store the node's triples and presignatures.
    #[arg(long, env("MPC_RECOVERY_GCP_DATASTORE_URL"))]
    pub gcp_datastore_url: Option<String>,
}

impl Options {
    pub fn into_str_args(self) -> Vec<String> {
        let mut opts = vec![
            "--env".to_string(),
            self.env,
            "--gcp-project-id".to_string(),
            self.gcp_project_id,
        ];
        if let Some(sk_share_secret_id) = self.sk_share_secret_id {
            opts.extend(vec!["--sk-share-secret-id".to_string(), sk_share_secret_id]);
        }
        if let Some(gcp_datastore_url) = self.gcp_datastore_url {
            opts.extend(vec!["--gcp-datastore-url".to_string(), gcp_datastore_url]);
        }

        opts
    }
}

'''
'''--- node/src/storage/secret_storage.rs ---
use crate::gcp::{GcpService, SecretResult};
use crate::storage::Options;
use crate::{gcp::SecretManagerService, protocol::state::PersistentNodeData};
use async_trait::async_trait;

#[async_trait]
pub trait SecretNodeStorage {
    async fn store(&mut self, data: &PersistentNodeData) -> SecretResult<()>;
    async fn load(&self) -> SecretResult<Option<PersistentNodeData>>;
}

#[derive(Default)]
struct MemoryNodeStorage {
    node_data: Option<PersistentNodeData>,
}

#[async_trait]
impl SecretNodeStorage for MemoryNodeStorage {
    async fn store(&mut self, data: &PersistentNodeData) -> SecretResult<()> {
        tracing::info!("storing PersistentNodeData using memory");
        self.node_data = Some(data.clone());
        Ok(())
    }

    async fn load(&self) -> SecretResult<Option<PersistentNodeData>> {
        tracing::info!("loading PersistentNodeData using memory");
        Ok(self.node_data.clone())
    }
}

struct SecretManagerNodeStorage {
    secret_manager: SecretManagerService,
    sk_share_secret_id: String,
}

impl SecretManagerNodeStorage {
    fn new(secret_manager: &SecretManagerService, sk_share_secret_id: String) -> Self {
        Self {
            secret_manager: secret_manager.clone(),
            sk_share_secret_id,
        }
    }
}

#[async_trait]
impl SecretNodeStorage for SecretManagerNodeStorage {
    async fn store(&mut self, data: &PersistentNodeData) -> SecretResult<()> {
        tracing::debug!("storing PersistentNodeData using SecretNodeStorage");
        self.secret_manager
            .store_secret(&serde_json::to_vec(data)?, &self.sk_share_secret_id)
            .await?;
        Ok(())
    }

    async fn load(&self) -> SecretResult<Option<PersistentNodeData>> {
        tracing::debug!("loading PersistentNodeData using SecretNodeStorage");
        let raw_data = self
            .secret_manager
            .load_secret(&self.sk_share_secret_id)
            .await?;
        match raw_data {
            Some(data) if data.len() > 1 => Ok(Some(serde_json::from_slice(&data)?)),
            _ => {
                tracing::info!("failed to load existing key share, presuming it is missing");
                Ok(None)
            }
        }
    }
}

pub type SecretNodeStorageBox = Box<dyn SecretNodeStorage + Send + Sync>;

pub fn init(gcp_service: Option<&GcpService>, opts: &Options) -> SecretNodeStorageBox {
    match gcp_service {
        Some(gcp) if opts.sk_share_secret_id.is_some() => Box::new(SecretManagerNodeStorage::new(
            &gcp.secret_manager.clone(),
            opts.clone().sk_share_secret_id.unwrap().clone(),
        )) as SecretNodeStorageBox,
        _ => Box::<MemoryNodeStorage>::default() as SecretNodeStorageBox,
    }
}

'''
'''--- node/src/storage/triple_storage.rs ---
use crate::gcp::{error, Keyable};
use crate::gcp::{
    error::ConvertError,
    value::{FromValue, IntoValue, Value},
    KeyKind,
};
use crate::gcp::{DatastoreService, GcpService};
use crate::protocol::triple::{Triple, TripleId};
use async_trait::async_trait;
use google_datastore1::api::{
    Filter, Key, PathElement, PropertyFilter, PropertyReference, Value as DatastoreValue,
};
use near_lake_primitives::AccountId;
use std::collections::{HashMap, HashSet};
use std::sync::Arc;
use tokio::sync::RwLock;

pub struct TripleKey<'a> {
    pub account_id: &'a str,
    pub triple_id: TripleId,
}

impl KeyKind for TripleKey<'_> {
    fn kind() -> String {
        "triples".to_string()
    }
}

impl Keyable for TripleKey<'_> {
    fn key(&self) -> Key {
        Key {
            path: Some(vec![PathElement {
                kind: None,
                name: Some(format!("{}/{}", self.account_id, self.triple_id)),
                id: None,
            }]),
            partition_id: None,
        }
    }
}

#[derive(Clone, Debug)]
pub struct TripleData {
    pub account_id: AccountId,
    pub triple: Triple,
    pub mine: bool,
}

impl KeyKind for TripleData {
    fn kind() -> String {
        "triples".to_string()
    }
}

impl IntoValue for TripleData {
    fn into_value(self) -> Value {
        let triple_key = TripleKey {
            account_id: &self.account_id,
            triple_id: self.triple.id,
        };
        let mut properties = HashMap::new();
        properties.insert(
            "account_id".to_string(),
            Value::StringValue(self.account_id.to_string()),
        );
        properties.insert(
            "triple_id".to_string(),
            Value::IntegerValue(self.triple.id as i64),
        );
        properties.insert(
            "triple_share".to_string(),
            Value::StringValue(serde_json::to_string(&self.triple.share).unwrap()),
        );
        properties.insert(
            "triple_public".to_string(),
            Value::StringValue(serde_json::to_string(&self.triple.public).unwrap()),
        );
        properties.insert("mine".to_string(), Value::BooleanValue(self.mine));
        Value::EntityValue {
            key: triple_key.key(),
            properties,
        }
    }
}

impl FromValue for TripleData {
    fn from_value(value: Value) -> Result<Self, ConvertError> {
        match value {
            Value::EntityValue { mut properties, .. } => {
                let (_, triple_id) = properties
                    .remove_entry("triple_id")
                    .ok_or_else(|| ConvertError::MissingProperty("triple_id".to_string()))?;

                let triple_id = i64::from_value(triple_id)?;
                let (_, account_id) = properties
                    .remove_entry("account_id")
                    .ok_or_else(|| ConvertError::MissingProperty("account_id".to_string()))?;
                let account_id = String::from_value(account_id)?.parse().map_err(|err| {
                    ConvertError::MalformedProperty(format!(
                        "TripleData failed to parse account_id: {err:?}"
                    ))
                })?;

                let (_, triple_share) = properties
                    .remove_entry("triple_share")
                    .ok_or_else(|| ConvertError::MissingProperty("triple_share".to_string()))?;
                let triple_share = String::from_value(triple_share)?;
                let triple_share = serde_json::from_str(&triple_share)
                    .map_err(|_| ConvertError::MalformedProperty("triple_share".to_string()))?;

                let (_, triple_public) = properties
                    .remove_entry("triple_public")
                    .ok_or_else(|| ConvertError::MissingProperty("triple_public".to_string()))?;
                let triple_public = String::from_value(triple_public)?;
                let triple_public = serde_json::from_str(&triple_public)
                    .map_err(|_| ConvertError::MalformedProperty("triple_public".to_string()))?;

                let (_, mine) = properties
                    .remove_entry("mine")
                    .ok_or_else(|| ConvertError::MissingProperty("mine".to_string()))?;
                let mine = bool::from_value(mine)?;

                Ok(Self {
                    account_id,
                    triple: Triple {
                        id: triple_id as u64,
                        share: triple_share,
                        public: triple_public,
                    },
                    mine,
                })
            }
            value => Err(ConvertError::UnexpectedPropertyType {
                expected: "entity".to_string(),
                got: format!("{:?}", value),
            }),
        }
    }
}

type TripleResult<T> = std::result::Result<T, error::DatastoreStorageError>;

#[async_trait]
pub trait TripleNodeStorage {
    async fn insert(&mut self, triple: Triple, mine: bool) -> TripleResult<()>;
    async fn delete(&mut self, id: TripleId) -> TripleResult<()>;
    async fn load(&self) -> TripleResult<Vec<TripleData>>;
    fn account_id(&self) -> &AccountId;
}

#[derive(Clone)]
struct MemoryTripleNodeStorage {
    triples: HashMap<TripleId, Triple>,
    mine: HashSet<TripleId>,
    account_id: AccountId,
}

#[async_trait]
impl TripleNodeStorage for MemoryTripleNodeStorage {
    async fn insert(&mut self, triple: Triple, mine: bool) -> TripleResult<()> {
        if mine {
            self.mine.insert(triple.id);
        }
        self.triples.insert(triple.id, triple);
        Ok(())
    }

    async fn delete(&mut self, id: TripleId) -> TripleResult<()> {
        self.triples.remove(&id);
        self.mine.remove(&id);
        Ok(())
    }

    async fn load(&self) -> TripleResult<Vec<TripleData>> {
        let mut res: Vec<TripleData> = vec![];
        for (triple_id, triple) in self.triples.clone() {
            let mine = self.mine.contains(&triple_id);
            res.push(TripleData {
                account_id: self.account_id().clone(),
                triple,
                mine,
            });
        }
        Ok(res)
    }

    fn account_id(&self) -> &AccountId {
        &self.account_id
    }
}

#[derive(Clone)]
struct DataStoreTripleNodeStorage {
    datastore: DatastoreService,
    account_id: AccountId,
}

impl DataStoreTripleNodeStorage {
    fn new(datastore: DatastoreService, account_id: &AccountId) -> Self {
        Self {
            datastore,
            account_id: account_id.clone(),
        }
    }
}

#[async_trait]
impl TripleNodeStorage for DataStoreTripleNodeStorage {
    async fn insert(&mut self, triple: Triple, mine: bool) -> TripleResult<()> {
        tracing::debug!(id = triple.id, "inserting triples using datastore");
        self.datastore
            .upsert(TripleData {
                account_id: self.account_id().clone(),
                triple,
                mine,
            })
            .await?;
        Ok(())
    }

    async fn delete(&mut self, id: TripleId) -> TripleResult<()> {
        tracing::debug!(id, "deleting triples using datastore");
        self.datastore
            .delete(TripleKey {
                account_id: &self.account_id,
                triple_id: id,
            })
            .await?;
        Ok(())
    }

    async fn load(&self) -> TripleResult<Vec<TripleData>> {
        tracing::debug!("loading triples using datastore");
        let filter = if self.datastore.is_emulator() {
            None
        } else {
            Some(Filter {
                composite_filter: None,
                property_filter: Some(PropertyFilter {
                    op: Some("Equal".to_string()),
                    property: Some(PropertyReference {
                        name: Some("account_id".to_string()),
                    }),
                    value: Some(DatastoreValue::from_value(self.account_id().into_value())?),
                }),
            })
        };
        let response = self.datastore.fetch_entities::<TripleData>(filter).await?;
        let mut res: Vec<TripleData> = vec![];
        for entity_result in response {
            let entity = entity_result.entity.ok_or_else(|| {
                error::DatastoreStorageError::FetchEntitiesError(
                    "entity was not able to unwrapped".to_string(),
                )
            })?;
            let triple_data = TripleData::from_value(entity.into_value())?;
            if &triple_data.account_id == self.account_id() {
                res.push(triple_data);
            }
        }
        tracing::debug!(count = res.len(), "loading triples success");
        Ok(res)
    }

    fn account_id(&self) -> &AccountId {
        &self.account_id
    }
}

pub type TripleNodeStorageBox = Box<dyn TripleNodeStorage + Send + Sync>;

pub struct TripleStorage {
    pub storage: TripleNodeStorageBox,
}

pub type LockTripleNodeStorageBox = Arc<RwLock<TripleNodeStorageBox>>;

pub fn init(gcp_service: Option<&GcpService>, account_id: &AccountId) -> TripleNodeStorageBox {
    match gcp_service {
        Some(gcp) => Box::new(DataStoreTripleNodeStorage::new(
            gcp.datastore.clone(),
            account_id,
        )) as TripleNodeStorageBox,
        _ => Box::new(MemoryTripleNodeStorage {
            triples: HashMap::new(),
            mine: HashSet::new(),
            account_id: account_id.clone(),
        }) as TripleNodeStorageBox,
    }
}

'''
'''--- node/src/test_utils.rs ---
use crate::protocol::contract::primitives::Participants;
use crate::protocol::presignature::GenerationError;
use crate::protocol::triple::{Triple, TripleConfig, TripleId, TripleManager};
use crate::protocol::ParticipantInfo;
use crate::storage::triple_storage::LockTripleNodeStorageBox;
use crate::{gcp::GcpService, protocol::message::TripleMessage, storage};

use cait_sith::protocol::{InitializationError, Participant, ProtocolError};
use std::io::prelude::*;
use std::{collections::HashMap, fs::OpenOptions, ops::Range};

use itertools::multiunzip;
use std::collections::VecDeque;
use std::sync::Arc;
use tokio::sync::RwLock;

// Constants to be used for testing.
const STARTING_EPOCH: u64 = 0;
const TRIPLE_CFG: TripleConfig = TripleConfig {
    min_triples: 2,
    max_triples: 10,
    max_concurrent_introduction: 4,
    max_concurrent_generation: 16,
};

struct TestTripleManagers {
    managers: Vec<TripleManager>,
    participants: Participants,
}

impl TestTripleManagers {
    async fn new(num_managers: u32, datastore_url: Option<String>) -> Self {
        let mut participants = Participants::default();
        (0..num_managers)
            .map(Participant::from)
            .for_each(|p| participants.insert(&p, ParticipantInfo::new(p.into())));

        let mut services = Vec::with_capacity(num_managers as usize);
        for num in 0..num_managers {
            let service = if let Some(url) = &datastore_url {
                let account_id = format!("account_{num}.testnet").parse().unwrap();
                let storage_options = storage::Options {
                    gcp_project_id: "triple-test".to_string(),
                    sk_share_secret_id: None,
                    gcp_datastore_url: Some(url.clone()),
                    env: "triple-test".to_string(),
                };
                Some(
                    GcpService::init(&account_id, &storage_options)
                        .await
                        .unwrap(),
                )
            } else {
                None
            };
            services.push(service);
        }

        let managers = (0..num_managers)
            .map(|num| {
                let account_id = format!("account_{num}.testnet").parse().unwrap();
                let triple_storage: LockTripleNodeStorageBox = Arc::new(RwLock::new(
                    storage::triple_storage::init(services[num as usize].as_ref(), &account_id),
                ));
                TripleManager::new(
                    Participant::from(num),
                    num_managers as usize,
                    STARTING_EPOCH,
                    &TRIPLE_CFG,
                    vec![],
                    triple_storage,
                    &account_id,
                )
            })
            .collect();
        TestTripleManagers {
            managers,
            participants,
        }
    }

    fn generate(&mut self, index: usize) -> Result<(), InitializationError> {
        self.managers[index].generate(&self.participants)
    }

    async fn poke(&mut self, index: usize) -> Result<bool, ProtocolError> {
        let mut quiet = true;
        let messages = self.managers[index].poke().await?;
        for (
            participant,
            ref tm @ TripleMessage {
                id, from, ref data, ..
            },
        ) in messages
        {
            // Self::debug_mailbox(participant.into(), &tm);
            quiet = false;
            let participant_i: u32 = participant.into();
            let manager = &mut self.managers[participant_i as usize];
            if let Some(protocol) = manager.get_or_generate(id, &self.participants).unwrap() {
                protocol.message(from, data.to_vec());
            } else {
                println!("Tried to write to completed mailbox {:?}", tm);
            }
        }
        Ok(quiet)
    }

    #[allow(unused)]
    fn wipe_mailboxes(mailboxes: Range<u32>) {
        for m in mailboxes {
            let mut file = OpenOptions::new()
                .write(true)
                .append(false)
                .create(true)
                .open(format!("{}.csv", m))
                .unwrap();
            write!(file, "").unwrap();
        }
    }
    // This allows you to see what each node is recieving and when
    #[allow(unused)]
    fn debug_mailbox(participant: u32, TripleMessage { id, from, data, .. }: &TripleMessage) {
        let mut file = OpenOptions::new()
            .write(true)
            .append(true)
            .open(format!("{}.csv", participant))
            .unwrap();

        writeln!(file, "'{id}, {from:?}, {}", hex::encode(data)).unwrap();
    }

    async fn poke_until_quiet(&mut self) -> Result<(), ProtocolError> {
        loop {
            let mut quiet = true;
            for i in 0..self.managers.len() {
                let poke = self.poke(i).await?;
                quiet = quiet && poke;
            }
            if quiet {
                return Ok(());
            }
        }
    }

    async fn take_two(
        &mut self,
        index: usize,
        triple_id0: u64,
        triple_id1: u64,
    ) -> Result<(Triple, Triple), GenerationError> {
        self.managers[index].take_two(triple_id0, triple_id1).await
    }

    fn triples(&self, index: usize) -> HashMap<TripleId, Triple> {
        self.managers[index].triples.clone()
    }

    fn mine(&self, index: usize) -> VecDeque<TripleId> {
        self.managers[index].mine.clone()
    }

    fn triple_storage(&self, index: usize) -> LockTripleNodeStorageBox {
        self.managers[index].triple_storage.clone()
    }
}

pub async fn test_triple_generation(datastore_url: Option<String>) {
    const M: usize = 2;
    const N: usize = M + 3;
    // Generate 5 triples
    let mut tm = TestTripleManagers::new(5, datastore_url).await;
    for _ in 0..M {
        tm.generate(0).unwrap();
    }
    tm.poke_until_quiet().await.unwrap();

    tm.generate(1).unwrap();
    tm.generate(2).unwrap();
    tm.generate(4).unwrap();

    tm.poke_until_quiet().await.unwrap();

    let inputs = tm.managers.into_iter().map(|m| {
        (
            m.my_len(),
            m.len(),
            m.generators,
            m.triples,
            m.triple_storage,
            m.mine,
        )
    });

    let (my_lens, lens, generators, mut triples, triple_stores, mines): (
        Vec<_>,
        Vec<_>,
        Vec<_>,
        Vec<_>,
        Vec<_>,
        Vec<_>,
    ) = multiunzip(inputs);

    assert_eq!(
        my_lens.iter().sum::<usize>(),
        N,
        "There should be {N} owned completed triples in total",
    );

    for l in lens {
        assert_eq!(l, N, "All nodes should have {N} completed triples")
    }

    // This passes, but we don't have deterministic entropy or enough triples
    // to ensure that it will no coincidentally fail
    // TODO: deterministic entropy for testing
    // assert_ne!(
    //     my_lens,
    //     vec![M, 1, 1, 0, 1],
    //     "The nodes that started the triple don't own it"
    // );

    for g in generators.iter() {
        assert!(g.is_empty(), "There are no triples still being generated")
    }

    assert_ne!(
        triples.len(),
        1,
        "The number of triples is not 1 before deduping"
    );

    // validates that the triples loaded from triple_storage is the same as the ones generated
    for i in 0..triples.len() {
        let local_mine = mines.get(i).unwrap();
        let local_triples = triples.get(i).unwrap();
        let triple_store = triple_stores.get(i).unwrap();

        let datastore_loaded_triples = {
            let triple_store = triple_store.read().await;
            let datastore_loaded_triples = triple_store
                .load()
                .await
                .expect("the triple loading result should return Ok");
            assert_eq!(
                datastore_loaded_triples.len(),
                local_triples.len(),
                "the number of triples loaded from datastore and stored locally should match"
            );
            datastore_loaded_triples
        };

        for loaded_triple_data in datastore_loaded_triples {
            let loaded_triple = loaded_triple_data.triple;
            assert!(
                local_triples.contains_key(&loaded_triple.id),
                "the loaded triple id should exist locally"
            );
            let local_triple = local_triples.get(&loaded_triple.id).unwrap();
            assert_eq!(
                local_triple.public, loaded_triple.public,
                "local and datastore loaded triple should have same public field value."
            );
            assert_eq!(
                local_triple.share.a, loaded_triple.share.a,
                "local and datastore loaded triple should have same share.a value."
            );
            assert_eq!(
                local_triple.share.b, loaded_triple.share.b,
                "local and datastore loaded triple should have same share.b value."
            );
            assert_eq!(
                local_triple.share.c, loaded_triple.share.c,
                "local and datastore loaded triple should have same share.c value."
            );
            assert_eq!(
                local_mine.contains(&loaded_triple.id),
                loaded_triple_data.mine,
                "local and datastore loaded triple should have same mine value."
            );
        }
    }

    triples.dedup_by_key(|kv| {
        kv.iter_mut()
            .map(|(id, triple)| (*id, (triple.id, triple.public.clone())))
            .collect::<HashMap<_, _>>()
    });

    assert_eq!(
        triples.len(),
        1,
        "All triple IDs and public parts are identical"
    )
}

pub async fn test_triple_deletion(datastore_url: Option<String>) {
    // Generate 3 triples
    let mut tm = TestTripleManagers::new(2, datastore_url).await;
    for _ in 0..3 {
        tm.generate(0).unwrap();
    }
    tm.poke_until_quiet().await.unwrap();

    for i in 0..2 {
        let mut mine = tm.mine(i);
        if mine.len() < 2 {
            continue;
        }
        let id0 = mine.pop_front().unwrap();
        let id1 = mine.pop_front().unwrap();
        let triples = tm.triples(i);
        assert_eq!(triples.len(), 3);
        let triple0 = triples.get(&id0).unwrap();
        assert!(
            tm.take_two(i, id0, id1).await.is_ok(),
            "take_two for participant 0 should succeed for id0 and id1"
        );

        let triple_storage = tm.triple_storage(i);
        {
            let triple_storage = triple_storage.read().await;
            let loaded_triples = triple_storage
                .load()
                .await
                .expect("expected triples to load successfully");
            assert_eq!(
                loaded_triples.len(),
                1,
                "the triples left in store for participant 0 should be 1"
            );
        }

        //verify that if in take_two, one of the triples were accidentally deleted, double deletion will not cause issue
        {
            let mut triple_storage = triple_storage.write().await;
            let del_res_mine_false = triple_storage.delete(triple0.id).await;
            let del_res_mine_true = triple_storage.delete(triple0.id).await;
            assert!(
                del_res_mine_false.is_ok() && del_res_mine_true.is_ok(),
                "repeatedly deleting a triple won't err out"
            );
        };

        {
            let triple_storage = triple_storage.read().await;
            let loaded_triples = triple_storage
                .load()
                .await
                .expect("expected to be able to load recently added triple");
            assert_eq!(
                loaded_triples.len(),
                1,
                "the triples left in store for participant 0 should still be 1"
            );
        }

        //insert triple0 and delete it with the wrong mine value, that does not impact deletion success
        {
            let mut triple_storage = triple_storage.write().await;
            triple_storage
                .insert(triple0.clone(), true)
                .await
                .expect("expected insert to succeed");
            triple_storage
                .delete(triple0.id)
                .await
                .expect("expected delete to succeed");
        }

        {
            let triple_storage = triple_storage.read().await;
            let loaded = triple_storage
                .load()
                .await
                .expect("expected to be able to load at least one triple");
            assert_eq!(
                loaded.len(),
                1,
                "the triples left in store for participant 0 should still be 1"
            );
        }
    }
}

'''
'''--- node/src/types.rs ---
use std::sync::Arc;
use std::time::Duration;

use cait_sith::protocol::{InitializationError, Participant};
use cait_sith::triples::TripleGenerationOutput;
use cait_sith::{protocol::Protocol, KeygenOutput};
use cait_sith::{FullSignature, PresignOutput};
use k256::{elliptic_curve::CurveArithmetic, Secp256k1};
use near_lake_primitives::AccountId;
use tokio::sync::{RwLock, RwLockWriteGuard};

use crate::gcp::error::ConvertError;
use crate::gcp::value::{FromValue, IntoValue, Value};
use crate::gcp::{DatastoreResult, GcpService, KeyKind};
use crate::protocol::contract::ResharingContractState;

/// Default timeout for triple generation protocols. Times out after 20 minutes of being alive.
pub const PROTOCOL_TRIPLE_TIMEOUT: Duration = Duration::from_secs(20 * 60);

/// Default timeout for presig generation protocols. Times out after 1 minute of being alive since this should be shorted lived.
pub const PROTOCOL_PRESIG_TIMEOUT: Duration = Duration::from_secs(60);

/// Default timeout for signature generation protocol. Times out after 1 minute of being alive since this should be shorted lived.
pub const PROTOCOL_SIGNATURE_TIMEOUT: Duration = Duration::from_secs(60);

/// Default invalidation time for failed triples. 120 mins
pub const FAILED_TRIPLES_TIMEOUT: Duration = Duration::from_secs(120 * 60);

/// Default invalidation time for taken triples and presignatures. 120 mins
pub const TAKEN_TIMEOUT: Duration = Duration::from_secs(120 * 60);

pub type SecretKeyShare = <Secp256k1 as CurveArithmetic>::Scalar;
pub type PublicKey = <Secp256k1 as CurveArithmetic>::AffinePoint;
pub type TripleProtocol =
    Box<dyn Protocol<Output = TripleGenerationOutput<Secp256k1>> + Send + Sync>;
pub type PresignatureProtocol = Box<dyn Protocol<Output = PresignOutput<Secp256k1>> + Send + Sync>;
pub type SignatureProtocol = Box<dyn Protocol<Output = FullSignature<Secp256k1>> + Send + Sync>;

#[derive(Clone)]
pub struct KeygenProtocol {
    me: Participant,
    threshold: usize,
    participants: Vec<Participant>,
    protocol: Arc<RwLock<Box<dyn Protocol<Output = KeygenOutput<Secp256k1>> + Send + Sync>>>,
}

impl KeygenProtocol {
    pub fn new(
        participants: &[Participant],
        me: Participant,
        threshold: usize,
    ) -> Result<Self, InitializationError> {
        Ok(Self {
            threshold,
            me,
            participants: participants.into(),
            protocol: Arc::new(RwLock::new(Box::new(cait_sith::keygen::<Secp256k1>(
                participants,
                me,
                threshold,
            )?))),
        })
    }

    pub async fn refresh(&mut self) -> Result<(), InitializationError> {
        *self.write().await = Box::new(cait_sith::keygen::<Secp256k1>(
            &self.participants,
            self.me,
            self.threshold,
        )?);
        Ok(())
    }

    pub async fn write(
        &self,
    ) -> RwLockWriteGuard<'_, Box<dyn Protocol<Output = KeygenOutput<Secp256k1>> + Send + Sync>>
    {
        self.protocol.write().await
    }
}

#[derive(Clone)]
pub struct ReshareProtocol {
    old_participants: Vec<Participant>,
    new_participants: Vec<Participant>,
    me: Participant,
    threshold: usize,
    private_share: Option<SecretKeyShare>,
    protocol: Arc<RwLock<Box<dyn Protocol<Output = SecretKeyShare> + Send + Sync>>>,
    root_pk: PublicKey,
}

impl ReshareProtocol {
    pub fn new(
        private_share: Option<SecretKeyShare>,
        me: Participant,
        contract_state: &ResharingContractState,
    ) -> Result<Self, InitializationError> {
        let old_participants = contract_state.old_participants.keys_vec();
        let new_participants = contract_state.new_participants.keys_vec();

        Ok(Self {
            protocol: Arc::new(RwLock::new(Box::new(cait_sith::reshare::<Secp256k1>(
                &old_participants,
                contract_state.threshold,
                &new_participants,
                contract_state.threshold,
                me,
                private_share,
                contract_state.public_key,
            )?))),
            private_share,
            me,
            threshold: contract_state.threshold,
            old_participants,
            new_participants,
            root_pk: contract_state.public_key,
        })
    }

    pub async fn refresh(&mut self) -> Result<(), InitializationError> {
        *self.write().await = Box::new(cait_sith::reshare::<Secp256k1>(
            &self.old_participants,
            self.threshold,
            &self.new_participants,
            self.threshold,
            self.me,
            self.private_share,
            self.root_pk,
        )?);
        Ok(())
    }

    pub async fn write(
        &self,
    ) -> RwLockWriteGuard<'_, Box<dyn Protocol<Output = SecretKeyShare> + Send + Sync>> {
        self.protocol.write().await
    }
}

#[derive(Clone, Debug)]
pub struct LatestBlockHeight {
    pub account_id: AccountId,
    pub block_height: near_primitives::types::BlockHeight,
}

impl LatestBlockHeight {
    pub async fn fetch(gcp: &GcpService) -> DatastoreResult<Self> {
        gcp.datastore
            .get(format!("{}/latest-block-height", gcp.account_id))
            .await
    }

    pub fn set(&mut self, block_height: near_primitives::types::BlockHeight) -> &mut Self {
        self.block_height = block_height;
        self
    }

    pub async fn store(&self, gcp: &GcpService) -> DatastoreResult<()> {
        gcp.datastore.upsert(self).await
    }
}

impl IntoValue for LatestBlockHeight {
    fn into_value(self) -> Value {
        (&self).into_value()
    }
}

impl IntoValue for &LatestBlockHeight {
    fn into_value(self) -> Value {
        let properties = {
            let mut properties = std::collections::HashMap::new();
            properties.insert(
                "account_id".to_string(),
                Value::StringValue(self.account_id.to_string()),
            );
            properties.insert(
                "block_height".to_string(),
                Value::IntegerValue(self.block_height as i64),
            );
            properties
        };
        Value::EntityValue {
            key: google_datastore1::api::Key {
                path: Some(vec![google_datastore1::api::PathElement {
                    kind: Some(LatestBlockHeight::kind()),
                    name: Some(format!("{}/latest-block-height", self.account_id)),
                    id: None,
                }]),
                partition_id: None,
            },
            properties,
        }
    }
}

impl FromValue for LatestBlockHeight {
    fn from_value(value: Value) -> Result<Self, ConvertError> {
        match value {
            Value::EntityValue {
                key: _,
                mut properties,
            } => {
                let account_id = properties
                    .remove("account_id")
                    .ok_or_else(|| ConvertError::MissingProperty("account_id".to_string()))?;
                let account_id = String::from_value(account_id)?.parse().map_err(|err| {
                    ConvertError::MalformedProperty(format!(
                        "LatestBlockHeight failed to parse account_id: {err:?}",
                    ))
                })?;

                let block_height = properties
                    .remove("block_height")
                    .ok_or_else(|| ConvertError::MissingProperty("block_height".to_string()))?;
                let block_height = i64::from_value(block_height)? as u64;

                Ok(LatestBlockHeight {
                    account_id,
                    block_height,
                })
            }
            _ => Err(ConvertError::UnexpectedPropertyType {
                expected: String::from("integer"),
                got: String::from(value.type_name()),
            }),
        }
    }
}

impl KeyKind for LatestBlockHeight {
    fn kind() -> String {
        "LatestBlockHeight".to_string()
    }
}

impl KeyKind for &LatestBlockHeight {
    fn kind() -> String {
        "LatestBlockHeight".to_string()
    }
}

'''
'''--- node/src/util.rs ---
use crate::types::PublicKey;
use chrono::{DateTime, LocalResult, TimeZone, Utc};
use k256::elliptic_curve::scalar::FromUintUnchecked;
use k256::elliptic_curve::sec1::{FromEncodedPoint, ToEncodedPoint};
use k256::{AffinePoint, EncodedPoint, Scalar, U256};
use std::env;
use std::time::Duration;

pub trait NearPublicKeyExt {
    fn into_affine_point(self) -> PublicKey;
}

impl NearPublicKeyExt for String {
    fn into_affine_point(self) -> PublicKey {
        let public_key_value = serde_json::json!(self);
        serde_json::from_value(public_key_value).expect("Failed to deserialize struct")
    }
}

impl NearPublicKeyExt for near_sdk::PublicKey {
    fn into_affine_point(self) -> PublicKey {
        let mut bytes = self.into_bytes();
        bytes[0] = 0x04;
        let point = EncodedPoint::from_bytes(bytes).unwrap();
        PublicKey::from_encoded_point(&point).unwrap()
    }
}

impl NearPublicKeyExt for near_crypto::Secp256K1PublicKey {
    fn into_affine_point(self) -> PublicKey {
        let mut bytes = vec![0x04];
        bytes.extend_from_slice(self.as_ref());
        let point = EncodedPoint::from_bytes(bytes).unwrap();
        PublicKey::from_encoded_point(&point).unwrap()
    }
}

impl NearPublicKeyExt for near_crypto::PublicKey {
    fn into_affine_point(self) -> PublicKey {
        match self {
            near_crypto::PublicKey::SECP256K1(public_key) => public_key.into_affine_point(),
            near_crypto::PublicKey::ED25519(_) => panic!("unsupported key type"),
        }
    }
}

pub trait AffinePointExt {
    fn into_near_public_key(self) -> near_crypto::PublicKey;
    fn to_base58(&self) -> String;
}

impl AffinePointExt for AffinePoint {
    fn into_near_public_key(self) -> near_crypto::PublicKey {
        near_crypto::PublicKey::SECP256K1(
            near_crypto::Secp256K1PublicKey::try_from(
                &self.to_encoded_point(false).as_bytes()[1..65],
            )
            .unwrap(),
        )
    }

    fn to_base58(&self) -> String {
        let key = near_crypto::Secp256K1PublicKey::try_from(
            &self.to_encoded_point(false).as_bytes()[1..65],
        )
        .unwrap();
        format!("{:?}", key)
    }
}

pub trait ScalarExt {
    fn from_bytes(bytes: &[u8]) -> Self;
}

impl ScalarExt for Scalar {
    fn from_bytes(bytes: &[u8]) -> Self {
        Scalar::from_uint_unchecked(U256::from_le_slice(bytes))
    }
}

pub fn get_triple_timeout() -> Duration {
    env::var("MPC_RECOVERY_TRIPLE_TIMEOUT_SEC")
        .map(|val| val.parse::<u64>().ok().map(Duration::from_secs))
        .unwrap_or_default()
        .unwrap_or(crate::types::PROTOCOL_TRIPLE_TIMEOUT)
}

pub fn is_elapsed_longer_than_timeout(timestamp_sec: u64, timeout: Duration) -> bool {
    if let LocalResult::Single(msg_timestamp) = Utc.timestamp_opt(timestamp_sec as i64, 0) {
        let now_datetime: DateTime<Utc> = Utc::now();
        // Calculate the difference in seconds
        let elapsed_duration = now_datetime.signed_duration_since(msg_timestamp);
        let timeout = chrono::Duration::seconds(timeout.as_secs() as i64)
            + chrono::Duration::nanoseconds(timeout.subsec_nanos() as i64);
        elapsed_duration > timeout
    } else {
        false
    }
}

'''
'''--- node/src/web/error.rs ---
use axum::extract::rejection::JsonRejection;
use reqwest::StatusCode;
use tokio::sync::mpsc::error::SendError;

use crate::protocol::{ConsensusError, CryptographicError, MpcMessage};

pub type Result<T, E = Error> = std::result::Result<T, E>;

/// This enum error type serves as one true source of all futures in sign-node
/// crate. It is used to unify all errors that can happen in the application.
#[derive(Debug, thiserror::Error)]
pub enum Error {
    #[error(transparent)]
    JsonExtractorRejection(#[from] JsonRejection),
    #[error(transparent)]
    Protocol(#[from] ConsensusError),
    #[error(transparent)]
    Cryptography(#[from] CryptographicError),
    #[error(transparent)]
    Message(#[from] SendError<MpcMessage>),
    #[error(transparent)]
    Rpc(#[from] near_fetch::Error),
}

impl Error {
    pub fn status(&self) -> StatusCode {
        match self {
            Error::JsonExtractorRejection(rejection) => rejection.status(),
            Error::Protocol(_) => StatusCode::INTERNAL_SERVER_ERROR,
            Error::Cryptography(_) => StatusCode::INTERNAL_SERVER_ERROR,
            Error::Message(_) => StatusCode::INTERNAL_SERVER_ERROR,
            Error::Rpc(_) => StatusCode::BAD_REQUEST,
        }
    }
}

impl axum::response::IntoResponse for Error {
    fn into_response(self) -> axum::response::Response {
        let status = self.status();
        let message = match self {
            Error::JsonExtractorRejection(json_rejection) => json_rejection.body_text(),
            err => format!("{err:?}"),
        };

        (status, axum::Json(message)).into_response()
    }
}

'''
'''--- node/src/web/mod.rs ---
mod error;

use self::error::Error;
use crate::protocol::message::SignedMessage;
use crate::protocol::{MpcMessage, NodeState};
use crate::web::error::Result;
use anyhow::Context;
use axum::http::StatusCode;
use axum::routing::{get, post};
use axum::{Extension, Json, Router};
use axum_extra::extract::WithRejection;
use cait_sith::protocol::Participant;
use mpc_keys::hpke::{self, Ciphered};
use prometheus::{Encoder, TextEncoder};
use serde::{Deserialize, Serialize};
use std::{net::SocketAddr, sync::Arc};
use tokio::sync::{mpsc::Sender, RwLock};

struct AxumState {
    sender: Sender<MpcMessage>,
    protocol_state: Arc<RwLock<NodeState>>,
    cipher_sk: hpke::SecretKey,
}

pub async fn run(
    port: u16,
    sender: Sender<MpcMessage>,
    cipher_sk: hpke::SecretKey,
    protocol_state: Arc<RwLock<NodeState>>,
) -> anyhow::Result<()> {
    tracing::debug!("running a node");
    let axum_state = AxumState {
        sender,
        protocol_state,
        cipher_sk,
    };

    let app = Router::new()
        // healthcheck endpoint
        .route(
            "/",
            get(|| async move {
                tracing::info!("node is ready to accept connections");
                StatusCode::OK
            }),
        )
        .route("/msg", post(msg))
        .route("/state", get(state))
        .route("/metrics", get(metrics))
        .layer(Extension(Arc::new(axum_state)));

    let addr = SocketAddr::from(([0, 0, 0, 0], port));
    tracing::info!(?addr, "starting http server");
    axum::Server::bind(&addr)
        .serve(app.into_make_service())
        .await
        .unwrap();

    Ok(())
}

#[derive(Serialize, Deserialize, Debug, Clone)]
pub struct MsgRequest {
    pub from: Participant,
    pub msg: Vec<u8>,
}

#[tracing::instrument(level = "debug", skip_all)]
async fn msg(
    Extension(state): Extension<Arc<AxumState>>,
    WithRejection(Json(encrypted), _): WithRejection<Json<Vec<Ciphered>>, Error>,
) -> Result<()> {
    for encrypted in encrypted.into_iter() {
        let message = match SignedMessage::decrypt(
            &state.cipher_sk,
            &state.protocol_state,
            encrypted,
        )
        .await
        {
            Ok(msg) => msg,
            Err(err) => {
                tracing::error!(?err, "failed to decrypt or verify an encrypted message");
                return Err(err.into());
            }
        };

        if let Err(err) = state.sender.send(message).await {
            tracing::error!(?err, "failed to forward an encrypted protocol message");
            return Err(err.into());
        }
    }
    Ok(())
}

#[derive(Debug, Serialize, Deserialize)]
#[serde(tag = "type")]
#[serde(rename_all = "snake_case")]
pub enum StateView {
    Running {
        participants: Vec<Participant>,
        triple_count: usize,
        triple_mine_count: usize,
        triple_potential_count: usize,
        presignature_count: usize,
        presignature_mine_count: usize,
        presignature_potential_count: usize,
    },
    NotRunning,
}

#[tracing::instrument(level = "debug", skip_all)]
async fn state(Extension(state): Extension<Arc<AxumState>>) -> Result<Json<StateView>> {
    tracing::debug!("fetching state");
    let protocol_state = state.protocol_state.read().await;
    match &*protocol_state {
        NodeState::Running(state) => {
            let triple_manager_read = state.triple_manager.read().await;
            let triple_potential_count = triple_manager_read.potential_len();
            let triple_count = triple_manager_read.len();
            let triple_mine_count = triple_manager_read.my_len();
            let presignature_read = state.presignature_manager.read().await;
            let presignature_count = presignature_read.len();
            let presignature_mine_count = presignature_read.my_len();
            let presignature_potential_count = presignature_read.potential_len();
            Ok(Json(StateView::Running {
                participants: state.participants.keys().cloned().collect(),
                triple_count,
                triple_mine_count,
                triple_potential_count,
                presignature_count,
                presignature_mine_count,
                presignature_potential_count,
            }))
        }
        _ => {
            tracing::debug!("not running, state unavailable");
            Ok(Json(StateView::NotRunning))
        }
    }
}

#[tracing::instrument(level = "debug", skip_all)]
async fn metrics() -> (StatusCode, String) {
    let grab_metrics = || {
        let encoder = TextEncoder::new();
        let mut buffer = vec![];
        encoder
            .encode(&prometheus::gather(), &mut buffer)
            .context("failed to encode metrics")?;

        let response =
            String::from_utf8(buffer).with_context(|| "failed to convert bytes to string")?;

        Ok::<String, anyhow::Error>(response)
    };

    match grab_metrics() {
        Ok(response) => (StatusCode::OK, response),
        Err(err) => {
            tracing::error!("failed to generate prometheus metrics: {err}");
            (
                StatusCode::INTERNAL_SERVER_ERROR,
                "failed to generate prometheus metrics".to_string(),
            )
        }
    }
}

'''
'''--- rustfmt.toml ---
edition = "2024"

'''
'''--- test-oidc-provider/Cargo.toml ---
[package]
name = "test-oidc-provider"
version = "0.1.0"
edition = "2021"

# See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html

[dependencies]
axum = "0.6.2"
tokio = { version = "1.28", features = ["full"] }
tracing = "0.1"
tracing-subscriber = { version = "0.3", features = ["env-filter"] }

'''
'''--- test-oidc-provider/README.md ---
# Test OIDC Provider
Simplistic server that can return a public key in RSA PEM format for JWT Roken validation.

## Usage
1. Build Dcoker image
```bash
docker build -t near/test-oidc-provider .
```
2. Run Integration or other type of tests
'''
'''--- test-oidc-provider/src/main.rs ---
use std::{
    collections::{hash_map::DefaultHasher, HashMap},
    hash::{Hash, Hasher},
    net::SocketAddr,
};

use axum::{routing::get, Router};
use tracing_subscriber::EnvFilter;

const PUBLIC_KEY: &str = "-----BEGIN PUBLIC KEY-----MIICIjANBgkqhkiG9w0BAQEFAAOCAg8AMIICCgKCAgEAg6UuFBM3QmtQID8cOHltjM8WF/XpFj2d5feVShG19jan76n6kEQPIhbqC4gweqWWdKdwbOmJKvDzV7qER5BC2tKB7ViKRFpsEc5pSp2vc4w81Wni9Dzicpz1R0Qr2p3lkqLuG6G/nJaD6s0KMfiyPiIBSBOgd1gaGIZcN2MtZm4bT2cVBxgBBW9L3bkpyONf0JHtia+6M7LPwzKwd29LYuirPFU31psCBejXwuWst/KBncEeHASEW/LK0UJS4tJVH05mNuicBjKkYJ8Q+UTVZPA+8bgkrWEzScAoedVn+QwbwUxZ+C0r1NunllwU+e29s9rpf9wifzX43vA4FGPYdDuEPiGmaNqFTsV/Z8oOMLDuAt/QqFVrp24S6DyHy/aWAZcJzcAbwckP0B5GsrvbAogcWzPpRzFLFkPmsQ1IMG/MK382AJ04rh+u0jomXxImLYiDFvzEXTelNsiDICHY6PQ1Fd/OfxuKVFl4cVVx5VeyWOIAjRePaeMaijHr0KrxKDZiz+Umx8UJTwbjAfPx9fM5mvBXlmsXYAm/hmnp74xDlr/s8c4fAyXmuqRocu8jq0GkMDjYJKj2QQSZSLQUMxmeF6gRIFpjK8mawsSvM88Kiu6o/pZD3i0e3QL5OBwYjcd0muxY23yvcmdVmLeTds+wB0xAtA8wkWEu8N8SGXcCAwEAAQ==-----END PUBLIC KEY-----";

#[tokio::main]
async fn main() {
    // Tracing setup
    tracing_subscriber::fmt()
        .with_thread_ids(true)
        .with_env_filter(EnvFilter::from_default_env())
        .init();

    tracing::info!("Starting Test OIDC Provider server...");
    let app = Router::new().route(
        "/jwt_signature_public_keys",
        get(jwt_signature_public_keys_handler),
    );

    let addr = SocketAddr::from(([0, 0, 0, 0], 3000));

    tracing::info!(?addr, "Binding OIDC Provider server...");
    axum::Server::bind(&addr)
        .serve(app.into_make_service())
        .await
        .expect("Failed to bind server");
}

async fn jwt_signature_public_keys_handler() -> impl axum::response::IntoResponse {
    tracing::info!("jwt_signature_public_keys called");
    axum::Json(jwt_signature_public_keys().await)
}

async fn jwt_signature_public_keys() -> HashMap<String, String> {
    let public_keys = HashMap::from([(hash_string(PUBLIC_KEY), String::from(PUBLIC_KEY))]);
    tracing::info!("Returning jwt_signature_public_keys: {:?}", public_keys);
    public_keys
}

fn hash_string(input_string: &str) -> String {
    let mut hasher = DefaultHasher::new();
    input_string.hash(&mut hasher);
    hasher.finish().to_string()
}

'''